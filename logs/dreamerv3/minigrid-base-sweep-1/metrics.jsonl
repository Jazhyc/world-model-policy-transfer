{"step": 1560, "time": 157.0198631286621, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 157.03587102890015, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 158.4125394821167, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 158.421795129776, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 158.43121981620789, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 158.43901205062866, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 158.45119190216064, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 158.45884490013123, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1561, "time": 281.78500747680664, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.81011962890625, "train/action_min": 0.0, "train/action_std": 2.178781270980835, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0020594652742147446, "train/actor_opt_grad_steps": 1.0, "train/actor_opt_loss": -2.954118251800537, "train/adv_mag": 0.0, "train/adv_max": 0.0, "train/adv_mean": 0.0, "train/adv_min": 0.0, "train/adv_std": 0.0, "train/cont_avg": 1.0, "train/cont_loss_mean": 0.47758394479751587, "train/cont_loss_std": 0.2245846837759018, "train/cont_neg_acc": NaN, "train/cont_neg_loss": NaN, "train/cont_pos_acc": 0.8427734375, "train/cont_pos_loss": 0.47758394479751587, "train/cont_pred": 0.6348351240158081, "train/cont_rate": 1.0, "train/dyn_loss_mean": 10.00960922241211, "train/dyn_loss_std": 0.41940438747406006, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 16.723114013671875, "train/extr_critic_critic_opt_grad_steps": 1.0, "train/extr_critic_critic_opt_loss": 66703.421875, "train/extr_critic_mag": 0.0, "train/extr_critic_max": 0.0, "train/extr_critic_mean": 0.0, "train/extr_critic_min": 0.0, "train/extr_critic_std": 0.0, "train/extr_return_normed_mag": 0.0, "train/extr_return_normed_max": 0.0, "train/extr_return_normed_mean": 0.0, "train/extr_return_normed_min": 0.0, "train/extr_return_normed_std": 0.0, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.0, "train/extr_return_raw_max": 0.0, "train/extr_return_raw_mean": 0.0, "train/extr_return_raw_min": 0.0, "train/extr_return_raw_std": 0.0, "train/extr_reward_mag": 0.0, "train/extr_reward_max": 0.0, "train/extr_reward_mean": 0.0, "train/extr_reward_min": 0.0, "train/extr_reward_std": 0.0, "train/image_loss_mean": 5040.1357421875, "train/image_loss_std": 39.978816986083984, "train/model_loss_mean": 5052.1611328125, "train/model_loss_std": 39.947898864746094, "train/model_opt_grad_norm": NaN, "train/model_opt_grad_steps": 0.0, "train/model_opt_loss": 50521612.0, "train/model_opt_model_opt_grad_overflow": 1.0, "train/model_opt_model_opt_grad_scale": 5000.0, "train/policy_entropy_mag": 1.93852698802948, "train/policy_entropy_max": 1.93852698802948, "train/policy_entropy_mean": 1.6351069211959839, "train/policy_entropy_min": 0.6143265962600708, "train/policy_entropy_std": 0.18148955702781677, "train/policy_logprob_mag": 4.640588760375977, "train/policy_logprob_max": -0.13954919576644897, "train/policy_logprob_mean": -1.6218725442886353, "train/policy_logprob_min": -4.640588760375977, "train/policy_logprob_std": 0.7638269066810608, "train/policy_randomness_mag": 0.9962058663368225, "train/policy_randomness_max": 0.9962058663368225, "train/policy_randomness_mean": 0.8402787446975708, "train/policy_randomness_min": 0.315701425075531, "train/policy_randomness_std": 0.09326718002557755, "train/post_ent_mag": 106.44729614257812, "train/post_ent_max": 106.44729614257812, "train/post_ent_mean": 106.17073059082031, "train/post_ent_min": 105.81322479248047, "train/post_ent_std": 0.10022274404764175, "train/prior_ent_mag": 106.80499267578125, "train/prior_ent_max": 106.80499267578125, "train/prior_ent_mean": 105.86888885498047, "train/prior_ent_min": 104.71406555175781, "train/prior_ent_std": 0.2803392708301544, "train/rep_loss_mean": 10.00960922241211, "train/rep_loss_std": 0.41940438747406006, "train/reward_avg": 0.0, "train/reward_loss_mean": 5.541262626647949, "train/reward_loss_std": 9.5367431640625e-07, "train/reward_max_data": 0.0, "train/reward_max_pred": 0.0, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 5.541262626647949, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0, "train/reward_rate": 0.0, "train/params_agent/wm/model_opt": 181559683.0, "train/params_agent/task_behavior/critic/critic_opt": 9708799.0, "train/params_agent/task_behavior/ac/actor_opt": 9454599.0, "report/cont_avg": 1.0, "report/cont_loss_mean": 0.4550374746322632, "report/cont_loss_std": 0.2396651655435562, "report/cont_neg_acc": NaN, "report/cont_neg_loss": NaN, "report/cont_pos_acc": 0.853515625, "report/cont_pos_loss": 0.4550374746322632, "report/cont_pred": 0.6509164571762085, "report/cont_rate": 1.0, "report/dyn_loss_mean": 10.036943435668945, "report/dyn_loss_std": 0.3896080553531647, "report/image_loss_mean": 5045.67236328125, "report/image_loss_std": 38.26341247558594, "report/model_loss_mean": 5057.6904296875, "report/model_loss_std": 38.197853088378906, "report/post_ent_mag": 106.49116516113281, "report/post_ent_max": 106.49116516113281, "report/post_ent_mean": 106.15187072753906, "report/post_ent_min": 105.86280822753906, "report/post_ent_std": 0.1030462235212326, "report/prior_ent_mag": 106.61581420898438, "report/prior_ent_max": 106.61581420898438, "report/prior_ent_mean": 105.82603454589844, "report/prior_ent_min": 104.73328399658203, "report/prior_ent_std": 0.27694907784461975, "report/rep_loss_mean": 10.036943435668945, "report/rep_loss_std": 0.3896080553531647, "report/reward_avg": 0.0, "report/reward_loss_mean": 5.541262626647949, "report/reward_loss_std": 9.5367431640625e-07, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.0, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 5.541262626647949, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.44306862354278564, "eval/cont_loss_std": 0.2186591476202011, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 0.8828125, "eval/cont_pos_loss": 0.44306862354278564, "eval/cont_pred": 0.656152069568634, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 10.03765869140625, "eval/dyn_loss_std": 0.40993532538414, "eval/image_loss_mean": 5039.9423828125, "eval/image_loss_std": 35.93557357788086, "eval/model_loss_mean": 5051.94921875, "eval/model_loss_std": 35.93947982788086, "eval/post_ent_mag": 106.445068359375, "eval/post_ent_max": 106.445068359375, "eval/post_ent_mean": 106.175537109375, "eval/post_ent_min": 105.85000610351562, "eval/post_ent_std": 0.10312855243682861, "eval/prior_ent_mag": 106.72132110595703, "eval/prior_ent_max": 106.72132110595703, "eval/prior_ent_mean": 105.86556243896484, "eval/prior_ent_min": 105.02665710449219, "eval/prior_ent_std": 0.30138716101646423, "eval/rep_loss_mean": 10.03765869140625, "eval/rep_loss_std": 0.40993532538414, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 5.541262626647949, "eval/reward_loss_std": 9.5367431640625e-07, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 5.541262626647949, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0, "eval/reward_rate": 0.0, "replay/size": 1057.0, "replay/inserts": 1057.0, "replay/samples": 112.0, "replay/insert_wait_avg": 1.5493824218057075e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.578304835728236e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 3368.0, "eval_replay/inserts": 3368.0, "eval_replay/samples": 112.0, "eval_replay/insert_wait_avg": 1.323548745089642e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.131776537214006e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 152.10321235656738, "timer/env.step_count": 196.0, "timer/env.step_total": 1.3205211162567139, "timer/env.step_frac": 0.008681743769888877, "timer/env.step_avg": 0.006737352633962826, "timer/env.step_min": 0.006182432174682617, "timer/env.step_max": 0.017316341400146484, "timer/replay._sample_count": 112.0, "timer/replay._sample_total": 0.08424949645996094, "timer/replay._sample_frac": 0.0005538968911613739, "timer/replay._sample_avg": 0.0007522276469639369, "timer/replay._sample_min": 0.0003561973571777344, "timer/replay._sample_max": 0.0011839866638183594, "timer/agent.save_count": 1.0, "timer/agent.save_total": 2.090348243713379, "timer/agent.save_frac": 0.013742959213859915, "timer/agent.save_avg": 2.090348243713379, "timer/agent.save_min": 2.090348243713379, "timer/agent.save_max": 2.090348243713379, "timer/agent.policy_count": 290.0, "timer/agent.policy_total": 24.097272396087646, "timer/agent.policy_frac": 0.1584271102677155, "timer/agent.policy_avg": 0.08309404274512981, "timer/agent.policy_min": 0.009251594543457031, "timer/agent.policy_max": 18.360510110855103, "timer/dataset_train_count": 1.0, "timer/dataset_train_total": 4.9114227294921875e-05, "timer/dataset_train_frac": 3.229006576125824e-07, "timer/dataset_train_avg": 4.9114227294921875e-05, "timer/dataset_train_min": 4.9114227294921875e-05, "timer/dataset_train_max": 4.9114227294921875e-05, "timer/agent.train_count": 1.0, "timer/agent.train_total": 96.00168108940125, "timer/agent.train_frac": 0.6311614304657134, "timer/agent.train_avg": 96.00168108940125, "timer/agent.train_min": 96.00168108940125, "timer/agent.train_max": 96.00168108940125, "timer/agent.report_count": 2.0, "timer/agent.report_total": 24.60456132888794, "timer/agent.report_frac": 0.16176227278624983, "timer/agent.report_avg": 12.30228066444397, "timer/agent.report_min": 0.24695253372192383, "timer/agent.report_max": 24.357608795166016, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.504753112792969e-05, "timer/dataset_eval_frac": 2.3041940130606608e-07, "timer/dataset_eval_avg": 3.504753112792969e-05, "timer/dataset_eval_min": 3.504753112792969e-05, "timer/dataset_eval_max": 3.504753112792969e-05}
{"step": 2312, "time": 304.6366150379181, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 2312, "time": 304.6452238559723, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 2312, "time": 304.65646386146545, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 2312, "time": 304.66659212112427, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 2312, "time": 304.67585587501526, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 2312, "time": 304.685818195343, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 2312, "time": 304.69562339782715, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 2312, "time": 304.7074408531189, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 4624, "time": 376.2701413631439, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 4624, "time": 376.2873046398163, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 4624, "time": 376.2988691329956, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 4624, "time": 376.30971455574036, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 4624, "time": 376.31852316856384, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 4624, "time": 376.3258798122406, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 4624, "time": 376.332236289978, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 4624, "time": 376.340457201004, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 6232, "time": 425.63015389442444, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 6936, "time": 447.45297050476074, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 6936, "time": 447.4673101902008, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 6936, "time": 447.4775061607361, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 6936, "time": 447.489271402359, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 6936, "time": 447.5014479160309, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 6936, "time": 447.5093400478363, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 6936, "time": 447.5185546875, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 8064, "time": 482.49390387535095, "episode/length": 228.0, "episode/score": 0.2874999940395355, "episode/reward_rate": 0.004366812227074236, "episode/intrinsic_return": 0.0}
{"step": 9248, "time": 519.5592555999756, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 9248, "time": 519.5792109966278, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 9248, "time": 519.5916068553925, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 9248, "time": 519.6013770103455, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 9248, "time": 519.608282327652, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 9248, "time": 519.6157896518707, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 9248, "time": 519.6231677532196, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 9920, "time": 540.2071113586426, "episode/length": 231.0, "episode/score": 0.27812498807907104, "episode/reward_rate": 0.004310344827586207, "episode/intrinsic_return": 0.0}
{"step": 10088, "time": 549.186196565628, "eval_episode/length": 185.0, "eval_episode/score": 0.421875, "eval_episode/reward_rate": 0.005376344086021506}
{"step": 10088, "time": 551.278698682785, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 551.285208940506, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 551.291913986206, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 551.2995908260345, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 551.3065092563629, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 551.3134198188782, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 551.3211936950684, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 11560, "time": 596.7499814033508, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 11560, "time": 596.7621974945068, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 11560, "time": 596.7713055610657, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 11560, "time": 596.7796132564545, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 11560, "time": 596.7875337600708, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 11560, "time": 596.794909954071, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 11560, "time": 596.8022122383118, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 12232, "time": 617.4455099105835, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 12248, "time": 617.937837600708, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 13872, "time": 667.8734171390533, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 13872, "time": 667.8924906253815, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 13872, "time": 667.9045803546906, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 13872, "time": 667.9134426116943, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 13872, "time": 667.9231321811676, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 13872, "time": 667.9311304092407, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 14544, "time": 688.5476686954498, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 14560, "time": 689.0445272922516, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 16184, "time": 738.9432408809662, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 16184, "time": 738.9572439193726, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 16184, "time": 738.9662692546844, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 16184, "time": 738.9760358333588, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 16184, "time": 738.984246969223, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 16184, "time": 738.9921889305115, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 16856, "time": 760.276287317276, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 16872, "time": 760.7748188972473, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 18496, "time": 811.2107529640198, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 18496, "time": 811.2242193222046, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 18496, "time": 811.232723236084, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 18496, "time": 811.2435357570648, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 18496, "time": 811.2509865760803, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 18496, "time": 811.2574760913849, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 19168, "time": 832.009458065033, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 19184, "time": 832.5078132152557, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 20072, "time": 864.706964969635, "eval_episode/length": 236.0, "eval_episode/score": 0.26249998807907104, "eval_episode/reward_rate": 0.004219409282700422}
{"step": 20072, "time": 866.4473948478699, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 866.4560911655426, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 866.4654424190521, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 866.4736115932465, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 866.4831821918488, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 866.4914338588715, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 866.5018651485443, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20808, "time": 889.1771194934845, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 20808, "time": 889.1931138038635, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 20808, "time": 889.2035095691681, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 20808, "time": 889.2131628990173, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 20808, "time": 889.222718000412, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 20808, "time": 889.2334413528442, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 21480, "time": 909.9386813640594, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 21496, "time": 910.4311702251434, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 22200, "time": 932.0542824268341, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 22864, "time": 952.7879002094269, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 23120, "time": 960.7305953502655, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 23120, "time": 960.7382645606995, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 23120, "time": 960.7464089393616, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 23120, "time": 960.757087469101, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 23120, "time": 960.7671754360199, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 23792, "time": 981.6044075489044, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 24512, "time": 1003.7259376049042, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 25176, "time": 1024.4117000102997, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 25432, "time": 1032.471803188324, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 25432, "time": 1032.481722354889, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 25432, "time": 1032.4930386543274, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 25432, "time": 1032.5016927719116, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 25432, "time": 1032.5134410858154, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 26104, "time": 1053.13321518898, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 26824, "time": 1075.2120978832245, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 27488, "time": 1095.9064269065857, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 27744, "time": 1103.7522847652435, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 27744, "time": 1103.7596335411072, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 27744, "time": 1103.7677946090698, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 27744, "time": 1103.778207540512, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 27744, "time": 1103.7893867492676, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 28416, "time": 1124.7786519527435, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 29136, "time": 1147.137230873108, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 29800, "time": 1167.4088351726532, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 30056, "time": 1175.3164010047913, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 30056, "time": 1175.3246989250183, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 30056, "time": 1175.3342854976654, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 30056, "time": 1175.3439259529114, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 30056, "time": 1175.3539907932281, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 30056, "time": 1181.6310019493103, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1181.6411559581757, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1181.6507151126862, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1181.6618452072144, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1181.6716034412384, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1181.6819591522217, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1181.6911430358887, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1181.7003667354584, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30728, "time": 1202.3923797607422, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 31448, "time": 1224.673513174057, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 31496, "time": 1226.1688587665558, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 32112, "time": 1245.475109577179, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 32368, "time": 1253.3206696510315, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 32368, "time": 1253.3297007083893, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 32368, "time": 1253.340006828308, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 32368, "time": 1253.3490152359009, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 32368, "time": 1253.3585731983185, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 32489, "time": 1257.8313806056976, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.000745704136982, "train/action_min": 0.0, "train/action_std": 1.9993364681234014, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00015599708530472512, "train/actor_opt_grad_steps": 970.0, "train/actor_opt_loss": -1.3562197601084882, "train/adv_mag": 0.0003807748750099919, "train/adv_max": 0.00038073623274101023, "train/adv_mean": 0.0002262824319839565, "train/adv_min": 3.209034528598793e-05, "train/adv_std": 0.00010510119998390114, "train/cont_avg": 0.9968729760362695, "train/cont_loss_mean": 0.02359683139178809, "train/cont_loss_std": 0.3052063872394499, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.778704648460847, "train/cont_pos_acc": 0.9992207628457658, "train/cont_pos_loss": 0.005555934209459222, "train/cont_pred": 0.9950155359475724, "train/cont_rate": 0.9968729760362695, "train/dyn_loss_mean": 1.060042732120178, "train/dyn_loss_std": 0.004478077293214403, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 4.497725759763174, "train/extr_critic_critic_opt_grad_steps": 970.0, "train/extr_critic_critic_opt_loss": 6178.803754262974, "train/extr_critic_mag": 0.0014952668254239571, "train/extr_critic_max": 0.0014952581781179793, "train/extr_critic_mean": 0.0014907186955890547, "train/extr_critic_min": 0.0014869629410264405, "train/extr_critic_std": 8.716948575567984e-07, "train/extr_return_normed_mag": 0.0006000466873925134, "train/extr_return_normed_max": 0.0006000412438749872, "train/extr_return_normed_mean": 0.000447878088311949, "train/extr_return_normed_min": 0.0002549515272403045, "train/extr_return_normed_std": 0.00010508146542543045, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.0018691733757188027, "train/extr_return_raw_max": 0.0018691650614681907, "train/extr_return_raw_mean": 0.0017170019663376027, "train/extr_return_raw_min": 0.001524075344525724, "train/extr_return_raw_std": 0.00010508146509317219, "train/extr_reward_mag": 4.0344006039318024e-05, "train/extr_reward_max": 4.034215304517993e-05, "train/extr_reward_mean": 4.0240303956710944e-05, "train/extr_reward_min": 3.9977113199975205e-05, "train/extr_reward_std": 4.5194288370409e-08, "train/image_loss_mean": 27.182157741077823, "train/image_loss_std": 0.3596026887007328, "train/model_loss_mean": 27.95115283548523, "train/model_loss_std": 0.6366067335318407, "train/model_opt_grad_norm": 101.95501837134361, "train/model_opt_grad_steps": 960.0, "train/model_opt_loss": 533.0106152351656, "train/model_opt_model_opt_grad_overflow": 0.0051813471502590676, "train/model_opt_model_opt_grad_scale": 14.420741580310882, "train/policy_entropy_mag": 1.9457869159125294, "train/policy_entropy_max": 1.9457869159125294, "train/policy_entropy_mean": 1.9408346266326508, "train/policy_entropy_min": 1.8585772949796884, "train/policy_entropy_std": 0.0034910918043327996, "train/policy_logprob_mag": 2.483688410082012, "train/policy_logprob_max": -1.4683011242145083, "train/policy_logprob_mean": -1.9407848292681837, "train/policy_logprob_min": -2.483688410082012, "train/policy_logprob_std": 0.08986131746534239, "train/policy_randomness_mag": 0.9999367285886577, "train/policy_randomness_max": 0.9999367285886577, "train/policy_randomness_mean": 0.9973917560256207, "train/policy_randomness_min": 0.955119846707181, "train/policy_randomness_std": 0.0017940664058913106, "train/post_ent_mag": 85.85608210588366, "train/post_ent_max": 85.85608210588366, "train/post_ent_mean": 85.80373177009542, "train/post_ent_min": 85.72667437143276, "train/post_ent_std": 0.018182811805003665, "train/prior_ent_mag": 90.44451172981856, "train/prior_ent_max": 90.44451172981856, "train/prior_ent_mean": 90.34540036058179, "train/prior_ent_min": 90.08981299523863, "train/prior_ent_std": 0.05290581722179225, "train/rep_loss_mean": 1.060042732120178, "train/rep_loss_std": 0.004478077293214403, "train/reward_avg": 7.970938341417036e-05, "train/reward_loss_mean": 0.10937375813925282, "train/reward_loss_std": 0.05600591391811246, "train/reward_max_data": 0.07043393705175331, "train/reward_max_pred": 4.035574166885929e-05, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.10745072886353803, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 9.73466630415483, "train/reward_pred": 4.020700812667917e-05, "train/reward_rate": 0.00019733646373056994, "train_stats/mean_log_entropy": 1.9271808914970934, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9990234375, "report/cont_loss_mean": 0.008230688981711864, "report/cont_loss_std": 0.18972662091255188, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 6.076517581939697, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0022988340351730585, "report/cont_pred": 0.9977036714553833, "report/cont_rate": 0.9990234375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.31116795539855957, "report/image_loss_std": 0.08745712041854858, "report/model_loss_mean": 0.9199942350387573, "report/model_loss_std": 0.20942261815071106, "report/post_ent_mag": 75.86767578125, "report/post_ent_max": 75.86767578125, "report/post_ent_mean": 75.72422790527344, "report/post_ent_min": 75.70111846923828, "report/post_ent_std": 0.022356651723384857, "report/prior_ent_mag": 79.32672119140625, "report/prior_ent_max": 79.32672119140625, "report/prior_ent_mean": 79.23596954345703, "report/prior_ent_min": 78.5247573852539, "report/prior_ent_std": 0.10647697746753693, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.0005955263040959835, "report/reward_loss_std": 2.067740467737167e-07, "report/reward_max_data": 0.0, "report/reward_max_pred": 5.996227264404297e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0005955263040959835, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 5.9862853959202766e-05, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.0022988514974713326, "eval/cont_loss_std": 6.858901429040998e-07, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0022988514974713326, "eval/cont_pred": 0.9977036714553833, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.31581544876098633, "eval/image_loss_std": 0.07941178977489471, "eval/model_loss_mean": 0.9187098741531372, "eval/model_loss_std": 0.07941178232431412, "eval/post_ent_mag": 75.86477661132812, "eval/post_ent_max": 75.86477661132812, "eval/post_ent_mean": 75.72492980957031, "eval/post_ent_min": 75.70480346679688, "eval/post_ent_std": 0.02166738733649254, "eval/prior_ent_mag": 79.34474182128906, "eval/prior_ent_max": 79.34474182128906, "eval/prior_ent_mean": 79.23469543457031, "eval/prior_ent_min": 78.5247573852539, "eval/prior_ent_std": 0.10541215538978577, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0005955379456281662, "eval/reward_loss_std": 2.146410622572148e-07, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 5.996227264404297e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0005955379456281662, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 5.9860292822122574e-05, "eval/reward_rate": 0.0, "replay/size": 31985.0, "replay/inserts": 30928.0, "replay/samples": 30928.0, "replay/insert_wait_avg": 1.3637067860910698e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.835085796310811e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 10304.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3502136371264957e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0281801223754883e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 976.0357794761658, "timer/env.step_count": 3866.0, "timer/env.step_total": 39.669641733169556, "timer/env.step_frac": 0.040643634759434825, "timer/env.step_avg": 0.010261159268797091, "timer/env.step_min": 0.00849008560180664, "timer/env.step_max": 0.04129338264465332, "timer/replay._sample_count": 30928.0, "timer/replay._sample_total": 16.62080144882202, "timer/replay._sample_frac": 0.017028885414162108, "timer/replay._sample_avg": 0.0005374030473623261, "timer/replay._sample_min": 0.0003535747528076172, "timer/replay._sample_max": 0.0117950439453125, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4733.0, "timer/agent.policy_total": 53.02359390258789, "timer/agent.policy_frac": 0.054325461235699195, "timer/agent.policy_avg": 0.011202956666509167, "timer/agent.policy_min": 0.009588479995727539, "timer/agent.policy_max": 0.09933853149414062, "timer/dataset_train_count": 1933.0, "timer/dataset_train_total": 0.2175767421722412, "timer/dataset_train_frac": 0.00022291881788289946, "timer/dataset_train_avg": 0.00011255910096856762, "timer/dataset_train_min": 7.557868957519531e-05, "timer/dataset_train_max": 0.0010466575622558594, "timer/agent.train_count": 1933.0, "timer/agent.train_total": 867.5058913230896, "timer/agent.train_frac": 0.8888054204208337, "timer/agent.train_avg": 0.44878732091210016, "timer/agent.train_min": 0.4379863739013672, "timer/agent.train_max": 0.6909301280975342, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47771453857421875, "timer/agent.report_frac": 0.0004894436747294306, "timer/agent.report_avg": 0.23885726928710938, "timer/agent.report_min": 0.2326216697692871, "timer/agent.report_max": 0.24509286880493164, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 4.267692565917969e-05, "timer/dataset_eval_frac": 4.372475533846127e-08, "timer/dataset_eval_avg": 4.267692565917969e-05, "timer/dataset_eval_min": 4.267692565917969e-05, "timer/dataset_eval_max": 4.267692565917969e-05, "fps": 31.68690822249355}
{"step": 33760, "time": 1297.9235599040985, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 33808, "time": 1299.4329566955566, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 34064, "time": 1307.3147518634796, "episode/length": 211.0, "episode/score": 0.34062498807907104, "episode/reward_rate": 0.0047169811320754715, "episode/intrinsic_return": 0.0}
{"step": 34424, "time": 1318.1241781711578, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 34680, "time": 1326.021582365036, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 34680, "time": 1326.03089261055, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 34680, "time": 1326.041321516037, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 34680, "time": 1326.0535583496094, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 36072, "time": 1368.985263824463, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 36120, "time": 1370.4906725883484, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 36376, "time": 1378.3650374412537, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 36648, "time": 1386.862759590149, "episode/length": 245.0, "episode/score": 0.234375, "episode/reward_rate": 0.0040650406504065045, "episode/intrinsic_return": 0.0}
{"step": 36736, "time": 1389.7845633029938, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 36992, "time": 1398.0810754299164, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 36992, "time": 1398.0898506641388, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 36992, "time": 1398.0985729694366, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 38384, "time": 1440.8131403923035, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 38432, "time": 1442.298299074173, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 38688, "time": 1450.321186542511, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 38960, "time": 1458.679236650467, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 39048, "time": 1461.2036175727844, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 39304, "time": 1469.0590856075287, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 39304, "time": 1469.0669417381287, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 39304, "time": 1469.0756464004517, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 40040, "time": 1497.5119287967682, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1497.520500421524, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1497.5285041332245, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1497.536005973816, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1497.5454428195953, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1497.5530507564545, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1497.5617895126343, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1497.5690417289734, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40696, "time": 1517.7501065731049, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 40744, "time": 1519.2264041900635, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 41000, "time": 1527.6492466926575, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 41272, "time": 1536.1210618019104, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 41360, "time": 1539.1489379405975, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 41616, "time": 1547.0069971084595, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 41616, "time": 1547.015697479248, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 41616, "time": 1547.0251336097717, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 43008, "time": 1589.9845538139343, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 43056, "time": 1591.4647943973541, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 43312, "time": 1599.3725671768188, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 43584, "time": 1607.6537728309631, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 43672, "time": 1610.156412601471, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 43928, "time": 1617.987622499466, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 43928, "time": 1617.9972326755524, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 43928, "time": 1618.0063412189484, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 45320, "time": 1661.0965938568115, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 45368, "time": 1662.5828449726105, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 45624, "time": 1670.5572085380554, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 45896, "time": 1678.8898077011108, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 45984, "time": 1681.8096520900726, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 46240, "time": 1689.8349957466125, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 46240, "time": 1689.8424735069275, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 46240, "time": 1689.8511970043182, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 47632, "time": 1732.5920770168304, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 47680, "time": 1734.0508942604065, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 47936, "time": 1741.8523473739624, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 48208, "time": 1750.3094968795776, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 48296, "time": 1752.7920157909393, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 48552, "time": 1760.6367461681366, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 48552, "time": 1760.6437792778015, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 48552, "time": 1760.652714729309, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 48808, "time": 1768.4612259864807, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 49944, "time": 1804.0145432949066, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 50024, "time": 1812.4455864429474, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1812.4538657665253, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1812.4638118743896, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1812.4721295833588, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1812.4801042079926, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1812.4897105693817, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1812.4995081424713, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1812.5082161426544, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50248, "time": 1819.3736243247986, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 50520, "time": 1827.7134733200073, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 50608, "time": 1830.6044533252716, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 50776, "time": 1835.503578901291, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 50864, "time": 1838.5567517280579, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 50864, "time": 1838.5658597946167, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 50864, "time": 1838.575792312622, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 51120, "time": 1846.3748626708984, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 52256, "time": 1881.222142457962, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 52832, "time": 1899.0037832260132, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 52920, "time": 1901.485806941986, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 53088, "time": 1906.8578429222107, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 53176, "time": 1909.3071229457855, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 53176, "time": 1909.3152675628662, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 53176, "time": 1909.3241844177246, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 53432, "time": 1917.1943037509918, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 54568, "time": 1952.0828640460968, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 55144, "time": 1969.7767837047577, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 55232, "time": 1972.7003695964813, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 55400, "time": 1977.6176452636719, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 55488, "time": 1980.5437684059143, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 55488, "time": 1980.5518009662628, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 55488, "time": 1980.5612742900848, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 55744, "time": 1988.5258872509003, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 56880, "time": 2023.4170830249786, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 57456, "time": 2041.5172634124756, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 57544, "time": 2043.9860508441925, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 57712, "time": 2049.441108942032, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 57800, "time": 2051.888077735901, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 57800, "time": 2051.8973054885864, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 57800, "time": 2051.9066512584686, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 58056, "time": 2059.8035666942596, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 59192, "time": 2094.618198156357, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 59768, "time": 2112.3385484218597, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 59856, "time": 2115.251437664032, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 60008, "time": 2125.97442483902, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2125.9815764427185, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2125.9889013767242, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2125.995642185211, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2126.0034399032593, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2126.010797739029, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2126.0188925266266, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2126.0250964164734, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60024, "time": 2126.5156321525574, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 60112, "time": 2129.4381992816925, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 60112, "time": 2129.4467618465424, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 60112, "time": 2129.4564814567566, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 60368, "time": 2137.352023601532, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 61504, "time": 2172.1087787151337, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 62080, "time": 2189.770188808441, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 62168, "time": 2192.2507350444794, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 62336, "time": 2197.7473425865173, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 62424, "time": 2200.2228446006775, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 62424, "time": 2200.2326130867004, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 62424, "time": 2200.2419152259827, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 62680, "time": 2208.110090970993, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 63816, "time": 2242.9455959796906, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 64281, "time": 2258.1838808059692, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.0011639618993406, "train/action_min": 0.0, "train/action_std": 1.9996931732599459, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0001150248960433756, "train/actor_opt_grad_steps": 2930.0, "train/actor_opt_loss": -0.8372926844620899, "train/adv_mag": 0.0004531686666922354, "train/adv_max": 0.0004531686666922354, "train/adv_mean": 0.0002543592011867835, "train/adv_min": 1.2629656074334629e-05, "train/adv_std": 0.00011881709536250877, "train/cont_avg": 0.9965010599874372, "train/cont_loss_mean": 0.023373529978386647, "train/cont_loss_std": 0.32507953006317614, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.702808893643892, "train/cont_pos_acc": 0.9999999844249169, "train/cont_pos_loss": 0.0034357173855056114, "train/cont_pred": 0.9965704526733513, "train/cont_rate": 0.9965010599874372, "train/dyn_loss_mean": 1.000000025758791, "train/dyn_loss_std": 5.608188020868049e-07, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.0844202078691679, "train/extr_critic_critic_opt_grad_steps": 2930.0, "train/extr_critic_critic_opt_loss": 4881.94805938874, "train/extr_critic_mag": 0.010938899001883502, "train/extr_critic_max": 0.010938899001883502, "train/extr_critic_mean": 0.010911900388666584, "train/extr_critic_min": 0.010885879022991238, "train/extr_critic_std": 7.567348056161004e-06, "train/extr_return_normed_mag": 0.0008868115986861177, "train/extr_return_normed_max": 0.0008868115986861177, "train/extr_return_normed_mean": 0.0007072873664382218, "train/extr_return_normed_min": 0.000477456660875723, "train/extr_return_normed_std": 0.0001183752755875946, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.011345785190749108, "train/extr_return_raw_max": 0.011345785190749108, "train/extr_return_raw_mean": 0.011166261551180976, "train/extr_return_raw_min": 0.010936430252938714, "train/extr_return_raw_std": 0.00011837527545048485, "train/extr_reward_mag": 7.306511078647633e-05, "train/extr_reward_max": 7.306511078647633e-05, "train/extr_reward_mean": 7.297234475830845e-05, "train/extr_reward_min": 7.276259475017912e-05, "train/extr_reward_std": 4.08252586694759e-08, "train/image_loss_mean": 0.26794550054935956, "train/image_loss_std": 0.08682036074112408, "train/model_loss_mean": 0.8936699652791622, "train/model_loss_std": 0.38397095704348244, "train/model_opt_grad_norm": 79.67666257925369, "train/model_opt_grad_steps": 2920.0, "train/model_opt_loss": 50.08645900170408, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 56.140075376884425, "train/policy_entropy_mag": 1.9458845811872627, "train/policy_entropy_max": 1.9458845811872627, "train/policy_entropy_mean": 1.9446870046644356, "train/policy_entropy_min": 1.9250830687470173, "train/policy_entropy_std": 0.00082413160859902, "train/policy_logprob_mag": 2.233477037755688, "train/policy_logprob_max": -1.6970885932146005, "train/policy_logprob_mean": -1.944693754066774, "train/policy_logprob_min": -2.233477037755688, "train/policy_logprob_std": 0.049204712761706446, "train/policy_randomness_mag": 0.9999869187273572, "train/policy_randomness_max": 0.9999869187273572, "train/policy_randomness_mean": 0.9993714836973641, "train/policy_randomness_min": 0.989297053622241, "train/policy_randomness_std": 0.0004235199199528457, "train/post_ent_mag": 65.81374338044593, "train/post_ent_max": 65.81374338044593, "train/post_ent_mean": 65.6636963465705, "train/post_ent_min": 65.6402922012099, "train/post_ent_std": 0.02374595988672882, "train/prior_ent_mag": 72.81803583499774, "train/prior_ent_max": 72.81803583499774, "train/prior_ent_mean": 72.70501896843838, "train/prior_ent_min": 72.39041735778503, "train/prior_ent_std": 0.05828982703949339, "train/rep_loss_mean": 1.000000025758791, "train/rep_loss_std": 5.608188020868049e-07, "train/reward_avg": 8.241279546789188e-05, "train/reward_loss_mean": 0.0023509000016179817, "train/reward_loss_std": 0.06096242748714572, "train/reward_max_data": 0.08176821500212703, "train/reward_max_pred": 7.316574978469005e-05, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.0003890454069033836, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 9.753166149824093, "train/reward_pred": 7.300261447870702e-05, "train/reward_rate": 0.0002012013190954774, "train_stats/mean_log_entropy": 1.937695412992317, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.02002684585750103, "report/cont_loss_std": 0.32027214765548706, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.928447246551514, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.002666163956746459, "report/cont_pred": 0.9973374009132385, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.24767959117889404, "report/image_loss_std": 0.08529289066791534, "report/model_loss_mean": 0.8780333399772644, "report/model_loss_std": 0.588904082775116, "report/post_ent_mag": 57.617706298828125, "report/post_ent_max": 57.617706298828125, "report/post_ent_mean": 57.4927978515625, "report/post_ent_min": 57.471336364746094, "report/post_ent_std": 0.018630526959896088, "report/prior_ent_mag": 64.87591552734375, "report/prior_ent_max": 64.87591552734375, "report/prior_ent_mean": 64.75653839111328, "report/prior_ent_min": 64.69351196289062, "report/prior_ent_std": 0.030307799577713013, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0006866455078125, "report/reward_loss_mean": 0.010326872579753399, "report/reward_loss_std": 0.32300838828086853, "report/reward_max_data": 0.703125, "report/reward_max_pred": 5.233287811279297e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00022792629897594452, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 10.341548919677734, "report/reward_pred": 5.23317139595747e-05, "report/reward_rate": 0.0009765625, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.002666163956746459, "eval/cont_loss_std": 2.3283064365386963e-10, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.002666163956746459, "eval/cont_pred": 0.9973374009132385, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.24709713459014893, "eval/image_loss_std": 0.0786171406507492, "eval/model_loss_mean": 0.8499912023544312, "eval/model_loss_std": 0.07861713320016861, "eval/post_ent_mag": 57.61964416503906, "eval/post_ent_max": 57.61964416503906, "eval/post_ent_mean": 57.491172790527344, "eval/post_ent_min": 57.47113800048828, "eval/post_ent_std": 0.017077991738915443, "eval/prior_ent_mag": 64.89231872558594, "eval/prior_ent_max": 64.89231872558594, "eval/prior_ent_mean": 64.75267791748047, "eval/prior_ent_min": 64.70104217529297, "eval/prior_ent_std": 0.028855297714471817, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00022792816162109375, "eval/reward_loss_std": 0.0, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 5.233287811279297e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00022792816162109375, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 5.2331830374896526e-05, "eval/reward_rate": 0.0, "replay/size": 63777.0, "replay/inserts": 31792.0, "replay/samples": 31792.0, "replay/insert_wait_avg": 1.3962395537961471e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.693743903971702e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 17240.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1975239992416717e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1473894119262695e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3376529216766, "timer/env.step_count": 3974.0, "timer/env.step_total": 40.91233158111572, "timer/env.step_frac": 0.04089852207564462, "timer/env.step_avg": 0.010295000397865054, "timer/env.step_min": 0.008447408676147461, "timer/env.step_max": 0.04151630401611328, "timer/replay._sample_count": 31792.0, "timer/replay._sample_total": 17.37565302848816, "timer/replay._sample_frac": 0.017369788068797826, "timer/replay._sample_avg": 0.0005465416780475642, "timer/replay._sample_min": 0.0003879070281982422, "timer/replay._sample_max": 0.011609315872192383, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4841.0, "timer/agent.policy_total": 53.44085216522217, "timer/agent.policy_frac": 0.05342281379605974, "timer/agent.policy_avg": 0.011039217551171694, "timer/agent.policy_min": 0.009029865264892578, "timer/agent.policy_max": 0.08881402015686035, "timer/dataset_train_count": 1987.0, "timer/dataset_train_total": 0.2269279956817627, "timer/dataset_train_frac": 0.00022685139864422405, "timer/dataset_train_avg": 0.00011420633904467172, "timer/dataset_train_min": 9.918212890625e-05, "timer/dataset_train_max": 0.0008227825164794922, "timer/agent.train_count": 1987.0, "timer/agent.train_total": 890.7836418151855, "timer/agent.train_frac": 0.8904829676394588, "timer/agent.train_avg": 0.4483058086639082, "timer/agent.train_min": 0.4367339611053467, "timer/agent.train_max": 0.8527088165283203, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47436976432800293, "timer/agent.report_frac": 0.00047420964605552506, "timer/agent.report_avg": 0.23718488216400146, "timer/agent.report_min": 0.23035907745361328, "timer/agent.report_max": 0.24401068687438965, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.24249267578125e-05, "timer/dataset_eval_frac": 3.241398208205932e-08, "timer/dataset_eval_avg": 3.24249267578125e-05, "timer/dataset_eval_min": 3.24249267578125e-05, "timer/dataset_eval_max": 3.24249267578125e-05, "fps": 31.780780894195054}
{"step": 64392, "time": 2261.341554403305, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 64480, "time": 2264.284464120865, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 64648, "time": 2269.187309741974, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 64736, "time": 2272.0964024066925, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 64736, "time": 2272.103977918625, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 64736, "time": 2272.1129188537598, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 64992, "time": 2279.9453966617584, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 65512, "time": 2295.902138710022, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 66128, "time": 2315.707172393799, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 66704, "time": 2333.5275428295135, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 66792, "time": 2335.9999585151672, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 66960, "time": 2341.355823993683, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 67048, "time": 2343.849164247513, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 67048, "time": 2343.8570363521576, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 67304, "time": 2351.7717413902283, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 67424, "time": 2355.7000510692596, "episode/length": 238.0, "episode/score": 0.2562499940395355, "episode/reward_rate": 0.0041841004184100415, "episode/intrinsic_return": 0.0}
{"step": 68304, "time": 2382.6958367824554, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 68440, "time": 2386.6188995838165, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 69016, "time": 2404.2697246074677, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 69104, "time": 2407.341514110565, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 69272, "time": 2412.264604330063, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 69360, "time": 2415.183213710785, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 69616, "time": 2423.0052859783173, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 69736, "time": 2426.457763671875, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 70096, "time": 2443.555798768997, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2443.5760548114777, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2443.587257862091, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2443.5982208251953, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2443.609937429428, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2443.6190905570984, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2443.628748655319, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2443.6401076316833, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70616, "time": 2459.249323606491, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 70752, "time": 2463.610420227051, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 71328, "time": 2481.232868909836, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 71416, "time": 2483.7016520500183, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 71584, "time": 2489.05020904541, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 71672, "time": 2491.525851249695, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 71928, "time": 2499.433272123337, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 72048, "time": 2503.317435026169, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 72544, "time": 2518.460166454315, "episode/length": 223.0, "episode/score": 0.3031249940395355, "episode/reward_rate": 0.004464285714285714, "episode/intrinsic_return": 0.0}
{"step": 72928, "time": 2530.3327326774597, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 73640, "time": 2551.7779207229614, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 73728, "time": 2554.8514919281006, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 73896, "time": 2560.3127825260162, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 73984, "time": 2563.222841978073, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 74240, "time": 2571.1104090213776, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 74360, "time": 2574.5772790908813, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 74856, "time": 2589.8712532520294, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 75240, "time": 2601.67236328125, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 75952, "time": 2623.79665184021, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 75984, "time": 2624.7750973701477, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 76040, "time": 2626.270117998123, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 76208, "time": 2631.7092266082764, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 76296, "time": 2634.1971793174744, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 76552, "time": 2642.031101703644, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 76672, "time": 2645.9127547740936, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 77168, "time": 2661.1943275928497, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 78264, "time": 2694.499542951584, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 78296, "time": 2695.4737541675568, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 78352, "time": 2697.4091901779175, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 78520, "time": 2702.2538657188416, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 78608, "time": 2705.1338064670563, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 78864, "time": 2713.0587360858917, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 78984, "time": 2716.4881570339203, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 79480, "time": 2731.6211297512054, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 79512, "time": 2732.6012284755707, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 80080, "time": 2752.579246044159, "eval_episode/length": 118.0, "eval_episode/score": 0.6312500238418579, "eval_episode/reward_rate": 0.008403361344537815}
{"step": 80080, "time": 2755.8885731697083, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2755.8957891464233, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2755.9023864269257, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2755.908698797226, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2755.915642976761, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2755.922877073288, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2755.9298186302185, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80608, "time": 2772.1735801696777, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 80664, "time": 2773.661448955536, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 80832, "time": 2779.0225129127502, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 80920, "time": 2781.515625476837, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 81176, "time": 2789.287089109421, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 81296, "time": 2793.138674259186, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 81792, "time": 2808.280805826187, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 81824, "time": 2809.263229370117, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 82920, "time": 2842.973392724991, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 82976, "time": 2844.9116699695587, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 83144, "time": 2849.8159654140472, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 83232, "time": 2852.7541830539703, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 83488, "time": 2860.672512769699, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 83608, "time": 2864.0846066474915, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 84104, "time": 2879.1732556819916, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 84136, "time": 2880.166006565094, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 85232, "time": 2914.647201538086, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 85288, "time": 2916.1183381080627, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 85456, "time": 2921.513554573059, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 85544, "time": 2923.9469294548035, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 85800, "time": 2931.6889140605927, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 85920, "time": 2935.5610859394073, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 86416, "time": 2950.759590625763, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 86448, "time": 2951.743682384491, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 87544, "time": 2984.9636075496674, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 87600, "time": 2986.8977088928223, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 87768, "time": 2991.830515384674, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 87856, "time": 2994.7564175128937, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 88112, "time": 3002.589314699173, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 88232, "time": 3006.008913040161, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 88728, "time": 3021.1722886562347, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 88760, "time": 3022.1723761558533, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 89856, "time": 3055.8313784599304, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 89912, "time": 3057.3253598213196, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 90064, "time": 3068.8836092948914, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3068.891181707382, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3068.899471759796, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3068.9072465896606, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3068.9165391921997, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3068.924630880356, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3068.9328927993774, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3068.9418110847473, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90080, "time": 3069.444706916809, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 90168, "time": 3072.402643918991, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 90424, "time": 3080.269043445587, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 90544, "time": 3084.148853778839, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 91040, "time": 3099.3450796604156, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 91072, "time": 3100.3259358406067, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 92168, "time": 3133.5028541088104, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 92224, "time": 3135.4414598941803, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 92392, "time": 3140.33655500412, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 92480, "time": 3143.2525453567505, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 92736, "time": 3151.029632091522, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 92856, "time": 3154.4608538150787, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 93352, "time": 3169.6617991924286, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 93384, "time": 3170.635080575943, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 94480, "time": 3204.329171895981, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 94536, "time": 3205.834430217743, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 94704, "time": 3211.233291387558, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 94792, "time": 3213.6772627830505, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 95048, "time": 3221.5639131069183, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 95168, "time": 3225.451657772064, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 95664, "time": 3240.526338815689, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 95696, "time": 3241.4967374801636, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 96233, "time": 3258.611499071121, "train_stats/mean_log_entropy": 1.9381574029507844, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.998682683436715, "train/action_min": 0.0, "train/action_std": 2.000256626450237, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 6.50658357836395e-05, "train/actor_opt_grad_steps": 4920.0, "train/actor_opt_loss": -3.090354971250697, "train/adv_mag": 0.0002800751870601021, "train/adv_max": 0.000278156456635825, "train/adv_mean": 0.00013638353212643405, "train/adv_min": -3.1569251912323076e-05, "train/adv_std": 6.911155983700393e-05, "train/cont_avg": 0.9965255967336684, "train/cont_loss_mean": 0.023209604861720197, "train/cont_loss_std": 0.32014311424423775, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.667151822257288, "train/cont_pos_acc": 0.9999999871206044, "train/cont_pos_loss": 0.003513229613066019, "train/cont_pred": 0.9964930765592872, "train/cont_rate": 0.9965255967336684, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.02431640916284005, "train/extr_critic_critic_opt_grad_steps": 4920.0, "train/extr_critic_critic_opt_loss": 6949.595833169755, "train/extr_critic_mag": 0.018273338600618756, "train/extr_critic_max": 0.018273338600618756, "train/extr_critic_mean": 0.018227806207185716, "train/extr_critic_min": 0.018191342377782468, "train/extr_critic_std": 1.2984633738193218e-05, "train/extr_return_normed_mag": 0.0005017816037613543, "train/extr_return_normed_max": 0.0005016545226900422, "train/extr_return_normed_mean": 0.0003930270122166908, "train/extr_return_normed_min": 0.0002520041746185653, "train/extr_return_normed_std": 6.62130892472456e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.018472810411573056, "train/extr_return_raw_max": 0.018472810411573056, "train/extr_return_raw_mean": 0.018364183754477667, "train/extr_return_raw_min": 0.018223160063501578, "train/extr_return_raw_std": 6.62130890915689e-05, "train/extr_reward_mag": 7.645808272625334e-05, "train/extr_reward_max": 7.645808272625334e-05, "train/extr_reward_mean": 7.633978347984334e-05, "train/extr_reward_min": 7.620049481415869e-05, "train/extr_reward_std": 3.907174568362926e-08, "train/image_loss_mean": 0.2587894124152073, "train/image_loss_std": 0.08514388062846122, "train/model_loss_mean": 0.884280062201035, "train/model_loss_std": 0.3795214227620681, "train/model_opt_grad_norm": 66.0652096043879, "train/model_opt_grad_steps": 4910.0, "train/model_opt_loss": 197.32119264075504, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 223.3825376884422, "train/policy_entropy_mag": 1.9458956329067747, "train/policy_entropy_max": 1.9458956329067747, "train/policy_entropy_mean": 1.9451983813664422, "train/policy_entropy_min": 1.9336842304498107, "train/policy_entropy_std": 0.00048535014780579913, "train/policy_logprob_mag": 2.1600992128477623, "train/policy_logprob_max": -1.7496315324725817, "train/policy_logprob_mean": -1.9452256725062078, "train/policy_logprob_min": -2.1600992128477623, "train/policy_logprob_std": 0.037629352348982986, "train/policy_randomness_mag": 0.9999925991398605, "train/policy_randomness_max": 0.9999925991398605, "train/policy_randomness_mean": 0.9996342796776163, "train/policy_randomness_min": 0.9937171786274742, "train/policy_randomness_std": 0.00024942066268901806, "train/post_ent_mag": 51.55658599240097, "train/post_ent_max": 51.55658599240097, "train/post_ent_mean": 51.5052300841365, "train/post_ent_min": 51.43915038372404, "train/post_ent_std": 0.017990072866218475, "train/prior_ent_mag": 60.47394720873042, "train/prior_ent_max": 60.47394720873042, "train/prior_ent_mean": 60.33979670845684, "train/prior_ent_min": 60.283535099508775, "train/prior_ent_std": 0.03151056129279448, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 9.365369280304142e-05, "train/reward_loss_mean": 0.002281025122270812, "train/reward_loss_std": 0.06062918531887297, "train/reward_max_data": 0.08739007447832194, "train/reward_max_pred": 7.647126164268608e-05, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00024526370094033736, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 9.89473768182703, "train/reward_pred": 7.627736461166312e-05, "train/reward_rate": 0.00020610866834170854, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.03608636185526848, "report/cont_loss_std": 0.40844181180000305, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.356292247772217, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0047295368276536465, "report/cont_pred": 0.995281457901001, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.2509278655052185, "report/image_loss_std": 0.07536599785089493, "report/model_loss_mean": 0.8872798681259155, "report/model_loss_std": 0.4208226799964905, "report/post_ent_mag": 47.25639724731445, "report/post_ent_max": 47.25639724731445, "report/post_ent_mean": 47.2232551574707, "report/post_ent_min": 47.06938934326172, "report/post_ent_std": 0.03800719976425171, "report/prior_ent_mag": 56.37811279296875, "report/prior_ent_max": 56.37811279296875, "report/prior_ent_mean": 56.28104782104492, "report/prior_ent_min": 56.23444366455078, "report/prior_ent_std": 0.026710713282227516, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.00026567187160253525, "report/reward_loss_std": 4.918784952678834e-07, "report/reward_max_data": 0.0, "report/reward_max_pred": 8.535385131835938e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00026567187160253525, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 8.519587572664022e-05, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.004729536361992359, "eval/cont_loss_std": 4.656612873077393e-10, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.004729536361992359, "eval/cont_pred": 0.995281457901001, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.26883459091186523, "eval/image_loss_std": 0.08687656372785568, "eval/model_loss_mean": 0.8738298416137695, "eval/model_loss_std": 0.08687655627727509, "eval/post_ent_mag": 47.255096435546875, "eval/post_ent_max": 47.255096435546875, "eval/post_ent_mean": 47.22684860229492, "eval/post_ent_min": 47.07115936279297, "eval/post_ent_std": 0.03388598933815956, "eval/prior_ent_mag": 56.393096923828125, "eval/prior_ent_max": 56.393096923828125, "eval/prior_ent_mean": 56.27729797363281, "eval/prior_ent_min": 56.231685638427734, "eval/prior_ent_std": 0.024866629391908646, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00026570307090878487, "eval/reward_loss_std": 4.7673503900114156e-07, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 8.535385131835938e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00026570307090878487, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 8.52108933031559e-05, "eval/reward_rate": 0.0, "replay/size": 95729.0, "replay/inserts": 31952.0, "replay/samples": 31952.0, "replay/insert_wait_avg": 1.3477305620983356e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.781238621810584e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 24176.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.219351536399903e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0728836059570312e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4060728549957, "timer/env.step_count": 3994.0, "timer/env.step_total": 40.54084610939026, "timer/env.step_frac": 0.04052439025454264, "timer/env.step_avg": 0.010150437183122248, "timer/env.step_min": 0.008293390274047852, "timer/env.step_max": 0.25373339653015137, "timer/replay._sample_count": 31952.0, "timer/replay._sample_total": 17.152117013931274, "timer/replay._sample_frac": 0.017145154831959317, "timer/replay._sample_avg": 0.0005368088699903379, "timer/replay._sample_min": 0.0003914833068847656, "timer/replay._sample_max": 0.025068044662475586, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4861.0, "timer/agent.policy_total": 52.921135663986206, "timer/agent.policy_frac": 0.0528996545502347, "timer/agent.policy_avg": 0.010886882465333514, "timer/agent.policy_min": 0.008953571319580078, "timer/agent.policy_max": 0.10158085823059082, "timer/dataset_train_count": 1997.0, "timer/dataset_train_total": 0.22614765167236328, "timer/dataset_train_frac": 0.00022605585652531553, "timer/dataset_train_avg": 0.00011324369137324151, "timer/dataset_train_min": 9.5367431640625e-05, "timer/dataset_train_max": 0.0013425350189208984, "timer/agent.train_count": 1997.0, "timer/agent.train_total": 891.9879269599915, "timer/agent.train_frac": 0.8916258619006614, "timer/agent.train_avg": 0.4466639594191244, "timer/agent.train_min": 0.4336276054382324, "timer/agent.train_max": 1.0964670181274414, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47638773918151855, "timer/agent.report_frac": 0.0004761943695743326, "timer/agent.report_avg": 0.23819386959075928, "timer/agent.report_min": 0.23046159744262695, "timer/agent.report_max": 0.2459261417388916, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.457069396972656e-05, "timer/dataset_eval_frac": 3.455666144755343e-08, "timer/dataset_eval_avg": 3.457069396972656e-05, "timer/dataset_eval_min": 3.457069396972656e-05, "timer/dataset_eval_max": 3.457069396972656e-05, "fps": 31.93848118626773}
{"step": 96792, "time": 3275.6398661136627, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 96848, "time": 3277.718047618866, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 97016, "time": 3282.6781690120697, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 97104, "time": 3285.619398355484, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 97360, "time": 3293.530350446701, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 97480, "time": 3296.9957439899445, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 97976, "time": 3312.4603927135468, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 98008, "time": 3313.474389076233, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 99104, "time": 3348.203665971756, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 99160, "time": 3349.7413992881775, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 99328, "time": 3355.164898633957, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 99416, "time": 3357.6298105716705, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 99672, "time": 3365.4650468826294, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 99792, "time": 3369.483081817627, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 100048, "time": 3383.6721398830414, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3383.6924006938934, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3383.701644420624, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3383.7092700004578, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3383.7178766727448, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3383.7281198501587, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3383.7363073825836, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3383.7430431842804, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100288, "time": 3391.094892024994, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 100320, "time": 3392.0781438350677, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 101416, "time": 3425.5513780117035, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 101472, "time": 3427.588919401169, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 101640, "time": 3432.528156518936, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 101728, "time": 3435.475648880005, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 101984, "time": 3443.381778240204, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 102104, "time": 3446.8664286136627, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 102600, "time": 3462.2241983413696, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 102632, "time": 3463.2019975185394, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 103728, "time": 3497.3794050216675, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 103784, "time": 3498.8711721897125, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 103952, "time": 3504.3068368434906, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 104040, "time": 3506.805783510208, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 104296, "time": 3514.6748793125153, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 104416, "time": 3518.72860121727, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 104912, "time": 3533.96137547493, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 104944, "time": 3534.953090429306, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 106040, "time": 3568.3976986408234, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 106096, "time": 3570.3379340171814, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 106264, "time": 3575.27689909935, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 106352, "time": 3578.339965581894, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 106608, "time": 3586.7191383838654, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 106728, "time": 3590.2419471740723, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 107224, "time": 3605.569699525833, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 107256, "time": 3606.664888381958, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 108128, "time": 3633.5806744098663, "episode/length": 221.0, "episode/score": 0.30937498807907104, "episode/reward_rate": 0.0045045045045045045, "episode/intrinsic_return": 0.0}
{"step": 108352, "time": 3640.5011076927185, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 108408, "time": 3642.029207468033, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 108576, "time": 3647.377144575119, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 108920, "time": 3657.682909011841, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 109040, "time": 3661.565529823303, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 109536, "time": 3676.8847618103027, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 109568, "time": 3677.8853166103363, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 110032, "time": 3698.4399240016937, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3698.503382205963, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3698.5132031440735, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3698.522737979889, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3698.5299780368805, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3698.5369489192963, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3698.545352458954, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3698.554526090622, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110440, "time": 3710.819924354553, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 110664, "time": 3717.7411522865295, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 110720, "time": 3719.7292416095734, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 110888, "time": 3724.7021601200104, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 111232, "time": 3735.697761297226, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 111352, "time": 3739.1932277679443, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 111848, "time": 3754.4229657649994, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 111880, "time": 3755.405942440033, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 112752, "time": 3782.4586708545685, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 112976, "time": 3789.476353406906, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 113032, "time": 3790.9869010448456, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 113200, "time": 3796.5498037338257, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 113544, "time": 3806.993266105652, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 113664, "time": 3810.9215035438538, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 114160, "time": 3826.225923061371, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 114192, "time": 3827.2408113479614, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 115064, "time": 3854.2495636940002, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 115288, "time": 3861.070904493332, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 115344, "time": 3863.0129063129425, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 115512, "time": 3867.9252138137817, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 115856, "time": 3878.9106788635254, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 115976, "time": 3882.35799407959, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 116472, "time": 3897.4545130729675, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 116504, "time": 3898.4451820850372, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 117376, "time": 3925.3959822654724, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 117600, "time": 3932.2415924072266, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 117656, "time": 3933.7277448177338, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 117824, "time": 3939.2344596385956, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 118168, "time": 3949.527282476425, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 118288, "time": 3953.424050807953, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 118784, "time": 3968.7620656490326, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 118816, "time": 3969.759238243103, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 119688, "time": 3996.1707463264465, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 119912, "time": 4003.2098836898804, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 119968, "time": 4005.163826942444, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 120016, "time": 4012.509100675583, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 4012.5181431770325, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 4012.5284502506256, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 4012.536117553711, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 4012.544795513153, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 4012.6162667274475, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 4012.627762556076, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 4012.6360681056976, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120136, "time": 4016.0722663402557, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 120480, "time": 4026.840053796768, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 120600, "time": 4030.29043674469, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 121096, "time": 4045.3817071914673, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 121128, "time": 4046.358414411545, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 122000, "time": 4073.2248301506042, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 122224, "time": 4080.146219968796, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 122280, "time": 4081.6496267318726, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 122448, "time": 4087.1558306217194, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 122792, "time": 4097.529345989227, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 122912, "time": 4101.994570732117, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 123408, "time": 4117.379702568054, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 123440, "time": 4118.3651213645935, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 124312, "time": 4144.976820468903, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 124536, "time": 4151.953377008438, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 124592, "time": 4153.953960895538, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 124760, "time": 4158.923770189285, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 125104, "time": 4169.815494060516, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 125224, "time": 4173.263994216919, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 125720, "time": 4188.672819852829, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 125752, "time": 4189.65673160553, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 126624, "time": 4216.744691848755, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 126848, "time": 4223.64332818985, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 126904, "time": 4225.1338522434235, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 127072, "time": 4230.550061941147, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 127096, "time": 4231.070326089859, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 127416, "time": 4241.031366109848, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 127536, "time": 4244.93497300148, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 127961, "time": 4258.708138227463, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.0005118978682477, "train/action_min": 0.0, "train/action_std": 1.9995402798580764, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 4.550780354590309e-05, "train/actor_opt_grad_steps": 6910.0, "train/actor_opt_loss": -6.492973760893596, "train/adv_mag": 0.00020118835545963976, "train/adv_max": 8.229014636883185e-05, "train/adv_mean": -4.1835773570244274e-05, "train/adv_min": -0.00015876196961307046, "train/adv_std": 4.6515938477034126e-05, "train/cont_avg": 0.996368561557789, "train/cont_loss_mean": 0.024059966674551892, "train/cont_loss_std": 0.32998414610837196, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.681483498684646, "train/cont_pos_acc": 0.9999999865215627, "train/cont_pos_loss": 0.0034662753170421673, "train/cont_pred": 0.9965398958579978, "train/cont_rate": 0.996368561557789, "train/dyn_loss_mean": 1.004535811031284, "train/dyn_loss_std": 0.00028033337401385283, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.013541809216506741, "train/extr_critic_critic_opt_grad_steps": 6910.0, "train/extr_critic_critic_opt_loss": 7308.440679962311, "train/extr_critic_mag": 0.01972836465691801, "train/extr_critic_max": 0.01972836465691801, "train/extr_critic_mean": 0.019686033106853615, "train/extr_critic_min": 0.019638641994802197, "train/extr_critic_std": 1.3837408538764867e-05, "train/extr_return_normed_mag": 0.00022597054028930375, "train/extr_return_normed_max": 6.065890192985535e-05, "train/extr_return_normed_mean": -3.0587934654750145e-05, "train/extr_return_normed_min": -0.00011147396760669784, "train/extr_return_normed_std": 4.259342412795139e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.019735437523030756, "train/extr_return_raw_max": 0.019735437523030756, "train/extr_return_raw_mean": 0.01964419176006437, "train/extr_return_raw_min": 0.019563304653494203, "train/extr_return_raw_std": 4.259342393999677e-05, "train/extr_reward_mag": 5.2548533108965236e-05, "train/extr_reward_max": 5.2548533108965236e-05, "train/extr_reward_mean": 5.250901802300812e-05, "train/extr_reward_min": 5.2467662485400635e-05, "train/extr_reward_std": 1.361655892339438e-08, "train/image_loss_mean": 0.25500051849451494, "train/image_loss_std": 0.08456977853673188, "train/model_loss_mean": 0.883653918103357, "train/model_loss_std": 0.38067569302853627, "train/model_opt_grad_norm": 55.77894632540755, "train/model_opt_grad_steps": 6900.0, "train/model_opt_loss": 784.0195758762072, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 888.8190954773869, "train/policy_entropy_mag": 1.9458979805510248, "train/policy_entropy_max": 1.9458979805510248, "train/policy_entropy_mean": 1.9453273376627782, "train/policy_entropy_min": 1.9284540846120173, "train/policy_entropy_std": 0.0005164516997001785, "train/policy_logprob_mag": 2.1595411875739168, "train/policy_logprob_max": -1.6900730768040797, "train/policy_logprob_mean": -1.9453227969270255, "train/policy_logprob_min": -2.1595411875739168, "train/policy_logprob_std": 0.0339194111357532, "train/policy_randomness_mag": 0.9999938074068807, "train/policy_randomness_max": 0.9999938074068807, "train/policy_randomness_mean": 0.9997005507574609, "train/policy_randomness_min": 0.9910294152983469, "train/policy_randomness_std": 0.0002654036921630356, "train/post_ent_mag": 38.26118193199886, "train/post_ent_max": 38.26118193199886, "train/post_ent_mean": 38.24437368575053, "train/post_ent_min": 38.124721833808934, "train/post_ent_std": 0.023930633468693823, "train/prior_ent_mag": 40.38092104274424, "train/prior_ent_max": 40.38092104274424, "train/prior_ent_mean": 40.33980084903276, "train/prior_ent_min": 40.2019209166867, "train/prior_ent_std": 0.03139955027206759, "train/rep_loss_mean": 1.004535811031284, "train/rep_loss_std": 0.00028033337401385283, "train/reward_avg": 8.327158193698331e-05, "train/reward_loss_mean": 0.0018719202492517143, "train/reward_loss_std": 0.05209548507668169, "train/reward_max_data": 0.0787688433824472, "train/reward_max_pred": 5.243291806935066e-05, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00015203261147744618, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 10.28432443065028, "train/reward_pred": 5.23787463345944e-05, "train/reward_rate": 0.0001668498743718593, "train_stats/mean_log_entropy": 1.9380713980477136, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.020111452788114548, "report/cont_loss_std": 0.3016933798789978, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.585789680480957, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0037578409537672997, "report/cont_pred": 0.996249258518219, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.2554144859313965, "report/image_loss_std": 0.08606858551502228, "report/model_loss_mean": 0.8756260871887207, "report/model_loss_std": 0.314704567193985, "report/post_ent_mag": 35.99534606933594, "report/post_ent_max": 35.99534606933594, "report/post_ent_mean": 35.985557556152344, "report/post_ent_min": 35.87709045410156, "report/post_ent_std": 0.019858848303556442, "report/prior_ent_mag": 36.21814727783203, "report/prior_ent_max": 36.21814727783203, "report/prior_ent_mean": 36.19799041748047, "report/prior_ent_min": 36.04299545288086, "report/prior_ent_std": 0.029373280704021454, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.00010013580322265625, "report/reward_loss_std": 0.0, "report/reward_max_data": 0.0, "report/reward_max_pred": 3.528594970703125e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00010013580322265625, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 3.528594970703125e-05, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.0037578269839286804, "eval/cont_loss_std": 4.5674366333514627e-07, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0037578269839286804, "eval/cont_pred": 0.9962493181228638, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2661658227443695, "eval/image_loss_std": 0.0841742753982544, "eval/model_loss_mean": 0.8700238466262817, "eval/model_loss_std": 0.0841742679476738, "eval/post_ent_mag": 35.996055603027344, "eval/post_ent_max": 35.996055603027344, "eval/post_ent_mean": 35.98640823364258, "eval/post_ent_min": 35.877403259277344, "eval/post_ent_std": 0.01845094934105873, "eval/prior_ent_mag": 36.21575164794922, "eval/prior_ent_max": 36.21575164794922, "eval/prior_ent_mean": 36.198997497558594, "eval/prior_ent_min": 36.04299545288086, "eval/prior_ent_std": 0.027195259928703308, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00010013580322265625, "eval/reward_loss_std": 0.0, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 3.528594970703125e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00010013580322265625, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 3.528594970703125e-05, "eval/reward_rate": 0.0, "replay/size": 127457.0, "replay/inserts": 31728.0, "replay/samples": 31728.0, "replay/insert_wait_avg": 1.4022796729929929e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.918228500489327e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 31112.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2720469922480424e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.387731552124023e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.075788974762, "timer/env.step_count": 3966.0, "timer/env.step_total": 39.84778642654419, "timer/env.step_frac": 0.03984476663253148, "timer/env.step_avg": 0.010047349073763033, "timer/env.step_min": 0.007968664169311523, "timer/env.step_max": 0.03760886192321777, "timer/replay._sample_count": 31728.0, "timer/replay._sample_total": 17.269669771194458, "timer/replay._sample_frac": 0.017268361019816946, "timer/replay._sample_avg": 0.0005443037623296287, "timer/replay._sample_min": 0.00036525726318359375, "timer/replay._sample_max": 0.02077960968017578, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4833.0, "timer/agent.policy_total": 53.77295279502869, "timer/agent.policy_frac": 0.05376887770691318, "timer/agent.policy_avg": 0.011126205833856546, "timer/agent.policy_min": 0.009290933609008789, "timer/agent.policy_max": 0.09108257293701172, "timer/dataset_train_count": 1983.0, "timer/dataset_train_total": 0.23141956329345703, "timer/dataset_train_frac": 0.00023140202557118115, "timer/dataset_train_avg": 0.00011670174649190974, "timer/dataset_train_min": 0.00010013580322265625, "timer/dataset_train_max": 0.0010814666748046875, "timer/agent.train_count": 1983.0, "timer/agent.train_total": 890.7485885620117, "timer/agent.train_frac": 0.8906810847557582, "timer/agent.train_avg": 0.44919242993545727, "timer/agent.train_min": 0.4366445541381836, "timer/agent.train_max": 0.7048158645629883, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47583580017089844, "timer/agent.report_frac": 0.00047579973979642725, "timer/agent.report_avg": 0.23791790008544922, "timer/agent.report_min": 0.23080658912658691, "timer/agent.report_max": 0.24502921104431152, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9802322387695312e-05, "timer/dataset_eval_frac": 2.9800063871406657e-08, "timer/dataset_eval_avg": 2.9802322387695312e-05, "timer/dataset_eval_min": 2.9802322387695312e-05, "timer/dataset_eval_max": 2.9802322387695312e-05, "fps": 31.725021641803565}
{"step": 128032, "time": 4260.923263549805, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 128064, "time": 4261.913086175919, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 128584, "time": 4277.743123292923, "episode/length": 244.0, "episode/score": 0.23749999701976776, "episode/reward_rate": 0.004081632653061225, "episode/intrinsic_return": 0.0}
{"step": 129216, "time": 4297.390131950378, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 129384, "time": 4302.34446144104, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 129408, "time": 4303.320077419281, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 129728, "time": 4313.150013446808, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 129848, "time": 4316.602102994919, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 130000, "time": 4328.499275445938, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4328.592704296112, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4328.638150215149, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4328.646213054657, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4328.653002500534, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4328.659548282623, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4328.6661632061005, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4328.673652648926, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130344, "time": 4338.969516515732, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 130376, "time": 4339.979866981506, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 130896, "time": 4356.032466173172, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 131528, "time": 4375.759967088699, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 131696, "time": 4381.087931632996, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 131720, "time": 4381.598626613617, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 132040, "time": 4391.391687870026, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 132160, "time": 4395.27487206459, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 132656, "time": 4410.273084163666, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 132688, "time": 4411.244585514069, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 133208, "time": 4427.069962501526, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 133840, "time": 4446.484497785568, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 134008, "time": 4451.4337112903595, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 134032, "time": 4452.409815311432, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 134352, "time": 4462.159344434738, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 134472, "time": 4465.581577301025, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 134520, "time": 4467.069715499878, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 134968, "time": 4480.862594842911, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 135000, "time": 4481.865738153458, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 135520, "time": 4497.948902606964, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 136152, "time": 4517.020173549652, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 136320, "time": 4522.341673135757, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 136664, "time": 4532.564047336578, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 136784, "time": 4536.449955701828, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 136832, "time": 4537.97159910202, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 137280, "time": 4551.561995983124, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 137312, "time": 4552.538432836533, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 137832, "time": 4568.279695987701, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 138056, "time": 4575.149372339249, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 138464, "time": 4588.529939174652, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 138632, "time": 4593.441023349762, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 138976, "time": 4604.320100784302, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 139096, "time": 4607.764516830444, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 139144, "time": 4609.226225137711, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 139624, "time": 4624.328122377396, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 140088, "time": 4644.1425976753235, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4644.149487733841, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4644.1555297374725, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4644.1616978645325, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4644.167958021164, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4644.1753985881805, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4644.183309316635, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4644.191242218018, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140144, "time": 4646.132395982742, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 140224, "time": 4648.5560257434845, "episode/length": 219.0, "episode/score": 0.31562501192092896, "episode/reward_rate": 0.004545454545454545, "episode/intrinsic_return": 0.0}
{"step": 140368, "time": 4652.954344749451, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 140944, "time": 4670.561643600464, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 141288, "time": 4680.8007073402405, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 141408, "time": 4684.692807197571, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 141456, "time": 4686.148503065109, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 141936, "time": 4700.957637310028, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 142456, "time": 4716.664879560471, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 142536, "time": 4719.116437673569, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 142680, "time": 4723.491517543793, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 143256, "time": 4740.980395793915, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 143600, "time": 4751.779495239258, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 143720, "time": 4755.208431720734, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 143768, "time": 4756.678874969482, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 144248, "time": 4771.260621547699, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 144248, "time": 4771.3014459609985, "episode/length": 195.0, "episode/score": 0.390625, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.0}
{"step": 144632, "time": 4783.135074138641, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 144768, "time": 4787.482813358307, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 144848, "time": 4789.903979539871, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 145256, "time": 4802.147020101547, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 145568, "time": 4811.881648302078, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 145792, "time": 4818.6544024944305, "episode/length": 273.0, "episode/score": 0.14687499403953552, "episode/reward_rate": 0.0036496350364963502, "episode/intrinsic_return": 0.0}
{"step": 146032, "time": 4825.969597816467, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 146080, "time": 4827.431599855423, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 146560, "time": 4842.096652030945, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 147080, "time": 4857.572046518326, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 147160, "time": 4860.0029296875, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 147568, "time": 4873.1416709423065, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 147880, "time": 4882.35507273674, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 148104, "time": 4889.15194606781, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 148200, "time": 4892.065792798996, "episode/length": 270.0, "episode/score": 0.15625, "episode/reward_rate": 0.0036900369003690036, "episode/intrinsic_return": 0.0}
{"step": 148392, "time": 4897.962032318115, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 148872, "time": 4912.5193338394165, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 149392, "time": 4928.671812295914, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 149472, "time": 4931.117990732193, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 149880, "time": 4943.3556406497955, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 150072, "time": 4954.5404369831085, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 4954.571982383728, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 4954.588711261749, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 4954.598725557327, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 4954.60721373558, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 4954.616110086441, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 4954.623852491379, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 4954.631525993347, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150192, "time": 4958.56029009819, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 150416, "time": 4965.366237401962, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 150512, "time": 4968.301774263382, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 150704, "time": 4974.117651462555, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 151184, "time": 4988.741957187653, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 151704, "time": 5004.369659900665, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 151784, "time": 5006.811819076538, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 152192, "time": 5019.540332317352, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 152256, "time": 5021.487287521362, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 152504, "time": 5028.826654434204, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 152728, "time": 5035.653432369232, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 152824, "time": 5038.598073959351, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 153016, "time": 5044.489023685455, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 153496, "time": 5059.317851781845, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 154016, "time": 5075.342642784119, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 154504, "time": 5090.074329376221, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 154568, "time": 5092.027733325958, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 154816, "time": 5099.747717142105, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 155040, "time": 5106.612620830536, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 155136, "time": 5109.518419265747, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 155328, "time": 5115.406149864197, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 155808, "time": 5130.466658115387, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 156328, "time": 5146.077068090439, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 156816, "time": 5161.036964893341, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 156880, "time": 5162.968699455261, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 157128, "time": 5170.440857410431, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 157352, "time": 5177.299291133881, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 157448, "time": 5180.23849773407, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 157640, "time": 5186.098530769348, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 158120, "time": 5200.777051687241, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 158640, "time": 5216.789409637451, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 159128, "time": 5231.463564157486, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 159192, "time": 5233.411964178085, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 159440, "time": 5241.152135848999, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 159664, "time": 5247.928218364716, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 159760, "time": 5250.827126264572, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 159952, "time": 5256.789353132248, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 159993, "time": 5258.766644716263, "train_stats/mean_log_entropy": 1.9376795006613445, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.998953552246094, "train/action_min": 0.0, "train/action_std": 1.9997403144836425, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 4.800286279532884e-05, "train/actor_opt_grad_steps": 8905.0, "train/actor_opt_loss": -4.524581780806184, "train/adv_mag": 0.0002196035161614418, "train/adv_max": 0.0001863078400492668, "train/adv_mean": 6.129067029641888e-05, "train/adv_min": -7.0302439853549e-05, "train/adv_std": 5.178145699801462e-05, "train/cont_avg": 0.9964697265625, "train/cont_loss_mean": 0.023512867831159384, "train/cont_loss_std": 0.3243600409652572, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.673433094909511, "train/cont_pos_acc": 0.9999999859929085, "train/cont_pos_loss": 0.0034791837143711745, "train/cont_pred": 0.9965269753336906, "train/cont_rate": 0.9964697265625, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.009729370272834785, "train/extr_critic_critic_opt_grad_steps": 8905.0, "train/extr_critic_critic_opt_loss": 7211.035300292969, "train/extr_critic_mag": 0.01932919979095459, "train/extr_critic_max": 0.01932919979095459, "train/extr_critic_mean": 0.01929125948809087, "train/extr_critic_min": 0.01924770474433899, "train/extr_critic_std": 1.2447311531502692e-05, "train/extr_return_normed_mag": 0.000323558896780014, "train/extr_return_normed_max": 0.0002869644109159708, "train/extr_return_normed_mean": 0.0001995447060232891, "train/extr_return_normed_min": 9.854513220489025e-05, "train/extr_return_normed_std": 4.8274485672727965e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.019439966334030032, "train/extr_return_raw_max": 0.019439966334030032, "train/extr_return_raw_mean": 0.019352547526359558, "train/extr_return_raw_min": 0.01925154705531895, "train/extr_return_raw_std": 4.8274486014072695e-05, "train/extr_reward_mag": 6.767511367797852e-05, "train/extr_reward_max": 6.767511367797852e-05, "train/extr_reward_mean": 6.763728153600823e-05, "train/extr_reward_min": 6.7596435546875e-05, "train/extr_reward_std": 1.7227663866581365e-08, "train/image_loss_mean": 0.2506370265781879, "train/image_loss_std": 0.08632456012070179, "train/model_loss_mean": 0.8765381217002869, "train/model_loss_std": 0.38759217515587807, "train/model_opt_grad_norm": 48.04051494598389, "train/model_opt_grad_steps": 8894.655, "train/model_opt_loss": 2350.444983520508, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2681.25, "train/policy_entropy_mag": 1.9459020352363587, "train/policy_entropy_max": 1.9459020352363587, "train/policy_entropy_mean": 1.9454948180913925, "train/policy_entropy_min": 1.9377365058660507, "train/policy_entropy_std": 0.0003015320058329962, "train/policy_logprob_mag": 2.116552140712738, "train/policy_logprob_max": -1.7880698376893998, "train/policy_logprob_mean": -1.9455070412158966, "train/policy_logprob_min": -2.116552140712738, "train/policy_logprob_std": 0.028808914022520185, "train/policy_randomness_mag": 0.9999958887696266, "train/policy_randomness_max": 0.9999958887696266, "train/policy_randomness_mean": 0.999786619246006, "train/policy_randomness_min": 0.9957996380329132, "train/policy_randomness_std": 0.0001549567988695344, "train/post_ent_mag": 36.13293809890747, "train/post_ent_max": 36.13293809890747, "train/post_ent_mean": 36.11918321609497, "train/post_ent_min": 36.004248733520505, "train/post_ent_std": 0.021602676436305045, "train/prior_ent_mag": 36.29021741867066, "train/prior_ent_max": 36.29021741867066, "train/prior_ent_mean": 36.27039529800415, "train/prior_ent_min": 36.10643186569214, "train/prior_ent_std": 0.03095349607989192, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.000115875243282062, "train/reward_loss_mean": 0.0023882085736840965, "train/reward_loss_std": 0.064155154387471, "train/reward_max_data": 0.10301562376320363, "train/reward_max_pred": 6.76119327545166e-05, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00017361095829983243, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 10.061940770400199, "train/reward_pred": 6.755264708772301e-05, "train/reward_rate": 0.0002197265625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9990234375, "report/cont_loss_mean": 0.009354819543659687, "report/cont_loss_std": 0.17276711761951447, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.535202980041504, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.003953210078179836, "report/cont_pred": 0.9960545897483826, "report/cont_rate": 0.9990234375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.2605550289154053, "report/image_loss_std": 0.08326207846403122, "report/model_loss_mean": 0.8700500726699829, "report/model_loss_std": 0.18931128084659576, "report/post_ent_mag": 36.642127990722656, "report/post_ent_max": 36.642127990722656, "report/post_ent_mean": 36.6282958984375, "report/post_ent_min": 36.50448989868164, "report/post_ent_std": 0.022024160251021385, "report/prior_ent_mag": 36.351200103759766, "report/prior_ent_max": 36.351200103759766, "report/prior_ent_mean": 36.329551696777344, "report/prior_ent_min": 36.14759063720703, "report/prior_ent_std": 0.03193993121385574, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.00014019012451171875, "report/reward_loss_std": 0.0, "report/reward_max_data": 0.0, "report/reward_max_pred": 5.412101745605469e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00014019012451171875, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 5.412101745605469e-05, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.003953210543841124, "eval/cont_loss_std": 0.0, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.003953210543841124, "eval/cont_pred": 0.9960545897483826, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2593218684196472, "eval/image_loss_std": 0.08732031285762787, "eval/model_loss_mean": 0.8634152412414551, "eval/model_loss_std": 0.08732031285762787, "eval/post_ent_mag": 36.64276123046875, "eval/post_ent_max": 36.64276123046875, "eval/post_ent_mean": 36.62910461425781, "eval/post_ent_min": 36.50436782836914, "eval/post_ent_std": 0.02137826569378376, "eval/prior_ent_mag": 36.35071563720703, "eval/prior_ent_max": 36.35071563720703, "eval/prior_ent_mean": 36.3302116394043, "eval/prior_ent_min": 36.14759063720703, "eval/prior_ent_std": 0.031106011942029, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00014019012451171875, "eval/reward_loss_std": 0.0, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 5.412101745605469e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00014019012451171875, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 5.412101745605469e-05, "eval/reward_rate": 0.0, "replay/size": 159489.0, "replay/inserts": 32032.0, "replay/samples": 32032.0, "replay/insert_wait_avg": 1.336184593585583e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.752162044460361e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 38048.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2385322698397344e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0728836059570312e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0457088947296, "timer/env.step_count": 4004.0, "timer/env.step_total": 38.814141273498535, "timer/env.step_frac": 0.03881236720309184, "timer/env.step_avg": 0.009693841476897736, "timer/env.step_min": 0.007817745208740234, "timer/env.step_max": 0.03917813301086426, "timer/replay._sample_count": 32032.0, "timer/replay._sample_total": 17.28637409210205, "timer/replay._sample_frac": 0.01728558398716324, "timer/replay._sample_avg": 0.0005396595308473417, "timer/replay._sample_min": 0.0003829002380371094, "timer/replay._sample_max": 0.011580705642700195, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4871.0, "timer/agent.policy_total": 52.71393179893494, "timer/agent.policy_frac": 0.0527115224135059, "timer/agent.policy_avg": 0.010821993799822405, "timer/agent.policy_min": 0.008931636810302734, "timer/agent.policy_max": 0.08826541900634766, "timer/dataset_train_count": 2002.0, "timer/dataset_train_total": 0.22408628463745117, "timer/dataset_train_frac": 0.00022407604236921908, "timer/dataset_train_avg": 0.00011193121110761797, "timer/dataset_train_min": 9.560585021972656e-05, "timer/dataset_train_max": 0.0004982948303222656, "timer/agent.train_count": 2002.0, "timer/agent.train_total": 893.7160058021545, "timer/agent.train_frac": 0.8936751568984854, "timer/agent.train_avg": 0.4464115913097675, "timer/agent.train_min": 0.4341292381286621, "timer/agent.train_max": 1.0986077785491943, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47100830078125, "timer/agent.report_frac": 0.0004709867724964469, "timer/agent.report_avg": 0.235504150390625, "timer/agent.report_min": 0.22794127464294434, "timer/agent.report_max": 0.24306702613830566, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.147125244140625e-05, "timer/dataset_eval_frac": 3.146981399099138e-08, "timer/dataset_eval_avg": 3.147125244140625e-05, "timer/dataset_eval_min": 3.147125244140625e-05, "timer/dataset_eval_max": 3.147125244140625e-05, "fps": 32.03000286711697}
{"step": 160056, "time": 5265.9142117500305, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5265.921701669693, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5265.930460214615, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5265.937393903732, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5265.943443059921, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5265.949949026108, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5265.957378149033, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5265.966231584549, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160432, "time": 5277.615657329559, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 160952, "time": 5293.407150268555, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 161440, "time": 5308.593430042267, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 161504, "time": 5310.540068626404, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 161752, "time": 5318.006721019745, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 161976, "time": 5324.8374536037445, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 162072, "time": 5327.798604011536, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 162264, "time": 5333.669609069824, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 162744, "time": 5348.405123949051, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 163264, "time": 5364.519480705261, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 163752, "time": 5379.353631496429, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 163816, "time": 5381.325223207474, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 164064, "time": 5389.639889240265, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 164288, "time": 5396.492316961288, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 164384, "time": 5399.407667636871, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 164576, "time": 5405.265734434128, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 165056, "time": 5420.148694038391, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 165576, "time": 5435.78640127182, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 166064, "time": 5451.0822904109955, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 166128, "time": 5453.066104412079, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 166376, "time": 5460.44436788559, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 166600, "time": 5467.355430841446, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 166696, "time": 5470.305131435394, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 166888, "time": 5476.179909467697, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 167368, "time": 5490.831714630127, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 167888, "time": 5507.0312213897705, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 168376, "time": 5521.6973469257355, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 168440, "time": 5523.660087585449, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 168688, "time": 5531.538688182831, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 168912, "time": 5538.420587062836, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 169008, "time": 5541.319858551025, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 169200, "time": 5547.167556524277, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 169680, "time": 5561.939665794373, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 170040, "time": 5575.513777256012, "eval_episode/length": 112.0, "eval_episode/score": 0.6499999761581421, "eval_episode/reward_rate": 0.008849557522123894}
{"step": 170040, "time": 5578.706347465515, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5578.716781616211, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5578.724450826645, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5578.729996681213, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5578.73558473587, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5578.742811918259, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5578.749528169632, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170200, "time": 5583.6149361133575, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 170688, "time": 5598.968567848206, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 170752, "time": 5600.91172170639, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 171000, "time": 5608.274614334106, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 171224, "time": 5615.092631340027, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 171320, "time": 5618.11153626442, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 171512, "time": 5623.963350057602, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 171992, "time": 5638.608596324921, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 172504, "time": 5654.986161470413, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 172512, "time": 5655.455553770065, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 173000, "time": 5670.140753746033, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 173064, "time": 5672.105647802353, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 173312, "time": 5680.079194068909, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 173632, "time": 5689.822220563889, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 173824, "time": 5695.67094540596, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 174304, "time": 5710.403890609741, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 174816, "time": 5726.0271854400635, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 174824, "time": 5726.0568079948425, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 175312, "time": 5741.4669687747955, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 175376, "time": 5743.412930488586, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 175624, "time": 5750.731127977371, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 175944, "time": 5760.473160505295, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 175960, "time": 5760.9846251010895, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 176136, "time": 5766.380952119827, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 176440, "time": 5775.738789319992, "episode/length": 201.0, "episode/score": 0.37187498807907104, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.0}
{"step": 176616, "time": 5781.203973054886, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 177128, "time": 5797.002794981003, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 177400, "time": 5805.317959785461, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 177624, "time": 5812.172714471817, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 177936, "time": 5821.902390956879, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 178256, "time": 5831.718405723572, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 178448, "time": 5837.573817014694, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 178752, "time": 5846.840577840805, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 178928, "time": 5852.178817987442, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 179440, "time": 5867.816468715668, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 179712, "time": 5876.137163639069, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 179936, "time": 5882.971244335175, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 180024, "time": 5889.355055809021, "eval_episode/length": 187.0, "eval_episode/score": 0.4156250059604645, "eval_episode/reward_rate": 0.005319148936170213}
{"step": 180024, "time": 5891.3386998176575, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 5891.35528922081, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 5891.398540735245, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 5891.408802032471, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 5891.49649477005, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 5891.5067484378815, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 5891.512343168259, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180248, "time": 5898.881571292877, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 180568, "time": 5908.649663448334, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 180760, "time": 5914.521340608597, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 181064, "time": 5923.891680955887, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 181240, "time": 5929.319007158279, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 181752, "time": 5944.937174797058, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 182024, "time": 5953.331101894379, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 182248, "time": 5960.200978517532, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 182560, "time": 5969.94936466217, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 182880, "time": 5979.831506252289, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 183072, "time": 5985.665525197983, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 183376, "time": 5994.932996273041, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 183552, "time": 6000.330091238022, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 184064, "time": 6016.117894411087, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 184336, "time": 6024.421714544296, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 184560, "time": 6031.247908592224, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 184872, "time": 6040.621036052704, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 185192, "time": 6050.376987218857, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 185384, "time": 6056.208129644394, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 185688, "time": 6065.497837305069, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 185864, "time": 6070.97757101059, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 186376, "time": 6086.843351125717, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 186648, "time": 6095.143729686737, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 186872, "time": 6102.1566417217255, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 187184, "time": 6111.914817810059, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 187504, "time": 6121.702213048935, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 187696, "time": 6127.647154808044, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 188000, "time": 6136.938223600388, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 188176, "time": 6142.32679104805, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 188688, "time": 6158.749837875366, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 188960, "time": 6167.024208307266, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 189184, "time": 6173.876343488693, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 189496, "time": 6183.187157392502, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 189816, "time": 6193.059412240982, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 190008, "time": 6198.943811416626, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 190008, "time": 6204.688571691513, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6204.69468164444, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6204.766877889633, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6204.78422999382, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6204.789563894272, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6204.798181295395, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6204.80383348465, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6204.810948133469, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190312, "time": 6214.094833135605, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 190448, "time": 6218.561424255371, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 190488, "time": 6219.556835889816, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 191000, "time": 6235.175083875656, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 191272, "time": 6243.480650424957, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 191496, "time": 6250.416757822037, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 191745, "time": 6258.7843697071075, "eval_stats/mean_log_entropy": 0.0, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.999753393308081, "train/action_min": 0.0, "train/action_std": 2.0010574791166515, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00014153972438869073, "train/actor_opt_grad_steps": 10895.0, "train/actor_opt_loss": -4.922926381775977, "train/adv_mag": 0.00034922366077550735, "train/adv_max": 0.0002947699165705479, "train/adv_mean": 3.941710672540691e-05, "train/adv_min": -0.00023366509927342637, "train/adv_std": 7.582135354924604e-05, "train/cont_avg": 0.9965672348484849, "train/cont_loss_mean": 0.0229212492751428, "train/cont_loss_std": 0.31575018779343816, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.6393523316108745, "train/cont_pos_acc": 0.9999999852493556, "train/cont_pos_loss": 0.0035855703730832294, "train/cont_pred": 0.9964209518047294, "train/cont_rate": 0.9965672348484849, "train/dyn_loss_mean": 1.000001189684627, "train/dyn_loss_std": 3.340403997175269e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.008122685470035055, "train/extr_critic_critic_opt_grad_steps": 10895.0, "train/extr_critic_critic_opt_loss": 7795.202942511048, "train/extr_critic_mag": 0.02196528995879973, "train/extr_critic_max": 0.02196528995879973, "train/extr_critic_mean": 0.021806075294135197, "train/extr_critic_min": 0.021649826054621225, "train/extr_critic_std": 4.403523977666829e-05, "train/extr_return_normed_mag": 0.00039611604403365743, "train/extr_return_normed_max": 0.00034714164682711013, "train/extr_return_normed_mean": 0.0001744610504040407, "train/extr_return_normed_min": -9.060931401421326e-06, "train/extr_return_normed_std": 6.146548600159492e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.02201816618367277, "train/extr_return_raw_max": 0.02201816618367277, "train/extr_return_raw_mean": 0.02184548685233099, "train/extr_return_raw_min": 0.02166196360544424, "train/extr_return_raw_std": 6.146548627260596e-05, "train/extr_reward_mag": 7.223360466234612e-05, "train/extr_reward_max": 7.223360466234612e-05, "train/extr_reward_mean": 7.167906501722014e-05, "train/extr_reward_min": 7.151473652232777e-05, "train/extr_reward_std": 1.1599004534679775e-07, "train/image_loss_mean": 0.2370847516288661, "train/image_loss_std": 0.08677837207461848, "train/model_loss_mean": 0.8622125131313247, "train/model_loss_std": 0.37554287797573843, "train/model_opt_grad_norm": 44.33065623466415, "train/model_opt_grad_steps": 10883.368686868687, "train/model_opt_loss": 2870.605608082781, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3345.959595959596, "train/policy_entropy_mag": 1.9457811785466743, "train/policy_entropy_max": 1.9457811785466743, "train/policy_entropy_mean": 1.9378888896017363, "train/policy_entropy_min": 1.8675340666915432, "train/policy_entropy_std": 0.0062270634581283145, "train/policy_logprob_mag": 2.4943854808807373, "train/policy_logprob_max": -1.4480581108969872, "train/policy_logprob_mean": -1.937995808293121, "train/policy_logprob_min": -2.4943854808807373, "train/policy_logprob_std": 0.10520990268148557, "train/policy_randomness_mag": 0.9999337801427552, "train/policy_randomness_max": 0.9999337801427552, "train/policy_randomness_mean": 0.9958779423525839, "train/policy_randomness_min": 0.9597227170009806, "train/policy_randomness_std": 0.003200077774112508, "train/post_ent_mag": 40.09712835755011, "train/post_ent_max": 40.09712835755011, "train/post_ent_mean": 39.88979611252294, "train/post_ent_min": 39.73253088286429, "train/post_ent_std": 0.08053676788271828, "train/prior_ent_mag": 38.772952089406026, "train/prior_ent_max": 38.772952089406026, "train/prior_ent_mean": 37.77060984601878, "train/prior_ent_min": 37.159832675047596, "train/prior_ent_std": 0.23098731503793687, "train/rep_loss_mean": 1.000001189684627, "train/rep_loss_std": 3.340403997175269e-05, "train/reward_avg": 9.875056672502647e-05, "train/reward_loss_mean": 0.0022057765774955653, "train/reward_loss_std": 0.06007324964397163, "train/reward_max_data": 0.09155618632682647, "train/reward_max_pred": 7.213426358772047e-05, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00017938112932365538, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 10.03448149893019, "train/reward_pred": 7.163019876720177e-05, "train/reward_rate": 0.00020221748737373737, "train_stats/mean_log_entropy": 1.9311144351959229, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.0310228168964386, "report/cont_loss_std": 0.3896474540233612, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.593572616577148, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0037286507431417704, "report/cont_pred": 0.9962780475616455, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.19527661800384521, "report/image_loss_std": 0.09267529845237732, "report/model_loss_mean": 0.8264492750167847, "report/model_loss_std": 0.39900168776512146, "report/post_ent_mag": 42.01925277709961, "report/post_ent_max": 42.01925277709961, "report/post_ent_mean": 41.61827850341797, "report/post_ent_min": 41.341461181640625, "report/post_ent_std": 0.14493681490421295, "report/prior_ent_mag": 43.82200622558594, "report/prior_ent_max": 43.82200622558594, "report/prior_ent_mean": 40.18821716308594, "report/prior_ent_min": 37.58586120605469, "report/prior_ent_std": 0.9690600633621216, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.00014982279390096664, "report/reward_loss_std": 2.8684584663096757e-07, "report/reward_max_data": 0.0, "report/reward_max_pred": 5.4717063903808594e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00014982279390096664, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 5.4288189858198166e-05, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.0037286507431417704, "eval/cont_loss_std": 6.984919309616089e-10, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0037286507431417704, "eval/cont_pred": 0.9962780475616455, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2140704244375229, "eval/image_loss_std": 0.08828184008598328, "eval/model_loss_mean": 0.8179488778114319, "eval/model_loss_std": 0.0882817953824997, "eval/post_ent_mag": 41.971595764160156, "eval/post_ent_max": 41.971595764160156, "eval/post_ent_mean": 41.57850646972656, "eval/post_ent_min": 41.344482421875, "eval/post_ent_std": 0.1355636715888977, "eval/prior_ent_mag": 42.39258575439453, "eval/prior_ent_max": 42.39258575439453, "eval/prior_ent_mean": 39.981651306152344, "eval/prior_ent_min": 37.79279327392578, "eval/prior_ent_std": 0.7158498167991638, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0001497957855463028, "eval/reward_loss_std": 2.4693224531802116e-07, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 5.4717063903808594e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0001497957855463028, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 5.427468568086624e-05, "eval/reward_rate": 0.0, "replay/size": 191241.0, "replay/inserts": 31752.0, "replay/samples": 31744.0, "replay/insert_wait_avg": 1.358802686803255e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.830515247198843e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 47296.0, "eval_replay/inserts": 9248.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2197038706611185e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.387731552124023e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0002436637878, "timer/env.step_count": 3969.0, "timer/env.step_total": 38.69300413131714, "timer/env.step_frac": 0.038692994703235485, "timer/env.step_avg": 0.009748804265889931, "timer/env.step_min": 0.007856607437133789, "timer/env.step_max": 0.03527545928955078, "timer/replay._sample_count": 31744.0, "timer/replay._sample_total": 17.489601373672485, "timer/replay._sample_frac": 0.017489597112091006, "timer/replay._sample_avg": 0.0005509577045637754, "timer/replay._sample_min": 0.000396728515625, "timer/replay._sample_max": 0.011356830596923828, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5125.0, "timer/agent.policy_total": 55.5665762424469, "timer/agent.policy_frac": 0.055566562702887755, "timer/agent.policy_avg": 0.010842258779014029, "timer/agent.policy_min": 0.008831024169921875, "timer/agent.policy_max": 0.09074044227600098, "timer/dataset_train_count": 1984.0, "timer/dataset_train_total": 0.22525811195373535, "timer/dataset_train_frac": 0.00022525805706650394, "timer/dataset_train_avg": 0.00011353735481539081, "timer/dataset_train_min": 9.703636169433594e-05, "timer/dataset_train_max": 0.0009663105010986328, "timer/agent.train_count": 1984.0, "timer/agent.train_total": 888.6199419498444, "timer/agent.train_frac": 0.8886197254253961, "timer/agent.train_avg": 0.4478931159021393, "timer/agent.train_min": 0.4379560947418213, "timer/agent.train_max": 0.7047755718231201, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4760451316833496, "timer/agent.report_frac": 0.0004760450156884179, "timer/agent.report_avg": 0.2380225658416748, "timer/agent.report_min": 0.23059487342834473, "timer/agent.report_max": 0.24545025825500488, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.4332275390625e-05, "timer/dataset_eval_frac": 3.433226702509477e-08, "timer/dataset_eval_avg": 3.4332275390625e-05, "timer/dataset_eval_min": 3.4332275390625e-05, "timer/dataset_eval_max": 3.4332275390625e-05, "fps": 31.75144509400647}
{"step": 191808, "time": 6261.0019681453705, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 192320, "time": 6276.7768750190735, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 192624, "time": 6286.083441019058, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 192760, "time": 6290.021069288254, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 192800, "time": 6291.461231231689, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 193312, "time": 6307.038003921509, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 193584, "time": 6315.316057920456, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 193808, "time": 6322.1273458004, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 194120, "time": 6331.451911449432, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 194632, "time": 6347.251701116562, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 194936, "time": 6356.54274225235, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 195072, "time": 6360.9232878685, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 195112, "time": 6361.923485279083, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 195624, "time": 6377.660360336304, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 195896, "time": 6385.961562395096, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 196120, "time": 6392.783604860306, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 196432, "time": 6402.6402361392975, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 196944, "time": 6418.84046292305, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 197248, "time": 6428.271231889725, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 197384, "time": 6432.19275188446, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 197424, "time": 6433.654116153717, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 197936, "time": 6449.3549818992615, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 198208, "time": 6457.787406206131, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 198432, "time": 6464.649664402008, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 198744, "time": 6474.009910583496, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 199256, "time": 6489.790286779404, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 199560, "time": 6499.933310985565, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 199696, "time": 6504.3063497543335, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 199736, "time": 6505.31157541275, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 200096, "time": 6517.904538154602, "eval_episode/length": 56.0, "eval_episode/score": 0.824999988079071, "eval_episode/reward_rate": 0.017543859649122806}
{"step": 200096, "time": 6522.998402118683, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6523.004741430283, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6523.01136636734, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6523.01816534996, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6523.024564266205, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6523.031291484833, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6523.038920402527, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200248, "time": 6527.476795196533, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 200520, "time": 6535.765556335449, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 200744, "time": 6542.563886165619, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 201056, "time": 6552.365451335907, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 201568, "time": 6568.032747745514, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 201872, "time": 6577.4280824661255, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 202008, "time": 6581.332095861435, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 202048, "time": 6582.792870521545, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 202560, "time": 6598.400842428207, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 202832, "time": 6606.806616306305, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 203056, "time": 6613.6212685108185, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 203368, "time": 6622.970602273941, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 203496, "time": 6626.897681474686, "episode/length": 202.0, "episode/score": 0.3687500059604645, "episode/reward_rate": 0.0049261083743842365, "episode/intrinsic_return": 0.0}
{"step": 203680, "time": 6632.7222192287445, "episode/length": 263.0, "episode/score": 0.17812499403953552, "episode/reward_rate": 0.003787878787878788, "episode/intrinsic_return": 0.0}
{"step": 203864, "time": 6638.251748085022, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 204320, "time": 6652.431315422058, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 204360, "time": 6653.434827327728, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 204872, "time": 6669.737845897675, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 205368, "time": 6684.9120008945465, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 205680, "time": 6694.665601730347, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 205808, "time": 6698.719617843628, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 205992, "time": 6704.117032766342, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 206176, "time": 6709.961140155792, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 206632, "time": 6723.61745262146, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 206672, "time": 6725.0815761089325, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 207184, "time": 6741.007176399231, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 207680, "time": 6756.123594045639, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 207992, "time": 6765.520701169968, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 208120, "time": 6769.430197477341, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 208304, "time": 6775.246812343597, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 208488, "time": 6780.621647357941, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 208944, "time": 6794.914226293564, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 208984, "time": 6795.922837257385, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 209496, "time": 6811.6017026901245, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 209992, "time": 6826.899533748627, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 210080, "time": 6832.6378536224365, "eval_episode/length": 144.0, "eval_episode/score": 0.550000011920929, "eval_episode/reward_rate": 0.006896551724137931}
{"step": 210080, "time": 6835.327205657959, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 6835.349962234497, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 6835.358206272125, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 6835.384185791016, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 6835.393903017044, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 6835.410616874695, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 6835.419167041779, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210304, "time": 6842.201220035553, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 210432, "time": 6846.104518175125, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 210616, "time": 6851.585314273834, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 210800, "time": 6857.3955891132355, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 210816, "time": 6857.887540102005, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 211256, "time": 6871.094947338104, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 211296, "time": 6872.5422422885895, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 211808, "time": 6888.214378118515, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 212304, "time": 6903.2994294166565, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 212744, "time": 6916.528326511383, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 212928, "time": 6922.351776123047, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 213112, "time": 6928.2067086696625, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 213128, "time": 6928.701946973801, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 213568, "time": 6942.516587257385, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 213608, "time": 6943.505818843842, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 214120, "time": 6958.986635923386, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 214616, "time": 6974.174081087112, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 215056, "time": 6987.765272855759, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 215240, "time": 6993.1452758312225, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 215424, "time": 6999.144768476486, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 215440, "time": 6999.643096208572, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 215880, "time": 7012.833832025528, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 215920, "time": 7014.2792019844055, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 216432, "time": 7029.943081855774, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 216928, "time": 7044.982593297958, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 217368, "time": 7058.239873886108, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 217552, "time": 7064.0323350429535, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 217736, "time": 7069.42977643013, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 217752, "time": 7069.925005912781, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 217976, "time": 7076.735917329788, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 218192, "time": 7083.505920171738, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 218232, "time": 7084.498803138733, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 219240, "time": 7115.268385410309, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 219680, "time": 7128.911860227585, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 219712, "time": 7129.8858234882355, "episode/length": 246.0, "episode/score": 0.23125000298023224, "episode/reward_rate": 0.004048582995951417, "episode/intrinsic_return": 0.0}
{"step": 219864, "time": 7134.288512945175, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 220064, "time": 7140.580161333084, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 220064, "time": 7146.020985841751, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7146.029043197632, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7146.038908243179, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7146.046133518219, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7146.05436372757, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7146.061705350876, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7146.07032251358, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7146.0780556201935, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220288, "time": 7152.9551882743835, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 220504, "time": 7159.275022029877, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 220544, "time": 7160.709463834763, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 221552, "time": 7191.833565235138, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 221992, "time": 7204.892176151276, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 222024, "time": 7205.862984418869, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 222176, "time": 7210.7951509952545, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 222376, "time": 7216.655778169632, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 222600, "time": 7223.424276828766, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 222816, "time": 7230.169696569443, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 222856, "time": 7231.177609205246, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 223737, "time": 7258.816337108612, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.2797512817382812, "train/action_min": 0.0, "train/action_std": 1.862504213452339, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00045616980649356266, "train/actor_opt_grad_steps": 12885.0, "train/actor_opt_loss": 0.5434835817362181, "train/adv_mag": 0.001810923833400011, "train/adv_max": 0.001753203347325325, "train/adv_mean": 0.0003704611459465923, "train/adv_min": -0.0009596950095146895, "train/adv_std": 0.0003842544477811316, "train/cont_avg": 0.996484375, "train/cont_loss_mean": 0.02342468899791129, "train/cont_loss_std": 0.3198337943269644, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.65413612899385, "train/cont_pos_acc": 0.9999999856948852, "train/cont_pos_loss": 0.0035314428980927916, "train/cont_pred": 0.9964748802781105, "train/cont_rate": 0.996484375, "train/dyn_loss_mean": 1.0002729511260986, "train/dyn_loss_std": 0.00044361621665302666, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.010632988537981874, "train/extr_critic_critic_opt_grad_steps": 12885.0, "train/extr_critic_critic_opt_loss": 9004.280649414062, "train/extr_critic_mag": 0.02893666982650757, "train/extr_critic_max": 0.02893666982650757, "train/extr_critic_mean": 0.028025689804926514, "train/extr_critic_min": 0.027261113524436952, "train/extr_critic_std": 0.00020062979081558296, "train/extr_return_normed_mag": 0.002706926502287388, "train/extr_return_normed_max": 0.002700481601059437, "train/extr_return_normed_mean": 0.0013342370068858145, "train/extr_return_normed_min": 0.0001995663344860077, "train/extr_return_normed_std": 0.0004141155380784767, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.029762384854257105, "train/extr_return_raw_max": 0.029762384854257105, "train/extr_return_raw_mean": 0.028396141761913896, "train/extr_return_raw_min": 0.027261469587683676, "train/extr_return_raw_std": 0.00041411553665966495, "train/extr_reward_mag": 0.0002518385648727417, "train/extr_reward_max": 0.00024442970752716067, "train/extr_reward_mean": 0.0001303152259788476, "train/extr_reward_min": 3.375411033630371e-05, "train/extr_reward_std": 7.392433909435781e-05, "train/image_loss_mean": 0.19747357025742532, "train/image_loss_std": 0.09790700066834689, "train/model_loss_mean": 0.8227344715595245, "train/model_loss_std": 0.36911072928458455, "train/model_opt_grad_norm": 40.06121356010437, "train/model_opt_grad_steps": 12871.955, "train/model_opt_loss": 2605.9346472167967, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3175.0, "train/policy_entropy_mag": 1.9374830162525176, "train/policy_entropy_max": 1.9374830162525176, "train/policy_entropy_mean": 1.8212380194664002, "train/policy_entropy_min": 1.5114226871728897, "train/policy_entropy_std": 0.04371899575460702, "train/policy_logprob_mag": 3.9507828640937803, "train/policy_logprob_max": -0.7286432315409184, "train/policy_logprob_mean": -1.8214305382966995, "train/policy_logprob_min": -3.9507828640937803, "train/policy_logprob_std": 0.40334399953484534, "train/policy_randomness_mag": 0.9956693699955941, "train/policy_randomness_max": 0.9956693699955941, "train/policy_randomness_mean": 0.935931259393692, "train/policy_randomness_min": 0.7767176613211632, "train/policy_randomness_std": 0.022467120802029967, "train/post_ent_mag": 37.296479301452635, "train/post_ent_max": 37.296479301452635, "train/post_ent_mean": 36.992050647735596, "train/post_ent_min": 36.73439323425293, "train/post_ent_std": 0.11802456859499216, "train/prior_ent_mag": 40.04553485870361, "train/prior_ent_max": 40.04553485870361, "train/prior_ent_mean": 37.23950588226318, "train/prior_ent_min": 34.90224945068359, "train/prior_ent_std": 0.9217500449717044, "train/rep_loss_mean": 1.0002729511260986, "train/rep_loss_std": 0.00044361621665302666, "train/reward_avg": 7.037353519990574e-05, "train/reward_loss_mean": 0.0016724221687763928, "train/reward_loss_std": 0.04502366316450388, "train/reward_max_data": 0.06564062468707561, "train/reward_max_pred": 0.00024837255477905273, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00018076281463436317, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 9.820686033793859, "train/reward_pred": 7.374963199254126e-05, "train/reward_rate": 0.0001513671875, "train_stats/mean_log_entropy": 1.823382550052234, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.03108219802379608, "report/cont_loss_std": 0.3929148316383362, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.640276908874512, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.003559162374585867, "report/cont_pred": 0.9964472651481628, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.16973361372947693, "report/image_loss_std": 0.0882241502404213, "report/model_loss_mean": 0.8009974956512451, "report/model_loss_std": 0.3981102705001831, "report/post_ent_mag": 35.029457092285156, "report/post_ent_max": 35.029457092285156, "report/post_ent_mean": 34.611045837402344, "report/post_ent_min": 33.93480682373047, "report/post_ent_std": 0.20142407715320587, "report/prior_ent_mag": 37.82073211669922, "report/prior_ent_max": 37.82073211669922, "report/prior_ent_mean": 34.67400360107422, "report/prior_ent_min": 33.568214416503906, "report/prior_ent_std": 0.801482081413269, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.00018162792548537254, "report/reward_loss_std": 0.00041637607500888407, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.0008689165115356445, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00018162792548537254, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 7.506750989705324e-05, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.020072385668754578, "eval/cont_loss_std": 0.30464908480644226, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.640276908874512, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0035585614386945963, "eval/cont_pred": 0.9964479207992554, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.24030911922454834, "eval/image_loss_std": 0.11710291355848312, "eval/model_loss_mean": 0.8605407476425171, "eval/model_loss_std": 0.32446369528770447, "eval/post_ent_mag": 34.98733139038086, "eval/post_ent_max": 34.98733139038086, "eval/post_ent_mean": 34.571414947509766, "eval/post_ent_min": 33.93596649169922, "eval/post_ent_std": 0.18117614090442657, "eval/prior_ent_mag": 37.74205780029297, "eval/prior_ent_max": 37.74205780029297, "eval/prior_ent_mean": 34.546749114990234, "eval/prior_ent_min": 33.52332305908203, "eval/prior_ent_std": 0.8197216987609863, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0001592603512108326, "eval/reward_loss_std": 0.00037247169530019164, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.00087738037109375, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0001592603512108326, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 6.639061030000448e-05, "eval/reward_rate": 0.0, "replay/size": 223233.0, "replay/inserts": 31992.0, "replay/samples": 32000.0, "replay/insert_wait_avg": 1.3424235899825787e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.817389607429504e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 54232.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1945334547806226e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.6391277313232422e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0182752609253, "timer/env.step_count": 3999.0, "timer/env.step_total": 38.32180666923523, "timer/env.step_frac": 0.0383211063410179, "timer/env.step_avg": 0.009582847379153596, "timer/env.step_min": 0.007653474807739258, "timer/env.step_max": 0.03470659255981445, "timer/replay._sample_count": 32000.0, "timer/replay._sample_total": 17.278830766677856, "timer/replay._sample_frac": 0.01727851499730788, "timer/replay._sample_avg": 0.000539963461458683, "timer/replay._sample_min": 0.00038695335388183594, "timer/replay._sample_max": 0.01199197769165039, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4866.0, "timer/agent.policy_total": 52.13030767440796, "timer/agent.policy_frac": 0.05212935499684353, "timer/agent.policy_avg": 0.010713174614551573, "timer/agent.policy_min": 0.008966684341430664, "timer/agent.policy_max": 0.08432626724243164, "timer/dataset_train_count": 2000.0, "timer/dataset_train_total": 0.2256302833557129, "timer/dataset_train_frac": 0.0002256261599787677, "timer/dataset_train_avg": 0.00011281514167785644, "timer/dataset_train_min": 9.751319885253906e-05, "timer/dataset_train_max": 0.0010950565338134766, "timer/agent.train_count": 2000.0, "timer/agent.train_total": 895.3685779571533, "timer/agent.train_frac": 0.8953522151618012, "timer/agent.train_avg": 0.44768428897857665, "timer/agent.train_min": 0.4342031478881836, "timer/agent.train_max": 1.26039457321167, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4689493179321289, "timer/agent.report_frac": 0.0004689407479176022, "timer/agent.report_avg": 0.23447465896606445, "timer/agent.report_min": 0.2226395606994629, "timer/agent.report_max": 0.24630975723266602, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.62396240234375e-05, "timer/dataset_eval_frac": 3.6238961746955914e-08, "timer/dataset_eval_avg": 3.62396240234375e-05, "timer/dataset_eval_min": 3.62396240234375e-05, "timer/dataset_eval_max": 3.62396240234375e-05, "fps": 31.990872132724345}
{"step": 223864, "time": 7262.454041004181, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 224304, "time": 7276.149696588516, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 224336, "time": 7277.1258244514465, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 224488, "time": 7281.536578655243, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 224688, "time": 7287.785044670105, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 224912, "time": 7294.557918787003, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 225128, "time": 7300.915512084961, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 225168, "time": 7302.341863632202, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 226176, "time": 7332.936973810196, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 226616, "time": 7346.041375875473, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 226648, "time": 7347.00502705574, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 226800, "time": 7351.824812889099, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 227000, "time": 7357.780270814896, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 227224, "time": 7364.502043008804, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 227440, "time": 7371.212593793869, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 227480, "time": 7372.229454994202, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 228488, "time": 7402.720922708511, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 228832, "time": 7413.346924066544, "episode/length": 253.0, "episode/score": 0.20937499403953552, "episode/reward_rate": 0.003937007874015748, "episode/intrinsic_return": 0.0}
{"step": 228928, "time": 7416.251291513443, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 228960, "time": 7417.302907705307, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 229312, "time": 7427.850828886032, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 229536, "time": 7435.038489341736, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 229752, "time": 7441.322727918625, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 229792, "time": 7442.7442445755005, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 230048, "time": 7453.166926145554, "eval_episode/length": 141.0, "eval_episode/score": 0.559374988079071, "eval_episode/reward_rate": 0.007042253521126761}
{"step": 230048, "time": 7455.3865485191345, "eval_episode/length": 122.0, "eval_episode/score": 0.6187499761581421, "eval_episode/reward_rate": 0.008130081300813009}
{"step": 230048, "time": 7455.81020450592, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7455.819113731384, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7455.828369617462, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7455.835560321808, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7455.843440294266, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7455.850608587265, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7455.858636856079, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230288, "time": 7463.095736503601, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 230800, "time": 7478.601334571838, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 231144, "time": 7488.708096027374, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 231240, "time": 7491.614476919174, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 231272, "time": 7492.582108259201, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 231624, "time": 7503.164833068848, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 231848, "time": 7509.960160255432, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 232104, "time": 7517.669892787933, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 232528, "time": 7530.680143594742, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 232600, "time": 7532.644634723663, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 233112, "time": 7548.133429288864, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 233456, "time": 7558.730934619904, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 233552, "time": 7561.628017425537, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 233584, "time": 7562.607007265091, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 233720, "time": 7566.588898181915, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 233832, "time": 7569.945950984955, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 234160, "time": 7580.064341783524, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 234416, "time": 7587.8205626010895, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 234840, "time": 7600.441347122192, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 235424, "time": 7618.34680223465, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 235760, "time": 7628.628434896469, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 235768, "time": 7628.657928466797, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 235864, "time": 7631.563561439514, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 236032, "time": 7636.88334107399, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 236144, "time": 7640.290855169296, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 236312, "time": 7645.206620931625, "episode/length": 20.0, "episode/score": 0.9375, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.0}
{"step": 236472, "time": 7650.080867290497, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 236728, "time": 7657.946056842804, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 237736, "time": 7689.195613145828, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 238072, "time": 7699.507983446121, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 238080, "time": 7699.985249996185, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 238176, "time": 7702.910069704056, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 238344, "time": 7707.797702074051, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 238624, "time": 7716.534136772156, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 238784, "time": 7721.522200584412, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 239040, "time": 7729.399883747101, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 240032, "time": 7765.449533462524, "eval_episode/length": 279.0, "eval_episode/score": 0.12812499701976776, "eval_episode/reward_rate": 0.0035714285714285713}
{"step": 240032, "time": 7765.628084182739, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7765.637608528137, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7765.647719144821, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7765.658479213715, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7765.66912817955, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7765.680459260941, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7765.692329406738, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240048, "time": 7766.182672739029, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 240280, "time": 7772.949937343597, "episode/length": 262.0, "episode/score": 0.18125000596046448, "episode/reward_rate": 0.0038022813688212928, "episode/intrinsic_return": 0.0}
{"step": 240384, "time": 7776.288199186325, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 240392, "time": 7776.316250085831, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 240656, "time": 7784.5975959300995, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 240936, "time": 7792.783286571503, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 241096, "time": 7797.577430009842, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 241352, "time": 7805.282831907272, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 241520, "time": 7810.644592761993, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 242360, "time": 7835.762080907822, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 242592, "time": 7843.062556505203, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 242696, "time": 7845.982050895691, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 242704, "time": 7846.44900226593, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 242968, "time": 7854.226461172104, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 243248, "time": 7862.918823719025, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 243664, "time": 7875.517526388168, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 243832, "time": 7880.365390062332, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 244672, "time": 7905.984184026718, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 244904, "time": 7912.734827756882, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 245008, "time": 7916.085577011108, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 245016, "time": 7916.114600658417, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 245280, "time": 7924.299273490906, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 245560, "time": 7932.59467959404, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 245976, "time": 7945.6126437187195, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 246144, "time": 7950.878407001495, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 246632, "time": 7965.457669973373, "episode/length": 202.0, "episode/score": 0.3687500059604645, "episode/reward_rate": 0.0049261083743842365, "episode/intrinsic_return": 0.0}
{"step": 246984, "time": 7976.052365064621, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 247216, "time": 7983.259184837341, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 247328, "time": 7986.761842489243, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 247592, "time": 7994.480667114258, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 247872, "time": 8003.207975387573, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 248288, "time": 8015.718386650085, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 248456, "time": 8020.663645982742, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 248944, "time": 8035.566107273102, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 249296, "time": 8046.205198287964, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 249528, "time": 8053.05983877182, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 249640, "time": 8056.437999486923, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 249904, "time": 8064.614331483841, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 250016, "time": 8069.796243190765, "eval_episode/length": 100.0, "eval_episode/score": 0.6875, "eval_episode/reward_rate": 0.009900990099009901}
{"step": 250016, "time": 8073.155574798584, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 8073.166906118393, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 8073.202248573303, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 8073.208743572235, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 8073.214985847473, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 8073.221132040024, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 8073.228602170944, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250064, "time": 8074.692795753479, "episode/length": 273.0, "episode/score": 0.14687499403953552, "episode/reward_rate": 0.0036496350364963502, "episode/intrinsic_return": 0.0}
{"step": 250600, "time": 8090.6575355529785, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 250768, "time": 8095.9237315654755, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 251256, "time": 8110.465400695801, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 251608, "time": 8121.029808521271, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 251840, "time": 8128.2385766506195, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 251952, "time": 8131.658613443375, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 252216, "time": 8139.438046455383, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 252376, "time": 8144.247411966324, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 252432, "time": 8146.172954320908, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 252912, "time": 8160.547613620758, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 253080, "time": 8165.409707784653, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 253512, "time": 8178.5831599235535, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 253920, "time": 8191.145386695862, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 254152, "time": 8198.417149543762, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 254264, "time": 8201.783829927444, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 254528, "time": 8209.956903219223, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 254688, "time": 8214.776729106903, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 255064, "time": 8225.905672073364, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 255224, "time": 8230.833843708038, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 255312, "time": 8233.715798854828, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 255392, "time": 8236.12134885788, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 256121, "time": 8258.99993801117, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.2566561393549875, "train/action_min": 0.0, "train/action_std": 1.8034571567779691, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0013037337989659907, "train/actor_opt_grad_steps": 14900.0, "train/actor_opt_loss": 0.000642439469768496, "train/adv_mag": 0.005201072968872897, "train/adv_max": 0.004893964055576935, "train/adv_mean": 0.0006599418303074506, "train/adv_min": -0.002436935883290662, "train/adv_std": 0.00098028681080403, "train/cont_avg": 0.9965940578817734, "train/cont_loss_mean": 0.0227828794296629, "train/cont_loss_std": 0.3169595629610079, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.665375264004023, "train/cont_pos_acc": 0.9999999841445772, "train/cont_pos_loss": 0.0035005430427145928, "train/cont_pred": 0.9965056730021397, "train/cont_rate": 0.9965940578817734, "train/dyn_loss_mean": 1.000003622670479, "train/dyn_loss_std": 0.0001158816149238075, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.054814963328269004, "train/extr_critic_critic_opt_grad_steps": 14900.0, "train/extr_critic_critic_opt_loss": 12631.784617456897, "train/extr_critic_mag": 0.05895140664330844, "train/extr_critic_max": 0.05895140664330844, "train/extr_critic_mean": 0.057254409463387994, "train/extr_critic_min": 0.05491058344911472, "train/extr_critic_std": 0.0005577599414420117, "train/extr_return_normed_mag": 0.007350274861739774, "train/extr_return_normed_max": 0.007275060057786885, "train/extr_return_normed_mean": 0.002965913279831735, "train/extr_return_normed_min": -5.6210740152838194e-05, "train/extr_return_normed_std": 0.0011100329731400652, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.062223474123501425, "train/extr_return_raw_max": 0.062223474123501425, "train/extr_return_raw_mean": 0.05791433050934904, "train/extr_return_raw_min": 0.054892203343912885, "train/extr_return_raw_std": 0.0011100329745737515, "train/extr_reward_mag": 0.0011337930933008054, "train/extr_reward_max": 0.0011337930933008054, "train/extr_reward_mean": 0.00026086961789305546, "train/extr_reward_min": 9.024671733085744e-06, "train/extr_reward_std": 0.0003095321973054291, "train/image_loss_mean": 0.1804839608264087, "train/image_loss_std": 0.10382393050223149, "train/model_loss_mean": 0.8051223047261168, "train/model_loss_std": 0.37279280245744534, "train/model_opt_grad_norm": 36.810791476019496, "train/model_opt_grad_steps": 14884.985221674877, "train/model_opt_loss": 1748.612437581781, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2179.8029556650245, "train/policy_entropy_mag": 1.8621399044403302, "train/policy_entropy_max": 1.8621399044403302, "train/policy_entropy_mean": 1.5006870301486237, "train/policy_entropy_min": 0.8059701507755102, "train/policy_entropy_std": 0.16795586251419753, "train/policy_logprob_mag": 5.533687490547819, "train/policy_logprob_max": -0.2619882318572017, "train/policy_logprob_mean": -1.500088619921595, "train/policy_logprob_min": -5.533687490547819, "train/policy_logprob_std": 0.7485040755107485, "train/policy_randomness_mag": 0.956950668043691, "train/policy_randomness_max": 0.956950668043691, "train/policy_randomness_mean": 0.7712006211427632, "train/policy_randomness_min": 0.4141867479557181, "train/policy_randomness_std": 0.08631224470589255, "train/post_ent_mag": 33.708982176381376, "train/post_ent_max": 33.708982176381376, "train/post_ent_mean": 33.37485464688005, "train/post_ent_min": 32.99898246238972, "train/post_ent_std": 0.12284325533018911, "train/prior_ent_mag": 37.65813515573887, "train/prior_ent_max": 37.65813515573887, "train/prior_ent_mean": 34.28834355171091, "train/prior_ent_min": 33.03139554103607, "train/prior_ent_std": 0.78735035848735, "train/rep_loss_mean": 1.000003622670479, "train/rep_loss_std": 0.0001158816149238075, "train/reward_avg": 8.355502391594183e-05, "train/reward_loss_mean": 0.0018532675888224188, "train/reward_loss_std": 0.05033038289010498, "train/reward_max_data": 0.08069581270511514, "train/reward_max_pred": 0.0009572828931761493, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00018997793942500648, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 8.597141530778673, "train/reward_pred": 7.884626464890729e-05, "train/reward_rate": 0.00019242610837438425, "train_stats/mean_log_entropy": 1.4973707810044288, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.02004619687795639, "report/cont_loss_std": 0.3073936700820923, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.690882682800293, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.003383606905117631, "report/cont_pred": 0.9966220259666443, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.1763678789138794, "report/image_loss_std": 0.12868478894233704, "report/model_loss_mean": 0.79659104347229, "report/model_loss_std": 0.3365907371044159, "report/post_ent_mag": 32.603492736816406, "report/post_ent_max": 32.603492736816406, "report/post_ent_mean": 32.40593719482422, "report/post_ent_min": 32.12175369262695, "report/post_ent_std": 0.07865957915782928, "report/prior_ent_mag": 35.86396789550781, "report/prior_ent_max": 35.86396789550781, "report/prior_ent_mean": 33.76091003417969, "report/prior_ent_min": 32.396522521972656, "report/prior_ent_std": 0.6705504059791565, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.000176925677806139, "report/reward_loss_std": 0.00041797946323640645, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.0008400678634643555, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.000176925677806139, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 7.261941209435463e-05, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.020046468824148178, "eval/cont_loss_std": 0.3073936402797699, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.690882682800293, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.003383878618478775, "eval/cont_pred": 0.9966217875480652, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.18160101771354675, "eval/image_loss_std": 0.10810092836618423, "eval/model_loss_mean": 0.8018079996109009, "eval/model_loss_std": 0.3286237418651581, "eval/post_ent_mag": 32.63800811767578, "eval/post_ent_max": 32.63800811767578, "eval/post_ent_mean": 32.404396057128906, "eval/post_ent_min": 32.121910095214844, "eval/post_ent_std": 0.08204327523708344, "eval/prior_ent_mag": 36.40370178222656, "eval/prior_ent_max": 36.40370178222656, "eval/prior_ent_mean": 33.679359436035156, "eval/prior_ent_min": 32.348060607910156, "eval/prior_ent_std": 0.6435514092445374, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00016047386452555656, "eval/reward_loss_std": 0.0003923224867321551, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0008713006973266602, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00016047386452555656, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 6.593181751668453e-05, "eval/reward_rate": 0.0, "replay/size": 255617.0, "replay/inserts": 32384.0, "replay/samples": 32384.0, "replay/insert_wait_avg": 1.3175232726123494e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.761426323487354e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 61168.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1526314582516714e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.98377799987793e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1667981147766, "timer/env.step_count": 4048.0, "timer/env.step_total": 38.43756580352783, "timer/env.step_frac": 0.038431155559231864, "timer/env.step_avg": 0.009495446097709444, "timer/env.step_min": 0.007706642150878906, "timer/env.step_max": 0.03646492958068848, "timer/replay._sample_count": 32384.0, "timer/replay._sample_total": 16.963813304901123, "timer/replay._sample_frac": 0.01696098424470435, "timer/replay._sample_avg": 0.0005238331677649803, "timer/replay._sample_min": 0.00036406517028808594, "timer/replay._sample_max": 0.03341960906982422, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4915.0, "timer/agent.policy_total": 51.796536684036255, "timer/agent.policy_frac": 0.05178789856018817, "timer/agent.policy_avg": 0.010538461176813074, "timer/agent.policy_min": 0.008807897567749023, "timer/agent.policy_max": 0.0786886215209961, "timer/dataset_train_count": 2024.0, "timer/dataset_train_total": 0.22311139106750488, "timer/dataset_train_frac": 0.0002230741827143728, "timer/dataset_train_avg": 0.00011023290072505182, "timer/dataset_train_min": 9.679794311523438e-05, "timer/dataset_train_max": 0.0005743503570556641, "timer/agent.train_count": 2024.0, "timer/agent.train_total": 896.4543025493622, "timer/agent.train_frac": 0.8963048005983572, "timer/agent.train_avg": 0.44291220481687854, "timer/agent.train_min": 0.4334697723388672, "timer/agent.train_max": 0.6615047454833984, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.46691155433654785, "timer/agent.report_frac": 0.0004668336873575824, "timer/agent.report_avg": 0.23345577716827393, "timer/agent.report_min": 0.22165727615356445, "timer/agent.report_max": 0.2452542781829834, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.1948089599609375e-05, "timer/dataset_eval_frac": 3.1942761607192534e-08, "timer/dataset_eval_avg": 3.1948089599609375e-05, "timer/dataset_eval_min": 3.1948089599609375e-05, "timer/dataset_eval_max": 3.1948089599609375e-05, "fps": 32.37805616249665}
{"step": 256232, "time": 8262.080893993378, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 256512, "time": 8270.736617565155, "episode/length": 280.0, "episode/score": 0.125, "episode/reward_rate": 0.0035587188612099642, "episode/intrinsic_return": 0.0}
{"step": 256840, "time": 8280.466428041458, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 257000, "time": 8285.314244031906, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 257248, "time": 8293.15284872055, "episode/length": 252.0, "episode/score": 0.21250000596046448, "episode/reward_rate": 0.003952569169960474, "episode/intrinsic_return": 0.0}
{"step": 257376, "time": 8297.074717760086, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 257624, "time": 8304.45511507988, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 257704, "time": 8306.879482746124, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 258528, "time": 8332.251027822495, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 258544, "time": 8332.74107503891, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 258824, "time": 8340.988951206207, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 259152, "time": 8351.187053442001, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 259312, "time": 8356.038969039917, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 259560, "time": 8363.35138463974, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 259688, "time": 8367.276624202728, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 259936, "time": 8375.052829742432, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 260000, "time": 8383.09734249115, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8383.107409000397, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8383.116423130035, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8383.1270236969, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8383.136272668839, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8383.147519111633, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8383.158326148987, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8383.171154022217, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260840, "time": 8409.036983013153, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 260856, "time": 8409.540842294693, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 261136, "time": 8418.341945886612, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 261464, "time": 8428.115393400192, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 261520, "time": 8430.023290395737, "episode/length": 197.0, "episode/score": 0.3843750059604645, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.0}
{"step": 261624, "time": 8432.953581571579, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 261720, "time": 8435.869574069977, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 261872, "time": 8440.766205787659, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 262000, "time": 8444.61520242691, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 262016, "time": 8445.103533744812, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 263152, "time": 8480.081189155579, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 263168, "time": 8480.570573329926, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 263448, "time": 8488.8206949234, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 263936, "time": 8503.904581069946, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 264032, "time": 8506.844363689423, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 264184, "time": 8511.234057664871, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 264312, "time": 8515.121448993683, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 264328, "time": 8515.609310150146, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 265184, "time": 8541.838732719421, "episode/length": 251.0, "episode/score": 0.21562500298023224, "episode/reward_rate": 0.003968253968253968, "episode/intrinsic_return": 0.0}
{"step": 265184, "time": 8541.855939865112, "episode/length": 216.0, "episode/score": 0.32499998807907104, "episode/reward_rate": 0.004608294930875576, "episode/intrinsic_return": 0.0}
{"step": 265464, "time": 8550.113384246826, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 266184, "time": 8571.94826221466, "episode/length": 231.0, "episode/score": 0.27812498807907104, "episode/reward_rate": 0.004310344827586207, "episode/intrinsic_return": 0.0}
{"step": 266248, "time": 8573.908820390701, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 266344, "time": 8576.80852484703, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 266496, "time": 8581.65258717537, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 266624, "time": 8585.525743961334, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 267496, "time": 8611.837173938751, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 267496, "time": 8611.858837127686, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 267776, "time": 8620.670471429825, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 267896, "time": 8624.084931850433, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 268192, "time": 8633.250156402588, "episode/length": 211.0, "episode/score": 0.34062498807907104, "episode/reward_rate": 0.0047169811320754715, "episode/intrinsic_return": 0.0}
{"step": 268496, "time": 8643.380205869675, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 268560, "time": 8645.325073003769, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 268656, "time": 8648.31591796875, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 269808, "time": 8683.302455663681, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 269808, "time": 8683.3428440094, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 269840, "time": 8684.31051659584, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 270088, "time": 8691.587736845016, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 270088, "time": 8693.866104364395, "eval_episode/length": 122.0, "eval_episode/score": 0.6187499761581421, "eval_episode/reward_rate": 0.008130081300813009}
{"step": 270088, "time": 8697.310046434402, "eval_episode/length": 158.0, "eval_episode/score": 0.5062500238418579, "eval_episode/reward_rate": 0.006289308176100629}
{"step": 270088, "time": 8697.441906690598, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "time": 8697.448364019394, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "time": 8697.453737020493, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "time": 8697.460016012192, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "time": 8697.46549129486, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "time": 8697.47094321251, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "time": 8697.476419448853, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270208, "time": 8701.328869104385, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 270504, "time": 8710.642399311066, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 270808, "time": 8719.851056575775, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 270872, "time": 8721.807136535645, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 272120, "time": 8759.834933042526, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 272120, "time": 8759.84846162796, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 272152, "time": 8760.824954032898, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 272400, "time": 8768.683334350586, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 272520, "time": 8772.10491514206, "episode/length": 251.0, "episode/score": 0.21562500298023224, "episode/reward_rate": 0.003968253968253968, "episode/intrinsic_return": 0.0}
{"step": 272520, "time": 8772.111780881882, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 273120, "time": 8790.60171699524, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 273184, "time": 8792.528302669525, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 274432, "time": 8830.449702978134, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 274432, "time": 8830.46301984787, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 274464, "time": 8831.434935569763, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 274712, "time": 8838.724940299988, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 274832, "time": 8842.600946426392, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 274832, "time": 8842.609588861465, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 275200, "time": 8853.732375383377, "episode/length": 259.0, "episode/score": 0.19062499701976776, "episode/reward_rate": 0.0038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 275496, "time": 8862.601313591003, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 275792, "time": 8871.762751817703, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 276632, "time": 8897.006853580475, "episode/length": 224.0, "episode/score": 0.30000001192092896, "episode/reward_rate": 0.0044444444444444444, "episode/intrinsic_return": 0.0}
{"step": 276744, "time": 8900.388086795807, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 276776, "time": 8901.385643720627, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 277024, "time": 8909.100512981415, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 277048, "time": 8909.610892772675, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 277144, "time": 8912.532487869263, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 277160, "time": 8913.018184185028, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 277512, "time": 8923.805437326431, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 277808, "time": 8933.052785873413, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 278200, "time": 8944.714849710464, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 278520, "time": 8954.48571896553, "episode/length": 235.0, "episode/score": 0.265625, "episode/reward_rate": 0.00423728813559322, "episode/intrinsic_return": 0.0}
{"step": 278888, "time": 8966.118970870972, "episode/length": 267.0, "episode/score": 0.16562500596046448, "episode/reward_rate": 0.0037313432835820895, "episode/intrinsic_return": 0.0}
{"step": 278896, "time": 8966.587748289108, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 279224, "time": 8976.262315750122, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 279360, "time": 8980.684636592865, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 279456, "time": 8983.584005117416, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 279472, "time": 8984.09513092041, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 280072, "time": 9005.034057855606, "eval_episode/length": 168.0, "eval_episode/score": 0.4749999940395355, "eval_episode/reward_rate": 0.005917159763313609}
{"step": 280072, "time": 9006.648263454437, "eval_episode/length": 246.0, "eval_episode/score": 0.23125000298023224, "eval_episode/reward_rate": 0.004048582995951417}
{"step": 280072, "time": 9006.716502189636, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 280072, "time": 9007.440847158432, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "time": 9007.450345993042, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "time": 9007.460130691528, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "time": 9007.470148086548, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "time": 9007.481403112411, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "time": 9007.492463350296, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280200, "time": 9011.375243902206, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 280512, "time": 9021.104692220688, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 280832, "time": 9030.81770324707, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 281200, "time": 9042.097054719925, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 281208, "time": 9042.125901937485, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 281232, "time": 9043.138556718826, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 281536, "time": 9052.32180094719, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 281656, "time": 9055.732164144516, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 281680, "time": 9056.679889440536, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 281768, "time": 9059.136620759964, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 281784, "time": 9059.632331371307, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 282048, "time": 9068.020326852798, "episode/length": 191.0, "episode/score": 0.40312498807907104, "episode/reward_rate": 0.005208333333333333, "episode/intrinsic_return": 0.0}
{"step": 282216, "time": 9072.924679517746, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 282240, "time": 9073.875672578812, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 282640, "time": 9085.979887962341, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 282840, "time": 9091.820813894272, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 283848, "time": 9122.419432640076, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 283856, "time": 9122.887892484665, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 283968, "time": 9126.279400587082, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 283992, "time": 9126.845809936523, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 284096, "time": 9130.191561698914, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 284360, "time": 9137.969395637512, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 284528, "time": 9143.311544418335, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 284608, "time": 9145.753776073456, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 284648, "time": 9146.7472615242, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 284672, "time": 9147.699109315872, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 284952, "time": 9155.997648477554, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 285008, "time": 9157.984650373459, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 285480, "time": 9172.055699825287, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 286168, "time": 9192.946406841278, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 286280, "time": 9196.413397550583, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 286368, "time": 9199.349145412445, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 286808, "time": 9213.020028352737, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 286840, "time": 9214.011790513992, "episode/length": 278.0, "episode/score": 0.13124999403953552, "episode/reward_rate": 0.0035842293906810036, "episode/intrinsic_return": 0.0}
{"step": 286960, "time": 9217.958572864532, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 286984, "time": 9218.472832679749, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 287264, "time": 9227.252131700516, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 287320, "time": 9228.778589010239, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 287376, "time": 9230.717940092087, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 287520, "time": 9235.088723659515, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 287792, "time": 9243.319042921066, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 288264, "time": 9257.472342014313, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 288297, "time": 9259.448256254196, "train_stats/mean_log_entropy": 1.1010238159058698, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.740709295320274, "train/action_min": 0.0, "train/action_std": 1.7209027341349208, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0019232766711169307, "train/actor_opt_grad_steps": 16920.0, "train/actor_opt_loss": 12.738343483550631, "train/adv_mag": 0.011538892113302477, "train/adv_max": 0.011376424548934349, "train/adv_mean": 0.00222392662282746, "train/adv_min": -0.0038201835988765924, "train/adv_std": 0.002106095700401961, "train/cont_avg": 0.996132618159204, "train/cont_loss_mean": 0.025378526535941595, "train/cont_loss_std": 0.34042725515602834, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.630400206912216, "train/cont_pos_acc": 0.9999999822075687, "train/cont_pos_loss": 0.003616338438210796, "train/cont_pred": 0.9963902739150015, "train/cont_rate": 0.996132618159204, "train/dyn_loss_mean": 1.0000161063018722, "train/dyn_loss_std": 0.0004813029414589577, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.13602493259654988, "train/extr_critic_critic_opt_grad_steps": 16920.0, "train/extr_critic_critic_opt_loss": 12054.039249553016, "train/extr_critic_mag": 0.10263988568415096, "train/extr_critic_max": 0.10263988568415096, "train/extr_critic_mean": 0.10009622470063356, "train/extr_critic_min": 0.09660820106961834, "train/extr_critic_std": 0.0010188659063751222, "train/extr_return_normed_mag": 0.01815193498609078, "train/extr_return_normed_max": 0.01815193498609078, "train/extr_return_normed_mean": 0.007928261123898796, "train/extr_return_normed_min": 0.0020958700991092036, "train/extr_return_normed_std": 0.0024120433630180817, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.11254382685790608, "train/extr_return_raw_max": 0.11254382685790608, "train/extr_return_raw_mean": 0.10232015802937361, "train/extr_return_raw_min": 0.0964877619709245, "train/extr_return_raw_std": 0.002412043349407335, "train/extr_reward_mag": 0.007146802707691097, "train/extr_reward_max": 0.007146802707691097, "train/extr_reward_mean": 0.0006195371188640372, "train/extr_reward_min": 9.673151803846976e-07, "train/extr_reward_std": 0.001428608169816249, "train/image_loss_mean": 0.1657038511180166, "train/image_loss_std": 0.1063622042759141, "train/model_loss_mean": 0.7933200849822505, "train/model_loss_std": 0.39837053388505433, "train/model_opt_grad_norm": 34.44655982534684, "train/model_opt_grad_steps": 16903.646766169153, "train/model_opt_loss": 2309.044875111746, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2910.4477611940297, "train/policy_entropy_mag": 1.7966749383442437, "train/policy_entropy_max": 1.7966749383442437, "train/policy_entropy_mean": 1.1130105095419718, "train/policy_entropy_min": 0.19642898833277214, "train/policy_entropy_std": 0.3272907107475385, "train/policy_logprob_mag": 6.180974146619958, "train/policy_logprob_max": -0.04148479727611168, "train/policy_logprob_mean": -1.1113887896288688, "train/policy_logprob_min": -6.180974146619958, "train/policy_logprob_std": 0.9457405850068846, "train/policy_randomness_mag": 0.9233083277199399, "train/policy_randomness_max": 0.9233083277199399, "train/policy_randomness_mean": 0.5719742902475803, "train/policy_randomness_min": 0.10094453731727837, "train/policy_randomness_std": 0.16819416323852776, "train/post_ent_mag": 31.78692458043644, "train/post_ent_max": 31.78692458043644, "train/post_ent_mean": 31.560136358536298, "train/post_ent_min": 31.373545879155248, "train/post_ent_std": 0.07185310699898212, "train/prior_ent_mag": 35.40057020045038, "train/prior_ent_max": 35.40057020045038, "train/prior_ent_mean": 32.386375664478514, "train/prior_ent_min": 31.171004565794078, "train/prior_ent_std": 0.5602364178320661, "train/rep_loss_mean": 1.0000161063018722, "train/rep_loss_std": 0.0004813029414589577, "train/reward_avg": 0.00012799163283235787, "train/reward_loss_mean": 0.00222802238390591, "train/reward_loss_std": 0.06068875758711188, "train/reward_max_data": 0.1187810943049578, "train/reward_max_pred": 0.0048012187824913516, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00025065108539408596, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 7.113419551115769, "train/reward_pred": 0.000101124621645098, "train/reward_rate": 0.00028179415422885574, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.031107034534215927, "report/cont_loss_std": 0.39449477195739746, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.662854194641113, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0034733384381979704, "report/cont_pred": 0.996532678604126, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.1511448323726654, "report/image_loss_std": 0.12139011174440384, "report/model_loss_mean": 0.7826471328735352, "report/model_loss_std": 0.41089728474617004, "report/post_ent_mag": 30.65372657775879, "report/post_ent_max": 30.65372657775879, "report/post_ent_mean": 30.461742401123047, "report/post_ent_min": 30.30734634399414, "report/post_ent_std": 0.060341622680425644, "report/prior_ent_mag": 33.423004150390625, "report/prior_ent_max": 33.423004150390625, "report/prior_ent_mean": 30.68740463256836, "report/prior_ent_min": 29.791213989257812, "report/prior_ent_std": 0.4003455936908722, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.00039532221853733063, "report/reward_loss_std": 0.0018467761110514402, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.011002182960510254, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00039532221853733063, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00015583401545882225, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.02006344497203827, "eval/cont_loss_std": 0.3061267137527466, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.667525291442871, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0034695323556661606, "eval/cont_pred": 0.9965365529060364, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.19612154364585876, "eval/image_loss_std": 0.10777991265058517, "eval/model_loss_mean": 0.8163869380950928, "eval/model_loss_std": 0.3238658905029297, "eval/post_ent_mag": 30.660728454589844, "eval/post_ent_max": 30.660728454589844, "eval/post_ent_mean": 30.445735931396484, "eval/post_ent_min": 30.287269592285156, "eval/post_ent_std": 0.06402374058961868, "eval/prior_ent_mag": 32.661956787109375, "eval/prior_ent_max": 32.661956787109375, "eval/prior_ent_mean": 30.7564640045166, "eval/prior_ent_min": 29.760364532470703, "eval/prior_ent_std": 0.402082234621048, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00020194146782159805, "eval/reward_loss_std": 0.0012407874455675483, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0073136091232299805, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00020194146782159805, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 7.958710193634033e-05, "eval/reward_rate": 0.0, "replay/size": 287793.0, "replay/inserts": 32176.0, "replay/samples": 32176.0, "replay/insert_wait_avg": 1.3359250386872143e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.594139128523285e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 68104.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1821244139709825e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.087784767150879e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.430921792984, "timer/env.step_count": 4022.0, "timer/env.step_total": 38.12433648109436, "timer/env.step_frac": 0.0381079149500572, "timer/env.step_avg": 0.009478949895846434, "timer/env.step_min": 0.007664918899536133, "timer/env.step_max": 0.04872703552246094, "timer/replay._sample_count": 32176.0, "timer/replay._sample_total": 16.846394538879395, "timer/replay._sample_frac": 0.016839138187259434, "timer/replay._sample_avg": 0.0005235701932769578, "timer/replay._sample_min": 0.0003731250762939453, "timer/replay._sample_max": 0.027674436569213867, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4889.0, "timer/agent.policy_total": 51.852604389190674, "timer/agent.policy_frac": 0.05183026959648531, "timer/agent.policy_avg": 0.010605973489300608, "timer/agent.policy_min": 0.008801698684692383, "timer/agent.policy_max": 0.08151483535766602, "timer/dataset_train_count": 2011.0, "timer/dataset_train_total": 0.21990108489990234, "timer/dataset_train_frac": 0.00021980636554675163, "timer/dataset_train_avg": 0.00010934912227742533, "timer/dataset_train_min": 9.512901306152344e-05, "timer/dataset_train_max": 0.0002110004425048828, "timer/agent.train_count": 2011.0, "timer/agent.train_total": 896.2680280208588, "timer/agent.train_frac": 0.895881972954771, "timer/agent.train_avg": 0.44568275883682684, "timer/agent.train_min": 0.43213677406311035, "timer/agent.train_max": 1.3495862483978271, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47116613388061523, "timer/agent.report_frac": 0.0004709631855802555, "timer/agent.report_avg": 0.23558306694030762, "timer/agent.report_min": 0.22474312782287598, "timer/agent.report_max": 0.24642300605773926, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9802322387695312e-05, "timer/dataset_eval_frac": 2.9789485449213467e-08, "timer/dataset_eval_avg": 2.9802322387695312e-05, "timer/dataset_eval_min": 2.9802322387695312e-05, "timer/dataset_eval_max": 2.9802322387695312e-05, "fps": 32.161592037642954}
{"step": 288344, "time": 9260.650404453278, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 288432, "time": 9263.596210718155, "episode/length": 202.0, "episode/score": 0.3687500059604645, "episode/reward_rate": 0.0049261083743842365, "episode/intrinsic_return": 0.0}
{"step": 288480, "time": 9265.080576181412, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 288640, "time": 9269.983336687088, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 288680, "time": 9270.980684280396, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 289152, "time": 9285.630918264389, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 289544, "time": 9297.294461488724, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 289632, "time": 9300.181759357452, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 289688, "time": 9301.653501033783, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 289776, "time": 9304.540346622467, "episode/length": 281.0, "episode/score": 0.12187500298023224, "episode/reward_rate": 0.0035460992907801418, "episode/intrinsic_return": 0.0}
{"step": 290056, "time": 9314.100787639618, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 290056, "time": 9315.842077970505, "eval_episode/length": 165.0, "eval_episode/score": 0.484375, "eval_episode/reward_rate": 0.006024096385542169}
{"step": 290056, "time": 9317.991834878922, "eval_episode/length": 285.0, "eval_episode/score": 0.109375, "eval_episode/reward_rate": 0.0034965034965034965}
{"step": 290056, "time": 9318.055552482605, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "time": 9318.061941623688, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "time": 9318.069743394852, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "time": 9318.07595539093, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "time": 9318.083222866058, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290744, "time": 9339.013816356659, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 290760, "time": 9339.507591247559, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 290792, "time": 9340.4826836586, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 290952, "time": 9345.359368562698, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 290992, "time": 9346.812886476517, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 291856, "time": 9373.016278982162, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 291944, "time": 9375.456890821457, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 291944, "time": 9375.465071439743, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 291952, "time": 9375.960021972656, "episode/length": 282.0, "episode/score": 0.11874999850988388, "episode/reward_rate": 0.0035335689045936395, "episode/intrinsic_return": 0.0}
{"step": 292088, "time": 9379.8926923275, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 292328, "time": 9387.191830158234, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 292384, "time": 9389.109440088272, "episode/length": 204.0, "episode/score": 0.36250001192092896, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.0}
{"step": 292704, "time": 9398.902977466583, "episode/length": 238.0, "episode/score": 0.2562499940395355, "episode/reward_rate": 0.0041841004184100415, "episode/intrinsic_return": 0.0}
{"step": 292864, "time": 9403.774396419525, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 293024, "time": 9408.649262428284, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 293072, "time": 9410.133803606033, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 293336, "time": 9417.89255452156, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 293552, "time": 9424.661680698395, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 293616, "time": 9426.699218273163, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 293688, "time": 9428.64619731903, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 293872, "time": 9434.44286108017, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 294256, "time": 9446.027372837067, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 294504, "time": 9453.266513586044, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 294696, "time": 9459.212762594223, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 294864, "time": 9464.51454782486, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 295016, "time": 9469.346223115921, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 295176, "time": 9474.158242225647, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 295176, "time": 9474.167392730713, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 295288, "time": 9477.53408575058, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 295496, "time": 9483.835946798325, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 295648, "time": 9488.82451581955, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 295664, "time": 9489.317101955414, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 295712, "time": 9490.764964342117, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 296000, "time": 9499.5398042202, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 296136, "time": 9503.422652244568, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 296184, "time": 9504.86862707138, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 296816, "time": 9524.298148870468, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 296880, "time": 9526.244592666626, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 296944, "time": 9528.220519542694, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 297336, "time": 9539.856862306595, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 297368, "time": 9540.83037185669, "episode/length": 214.0, "episode/score": 0.33125001192092896, "episode/reward_rate": 0.004651162790697674, "episode/intrinsic_return": 0.0}
{"step": 297600, "time": 9548.200926303864, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 297712, "time": 9551.648252248764, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 297824, "time": 9555.041875123978, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 297832, "time": 9555.069253444672, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 297976, "time": 9559.448568582535, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 298024, "time": 9560.910702943802, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 298360, "time": 9571.07620048523, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 298448, "time": 9573.9421043396, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 298560, "time": 9577.45463514328, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 298744, "time": 9582.81762599945, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0}
{"step": 298776, "time": 9583.791975021362, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 298800, "time": 9584.743781089783, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 299256, "time": 9598.324880361557, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 299328, "time": 9600.730688333511, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 299472, "time": 9605.092074155807, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 299480, "time": 9605.119268417358, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 299552, "time": 9607.588730812073, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 299912, "time": 9618.229009628296, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 300040, "time": 9623.188845872879, "eval_episode/length": 58.0, "eval_episode/score": 0.8187500238418579, "eval_episode/reward_rate": 0.01694915254237288}
{"step": 300040, "time": 9623.415851593018, "eval_episode/length": 70.0, "eval_episode/score": 0.78125, "eval_episode/reward_rate": 0.014084507042253521}
{"step": 300040, "time": 9623.895730733871, "eval_episode/length": 96.0, "eval_episode/score": 0.699999988079071, "eval_episode/reward_rate": 0.010309278350515464}
{"step": 300040, "time": 9624.27068734169, "eval_episode/length": 116.0, "eval_episode/score": 0.637499988079071, "eval_episode/reward_rate": 0.008547008547008548}
{"step": 300040, "time": 9624.853571414948, "eval_episode/length": 146.0, "eval_episode/score": 0.543749988079071, "eval_episode/reward_rate": 0.006802721088435374}
{"step": 300040, "time": 9625.551676750183, "eval_episode/length": 182.0, "eval_episode/score": 0.4312500059604645, "eval_episode/reward_rate": 0.00546448087431694}
{"step": 300040, "time": 9627.062529087067, "eval_episode/length": 116.0, "eval_episode/score": 0.637499988079071, "eval_episode/reward_rate": 0.008547008547008548}
{"step": 300040, "time": 9627.541677236557, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300040, "time": 9627.552502393723, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300104, "time": 9629.507911205292, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 300144, "time": 9630.96143078804, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 300232, "time": 9633.403098106384, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 300608, "time": 9645.136780023575, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 300672, "time": 9647.097400903702, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 300720, "time": 9648.58704662323, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 300760, "time": 9649.623430013657, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 300776, "time": 9650.12182188034, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 300920, "time": 9654.547843456268, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 301168, "time": 9662.393133163452, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 301568, "time": 9674.694719076157, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 301864, "time": 9683.40507888794, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 302424, "time": 9700.49680018425, "episode/length": 187.0, "episode/score": 0.4156250059604645, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.0}
{"step": 302496, "time": 9702.934901475906, "episode/length": 227.0, "episode/score": 0.2906250059604645, "episode/reward_rate": 0.0043859649122807015, "episode/intrinsic_return": 0.0}
{"step": 302544, "time": 9704.429918766022, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 302664, "time": 9707.892611980438, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 302920, "time": 9715.788131475449, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 302928, "time": 9716.256368398666, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 303072, "time": 9720.596701145172, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 303304, "time": 9727.874814033508, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 303480, "time": 9733.200216531754, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 303488, "time": 9733.666181325912, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 303880, "time": 9745.269688129425, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 304000, "time": 9749.110247373581, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 304272, "time": 9757.406723022461, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 304304, "time": 9758.373987674713, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 304456, "time": 9762.729837417603, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0}
{"step": 304504, "time": 9764.184584379196, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 304736, "time": 9771.404016494751, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 304920, "time": 9776.7490503788, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 305232, "time": 9786.455604076385, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 305240, "time": 9786.50645685196, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 305616, "time": 9798.18250155449, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 305656, "time": 9799.181031942368, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 306312, "time": 9819.241456270218, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 306536, "time": 9826.02148604393, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 306688, "time": 9830.848278522491, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 306768, "time": 9833.283913850784, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 306816, "time": 9834.738567113876, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 307136, "time": 9844.370189905167, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 307232, "time": 9847.383503437042, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 307544, "time": 9856.627544641495, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 307552, "time": 9857.10627746582, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 307928, "time": 9868.268528699875, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 307936, "time": 9868.737479686737, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 308200, "time": 9876.529192686081, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 308264, "time": 9878.476813554764, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 308584, "time": 9888.12304520607, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 308688, "time": 9891.511598348618, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 308888, "time": 9897.343994379044, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 309000, "time": 9900.730718135834, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 309128, "time": 9904.600842475891, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 309240, "time": 9908.028711557388, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 309448, "time": 9914.2977039814, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 309464, "time": 9914.785620450974, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 309544, "time": 9917.186251878738, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 309592, "time": 9918.646524429321, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 309624, "time": 9919.611536979675, "episode/length": 19.0, "episode/score": 0.940625011920929, "episode/reward_rate": 0.05, "episode/intrinsic_return": 0.0}
{"step": 309856, "time": 9926.827308893204, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 309864, "time": 9926.853942871094, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 309992, "time": 9930.725335121155, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 310024, "time": 9932.119420528412, "eval_episode/length": 21.0, "eval_episode/score": 0.934374988079071, "eval_episode/reward_rate": 0.045454545454545456}
{"step": 310024, "time": 9932.387476205826, "eval_episode/length": 36.0, "eval_episode/score": 0.887499988079071, "eval_episode/reward_rate": 0.02702702702702703}
{"step": 310024, "time": 9933.656619787216, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 310024, "time": 9933.77838087082, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 310024, "time": 9933.965072870255, "eval_episode/length": 89.0, "eval_episode/score": 0.721875011920929, "eval_episode/reward_rate": 0.011111111111111112}
{"step": 310024, "time": 9934.286286830902, "eval_episode/length": 107.0, "eval_episode/score": 0.6656249761581421, "eval_episode/reward_rate": 0.009259259259259259}
{"step": 310024, "time": 9934.37941122055, "eval_episode/length": 75.0, "eval_episode/score": 0.765625, "eval_episode/reward_rate": 0.013157894736842105}
{"step": 310024, "time": 9935.621273994446, "eval_episode/length": 87.0, "eval_episode/score": 0.7281249761581421, "eval_episode/reward_rate": 0.011363636363636364}
{"step": 310096, "time": 9938.123538017273, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 310176, "time": 9940.540002822876, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 310304, "time": 9944.4119181633, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 310552, "time": 9951.729625940323, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 310576, "time": 9952.674405574799, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 310592, "time": 9953.15971493721, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 310704, "time": 9956.548455953598, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 310808, "time": 9959.462208509445, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 311000, "time": 9965.321261405945, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 311184, "time": 9971.190655946732, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 311632, "time": 9985.263852596283, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 311664, "time": 9986.233278512955, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 311856, "time": 9992.031334161758, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 311896, "time": 9993.022009849548, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 311904, "time": 9993.492455720901, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 312592, "time": 10014.33973789215, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 312704, "time": 10017.71447467804, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 312832, "time": 10021.582749128342, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 312888, "time": 10023.05510354042, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 312904, "time": 10023.548267126083, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 313104, "time": 10029.960815668106, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 313168, "time": 10031.895351171494, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 313496, "time": 10041.598543167114, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 313944, "time": 10055.225833177567, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 313976, "time": 10056.215519189835, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 313984, "time": 10056.79738855362, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 314016, "time": 10057.781053304672, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 314096, "time": 10060.25009226799, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 314256, "time": 10065.075439691544, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 314624, "time": 10076.205720186234, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 314656, "time": 10077.17083311081, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 315016, "time": 10087.951846122742, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 315072, "time": 10089.867364645004, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 315136, "time": 10091.803525447845, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 315216, "time": 10094.25031876564, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 315648, "time": 10107.366260766983, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 315768, "time": 10110.758104085922, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 315856, "time": 10113.648345470428, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 315976, "time": 10117.114004611969, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 316240, "time": 10125.26930975914, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 316256, "time": 10125.764952659607, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 316408, "time": 10130.118160009384, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 316456, "time": 10131.585198879242, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 316568, "time": 10134.974056005478, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 317000, "time": 10148.08771276474, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 317136, "time": 10152.398786783218, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 317256, "time": 10155.796812534332, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 317280, "time": 10156.746360778809, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 317384, "time": 10159.689492464066, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 317808, "time": 10172.716054916382, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 317960, "time": 10177.158354520798, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 318016, "time": 10179.06105017662, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 318112, "time": 10181.974400520325, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 318120, "time": 10182.001375198364, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 318168, "time": 10183.443813562393, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 318312, "time": 10187.812732696533, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 318336, "time": 10188.774912118912, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 318784, "time": 10202.422110080719, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 318792, "time": 10202.44983625412, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 318832, "time": 10203.886638879776, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 318880, "time": 10205.336738824844, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 319000, "time": 10208.813926935196, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 319104, "time": 10212.189710855484, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 319312, "time": 10218.552434682846, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 319328, "time": 10219.040830850601, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 319584, "time": 10227.292323827744, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 319920, "time": 10237.50411105156, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 320008, "time": 10241.714393854141, "eval_episode/length": 94.0, "eval_episode/score": 0.706250011920929, "eval_episode/reward_rate": 0.010526315789473684}
{"step": 320008, "time": 10241.914404392242, "eval_episode/length": 104.0, "eval_episode/score": 0.675000011920929, "eval_episode/reward_rate": 0.009523809523809525}
{"step": 320008, "time": 10242.543197154999, "eval_episode/length": 139.0, "eval_episode/score": 0.565625011920929, "eval_episode/reward_rate": 0.007142857142857143}
{"step": 320008, "time": 10243.295999288559, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 320008, "time": 10245.03549528122, "eval_episode/length": 137.0, "eval_episode/score": 0.5718749761581421, "eval_episode/reward_rate": 0.007246376811594203}
{"step": 320008, "time": 10245.261141061783, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 320008, "time": 10245.267425775528, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 320008, "time": 10245.27443265915, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 320008, "time": 10245.280731201172, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 320008, "time": 10245.287940979004, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 320024, "time": 10245.774001121521, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 320120, "time": 10248.68681883812, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 320328, "time": 10254.952114343643, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 320400, "time": 10257.340188980103, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 320457, "time": 10259.822370052338, "train_stats/mean_log_entropy": 0.2902030796924634, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.3794349176966727, "train/action_min": 0.0, "train/action_std": 1.593952024754007, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0034693215585044996, "train/actor_opt_grad_steps": 18930.0, "train/actor_opt_loss": 18.472928812152784, "train/adv_mag": 0.03205511426154654, "train/adv_max": 0.03178112053159458, "train/adv_mean": 0.00760735552890466, "train/adv_min": -0.010953508428673245, "train/adv_std": 0.005600614035363073, "train/cont_avg": 0.996200637437811, "train/cont_loss_mean": 0.024515796501411877, "train/cont_loss_std": 0.32413072045784785, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.442378006610774, "train/cont_pos_acc": 0.9999999830971903, "train/cont_pos_loss": 0.003773344223114166, "train/cont_pred": 0.9962298994633689, "train/cont_rate": 0.996200637437811, "train/dyn_loss_mean": 1.0000223959263284, "train/dyn_loss_std": 0.0004235722072776094, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.4517146581274212, "train/extr_critic_critic_opt_grad_steps": 18930.0, "train/extr_critic_critic_opt_loss": 8304.135822656735, "train/extr_critic_mag": 0.2883182853015501, "train/extr_critic_max": 0.2883182853015501, "train/extr_critic_mean": 0.27834285447253515, "train/extr_critic_min": 0.26700852225668986, "train/extr_critic_std": 0.0038606608872920442, "train/extr_return_normed_mag": 0.05267041098715654, "train/extr_return_normed_max": 0.05267041098715654, "train/extr_return_normed_mean": 0.02325262589755454, "train/extr_return_normed_min": 0.004758835209542839, "train/extr_return_normed_std": 0.007311654632762816, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.3153679549545791, "train/extr_return_raw_max": 0.3153679549545791, "train/extr_return_raw_mean": 0.2859501831270569, "train/extr_return_raw_min": 0.2674563791769654, "train/extr_return_raw_std": 0.007311654657088405, "train/extr_reward_mag": 0.021588396670213388, "train/extr_reward_max": 0.021588396670213388, "train/extr_reward_mean": 0.0018110079763211607, "train/extr_reward_min": -3.188700225222763e-05, "train/extr_reward_std": 0.004197918411763616, "train/image_loss_mean": 0.14662888864824428, "train/image_loss_std": 0.10820473597120883, "train/model_loss_mean": 0.7746515161362454, "train/model_loss_std": 0.4038901919156165, "train/model_opt_grad_norm": 31.155671020052328, "train/model_opt_grad_steps": 18911.99502487562, "train/model_opt_loss": 2254.7872369111474, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2910.4477611940297, "train/policy_entropy_mag": 1.6391276210101682, "train/policy_entropy_max": 1.6391276210101682, "train/policy_entropy_mean": 0.3664966104042471, "train/policy_entropy_min": 0.06495108440592515, "train/policy_entropy_std": 0.3308347903970462, "train/policy_logprob_mag": 6.549194174619457, "train/policy_logprob_max": -0.00864924995497388, "train/policy_logprob_mean": -0.36596307573626885, "train/policy_logprob_min": -6.549194174619457, "train/policy_logprob_std": 0.8557203506948936, "train/policy_randomness_mag": 0.8423450153265426, "train/policy_randomness_max": 0.8423450153265426, "train/policy_randomness_mean": 0.18834201046335164, "train/policy_randomness_min": 0.0333782565312006, "train/policy_randomness_std": 0.1700154604455132, "train/post_ent_mag": 30.12551617978224, "train/post_ent_max": 30.12551617978224, "train/post_ent_mean": 29.91676820214115, "train/post_ent_min": 29.722237942823725, "train/post_ent_std": 0.06971277103791783, "train/prior_ent_mag": 31.71191620708105, "train/prior_ent_max": 31.71191620708105, "train/prior_ent_mean": 29.239193968511934, "train/prior_ent_min": 28.036047323426203, "train/prior_ent_std": 0.4412413985278476, "train/rep_loss_mean": 1.0000223959263284, "train/rep_loss_std": 0.0004235722072776094, "train/reward_avg": 0.0002824773841328451, "train/reward_loss_mean": 0.0034933703261154207, "train/reward_loss_std": 0.08676936841495705, "train/reward_max_data": 0.23726679047393562, "train/reward_max_pred": 0.013674330948597163, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.0004478425306032889, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 5.868960014411381, "train/reward_pred": 0.00020463263560364497, "train/reward_rate": 0.0005198616293532338, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.03418702632188797, "report/cont_loss_std": 0.3822573721408844, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 4.532137870788574, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.003227683249861002, "report/cont_pred": 0.9966858625411987, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.1693337857723236, "report/image_loss_std": 0.12096745520830154, "report/model_loss_mean": 0.8246743679046631, "report/model_loss_std": 0.677451491355896, "report/post_ent_mag": 29.749267578125, "report/post_ent_max": 29.749267578125, "report/post_ent_mean": 29.520729064941406, "report/post_ent_min": 29.310691833496094, "report/post_ent_std": 0.0799010768532753, "report/prior_ent_mag": 29.66632843017578, "report/prior_ent_max": 29.66632843017578, "report/prior_ent_mean": 27.86800765991211, "report/prior_ent_min": 26.902477264404297, "report/prior_ent_std": 0.35635173320770264, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0017852784367278218, "report/reward_loss_mean": 0.021153483539819717, "report/reward_loss_std": 0.3358106017112732, "report/reward_max_data": 0.8125, "report/reward_max_pred": 0.02329719066619873, "report/reward_neg_acc": 0.9999999403953552, "report/reward_neg_loss": 0.0003648477140814066, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 5.322255611419678, "report/reward_pred": 0.00023950566537678242, "report/reward_rate": 0.00390625, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.03222314268350601, "eval/cont_loss_std": 0.41352853178977966, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.930093765258789, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0032836419995874166, "eval/cont_pred": 0.9967260956764221, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.21544089913368225, "eval/image_loss_std": 0.12644752860069275, "eval/model_loss_mean": 0.8477822542190552, "eval/model_loss_std": 0.4360624849796295, "eval/post_ent_mag": 29.75872802734375, "eval/post_ent_max": 29.75872802734375, "eval/post_ent_mean": 29.519420623779297, "eval/post_ent_min": 29.245214462280273, "eval/post_ent_std": 0.07644744217395782, "eval/prior_ent_mag": 29.732084274291992, "eval/prior_ent_max": 29.732084274291992, "eval/prior_ent_mean": 27.855457305908203, "eval/prior_ent_min": 26.759899139404297, "eval/prior_ent_std": 0.376730352640152, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0001181471161544323, "eval/reward_loss_std": 0.00047521202941425145, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.002309441566467285, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0001181471161544323, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 5.50377881154418e-05, "eval/reward_rate": 0.0, "replay/size": 319953.0, "replay/inserts": 32160.0, "replay/samples": 32160.0, "replay/insert_wait_avg": 1.3046300233300052e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.734749324286162e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 76464.0, "eval_replay/inserts": 8360.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1569575259560034e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0281801223754883e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3542313575745, "timer/env.step_count": 4020.0, "timer/env.step_total": 38.407180309295654, "timer/env.step_frac": 0.03839358009929494, "timer/env.step_avg": 0.009554024952561108, "timer/env.step_min": 0.007710933685302734, "timer/env.step_max": 0.035846710205078125, "timer/replay._sample_count": 32160.0, "timer/replay._sample_total": 16.798324584960938, "timer/replay._sample_frac": 0.016792376198743155, "timer/replay._sample_avg": 0.0005223359634627157, "timer/replay._sample_min": 0.00040411949157714844, "timer/replay._sample_max": 0.028182268142700195, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5065.0, "timer/agent.policy_total": 53.24551773071289, "timer/agent.policy_frac": 0.053226663177556345, "timer/agent.policy_avg": 0.010512441802707382, "timer/agent.policy_min": 0.008455991744995117, "timer/agent.policy_max": 0.08162617683410645, "timer/dataset_train_count": 2010.0, "timer/dataset_train_total": 0.2195453643798828, "timer/dataset_train_frac": 0.00021946762206617469, "timer/dataset_train_avg": 0.00010922654944272777, "timer/dataset_train_min": 9.608268737792969e-05, "timer/dataset_train_max": 0.0005464553833007812, "timer/agent.train_count": 2010.0, "timer/agent.train_total": 893.568069934845, "timer/agent.train_frac": 0.8932516521894343, "timer/agent.train_avg": 0.44456122882330595, "timer/agent.train_min": 0.4320988655090332, "timer/agent.train_max": 0.6994235515594482, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4781370162963867, "timer/agent.report_frac": 0.00047796770514731563, "timer/agent.report_avg": 0.23906850814819336, "timer/agent.report_min": 0.23222088813781738, "timer/agent.report_max": 0.24591612815856934, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.838539123535156e-05, "timer/dataset_eval_frac": 3.837179874099097e-08, "timer/dataset_eval_avg": 3.838539123535156e-05, "timer/dataset_eval_min": 3.838539123535156e-05, "timer/dataset_eval_max": 3.838539123535156e-05, "fps": 32.148045082166576}
{"step": 320600, "time": 10263.900201797485, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 321144, "time": 10280.455689191818, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 321248, "time": 10283.807936906815, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 321264, "time": 10284.293908834457, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 321320, "time": 10285.767612218857, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 321416, "time": 10288.665618896484, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 321608, "time": 10294.42895102501, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 321624, "time": 10294.91911149025, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 322072, "time": 10308.520340681076, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 322320, "time": 10316.285324811935, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 322368, "time": 10317.751745462418, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 322640, "time": 10326.058571100235, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 322640, "time": 10326.077008724213, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 322912, "time": 10334.443907260895, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 323000, "time": 10336.939539909363, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 323040, "time": 10338.37053847313, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 323200, "time": 10343.237418413162, "episode/length": 196.0, "episode/score": 0.38749998807907104, "episode/reward_rate": 0.005076142131979695, "episode/intrinsic_return": 0.0}
{"step": 323480, "time": 10351.498068094254, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 323632, "time": 10356.325412034988, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 323728, "time": 10359.311928033829, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 323920, "time": 10365.109680652618, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 324024, "time": 10368.058118581772, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 324384, "time": 10379.144690275192, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 324536, "time": 10383.519617795944, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 324680, "time": 10387.977915763855, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 325312, "time": 10407.316770792007, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 325352, "time": 10408.312448263168, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 325792, "time": 10421.928740739822, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 326232, "time": 10434.970319986343, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 326336, "time": 10438.323038816452, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 326640, "time": 10447.559478759766, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 326696, "time": 10449.047285079956, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 326808, "time": 10452.417129278183, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 326848, "time": 10453.872459888458, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 326992, "time": 10458.304708480835, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 326992, "time": 10458.312205553055, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 327208, "time": 10464.70098233223, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 327624, "time": 10477.499547719955, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 328104, "time": 10492.541333675385, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 328112, "time": 10493.030916690826, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 328288, "time": 10498.327783346176, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 328392, "time": 10501.227529764175, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 328464, "time": 10503.649832725525, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 328512, "time": 10505.109817743301, "episode/length": 226.0, "episode/score": 0.29374998807907104, "episode/reward_rate": 0.004405286343612335, "episode/intrinsic_return": 0.0}
{"step": 328600, "time": 10507.624010324478, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 329160, "time": 10524.52586197853, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 329224, "time": 10526.466210842133, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 329248, "time": 10527.431772708893, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 329304, "time": 10528.900143623352, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 329312, "time": 10529.367283821106, "episode/length": 18.0, "episode/score": 0.9437500238418579, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.0}
{"step": 330088, "time": 10552.660311222076, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 330096, "time": 10554.938118219376, "eval_episode/length": 97.0, "eval_episode/score": 0.6968749761581421, "eval_episode/reward_rate": 0.01020408163265306}
{"step": 330096, "time": 10555.089188098907, "eval_episode/length": 105.0, "eval_episode/score": 0.671875, "eval_episode/reward_rate": 0.009433962264150943}
{"step": 330096, "time": 10555.602060079575, "eval_episode/length": 134.0, "eval_episode/score": 0.581250011920929, "eval_episode/reward_rate": 0.007407407407407408}
{"step": 330096, "time": 10555.940878391266, "eval_episode/length": 153.0, "eval_episode/score": 0.5218750238418579, "eval_episode/reward_rate": 0.006493506493506494}
{"step": 330096, "time": 10556.086658239365, "eval_episode/length": 161.0, "eval_episode/score": 0.49687498807907104, "eval_episode/reward_rate": 0.006172839506172839}
{"step": 330096, "time": 10556.914647817612, "eval_episode/length": 208.0, "eval_episode/score": 0.3499999940395355, "eval_episode/reward_rate": 0.004784688995215311}
{"step": 330096, "time": 10557.480217456818, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 330096, "time": 10557.805774450302, "eval_episode/length": 258.0, "eval_episode/score": 0.19374999403953552, "eval_episode/reward_rate": 0.003861003861003861}
{"step": 330152, "time": 10559.263860702515, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 330320, "time": 10564.523553848267, "episode/length": 231.0, "episode/score": 0.27812498807907104, "episode/reward_rate": 0.004310344827586207, "episode/intrinsic_return": 0.0}
{"step": 330416, "time": 10567.515741825104, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 330704, "time": 10576.17349076271, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 330728, "time": 10576.680421352386, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 330744, "time": 10577.16493010521, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 330832, "time": 10580.070965766907, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 330896, "time": 10581.997144937515, "episode/length": 286.0, "episode/score": 0.10625000298023224, "episode/reward_rate": 0.003484320557491289, "episode/intrinsic_return": 0.0}
{"step": 330968, "time": 10583.943056583405, "episode/length": 8.0, "episode/score": 0.9750000238418579, "episode/reward_rate": 0.1111111111111111, "episode/intrinsic_return": 0.0}
{"step": 331176, "time": 10590.212146759033, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 331416, "time": 10597.590736627579, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 331440, "time": 10598.553861618042, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 331560, "time": 10601.95823431015, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 332096, "time": 10618.275480270386, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 332120, "time": 10618.800317525864, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 332144, "time": 10619.742495536804, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 332728, "time": 10637.259627103806, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 332880, "time": 10642.099340200424, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 332928, "time": 10643.575345993042, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 333040, "time": 10646.961248874664, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 333184, "time": 10651.324100971222, "episode/length": 202.0, "episode/score": 0.3687500059604645, "episode/reward_rate": 0.0049261083743842365, "episode/intrinsic_return": 0.0}
{"step": 333272, "time": 10653.79085612297, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 333280, "time": 10654.261759519577, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 333320, "time": 10655.260205745697, "episode/length": 234.0, "episode/score": 0.26875001192092896, "episode/reward_rate": 0.00425531914893617, "episode/intrinsic_return": 0.0}
{"step": 333696, "time": 10666.946741580963, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 333784, "time": 10669.401205062866, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 333824, "time": 10670.83030128479, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 334520, "time": 10691.765820264816, "episode/length": 198.0, "episode/score": 0.3812499940395355, "episode/reward_rate": 0.005025125628140704, "episode/intrinsic_return": 0.0}
{"step": 334864, "time": 10702.456865310669, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 334992, "time": 10706.33990764618, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 335040, "time": 10707.785098314285, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 335192, "time": 10712.191772222519, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 335592, "time": 10724.382488250732, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 335632, "time": 10725.842844247818, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 335952, "time": 10736.081149101257, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 336136, "time": 10741.433255195618, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 336264, "time": 10745.300585269928, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 336272, "time": 10745.788487911224, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 336584, "time": 10755.044222354889, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 337024, "time": 10768.600570440292, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 337176, "time": 10772.986026287079, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 337304, "time": 10776.960516691208, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 337352, "time": 10778.406661987305, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 337456, "time": 10781.802038192749, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 337904, "time": 10795.290128231049, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 337928, "time": 10795.796600103378, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 338264, "time": 10805.92344379425, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 338488, "time": 10812.771032333374, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 338896, "time": 10825.360594511032, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 339488, "time": 10843.30426311493, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 339616, "time": 10847.135623693466, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 339664, "time": 10848.623132944107, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 339768, "time": 10851.560072183609, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 340080, "time": 10864.232944726944, "eval_episode/length": 165.0, "eval_episode/score": 0.484375, "eval_episode/reward_rate": 0.006024096385542169}
{"step": 340080, "time": 10866.645824432373, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340080, "time": 10866.653407335281, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340080, "time": 10866.659087896347, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340080, "time": 10866.665747404099, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340080, "time": 10866.671895980835, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340080, "time": 10866.677408456802, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340080, "time": 10866.683737277985, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340216, "time": 10870.61188173294, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 340240, "time": 10871.569755792618, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 340800, "time": 10888.655122995377, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 341208, "time": 10900.942729473114, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 341800, "time": 10918.82601428032, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 341928, "time": 10922.742083072662, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 341976, "time": 10924.192249059677, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 342080, "time": 10927.696937322617, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 342528, "time": 10941.281995534897, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 342552, "time": 10941.794382810593, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 343112, "time": 10958.772376537323, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 343520, "time": 10971.395852088928, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 344112, "time": 10989.877445936203, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 344240, "time": 10993.728437900543, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 344288, "time": 10995.227602481842, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 344392, "time": 10998.167808055878, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 344472, "time": 11000.621257781982, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 344840, "time": 11011.764360666275, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 344864, "time": 11012.716291427612, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 345008, "time": 11017.156552314758, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 345104, "time": 11020.059449672699, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 345424, "time": 11029.696112155914, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 345832, "time": 11041.785679340363, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 346144, "time": 11051.518986701965, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 346424, "time": 11059.804691553116, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 346784, "time": 11070.898078918457, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 346832, "time": 11072.362424850464, "episode/length": 245.0, "episode/score": 0.234375, "episode/reward_rate": 0.0040650406504065045, "episode/intrinsic_return": 0.0}
{"step": 347152, "time": 11082.109853029251, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 347416, "time": 11090.941673517227, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 347576, "time": 11095.800990581512, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 347736, "time": 11100.664682388306, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 347752, "time": 11101.15721654892, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 347768, "time": 11101.648808479309, "episode/length": 241.0, "episode/score": 0.24687500298023224, "episode/reward_rate": 0.004132231404958678, "episode/intrinsic_return": 0.0}
{"step": 347808, "time": 11103.101883888245, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 347920, "time": 11106.551866292953, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0}
{"step": 348032, "time": 11109.967281341553, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 348056, "time": 11110.47618484497, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 348080, "time": 11111.42673277855, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 348536, "time": 11124.97177696228, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 348552, "time": 11125.462637424469, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 348592, "time": 11126.908339738846, "episode/length": 225.0, "episode/score": 0.296875, "episode/reward_rate": 0.004424778761061947, "episode/intrinsic_return": 0.0}
{"step": 348976, "time": 11138.532946109772, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 349208, "time": 11145.306859254837, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 349384, "time": 11150.6274766922, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 349512, "time": 11154.503269433975, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 349608, "time": 11157.410252571106, "episode/length": 196.0, "episode/score": 0.38749998807907104, "episode/reward_rate": 0.005076142131979695, "episode/intrinsic_return": 0.0}
{"step": 349776, "time": 11162.695729255676, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 349944, "time": 11167.654421329498, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 350064, "time": 11171.525518417358, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 350064, "time": 11172.532142162323, "eval_episode/length": 55.0, "eval_episode/score": 0.828125, "eval_episode/reward_rate": 0.017857142857142856}
{"step": 350064, "time": 11174.182847738266, "eval_episode/length": 111.0, "eval_episode/score": 0.653124988079071, "eval_episode/reward_rate": 0.008928571428571428}
{"step": 350064, "time": 11174.47472333908, "eval_episode/length": 126.0, "eval_episode/score": 0.606249988079071, "eval_episode/reward_rate": 0.007874015748031496}
{"step": 350064, "time": 11174.610211610794, "eval_episode/length": 133.0, "eval_episode/score": 0.5843750238418579, "eval_episode/reward_rate": 0.007462686567164179}
{"step": 350064, "time": 11175.063404798508, "eval_episode/length": 157.0, "eval_episode/score": 0.5093749761581421, "eval_episode/reward_rate": 0.006329113924050633}
{"step": 350064, "time": 11175.25383234024, "eval_episode/length": 167.0, "eval_episode/score": 0.4781250059604645, "eval_episode/reward_rate": 0.005952380952380952}
{"step": 350064, "time": 11175.388706922531, "eval_episode/length": 174.0, "eval_episode/score": 0.45625001192092896, "eval_episode/reward_rate": 0.005714285714285714}
{"step": 350064, "time": 11176.05897450447, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 350104, "time": 11177.050283432007, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 350240, "time": 11181.405040740967, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 350368, "time": 11185.31194782257, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 350496, "time": 11189.236207962036, "episode/length": 242.0, "episode/score": 0.24375000596046448, "episode/reward_rate": 0.00411522633744856, "episode/intrinsic_return": 0.0}
{"step": 350768, "time": 11197.552664756775, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 351328, "time": 11214.487651109695, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 351576, "time": 11221.757549762726, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 351824, "time": 11229.592431306839, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 352088, "time": 11237.32988357544, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 352192, "time": 11240.727615594864, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 352376, "time": 11246.550845384598, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 352376, "time": 11246.570099830627, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 352416, "time": 11248.006007909775, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 352793, "time": 11260.222169876099, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.459972117206838, "train/action_min": 0.0, "train/action_std": 1.5383047051358931, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.008647394589019367, "train/actor_opt_grad_steps": 20945.0, "train/actor_opt_loss": 9.958238101057193, "train/adv_mag": 0.27106800808174775, "train/adv_max": 0.18730467882486854, "train/adv_mean": 0.010854664486302708, "train/adv_min": -0.17299993070635464, "train/adv_std": 0.023168215144305757, "train/cont_avg": 0.9962581219059405, "train/cont_loss_mean": 0.022628287397472576, "train/cont_loss_std": 0.30441379643939803, "train/cont_neg_acc": 0.003938640231516824, "train/cont_neg_loss": 5.011261669557486, "train/cont_pos_acc": 0.9999902835576842, "train/cont_pos_loss": 0.003958427455589765, "train/cont_pred": 0.996013332121443, "train/cont_rate": 0.9962581219059405, "train/dyn_loss_mean": 1.000015123055713, "train/dyn_loss_std": 0.0004784974153693892, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0922205583976194, "train/extr_critic_critic_opt_grad_steps": 20945.0, "train/extr_critic_critic_opt_loss": 11615.17282013846, "train/extr_critic_mag": 0.6172806833050039, "train/extr_critic_max": 0.6172806833050039, "train/extr_critic_mean": 0.6016025107980955, "train/extr_critic_min": 0.5740095878591632, "train/extr_critic_std": 0.008606538783970961, "train/extr_return_normed_mag": 0.2897472436180209, "train/extr_return_normed_max": 0.22841860029366937, "train/extr_return_normed_mean": 0.04276110351663129, "train/extr_return_normed_min": -0.13642325776048225, "train/extr_return_normed_std": 0.02555384447263314, "train/extr_return_rate": 0.7668284772173299, "train/extr_return_raw_mag": 0.7981146733359535, "train/extr_return_raw_max": 0.7981146733359535, "train/extr_return_raw_mean": 0.6124572063436603, "train/extr_return_raw_min": 0.4332728152818019, "train/extr_return_raw_std": 0.02555384468702175, "train/extr_reward_mag": 0.19384167985160752, "train/extr_reward_max": 0.19384167985160752, "train/extr_reward_mean": 0.0032416020072956273, "train/extr_reward_min": 2.213043741660543e-07, "train/extr_reward_std": 0.012203444908015743, "train/image_loss_mean": 0.12805252418954774, "train/image_loss_std": 0.10681360919434245, "train/model_loss_mean": 0.7555403682855096, "train/model_loss_std": 0.3953774089344067, "train/model_opt_grad_norm": 30.552619513898794, "train/model_opt_grad_steps": 20925.346534653465, "train/model_opt_loss": 2268.9418087194463, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3007.4257425742576, "train/policy_entropy_mag": 1.4779664248523146, "train/policy_entropy_max": 1.4779664248523146, "train/policy_entropy_mean": 0.20082676613537392, "train/policy_entropy_min": 0.06469696494612363, "train/policy_entropy_std": 0.23546920805284294, "train/policy_logprob_mag": 6.551030836483039, "train/policy_logprob_max": -0.008609938628897808, "train/policy_logprob_mean": -0.20048234497409056, "train/policy_logprob_min": -6.551030836483039, "train/policy_logprob_std": 0.7319709478628518, "train/policy_randomness_mag": 0.759524539850726, "train/policy_randomness_max": 0.759524539850726, "train/policy_randomness_mean": 0.1032045486355477, "train/policy_randomness_min": 0.033247665050301224, "train/policy_randomness_std": 0.12100724263651537, "train/post_ent_mag": 28.55067313543641, "train/post_ent_max": 28.55067313543641, "train/post_ent_mean": 28.339558252013557, "train/post_ent_min": 28.12444536756761, "train/post_ent_std": 0.07589893858179007, "train/prior_ent_mag": 29.282439316853438, "train/prior_ent_max": 29.282439316853438, "train/prior_ent_mean": 27.293136549468088, "train/prior_ent_min": 26.004921318280815, "train/prior_ent_std": 0.41491745338581576, "train/rep_loss_mean": 1.000015123055713, "train/rep_loss_std": 0.0004784974153693892, "train/reward_avg": 0.0005416265814328833, "train/reward_loss_mean": 0.00485045996628296, "train/reward_loss_std": 0.10795150693139467, "train/reward_max_data": 0.41132425782409043, "train/reward_max_pred": 0.04691773062885398, "train/reward_neg_acc": 0.9999564467090192, "train/reward_neg_loss": 0.0008322975866549584, "train/reward_pos_acc": 0.05225988717402442, "train/reward_pos_loss": 4.944210488917464, "train/reward_pred": 0.0004217215262740703, "train/reward_rate": 0.0008170250618811881, "train_stats/mean_log_entropy": 0.1674297814627728, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.020277157425880432, "report/cont_loss_std": 0.2563897967338562, "report/cont_neg_acc": 0.20000000298023224, "report/cont_neg_loss": 3.199418306350708, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.004677837248891592, "report/cont_pred": 0.9944940805435181, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.11205963790416718, "report/image_loss_std": 0.11044039577245712, "report/model_loss_mean": 0.7435712814331055, "report/model_loss_std": 0.4677604138851166, "report/post_ent_mag": 28.59079360961914, "report/post_ent_max": 28.59079360961914, "report/post_ent_mean": 28.33687973022461, "report/post_ent_min": 28.08024024963379, "report/post_ent_std": 0.08261328935623169, "report/prior_ent_mag": 28.777851104736328, "report/prior_ent_max": 28.777851104736328, "report/prior_ent_mean": 27.09244155883789, "report/prior_ent_min": 26.068126678466797, "report/prior_ent_std": 0.3448294699192047, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0013214112259447575, "report/reward_loss_mean": 0.011234492063522339, "report/reward_loss_std": 0.23588493466377258, "report/reward_max_data": 0.815625011920929, "report/reward_max_pred": 0.03667712211608887, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.000829750788398087, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 5.328057289123535, "report/reward_pred": 0.00041931704618036747, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 0.010642437264323235, "eval/cont_loss_std": 0.19684669375419617, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.302614212036133, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.004491926170885563, "eval/cont_pred": 0.9955450296401978, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.22010540962219238, "eval/image_loss_std": 0.1471065729856491, "eval/model_loss_mean": 0.8307626247406006, "eval/model_loss_std": 0.2434605211019516, "eval/post_ent_mag": 28.5589599609375, "eval/post_ent_max": 28.5589599609375, "eval/post_ent_mean": 28.312963485717773, "eval/post_ent_min": 28.113147735595703, "eval/post_ent_std": 0.07547158002853394, "eval/prior_ent_mag": 28.235301971435547, "eval/prior_ent_max": 28.235301971435547, "eval/prior_ent_mean": 27.018901824951172, "eval/prior_ent_min": 25.90041732788086, "eval/prior_ent_std": 0.33545351028442383, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 1.4771241694688797e-05, "eval/reward_loss_std": 0.0001289183710468933, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0014556646347045898, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 1.4771241694688797e-05, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 7.128226570785046e-06, "eval/reward_rate": 0.0, "replay/size": 352289.0, "replay/inserts": 32336.0, "replay/samples": 32336.0, "replay/insert_wait_avg": 1.306487510016742e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.630360311237318e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 82544.0, "eval_replay/inserts": 6080.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1120187608819258e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1622905731201172e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3825669288635, "timer/env.step_count": 4042.0, "timer/env.step_total": 38.30822157859802, "timer/env.step_frac": 0.03829357172446818, "timer/env.step_avg": 0.0094775412119243, "timer/env.step_min": 0.0077669620513916016, "timer/env.step_max": 0.03578543663024902, "timer/replay._sample_count": 32336.0, "timer/replay._sample_total": 16.78071403503418, "timer/replay._sample_frac": 0.016774296743845042, "timer/replay._sample_avg": 0.0005189483558583059, "timer/replay._sample_min": 0.0003695487976074219, "timer/replay._sample_max": 0.011218547821044922, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4802.0, "timer/agent.policy_total": 50.5649037361145, "timer/agent.policy_frac": 0.0505455666739044, "timer/agent.policy_avg": 0.010529967458582779, "timer/agent.policy_min": 0.008772134780883789, "timer/agent.policy_max": 0.09254121780395508, "timer/dataset_train_count": 2021.0, "timer/dataset_train_total": 0.22046518325805664, "timer/dataset_train_frac": 0.00022038087282435996, "timer/dataset_train_avg": 0.00010908717627810818, "timer/dataset_train_min": 9.632110595703125e-05, "timer/dataset_train_max": 0.0009999275207519531, "timer/agent.train_count": 2021.0, "timer/agent.train_total": 898.7620632648468, "timer/agent.train_frac": 0.898418358112749, "timer/agent.train_avg": 0.4447115602498005, "timer/agent.train_min": 0.4328925609588623, "timer/agent.train_max": 1.5151472091674805, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4654362201690674, "timer/agent.report_frac": 0.00046525822775774563, "timer/agent.report_avg": 0.2327181100845337, "timer/agent.report_min": 0.22262096405029297, "timer/agent.report_max": 0.24281525611877441, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.4809112548828125e-05, "timer/dataset_eval_frac": 3.479580082616871e-08, "timer/dataset_eval_avg": 3.4809112548828125e-05, "timer/dataset_eval_min": 3.4809112548828125e-05, "timer/dataset_eval_max": 3.4809112548828125e-05, "fps": 32.32313747966574}
{"step": 352808, "time": 11260.273938894272, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 353080, "time": 11268.92074084282, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 353640, "time": 11285.83955836296, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 353880, "time": 11293.205413103104, "episode/length": 223.0, "episode/score": 0.3031249940395355, "episode/reward_rate": 0.004464285714285714, "episode/intrinsic_return": 0.0}
{"step": 353992, "time": 11296.614263296127, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 354128, "time": 11300.994242191315, "episode/length": 213.0, "episode/score": 0.3343749940395355, "episode/reward_rate": 0.004672897196261682, "episode/intrinsic_return": 0.0}
{"step": 354344, "time": 11307.379277706146, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 354464, "time": 11311.23205947876, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 354504, "time": 11312.22262430191, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 354640, "time": 11316.677195072174, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 354688, "time": 11318.15218782425, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 354688, "time": 11318.15955710411, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 355232, "time": 11334.580606460571, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 355336, "time": 11337.508511304855, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 355392, "time": 11339.418452501297, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 355488, "time": 11342.318839788437, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 355536, "time": 11343.767907381058, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 355944, "time": 11356.028530359268, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 355952, "time": 11356.517996549606, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 356192, "time": 11363.792422056198, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 356256, "time": 11365.73590683937, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 356568, "time": 11374.97849559784, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 356608, "time": 11376.434445619583, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 356656, "time": 11377.959695577621, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 356680, "time": 11378.46632862091, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 356680, "time": 11378.47564458847, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 356792, "time": 11381.882209539413, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 357360, "time": 11399.247474431992, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 357688, "time": 11409.005350351334, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 357704, "time": 11409.49087882042, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 357800, "time": 11412.398091077805, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 357800, "time": 11412.40708732605, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 357872, "time": 11414.812013864517, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 358176, "time": 11423.975796937943, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 358256, "time": 11426.406378984451, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 358288, "time": 11427.377148389816, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 358392, "time": 11430.312175273895, "episode/length": 12.0, "episode/score": 0.9624999761581421, "episode/reward_rate": 0.07692307692307693, "episode/intrinsic_return": 0.0}
{"step": 358432, "time": 11431.745030879974, "episode/length": 218.0, "episode/score": 0.3187499940395355, "episode/reward_rate": 0.0045662100456621, "episode/intrinsic_return": 0.0}
{"step": 358728, "time": 11440.576796770096, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 358800, "time": 11442.973680734634, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 358864, "time": 11444.922494411469, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 358904, "time": 11445.913498401642, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 358968, "time": 11447.867436408997, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 359120, "time": 11452.66452407837, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 359344, "time": 11459.407164096832, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 359512, "time": 11464.244688510895, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 359560, "time": 11465.690388917923, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 359600, "time": 11467.23271369934, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 359632, "time": 11468.220156669617, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 359952, "time": 11477.856881380081, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 359968, "time": 11478.341568470001, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 360048, "time": 11482.380859375, "eval_episode/length": 87.0, "eval_episode/score": 0.7281249761581421, "eval_episode/reward_rate": 0.011363636363636364}
{"step": 360048, "time": 11482.406705379486, "eval_episode/length": 88.0, "eval_episode/score": 0.7250000238418579, "eval_episode/reward_rate": 0.011235955056179775}
{"step": 360048, "time": 11482.697196483612, "eval_episode/length": 103.0, "eval_episode/score": 0.6781250238418579, "eval_episode/reward_rate": 0.009615384615384616}
{"step": 360048, "time": 11483.067150354385, "eval_episode/length": 122.0, "eval_episode/score": 0.6187499761581421, "eval_episode/reward_rate": 0.008130081300813009}
{"step": 360048, "time": 11483.30194234848, "eval_episode/length": 45.0, "eval_episode/score": 0.859375, "eval_episode/reward_rate": 0.021739130434782608}
{"step": 360048, "time": 11483.461373567581, "eval_episode/length": 142.0, "eval_episode/score": 0.5562499761581421, "eval_episode/reward_rate": 0.006993006993006993}
{"step": 360048, "time": 11483.834057569504, "eval_episode/length": 26.0, "eval_episode/score": 0.918749988079071, "eval_episode/reward_rate": 0.037037037037037035}
{"step": 360048, "time": 11483.900536298752, "eval_episode/length": 41.0, "eval_episode/score": 0.871874988079071, "eval_episode/reward_rate": 0.023809523809523808}
{"step": 360184, "time": 11487.82479262352, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 360440, "time": 11495.57360959053, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 360704, "time": 11504.364181995392, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 360744, "time": 11505.36625790596, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 361040, "time": 11514.63544011116, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 361448, "time": 11526.972907066345, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 361872, "time": 11540.150256872177, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 362136, "time": 11547.97458410263, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 362264, "time": 11551.884498119354, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 362280, "time": 11552.380591630936, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 362496, "time": 11559.243163824081, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 362584, "time": 11561.724878072739, "episode/length": 229.0, "episode/score": 0.28437501192092896, "episode/reward_rate": 0.004347826086956522, "episode/intrinsic_return": 0.0}
{"step": 362672, "time": 11564.635669231415, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 362688, "time": 11565.126827478409, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 362752, "time": 11567.07921719551, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 362800, "time": 11568.531919717789, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 362904, "time": 11571.473236560822, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 363016, "time": 11574.892451286316, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 363064, "time": 11576.350808143616, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 363440, "time": 11588.052780628204, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 364184, "time": 11610.424890756607, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 364432, "time": 11618.270448923111, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 364448, "time": 11618.758256912231, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 364544, "time": 11621.667413711548, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 364912, "time": 11632.834715127945, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 365064, "time": 11637.214428424835, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 365112, "time": 11638.71399641037, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 365216, "time": 11642.11845111847, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 365240, "time": 11642.652425765991, "episode/length": 15.0, "episode/score": 0.953125, "episode/reward_rate": 0.0625, "episode/intrinsic_return": 0.0}
{"step": 365376, "time": 11647.061163902283, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 365568, "time": 11652.903528213501, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 365752, "time": 11658.30836892128, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 366760, "time": 11688.98417019844, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 366856, "time": 11691.920041799545, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 367376, "time": 11707.995854139328, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 367528, "time": 11712.3879404068, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 367552, "time": 11713.347997665405, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 367688, "time": 11717.268345117569, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 367880, "time": 11723.126422643661, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 368064, "time": 11728.956286430359, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 368720, "time": 11749.394736528397, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 369072, "time": 11760.0951795578, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 369168, "time": 11763.019145488739, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 369840, "time": 11783.60663318634, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 369864, "time": 11784.120185375214, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 370000, "time": 11788.466549634933, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 370032, "time": 11789.778140306473, "eval_episode/length": 15.0, "eval_episode/score": 0.953125, "eval_episode/reward_rate": 0.0625}
{"step": 370032, "time": 11790.08643078804, "eval_episode/length": 31.0, "eval_episode/score": 0.903124988079071, "eval_episode/reward_rate": 0.03125}
{"step": 370032, "time": 11792.136877059937, "eval_episode/length": 138.0, "eval_episode/score": 0.5687500238418579, "eval_episode/reward_rate": 0.007194244604316547}
{"step": 370032, "time": 11792.60482597351, "eval_episode/length": 161.0, "eval_episode/score": 0.49687498807907104, "eval_episode/reward_rate": 0.006172839506172839}
{"step": 370032, "time": 11793.006089925766, "eval_episode/length": 182.0, "eval_episode/score": 0.4312500059604645, "eval_episode/reward_rate": 0.00546448087431694}
{"step": 370032, "time": 11795.013375997543, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 370032, "time": 11795.02452969551, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 370032, "time": 11795.03545498848, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 370192, "time": 11799.969668149948, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 370376, "time": 11805.33919453621, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 370520, "time": 11809.71282863617, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 370800, "time": 11818.421481132507, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 371032, "time": 11825.248054027557, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 371384, "time": 11836.059416770935, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 371480, "time": 11839.00174331665, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 372056, "time": 11856.453814983368, "episode/length": 232.0, "episode/score": 0.2750000059604645, "episode/reward_rate": 0.004291845493562232, "episode/intrinsic_return": 0.0}
{"step": 372120, "time": 11858.456465482712, "episode/length": 217.0, "episode/score": 0.3218750059604645, "episode/reward_rate": 0.0045871559633027525, "episode/intrinsic_return": 0.0}
{"step": 372176, "time": 11860.373623132706, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 372536, "time": 11871.012081861496, "episode/length": 216.0, "episode/score": 0.32499998807907104, "episode/reward_rate": 0.004608294930875576, "episode/intrinsic_return": 0.0}
{"step": 372600, "time": 11872.959489822388, "episode/length": 259.0, "episode/score": 0.19062499701976776, "episode/reward_rate": 0.0038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 372648, "time": 11874.396558523178, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 372648, "time": 11874.407346010208, "episode/length": 201.0, "episode/score": 0.37187498807907104, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.0}
{"step": 373120, "time": 11888.951038837433, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 373200, "time": 11891.37320637703, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 373256, "time": 11892.858612298965, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 373792, "time": 11909.465575933456, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 373880, "time": 11911.977907657623, "episode/length": 10.0, "episode/score": 0.96875, "episode/reward_rate": 0.09090909090909091, "episode/intrinsic_return": 0.0}
{"step": 374120, "time": 11919.36823964119, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 374432, "time": 11929.03368473053, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 374616, "time": 11934.35840678215, "episode/length": 259.0, "episode/score": 0.19062499701976776, "episode/reward_rate": 0.0038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 374648, "time": 11935.32476401329, "episode/length": 255.0, "episode/score": 0.203125, "episode/reward_rate": 0.00390625, "episode/intrinsic_return": 0.0}
{"step": 374896, "time": 11943.050724744797, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 374912, "time": 11943.539508342743, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 374928, "time": 11944.022193431854, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 374960, "time": 11944.988290309906, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 375376, "time": 11957.742715120316, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 375432, "time": 11959.24587726593, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 375504, "time": 11961.707193374634, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 375512, "time": 11961.734860658646, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 375512, "time": 11961.746014118195, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 375568, "time": 11963.682625055313, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 375776, "time": 11969.974703073502, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 375888, "time": 11973.361239433289, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 375952, "time": 11975.31149983406, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 376744, "time": 11999.258460998535, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 377464, "time": 12021.875890731812, "episode/length": 244.0, "episode/score": 0.23749999701976776, "episode/reward_rate": 0.004081632653061225, "episode/intrinsic_return": 0.0}
{"step": 377688, "time": 12028.690035581589, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 377744, "time": 12030.627148866653, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 377824, "time": 12033.038533687592, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 378056, "time": 12039.945996522903, "episode/length": 284.0, "episode/score": 0.11249999701976776, "episode/reward_rate": 0.0035087719298245615, "episode/intrinsic_return": 0.0}
{"step": 378200, "time": 12044.31376028061, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 378264, "time": 12046.25347161293, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 378808, "time": 12062.711253643036, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 378952, "time": 12067.144077777863, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 379056, "time": 12070.567477464676, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 379280, "time": 12077.385711669922, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 379488, "time": 12083.73034453392, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 379640, "time": 12088.111500024796, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 379840, "time": 12094.380041837692, "episode/length": 196.0, "episode/score": 0.38749998807907104, "episode/reward_rate": 0.005076142131979695, "episode/intrinsic_return": 0.0}
{"step": 379864, "time": 12094.89276599884, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 380000, "time": 12099.321143865585, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 380016, "time": 12101.269434690475, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 380016, "time": 12101.665246486664, "eval_episode/length": 94.0, "eval_episode/score": 0.706250011920929, "eval_episode/reward_rate": 0.010526315789473684}
{"step": 380016, "time": 12101.787819385529, "eval_episode/length": 100.0, "eval_episode/score": 0.6875, "eval_episode/reward_rate": 0.009900990099009901}
{"step": 380016, "time": 12103.728896856308, "eval_episode/length": 106.0, "eval_episode/score": 0.668749988079071, "eval_episode/reward_rate": 0.009345794392523364}
{"step": 380016, "time": 12105.42419719696, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380016, "time": 12105.433346509933, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380016, "time": 12105.441399812698, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380016, "time": 12105.451522111893, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380016, "time": 12105.467286348343, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380056, "time": 12106.473491668701, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 380096, "time": 12107.914609909058, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 380136, "time": 12108.933559656143, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 381024, "time": 12136.16694688797, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 381192, "time": 12141.055998325348, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 381344, "time": 12145.864503145218, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 381400, "time": 12147.349736452103, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 381432, "time": 12148.315686225891, "episode/length": 198.0, "episode/score": 0.3812499940395355, "episode/reward_rate": 0.005025125628140704, "episode/intrinsic_return": 0.0}
{"step": 381448, "time": 12148.802973508835, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 381792, "time": 12159.473806858063, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 381800, "time": 12159.503159999847, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 381944, "time": 12163.840894937515, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 382216, "time": 12172.089584589005, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 382248, "time": 12173.057181835175, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 382304, "time": 12174.970113277435, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 382312, "time": 12175.000538349152, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 382568, "time": 12182.760373830795, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 382712, "time": 12187.260020971298, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 382776, "time": 12189.200902462006, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 382912, "time": 12193.559048652649, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 383336, "time": 12206.262491941452, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 383496, "time": 12211.11214017868, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 383656, "time": 12215.967107534409, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 384224, "time": 12233.52561378479, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 384256, "time": 12234.50206375122, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 384584, "time": 12244.238664388657, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 384712, "time": 12248.28091096878, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 384880, "time": 12253.625879049301, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 385016, "time": 12257.556617975235, "episode/length": 287.0, "episode/score": 0.10312499850988388, "episode/reward_rate": 0.003472222222222222, "episode/intrinsic_return": 0.0}
{"step": 385065, "time": 12260.594185590744, "train_stats/mean_log_entropy": 0.1281017807608876, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.3113617849822092, "train/action_min": 0.0, "train/action_std": 1.3379160260209944, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.01151205707654947, "train/actor_opt_grad_steps": 22965.0, "train/actor_opt_loss": -4.638004497541945, "train/adv_mag": 0.5986275309973424, "train/adv_max": 0.2563735792542448, "train/adv_mean": 0.0040102205291059545, "train/adv_min": -0.5453082069311992, "train/adv_std": 0.035915130820807696, "train/cont_avg": 0.9957553372524752, "train/cont_loss_mean": 0.01978230614809891, "train/cont_loss_std": 0.27544336288817006, "train/cont_neg_acc": 0.16197619311511516, "train/cont_neg_loss": 3.8410660549998283, "train/cont_pos_acc": 0.9999223268858277, "train/cont_pos_loss": 0.0033865823885333717, "train/cont_pred": 0.9959602013672932, "train/cont_rate": 0.9957553372524752, "train/dyn_loss_mean": 1.0000092056718204, "train/dyn_loss_std": 0.0002698478010913304, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.026719305055714, "train/extr_critic_critic_opt_grad_steps": 22965.0, "train/extr_critic_critic_opt_loss": 9272.293664913366, "train/extr_critic_mag": 0.8443295908446359, "train/extr_critic_max": 0.8443295908446359, "train/extr_critic_mean": 0.8268217624414085, "train/extr_critic_min": 0.7955471176912289, "train/extr_critic_std": 0.008759017867764623, "train/extr_return_normed_mag": 0.5876064126444335, "train/extr_return_normed_max": 0.3006811000332974, "train/extr_return_normed_mean": 0.0375567796001975, "train/extr_return_normed_min": -0.5069535657911017, "train/extr_return_normed_std": 0.0376351710090801, "train/extr_return_rate": 0.9965005280947922, "train/extr_return_raw_mag": 1.0939562665944051, "train/extr_return_raw_max": 1.0939562665944051, "train/extr_return_raw_mean": 0.8308319859575517, "train/extr_return_raw_min": 0.28632160077000607, "train/extr_return_raw_std": 0.03763517110359551, "train/extr_reward_mag": 0.2903824011878212, "train/extr_reward_max": 0.2903824011878212, "train/extr_reward_mean": 0.0030569076221977996, "train/extr_reward_min": 3.1395713881690905e-07, "train/extr_reward_std": 0.014171270371211858, "train/image_loss_mean": 0.11447149319666447, "train/image_loss_std": 0.10481805133052391, "train/model_loss_mean": 0.7403042676425217, "train/model_loss_std": 0.39224535802213273, "train/model_opt_grad_norm": 29.79136913601715, "train/model_opt_grad_steps": 22944.178217821784, "train/model_opt_loss": 3428.311739779935, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 4653.465346534654, "train/policy_entropy_mag": 1.4112525287241038, "train/policy_entropy_max": 1.4112525287241038, "train/policy_entropy_mean": 0.15066629331005682, "train/policy_entropy_min": 0.0646870949923402, "train/policy_entropy_std": 0.19016422014130224, "train/policy_logprob_mag": 6.551079282666197, "train/policy_logprob_max": -0.008608317122527279, "train/policy_logprob_mean": -0.1510876192904935, "train/policy_logprob_min": -6.551079282666197, "train/policy_logprob_std": 0.6879244700516804, "train/policy_randomness_mag": 0.7252403778014797, "train/policy_randomness_max": 0.7252403778014797, "train/policy_randomness_mean": 0.07742716257672498, "train/policy_randomness_min": 0.03324259284625549, "train/policy_randomness_std": 0.09772508355355498, "train/post_ent_mag": 27.3965161106374, "train/post_ent_max": 27.3965161106374, "train/post_ent_mean": 27.152677035567784, "train/post_ent_min": 26.948701801866587, "train/post_ent_std": 0.07857653782656877, "train/prior_ent_mag": 27.79663575049674, "train/prior_ent_max": 27.79663575049674, "train/prior_ent_mean": 26.154750295204693, "train/prior_ent_min": 24.923237158520386, "train/prior_ent_std": 0.397073817872765, "train/rep_loss_mean": 1.0000092056718204, "train/rep_loss_std": 0.0002698478010913304, "train/reward_avg": 0.0007227831582454065, "train/reward_loss_mean": 0.006044923753758874, "train/reward_loss_std": 0.13406062915882022, "train/reward_max_data": 0.5148050741172663, "train/reward_max_pred": 0.1128734798714666, "train/reward_neg_acc": 0.9999128553536859, "train/reward_neg_loss": 0.0008576289937000993, "train/reward_pos_acc": 0.19355555603901545, "train/reward_pos_loss": 4.555640949408214, "train/reward_pred": 0.00050674039538544, "train/reward_rate": 0.0011506033415841584, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.029323169961571693, "report/cont_loss_std": 0.39127540588378906, "report/cont_neg_acc": 0.1666666716337204, "report/cont_neg_loss": 4.387876033782959, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0036342544481158257, "report/cont_pred": 0.9953357577323914, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.10969235002994537, "report/image_loss_std": 0.09913305938243866, "report/model_loss_mean": 0.7418211698532104, "report/model_loss_std": 0.41150492429733276, "report/post_ent_mag": 26.91962432861328, "report/post_ent_max": 26.91962432861328, "report/post_ent_mean": 26.689180374145508, "report/post_ent_min": 26.470291137695312, "report/post_ent_std": 0.07727262377738953, "report/prior_ent_mag": 27.546287536621094, "report/prior_ent_max": 27.546287536621094, "report/prior_ent_mean": 25.67473602294922, "report/prior_ent_min": 24.12140655517578, "report/prior_ent_std": 0.4048391580581665, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0006835937383584678, "report/reward_loss_mean": 0.002805650234222412, "report/reward_loss_std": 0.042474184185266495, "report/reward_max_data": 0.699999988079071, "report/reward_max_pred": 0.4794297218322754, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0014973991783335805, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 1.3411463499069214, "report/reward_pred": 0.0012131469557061791, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.01643558219075203, "eval/cont_loss_std": 0.31966090202331543, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 7.19049072265625, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0023963351268321276, "eval/cont_pred": 0.9976489543914795, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.22773617506027222, "eval/image_loss_std": 0.12618939578533173, "eval/model_loss_mean": 0.844398021697998, "eval/model_loss_std": 0.347001850605011, "eval/post_ent_mag": 26.91419219970703, "eval/post_ent_max": 26.91419219970703, "eval/post_ent_mean": 26.667646408081055, "eval/post_ent_min": 26.50870132446289, "eval/post_ent_std": 0.07312333583831787, "eval/prior_ent_mag": 27.07669448852539, "eval/prior_ent_max": 27.07669448852539, "eval/prior_ent_mean": 25.671703338623047, "eval/prior_ent_min": 24.31076431274414, "eval/prior_ent_std": 0.4199847877025604, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00022626807913184166, "eval/reward_loss_std": 0.0017564566805958748, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.019186735153198242, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00022626807913184166, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00011160504072904587, "eval/reward_rate": 0.0, "replay/size": 384561.0, "replay/inserts": 32272.0, "replay/samples": 32272.0, "replay/insert_wait_avg": 1.3282719258926384e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.55800948287215e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 88488.0, "eval_replay/inserts": 5944.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1770914573207358e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.834766387939453e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.35600233078, "timer/env.step_count": 4034.0, "timer/env.step_total": 38.83607888221741, "timer/env.step_frac": 0.038822258067859106, "timer/env.step_avg": 0.00962718861730724, "timer/env.step_min": 0.007753610610961914, "timer/env.step_max": 0.035637617111206055, "timer/replay._sample_count": 32272.0, "timer/replay._sample_total": 16.835946798324585, "timer/replay._sample_frac": 0.016829955295012636, "timer/replay._sample_avg": 0.0005216889811082234, "timer/replay._sample_min": 0.000385284423828125, "timer/replay._sample_max": 0.0254514217376709, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4777.0, "timer/agent.policy_total": 50.25345778465271, "timer/agent.policy_frac": 0.05023557380329067, "timer/agent.policy_avg": 0.010519878121133077, "timer/agent.policy_min": 0.008989095687866211, "timer/agent.policy_max": 0.08291006088256836, "timer/dataset_train_count": 2017.0, "timer/dataset_train_total": 0.22379374504089355, "timer/dataset_train_frac": 0.00022371410229904672, "timer/dataset_train_avg": 0.00011095376551358134, "timer/dataset_train_min": 9.72747802734375e-05, "timer/dataset_train_max": 0.0004315376281738281, "timer/agent.train_count": 2017.0, "timer/agent.train_total": 897.8414800167084, "timer/agent.train_frac": 0.897521960106984, "timer/agent.train_avg": 0.44513707487194265, "timer/agent.train_min": 0.4329657554626465, "timer/agent.train_max": 0.7740342617034912, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4730980396270752, "timer/agent.report_frac": 0.0004729296755602807, "timer/agent.report_avg": 0.2365490198135376, "timer/agent.report_min": 0.226531982421875, "timer/agent.report_max": 0.2465660572052002, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.361701965332031e-05, "timer/dataset_eval_frac": 3.360505617499602e-08, "timer/dataset_eval_avg": 3.361701965332031e-05, "timer/dataset_eval_min": 3.361701965332031e-05, "timer/dataset_eval_max": 3.361701965332031e-05, "fps": 32.25993868011941}
{"step": 385088, "time": 12261.286813259125, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 385128, "time": 12262.383199453354, "episode/length": 223.0, "episode/score": 0.3031249940395355, "episode/reward_rate": 0.004464285714285714, "episode/intrinsic_return": 0.0}
{"step": 385240, "time": 12265.832634210587, "episode/length": 197.0, "episode/score": 0.3843750059604645, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.0}
{"step": 385304, "time": 12267.788531064987, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 385664, "time": 12278.965897321701, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 385896, "time": 12285.81681227684, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 386136, "time": 12293.09616112709, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 386248, "time": 12296.520385980606, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 386296, "time": 12297.971455574036, "episode/length": 19.0, "episode/score": 0.940625011920929, "episode/reward_rate": 0.05, "episode/intrinsic_return": 0.0}
{"step": 386336, "time": 12299.407289981842, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 386536, "time": 12305.299189805984, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 386808, "time": 12313.646780014038, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 387024, "time": 12320.450458288193, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 387400, "time": 12331.608172416687, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 387440, "time": 12333.043171167374, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 387744, "time": 12342.368554830551, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 387824, "time": 12344.80354809761, "episode/length": 240.0, "episode/score": 0.25, "episode/reward_rate": 0.004149377593360996, "episode/intrinsic_return": 0.0}
{"step": 387976, "time": 12349.212234735489, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 388064, "time": 12352.09271812439, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 388512, "time": 12365.879352807999, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 388608, "time": 12368.936688899994, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 388632, "time": 12369.451241016388, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 388648, "time": 12369.947523117065, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 388696, "time": 12371.413107395172, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 388784, "time": 12374.322118759155, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 389104, "time": 12384.135356426239, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 389336, "time": 12390.980830192566, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 389768, "time": 12404.218385457993, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 390000, "time": 12412.888959884644, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 390000, "time": 12413.010401964188, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 390000, "time": 12413.095791101456, "eval_episode/length": 81.0, "eval_episode/score": 0.746874988079071, "eval_episode/reward_rate": 0.012195121951219513}
{"step": 390000, "time": 12413.125643491745, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 390000, "time": 12413.755497694016, "eval_episode/length": 113.0, "eval_episode/score": 0.6468750238418579, "eval_episode/reward_rate": 0.008771929824561403}
{"step": 390000, "time": 12413.938484430313, "eval_episode/length": 42.0, "eval_episode/score": 0.8687499761581421, "eval_episode/reward_rate": 0.023255813953488372}
{"step": 390000, "time": 12414.084928512573, "eval_episode/length": 55.0, "eval_episode/score": 0.828125, "eval_episode/reward_rate": 0.017857142857142856}
{"step": 390000, "time": 12414.185838460922, "eval_episode/length": 134.0, "eval_episode/score": 0.581250011920929, "eval_episode/reward_rate": 0.007407407407407408}
{"step": 390056, "time": 12415.686815738678, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 390128, "time": 12418.091743469238, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 390520, "time": 12429.91774725914, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 390576, "time": 12431.83362364769, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 390824, "time": 12439.144638299942, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 390920, "time": 12442.081961154938, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 390960, "time": 12443.517762422562, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 391008, "time": 12444.99101471901, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 391096, "time": 12447.44622182846, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 391152, "time": 12449.378640890121, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 391168, "time": 12449.864863872528, "episode/length": 228.0, "episode/score": 0.2874999940395355, "episode/reward_rate": 0.004366812227074236, "episode/intrinsic_return": 0.0}
{"step": 391712, "time": 12466.485121250153, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 391744, "time": 12467.455918312073, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 391976, "time": 12474.317806482315, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 391992, "time": 12474.81540465355, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 392168, "time": 12480.140563249588, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 392192, "time": 12481.091507434845, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 392392, "time": 12487.02956700325, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 392608, "time": 12493.832692623138, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 392776, "time": 12498.750925779343, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 392840, "time": 12500.699851036072, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 392888, "time": 12502.161811113358, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 393232, "time": 12513.351324796677, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 393408, "time": 12518.770015954971, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 393896, "time": 12533.4724817276, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 394024, "time": 12537.392125606537, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 394296, "time": 12545.639172792435, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 394480, "time": 12551.546357631683, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 394504, "time": 12552.062120437622, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 394632, "time": 12555.976600408554, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 394920, "time": 12564.76379609108, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 395088, "time": 12570.091126441956, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 395360, "time": 12578.453052520752, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 395448, "time": 12580.898825407028, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 395464, "time": 12581.390494585037, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 395544, "time": 12583.8405854702, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 395720, "time": 12589.180267095566, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 396016, "time": 12598.37870144844, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 396168, "time": 12602.790911197662, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 396296, "time": 12606.799162387848, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 396608, "time": 12616.516225099564, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 396808, "time": 12622.395748376846, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 396816, "time": 12622.869229316711, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 396816, "time": 12622.878801345825, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 397136, "time": 12632.58258986473, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 397184, "time": 12634.0372402668, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 397232, "time": 12635.510194301605, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 397392, "time": 12640.431745052338, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 397424, "time": 12641.396431446075, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 397672, "time": 12648.691525220871, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 397728, "time": 12650.621230602264, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 397760, "time": 12651.597348213196, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 398088, "time": 12661.325817346573, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 398216, "time": 12665.243555307388, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 398248, "time": 12666.213316440582, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 398336, "time": 12669.221940517426, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 398392, "time": 12670.720535993576, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 398472, "time": 12673.144057035446, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 398696, "time": 12679.995309114456, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 399104, "time": 12692.58275437355, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 399120, "time": 12693.071066379547, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 399288, "time": 12698.012498140335, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 399312, "time": 12698.98091006279, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 399368, "time": 12700.462941646576, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 399448, "time": 12702.888220071793, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 399704, "time": 12710.662180423737, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 399744, "time": 12712.095804691315, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 400088, "time": 12723.742596149445, "eval_episode/length": 45.0, "eval_episode/score": 0.859375, "eval_episode/reward_rate": 0.021739130434782608}
{"step": 400088, "time": 12723.822994709015, "eval_episode/length": 49.0, "eval_episode/score": 0.846875011920929, "eval_episode/reward_rate": 0.02}
{"step": 400088, "time": 12724.355555057526, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 400088, "time": 12724.929491996765, "eval_episode/length": 106.0, "eval_episode/score": 0.668749988079071, "eval_episode/reward_rate": 0.009345794392523364}
{"step": 400088, "time": 12725.216505289078, "eval_episode/length": 121.0, "eval_episode/score": 0.621874988079071, "eval_episode/reward_rate": 0.00819672131147541}
{"step": 400088, "time": 12726.100865840912, "eval_episode/length": 120.0, "eval_episode/score": 0.625, "eval_episode/reward_rate": 0.008264462809917356}
{"step": 400088, "time": 12726.915694475174, "eval_episode/length": 93.0, "eval_episode/score": 0.7093750238418579, "eval_episode/reward_rate": 0.010638297872340425}
{"step": 400088, "time": 12728.535046577454, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 400088, "time": 12728.548090934753, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 400088, "time": 12728.592617034912, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 400184, "time": 12731.509857654572, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 400328, "time": 12735.860610961914, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 400432, "time": 12739.250247240067, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 400528, "time": 12742.161047935486, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 400672, "time": 12746.5433177948, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 400736, "time": 12748.494444131851, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 400784, "time": 12749.968384504318, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 401024, "time": 12757.307845115662, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 401176, "time": 12761.678566217422, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 401328, "time": 12766.499799013138, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 401368, "time": 12767.489329099655, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 401624, "time": 12775.72152853012, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 401632, "time": 12776.18971657753, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 401680, "time": 12777.64491057396, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 401736, "time": 12779.136204004288, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 401848, "time": 12782.514372348785, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 401992, "time": 12786.987001895905, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 402232, "time": 12794.28764295578, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 402240, "time": 12794.757163763046, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 402288, "time": 12796.232011318207, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 402464, "time": 12801.56923699379, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 402744, "time": 12809.817170858383, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 402952, "time": 12816.1030960083, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 402984, "time": 12817.143919467926, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 403104, "time": 12820.97057056427, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 403160, "time": 12822.451721668243, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 403344, "time": 12828.23826098442, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 403792, "time": 12841.872599601746, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 403880, "time": 12844.328169584274, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 403944, "time": 12846.275893211365, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 403976, "time": 12847.34116768837, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 404160, "time": 12853.111336708069, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 404232, "time": 12855.079962968826, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 404384, "time": 12859.92758154869, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 404504, "time": 12863.36250424385, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 404544, "time": 12864.797879695892, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 404776, "time": 12871.66164135933, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 404936, "time": 12876.557468891144, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 405064, "time": 12880.436317443848, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 405168, "time": 12883.80964422226, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 405408, "time": 12891.080040216446, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 405424, "time": 12891.572009801865, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 405784, "time": 12902.216546058655, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 405800, "time": 12902.703580617905, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 406128, "time": 12912.914100408554, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 406192, "time": 12914.88049030304, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 406256, "time": 12916.813105583191, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 406312, "time": 12918.278660535812, "episode/length": 14.0, "episode/score": 0.956250011920929, "episode/reward_rate": 0.06666666666666667, "episode/intrinsic_return": 0.0}
{"step": 406512, "time": 12924.587518930435, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 406544, "time": 12925.576843976974, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 406544, "time": 12925.58461523056, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 406824, "time": 12933.809224843979, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 406920, "time": 12936.803126096725, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 406992, "time": 12939.211962461472, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 407032, "time": 12940.195911169052, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 407088, "time": 12942.11031794548, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 407384, "time": 12950.877845525742, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 407480, "time": 12953.790838956833, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 407720, "time": 12961.054509162903, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 407824, "time": 12964.468415498734, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 407920, "time": 12967.467224359512, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 408112, "time": 12973.321873664856, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 408136, "time": 12973.831808805466, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 408256, "time": 12977.682127952576, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 408400, "time": 12982.069209814072, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 408456, "time": 12983.570363998413, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 408456, "time": 12983.578800916672, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 408752, "time": 12992.778124332428, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 408824, "time": 12994.768146514893, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 408888, "time": 12996.835569620132, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 409080, "time": 13002.747846126556, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 409240, "time": 13007.617466688156, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 409272, "time": 13008.590723276138, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 409304, "time": 13009.566906452179, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 409304, "time": 13009.57494878769, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 409400, "time": 13012.507490634918, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 409760, "time": 13024.182544469833, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 409784, "time": 13024.691200971603, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 409976, "time": 13030.611931085587, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 410072, "time": 13034.322949409485, "eval_episode/length": 41.0, "eval_episode/score": 0.871874988079071, "eval_episode/reward_rate": 0.023809523809523808}
{"step": 410072, "time": 13034.36465215683, "eval_episode/length": 43.0, "eval_episode/score": 0.8656250238418579, "eval_episode/reward_rate": 0.022727272727272728}
{"step": 410072, "time": 13034.448779344559, "eval_episode/length": 47.0, "eval_episode/score": 0.8531249761581421, "eval_episode/reward_rate": 0.020833333333333332}
{"step": 410072, "time": 13034.69165110588, "eval_episode/length": 59.0, "eval_episode/score": 0.815625011920929, "eval_episode/reward_rate": 0.016666666666666666}
{"step": 410072, "time": 13035.140371799469, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 410072, "time": 13035.258448839188, "eval_episode/length": 41.0, "eval_episode/score": 0.871874988079071, "eval_episode/reward_rate": 0.023809523809523808}
{"step": 410072, "time": 13035.710426092148, "eval_episode/length": 71.0, "eval_episode/score": 0.778124988079071, "eval_episode/reward_rate": 0.013888888888888888}
{"step": 410072, "time": 13036.128126382828, "eval_episode/length": 135.0, "eval_episode/score": 0.578125, "eval_episode/reward_rate": 0.007352941176470588}
{"step": 410112, "time": 13037.552166938782, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 410184, "time": 13039.510087490082, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 410336, "time": 13044.333030462265, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 410704, "time": 13055.505954265594, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 411064, "time": 13066.243872642517, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 411328, "time": 13074.4564743042, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 411552, "time": 13081.213160991669, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 411616, "time": 13083.145992994308, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 411616, "time": 13083.153104782104, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 411712, "time": 13086.069659471512, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 412064, "time": 13096.855264425278, "episode/length": 234.0, "episode/score": 0.26875001192092896, "episode/reward_rate": 0.00425531914893617, "episode/intrinsic_return": 0.0}
{"step": 412168, "time": 13099.80696773529, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 412176, "time": 13100.278634786606, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 412256, "time": 13102.704857110977, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 412536, "time": 13110.976825475693, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 412624, "time": 13113.87471485138, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 412648, "time": 13114.383399486542, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 412672, "time": 13115.329884052277, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 413000, "time": 13125.175075054169, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 413072, "time": 13127.602048397064, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 413328, "time": 13135.35606789589, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 413360, "time": 13136.332828760147, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 413376, "time": 13136.820132732391, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 413520, "time": 13141.189222335815, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 413640, "time": 13144.608855485916, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 413720, "time": 13147.133776903152, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 413720, "time": 13147.141564846039, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 413832, "time": 13150.52749991417, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 414064, "time": 13157.796756029129, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 414376, "time": 13167.079520225525, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 414448, "time": 13169.472910642624, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 414568, "time": 13172.886586666107, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 414696, "time": 13176.846632957458, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 414712, "time": 13177.343662261963, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 414768, "time": 13179.252478837967, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 414872, "time": 13182.186256408691, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 415240, "time": 13193.303667068481, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 415240, "time": 13193.309576272964, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 415384, "time": 13197.666726350784, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 415584, "time": 13203.93174982071, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 415744, "time": 13208.881630420685, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 415904, "time": 13213.727267980576, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 415936, "time": 13214.6973798275, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 416144, "time": 13221.027557134628, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 416520, "time": 13232.186668872833, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 416536, "time": 13232.676495552063, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 416688, "time": 13237.62282705307, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 417008, "time": 13247.345127344131, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 417080, "time": 13249.33294081688, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 417088, "time": 13249.802305936813, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 417408, "time": 13259.475759983063, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 417433, "time": 13260.96548819542, "train_stats/mean_log_entropy": 0.09642798261510001, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.4054233060024752, "train/action_min": 0.0, "train/action_std": 1.5420798570802896, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.011989864596801967, "train/actor_opt_grad_steps": 24985.0, "train/actor_opt_loss": -4.3790936432778835, "train/adv_mag": 0.8191947757017495, "train/adv_max": 0.3134909390222908, "train/adv_mean": 0.004716985866540955, "train/adv_min": -0.8056665101263782, "train/adv_std": 0.040561527066799524, "train/cont_avg": 0.9957891785272277, "train/cont_loss_mean": 0.015157918652086195, "train/cont_loss_std": 0.2262261745031222, "train/cont_neg_acc": 0.3426517561901754, "train/cont_neg_loss": 2.867450113703108, "train/cont_pos_acc": 0.9997766596255916, "train/cont_pos_loss": 0.00306338413173591, "train/cont_pred": 0.9957470885007689, "train/cont_rate": 0.9957891785272277, "train/dyn_loss_mean": 1.0000021953393918, "train/dyn_loss_std": 5.672808095702145e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.798474863448208, "train/extr_critic_critic_opt_grad_steps": 24985.0, "train/extr_critic_critic_opt_loss": 8009.693181708308, "train/extr_critic_mag": 0.9457679308286988, "train/extr_critic_max": 0.9457679308286988, "train/extr_critic_mean": 0.913756912002469, "train/extr_critic_min": 0.8512860790337666, "train/extr_critic_std": 0.011451167402567693, "train/extr_return_normed_mag": 0.8026403613609843, "train/extr_return_normed_max": 0.34046913373588333, "train/extr_return_normed_mean": 0.032343229359605964, "train/extr_return_normed_min": -0.7843653361986179, "train/extr_return_normed_std": 0.043074994758324756, "train/extr_return_rate": 0.9963951476729742, "train/extr_return_raw_mag": 1.226599763230522, "train/extr_return_raw_max": 1.226599763230522, "train/extr_return_raw_mean": 0.918473901429979, "train/extr_return_raw_min": 0.10176529329602081, "train/extr_return_raw_std": 0.0430749947306617, "train/extr_reward_mag": 0.3692536118006942, "train/extr_reward_max": 0.3692536118006942, "train/extr_reward_mean": 0.0030243325209715357, "train/extr_reward_min": 2.5258205904819e-07, "train/extr_reward_std": 0.012944020960240228, "train/image_loss_mean": 0.10399862282937115, "train/image_loss_std": 0.1038026787930786, "train/model_loss_mean": 0.7257329370125686, "train/model_loss_std": 0.3553023520525139, "train/model_opt_grad_norm": 28.00619334041482, "train/model_opt_grad_steps": 24962.81683168317, "train/model_opt_loss": 3041.8011921797647, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 4207.920792079208, "train/policy_entropy_mag": 1.3843003175046185, "train/policy_entropy_max": 1.3843003175046185, "train/policy_entropy_mean": 0.12757381870604978, "train/policy_entropy_min": 0.06468666496105713, "train/policy_entropy_std": 0.16475239440356151, "train/policy_logprob_mag": 6.551080009724834, "train/policy_logprob_max": -0.008608148488594165, "train/policy_logprob_mean": -0.12731289317702302, "train/policy_logprob_min": -6.551080009724834, "train/policy_logprob_std": 0.6627787555208301, "train/policy_randomness_mag": 0.711389680900196, "train/policy_randomness_max": 0.711389680900196, "train/policy_randomness_mean": 0.06555997759177543, "train/policy_randomness_min": 0.03324237203981617, "train/policy_randomness_std": 0.08466598701359022, "train/post_ent_mag": 26.934484377946003, "train/post_ent_max": 26.934484377946003, "train/post_ent_mean": 26.659419900119893, "train/post_ent_min": 26.45625142767878, "train/post_ent_std": 0.08373804751894262, "train/prior_ent_mag": 27.046145854610028, "train/prior_ent_max": 27.046145854610028, "train/prior_ent_mean": 25.645775058481952, "train/prior_ent_min": 24.46911441689671, "train/prior_ent_std": 0.3705523527494752, "train/rep_loss_mean": 1.0000021953393918, "train/rep_loss_std": 5.672808095702145e-05, "train/reward_avg": 0.0008060417541027263, "train/reward_loss_mean": 0.006575058689248739, "train/reward_loss_std": 0.12990724989777835, "train/reward_max_data": 0.4960086604598725, "train/reward_max_pred": 0.14129872428308618, "train/reward_neg_acc": 0.999840248339247, "train/reward_neg_loss": 0.0010797209497018184, "train/reward_pos_acc": 0.2436342601560884, "train/reward_pos_loss": 4.214021476606528, "train/reward_pred": 0.0006547501727957094, "train/reward_rate": 0.0012859684405940595, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 0.02381173148751259, "report/cont_loss_std": 0.28821948170661926, "report/cont_neg_acc": 0.375, "report/cont_neg_loss": 2.4870758056640625, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.004415950737893581, "report/cont_pred": 0.9930734634399414, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.1332339346408844, "report/image_loss_std": 0.12687762081623077, "report/model_loss_mean": 0.7785089015960693, "report/model_loss_std": 0.5348345637321472, "report/post_ent_mag": 26.793630599975586, "report/post_ent_max": 26.793630599975586, "report/post_ent_mean": 26.52682876586914, "report/post_ent_min": 26.305625915527344, "report/post_ent_std": 0.08310816437005997, "report/prior_ent_mag": 26.686677932739258, "report/prior_ent_max": 26.686677932739258, "report/prior_ent_mean": 25.779905319213867, "report/prior_ent_min": 24.32486343383789, "report/prior_ent_std": 0.32028961181640625, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0037384035531431437, "report/reward_loss_mean": 0.02146325260400772, "report/reward_loss_std": 0.28685155510902405, "report/reward_max_data": 0.921875, "report/reward_max_pred": 0.3618963956832886, "report/reward_neg_acc": 0.999018669128418, "report/reward_neg_loss": 0.0034916826989501715, "report/reward_pos_acc": 0.20000000298023224, "report/reward_pos_loss": 3.6840691566467285, "report/reward_pred": 0.0023111854679882526, "report/reward_rate": 0.0048828125, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.01583024486899376, "eval/cont_loss_std": 0.30110251903533936, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.4898786544799805, "eval/cont_pos_acc": 0.9990215301513672, "eval/cont_pos_loss": 0.0031608722638338804, "eval/cont_pred": 0.9972827434539795, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.21257883310317993, "eval/image_loss_std": 0.1363314837217331, "eval/model_loss_mean": 0.8358981013298035, "eval/model_loss_std": 0.49004891514778137, "eval/post_ent_mag": 26.783000946044922, "eval/post_ent_max": 26.783000946044922, "eval/post_ent_mean": 26.512126922607422, "eval/post_ent_min": 26.33053207397461, "eval/post_ent_std": 0.07985714823007584, "eval/prior_ent_mag": 26.76015853881836, "eval/prior_ent_max": 26.76015853881836, "eval/prior_ent_mean": 25.795408248901367, "eval/prior_ent_min": 24.856075286865234, "eval/prior_ent_std": 0.33667486906051636, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0002563476446084678, "eval/reward_loss_mean": 0.007489013019949198, "eval/reward_loss_std": 0.23427484929561615, "eval/reward_max_data": 0.26249998807907104, "eval/reward_max_pred": 0.00783693790435791, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00016442958440165967, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 7.500537872314453, "eval/reward_pred": 9.094132110476494e-05, "eval/reward_rate": 0.0009765625, "replay/size": 416929.0, "replay/inserts": 32368.0, "replay/samples": 32368.0, "replay/insert_wait_avg": 1.3171285906464996e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.57483380157878e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 92968.0, "eval_replay/inserts": 4480.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2284410851342338e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.685754776000977e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3563454151154, "timer/env.step_count": 4046.0, "timer/env.step_total": 38.93589925765991, "timer/env.step_frac": 0.038922029570875344, "timer/env.step_avg": 0.009623306786371704, "timer/env.step_min": 0.007776737213134766, "timer/env.step_max": 0.03596305847167969, "timer/replay._sample_count": 32368.0, "timer/replay._sample_total": 16.985057592391968, "timer/replay._sample_frac": 0.01697900720102267, "timer/replay._sample_avg": 0.0005247484426715264, "timer/replay._sample_min": 0.0003972053527832031, "timer/replay._sample_max": 0.011518001556396484, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4606.0, "timer/agent.policy_total": 48.9639949798584, "timer/agent.policy_frac": 0.048946553100075486, "timer/agent.policy_avg": 0.010630480890112549, "timer/agent.policy_min": 0.008945465087890625, "timer/agent.policy_max": 0.08242678642272949, "timer/dataset_train_count": 2023.0, "timer/dataset_train_total": 0.22594380378723145, "timer/dataset_train_frac": 0.00022586331842926644, "timer/dataset_train_avg": 0.00011168749569314456, "timer/dataset_train_min": 9.512901306152344e-05, "timer/dataset_train_max": 0.0010733604431152344, "timer/agent.train_count": 2023.0, "timer/agent.train_total": 900.9505915641785, "timer/agent.train_frac": 0.9006296563154336, "timer/agent.train_avg": 0.44535372791111144, "timer/agent.train_min": 0.43396949768066406, "timer/agent.train_max": 0.6973457336425781, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4716970920562744, "timer/agent.report_frac": 0.0004715290648359265, "timer/agent.report_avg": 0.2358485460281372, "timer/agent.report_min": 0.2288358211517334, "timer/agent.report_max": 0.24286127090454102, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.1948089599609375e-05, "timer/dataset_eval_frac": 3.1936709099747804e-08, "timer/dataset_eval_avg": 3.1948089599609375e-05, "timer/dataset_eval_min": 3.1948089599609375e-05, "timer/dataset_eval_max": 3.1948089599609375e-05, "fps": 32.35595613302116}
{"step": 417480, "time": 13262.168562173843, "episode/length": 8.0, "episode/score": 0.9750000238418579, "episode/reward_rate": 0.1111111111111111, "episode/intrinsic_return": 0.0}
{"step": 417536, "time": 13264.109590768814, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 417896, "time": 13275.357436418533, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 418040, "time": 13279.748240470886, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 418056, "time": 13280.245762825012, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 418280, "time": 13287.018443346024, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 418456, "time": 13292.363714933395, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 418848, "time": 13304.57632946968, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 419016, "time": 13309.446859359741, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 419072, "time": 13311.359133005142, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 419088, "time": 13311.845841407776, "episode/length": 8.0, "episode/score": 0.9750000238418579, "episode/reward_rate": 0.1111111111111111, "episode/intrinsic_return": 0.0}
{"step": 419392, "time": 13321.072217226028, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 419400, "time": 13321.101823091507, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 419568, "time": 13326.453658103943, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 419704, "time": 13330.444312095642, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 419808, "time": 13333.836563825607, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 419816, "time": 13333.864512205124, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 419848, "time": 13334.839310407639, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 419952, "time": 13338.232009410858, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 420032, "time": 13340.664737224579, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 420056, "time": 13341.904507160187, "eval_episode/length": 36.0, "eval_episode/score": 0.887499988079071, "eval_episode/reward_rate": 0.02702702702702703}
{"step": 420056, "time": 13341.94578409195, "eval_episode/length": 38.0, "eval_episode/score": 0.8812500238418579, "eval_episode/reward_rate": 0.02564102564102564}
{"step": 420056, "time": 13342.218260288239, "eval_episode/length": 53.0, "eval_episode/score": 0.8343750238418579, "eval_episode/reward_rate": 0.018518518518518517}
{"step": 420056, "time": 13342.746786117554, "eval_episode/length": 81.0, "eval_episode/score": 0.746874988079071, "eval_episode/reward_rate": 0.012195121951219513}
{"step": 420056, "time": 13342.794902801514, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 420056, "time": 13342.982569694519, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 420056, "time": 13343.377383947372, "eval_episode/length": 75.0, "eval_episode/score": 0.765625, "eval_episode/reward_rate": 0.013157894736842105}
{"step": 420056, "time": 13343.880115509033, "eval_episode/length": 55.0, "eval_episode/score": 0.828125, "eval_episode/reward_rate": 0.017857142857142856}
{"step": 420352, "time": 13353.06296300888, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 420368, "time": 13353.550075054169, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 420816, "time": 13367.172492027283, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 420848, "time": 13368.143205165863, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 420936, "time": 13370.593304872513, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 421040, "time": 13373.952964782715, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 421192, "time": 13378.327775239944, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 421352, "time": 13383.16839647293, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 421584, "time": 13390.517196178436, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 421840, "time": 13398.313386440277, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 421952, "time": 13401.728291273117, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 422016, "time": 13403.678476810455, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 422160, "time": 13408.064218997955, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 422344, "time": 13413.434527635574, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 422384, "time": 13414.891387224197, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 422512, "time": 13418.911500692368, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 422576, "time": 13420.865901947021, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 422992, "time": 13433.53242444992, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 423128, "time": 13437.42886042595, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 423160, "time": 13438.417317390442, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 423168, "time": 13438.88502907753, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 423248, "time": 13441.286370754242, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 423264, "time": 13441.774360895157, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 423288, "time": 13442.281914234161, "episode/length": 15.0, "episode/score": 0.953125, "episode/reward_rate": 0.0625, "episode/intrinsic_return": 0.0}
{"step": 423360, "time": 13444.663816928864, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 423536, "time": 13450.068417549133, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 423992, "time": 13463.712665081024, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 424016, "time": 13464.663455963135, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 424152, "time": 13468.586919307709, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 424256, "time": 13471.95576429367, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 424304, "time": 13473.426819086075, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 424368, "time": 13475.391877412796, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 424648, "time": 13483.781210899353, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 424648, "time": 13483.789952516556, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 424720, "time": 13486.17996430397, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 424944, "time": 13492.967235326767, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 425304, "time": 13503.623794317245, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 425528, "time": 13510.609762907028, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 425576, "time": 13512.103794574738, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 425672, "time": 13515.029301643372, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 425824, "time": 13519.886697530746, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 425840, "time": 13520.382753133774, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 426464, "time": 13540.111535072327, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 426600, "time": 13544.08333683014, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 426608, "time": 13544.555155038834, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 426624, "time": 13545.049396276474, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 426792, "time": 13549.981054782867, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 426960, "time": 13555.330012083054, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 427032, "time": 13557.332076311111, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 427344, "time": 13567.209336042404, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 427464, "time": 13570.667521715164, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 427496, "time": 13571.662957191467, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 427616, "time": 13575.537336111069, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 427632, "time": 13576.048567056656, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 427704, "time": 13578.021263122559, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 427808, "time": 13581.457122564316, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 427984, "time": 13586.842234611511, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 428136, "time": 13591.312128305435, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 428152, "time": 13591.813811540604, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 428304, "time": 13596.818164348602, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 428472, "time": 13601.742460012436, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 428688, "time": 13608.574789047241, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 428800, "time": 13612.01708650589, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 428880, "time": 13614.49218583107, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 429256, "time": 13625.911454200745, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 429448, "time": 13631.932574987411, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 429656, "time": 13638.344016075134, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 429808, "time": 13643.2412545681, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 430016, "time": 13649.64535164833, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 430040, "time": 13651.316135406494, "eval_episode/length": 54.0, "eval_episode/score": 0.831250011920929, "eval_episode/reward_rate": 0.01818181818181818}
{"step": 430040, "time": 13651.565068244934, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 430040, "time": 13652.949611902237, "eval_episode/length": 76.0, "eval_episode/score": 0.762499988079071, "eval_episode/reward_rate": 0.012987012987012988}
{"step": 430040, "time": 13656.106343984604, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 430040, "time": 13656.115725040436, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 430040, "time": 13656.12154340744, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 430040, "time": 13656.127206325531, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 430040, "time": 13656.135452747345, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 430040, "time": 13656.144114017487, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 430120, "time": 13658.719836235046, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 430320, "time": 13665.054210186005, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 430336, "time": 13665.552391052246, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 430640, "time": 13674.8664021492, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 430648, "time": 13674.894528627396, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 430712, "time": 13676.867222309113, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 430920, "time": 13683.254894018173, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 431000, "time": 13685.71564912796, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 431112, "time": 13689.281889677048, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 431224, "time": 13692.723541736603, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 431968, "time": 13715.87737083435, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 432232, "time": 13723.86024260521, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 432328, "time": 13726.805666923523, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 432648, "time": 13736.61832690239, "episode/length": 250.0, "episode/score": 0.21875, "episode/reward_rate": 0.00398406374501992, "episode/intrinsic_return": 0.0}
{"step": 432888, "time": 13743.97661447525, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 432960, "time": 13746.424029111862, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 433024, "time": 13748.441387176514, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 433216, "time": 13754.31204199791, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 433232, "time": 13754.837749242783, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 433424, "time": 13760.691194295883, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 433456, "time": 13761.675482034683, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 433536, "time": 13764.140354394913, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 434120, "time": 13781.916451215744, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 434416, "time": 13791.674540996552, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 434416, "time": 13791.72371339798, "episode/length": 220.0, "episode/score": 0.3125, "episode/reward_rate": 0.004524886877828055, "episode/intrinsic_return": 0.0}
{"step": 434472, "time": 13793.22179365158, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 434592, "time": 13797.104206085205, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 434600, "time": 13797.131925821304, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 434640, "time": 13798.59536600113, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 434792, "time": 13802.967683315277, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 435200, "time": 13815.716901779175, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 435232, "time": 13816.697969913483, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 435416, "time": 13822.14301776886, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 435496, "time": 13824.580610752106, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 435544, "time": 13826.036256790161, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 435880, "time": 13836.230140209198, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 435952, "time": 13838.739286899567, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 436232, "time": 13847.060057640076, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 436728, "time": 13862.26694393158, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 436912, "time": 13868.326203346252, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 437104, "time": 13874.218511343002, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 437512, "time": 13886.416059970856, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 437544, "time": 13887.406417131424, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 438072, "time": 13903.702315807343, "episode/length": 273.0, "episode/score": 0.14687499403953552, "episode/reward_rate": 0.0036496350364963502, "episode/intrinsic_return": 0.0}
{"step": 438176, "time": 13907.072261333466, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 438208, "time": 13908.061308860779, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 438264, "time": 13909.52898144722, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 438544, "time": 13919.534142971039, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 438592, "time": 13920.995265007019, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 438808, "time": 13927.4219353199, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 438824, "time": 13927.912578821182, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 438840, "time": 13928.422756195068, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 439040, "time": 13934.699803113937, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 439040, "time": 13934.708047389984, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 439072, "time": 13935.67893242836, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 439240, "time": 13940.615508794785, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 439296, "time": 13942.538717269897, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 439352, "time": 13944.038190603256, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 439416, "time": 13945.988285779953, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 439544, "time": 13949.879177093506, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 439856, "time": 13959.69646692276, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 439880, "time": 13960.206113815308, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 439968, "time": 13963.115344762802, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 440024, "time": 13965.485841751099, "eval_episode/length": 44.0, "eval_episode/score": 0.862500011920929, "eval_episode/reward_rate": 0.022222222222222223}
{"step": 440024, "time": 13965.510541439056, "eval_episode/length": 45.0, "eval_episode/score": 0.859375, "eval_episode/reward_rate": 0.021739130434782608}
{"step": 440024, "time": 13965.51840519905, "eval_episode/length": 45.0, "eval_episode/score": 0.859375, "eval_episode/reward_rate": 0.021739130434782608}
{"step": 440024, "time": 13966.04884147644, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 440024, "time": 13966.075131893158, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 440024, "time": 13966.284702777863, "eval_episode/length": 85.0, "eval_episode/score": 0.734375, "eval_episode/reward_rate": 0.011627906976744186}
{"step": 440024, "time": 13966.717019796371, "eval_episode/length": 63.0, "eval_episode/score": 0.8031250238418579, "eval_episode/reward_rate": 0.015625}
{"step": 440024, "time": 13967.403807163239, "eval_episode/length": 72.0, "eval_episode/score": 0.7749999761581421, "eval_episode/reward_rate": 0.0136986301369863}
{"step": 440080, "time": 13969.326878070831, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 440176, "time": 13972.248517990112, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 440512, "time": 13982.443107366562, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 440800, "time": 13991.260340452194, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 441000, "time": 13997.198449373245, "episode/length": 212.0, "episode/score": 0.3375000059604645, "episode/reward_rate": 0.004694835680751174, "episode/intrinsic_return": 0.0}
{"step": 441000, "time": 13997.247394323349, "episode/length": 271.0, "episode/score": 0.15312500298023224, "episode/reward_rate": 0.003676470588235294, "episode/intrinsic_return": 0.0}
{"step": 441352, "time": 14007.944015026093, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 441480, "time": 14011.851694822311, "episode/length": 199.0, "episode/score": 0.37812501192092896, "episode/reward_rate": 0.005, "episode/intrinsic_return": 0.0}
{"step": 441552, "time": 14014.27564740181, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 441624, "time": 14016.227202177048, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 441768, "time": 14020.705560445786, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 441784, "time": 14021.192846775055, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 442032, "time": 14028.921898841858, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 442200, "time": 14033.786879062653, "episode/length": 20.0, "episode/score": 0.9375, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.0}
{"step": 442280, "time": 14036.205470323563, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 442368, "time": 14039.232211828232, "episode/length": 231.0, "episode/score": 0.27812498807907104, "episode/reward_rate": 0.004310344827586207, "episode/intrinsic_return": 0.0}
{"step": 442656, "time": 14048.400761842728, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 442832, "time": 14053.756304979324, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 443040, "time": 14060.053662776947, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 443112, "time": 14062.010595560074, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 443304, "time": 14067.873553037643, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 443464, "time": 14072.742126703262, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 443472, "time": 14073.238255500793, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 443560, "time": 14075.723034143448, "episode/length": 241.0, "episode/score": 0.24687500298023224, "episode/reward_rate": 0.004132231404958678, "episode/intrinsic_return": 0.0}
{"step": 443664, "time": 14079.286478042603, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 443680, "time": 14079.785586833954, "episode/length": 236.0, "episode/score": 0.26249998807907104, "episode/reward_rate": 0.004219409282700422, "episode/intrinsic_return": 0.0}
{"step": 443760, "time": 14082.249207258224, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 443792, "time": 14083.25410914421, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 443896, "time": 14086.18530845642, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 444224, "time": 14096.36388015747, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 444288, "time": 14098.314586400986, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 444664, "time": 14109.545480012894, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 445048, "time": 14121.227427005768, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 445648, "time": 14139.843108415604, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 445776, "time": 14143.769015312195, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 445872, "time": 14146.699426174164, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 445992, "time": 14150.140979290009, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 446000, "time": 14150.614174127579, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 446072, "time": 14152.629890680313, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 446104, "time": 14153.608722448349, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 446600, "time": 14168.875527858734, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 446608, "time": 14169.351006746292, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 446608, "time": 14169.365393161774, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 446624, "time": 14169.860279083252, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 446888, "time": 14177.713878393173, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 446984, "time": 14180.651263237, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 447152, "time": 14185.99355173111, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 447256, "time": 14188.922176837921, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 447472, "time": 14195.71324133873, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 447520, "time": 14197.313559055328, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 447712, "time": 14203.12888288498, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 448088, "time": 14214.337372303009, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 448152, "time": 14216.293332576752, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 448312, "time": 14221.194813728333, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 448416, "time": 14224.627101421356, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 448568, "time": 14229.247680187225, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 448656, "time": 14232.190730333328, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 448760, "time": 14235.179407119751, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 448920, "time": 14240.100996017456, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 449208, "time": 14248.864456892014, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 449296, "time": 14251.755593538284, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 449344, "time": 14253.213499307632, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 449568, "time": 14260.137454986572, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 449577, "time": 14261.159074783325, "train_stats/mean_log_entropy": 0.09653826472024585, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.457054631627021, "train/action_min": 0.0, "train/action_std": 1.5357383252376349, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.013828947648999109, "train/actor_opt_grad_steps": 27000.0, "train/actor_opt_loss": -5.077787923881441, "train/adv_mag": 0.9408938119660563, "train/adv_max": 0.3745937430443455, "train/adv_mean": 0.006132935651543114, "train/adv_min": -0.9250170128855539, "train/adv_std": 0.04755375860953954, "train/cont_avg": 0.9954572838930348, "train/cont_loss_mean": 0.014257426934886668, "train/cont_loss_std": 0.2130792371659952, "train/cont_neg_acc": 0.41185913380235434, "train/cont_neg_loss": 2.4710096819396132, "train/cont_pos_acc": 0.9998242567427715, "train/cont_pos_loss": 0.0029257779080300262, "train/cont_pred": 0.9954939754448127, "train/cont_rate": 0.9954572838930348, "train/dyn_loss_mean": 1.0000044919958162, "train/dyn_loss_std": 0.00014366982392871182, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.5802076990665191, "train/extr_critic_critic_opt_grad_steps": 27000.0, "train/extr_critic_critic_opt_loss": 12530.683137049129, "train/extr_critic_mag": 1.100004276232933, "train/extr_critic_max": 1.100004276232933, "train/extr_critic_mean": 1.038562837821334, "train/extr_critic_min": 0.9086192371833384, "train/extr_critic_std": 0.018687322504114156, "train/extr_return_normed_mag": 0.9200513164202372, "train/extr_return_normed_max": 0.39239030068193503, "train/extr_return_normed_mean": 0.0489529229385491, "train/extr_return_normed_min": -0.9032247920534504, "train/extr_return_normed_std": 0.052222989119626397, "train/extr_return_rate": 0.997353126753622, "train/extr_return_raw_mag": 1.3881330952715518, "train/extr_return_raw_max": 1.3881330952715518, "train/extr_return_raw_mean": 1.0446957649283148, "train/extr_return_raw_min": 0.09251800253616636, "train/extr_return_raw_std": 0.052222988952822354, "train/extr_reward_mag": 0.39209252684863644, "train/extr_reward_max": 0.39209252684863644, "train/extr_reward_mean": 0.0032204282652489396, "train/extr_reward_min": 2.645141449733753e-07, "train/extr_reward_std": 0.016160605142856787, "train/image_loss_mean": 0.09616258121396772, "train/image_loss_std": 0.10119618430956086, "train/model_loss_mean": 0.7185750247827217, "train/model_loss_std": 0.3668953855313472, "train/model_opt_grad_norm": 26.686679854321834, "train/model_opt_grad_steps": 26976.248756218905, "train/model_opt_loss": 2698.2457269317474, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3756.218905472637, "train/policy_entropy_mag": 1.375963875903419, "train/policy_entropy_max": 1.375963875903419, "train/policy_entropy_mean": 0.12970275357736283, "train/policy_entropy_min": 0.06468662430546177, "train/policy_entropy_std": 0.1693028500720636, "train/policy_logprob_mag": 6.551080115398958, "train/policy_logprob_max": -0.008608145004518293, "train/policy_logprob_mean": -0.12992649302998585, "train/policy_logprob_min": -6.551080115398958, "train/policy_logprob_std": 0.667138125172895, "train/policy_randomness_mag": 0.7071055989360335, "train/policy_randomness_max": 0.7071055989360335, "train/policy_randomness_mean": 0.06665403334729707, "train/policy_randomness_min": 0.033242351380153676, "train/policy_randomness_std": 0.08700445905995013, "train/post_ent_mag": 26.73031800303293, "train/post_ent_max": 26.73031800303293, "train/post_ent_mean": 26.42621164654025, "train/post_ent_min": 26.213833130414212, "train/post_ent_std": 0.09344147883392685, "train/prior_ent_mag": 26.770166378116134, "train/prior_ent_max": 26.770166378116134, "train/prior_ent_mean": 25.41994220107349, "train/prior_ent_min": 24.376409094132, "train/prior_ent_std": 0.3561207016012562, "train/rep_loss_mean": 1.0000044919958162, "train/rep_loss_std": 0.00014366982392871182, "train/reward_avg": 0.0010513229791824451, "train/reward_loss_mean": 0.008152298980267413, "train/reward_loss_std": 0.15470036284578734, "train/reward_max_data": 0.6173041057379092, "train/reward_max_pred": 0.16909466513353794, "train/reward_neg_acc": 0.9998248029704118, "train/reward_neg_loss": 0.001361147564899846, "train/reward_pos_acc": 0.21467065980691397, "train/reward_pos_loss": 4.1694678032469605, "train/reward_pred": 0.0008421338618552285, "train/reward_rate": 0.0016178871268656715, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.006943549495190382, "report/cont_loss_std": 0.1358855664730072, "report/cont_neg_acc": 0.5, "report/cont_neg_loss": 2.174973487854004, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.00270082987844944, "report/cont_pred": 0.9963572025299072, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.09616181254386902, "report/image_loss_std": 0.101094551384449, "report/model_loss_mean": 0.7103223204612732, "report/model_loss_std": 0.3451191484928131, "report/post_ent_mag": 26.64458465576172, "report/post_ent_max": 26.64458465576172, "report/post_ent_mean": 26.307048797607422, "report/post_ent_min": 26.072689056396484, "report/post_ent_std": 0.09405945241451263, "report/prior_ent_mag": 26.93354034423828, "report/prior_ent_max": 26.93354034423828, "report/prior_ent_mean": 25.60242462158203, "report/prior_ent_min": 24.732040405273438, "report/prior_ent_std": 0.3077971339225769, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0005249023670330644, "report/reward_loss_mean": 0.00721694203093648, "report/reward_loss_std": 0.18460923433303833, "report/reward_max_data": 0.5375000238418579, "report/reward_max_pred": 0.04839622974395752, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.001449726172722876, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 5.907078742980957, "report/reward_pred": 0.0007393948035314679, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.05153350159525871, "eval/cont_loss_std": 0.7802976965904236, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 12.490238189697266, "eval/cont_pos_acc": 0.9990195631980896, "eval/cont_pos_loss": 0.002754266606643796, "eval/cont_pred": 0.9979127049446106, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0000576972961426, "eval/dyn_loss_std": 0.0018458100967109203, "eval/image_loss_mean": 0.2343570441007614, "eval/image_loss_std": 0.14047926664352417, "eval/model_loss_mean": 0.8860365748405457, "eval/model_loss_std": 0.7951219081878662, "eval/post_ent_mag": 26.644866943359375, "eval/post_ent_max": 26.644866943359375, "eval/post_ent_mean": 26.301551818847656, "eval/post_ent_min": 26.1083984375, "eval/post_ent_std": 0.09629030525684357, "eval/prior_ent_mag": 27.42635726928711, "eval/prior_ent_max": 27.42635726928711, "eval/prior_ent_mean": 25.57345962524414, "eval/prior_ent_min": 24.495094299316406, "eval/prior_ent_std": 0.356082558631897, "eval/rep_loss_mean": 1.0000576972961426, "eval/rep_loss_std": 0.0018458100967109203, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00011135824024677277, "eval/reward_loss_std": 0.0009018696728162467, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.008141160011291504, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00011135824024677277, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 5.51177654415369e-05, "eval/reward_rate": 0.0, "replay/size": 449073.0, "replay/inserts": 32144.0, "replay/samples": 32144.0, "replay/insert_wait_avg": 1.359054139148186e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.849835977321718e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 97576.0, "eval_replay/inserts": 4608.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1873328023486667e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0579824447631836e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1790590286255, "timer/env.step_count": 4018.0, "timer/env.step_total": 39.54663300514221, "timer/env.step_frac": 0.03953955309117342, "timer/env.step_avg": 0.00984236759709861, "timer/env.step_min": 0.0077495574951171875, "timer/env.step_max": 0.049553871154785156, "timer/replay._sample_count": 32144.0, "timer/replay._sample_total": 17.16390609741211, "timer/replay._sample_frac": 0.017160833295271852, "timer/replay._sample_avg": 0.0005339692041255634, "timer/replay._sample_min": 0.000392913818359375, "timer/replay._sample_max": 0.011917829513549805, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4594.0, "timer/agent.policy_total": 49.27942228317261, "timer/agent.policy_frac": 0.04927059993740802, "timer/agent.policy_avg": 0.010726909508744581, "timer/agent.policy_min": 0.008638143539428711, "timer/agent.policy_max": 0.07628607749938965, "timer/dataset_train_count": 2009.0, "timer/dataset_train_total": 0.22832465171813965, "timer/dataset_train_frac": 0.00022828377544705715, "timer/dataset_train_avg": 0.00011365089682336469, "timer/dataset_train_min": 9.632110595703125e-05, "timer/dataset_train_max": 0.0010876655578613281, "timer/agent.train_count": 2009.0, "timer/agent.train_total": 899.4633507728577, "timer/agent.train_frac": 0.8993023225725372, "timer/agent.train_avg": 0.4477169491154095, "timer/agent.train_min": 0.43365478515625, "timer/agent.train_max": 1.7245264053344727, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4776482582092285, "timer/agent.report_frac": 0.0004775627462877705, "timer/agent.report_avg": 0.23882412910461426, "timer/agent.report_min": 0.22993731498718262, "timer/agent.report_max": 0.2477109432220459, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.62396240234375e-05, "timer/dataset_eval_frac": 3.623313615327384e-08, "timer/dataset_eval_avg": 3.62396240234375e-05, "timer/dataset_eval_min": 3.62396240234375e-05, "timer/dataset_eval_max": 3.62396240234375e-05, "fps": 32.13772292475996}
{"step": 449952, "time": 14272.514857769012, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 450008, "time": 14275.43518447876, "eval_episode/length": 43.0, "eval_episode/score": 0.8656250238418579, "eval_episode/reward_rate": 0.022727272727272728}
{"step": 450008, "time": 14275.752930879593, "eval_episode/length": 60.0, "eval_episode/score": 0.8125, "eval_episode/reward_rate": 0.01639344262295082}
{"step": 450008, "time": 14275.797410011292, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 450008, "time": 14276.022324085236, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 450008, "time": 14276.105548620224, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 450008, "time": 14276.813878536224, "eval_episode/length": 53.0, "eval_episode/score": 0.8343750238418579, "eval_episode/reward_rate": 0.018518518518518517}
{"step": 450008, "time": 14276.87578201294, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 450008, "time": 14277.093233346939, "eval_episode/length": 129.0, "eval_episode/score": 0.596875011920929, "eval_episode/reward_rate": 0.007692307692307693}
{"step": 450144, "time": 14281.446022510529, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 450728, "time": 14299.699901103973, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 450736, "time": 14300.171585321426, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 450880, "time": 14304.58337521553, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 451072, "time": 14310.424417257309, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 451232, "time": 14315.28872013092, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 451608, "time": 14326.70215845108, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 451880, "time": 14334.943523406982, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 452136, "time": 14342.740939378738, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 452264, "time": 14346.723403453827, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 452448, "time": 14352.512768268585, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 452656, "time": 14358.78184556961, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 453040, "time": 14370.449447631836, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 453048, "time": 14370.479545354843, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 453192, "time": 14374.835703372955, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 453352, "time": 14379.783557415009, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 453376, "time": 14380.733093976974, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 453384, "time": 14380.760779619217, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 454192, "time": 14405.476647615433, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 454576, "time": 14417.355395793915, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 454696, "time": 14420.78334236145, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 454720, "time": 14421.735519170761, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 454968, "time": 14429.02212882042, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 455088, "time": 14432.87471818924, "episode/length": 14.0, "episode/score": 0.956250011920929, "episode/reward_rate": 0.06666666666666667, "episode/intrinsic_return": 0.0}
{"step": 455360, "time": 14441.195807695389, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 455504, "time": 14445.588904380798, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 455664, "time": 14450.484027147293, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 455696, "time": 14451.46921491623, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 455992, "time": 14460.284823656082, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 456104, "time": 14463.725210666656, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 456376, "time": 14472.197178840637, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 456608, "time": 14479.528833389282, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 456760, "time": 14483.917189836502, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 456864, "time": 14487.298177719116, "episode/length": 285.0, "episode/score": 0.109375, "episode/reward_rate": 0.0034965034965034965, "episode/intrinsic_return": 0.0}
{"step": 456912, "time": 14488.759597301483, "episode/length": 18.0, "episode/score": 0.9437500238418579, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.0}
{"step": 457008, "time": 14491.641392707825, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 457032, "time": 14492.150218248367, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 457424, "time": 14504.339520692825, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 457472, "time": 14505.797307491302, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 457816, "time": 14516.016568183899, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 457976, "time": 14520.862542152405, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 458000, "time": 14521.815004348755, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 458288, "time": 14530.68864107132, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 458688, "time": 14542.814429044724, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 458920, "time": 14550.114050388336, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 459320, "time": 14562.419563055038, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 459448, "time": 14566.323119878769, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 459464, "time": 14566.814389705658, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 459736, "time": 14575.114585876465, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 459984, "time": 14582.890134096146, "episode/length": 270.0, "episode/score": 0.15625, "episode/reward_rate": 0.0036900369003690036, "episode/intrinsic_return": 0.0}
{"step": 460000, "time": 14583.377071142197, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 460080, "time": 14585.804151058197, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 460096, "time": 14586.840954303741, "eval_episode/length": 19.0, "eval_episode/score": 0.940625011920929, "eval_episode/reward_rate": 0.05}
{"step": 460096, "time": 14588.029212713242, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 460096, "time": 14588.171757936478, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 460096, "time": 14591.308827638626, "eval_episode/length": 156.0, "eval_episode/score": 0.512499988079071, "eval_episode/reward_rate": 0.006369426751592357}
{"step": 460096, "time": 14592.192725896835, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 460096, "time": 14592.202709197998, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 460096, "time": 14592.213238239288, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 460096, "time": 14592.224083662033, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 460096, "time": 14592.232744932175, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 460224, "time": 14596.226234674454, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 460288, "time": 14598.219936132431, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 460312, "time": 14598.729504108429, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 460600, "time": 14607.484010219574, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 461096, "time": 14622.52641582489, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 461280, "time": 14628.302653312683, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 461488, "time": 14634.628168821335, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 461656, "time": 14639.552548646927, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 462048, "time": 14651.8376121521, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 462088, "time": 14652.830740213394, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 462296, "time": 14659.126285552979, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 462296, "time": 14659.136761426926, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 462312, "time": 14659.633590698242, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 462392, "time": 14662.078110933304, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 462448, "time": 14664.014368772507, "episode/length": 16.0, "episode/score": 0.949999988079071, "episode/reward_rate": 0.058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 462600, "time": 14668.405257940292, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 462664, "time": 14670.35153746605, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 463344, "time": 14691.346059799194, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 463968, "time": 14710.260035037994, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 464200, "time": 14717.037645578384, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 464360, "time": 14721.861726284027, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 464400, "time": 14723.297364473343, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 464608, "time": 14729.674333810806, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 464704, "time": 14732.579252243042, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 464704, "time": 14732.599201202393, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 464760, "time": 14734.104835510254, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 464792, "time": 14735.075612545013, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 464912, "time": 14739.029855251312, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 465632, "time": 14760.864669799805, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 466280, "time": 14780.671203613281, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 466712, "time": 14794.0254509449, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 466872, "time": 14798.999989748001, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 466920, "time": 14800.477829694748, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 467016, "time": 14803.925017595291, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 467016, "time": 14803.937448978424, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 467104, "time": 14806.842574357986, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 467160, "time": 14808.369480848312, "episode/length": 280.0, "episode/score": 0.125, "episode/reward_rate": 0.0035587188612099642, "episode/intrinsic_return": 0.0}
{"step": 467208, "time": 14809.84002494812, "episode/length": 196.0, "episode/score": 0.38749998807907104, "episode/reward_rate": 0.005076142131979695, "episode/intrinsic_return": 0.0}
{"step": 467240, "time": 14810.815390825272, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 467440, "time": 14817.170544147491, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 467576, "time": 14821.083132505417, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 467584, "time": 14821.55262517929, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 467600, "time": 14822.043889284134, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 467912, "time": 14831.446183681488, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 468088, "time": 14836.796487092972, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 468192, "time": 14840.188108921051, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 468264, "time": 14842.16485786438, "episode/length": 21.0, "episode/score": 0.934374988079071, "episode/reward_rate": 0.045454545454545456, "episode/intrinsic_return": 0.0}
{"step": 468368, "time": 14845.564573049545, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 468576, "time": 14851.879358053207, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 468704, "time": 14855.761756420135, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 468952, "time": 14863.167172431946, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 469240, "time": 14871.895756483078, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 469472, "time": 14879.113935947418, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 469552, "time": 14881.55410528183, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 469752, "time": 14887.521809577942, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 469824, "time": 14889.923592329025, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 469888, "time": 14891.87559580803, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 469904, "time": 14892.361790895462, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 470080, "time": 14899.101818799973, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 470080, "time": 14899.407462596893, "eval_episode/length": 88.0, "eval_episode/score": 0.7250000238418579, "eval_episode/reward_rate": 0.011235955056179775}
{"step": 470080, "time": 14899.915618896484, "eval_episode/length": 112.0, "eval_episode/score": 0.6499999761581421, "eval_episode/reward_rate": 0.008849557522123894}
{"step": 470080, "time": 14900.877746343613, "eval_episode/length": 161.0, "eval_episode/score": 0.49687498807907104, "eval_episode/reward_rate": 0.006172839506172839}
{"step": 470080, "time": 14901.698427915573, "eval_episode/length": 112.0, "eval_episode/score": 0.6499999761581421, "eval_episode/reward_rate": 0.008849557522123894}
{"step": 470080, "time": 14901.969014406204, "eval_episode/length": 101.0, "eval_episode/score": 0.684374988079071, "eval_episode/reward_rate": 0.00980392156862745}
{"step": 470080, "time": 14903.101670742035, "eval_episode/length": 107.0, "eval_episode/score": 0.6656249761581421, "eval_episode/reward_rate": 0.009259259259259259}
{"step": 470080, "time": 14903.487518310547, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 470080, "time": 14903.51844406128, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 470080, "time": 14903.528341770172, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 470080, "time": 14903.54031586647, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 470184, "time": 14906.467989444733, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 470272, "time": 14909.364344835281, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 470416, "time": 14913.730165243149, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 470632, "time": 14920.187759399414, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 470680, "time": 14921.658261060715, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 470752, "time": 14924.0453145504, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 471016, "time": 14931.82375741005, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 471224, "time": 14938.113352298737, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 471264, "time": 14939.547375679016, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 471680, "time": 14952.362551689148, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 471984, "time": 14961.596930503845, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 472192, "time": 14967.896234750748, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 472200, "time": 14967.92424917221, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 472584, "time": 14979.703288316727, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 472728, "time": 14984.082939863205, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 472848, "time": 14987.992257118225, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 472992, "time": 14992.39349079132, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 473032, "time": 14993.396691322327, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0}
{"step": 473072, "time": 14994.854835748672, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 473096, "time": 14995.363651275635, "episode/length": 259.0, "episode/score": 0.19062499701976776, "episode/reward_rate": 0.0038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 473368, "time": 15003.633877515793, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 473432, "time": 15005.596517086029, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 473504, "time": 15008.097368001938, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 473576, "time": 15010.098046302795, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 473848, "time": 15018.316484212875, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 474000, "time": 15023.14690232277, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 474000, "time": 15023.155685901642, "episode/length": 224.0, "episode/score": 0.30000001192092896, "episode/reward_rate": 0.0044444444444444444, "episode/intrinsic_return": 0.0}
{"step": 474168, "time": 15028.054040670395, "episode/length": 272.0, "episode/score": 0.15000000596046448, "episode/reward_rate": 0.003663003663003663, "episode/intrinsic_return": 0.0}
{"step": 474192, "time": 15029.02218413353, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 474512, "time": 15038.804875612259, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 474616, "time": 15041.72444820404, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 474872, "time": 15049.473777770996, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 475104, "time": 15056.701273679733, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 475304, "time": 15063.019571304321, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 475344, "time": 15064.471857786179, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 475512, "time": 15069.491030931473, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 475816, "time": 15078.671216249466, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 475968, "time": 15083.501586914062, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 475984, "time": 15083.9913585186, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 476000, "time": 15084.47910785675, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 476160, "time": 15089.315880537033, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 476424, "time": 15097.269188642502, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 476440, "time": 15097.787330627441, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 476592, "time": 15102.696661233902, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 476656, "time": 15104.670669317245, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 476776, "time": 15108.160260677338, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 477184, "time": 15120.84384727478, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 477192, "time": 15120.871393918991, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 477360, "time": 15126.187836408615, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 477616, "time": 15134.050636529922, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 477640, "time": 15134.56396484375, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 477656, "time": 15135.050527572632, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 477824, "time": 15140.339496850967, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 478472, "time": 15159.939749002457, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 478552, "time": 15162.365907907486, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 478560, "time": 15162.832267045975, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 478592, "time": 15163.804428339005, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 478752, "time": 15168.632038354874, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 478752, "time": 15168.640408277512, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 479280, "time": 15184.555502176285, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 479432, "time": 15188.986008644104, "episode/length": 18.0, "episode/score": 0.9437500238418579, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.0}
{"step": 479504, "time": 15191.398647069931, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 479672, "time": 15196.297965049744, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 479872, "time": 15202.561687231064, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 480064, "time": 15209.345680475235, "eval_episode/length": 51.0, "eval_episode/score": 0.840624988079071, "eval_episode/reward_rate": 0.019230769230769232}
{"step": 480064, "time": 15209.655556678772, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 480064, "time": 15209.661969661713, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 480064, "time": 15209.880184412003, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 480064, "time": 15209.88741183281, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 480064, "time": 15210.113790273666, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 480064, "time": 15210.901590824127, "eval_episode/length": 42.0, "eval_episode/score": 0.8687499761581421, "eval_episode/reward_rate": 0.023255813953488372}
{"step": 480064, "time": 15211.370356798172, "eval_episode/length": 91.0, "eval_episode/score": 0.715624988079071, "eval_episode/reward_rate": 0.010869565217391304}
{"step": 480104, "time": 15212.361906766891, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 480304, "time": 15218.761261224747, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 480304, "time": 15218.768727064133, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 480592, "time": 15227.473772287369, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 480784, "time": 15233.303384780884, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 480904, "time": 15236.695979118347, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 480976, "time": 15239.106430768967, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 481064, "time": 15241.535597801208, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 481064, "time": 15241.542472362518, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 481160, "time": 15244.463061332703, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 481248, "time": 15247.48613023758, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0}
{"step": 481616, "time": 15258.617537021637, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 481689, "time": 15261.560782909393, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.3249822998046876, "train/action_min": 0.0, "train/action_std": 1.557855381965637, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.012192394685698674, "train/actor_opt_grad_steps": 29005.0, "train/actor_opt_loss": -9.210183941312135, "train/adv_mag": 1.0066391065716744, "train/adv_max": 0.3737642711400986, "train/adv_mean": 0.0008699077286655665, "train/adv_min": -0.9856368768215179, "train/adv_std": 0.04231644582003355, "train/cont_avg": 0.9955078125, "train/cont_loss_mean": 0.013986199782520999, "train/cont_loss_std": 0.21643944500945508, "train/cont_neg_acc": 0.41652580089867114, "train/cont_neg_loss": 2.5364483452506827, "train/cont_pos_acc": 0.9998577865958214, "train/cont_pos_loss": 0.0028101447253720837, "train/cont_pred": 0.9954918348789215, "train/cont_rate": 0.9955078125, "train/dyn_loss_mean": 1.0000033861398696, "train/dyn_loss_std": 9.816225807298906e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.4094274206273258, "train/extr_critic_critic_opt_grad_steps": 29005.0, "train/extr_critic_critic_opt_loss": 9481.726291503906, "train/extr_critic_mag": 1.1991916608810425, "train/extr_critic_max": 1.1991916608810425, "train/extr_critic_mean": 1.1361955994367599, "train/extr_critic_min": 0.943479740023613, "train/extr_critic_std": 0.017602484528906642, "train/extr_return_normed_mag": 0.9994099205732345, "train/extr_return_normed_max": 0.36310607731342315, "train/extr_return_normed_mean": 0.03306581381708384, "train/extr_return_normed_min": -0.9730145362019539, "train/extr_return_normed_std": 0.04665135606657714, "train/extr_return_rate": 0.9983864423632621, "train/extr_return_raw_mag": 1.4671057868003845, "train/extr_return_raw_max": 1.4671057868003845, "train/extr_return_raw_mean": 1.137065578699112, "train/extr_return_raw_min": 0.13098517328500747, "train/extr_return_raw_std": 0.04665135638322681, "train/extr_reward_mag": 0.40095859110355375, "train/extr_reward_max": 0.40095859110355375, "train/extr_reward_mean": 0.0025439611964975482, "train/extr_reward_min": 2.1517276763916015e-07, "train/extr_reward_std": 0.012631868285825475, "train/image_loss_mean": 0.0908769098483026, "train/image_loss_std": 0.09993343744426966, "train/model_loss_mean": 0.7128601199388505, "train/model_loss_std": 0.36712151050567626, "train/model_opt_grad_norm": 25.980037178993225, "train/model_opt_grad_steps": 28980.015, "train/model_opt_loss": 3651.9443627929686, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5125.0, "train/policy_entropy_mag": 1.370593972802162, "train/policy_entropy_max": 1.370593972802162, "train/policy_entropy_mean": 0.10846050098538398, "train/policy_entropy_min": 0.06468656122684478, "train/policy_entropy_std": 0.141130166426301, "train/policy_logprob_mag": 6.551080195903778, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.10855647776275873, "train/policy_logprob_min": -6.551080195903778, "train/policy_logprob_std": 0.6474579346179962, "train/policy_randomness_mag": 0.7043460100889206, "train/policy_randomness_max": 0.7043460100889206, "train/policy_randomness_mean": 0.0557376748509705, "train/policy_randomness_min": 0.03324231857433915, "train/policy_randomness_std": 0.07252656247466803, "train/post_ent_mag": 26.72680305480957, "train/post_ent_max": 26.72680305480957, "train/post_ent_mean": 26.408448514938353, "train/post_ent_min": 26.187259731292723, "train/post_ent_std": 0.1000325271114707, "train/prior_ent_mag": 26.657965173721312, "train/prior_ent_max": 26.657965173721312, "train/prior_ent_mean": 25.464935369491577, "train/prior_ent_min": 24.510523471832276, "train/prior_ent_std": 0.33536503165960313, "train/rep_loss_mean": 1.0000033861398696, "train/rep_loss_std": 9.816225807298906e-05, "train/reward_avg": 0.001067642212510691, "train/reward_loss_mean": 0.007994955239119007, "train/reward_loss_std": 0.15120059810695238, "train/reward_max_data": 0.6019687516242266, "train/reward_max_pred": 0.17781818449497222, "train/reward_neg_acc": 0.9997994866967201, "train/reward_neg_loss": 0.0014083679809118621, "train/reward_pos_acc": 0.22473794671724429, "train/reward_pos_loss": 4.216023199213375, "train/reward_pred": 0.0008731291838921607, "train/reward_rate": 0.0015478515625, "train_stats/mean_log_entropy": 0.08543534549002979, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.019867513328790665, "report/cont_loss_std": 0.26610884070396423, "report/cont_neg_acc": 0.4285714626312256, "report/cont_neg_loss": 2.271354913711548, "report/cont_pos_acc": 0.9990166425704956, "report/cont_pos_loss": 0.004370551090687513, "report/cont_pred": 0.9936467409133911, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.09704573452472687, "report/image_loss_std": 0.11301346123218536, "report/model_loss_mean": 0.7321893572807312, "report/model_loss_std": 0.49492666125297546, "report/post_ent_mag": 27.03567123413086, "report/post_ent_max": 27.03567123413086, "report/post_ent_mean": 26.712608337402344, "report/post_ent_min": 26.519681930541992, "report/post_ent_std": 0.1032780185341835, "report/prior_ent_mag": 27.460702896118164, "report/prior_ent_max": 27.460702896118164, "report/prior_ent_mean": 25.617015838623047, "report/prior_ent_min": 24.7801570892334, "report/prior_ent_std": 0.35622158646583557, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.002438354305922985, "report/reward_loss_mean": 0.01527606975287199, "report/reward_loss_std": 0.23604078590869904, "report/reward_max_data": 0.8843749761581421, "report/reward_max_pred": 0.5258709192276001, "report/reward_neg_acc": 0.999020516872406, "report/reward_neg_loss": 0.0028656702488660812, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.238948345184326, "report/reward_pred": 0.001148816430941224, "report/reward_rate": 0.0029296875, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.04335775226354599, "eval/cont_loss_std": 0.6367460489273071, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 8.681057929992676, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0009745368734002113, "eval/cont_pred": 0.9990248680114746, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.21966521441936493, "eval/image_loss_std": 0.16016320884227753, "eval/model_loss_mean": 0.8632254004478455, "eval/model_loss_std": 0.6522427201271057, "eval/post_ent_mag": 27.036766052246094, "eval/post_ent_max": 27.036766052246094, "eval/post_ent_mean": 26.67523956298828, "eval/post_ent_min": 26.461475372314453, "eval/post_ent_std": 0.10223887860774994, "eval/prior_ent_mag": 26.79897117614746, "eval/prior_ent_max": 26.79897117614746, "eval/prior_ent_mean": 25.551599502563477, "eval/prior_ent_min": 24.682289123535156, "eval/prior_ent_std": 0.3508455157279968, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00020242715254426003, "eval/reward_loss_std": 0.001160851796157658, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.008100271224975586, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00020242715254426003, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00010223360732197762, "eval/reward_rate": 0.0, "replay/size": 481185.0, "replay/inserts": 32112.0, "replay/samples": 32112.0, "replay/insert_wait_avg": 1.3408372220437089e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.922283721908623e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 6952.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1901723776094109e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0281801223754883e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3823971748352, "timer/env.step_count": 4014.0, "timer/env.step_total": 38.84571933746338, "timer/env.step_frac": 0.038830870522279265, "timer/env.step_avg": 0.00967755838003572, "timer/env.step_min": 0.007818222045898438, "timer/env.step_max": 0.035888671875, "timer/replay._sample_count": 32112.0, "timer/replay._sample_total": 17.124412059783936, "timer/replay._sample_frac": 0.017117866236096044, "timer/replay._sample_avg": 0.0005332714268741883, "timer/replay._sample_min": 0.00040793418884277344, "timer/replay._sample_max": 0.025002002716064453, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4883.0, "timer/agent.policy_total": 52.28917407989502, "timer/agent.policy_frac": 0.05226918649065006, "timer/agent.policy_avg": 0.010708411648555195, "timer/agent.policy_min": 0.008738279342651367, "timer/agent.policy_max": 0.08647346496582031, "timer/dataset_train_count": 2007.0, "timer/dataset_train_total": 0.22357940673828125, "timer/dataset_train_frac": 0.000223493943285776, "timer/dataset_train_avg": 0.00011139980405494831, "timer/dataset_train_min": 9.655952453613281e-05, "timer/dataset_train_max": 0.00036454200744628906, "timer/agent.train_count": 2007.0, "timer/agent.train_total": 894.6153292655945, "timer/agent.train_frac": 0.8942733616585659, "timer/agent.train_avg": 0.44574754821404805, "timer/agent.train_min": 0.43343067169189453, "timer/agent.train_max": 0.7029969692230225, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47173166275024414, "timer/agent.report_frac": 0.00047155134284894895, "timer/agent.report_avg": 0.23586583137512207, "timer/agent.report_min": 0.22875571250915527, "timer/agent.report_max": 0.24297595024108887, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.361701965332031e-05, "timer/dataset_eval_frac": 3.3604169513835536e-08, "timer/dataset_eval_avg": 3.361701965332031e-05, "timer/dataset_eval_min": 3.361701965332031e-05, "timer/dataset_eval_max": 3.361701965332031e-05, "fps": 32.09916928328032}
{"step": 481792, "time": 15264.696388721466, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 481816, "time": 15265.210658550262, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 482176, "time": 15276.421333789825, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 482416, "time": 15283.837518453598, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 482616, "time": 15289.705075025558, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 482616, "time": 15289.738117694855, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 482688, "time": 15292.15675830841, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 483216, "time": 15308.25713634491, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 483240, "time": 15308.76613664627, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 483280, "time": 15310.202167510986, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 483288, "time": 15310.231847047806, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 483304, "time": 15310.718116521835, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 483592, "time": 15319.984426021576, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 483928, "time": 15330.177641391754, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 484128, "time": 15336.49409198761, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 484200, "time": 15338.552741765976, "episode/length": 8.0, "episode/score": 0.9750000238418579, "episode/reward_rate": 0.1111111111111111, "episode/intrinsic_return": 0.0}
{"step": 484488, "time": 15347.32263636589, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 484792, "time": 15356.587267637253, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 484968, "time": 15361.948077440262, "episode/length": 21.0, "episode/score": 0.934374988079071, "episode/reward_rate": 0.045454545454545456, "episode/intrinsic_return": 0.0}
{"step": 485552, "time": 15380.046241044998, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 485592, "time": 15381.035771131516, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 485600, "time": 15381.506624937057, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 485616, "time": 15381.999798297882, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 485904, "time": 15390.797107934952, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 486120, "time": 15397.306227445602, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 486240, "time": 15401.198210000992, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 486304, "time": 15403.14121723175, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 486624, "time": 15412.855772256851, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 486800, "time": 15418.213483572006, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 486824, "time": 15418.728178739548, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 487040, "time": 15425.526847600937, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 487280, "time": 15432.938011407852, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 487440, "time": 15437.839137077332, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 487864, "time": 15450.59914112091, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 487904, "time": 15452.04219007492, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 487912, "time": 15452.104027986526, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 488304, "time": 15464.321937084198, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 488368, "time": 15466.262301206589, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 488584, "time": 15472.57237291336, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 488616, "time": 15473.57810330391, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 489112, "time": 15488.78222489357, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 489112, "time": 15488.800971031189, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 489288, "time": 15494.141202449799, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 489312, "time": 15495.093588590622, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 489352, "time": 15496.109282016754, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 489920, "time": 15513.649937868118, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 490048, "time": 15519.362673997879, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 490048, "time": 15519.403925418854, "eval_episode/length": 81.0, "eval_episode/score": 0.746874988079071, "eval_episode/reward_rate": 0.012195121951219513}
{"step": 490048, "time": 15521.364794254303, "eval_episode/length": 95.0, "eval_episode/score": 0.703125, "eval_episode/reward_rate": 0.010416666666666666}
{"step": 490048, "time": 15521.988342523575, "eval_episode/length": 104.0, "eval_episode/score": 0.675000011920929, "eval_episode/reward_rate": 0.009523809523809525}
{"step": 490048, "time": 15522.86189031601, "eval_episode/length": 42.0, "eval_episode/score": 0.8687499761581421, "eval_episode/reward_rate": 0.023255813953488372}
{"step": 490048, "time": 15523.808570623398, "eval_episode/length": 48.0, "eval_episode/score": 0.8500000238418579, "eval_episode/reward_rate": 0.02040816326530612}
{"step": 490048, "time": 15524.193345785141, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 490048, "time": 15524.206196308136, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 490048, "time": 15524.216841220856, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 490048, "time": 15524.227792739868, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 490048, "time": 15524.239030838013, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 490048, "time": 15524.248712778091, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 490096, "time": 15525.70955491066, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 490176, "time": 15528.145016908646, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 490208, "time": 15529.14471077919, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 490216, "time": 15529.17370223999, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 490680, "time": 15543.353022575378, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 490848, "time": 15548.7828707695, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 490856, "time": 15548.810233354568, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 490904, "time": 15550.292335987091, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 491232, "time": 15560.56473851204, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 491424, "time": 15566.439653635025, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 491424, "time": 15566.451154232025, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 491760, "time": 15577.192650318146, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 492040, "time": 15585.486762523651, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 492184, "time": 15589.86541056633, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 492208, "time": 15590.81346654892, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 492408, "time": 15596.634555339813, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 492488, "time": 15599.068936824799, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 492576, "time": 15601.93171095848, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 492792, "time": 15608.351417303085, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 493088, "time": 15617.499194383621, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 493168, "time": 15619.914217710495, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 493216, "time": 15621.371698379517, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 493224, "time": 15621.399903059006, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 493704, "time": 15635.881206989288, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 493936, "time": 15643.200110673904, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 494312, "time": 15654.388056755066, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 494352, "time": 15655.848036050797, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 494496, "time": 15660.23142695427, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 494800, "time": 15669.56651854515, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 494888, "time": 15672.058262109756, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 494896, "time": 15672.527253866196, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 495400, "time": 15687.740930557251, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 495416, "time": 15688.236211776733, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 495472, "time": 15690.180967569351, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 495480, "time": 15690.20936369896, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 495504, "time": 15691.156568050385, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 495984, "time": 15705.799578666687, "episode/length": 203.0, "episode/score": 0.3656249940395355, "episode/reward_rate": 0.004901960784313725, "episode/intrinsic_return": 0.0}
{"step": 496008, "time": 15706.308980464935, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 496016, "time": 15706.778812885284, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 496160, "time": 15711.175619363785, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 496240, "time": 15713.629343271255, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 496808, "time": 15730.848635911942, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 497320, "time": 15746.33455991745, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 497784, "time": 15760.43867444992, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 497792, "time": 15760.906517982483, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 498296, "time": 15775.938175201416, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 498320, "time": 15776.88261127472, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 498472, "time": 15781.253395080566, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 498552, "time": 15783.693370103836, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 498912, "time": 15795.005635976791, "episode/length": 198.0, "episode/score": 0.3812499940395355, "episode/reward_rate": 0.005025125628140704, "episode/intrinsic_return": 0.0}
{"step": 499120, "time": 15801.332653999329, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 499232, "time": 15804.736432552338, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 499360, "time": 15808.656793832779, "episode/length": 195.0, "episode/score": 0.390625, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.0}
{"step": 499608, "time": 15815.954934120178, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 499616, "time": 15816.452588319778, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 499992, "time": 15828.323233127594, "episode/length": 189.0, "episode/score": 0.40937501192092896, "episode/reward_rate": 0.005263157894736842, "episode/intrinsic_return": 0.0}
{"step": 500032, "time": 15831.158841609955, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 500032, "time": 15832.523564338684, "eval_episode/length": 135.0, "eval_episode/score": 0.578125, "eval_episode/reward_rate": 0.007352941176470588}
{"step": 500032, "time": 15833.277984380722, "eval_episode/length": 170.0, "eval_episode/score": 0.46875, "eval_episode/reward_rate": 0.005847953216374269}
{"step": 500032, "time": 15833.629324674606, "eval_episode/length": 119.0, "eval_episode/score": 0.628125011920929, "eval_episode/reward_rate": 0.008333333333333333}
{"step": 500032, "time": 15834.013920545578, "eval_episode/length": 208.0, "eval_episode/score": 0.3499999940395355, "eval_episode/reward_rate": 0.004784688995215311}
{"step": 500032, "time": 15834.66618514061, "eval_episode/length": 54.0, "eval_episode/score": 0.831250011920929, "eval_episode/reward_rate": 0.01818181818181818}
{"step": 500032, "time": 15835.521431207657, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 500032, "time": 15835.535696744919, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 500032, "time": 15835.543884515762, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 500032, "time": 15835.556987524033, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 500592, "time": 15852.66604423523, "episode/length": 209.0, "episode/score": 0.34687501192092896, "episode/reward_rate": 0.004761904761904762, "episode/intrinsic_return": 0.0}
{"step": 500632, "time": 15853.66413283348, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 500784, "time": 15858.510864019394, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 500832, "time": 15859.97379565239, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 501432, "time": 15878.085898160934, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 501544, "time": 15881.48368883133, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 501584, "time": 15882.93699336052, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 501672, "time": 15885.39382815361, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 501816, "time": 15889.769726753235, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 501904, "time": 15892.663190364838, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 502136, "time": 15899.441747426987, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 502304, "time": 15904.749691963196, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 502336, "time": 15905.720947742462, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 502592, "time": 15913.626717329025, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 502944, "time": 15924.369046211243, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 503000, "time": 15925.879691839218, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 503128, "time": 15929.76990890503, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 503448, "time": 15939.458695411682, "episode/length": 251.0, "episode/score": 0.21562500298023224, "episode/reward_rate": 0.003968253968253968, "episode/intrinsic_return": 0.0}
{"step": 503520, "time": 15941.860528230667, "episode/length": 201.0, "episode/score": 0.37187498807907104, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.0}
{"step": 503648, "time": 15945.735487222672, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 503664, "time": 15946.220605134964, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 503760, "time": 15949.102800130844, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 504096, "time": 15959.22232913971, "episode/length": 187.0, "episode/score": 0.4156250059604645, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.0}
{"step": 504128, "time": 15960.210842132568, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 504160, "time": 15961.170586109161, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 504448, "time": 15969.937638998032, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 504480, "time": 15970.905881404877, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 504696, "time": 15977.208643198013, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 504768, "time": 15979.635514259338, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 505440, "time": 16000.176578521729, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 505456, "time": 16000.664904117584, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 505464, "time": 16000.692659854889, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 505512, "time": 16002.139916658401, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 505704, "time": 16007.949536800385, "episode/length": 196.0, "episode/score": 0.38749998807907104, "episode/reward_rate": 0.005076142131979695, "episode/intrinsic_return": 0.0}
{"step": 505832, "time": 16011.867661714554, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 505872, "time": 16013.330684185028, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 506008, "time": 16017.245548248291, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 506240, "time": 16024.510325431824, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 506320, "time": 16027.046449899673, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 506504, "time": 16032.407382965088, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 506536, "time": 16033.417916297913, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 506576, "time": 16034.863187789917, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 506672, "time": 16037.785639762878, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 506712, "time": 16038.786128520966, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 506984, "time": 16047.013545274734, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 507016, "time": 16048.018562555313, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 507544, "time": 16064.17013669014, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 507592, "time": 16065.629846096039, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 507688, "time": 16068.580447912216, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 507768, "time": 16071.02292919159, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 508248, "time": 16086.127004384995, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 508312, "time": 16088.226979255676, "episode/length": 199.0, "episode/score": 0.37812501192092896, "episode/reward_rate": 0.005, "episode/intrinsic_return": 0.0}
{"step": 508432, "time": 16092.124083518982, "episode/length": 219.0, "episode/score": 0.31562501192092896, "episode/reward_rate": 0.004545454545454545, "episode/intrinsic_return": 0.0}
{"step": 508672, "time": 16099.45771241188, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 508712, "time": 16100.466178655624, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 508888, "time": 16105.900770187378, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 508888, "time": 16105.910024881363, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 508904, "time": 16106.417717218399, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 509296, "time": 16118.802865743637, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 509328, "time": 16119.796350717545, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 509568, "time": 16127.13056898117, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 509776, "time": 16133.439195156097, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 509856, "time": 16135.85048866272, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 509984, "time": 16139.74683880806, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 510016, "time": 16141.63230252266, "eval_episode/length": 46.0, "eval_episode/score": 0.856249988079071, "eval_episode/reward_rate": 0.02127659574468085}
{"step": 510016, "time": 16142.692688941956, "eval_episode/length": 102.0, "eval_episode/score": 0.6812499761581421, "eval_episode/reward_rate": 0.009708737864077669}
{"step": 510016, "time": 16142.717740774155, "eval_episode/length": 103.0, "eval_episode/score": 0.6781250238418579, "eval_episode/reward_rate": 0.009615384615384616}
{"step": 510016, "time": 16143.393227100372, "eval_episode/length": 138.0, "eval_episode/score": 0.5687500238418579, "eval_episode/reward_rate": 0.007194244604316547}
{"step": 510016, "time": 16143.495478868484, "eval_episode/length": 143.0, "eval_episode/score": 0.5531250238418579, "eval_episode/reward_rate": 0.006944444444444444}
{"step": 510016, "time": 16143.556494474411, "eval_episode/length": 96.0, "eval_episode/score": 0.699999988079071, "eval_episode/reward_rate": 0.010309278350515464}
{"step": 510016, "time": 16143.818003416061, "eval_episode/length": 53.0, "eval_episode/score": 0.8343750238418579, "eval_episode/reward_rate": 0.018518518518518517}
{"step": 510016, "time": 16144.869399309158, "eval_episode/length": 108.0, "eval_episode/score": 0.6625000238418579, "eval_episode/reward_rate": 0.009174311926605505}
{"step": 510056, "time": 16145.897939682007, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 510080, "time": 16146.967419862747, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 510176, "time": 16149.8973133564, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 510200, "time": 16150.433128595352, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 510240, "time": 16151.898164272308, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 510544, "time": 16161.21206331253, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 511136, "time": 16179.32470202446, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 511152, "time": 16179.840569257736, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 511736, "time": 16197.47656083107, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 512016, "time": 16206.25661277771, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 512032, "time": 16206.852149009705, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 512168, "time": 16210.811390399933, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 512368, "time": 16217.127791881561, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 512392, "time": 16217.641593694687, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 512552, "time": 16222.57302069664, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 512672, "time": 16226.490757465363, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 512800, "time": 16230.409697532654, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 512856, "time": 16231.89207148552, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 512984, "time": 16235.831286907196, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 512992, "time": 16236.300995349884, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 513232, "time": 16243.718669652939, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 513288, "time": 16245.201381444931, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 513392, "time": 16248.590540885925, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 513528, "time": 16252.492887735367, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 513528, "time": 16252.502555847168, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 513712, "time": 16258.350481271744, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0}
{"step": 513801, "time": 16261.799194335938, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.4010893408931904, "train/action_min": 0.0, "train/action_std": 1.6233983449081877, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.012988154353592452, "train/actor_opt_grad_steps": 31010.0, "train/actor_opt_loss": -9.171550608893384, "train/adv_mag": 1.0018714194867149, "train/adv_max": 0.4100966281558744, "train/adv_mean": 0.0022077411301745713, "train/adv_min": -0.9865600015986619, "train/adv_std": 0.04537208340784062, "train/cont_avg": 0.9953066697761194, "train/cont_loss_mean": 0.014841132822784767, "train/cont_loss_std": 0.21853239560008642, "train/cont_neg_acc": 0.3978125312138553, "train/cont_neg_loss": 2.4797947879994187, "train/cont_pos_acc": 0.9998731112005699, "train/cont_pos_loss": 0.002982635853466907, "train/cont_pred": 0.9952995163291248, "train/cont_rate": 0.9953066697761194, "train/dyn_loss_mean": 1.0000052226716607, "train/dyn_loss_std": 0.00016704810359306744, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.42337687754660697, "train/extr_critic_critic_opt_grad_steps": 31010.0, "train/extr_critic_critic_opt_loss": 8753.863950511117, "train/extr_critic_mag": 1.2249650041855389, "train/extr_critic_max": 1.2249650041855389, "train/extr_critic_mean": 1.145135593058458, "train/extr_critic_min": 0.9941010125240877, "train/extr_critic_std": 0.018503467496762526, "train/extr_return_normed_mag": 0.9870436719400966, "train/extr_return_normed_max": 0.43363798020490957, "train/extr_return_normed_mean": 0.04309392800156157, "train/extr_return_normed_min": -0.9659366174716855, "train/extr_return_normed_std": 0.05010480880829973, "train/extr_return_rate": 0.9986458162763225, "train/extr_return_raw_mag": 1.5378873460921483, "train/extr_return_raw_max": 1.5378873460921483, "train/extr_return_raw_mean": 1.147343355031749, "train/extr_return_raw_min": 0.13831274841555316, "train/extr_return_raw_std": 0.05010480870173049, "train/extr_reward_mag": 0.4400284895256384, "train/extr_reward_max": 0.4400284895256384, "train/extr_reward_mean": 0.0026251137973648028, "train/extr_reward_min": 4.815818065434546e-07, "train/extr_reward_std": 0.01452805484825773, "train/image_loss_mean": 0.09051952340561359, "train/image_loss_std": 0.10022836137766862, "train/model_loss_mean": 0.7152968570960695, "train/model_loss_std": 0.3928566424185364, "train/model_opt_grad_norm": 25.767377967265116, "train/model_opt_grad_steps": 30983.064676616916, "train/model_opt_loss": 3647.644780249145, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5099.502487562189, "train/policy_entropy_mag": 1.3453258074338164, "train/policy_entropy_max": 1.3453258074338164, "train/policy_entropy_mean": 0.11013502516408465, "train/policy_entropy_min": 0.06468651380705003, "train/policy_entropy_std": 0.14112197403884053, "train/policy_logprob_mag": 6.55108023638749, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.1097868194256849, "train/policy_logprob_min": -6.55108023638749, "train/policy_logprob_std": 0.6465185340957262, "train/policy_randomness_mag": 0.6913607420019843, "train/policy_randomness_max": 0.6913607420019843, "train/policy_randomness_mean": 0.05659821049416836, "train/policy_randomness_min": 0.03324229374008985, "train/policy_randomness_std": 0.0725223526395672, "train/post_ent_mag": 26.9011905157744, "train/post_ent_max": 26.9011905157744, "train/post_ent_mean": 26.56092489062257, "train/post_ent_min": 26.327485829443482, "train/post_ent_std": 0.1077847772124988, "train/prior_ent_mag": 27.003003201081384, "train/prior_ent_max": 27.003003201081384, "train/prior_ent_mean": 25.745797275903808, "train/prior_ent_min": 24.6821374845742, "train/prior_ent_std": 0.3695734106189576, "train/rep_loss_mean": 1.0000052226716607, "train/rep_loss_std": 0.00016704810359306744, "train/reward_avg": 0.0013778762393358826, "train/reward_loss_mean": 0.00993304392114393, "train/reward_loss_std": 0.17737601747022785, "train/reward_max_data": 0.6805348272495602, "train/reward_max_pred": 0.22699529436690297, "train/reward_neg_acc": 0.9996980464280542, "train/reward_neg_loss": 0.0016761165539692364, "train/reward_pos_acc": 0.2355125122993006, "train/reward_pos_loss": 4.184678283114891, "train/reward_pred": 0.0010752548626971556, "train/reward_rate": 0.0020162857587064675, "train_stats/mean_log_entropy": 0.09432951760633539, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.022709494456648827, "report/cont_loss_std": 0.3180607259273529, "report/cont_neg_acc": 0.2857142984867096, "report/cont_neg_loss": 3.0409209728240967, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0019351789960637689, "report/cont_pred": 0.9959613084793091, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.10497019439935684, "report/image_loss_std": 0.12335847318172455, "report/model_loss_mean": 0.7404772043228149, "report/model_loss_std": 0.5126499533653259, "report/post_ent_mag": 26.699050903320312, "report/post_ent_max": 26.699050903320312, "report/post_ent_mean": 26.35138702392578, "report/post_ent_min": 26.112045288085938, "report/post_ent_std": 0.10934633761644363, "report/prior_ent_mag": 26.761306762695312, "report/prior_ent_max": 26.761306762695312, "report/prior_ent_mean": 25.724876403808594, "report/prior_ent_min": 25.02172088623047, "report/prior_ent_std": 0.2945711612701416, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.002349853515625, "report/reward_loss_mean": 0.012797482311725616, "report/reward_loss_std": 0.21730273962020874, "report/reward_max_data": 0.862500011920929, "report/reward_max_pred": 0.14613676071166992, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0016587742138653994, "report/reward_pos_acc": 0.3333333432674408, "report/reward_pos_loss": 3.803670883178711, "report/reward_pred": 0.0010165649000555277, "report/reward_rate": 0.0029296875, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.033335037529468536, "eval/cont_loss_std": 0.5766821503639221, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 10.311359405517578, "eval/cont_pos_acc": 0.999020516872406, "eval/cont_pos_loss": 0.0031351668294519186, "eval/cont_pred": 0.9981476664543152, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.20365175604820251, "eval/image_loss_std": 0.1488793045282364, "eval/model_loss_mean": 0.8371284604072571, "eval/model_loss_std": 0.6043543815612793, "eval/post_ent_mag": 26.698299407958984, "eval/post_ent_max": 26.698299407958984, "eval/post_ent_mean": 26.325511932373047, "eval/post_ent_min": 26.127031326293945, "eval/post_ent_std": 0.10589027404785156, "eval/prior_ent_mag": 26.761306762695312, "eval/prior_ent_max": 26.761306762695312, "eval/prior_ent_mean": 25.72677230834961, "eval/prior_ent_min": 25.0313720703125, "eval/prior_ent_std": 0.2921310365200043, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0001416616141796112, "eval/reward_loss_std": 0.0008989537600427866, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.008240103721618652, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0001416616141796112, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 7.11195170879364e-05, "eval/reward_rate": 0.0, "replay/size": 513297.0, "replay/inserts": 32112.0, "replay/samples": 32112.0, "replay/insert_wait_avg": 1.353949055959172e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.747081926704107e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 6328.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1866297643495118e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1771917343139648e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2214515209198, "timer/env.step_count": 4014.0, "timer/env.step_total": 38.84972810745239, "timer/env.step_frac": 0.03884112668087467, "timer/env.step_avg": 0.009678557077093272, "timer/env.step_min": 0.007722139358520508, "timer/env.step_max": 0.03631711006164551, "timer/replay._sample_count": 32112.0, "timer/replay._sample_total": 17.13568925857544, "timer/replay._sample_frac": 0.017131895374288563, "timer/replay._sample_avg": 0.0005336226101948007, "timer/replay._sample_min": 0.00041604042053222656, "timer/replay._sample_max": 0.024904251098632812, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4805.0, "timer/agent.policy_total": 51.613900661468506, "timer/agent.policy_frac": 0.05160247321529176, "timer/agent.policy_avg": 0.010741706693333715, "timer/agent.policy_min": 0.009122610092163086, "timer/agent.policy_max": 0.0932455062866211, "timer/dataset_train_count": 2007.0, "timer/dataset_train_total": 0.22307562828063965, "timer/dataset_train_frac": 0.0002230262387808566, "timer/dataset_train_avg": 0.00011114879336354741, "timer/dataset_train_min": 9.608268737792969e-05, "timer/dataset_train_max": 0.0003349781036376953, "timer/agent.train_count": 2007.0, "timer/agent.train_total": 895.6264190673828, "timer/agent.train_frac": 0.8954281251471946, "timer/agent.train_avg": 0.4462513298791145, "timer/agent.train_min": 0.434312105178833, "timer/agent.train_max": 0.7235689163208008, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4746992588043213, "timer/agent.report_frac": 0.00047459415920594547, "timer/agent.report_avg": 0.23734962940216064, "timer/agent.report_min": 0.22952055931091309, "timer/agent.report_max": 0.2451786994934082, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.147125244140625e-05, "timer/dataset_eval_frac": 3.1464284627720785e-08, "timer/dataset_eval_avg": 3.147125244140625e-05, "timer/dataset_eval_min": 3.147125244140625e-05, "timer/dataset_eval_max": 3.147125244140625e-05, "fps": 32.10433421823099}
{"step": 513912, "time": 16264.97474360466, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 514056, "time": 16269.453755617142, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 514112, "time": 16271.373508691788, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 514264, "time": 16275.772909879684, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 514312, "time": 16277.220665931702, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 514544, "time": 16284.510434865952, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 514616, "time": 16286.480660676956, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 514632, "time": 16286.96983242035, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 514696, "time": 16288.936937570572, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 514752, "time": 16290.864218235016, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 514776, "time": 16291.389459848404, "episode/length": 239.0, "episode/score": 0.25312501192092896, "episode/reward_rate": 0.004166666666666667, "episode/intrinsic_return": 0.0}
{"step": 515048, "time": 16299.828022003174, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 515232, "time": 16305.633209466934, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 515256, "time": 16306.146974802017, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 515464, "time": 16312.483516454697, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 515544, "time": 16314.93476653099, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 515784, "time": 16322.193834543228, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 515968, "time": 16328.140641450882, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 516616, "time": 16348.142997980118, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 516760, "time": 16352.539612293243, "episode/length": 250.0, "episode/score": 0.21875, "episode/reward_rate": 0.00398406374501992, "episode/intrinsic_return": 0.0}
{"step": 516928, "time": 16358.026806592941, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 516944, "time": 16358.518644809723, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 517008, "time": 16360.46181678772, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 517304, "time": 16369.196417093277, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 517360, "time": 16371.111436128616, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 517424, "time": 16373.082444667816, "episode/length": 204.0, "episode/score": 0.36250001192092896, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.0}
{"step": 517640, "time": 16379.425540447235, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 517688, "time": 16380.885344028473, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 517712, "time": 16381.86159992218, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 517888, "time": 16387.34183382988, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 518120, "time": 16394.20589542389, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 518144, "time": 16395.17546224594, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 518176, "time": 16396.176777362823, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 518200, "time": 16396.718527317047, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 518280, "time": 16399.166449785233, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 518304, "time": 16400.12273335457, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 518400, "time": 16403.085433721542, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 518608, "time": 16409.440478801727, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 519184, "time": 16427.033806324005, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 519296, "time": 16430.413846492767, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 519320, "time": 16430.940933942795, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 519640, "time": 16440.64684510231, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 519712, "time": 16443.045577287674, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 519952, "time": 16450.45240020752, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 520000, "time": 16452.357221603394, "eval_episode/length": 22.0, "eval_episode/score": 0.9312499761581421, "eval_episode/reward_rate": 0.043478260869565216}
{"step": 520000, "time": 16453.27736377716, "eval_episode/length": 70.0, "eval_episode/score": 0.78125, "eval_episode/reward_rate": 0.014084507042253521}
{"step": 520000, "time": 16453.615339756012, "eval_episode/length": 87.0, "eval_episode/score": 0.7281249761581421, "eval_episode/reward_rate": 0.011363636363636364}
{"step": 520000, "time": 16454.219820022583, "eval_episode/length": 117.0, "eval_episode/score": 0.6343749761581421, "eval_episode/reward_rate": 0.00847457627118644}
{"step": 520000, "time": 16454.30501818657, "eval_episode/length": 33.0, "eval_episode/score": 0.8968750238418579, "eval_episode/reward_rate": 0.029411764705882353}
{"step": 520000, "time": 16454.42867231369, "eval_episode/length": 127.0, "eval_episode/score": 0.6031249761581421, "eval_episode/reward_rate": 0.0078125}
{"step": 520000, "time": 16454.57151198387, "eval_episode/length": 63.0, "eval_episode/score": 0.8031250238418579, "eval_episode/reward_rate": 0.015625}
{"step": 520000, "time": 16454.830540895462, "eval_episode/length": 147.0, "eval_episode/score": 0.5406249761581421, "eval_episode/reward_rate": 0.006756756756756757}
{"step": 520056, "time": 16456.31657767296, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 520440, "time": 16467.99901151657, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 520456, "time": 16468.492695331573, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 520488, "time": 16469.46591448784, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 520616, "time": 16473.363102436066, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 520920, "time": 16482.684091091156, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 521088, "time": 16488.034677028656, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 521128, "time": 16489.027588367462, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 521376, "time": 16496.749895334244, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 521424, "time": 16498.215660333633, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 521776, "time": 16508.971366405487, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 521912, "time": 16512.927686452866, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 521944, "time": 16513.907702445984, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 521952, "time": 16514.379243850708, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 521952, "time": 16514.387768268585, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 522024, "time": 16516.355532169342, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 522144, "time": 16520.248491048813, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 522288, "time": 16524.635981082916, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 522360, "time": 16526.618246793747, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 522888, "time": 16542.668587207794, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 522968, "time": 16545.078823804855, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 523104, "time": 16549.412847995758, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 523296, "time": 16555.22205901146, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 523440, "time": 16559.59265089035, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 523656, "time": 16566.03272509575, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 523728, "time": 16568.504189491272, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 523864, "time": 16572.481345415115, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 524264, "time": 16584.656907320023, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 524368, "time": 16588.534749507904, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 524456, "time": 16590.991627454758, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 524480, "time": 16591.944217681885, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 524824, "time": 16602.215169668198, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 525080, "time": 16609.982941627502, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 525280, "time": 16616.257411003113, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 525368, "time": 16618.695685863495, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 525608, "time": 16625.970456838608, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 525640, "time": 16627.047401428223, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 525736, "time": 16629.962413549423, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 526040, "time": 16639.153475522995, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 526040, "time": 16639.16355586052, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 526128, "time": 16642.047161579132, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 526248, "time": 16645.475048065186, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 526576, "time": 16655.654651641846, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 526768, "time": 16661.68496632576, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 526792, "time": 16662.194328308105, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 526840, "time": 16663.668330669403, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 526896, "time": 16665.582475185394, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 527032, "time": 16669.491681098938, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 527120, "time": 16672.359728574753, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 527184, "time": 16674.317286014557, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 527392, "time": 16680.617250442505, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 527416, "time": 16681.128374814987, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 527440, "time": 16682.079607248306, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 527456, "time": 16682.569035053253, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 527704, "time": 16689.97619652748, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 527784, "time": 16692.403897047043, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 527936, "time": 16697.261838674545, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 528384, "time": 16710.877171754837, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 528760, "time": 16722.207377910614, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 529032, "time": 16730.40894794464, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 529112, "time": 16732.847760677338, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 529432, "time": 16742.541888713837, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 529704, "time": 16750.907568216324, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 529752, "time": 16752.38049674034, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 529768, "time": 16752.871833324432, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 529864, "time": 16755.791680336, "episode/length": 11.0, "episode/score": 0.965624988079071, "episode/reward_rate": 0.08333333333333333, "episode/intrinsic_return": 0.0}
{"step": 529872, "time": 16756.286502838135, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 529920, "time": 16757.747534513474, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 530088, "time": 16763.286623716354, "eval_episode/length": 28.0, "eval_episode/score": 0.9125000238418579, "eval_episode/reward_rate": 0.034482758620689655}
{"step": 530088, "time": 16763.44787120819, "eval_episode/length": 36.0, "eval_episode/score": 0.887499988079071, "eval_episode/reward_rate": 0.02702702702702703}
{"step": 530088, "time": 16763.88996577263, "eval_episode/length": 60.0, "eval_episode/score": 0.8125, "eval_episode/reward_rate": 0.01639344262295082}
{"step": 530088, "time": 16764.07404923439, "eval_episode/length": 70.0, "eval_episode/score": 0.78125, "eval_episode/reward_rate": 0.014084507042253521}
{"step": 530088, "time": 16764.69172024727, "eval_episode/length": 102.0, "eval_episode/score": 0.6812499761581421, "eval_episode/reward_rate": 0.009708737864077669}
{"step": 530088, "time": 16765.20719408989, "eval_episode/length": 128.0, "eval_episode/score": 0.6000000238418579, "eval_episode/reward_rate": 0.007751937984496124}
{"step": 530088, "time": 16765.234902381897, "eval_episode/length": 58.0, "eval_episode/score": 0.8187500238418579, "eval_episode/reward_rate": 0.01694915254237288}
{"step": 530088, "time": 16765.906185388565, "eval_episode/length": 103.0, "eval_episode/score": 0.6781250238418579, "eval_episode/reward_rate": 0.009615384615384616}
{"step": 530096, "time": 16766.375409841537, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 530520, "time": 16779.081309318542, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 530696, "time": 16784.415006160736, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 530872, "time": 16789.833648443222, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 531200, "time": 16800.040091991425, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 531392, "time": 16805.866188764572, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 531712, "time": 16815.64863562584, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 531744, "time": 16816.619010448456, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 531880, "time": 16820.515144109726, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 531952, "time": 16822.931592941284, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 532064, "time": 16826.31422662735, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 532176, "time": 16829.715359926224, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 532400, "time": 16836.496030330658, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 532408, "time": 16836.552455425262, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 532416, "time": 16837.05177474022, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 532440, "time": 16837.582380771637, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 532912, "time": 16852.509020090103, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 533040, "time": 16856.36653804779, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 533248, "time": 16862.675999879837, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 533304, "time": 16864.148478746414, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 533936, "time": 16883.687043905258, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 533936, "time": 16883.699115991592, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 534024, "time": 16886.172532320023, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 534056, "time": 16887.170905828476, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 534112, "time": 16889.11991906166, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 534376, "time": 16897.075273513794, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 534688, "time": 16906.837861299515, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 534720, "time": 16907.82121706009, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 534728, "time": 16907.848894119263, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 534736, "time": 16908.322627067566, "episode/length": 5.0, "episode/score": 0.984375, "episode/reward_rate": 0.16666666666666666, "episode/intrinsic_return": 0.0}
{"step": 534752, "time": 16908.8159866333, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 534920, "time": 16913.717265605927, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 535192, "time": 16922.104677915573, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 535232, "time": 16923.551050186157, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 535320, "time": 16926.04848384857, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 535560, "time": 16933.45127105713, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 535664, "time": 16936.847494363785, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 535984, "time": 16946.64644908905, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 536024, "time": 16947.64949440956, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 536248, "time": 16954.45964694023, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 536248, "time": 16954.469102859497, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 536464, "time": 16961.393992185593, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 536608, "time": 16965.79513525963, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 536928, "time": 16975.495881795883, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 537096, "time": 16980.379537582397, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 537544, "time": 16994.116017341614, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 537600, "time": 16996.09041285515, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 537632, "time": 16997.070597410202, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 537688, "time": 16998.554111242294, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 537896, "time": 17004.92722606659, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 537928, "time": 17005.90624141693, "episode/length": 182.0, "episode/score": 0.4312500059604645, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.0}
{"step": 538336, "time": 17018.76580429077, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 538376, "time": 17019.78044295311, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 538512, "time": 17024.1585354805, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 538552, "time": 17025.15417790413, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 538560, "time": 17025.628995656967, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 538880, "time": 17035.382583379745, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 538928, "time": 17036.85232901573, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 538952, "time": 17037.36751818657, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 539280, "time": 17047.69917368889, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 539288, "time": 17047.728440999985, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 539376, "time": 17050.63404393196, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 539408, "time": 17051.61196899414, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 539512, "time": 17054.568926095963, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 539944, "time": 17067.78760242462, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 540024, "time": 17070.240707874298, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 540064, "time": 17071.675071954727, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 540072, "time": 17072.63292980194, "eval_episode/length": 45.0, "eval_episode/score": 0.859375, "eval_episode/reward_rate": 0.021739130434782608}
{"step": 540072, "time": 17073.564774513245, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 540072, "time": 17073.59186220169, "eval_episode/length": 93.0, "eval_episode/score": 0.7093750238418579, "eval_episode/reward_rate": 0.010638297872340425}
{"step": 540072, "time": 17073.734139442444, "eval_episode/length": 100.0, "eval_episode/score": 0.6875, "eval_episode/reward_rate": 0.009900990099009901}
{"step": 540072, "time": 17074.092559576035, "eval_episode/length": 104.0, "eval_episode/score": 0.675000011920929, "eval_episode/reward_rate": 0.009523809523809525}
{"step": 540072, "time": 17074.91642165184, "eval_episode/length": 129.0, "eval_episode/score": 0.596875011920929, "eval_episode/reward_rate": 0.007692307692307693}
{"step": 540072, "time": 17075.26831316948, "eval_episode/length": 147.0, "eval_episode/score": 0.5406249761581421, "eval_episode/reward_rate": 0.006756756756756757}
{"step": 540072, "time": 17075.96272444725, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 540088, "time": 17076.477994441986, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 540208, "time": 17080.43042230606, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 540240, "time": 17081.402256011963, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 540312, "time": 17083.39102959633, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 540496, "time": 17089.272709846497, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 540944, "time": 17103.37042784691, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 540960, "time": 17103.864400863647, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 541264, "time": 17113.36605978012, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 541280, "time": 17113.85545730591, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 541344, "time": 17115.800167798996, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 541528, "time": 17121.184423923492, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 541632, "time": 17124.589585781097, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 541768, "time": 17128.508422851562, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 542168, "time": 17140.79603290558, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 542176, "time": 17141.26740837097, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 542336, "time": 17147.655970335007, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 542552, "time": 17154.024072170258, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 542552, "time": 17154.03271007538, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 542624, "time": 17156.446214437485, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 542952, "time": 17166.250591039658, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 543024, "time": 17168.77286887169, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 543096, "time": 17170.729964494705, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 543136, "time": 17172.177807569504, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 543256, "time": 17175.66213941574, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 543304, "time": 17177.121707439423, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 543320, "time": 17177.63335633278, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 543776, "time": 17191.816456079483, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 543832, "time": 17193.309972047806, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 543880, "time": 17194.76002597809, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 543912, "time": 17195.727429389954, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 544432, "time": 17211.860586166382, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 544488, "time": 17213.341814041138, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 544496, "time": 17213.813811540604, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 544864, "time": 17224.995006084442, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 544904, "time": 17225.992817640305, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 544928, "time": 17227.087911367416, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 545128, "time": 17232.94983649254, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 545360, "time": 17240.23481273651, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 545568, "time": 17246.6138150692, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 545608, "time": 17247.62234377861, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 545816, "time": 17253.944674253464, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 546008, "time": 17259.879190206528, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 546041, "time": 17261.865201711655, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.4589348217048266, "train/action_min": 0.0, "train/action_std": 1.7139485643641783, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.01357877507602962, "train/actor_opt_grad_steps": 33025.0, "train/actor_opt_loss": -10.65238535002169, "train/adv_mag": 1.0164675084081027, "train/adv_max": 0.41076642746972564, "train/adv_mean": 0.0011374569296662015, "train/adv_min": -0.995920333236751, "train/adv_std": 0.038699758439647534, "train/cont_avg": 0.995184870049505, "train/cont_loss_mean": 0.01496115387970637, "train/cont_loss_std": 0.2170181988881403, "train/cont_neg_acc": 0.41248430319093354, "train/cont_neg_loss": 2.4296113691279384, "train/cont_pos_acc": 0.9998202188180225, "train/cont_pos_loss": 0.0031897188677212757, "train/cont_pred": 0.9950738248258534, "train/cont_rate": 0.995184870049505, "train/dyn_loss_mean": 1.0000182354804312, "train/dyn_loss_std": 0.000583249241572048, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.271596528884798, "train/extr_critic_critic_opt_grad_steps": 33025.0, "train/extr_critic_critic_opt_loss": 5238.307259436881, "train/extr_critic_mag": 1.2530710107029075, "train/extr_critic_max": 1.2530710107029075, "train/extr_critic_mean": 1.1772130745472293, "train/extr_critic_min": 0.949019453903236, "train/extr_critic_std": 0.01842116749854666, "train/extr_return_normed_mag": 1.0121475086353793, "train/extr_return_normed_max": 0.36856772344891386, "train/extr_return_normed_mean": 0.0361669112531708, "train/extr_return_normed_min": -0.9892241984310717, "train/extr_return_normed_std": 0.04367994959696685, "train/extr_return_rate": 0.9987791826819429, "train/extr_return_raw_mag": 1.5107513052402157, "train/extr_return_raw_max": 1.5107513052402157, "train/extr_return_raw_mean": 1.1783505518837731, "train/extr_return_raw_min": 0.1529593833602301, "train/extr_return_raw_std": 0.04367994956008279, "train/extr_reward_mag": 0.39297490780896477, "train/extr_reward_max": 0.39297490780896477, "train/extr_reward_mean": 0.0022775288538703013, "train/extr_reward_min": 3.6825047861231437e-07, "train/extr_reward_std": 0.01082996676427008, "train/image_loss_mean": 0.08709928065095798, "train/image_loss_std": 0.09924734269480893, "train/model_loss_mean": 0.7119541507546264, "train/model_loss_std": 0.38614175966618086, "train/model_opt_grad_norm": 23.783297954219403, "train/model_opt_grad_steps": 32996.12871287129, "train/model_opt_loss": 3682.1816309560645, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5198.019801980198, "train/policy_entropy_mag": 1.3758594676999762, "train/policy_entropy_max": 1.3758594676999762, "train/policy_entropy_mean": 0.11946706990204235, "train/policy_entropy_min": 0.06468652664582328, "train/policy_entropy_std": 0.15601850422744704, "train/policy_logprob_mag": 6.551080236340513, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.11992786297261125, "train/policy_logprob_min": -6.551080236340513, "train/policy_logprob_std": 0.6581307478470377, "train/policy_randomness_mag": 0.7070519419589846, "train/policy_randomness_max": 0.7070519419589846, "train/policy_randomness_mean": 0.06139393259614411, "train/policy_randomness_min": 0.03324230085357581, "train/policy_randomness_std": 0.08017765553575931, "train/post_ent_mag": 27.09972326826341, "train/post_ent_max": 27.09972326826341, "train/post_ent_mean": 26.700256942522408, "train/post_ent_min": 26.4353127621188, "train/post_ent_std": 0.12432072890719564, "train/prior_ent_mag": 27.08632479563798, "train/prior_ent_max": 27.08632479563798, "train/prior_ent_mean": 25.64382794823977, "train/prior_ent_min": 24.769698718986888, "train/prior_ent_std": 0.3581762930544296, "train/rep_loss_mean": 1.0000182354804312, "train/rep_loss_std": 0.000583249241572048, "train/reward_avg": 0.0013486201242263669, "train/reward_loss_mean": 0.009882748775912614, "train/reward_loss_std": 0.1667123889477951, "train/reward_max_data": 0.6344987640138899, "train/reward_max_pred": 0.21332301184682562, "train/reward_neg_acc": 0.9996995760662721, "train/reward_neg_loss": 0.001834227406422119, "train/reward_pos_acc": 0.22735226764736405, "train/reward_pos_loss": 4.059580266116614, "train/reward_pred": 0.0011138339638756126, "train/reward_rate": 0.0019627939356435644, "train_stats/mean_log_entropy": 0.09835570802853118, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.0073286136612296104, "report/cont_loss_std": 0.1082736998796463, "report/cont_neg_acc": 0.6666666865348816, "report/cont_neg_loss": 1.2092227935791016, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0037970924749970436, "report/cont_pred": 0.9945134520530701, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.06174567714333534, "report/image_loss_std": 0.07907800376415253, "report/model_loss_mean": 0.6715253591537476, "report/model_loss_std": 0.1354506015777588, "report/post_ent_mag": 27.590957641601562, "report/post_ent_max": 27.590957641601562, "report/post_ent_mean": 27.147171020507812, "report/post_ent_min": 26.848731994628906, "report/post_ent_std": 0.13219386339187622, "report/prior_ent_mag": 26.930557250976562, "report/prior_ent_max": 26.930557250976562, "report/prior_ent_mean": 25.6745548248291, "report/prior_ent_min": 24.849388122558594, "report/prior_ent_std": 0.3063071072101593, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00018615722365211695, "report/reward_loss_mean": 0.002451003761962056, "report/reward_loss_std": 0.018471837043762207, "report/reward_max_data": 0.19062499701976776, "report/reward_max_pred": 0.24919748306274414, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0019271352794021368, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.5383684635162354, "report/reward_pred": 0.0012118978193029761, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.02651311829686165, "eval/cont_loss_std": 0.5279669761657715, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 11.785176277160645, "eval/cont_pos_acc": 0.9980430603027344, "eval/cont_pos_loss": 0.003502035280689597, "eval/cont_pred": 0.9975643157958984, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.21695470809936523, "eval/image_loss_std": 0.15615305304527283, "eval/model_loss_mean": 0.8437422513961792, "eval/model_loss_std": 0.5427547693252563, "eval/post_ent_mag": 27.601097106933594, "eval/post_ent_max": 27.601097106933594, "eval/post_ent_mean": 27.09128761291504, "eval/post_ent_min": 26.858787536621094, "eval/post_ent_std": 0.13067947328090668, "eval/prior_ent_mag": 26.930557250976562, "eval/prior_ent_max": 26.930557250976562, "eval/prior_ent_mean": 25.67151641845703, "eval/prior_ent_min": 24.723100662231445, "eval/prior_ent_std": 0.3090958297252655, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00027434341609477997, "eval/reward_loss_std": 0.0023976247757673264, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.021265268325805664, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00027434341609477997, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00013792188838124275, "eval/reward_rate": 0.0, "replay/size": 545537.0, "replay/inserts": 32240.0, "replay/samples": 32240.0, "replay/insert_wait_avg": 1.350984384049257e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.875471782447683e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3960.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.156330108642578e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1473894119262695e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0482578277588, "timer/env.step_count": 4030.0, "timer/env.step_total": 39.292858362197876, "timer/env.step_frac": 0.03929096226570838, "timer/env.step_avg": 0.009750088923622302, "timer/env.step_min": 0.007631540298461914, "timer/env.step_max": 0.04103589057922363, "timer/replay._sample_count": 32240.0, "timer/replay._sample_total": 17.333881616592407, "timer/replay._sample_frac": 0.01733304516148447, "timer/replay._sample_avg": 0.0005376514149067124, "timer/replay._sample_min": 0.0003840923309326172, "timer/replay._sample_max": 0.029309988021850586, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4525.0, "timer/agent.policy_total": 48.845229148864746, "timer/agent.policy_frac": 0.0488428720979558, "timer/agent.policy_avg": 0.01079452577875464, "timer/agent.policy_min": 0.00900888442993164, "timer/agent.policy_max": 0.0865321159362793, "timer/dataset_train_count": 2015.0, "timer/dataset_train_total": 0.22537732124328613, "timer/dataset_train_frac": 0.00022536644554817427, "timer/dataset_train_avg": 0.00011184978721751172, "timer/dataset_train_min": 9.751319885253906e-05, "timer/dataset_train_max": 0.00034689903259277344, "timer/agent.train_count": 2015.0, "timer/agent.train_total": 900.822395324707, "timer/agent.train_frac": 0.9007789256904624, "timer/agent.train_avg": 0.4470582607070506, "timer/agent.train_min": 0.4351491928100586, "timer/agent.train_max": 1.9604222774505615, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4752845764160156, "timer/agent.report_frac": 0.0004752616413215884, "timer/agent.report_avg": 0.2376422882080078, "timer/agent.report_min": 0.22884917259216309, "timer/agent.report_max": 0.24643540382385254, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.457069396972656e-05, "timer/dataset_eval_frac": 3.456902574363644e-08, "timer/dataset_eval_avg": 3.457069396972656e-05, "timer/dataset_eval_min": 3.457069396972656e-05, "timer/dataset_eval_max": 3.457069396972656e-05, "fps": 32.2378823690598}
{"step": 546192, "time": 17266.463606357574, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 546592, "time": 17278.62357902527, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 546808, "time": 17284.959881544113, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 547024, "time": 17291.888656139374, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 547064, "time": 17292.89349770546, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 547176, "time": 17296.371431827545, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 547216, "time": 17297.817980527878, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 547336, "time": 17301.273150920868, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 547672, "time": 17311.544595241547, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 547920, "time": 17319.398375988007, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 548280, "time": 17330.13068795204, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 548312, "time": 17331.100848197937, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 548376, "time": 17333.042204141617, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 548504, "time": 17336.953689336777, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 548608, "time": 17340.342759132385, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 548656, "time": 17341.80748772621, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 549056, "time": 17354.577885389328, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 549320, "time": 17362.450318336487, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 549368, "time": 17363.926355838776, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 549376, "time": 17364.398396492004, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 549480, "time": 17367.372259140015, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 549648, "time": 17372.803151369095, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 550056, "time": 17386.714317798615, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 550056, "time": 17386.904824256897, "eval_episode/length": 78.0, "eval_episode/score": 0.7562500238418579, "eval_episode/reward_rate": 0.012658227848101266}
{"step": 550056, "time": 17388.068808078766, "eval_episode/length": 133.0, "eval_episode/score": 0.5843750238418579, "eval_episode/reward_rate": 0.007462686567164179}
{"step": 550056, "time": 17388.387841939926, "eval_episode/length": 149.0, "eval_episode/score": 0.534375011920929, "eval_episode/reward_rate": 0.006666666666666667}
{"step": 550056, "time": 17388.473427772522, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 550056, "time": 17388.82007241249, "eval_episode/length": 169.0, "eval_episode/score": 0.47187501192092896, "eval_episode/reward_rate": 0.0058823529411764705}
{"step": 550056, "time": 17388.98804116249, "eval_episode/length": 43.0, "eval_episode/score": 0.8656250238418579, "eval_episode/reward_rate": 0.022727272727272728}
{"step": 550056, "time": 17390.09561729431, "eval_episode/length": 151.0, "eval_episode/score": 0.528124988079071, "eval_episode/reward_rate": 0.006578947368421052}
{"step": 550096, "time": 17391.544790029526, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 550144, "time": 17393.00099158287, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 550152, "time": 17393.028446674347, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 550256, "time": 17396.44095182419, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 550688, "time": 17409.74824333191, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 550888, "time": 17415.64455628395, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 550920, "time": 17416.623927116394, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 550968, "time": 17418.09419465065, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 551000, "time": 17419.106350421906, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 551120, "time": 17422.99786734581, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 551232, "time": 17426.414820432663, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 551440, "time": 17432.730380773544, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 551616, "time": 17438.243263959885, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 551632, "time": 17438.755167007446, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 551760, "time": 17442.638287067413, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 551800, "time": 17443.653262853622, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 551840, "time": 17445.097692728043, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 551904, "time": 17447.044674158096, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 552104, "time": 17452.923820734024, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 552120, "time": 17453.43977689743, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 552320, "time": 17459.72301530838, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 552496, "time": 17465.062140226364, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 552552, "time": 17466.633044719696, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 552640, "time": 17469.55862402916, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 552752, "time": 17472.974895715714, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 552800, "time": 17474.448605298996, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 552808, "time": 17474.477717638016, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 552936, "time": 17478.39404797554, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 553056, "time": 17482.272752523422, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 553248, "time": 17488.158369779587, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 553368, "time": 17491.56916975975, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 553568, "time": 17497.98704624176, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 553784, "time": 17504.364784240723, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 553792, "time": 17504.84099316597, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 553928, "time": 17508.788174152374, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 554224, "time": 17518.019265651703, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 554360, "time": 17521.96772313118, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 554392, "time": 17522.945009708405, "episode/length": 197.0, "episode/score": 0.3843750059604645, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.0}
{"step": 554464, "time": 17525.35679960251, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 554496, "time": 17526.37424659729, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 554864, "time": 17537.684306144714, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 554880, "time": 17538.177577257156, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 554920, "time": 17539.178594827652, "episode/length": 232.0, "episode/score": 0.2750000059604645, "episode/reward_rate": 0.004291845493562232, "episode/intrinsic_return": 0.0}
{"step": 555048, "time": 17543.076590299606, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 555112, "time": 17545.01612663269, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 555336, "time": 17551.80585551262, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 555336, "time": 17551.824501991272, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 555400, "time": 17553.77155637741, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 555440, "time": 17555.20631957054, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 555560, "time": 17558.778978824615, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 556256, "time": 17580.32398748398, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 556936, "time": 17600.97212576866, "episode/length": 227.0, "episode/score": 0.2906250059604645, "episode/reward_rate": 0.0043859649122807015, "episode/intrinsic_return": 0.0}
{"step": 557176, "time": 17608.83734679222, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 557232, "time": 17610.786272525787, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 557560, "time": 17620.677982330322, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 557648, "time": 17623.59784770012, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 557648, "time": 17623.60743188858, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 557712, "time": 17625.58390212059, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 557872, "time": 17630.457561016083, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 558144, "time": 17638.700632572174, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 558192, "time": 17640.176380634308, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 558328, "time": 17644.071115732193, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 558472, "time": 17648.533956050873, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 558768, "time": 17657.735609054565, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 558976, "time": 17664.104187250137, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 559096, "time": 17667.538133382797, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 559160, "time": 17669.50526714325, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 559248, "time": 17672.400872707367, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 559344, "time": 17675.324974298477, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 559424, "time": 17677.863799095154, "episode/length": 273.0, "episode/score": 0.14687499403953552, "episode/reward_rate": 0.0036496350364963502, "episode/intrinsic_return": 0.0}
{"step": 559536, "time": 17681.30241060257, "episode/length": 207.0, "episode/score": 0.3531250059604645, "episode/reward_rate": 0.004807692307692308, "episode/intrinsic_return": 0.0}
{"step": 559680, "time": 17685.715791225433, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 559768, "time": 17688.174766778946, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 559792, "time": 17689.15095973015, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 559824, "time": 17690.125346899033, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 560040, "time": 17696.474609851837, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 560040, "time": 17697.503232240677, "eval_episode/length": 50.0, "eval_episode/score": 0.84375, "eval_episode/reward_rate": 0.0196078431372549}
{"step": 560040, "time": 17698.00949025154, "eval_episode/length": 76.0, "eval_episode/score": 0.762499988079071, "eval_episode/reward_rate": 0.012987012987012988}
{"step": 560040, "time": 17698.214927196503, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 560040, "time": 17698.281610250473, "eval_episode/length": 89.0, "eval_episode/score": 0.721875011920929, "eval_episode/reward_rate": 0.011111111111111112}
{"step": 560040, "time": 17698.420773983, "eval_episode/length": 96.0, "eval_episode/score": 0.699999988079071, "eval_episode/reward_rate": 0.010309278350515464}
{"step": 560040, "time": 17699.317036151886, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 560040, "time": 17699.633642435074, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 560040, "time": 17699.753429174423, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 560248, "time": 17706.067402601242, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 560384, "time": 17710.513457536697, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 560672, "time": 17719.30295562744, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 560688, "time": 17719.79554629326, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 560704, "time": 17720.286511182785, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 560864, "time": 17725.162402629852, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 560960, "time": 17728.096348285675, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 561040, "time": 17730.53216958046, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 561472, "time": 17743.747074842453, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 561560, "time": 17746.214337348938, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 561784, "time": 17753.019912481308, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 561992, "time": 17759.295362472534, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 562160, "time": 17764.608361005783, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 562312, "time": 17769.076142311096, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 562312, "time": 17769.087349414825, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 562328, "time": 17769.586383104324, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 562472, "time": 17773.970525741577, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 562768, "time": 17783.173376321793, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 562984, "time": 17789.503218889236, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 563176, "time": 17795.42369055748, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 563192, "time": 17795.917108297348, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 563208, "time": 17796.45839905739, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 563272, "time": 17798.50159907341, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 563320, "time": 17800.001168727875, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 563488, "time": 17805.337915182114, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 563544, "time": 17806.810231924057, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 564064, "time": 17822.971640586853, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 564168, "time": 17825.927038431168, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 564184, "time": 17826.467166423798, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 564616, "time": 17839.6196808815, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 564624, "time": 17840.09165763855, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 564656, "time": 17841.06471657753, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 564992, "time": 17851.211665153503, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 565504, "time": 17867.281990766525, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 565584, "time": 17869.728862047195, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 565696, "time": 17873.109290599823, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 565720, "time": 17873.643988847733, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 565856, "time": 17877.983866930008, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 565880, "time": 17878.509675979614, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 566248, "time": 17889.89609336853, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 566368, "time": 17893.774693250656, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 566432, "time": 17895.73614835739, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0}
{"step": 566440, "time": 17895.76359796524, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 566560, "time": 17899.647264003754, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 566672, "time": 17903.056589365005, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 566928, "time": 17910.815378904343, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 566960, "time": 17911.796538829803, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 566968, "time": 17911.825531721115, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 567128, "time": 17916.853332042694, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 567224, "time": 17919.78748202324, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 567256, "time": 17920.756864786148, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 567600, "time": 17931.39604282379, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 567720, "time": 17934.819252967834, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 567784, "time": 17936.752805233, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 568128, "time": 17947.45796728134, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 568160, "time": 17948.42782855034, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 568288, "time": 17952.340683698654, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 568480, "time": 17958.20162630081, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 568648, "time": 17963.087393045425, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 568856, "time": 17969.416517734528, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 568872, "time": 17969.907319307327, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 568968, "time": 17972.83798265457, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 569232, "time": 17981.153554439545, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 569240, "time": 17981.181490898132, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 569320, "time": 17983.59107708931, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 569384, "time": 17985.52174425125, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 569440, "time": 17987.457890987396, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 569848, "time": 17999.650366783142, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 570024, "time": 18006.069159269333, "eval_episode/length": 55.0, "eval_episode/score": 0.828125, "eval_episode/reward_rate": 0.017857142857142856}
{"step": 570024, "time": 18006.336317300797, "eval_episode/length": 12.0, "eval_episode/score": 0.9624999761581421, "eval_episode/reward_rate": 0.07692307692307693}
{"step": 570024, "time": 18006.55365586281, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 570024, "time": 18006.961896657944, "eval_episode/length": 91.0, "eval_episode/score": 0.715624988079071, "eval_episode/reward_rate": 0.010869565217391304}
{"step": 570024, "time": 18006.971087694168, "eval_episode/length": 91.0, "eval_episode/score": 0.715624988079071, "eval_episode/reward_rate": 0.010869565217391304}
{"step": 570024, "time": 18007.038022994995, "eval_episode/length": 94.0, "eval_episode/score": 0.706250011920929, "eval_episode/reward_rate": 0.010526315789473684}
{"step": 570024, "time": 18007.199084043503, "eval_episode/length": 102.0, "eval_episode/score": 0.6812499761581421, "eval_episode/reward_rate": 0.009708737864077669}
{"step": 570024, "time": 18007.222714424133, "eval_episode/length": 103.0, "eval_episode/score": 0.6781250238418579, "eval_episode/reward_rate": 0.009615384615384616}
{"step": 570232, "time": 18013.53568172455, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 570248, "time": 18014.027445077896, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 570312, "time": 18015.964816093445, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 570600, "time": 18024.68451499939, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 570976, "time": 18036.418519496918, "episode/length": 262.0, "episode/score": 0.18125000596046448, "episode/reward_rate": 0.0038022813688212928, "episode/intrinsic_return": 0.0}
{"step": 571280, "time": 18045.729124307632, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 571368, "time": 18048.186871767044, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 571368, "time": 18048.19623398781, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 571480, "time": 18051.600061178207, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 571592, "time": 18054.97622013092, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 571632, "time": 18056.43017888069, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 571752, "time": 18059.843356370926, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 572096, "time": 18070.647892713547, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 572224, "time": 18074.568108320236, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 572888, "time": 18094.56452202797, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 572904, "time": 18095.056329250336, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 572912, "time": 18095.550186872482, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 573536, "time": 18115.05774450302, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 573592, "time": 18116.581332683563, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 573680, "time": 18119.492681741714, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 573680, "time": 18119.501413822174, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 573712, "time": 18120.495649814606, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 573720, "time": 18120.521390914917, "episode/length": 4.0, "episode/score": 0.987500011920929, "episode/reward_rate": 0.2, "episode/intrinsic_return": 0.0}
{"step": 573728, "time": 18120.993559598923, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 573944, "time": 18127.473880052567, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 574064, "time": 18131.348073244095, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 574144, "time": 18133.766757011414, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 574304, "time": 18138.639750480652, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 574648, "time": 18148.92148709297, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 574680, "time": 18149.91915011406, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 574920, "time": 18157.317994117737, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 574928, "time": 18157.786366701126, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 574936, "time": 18157.814381837845, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 575224, "time": 18166.59009051323, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 575368, "time": 18170.985347509384, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 575864, "time": 18186.090413331985, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 575864, "time": 18186.10978126526, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 576040, "time": 18191.566920518875, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 576256, "time": 18198.422092676163, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 576288, "time": 18199.43185520172, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 576488, "time": 18205.295035600662, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 576520, "time": 18206.275592803955, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 576616, "time": 18209.207911491394, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 576784, "time": 18214.53637957573, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 576928, "time": 18219.02454805374, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 576960, "time": 18219.998348474503, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 577200, "time": 18227.278792619705, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 577304, "time": 18230.237253904343, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 577392, "time": 18233.150247097015, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 577560, "time": 18238.04781126976, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 577592, "time": 18239.01609301567, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 577680, "time": 18241.90448331833, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 577784, "time": 18244.85508131981, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 577792, "time": 18245.32603907585, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 578008, "time": 18251.752940654755, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 578048, "time": 18253.209493637085, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 578120, "time": 18255.175354719162, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 578313, "time": 18262.01343035698, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.5162560002720773, "train/action_min": 0.0, "train/action_std": 1.7558495589156649, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.01354244830021959, "train/actor_opt_grad_steps": 35040.0, "train/actor_opt_loss": -11.529219236984774, "train/adv_mag": 1.0061271241055199, "train/adv_max": 0.4002790356156838, "train/adv_mean": 0.003737912919276104, "train/adv_min": -0.9700400648425468, "train/adv_std": 0.04058735914973181, "train/cont_avg": 0.9951706312189055, "train/cont_loss_mean": 0.016218010990055678, "train/cont_loss_std": 0.22866190382654764, "train/cont_neg_acc": 0.3610143786416718, "train/cont_neg_loss": 2.677532756304373, "train/cont_pos_acc": 0.9998975034376875, "train/cont_pos_loss": 0.003166029814153502, "train/cont_pred": 0.9952990130998602, "train/cont_rate": 0.9951706312189055, "train/dyn_loss_mean": 1.0000006162112032, "train/dyn_loss_std": 1.9692175845564598e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.43541797574850455, "train/extr_critic_critic_opt_grad_steps": 35040.0, "train/extr_critic_critic_opt_loss": 7224.412030424051, "train/extr_critic_mag": 1.32855249637395, "train/extr_critic_max": 1.32855249637395, "train/extr_critic_mean": 1.2380991314181047, "train/extr_critic_min": 0.9691063391035469, "train/extr_critic_std": 0.02200510040555724, "train/extr_return_normed_mag": 0.9958833527209153, "train/extr_return_normed_max": 0.3668711066839114, "train/extr_return_normed_mean": 0.047316366204278384, "train/extr_return_normed_min": -0.9569243524798113, "train/extr_return_normed_std": 0.047151344805140404, "train/extr_return_rate": 0.9988897075107441, "train/extr_return_raw_mag": 1.561391705897317, "train/extr_return_raw_max": 1.561391705897317, "train/extr_return_raw_mean": 1.2418370335849362, "train/extr_return_raw_min": 0.2375962467335943, "train/extr_return_raw_std": 0.047151344888542425, "train/extr_reward_mag": 0.3791107674736289, "train/extr_reward_max": 0.3791107674736289, "train/extr_reward_mean": 0.002708882908915999, "train/extr_reward_min": 3.5881403073742617e-07, "train/extr_reward_std": 0.012976476848496133, "train/image_loss_mean": 0.08632624662708287, "train/image_loss_std": 0.09957582310805867, "train/model_loss_mean": 0.7135217646461222, "train/model_loss_std": 0.40961201770685207, "train/model_opt_grad_norm": 22.893965282440185, "train/model_opt_grad_steps": 35009.13432835821, "train/model_opt_loss": 3603.9365659495493, "train/model_opt_model_opt_grad_overflow": 0.004975124378109453, "train/model_opt_model_opt_grad_scale": 5024.875621890547, "train/policy_entropy_mag": 1.4389103390091094, "train/policy_entropy_max": 1.4389103390091094, "train/policy_entropy_mean": 0.1160177946535509, "train/policy_entropy_min": 0.06468652400063045, "train/policy_entropy_std": 0.1544015163657677, "train/policy_logprob_mag": 6.551080238759814, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.11630935763096928, "train/policy_logprob_min": -6.551080238759814, "train/policy_logprob_std": 0.6555881319354423, "train/policy_randomness_mag": 0.7394536804797044, "train/policy_randomness_max": 0.7394536804797044, "train/policy_randomness_mean": 0.05962135548244661, "train/policy_randomness_min": 0.033242299911839454, "train/policy_randomness_std": 0.07934668815847654, "train/post_ent_mag": 27.345746851679106, "train/post_ent_max": 27.345746851679106, "train/post_ent_mean": 26.878307143254066, "train/post_ent_min": 26.5816984888333, "train/post_ent_std": 0.1445817687173388, "train/prior_ent_mag": 26.995873693209976, "train/prior_ent_max": 26.995873693209976, "train/prior_ent_mean": 25.753440714594145, "train/prior_ent_min": 24.918231518114386, "train/prior_ent_std": 0.3216797673138813, "train/rep_loss_mean": 1.0000006162112032, "train/rep_loss_std": 1.9692175845564598e-05, "train/reward_avg": 0.0015030438651647002, "train/reward_loss_mean": 0.010977113880657252, "train/reward_loss_std": 0.18514110230196693, "train/reward_max_data": 0.6867848261820143, "train/reward_max_pred": 0.22999462855989067, "train/reward_neg_acc": 0.9996444858721832, "train/reward_neg_loss": 0.0019020567933648862, "train/reward_pos_acc": 0.23113654471563372, "train/reward_pos_loss": 4.077639789871089, "train/reward_pred": 0.0011773024035840116, "train/reward_rate": 0.002200909514925373, "train_stats/mean_log_entropy": 0.08684698428808306, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.02362891100347042, "report/cont_loss_std": 0.3166634142398834, "report/cont_neg_acc": 0.2857142984867096, "report/cont_neg_loss": 3.175293207168579, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0019360397709533572, "report/cont_pred": 0.996065616607666, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.09714118391275406, "report/image_loss_std": 0.11235802620649338, "report/model_loss_mean": 0.7408095598220825, "report/model_loss_std": 0.6197855472564697, "report/post_ent_mag": 27.28359603881836, "report/post_ent_max": 27.28359603881836, "report/post_ent_mean": 26.86103057861328, "report/post_ent_min": 26.527420043945312, "report/post_ent_std": 0.1451483517885208, "report/prior_ent_mag": 27.419525146484375, "report/prior_ent_max": 27.419525146484375, "report/prior_ent_mean": 26.320974349975586, "report/prior_ent_min": 25.566741943359375, "report/prior_ent_std": 0.2936461269855499, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0028503418434411287, "report/reward_loss_mean": 0.020039428025484085, "report/reward_loss_std": 0.29541143774986267, "report/reward_max_data": 0.831250011920929, "report/reward_max_pred": 0.09365880489349365, "report/reward_neg_acc": 0.9999999403953552, "report/reward_neg_loss": 0.00157852191478014, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.727570533752441, "report/reward_pred": 0.0008512091590091586, "report/reward_rate": 0.00390625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.03708387911319733, "eval/cont_loss_std": 0.5830169916152954, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 8.862726211547852, "eval/cont_pos_acc": 0.9990195631980896, "eval/cont_pos_loss": 0.002473515458405018, "eval/cont_pred": 0.9977920651435852, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.15474411845207214, "eval/image_loss_std": 0.16569115221500397, "eval/model_loss_mean": 0.7941885590553284, "eval/model_loss_std": 0.6158058643341064, "eval/post_ent_mag": 27.29061508178711, "eval/post_ent_max": 27.29061508178711, "eval/post_ent_mean": 26.83885955810547, "eval/post_ent_min": 26.552217483520508, "eval/post_ent_std": 0.13588134944438934, "eval/prior_ent_mag": 27.419525146484375, "eval/prior_ent_max": 27.419525146484375, "eval/prior_ent_mean": 26.35353660583496, "eval/prior_ent_min": 25.477781295776367, "eval/prior_ent_std": 0.27642250061035156, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0023605413734912872, "eval/reward_loss_std": 0.04628990218043327, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.409420371055603, "eval/reward_neg_acc": 0.9990234375, "eval/reward_neg_loss": 0.0023605413734912872, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0008744042133912444, "eval/reward_rate": 0.0, "replay/size": 577809.0, "replay/inserts": 32272.0, "replay/samples": 32272.0, "replay/insert_wait_avg": 1.3543434171435498e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.928802383377461e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4008.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2188019628772242e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0132789611816406e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1309232711792, "timer/env.step_count": 4034.0, "timer/env.step_total": 39.349443435668945, "timer/env.step_frac": 0.039344292352211964, "timer/env.step_avg": 0.009754448050488088, "timer/env.step_min": 0.007781028747558594, "timer/env.step_max": 0.035044193267822266, "timer/replay._sample_count": 32272.0, "timer/replay._sample_total": 17.28140425682068, "timer/replay._sample_frac": 0.017279142015024902, "timer/replay._sample_avg": 0.0005354921993313299, "timer/replay._sample_min": 0.0003914833068847656, "timer/replay._sample_max": 0.028620481491088867, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4535.0, "timer/agent.policy_total": 48.76539444923401, "timer/agent.policy_frac": 0.048759010760045844, "timer/agent.policy_avg": 0.010753118952422053, "timer/agent.policy_min": 0.00853872299194336, "timer/agent.policy_max": 0.08707261085510254, "timer/dataset_train_count": 2017.0, "timer/dataset_train_total": 0.22596025466918945, "timer/dataset_train_frac": 0.00022593067508614744, "timer/dataset_train_avg": 0.00011202789026732248, "timer/dataset_train_min": 9.822845458984375e-05, "timer/dataset_train_max": 0.0003459453582763672, "timer/agent.train_count": 2017.0, "timer/agent.train_total": 900.6905989646912, "timer/agent.train_frac": 0.9005726930417834, "timer/agent.train_avg": 0.4465496276473432, "timer/agent.train_min": 0.4367408752441406, "timer/agent.train_max": 0.7259616851806641, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47763514518737793, "timer/agent.report_frac": 0.00047757261981776574, "timer/agent.report_avg": 0.23881757259368896, "timer/agent.report_min": 0.23182272911071777, "timer/agent.report_max": 0.24581241607666016, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.2901763916015625e-05, "timer/dataset_eval_frac": 3.289745687334829e-08, "timer/dataset_eval_avg": 3.2901763916015625e-05, "timer/dataset_eval_min": 3.2901763916015625e-05, "timer/dataset_eval_max": 3.2901763916015625e-05, "fps": 32.26719518281036}
{"step": 578360, "time": 18263.256791353226, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 578424, "time": 18265.213824748993, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 578568, "time": 18269.64620900154, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 578928, "time": 18280.94911313057, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 579296, "time": 18292.20600128174, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 579544, "time": 18299.606887102127, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 579728, "time": 18305.469175577164, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 579960, "time": 18312.44355416298, "episode/length": 199.0, "episode/score": 0.37812501192092896, "episode/reward_rate": 0.005, "episode/intrinsic_return": 0.0}
{"step": 580008, "time": 18314.362905740738, "eval_episode/length": 21.0, "eval_episode/score": 0.934374988079071, "eval_episode/reward_rate": 0.045454545454545456}
{"step": 580008, "time": 18314.90690755844, "eval_episode/length": 48.0, "eval_episode/score": 0.8500000238418579, "eval_episode/reward_rate": 0.02040816326530612}
{"step": 580008, "time": 18315.274638414383, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 580008, "time": 18315.484032392502, "eval_episode/length": 76.0, "eval_episode/score": 0.762499988079071, "eval_episode/reward_rate": 0.012987012987012988}
{"step": 580008, "time": 18315.848908901215, "eval_episode/length": 94.0, "eval_episode/score": 0.706250011920929, "eval_episode/reward_rate": 0.010526315789473684}
{"step": 580008, "time": 18315.894928216934, "eval_episode/length": 96.0, "eval_episode/score": 0.699999988079071, "eval_episode/reward_rate": 0.010309278350515464}
{"step": 580008, "time": 18316.094913244247, "eval_episode/length": 106.0, "eval_episode/score": 0.668749988079071, "eval_episode/reward_rate": 0.009345794392523364}
{"step": 580008, "time": 18316.1406955719, "eval_episode/length": 59.0, "eval_episode/score": 0.815625011920929, "eval_episode/reward_rate": 0.016666666666666666}
{"step": 580056, "time": 18317.6129219532, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 580104, "time": 18319.09121656418, "episode/length": 256.0, "episode/score": 0.20000000298023224, "episode/reward_rate": 0.0038910505836575876, "episode/intrinsic_return": 0.0}
{"step": 580104, "time": 18319.131121635437, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 580216, "time": 18322.573785066605, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 580264, "time": 18324.057146072388, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 580320, "time": 18326.01121020317, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 580432, "time": 18329.452966213226, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 580608, "time": 18334.845187187195, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 580736, "time": 18338.85611128807, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 580776, "time": 18339.877197027206, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 581000, "time": 18346.700169801712, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 581256, "time": 18354.549211502075, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 581352, "time": 18357.478990077972, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 581576, "time": 18364.36955666542, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 581792, "time": 18371.89291882515, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 581840, "time": 18373.35535287857, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 581936, "time": 18376.312505722046, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 582120, "time": 18381.735189437866, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 582456, "time": 18392.069943904877, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 582528, "time": 18394.512690782547, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 582560, "time": 18395.48966407776, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 582576, "time": 18395.98054933548, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 582632, "time": 18397.56040096283, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 582648, "time": 18398.05001783371, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 583560, "time": 18425.921519994736, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 583616, "time": 18427.949974775314, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 583664, "time": 18429.43416786194, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 584080, "time": 18442.13773393631, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 584152, "time": 18444.15087914467, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 584200, "time": 18445.619345903397, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 584216, "time": 18446.111405849457, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 584560, "time": 18456.939742565155, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 584688, "time": 18460.85481405258, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 584840, "time": 18465.278770685196, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 584872, "time": 18466.263780117035, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 584888, "time": 18466.758142471313, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 584920, "time": 18467.763341903687, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 584928, "time": 18468.233959674835, "episode/length": 6.0, "episode/score": 0.981249988079071, "episode/reward_rate": 0.14285714285714285, "episode/intrinsic_return": 0.0}
{"step": 584944, "time": 18468.726251125336, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 584960, "time": 18469.231875896454, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 584976, "time": 18469.725779533386, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 585320, "time": 18479.985956192017, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 585336, "time": 18480.476427316666, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 585360, "time": 18481.431680202484, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 585480, "time": 18484.888920545578, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 585640, "time": 18489.90677714348, "episode/length": 19.0, "episode/score": 0.940625011920929, "episode/reward_rate": 0.05, "episode/intrinsic_return": 0.0}
{"step": 585648, "time": 18490.380692481995, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 585784, "time": 18494.31600666046, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 585808, "time": 18495.287778139114, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 585864, "time": 18496.785546541214, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 585880, "time": 18497.299643993378, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 585984, "time": 18500.698646068573, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 586032, "time": 18502.18977165222, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 586192, "time": 18507.11096930504, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 586232, "time": 18508.11833000183, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 586248, "time": 18508.61471223831, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 586648, "time": 18520.95954823494, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 586808, "time": 18525.83740878105, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 586888, "time": 18528.2948448658, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 586904, "time": 18528.792934656143, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 587192, "time": 18537.62705373764, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 587288, "time": 18540.55659198761, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 587448, "time": 18545.479271888733, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 587448, "time": 18545.48959827423, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 587536, "time": 18548.545605897903, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 587744, "time": 18554.889516830444, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 587744, "time": 18554.89804506302, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 588120, "time": 18566.214172124863, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 588152, "time": 18567.19199037552, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 588344, "time": 18573.049504995346, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 588552, "time": 18579.475711345673, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 588568, "time": 18579.974991559982, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 588688, "time": 18583.900535345078, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 588848, "time": 18588.834557533264, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 589008, "time": 18593.764902114868, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 589080, "time": 18595.774903297424, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 589088, "time": 18596.251715421677, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 589168, "time": 18598.70739388466, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 589424, "time": 18606.79044985771, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 589480, "time": 18608.285071372986, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 589504, "time": 18609.25180888176, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 589632, "time": 18613.182782411575, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 589848, "time": 18620.114355802536, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 589928, "time": 18622.592384576797, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 589992, "time": 18624.576400995255, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 590016, "time": 18625.543651103973, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 590096, "time": 18628.425903081894, "eval_episode/length": 18.0, "eval_episode/score": 0.9437500238418579, "eval_episode/reward_rate": 0.05263157894736842}
{"step": 590096, "time": 18628.813901424408, "eval_episode/length": 36.0, "eval_episode/score": 0.887499988079071, "eval_episode/reward_rate": 0.02702702702702703}
{"step": 590096, "time": 18629.979667901993, "eval_episode/length": 90.0, "eval_episode/score": 0.71875, "eval_episode/reward_rate": 0.01098901098901099}
{"step": 590096, "time": 18630.721150636673, "eval_episode/length": 126.0, "eval_episode/score": 0.606249988079071, "eval_episode/reward_rate": 0.007874015748031496}
{"step": 590096, "time": 18630.747417211533, "eval_episode/length": 36.0, "eval_episode/score": 0.887499988079071, "eval_episode/reward_rate": 0.02702702702702703}
{"step": 590096, "time": 18630.839302539825, "eval_episode/length": 131.0, "eval_episode/score": 0.590624988079071, "eval_episode/reward_rate": 0.007575757575757576}
{"step": 590096, "time": 18631.180745363235, "eval_episode/length": 128.0, "eval_episode/score": 0.6000000238418579, "eval_episode/reward_rate": 0.007751937984496124}
{"step": 590096, "time": 18631.519090652466, "eval_episode/length": 163.0, "eval_episode/score": 0.4906249940395355, "eval_episode/reward_rate": 0.006097560975609756}
{"step": 590112, "time": 18632.014379501343, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 590352, "time": 18639.49425292015, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 590400, "time": 18640.9666595459, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 590624, "time": 18647.84650492668, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 590696, "time": 18649.849516630173, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 591040, "time": 18660.663992404938, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 591128, "time": 18663.168582201004, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 591320, "time": 18669.23414206505, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 591344, "time": 18670.200749874115, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 591344, "time": 18670.21137547493, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 591480, "time": 18674.21973490715, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 591728, "time": 18682.13331580162, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 591744, "time": 18682.63515138626, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 591760, "time": 18683.143821954727, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 591920, "time": 18688.11659860611, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 592104, "time": 18693.562907218933, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 592240, "time": 18698.091419696808, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 592424, "time": 18703.532084703445, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 592432, "time": 18704.026827812195, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 592480, "time": 18705.497807741165, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 592536, "time": 18707.00044941902, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 592720, "time": 18712.865584611893, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 592896, "time": 18718.31680083275, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 592912, "time": 18718.83239841461, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 592968, "time": 18720.33101296425, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 593048, "time": 18722.777115345, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 593072, "time": 18723.76340842247, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 593288, "time": 18730.326839208603, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 593384, "time": 18733.29261469841, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 593568, "time": 18739.258742809296, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 593608, "time": 18740.276979207993, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 593664, "time": 18742.21377134323, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 593680, "time": 18742.70502114296, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 593704, "time": 18743.222101211548, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 594048, "time": 18754.00306367874, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 594208, "time": 18759.03725552559, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 594288, "time": 18761.492527246475, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 594480, "time": 18767.371113538742, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 594704, "time": 18774.348234176636, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 594856, "time": 18778.854889392853, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 595016, "time": 18783.78679227829, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 595208, "time": 18789.82562661171, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 595256, "time": 18791.28699183464, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 595600, "time": 18802.0585565567, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 595664, "time": 18804.04547572136, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 595984, "time": 18813.809449911118, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 596016, "time": 18814.794610261917, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 596080, "time": 18816.842339515686, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 596352, "time": 18825.135309696198, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 596432, "time": 18827.583691120148, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 596600, "time": 18832.465341567993, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 596640, "time": 18833.9032702446, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 597136, "time": 18849.232912778854, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 597168, "time": 18850.213439702988, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 597176, "time": 18850.24102449417, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 597312, "time": 18854.627566099167, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 597424, "time": 18858.107331752777, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 597568, "time": 18862.581966161728, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 598104, "time": 18879.588659763336, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 598152, "time": 18881.076100111008, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 598296, "time": 18885.569476127625, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 598312, "time": 18886.068398714066, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 598392, "time": 18888.586798906326, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 598600, "time": 18895.054146528244, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 598704, "time": 18898.511378765106, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 598896, "time": 18904.417320728302, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 599424, "time": 18920.716782808304, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 599488, "time": 18922.690276384354, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 599520, "time": 18923.68183851242, "episode/length": 11.0, "episode/score": 0.965624988079071, "episode/reward_rate": 0.08333333333333333, "episode/intrinsic_return": 0.0}
{"step": 599728, "time": 18930.031641960144, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 599736, "time": 18930.05944466591, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 599760, "time": 18931.022743225098, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 600080, "time": 18941.44826555252, "eval_episode/length": 24.0, "eval_episode/score": 0.925000011920929, "eval_episode/reward_rate": 0.04}
{"step": 600080, "time": 18942.742927074432, "eval_episode/length": 90.0, "eval_episode/score": 0.71875, "eval_episode/reward_rate": 0.01098901098901099}
{"step": 600080, "time": 18942.75239777565, "eval_episode/length": 90.0, "eval_episode/score": 0.71875, "eval_episode/reward_rate": 0.01098901098901099}
{"step": 600080, "time": 18942.871649980545, "eval_episode/length": 96.0, "eval_episode/score": 0.699999988079071, "eval_episode/reward_rate": 0.010309278350515464}
{"step": 600080, "time": 18943.11000275612, "eval_episode/length": 108.0, "eval_episode/score": 0.6625000238418579, "eval_episode/reward_rate": 0.009174311926605505}
{"step": 600080, "time": 18943.792144060135, "eval_episode/length": 118.0, "eval_episode/score": 0.6312500238418579, "eval_episode/reward_rate": 0.008403361344537815}
{"step": 600080, "time": 18943.835405111313, "eval_episode/length": 48.0, "eval_episode/score": 0.8500000238418579, "eval_episode/reward_rate": 0.02040816326530612}
{"step": 600080, "time": 18944.001125097275, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 600296, "time": 18950.362481832504, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 600360, "time": 18952.302749872208, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 600416, "time": 18954.228241205215, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 600608, "time": 18960.111796855927, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 600624, "time": 18960.60421037674, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 600720, "time": 18963.5257229805, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 601064, "time": 18973.843710184097, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 601176, "time": 18977.278752326965, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 601248, "time": 18979.723554849625, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 601256, "time": 18979.75291800499, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 601520, "time": 18988.02562189102, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 601776, "time": 18995.835431337357, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 601800, "time": 18996.3821747303, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 601848, "time": 18997.92058610916, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 602000, "time": 19002.781103610992, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 602040, "time": 19003.800939321518, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 602048, "time": 19004.275053024292, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 602048, "time": 19004.282163858414, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 602144, "time": 19007.223215579987, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 602168, "time": 19007.735908269882, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 602456, "time": 19016.549461364746, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 602712, "time": 19024.418588638306, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 602728, "time": 19024.914258003235, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 602744, "time": 19025.408955574036, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 602752, "time": 19025.883934497833, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 602952, "time": 19031.95145392418, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 603168, "time": 19038.826216459274, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 603544, "time": 19050.190272569656, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 603712, "time": 19055.57209944725, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 603728, "time": 19056.066892385483, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 603928, "time": 19062.122515439987, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 604000, "time": 19064.56399154663, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 604160, "time": 19069.52276301384, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 604312, "time": 19073.95362329483, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 604480, "time": 19079.349223136902, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 604800, "time": 19089.290042877197, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 604936, "time": 19093.226863861084, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 604936, "time": 19093.24939107895, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 605064, "time": 19097.296377182007, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 605072, "time": 19097.793478250504, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 605400, "time": 19107.66228723526, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 605576, "time": 19113.120002508163, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 605592, "time": 19113.616278886795, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 605744, "time": 19118.633222341537, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 605800, "time": 19120.132840633392, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 605856, "time": 19122.080724716187, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 605920, "time": 19124.06661581993, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 606208, "time": 19133.080835819244, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 606256, "time": 19134.933814048767, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 606288, "time": 19135.922891139984, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 606416, "time": 19139.868227005005, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 606472, "time": 19141.385154008865, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 606520, "time": 19142.881183862686, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 606712, "time": 19148.85613465309, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 606984, "time": 19157.17655301094, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 607064, "time": 19159.650978565216, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 607280, "time": 19166.490488767624, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 607648, "time": 19177.88484454155, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 607816, "time": 19182.79220366478, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 607904, "time": 19185.71711587906, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 608336, "time": 19198.95269727707, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 608568, "time": 19205.83233332634, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 608728, "time": 19210.86911702156, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 608768, "time": 19212.342076539993, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 608784, "time": 19212.838372945786, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 609024, "time": 19220.220438480377, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 609064, "time": 19221.22822856903, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 609296, "time": 19228.578115701675, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 609424, "time": 19232.49797654152, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 609656, "time": 19239.460961580276, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 609848, "time": 19245.332503080368, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 609976, "time": 19249.251232147217, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 610000, "time": 19250.208676338196, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 610064, "time": 19253.451471090317, "eval_episode/length": 31.0, "eval_episode/score": 0.903124988079071, "eval_episode/reward_rate": 0.03125}
{"step": 610064, "time": 19253.692245960236, "eval_episode/length": 42.0, "eval_episode/score": 0.8687499761581421, "eval_episode/reward_rate": 0.023255813953488372}
{"step": 610064, "time": 19254.363476753235, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 610064, "time": 19254.868374586105, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 610064, "time": 19255.139476776123, "eval_episode/length": 111.0, "eval_episode/score": 0.653124988079071, "eval_episode/reward_rate": 0.008928571428571428}
{"step": 610064, "time": 19255.88559770584, "eval_episode/length": 117.0, "eval_episode/score": 0.6343749761581421, "eval_episode/reward_rate": 0.00847457627118644}
{"step": 610064, "time": 19256.47723674774, "eval_episode/length": 67.0, "eval_episode/score": 0.7906249761581421, "eval_episode/reward_rate": 0.014705882352941176}
{"step": 610064, "time": 19256.52325487137, "eval_episode/length": 181.0, "eval_episode/score": 0.43437498807907104, "eval_episode/reward_rate": 0.005494505494505495}
{"step": 610136, "time": 19258.512044906616, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 610216, "time": 19260.993089199066, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 610225, "time": 19262.02200961113, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.4794320678710937, "train/action_min": 0.0, "train/action_std": 1.759772623181343, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.011856263666413725, "train/actor_opt_grad_steps": 37045.0, "train/actor_opt_loss": -12.61149963401258, "train/adv_mag": 1.030995631814003, "train/adv_max": 0.3958142703771591, "train/adv_mean": 0.001916319458172211, "train/adv_min": -0.9969000694155693, "train/adv_std": 0.03483385060913861, "train/cont_avg": 0.9947119140625, "train/cont_loss_mean": 0.017145230997120963, "train/cont_loss_std": 0.2388504619942978, "train/cont_neg_acc": 0.36020325962922084, "train/cont_neg_loss": 2.6603541391203764, "train/cont_pos_acc": 0.9998674884438514, "train/cont_pos_loss": 0.0033087823033565657, "train/cont_pred": 0.9948384881019592, "train/cont_rate": 0.9947119140625, "train/dyn_loss_mean": 1.0000224149227142, "train/dyn_loss_std": 0.00041138620465062557, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.2303375273384154, "train/extr_critic_critic_opt_grad_steps": 37045.0, "train/extr_critic_critic_opt_loss": 11441.668803710938, "train/extr_critic_mag": 1.410729296207428, "train/extr_critic_max": 1.410729296207428, "train/extr_critic_mean": 1.2974004513025283, "train/extr_critic_min": 0.9376904624700546, "train/extr_critic_std": 0.022556178914383055, "train/extr_return_normed_mag": 1.058676053583622, "train/extr_return_normed_max": 0.3606238204240799, "train/extr_return_normed_mean": 0.04573392974212766, "train/extr_return_normed_min": -1.0165164974331855, "train/extr_return_normed_std": 0.04196463017724454, "train/extr_return_rate": 0.9993281686305999, "train/extr_return_raw_mag": 1.6142066103219985, "train/extr_return_raw_max": 1.6142066103219985, "train/extr_return_raw_mean": 1.299316777586937, "train/extr_return_raw_min": 0.23706629246473312, "train/extr_return_raw_std": 0.04196463014930487, "train/extr_reward_mag": 0.37216359794139864, "train/extr_reward_max": 0.37216359794139864, "train/extr_reward_mean": 0.0023527284630108624, "train/extr_reward_min": 3.129243850708008e-07, "train/extr_reward_std": 0.010294004521565512, "train/image_loss_mean": 0.08719653595238924, "train/image_loss_std": 0.10093179946765303, "train/model_loss_mean": 0.7167386502027512, "train/model_loss_std": 0.4387498285993934, "train/model_opt_grad_norm": 23.217384996414186, "train/model_opt_grad_steps": 37012.16, "train/model_opt_loss": 3636.1488037109375, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5075.0, "train/policy_entropy_mag": 1.408902296423912, "train/policy_entropy_max": 1.408902296423912, "train/policy_entropy_mean": 0.10404430836439132, "train/policy_entropy_min": 0.06468650236725808, "train/policy_entropy_std": 0.13718253768980504, "train/policy_logprob_mag": 6.551080243587494, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.10392715241760016, "train/policy_logprob_min": -6.551080243587494, "train/policy_logprob_std": 0.6421858215332031, "train/policy_randomness_mag": 0.7240325966477394, "train/policy_randomness_max": 0.7240325966477394, "train/policy_randomness_mean": 0.05346820056438446, "train/policy_randomness_min": 0.03324228715151548, "train/policy_randomness_std": 0.0704978833720088, "train/post_ent_mag": 28.63874442100525, "train/post_ent_max": 28.63874442100525, "train/post_ent_mean": 28.155384607315064, "train/post_ent_min": 27.8524019241333, "train/post_ent_std": 0.1494108422100544, "train/prior_ent_mag": 28.383358335494997, "train/prior_ent_max": 28.383358335494997, "train/prior_ent_mean": 27.712752361297607, "train/prior_ent_min": 26.848069677352907, "train/prior_ent_std": 0.22086212694644927, "train/rep_loss_mean": 1.0000224149227142, "train/rep_loss_std": 0.00041138620465062557, "train/reward_avg": 0.0017178802480339072, "train/reward_loss_mean": 0.012383408723399042, "train/reward_loss_std": 0.20292452214984225, "train/reward_max_data": 0.728874998986721, "train/reward_max_pred": 0.26006450116634366, "train/reward_neg_acc": 0.9997307068109512, "train/reward_neg_loss": 0.002117028788779862, "train/reward_pos_acc": 0.19414414642630395, "train/reward_pos_loss": 4.139566086756217, "train/reward_pred": 0.001337694424437359, "train/reward_rate": 0.0025, "train_stats/mean_log_entropy": 0.08219040333606395, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.006459942553192377, "report/cont_loss_std": 0.11620607227087021, "report/cont_neg_acc": 0.6666666865348816, "report/cont_neg_loss": 1.3681715726852417, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.002458831761032343, "report/cont_pred": 0.9960461854934692, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.07310676574707031, "report/image_loss_std": 0.09068293124437332, "report/model_loss_mean": 0.6867973804473877, "report/model_loss_std": 0.27472275495529175, "report/post_ent_mag": 29.091136932373047, "report/post_ent_max": 29.091136932373047, "report/post_ent_mean": 28.557552337646484, "report/post_ent_min": 28.27541160583496, "report/post_ent_std": 0.15369755029678345, "report/prior_ent_mag": 28.58124351501465, "report/prior_ent_max": 28.58124351501465, "report/prior_ent_mean": 28.067110061645508, "report/prior_ent_min": 27.280052185058594, "report/prior_ent_std": 0.1912396252155304, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0012756348587572575, "report/reward_loss_mean": 0.007230670191347599, "report/reward_loss_std": 0.13505153357982635, "report/reward_max_data": 0.7093750238418579, "report/reward_max_pred": 0.5870481729507446, "report/reward_neg_acc": 0.9980430603027344, "report/reward_neg_loss": 0.002179892733693123, "report/reward_pos_acc": 0.5, "report/reward_pos_loss": 2.5881781578063965, "report/reward_pred": 0.001672967104241252, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.03882445767521858, "eval/cont_loss_std": 0.6349641680717468, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 9.531084060668945, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.0015999077586457133, "eval/cont_pred": 0.9984301328659058, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.1915772259235382, "eval/image_loss_std": 0.17284263670444489, "eval/model_loss_mean": 0.8369736075401306, "eval/model_loss_std": 0.7340390086174011, "eval/post_ent_mag": 29.063499450683594, "eval/post_ent_max": 29.063499450683594, "eval/post_ent_mean": 28.528995513916016, "eval/post_ent_min": 28.281864166259766, "eval/post_ent_std": 0.14147204160690308, "eval/prior_ent_mag": 28.524431228637695, "eval/prior_ent_max": 28.524431228637695, "eval/prior_ent_mean": 28.076904296875, "eval/prior_ent_min": 27.213176727294922, "eval/prior_ent_std": 0.19700033962726593, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0008666992071084678, "eval/reward_loss_mean": 0.006571888457983732, "eval/reward_loss_std": 0.19420218467712402, "eval/reward_max_data": 0.887499988079071, "eval/reward_max_pred": 0.020610451698303223, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0005007521831430495, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 6.217344284057617, "eval/reward_pred": 0.00025882350746542215, "eval/reward_rate": 0.0009765625, "replay/size": 609721.0, "replay/inserts": 31912.0, "replay/samples": 31904.0, "replay/insert_wait_avg": 1.3969735891247012e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.833309712118227e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4872.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1964971796045163e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0281801223754883e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 999.9922308921814, "timer/env.step_count": 3989.0, "timer/env.step_total": 39.86118292808533, "timer/env.step_frac": 0.03986149261631927, "timer/env.step_avg": 0.009992775865651874, "timer/env.step_min": 0.007867574691772461, "timer/env.step_max": 0.05377078056335449, "timer/replay._sample_count": 31904.0, "timer/replay._sample_total": 17.186269283294678, "timer/replay._sample_frac": 0.017186402806311094, "timer/replay._sample_avg": 0.0005386869760310518, "timer/replay._sample_min": 0.0003809928894042969, "timer/replay._sample_max": 0.025085926055908203, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4598.0, "timer/agent.policy_total": 50.734946489334106, "timer/agent.policy_frac": 0.05073534065766589, "timer/agent.policy_avg": 0.01103413364274339, "timer/agent.policy_min": 0.009068965911865234, "timer/agent.policy_max": 0.09121203422546387, "timer/dataset_train_count": 1994.0, "timer/dataset_train_total": 0.2307291030883789, "timer/dataset_train_frac": 0.00023073089566158438, "timer/dataset_train_avg": 0.00011571168660400145, "timer/dataset_train_min": 9.608268737792969e-05, "timer/dataset_train_max": 0.00046563148498535156, "timer/agent.train_count": 1994.0, "timer/agent.train_total": 896.4158370494843, "timer/agent.train_frac": 0.8964228014548798, "timer/agent.train_avg": 0.449556588289611, "timer/agent.train_min": 0.4397730827331543, "timer/agent.train_max": 0.6943602561950684, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.477114200592041, "timer/agent.report_frac": 0.0004771179073725056, "timer/agent.report_avg": 0.2385571002960205, "timer/agent.report_min": 0.22998428344726562, "timer/agent.report_max": 0.2471299171447754, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.3855438232421875e-05, "timer/dataset_eval_frac": 3.3855701261015244e-08, "timer/dataset_eval_avg": 3.3855438232421875e-05, "timer/dataset_eval_min": 3.3855438232421875e-05, "timer/dataset_eval_max": 3.3855438232421875e-05, "fps": 31.91172484409118}
{"step": 610232, "time": 19262.13622021675, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 610464, "time": 19269.959275007248, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 610624, "time": 19274.883088350296, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 610768, "time": 19279.3048787117, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 610784, "time": 19279.810826301575, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 611032, "time": 19287.200236797333, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 611504, "time": 19301.970526456833, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 611528, "time": 19302.485490322113, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 611680, "time": 19307.357597351074, "episode/length": 18.0, "episode/score": 0.9437500238418579, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.0}
{"step": 611720, "time": 19308.363188505173, "episode/length": 187.0, "episode/score": 0.4156250059604645, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.0}
{"step": 611752, "time": 19309.342389583588, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 611968, "time": 19316.19148159027, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 612048, "time": 19318.630378961563, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 612184, "time": 19322.57621192932, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 612288, "time": 19326.05062198639, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 612312, "time": 19326.665606975555, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 612312, "time": 19326.67486524582, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 612680, "time": 19337.943428754807, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 612760, "time": 19340.448414564133, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 612848, "time": 19343.37408542633, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 613056, "time": 19349.73811173439, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 613304, "time": 19357.22593832016, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 613376, "time": 19359.64789700508, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 613880, "time": 19374.884134054184, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 613936, "time": 19376.811180830002, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 613968, "time": 19377.782481193542, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 614032, "time": 19379.762854337692, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 614168, "time": 19383.733214378357, "episode/length": 234.0, "episode/score": 0.26875001192092896, "episode/reward_rate": 0.00425531914893617, "episode/intrinsic_return": 0.0}
{"step": 614368, "time": 19390.247928142548, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 614528, "time": 19395.62738442421, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 614624, "time": 19398.56950521469, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 614776, "time": 19403.02253460884, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 615040, "time": 19411.354829072952, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 615072, "time": 19412.33663392067, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 615160, "time": 19414.82807302475, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 615168, "time": 19415.301029205322, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 615408, "time": 19422.72768998146, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 615424, "time": 19423.227598905563, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 615480, "time": 19424.732326745987, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 615712, "time": 19432.087376117706, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 615864, "time": 19436.52439379692, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 615880, "time": 19437.01996946335, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 616040, "time": 19441.91961789131, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 616104, "time": 19443.871146202087, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 616272, "time": 19449.36843442917, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 616360, "time": 19451.83820962906, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 616560, "time": 19458.181062221527, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 616712, "time": 19462.633583307266, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 616840, "time": 19466.557423830032, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 617000, "time": 19471.47081208229, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 617040, "time": 19472.936067342758, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 617176, "time": 19476.97658419609, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 617208, "time": 19477.954025268555, "episode/length": 20.0, "episode/score": 0.9375, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.0}
{"step": 617248, "time": 19479.41703224182, "episode/length": 4.0, "episode/score": 0.987500011920929, "episode/reward_rate": 0.2, "episode/intrinsic_return": 0.0}
{"step": 617472, "time": 19486.281200170517, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 617520, "time": 19487.752510786057, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 617608, "time": 19490.25719499588, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 617648, "time": 19491.708943605423, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 617896, "time": 19499.105152606964, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 617960, "time": 19501.05860185623, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 618152, "time": 19507.068982362747, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 618160, "time": 19507.542770147324, "episode/length": 199.0, "episode/score": 0.37812501192092896, "episode/reward_rate": 0.005, "episode/intrinsic_return": 0.0}
{"step": 618176, "time": 19508.037229776382, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 618608, "time": 19521.304873228073, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 618928, "time": 19531.17256784439, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 619040, "time": 19534.62349319458, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 619152, "time": 19538.170265197754, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 619680, "time": 19554.334958314896, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 619792, "time": 19557.79601740837, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 619824, "time": 19558.784497499466, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 619832, "time": 19558.81363248825, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 619832, "time": 19558.82161784172, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 620048, "time": 19567.123771429062, "eval_episode/length": 60.0, "eval_episode/score": 0.8125, "eval_episode/reward_rate": 0.01639344262295082}
{"step": 620048, "time": 19567.900868415833, "eval_episode/length": 97.0, "eval_episode/score": 0.6968749761581421, "eval_episode/reward_rate": 0.01020408163265306}
{"step": 620048, "time": 19568.264350891113, "eval_episode/length": 114.0, "eval_episode/score": 0.643750011920929, "eval_episode/reward_rate": 0.008695652173913044}
{"step": 620048, "time": 19568.845595121384, "eval_episode/length": 142.0, "eval_episode/score": 0.5562499761581421, "eval_episode/reward_rate": 0.006993006993006993}
{"step": 620048, "time": 19569.36439394951, "eval_episode/length": 24.0, "eval_episode/score": 0.925000011920929, "eval_episode/reward_rate": 0.04}
{"step": 620048, "time": 19569.475677013397, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 620048, "time": 19569.947341918945, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 620048, "time": 19570.760596752167, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 620208, "time": 19575.678860902786, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 620232, "time": 19576.196640253067, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 620344, "time": 19579.640146255493, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 620472, "time": 19583.573554754257, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 620472, "time": 19583.58162045479, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 620488, "time": 19584.082063913345, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 620520, "time": 19585.067500591278, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 620736, "time": 19591.89329123497, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 620816, "time": 19594.364535808563, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 621232, "time": 19607.21654200554, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 621336, "time": 19610.1626329422, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 621344, "time": 19610.63604092598, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 621440, "time": 19613.583812236786, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 621720, "time": 19621.90535211563, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 621792, "time": 19624.327574014664, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 621968, "time": 19629.85325574875, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 622064, "time": 19632.803849220276, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 622392, "time": 19642.66525053978, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 622520, "time": 19646.599314451218, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 622632, "time": 19650.511932611465, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 622896, "time": 19658.932884931564, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 622936, "time": 19659.938327550888, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 622960, "time": 19660.90844297409, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 623024, "time": 19662.896956682205, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 623048, "time": 19663.415843248367, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 623256, "time": 19669.788899183273, "episode/length": 239.0, "episode/score": 0.25312501192092896, "episode/reward_rate": 0.004166666666666667, "episode/intrinsic_return": 0.0}
{"step": 623264, "time": 19670.261907339096, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 623480, "time": 19676.67501974106, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 623600, "time": 19680.554882764816, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 623656, "time": 19682.0678088665, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 623784, "time": 19685.95487689972, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 624040, "time": 19693.945091962814, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 624056, "time": 19694.43972849846, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 624176, "time": 19698.37514448166, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 624208, "time": 19699.370190382004, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 624256, "time": 19700.85794186592, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 624928, "time": 19721.602919340134, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 625024, "time": 19724.53331899643, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 625040, "time": 19725.033391714096, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 625080, "time": 19726.060466766357, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 625248, "time": 19731.413617134094, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 625640, "time": 19743.164833545685, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 625656, "time": 19743.658886671066, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 625712, "time": 19745.597882032394, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 625832, "time": 19749.101273298264, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 625912, "time": 19751.55909180641, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 625968, "time": 19753.494423866272, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 626080, "time": 19756.933926582336, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 626240, "time": 19761.829466104507, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 626352, "time": 19765.28514099121, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 626416, "time": 19767.236575365067, "episode/length": 21.0, "episode/score": 0.934374988079071, "episode/reward_rate": 0.045454545454545456, "episode/intrinsic_return": 0.0}
{"step": 626816, "time": 19779.579626083374, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 626824, "time": 19779.60864496231, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 626960, "time": 19784.021917819977, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 627096, "time": 19787.988198280334, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 627144, "time": 19789.460115909576, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 627352, "time": 19795.84112215042, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 627632, "time": 19804.644458293915, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 627784, "time": 19809.18968272209, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 628056, "time": 19817.577104330063, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 628080, "time": 19818.538398742676, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 628224, "time": 19822.966069936752, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 628280, "time": 19824.48526954651, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 628312, "time": 19825.475197792053, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 628520, "time": 19831.827236175537, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 628608, "time": 19834.788318157196, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 628832, "time": 19841.735341072083, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 628912, "time": 19844.200748682022, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 628944, "time": 19845.173239946365, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 629136, "time": 19851.050770998, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 629224, "time": 19853.5160779953, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 629312, "time": 19856.451488494873, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 629392, "time": 19858.913908958435, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 629664, "time": 19867.348658800125, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 629736, "time": 19869.35255408287, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 629928, "time": 19875.221831798553, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 630024, "time": 19878.173443078995, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 630024, "time": 19878.190878152847, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 630032, "time": 19881.213258981705, "eval_episode/length": 121.0, "eval_episode/score": 0.621874988079071, "eval_episode/reward_rate": 0.00819672131147541}
{"step": 630032, "time": 19881.58123445511, "eval_episode/length": 139.0, "eval_episode/score": 0.565625011920929, "eval_episode/reward_rate": 0.007142857142857143}
{"step": 630032, "time": 19882.005028486252, "eval_episode/length": 160.0, "eval_episode/score": 0.5, "eval_episode/reward_rate": 0.006211180124223602}
{"step": 630032, "time": 19882.36538028717, "eval_episode/length": 178.0, "eval_episode/score": 0.4437499940395355, "eval_episode/reward_rate": 0.00558659217877095}
{"step": 630032, "time": 19882.4783911705, "eval_episode/length": 183.0, "eval_episode/score": 0.4281249940395355, "eval_episode/reward_rate": 0.005434782608695652}
{"step": 630032, "time": 19882.727445602417, "eval_episode/length": 195.0, "eval_episode/score": 0.390625, "eval_episode/reward_rate": 0.00510204081632653}
{"step": 630032, "time": 19883.7353951931, "eval_episode/length": 120.0, "eval_episode/score": 0.625, "eval_episode/reward_rate": 0.008264462809917356}
{"step": 630032, "time": 19884.044358491898, "eval_episode/length": 78.0, "eval_episode/score": 0.7562500238418579, "eval_episode/reward_rate": 0.012658227848101266}
{"step": 630136, "time": 19887.00510406494, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 630176, "time": 19888.461190223694, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 630320, "time": 19892.882539510727, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 630416, "time": 19895.84459733963, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 630536, "time": 19899.444864988327, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 630832, "time": 19909.317308664322, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 630840, "time": 19909.344938516617, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 630840, "time": 19909.35290312767, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 631104, "time": 19917.6754488945, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 631224, "time": 19921.137484788895, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 631344, "time": 19925.033179998398, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 631448, "time": 19928.075083971024, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 631680, "time": 19935.449562072754, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 631912, "time": 19942.318331718445, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 631944, "time": 19943.30069589615, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 631992, "time": 19944.801671028137, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 631992, "time": 19944.810089349747, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 632024, "time": 19945.802955389023, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 632072, "time": 19947.26951432228, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 632288, "time": 19954.14591407776, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 632448, "time": 19959.143781900406, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 632496, "time": 19960.617438554764, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 632520, "time": 19961.13308119774, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 632744, "time": 19968.014162540436, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 632824, "time": 19970.474316835403, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 632880, "time": 19972.412018299103, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 633088, "time": 19978.80313515663, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 633248, "time": 19983.698617219925, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 633520, "time": 19992.116722106934, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 633568, "time": 19993.602222919464, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 633648, "time": 19996.094136714935, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 633864, "time": 20002.54206085205, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 633992, "time": 20006.51259446144, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 634032, "time": 20007.999145269394, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 634184, "time": 20012.445504188538, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 634384, "time": 20018.90282678604, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 634392, "time": 20018.93029975891, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 634392, "time": 20018.93907570839, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 634552, "time": 20023.88347887993, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 634744, "time": 20029.7981569767, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 635288, "time": 20046.703655719757, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 635400, "time": 20050.191086530685, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 635736, "time": 20060.490878582, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 636400, "time": 20081.323812007904, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 636496, "time": 20084.287848711014, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 636584, "time": 20086.785561323166, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 636696, "time": 20090.250406980515, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 636704, "time": 20090.72451543808, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 636704, "time": 20090.73139977455, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 636864, "time": 20095.63080716133, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 637040, "time": 20101.036093473434, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 637096, "time": 20102.56262755394, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 637184, "time": 20105.49106144905, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 637408, "time": 20112.441834926605, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 637576, "time": 20117.355948209763, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 637776, "time": 20123.744525194168, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 637920, "time": 20128.175131320953, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 637960, "time": 20129.193217277527, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 638008, "time": 20130.660937547684, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 638040, "time": 20131.665503263474, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 638048, "time": 20132.144543886185, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 638584, "time": 20148.449996232986, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 638624, "time": 20149.905947446823, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 638912, "time": 20158.708832263947, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 638992, "time": 20161.735385894775, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 639016, "time": 20162.26186275482, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 639424, "time": 20175.11570072174, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 639448, "time": 20175.632224559784, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 639696, "time": 20183.511120319366, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 639912, "time": 20189.914529800415, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 640016, "time": 20194.911873340607, "eval_episode/length": 78.0, "eval_episode/score": 0.7562500238418579, "eval_episode/reward_rate": 0.012658227848101266}
{"step": 640016, "time": 20195.30892777443, "eval_episode/length": 18.0, "eval_episode/score": 0.9437500238418579, "eval_episode/reward_rate": 0.05263157894736842}
{"step": 640016, "time": 20195.699019908905, "eval_episode/length": 116.0, "eval_episode/score": 0.637499988079071, "eval_episode/reward_rate": 0.008547008547008548}
{"step": 640016, "time": 20196.15717482567, "eval_episode/length": 139.0, "eval_episode/score": 0.565625011920929, "eval_episode/reward_rate": 0.007142857142857143}
{"step": 640016, "time": 20196.226053476334, "eval_episode/length": 142.0, "eval_episode/score": 0.5562499761581421, "eval_episode/reward_rate": 0.006993006993006993}
{"step": 640016, "time": 20197.87462234497, "eval_episode/length": 100.0, "eval_episode/score": 0.6875, "eval_episode/reward_rate": 0.009900990099009901}
{"step": 640016, "time": 20197.97658586502, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 640016, "time": 20198.081933259964, "eval_episode/length": 129.0, "eval_episode/score": 0.596875011920929, "eval_episode/reward_rate": 0.007692307692307693}
{"step": 640080, "time": 20200.042365074158, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 640088, "time": 20200.073040485382, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 640328, "time": 20207.447972774506, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 640352, "time": 20208.409152269363, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 640360, "time": 20208.438677072525, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 640392, "time": 20209.418689012527, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 640400, "time": 20209.889117002487, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 640496, "time": 20212.8269636631, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 640512, "time": 20213.319582939148, "episode/length": 18.0, "episode/score": 0.9437500238418579, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.0}
{"step": 640872, "time": 20224.088591337204, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 640904, "time": 20225.06819295883, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 641160, "time": 20233.027829170227, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 641304, "time": 20237.433806419373, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 641704, "time": 20249.68341612816, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 641872, "time": 20255.07024216652, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 641976, "time": 20258.11944913864, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 642073, "time": 20262.07253241539, "train_stats/mean_log_entropy": 0.0802768796713928, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.482754961330088, "train/action_min": 0.0, "train/action_std": 1.7410983332437486, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.010285230722025637, "train/actor_opt_grad_steps": 39040.0, "train/actor_opt_loss": -13.766176393882713, "train/adv_mag": 0.9632525174462017, "train/adv_max": 0.41923183232695616, "train/adv_mean": -7.85880674423301e-05, "train/adv_min": -0.9138312561428128, "train/adv_std": 0.02613373678037195, "train/cont_avg": 0.9950386699120602, "train/cont_loss_mean": 0.016856217704217264, "train/cont_loss_std": 0.23369184697524237, "train/cont_neg_acc": 0.34678225926867684, "train/cont_neg_loss": 2.67174466767924, "train/cont_pos_acc": 0.999832331834726, "train/cont_pos_loss": 0.0035872634906256246, "train/cont_pred": 0.9949222153155648, "train/cont_rate": 0.9950386699120602, "train/dyn_loss_mean": 1.000001654553054, "train/dyn_loss_std": 5.291557306863704e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.11912212369673365, "train/extr_critic_critic_opt_grad_steps": 39040.0, "train/extr_critic_critic_opt_loss": 12183.80358334642, "train/extr_critic_mag": 1.4050615289103445, "train/extr_critic_max": 1.4050615289103445, "train/extr_critic_mean": 1.312739387828501, "train/extr_critic_min": 0.8786824067034315, "train/extr_critic_std": 0.02135694918489486, "train/extr_return_normed_mag": 1.024561108656265, "train/extr_return_normed_max": 0.28241044312865293, "train/extr_return_normed_mean": 0.03781800090929671, "train/extr_return_normed_min": -0.9785589461949602, "train/extr_return_normed_std": 0.03366850744277688, "train/extr_return_rate": 0.999532208370803, "train/extr_return_raw_mag": 1.5572531468904198, "train/extr_return_raw_max": 1.5572531468904198, "train/extr_return_raw_mean": 1.3126607648092299, "train/extr_return_raw_min": 0.29628375756680664, "train/extr_return_raw_std": 0.033668507480216985, "train/extr_reward_mag": 0.29920296992488843, "train/extr_reward_max": 0.29920296992488843, "train/extr_reward_mean": 0.0019845231872019195, "train/extr_reward_min": 2.6837066190326633e-07, "train/extr_reward_std": 0.007384158230981036, "train/image_loss_mean": 0.08584947348689315, "train/image_loss_std": 0.10077485303633177, "train/model_loss_mean": 0.7152163488181991, "train/model_loss_std": 0.4398605526616825, "train/model_opt_grad_norm": 21.855904885871926, "train/model_opt_grad_steps": 39005.25628140703, "train/model_opt_loss": 3792.1652684810774, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5301.507537688442, "train/policy_entropy_mag": 1.3655530304165941, "train/policy_entropy_max": 1.3655530304165941, "train/policy_entropy_mean": 0.09872104819096512, "train/policy_entropy_min": 0.06468649369538129, "train/policy_entropy_std": 0.12748988448225673, "train/policy_logprob_mag": 6.551080243671359, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.0985873269300964, "train/policy_logprob_min": -6.551080243671359, "train/policy_logprob_std": 0.6364516705723863, "train/policy_randomness_mag": 0.7017554793525581, "train/policy_randomness_max": 0.7017554793525581, "train/policy_randomness_mean": 0.050732585409628085, "train/policy_randomness_min": 0.033242282331289355, "train/policy_randomness_std": 0.06551684399870172, "train/post_ent_mag": 28.719715118408203, "train/post_ent_max": 28.719715118408203, "train/post_ent_mean": 28.22276978995932, "train/post_ent_min": 27.898730196545472, "train/post_ent_std": 0.15814028800132884, "train/prior_ent_mag": 28.521652384619017, "train/prior_ent_max": 28.521652384619017, "train/prior_ent_mean": 28.04655237054106, "train/prior_ent_min": 27.209836720222206, "train/prior_ent_std": 0.1929522263045287, "train/rep_loss_mean": 1.000001654553054, "train/rep_loss_std": 5.291557306863704e-05, "train/reward_avg": 0.0015962226978847149, "train/reward_loss_mean": 0.012509638621429703, "train/reward_loss_std": 0.2074273243551166, "train/reward_max_data": 0.7200062818563164, "train/reward_max_pred": 0.2098460952241217, "train/reward_neg_acc": 0.9997048545722387, "train/reward_neg_loss": 0.002294416219375129, "train/reward_pos_acc": 0.14828829008179742, "train/reward_pos_loss": 4.368844419878882, "train/reward_pred": 0.0013440300361838324, "train/reward_rate": 0.002389879082914573, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.025715574622154236, "report/cont_loss_std": 0.2792229652404785, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 3.2684719562530518, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.003395716892555356, "report/cont_pred": 0.9962807893753052, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.0965287983417511, "report/image_loss_std": 0.10986607521772385, "report/model_loss_mean": 0.7413241267204285, "report/model_loss_std": 0.5475267767906189, "report/post_ent_mag": 28.609895706176758, "report/post_ent_max": 28.609895706176758, "report/post_ent_mean": 28.11377716064453, "report/post_ent_min": 27.793212890625, "report/post_ent_std": 0.1626334935426712, "report/prior_ent_mag": 28.500118255615234, "report/prior_ent_max": 28.500118255615234, "report/prior_ent_mean": 28.017654418945312, "report/prior_ent_min": 27.242839813232422, "report/prior_ent_std": 0.19864241778850555, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00311279296875, "report/reward_loss_mean": 0.019079742953181267, "report/reward_loss_std": 0.26476263999938965, "report/reward_max_data": 0.856249988079071, "report/reward_max_pred": 0.04076647758483887, "report/reward_neg_acc": 0.9999999403953552, "report/reward_neg_loss": 0.0025234604254364967, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.240931510925293, "report/reward_pred": 0.0013585960259661078, "report/reward_rate": 0.00390625, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.028038188815116882, "eval/cont_loss_std": 0.5265048742294312, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 8.36851978302002, "eval/cont_pos_acc": 0.999020516872406, "eval/cont_pos_loss": 0.003531385911628604, "eval/cont_pred": 0.9969722032546997, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.20483733713626862, "eval/image_loss_std": 0.1635775864124298, "eval/model_loss_mean": 0.8357188701629639, "eval/model_loss_std": 0.5554769039154053, "eval/post_ent_mag": 28.603199005126953, "eval/post_ent_max": 28.603199005126953, "eval/post_ent_mean": 28.033723831176758, "eval/post_ent_min": 27.757265090942383, "eval/post_ent_std": 0.15495796501636505, "eval/prior_ent_mag": 28.490163803100586, "eval/prior_ent_max": 28.490163803100586, "eval/prior_ent_mean": 28.032386779785156, "eval/prior_ent_min": 27.173795700073242, "eval/prior_ent_std": 0.19057846069335938, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0008514404180459678, "eval/reward_loss_mean": 0.0028432896360754967, "eval/reward_loss_std": 0.05392967164516449, "eval/reward_max_data": 0.871874988079071, "eval/reward_max_pred": 0.2136460542678833, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.001167071284726262, "eval/reward_pos_acc": 1.0, "eval/reward_pos_loss": 1.7176145315170288, "eval/reward_pred": 0.0008106455206871033, "eval/reward_rate": 0.0009765625, "replay/size": 641569.0, "replay/inserts": 31848.0, "replay/samples": 31856.0, "replay/insert_wait_avg": 1.394525600779269e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.950126883613591e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5768.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3164690231979306e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.2069940567016602e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0299136638641, "timer/env.step_count": 3981.0, "timer/env.step_total": 39.655946254730225, "timer/env.step_frac": 0.03965476003556791, "timer/env.step_avg": 0.009961302751753385, "timer/env.step_min": 0.007908821105957031, "timer/env.step_max": 0.03626704216003418, "timer/replay._sample_count": 31856.0, "timer/replay._sample_total": 17.138648986816406, "timer/replay._sample_frac": 0.0171381363223672, "timer/replay._sample_avg": 0.0005380037979286918, "timer/replay._sample_min": 0.00041174888610839844, "timer/replay._sample_max": 0.025024890899658203, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4702.0, "timer/agent.policy_total": 51.277645111083984, "timer/agent.policy_frac": 0.05127611125472765, "timer/agent.policy_avg": 0.010905496620817521, "timer/agent.policy_min": 0.009350299835205078, "timer/agent.policy_max": 0.08824706077575684, "timer/dataset_train_count": 1991.0, "timer/dataset_train_total": 0.23029184341430664, "timer/dataset_train_frac": 0.00023028495474757736, "timer/dataset_train_avg": 0.00011566642059985266, "timer/dataset_train_min": 9.942054748535156e-05, "timer/dataset_train_max": 0.0004553794860839844, "timer/agent.train_count": 1991.0, "timer/agent.train_total": 894.9727191925049, "timer/agent.train_frac": 0.8949459480802374, "timer/agent.train_avg": 0.44950915077473874, "timer/agent.train_min": 0.43865180015563965, "timer/agent.train_max": 0.7186920642852783, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4787716865539551, "timer/agent.report_frac": 0.000478757365167061, "timer/agent.report_avg": 0.23938584327697754, "timer/agent.report_min": 0.23221874237060547, "timer/agent.report_max": 0.2465529441833496, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0994415283203125e-05, "timer/dataset_eval_frac": 3.09934881544165e-08, "timer/dataset_eval_avg": 3.0994415283203125e-05, "timer/dataset_eval_min": 3.0994415283203125e-05, "timer/dataset_eval_max": 3.0994415283203125e-05, "fps": 31.84653456575613}
{"step": 642120, "time": 20263.299791812897, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 642120, "time": 20263.30769634247, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 642152, "time": 20264.286146879196, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 642360, "time": 20270.65442633629, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 642632, "time": 20278.936478853226, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 642664, "time": 20279.918655872345, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 642808, "time": 20284.355538129807, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 642824, "time": 20284.857231378555, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 643360, "time": 20301.678685426712, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 643384, "time": 20302.194763183594, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 643392, "time": 20302.66962146759, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 643440, "time": 20304.155509710312, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 643664, "time": 20311.023109197617, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 643896, "time": 20318.014461517334, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 644016, "time": 20321.926916122437, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 644376, "time": 20332.698434829712, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 644432, "time": 20334.645166397095, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 644544, "time": 20338.038288593292, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 644560, "time": 20338.529061555862, "episode/length": 236.0, "episode/score": 0.26249998807907104, "episode/reward_rate": 0.004219409282700422, "episode/intrinsic_return": 0.0}
{"step": 644592, "time": 20339.5290081501, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 644840, "time": 20346.937945127487, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 644944, "time": 20350.343824386597, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 645240, "time": 20359.150547027588, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 645248, "time": 20359.62278485298, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 645248, "time": 20359.63103246689, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 645400, "time": 20364.058410406113, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 645576, "time": 20369.428272485733, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 645600, "time": 20370.3811211586, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 645672, "time": 20372.37838292122, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 645760, "time": 20375.307188034058, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 645976, "time": 20381.764446735382, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 646312, "time": 20392.0133125782, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 646312, "time": 20392.023470401764, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 646320, "time": 20392.49524617195, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 646584, "time": 20400.32466006279, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 647072, "time": 20415.617780447006, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 647096, "time": 20416.136172294617, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 647112, "time": 20416.62921690941, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 647168, "time": 20418.728417158127, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 647208, "time": 20420.09516954422, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 647264, "time": 20422.056612730026, "episode/length": 20.0, "episode/score": 0.9375, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.0}
{"step": 647512, "time": 20429.413402080536, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 647560, "time": 20430.8805642128, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 647696, "time": 20435.241016626358, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 647728, "time": 20436.22109556198, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 647912, "time": 20441.729030132294, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 648072, "time": 20446.61589026451, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 648080, "time": 20447.08911037445, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 648088, "time": 20447.140543222427, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 648240, "time": 20452.011023759842, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 648336, "time": 20454.94323015213, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 648416, "time": 20457.37202000618, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 648704, "time": 20466.204476356506, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 648784, "time": 20468.77970480919, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 648952, "time": 20473.700778245926, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 649000, "time": 20475.18350315094, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 649112, "time": 20478.617824554443, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 649184, "time": 20481.068043231964, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 649520, "time": 20491.345423698425, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 649544, "time": 20491.860985279083, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 649584, "time": 20493.32422351837, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 649640, "time": 20494.822716236115, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 649640, "time": 20494.830607652664, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 649784, "time": 20499.35888361931, "episode/length": 17.0, "episode/score": 0.9468749761581421, "episode/reward_rate": 0.05555555555555555, "episode/intrinsic_return": 0.0}
{"step": 649952, "time": 20504.6893324852, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 650000, "time": 20506.863089323044, "eval_episode/length": 35.0, "eval_episode/score": 0.890625, "eval_episode/reward_rate": 0.027777777777777776}
{"step": 650000, "time": 20507.06328678131, "eval_episode/length": 45.0, "eval_episode/score": 0.859375, "eval_episode/reward_rate": 0.021739130434782608}
{"step": 650000, "time": 20507.549840688705, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 650000, "time": 20507.87986588478, "eval_episode/length": 85.0, "eval_episode/score": 0.734375, "eval_episode/reward_rate": 0.011627906976744186}
{"step": 650000, "time": 20508.468814373016, "eval_episode/length": 114.0, "eval_episode/score": 0.643750011920929, "eval_episode/reward_rate": 0.008695652173913044}
{"step": 650000, "time": 20508.869398593903, "eval_episode/length": 134.0, "eval_episode/score": 0.581250011920929, "eval_episode/reward_rate": 0.007407407407407408}
{"step": 650000, "time": 20509.344339847565, "eval_episode/length": 94.0, "eval_episode/score": 0.706250011920929, "eval_episode/reward_rate": 0.010526315789473684}
{"step": 650000, "time": 20509.879855632782, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 650008, "time": 20509.90567803383, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 650184, "time": 20515.29198050499, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 650232, "time": 20516.777501821518, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 650384, "time": 20521.608070373535, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 650456, "time": 20523.576342344284, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 650600, "time": 20528.05225110054, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 650616, "time": 20528.542229413986, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 650880, "time": 20536.83851838112, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 650928, "time": 20538.29187464714, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 651056, "time": 20542.203667402267, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 651056, "time": 20542.21261024475, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 651288, "time": 20549.140282392502, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 651496, "time": 20555.50713467598, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 651776, "time": 20564.348900079727, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 651856, "time": 20566.81133031845, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 651944, "time": 20569.26138830185, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 651960, "time": 20569.77279639244, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 652056, "time": 20572.664139032364, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 652360, "time": 20581.90149641037, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 652904, "time": 20598.59308409691, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 652912, "time": 20599.08966422081, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 652912, "time": 20599.099495887756, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 652952, "time": 20600.116096258163, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 653240, "time": 20608.919417142868, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 653432, "time": 20614.800864219666, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 653704, "time": 20623.18885564804, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 653864, "time": 20628.090054512024, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 654000, "time": 20632.480739831924, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 654128, "time": 20636.412343502045, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 654176, "time": 20637.879133701324, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 654256, "time": 20640.340252637863, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 654368, "time": 20643.786319971085, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 654672, "time": 20653.217260360718, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 654680, "time": 20653.24883699417, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 654768, "time": 20656.180414438248, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 654992, "time": 20663.019647598267, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 655048, "time": 20664.51926469803, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 655072, "time": 20665.487808942795, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 655392, "time": 20675.7191927433, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 655784, "time": 20687.55705499649, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 655808, "time": 20688.535480499268, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 656016, "time": 20694.909860372543, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 656040, "time": 20695.426342964172, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 656464, "time": 20708.694900035858, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 656568, "time": 20711.69554209709, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 656680, "time": 20715.18106174469, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 656832, "time": 20720.03649020195, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 656880, "time": 20721.502504587173, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 656896, "time": 20721.998643636703, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 657080, "time": 20727.447340250015, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 657088, "time": 20727.914526462555, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 657200, "time": 20731.306052684784, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 657576, "time": 20742.711354970932, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 657704, "time": 20746.64804005623, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 657976, "time": 20755.004285812378, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 658208, "time": 20762.341214179993, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 658264, "time": 20763.843413114548, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 658600, "time": 20774.28540635109, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 658992, "time": 20786.62565279007, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 659208, "time": 20793.065948724747, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 659392, "time": 20799.087740421295, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 659480, "time": 20801.618537664413, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 659512, "time": 20802.60726094246, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 659888, "time": 20814.438215970993, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 660016, "time": 20818.43630361557, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 660072, "time": 20819.94683289528, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 660088, "time": 20821.786218881607, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 660088, "time": 20821.825078964233, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 660088, "time": 20822.27734899521, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 660088, "time": 20822.325890541077, "eval_episode/length": 22.0, "eval_episode/score": 0.9312499761581421, "eval_episode/reward_rate": 0.043478260869565216}
{"step": 660088, "time": 20822.56096816063, "eval_episode/length": 95.0, "eval_episode/score": 0.703125, "eval_episode/reward_rate": 0.010416666666666666}
{"step": 660088, "time": 20824.007949352264, "eval_episode/length": 161.0, "eval_episode/score": 0.49687498807907104, "eval_episode/reward_rate": 0.006172839506172839}
{"step": 660088, "time": 20824.459923028946, "eval_episode/length": 182.0, "eval_episode/score": 0.4312500059604645, "eval_episode/reward_rate": 0.00546448087431694}
{"step": 660088, "time": 20824.642153978348, "eval_episode/length": 105.0, "eval_episode/score": 0.671875, "eval_episode/reward_rate": 0.009433962264150943}
{"step": 660288, "time": 20833.022036790848, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 660288, "time": 20833.03049683571, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 661048, "time": 20856.18895125389, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 661368, "time": 20866.166741132736, "episode/length": 246.0, "episode/score": 0.23125000298023224, "episode/reward_rate": 0.004048582995951417, "episode/intrinsic_return": 0.0}
{"step": 661400, "time": 20867.172930002213, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 661520, "time": 20871.067370176315, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 661824, "time": 20880.434033870697, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 662208, "time": 20892.408577919006, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 662272, "time": 20894.406784534454, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 662384, "time": 20897.936625003815, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 662600, "time": 20904.3802382946, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 662600, "time": 20904.389807462692, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 662624, "time": 20905.359446525574, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 663032, "time": 20917.85888171196, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 663272, "time": 20925.296558856964, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 663328, "time": 20927.266739845276, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 663360, "time": 20928.252372264862, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 663640, "time": 20937.210612297058, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 663672, "time": 20938.197153806686, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 663768, "time": 20941.161194562912, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 663824, "time": 20943.13862347603, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 663896, "time": 20945.126947164536, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 664136, "time": 20952.652289152145, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 664376, "time": 20960.021421909332, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 664696, "time": 20969.851234436035, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 664864, "time": 20975.25960612297, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 664888, "time": 20975.777941703796, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 664976, "time": 20978.823043346405, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 665016, "time": 20979.829439401627, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 665344, "time": 20990.19840669632, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 665472, "time": 20994.136781692505, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 665712, "time": 21001.518444776535, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 665760, "time": 21003.001477956772, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 665784, "time": 21003.521617650986, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 665800, "time": 21004.016068458557, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 665984, "time": 21009.97148013115, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 666336, "time": 21020.85202050209, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 666448, "time": 21024.285852193832, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 666456, "time": 21024.314187049866, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 666544, "time": 21027.266683101654, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 666856, "time": 21036.77907896042, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 666912, "time": 21038.724343061447, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 667432, "time": 21054.56133413315, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 667448, "time": 21055.055468082428, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 667664, "time": 21061.925887584686, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 667784, "time": 21065.40292286873, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 668072, "time": 21074.39830350876, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 668096, "time": 21075.36237025261, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 668112, "time": 21075.88068509102, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 668160, "time": 21077.357404708862, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 668736, "time": 21095.15720653534, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 668760, "time": 21095.697015047073, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 668776, "time": 21096.19501376152, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 669616, "time": 21122.51367998123, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 669640, "time": 21123.039536714554, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 669760, "time": 21127.087541103363, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 669976, "time": 21133.52822971344, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 670072, "time": 21137.15244793892, "eval_episode/length": 32.0, "eval_episode/score": 0.8999999761581421, "eval_episode/reward_rate": 0.030303030303030304}
{"step": 670072, "time": 21137.35734987259, "eval_episode/length": 42.0, "eval_episode/score": 0.8687499761581421, "eval_episode/reward_rate": 0.023255813953488372}
{"step": 670072, "time": 21138.374089956284, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 670072, "time": 21138.524035453796, "eval_episode/length": 99.0, "eval_episode/score": 0.690625011920929, "eval_episode/reward_rate": 0.01}
{"step": 670072, "time": 21139.612928390503, "eval_episode/length": 119.0, "eval_episode/score": 0.628125011920929, "eval_episode/reward_rate": 0.008333333333333333}
{"step": 670072, "time": 21140.95489692688, "eval_episode/length": 124.0, "eval_episode/score": 0.612500011920929, "eval_episode/reward_rate": 0.008}
{"step": 670072, "time": 21141.4033036232, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 670072, "time": 21141.888263702393, "eval_episode/length": 163.0, "eval_episode/score": 0.4906249940395355, "eval_episode/reward_rate": 0.006097560975609756}
{"step": 670384, "time": 21151.698860406876, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 670408, "time": 21152.225915908813, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 670424, "time": 21152.723402023315, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 670848, "time": 21166.068155050278, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 671072, "time": 21172.941073656082, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 671104, "time": 21173.936805009842, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 671112, "time": 21173.965633630753, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 671504, "time": 21186.268125772476, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 671608, "time": 21189.344327926636, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 671680, "time": 21191.794217586517, "episode/length": 254.0, "episode/score": 0.20624999701976776, "episode/reward_rate": 0.00392156862745098, "episode/intrinsic_return": 0.0}
{"step": 671832, "time": 21196.878168582916, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 672072, "time": 21204.26187801361, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 672096, "time": 21205.23917198181, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 672120, "time": 21205.784969568253, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 672288, "time": 21211.202062368393, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 672504, "time": 21217.75473690033, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 672648, "time": 21222.176797628403, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 672752, "time": 21225.60367655754, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 672800, "time": 21227.081349134445, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 672824, "time": 21227.59932422638, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 672872, "time": 21229.070405960083, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 673160, "time": 21237.96224617958, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 673504, "time": 21248.970096588135, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 673632, "time": 21252.955224514008, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 673913, "time": 21262.336180210114, "train_stats/mean_log_entropy": 0.07985820181948959, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.48628457227544, "train/action_min": 0.0, "train/action_std": 1.6788220267799032, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.009760826737175335, "train/actor_opt_grad_steps": 41030.0, "train/actor_opt_loss": -13.119975693261804, "train/adv_mag": 0.9539070953076808, "train/adv_max": 0.45924621550881084, "train/adv_mean": 0.0015019099887399192, "train/adv_min": -0.8796269543206872, "train/adv_std": 0.028642500984721146, "train/cont_avg": 0.9948472832914573, "train/cont_loss_mean": 0.017302776232885956, "train/cont_loss_std": 0.23384349522690975, "train/cont_neg_acc": 0.34009941347470185, "train/cont_neg_loss": 2.639244999877657, "train/cont_pos_acc": 0.9999112759403248, "train/cont_pos_loss": 0.003572088603080068, "train/cont_pred": 0.9948288642581383, "train/cont_rate": 0.9948472832914573, "train/dyn_loss_mean": 1.0000000527156658, "train/dyn_loss_std": 1.684168907088326e-06, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.14755390254059927, "train/extr_critic_critic_opt_grad_steps": 41030.0, "train/extr_critic_critic_opt_loss": 11936.617481940955, "train/extr_critic_mag": 1.4290058217455994, "train/extr_critic_max": 1.4290058217455994, "train/extr_critic_mean": 1.3093063226297272, "train/extr_critic_min": 0.8117346350272098, "train/extr_critic_std": 0.02406685302342901, "train/extr_return_normed_mag": 1.0248521177013914, "train/extr_return_normed_max": 0.328255182534606, "train/extr_return_normed_mean": 0.04459282571459236, "train/extr_return_normed_min": -0.968232159039483, "train/extr_return_normed_std": 0.03751216139925185, "train/extr_return_rate": 0.9995884811458875, "train/extr_return_raw_mag": 1.5944706009860015, "train/extr_return_raw_max": 1.5944706009860015, "train/extr_return_raw_mean": 1.310808311155693, "train/extr_return_raw_min": 0.29798325941191245, "train/extr_return_raw_std": 0.03751216152093219, "train/extr_reward_mag": 0.3244520186179846, "train/extr_reward_max": 0.3244520186179846, "train/extr_reward_mean": 0.0020306649768196197, "train/extr_reward_min": 2.486022872541418e-07, "train/extr_reward_std": 0.008787139871124946, "train/image_loss_mean": 0.08451319798527651, "train/image_loss_std": 0.09974768469531332, "train/model_loss_mean": 0.7154146220216799, "train/model_loss_std": 0.45128347196770674, "train/model_opt_grad_norm": 21.77208861633761, "train/model_opt_grad_steps": 40993.26633165829, "train/model_opt_loss": 2677.8954538316584, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3743.718592964824, "train/policy_entropy_mag": 1.3555402905497718, "train/policy_entropy_max": 1.3555402905497718, "train/policy_entropy_mean": 0.1012028124389337, "train/policy_entropy_min": 0.0646864990493161, "train/policy_entropy_std": 0.13044508524126744, "train/policy_logprob_mag": 6.551080238879027, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.10118783531176984, "train/policy_logprob_min": -6.551080238879027, "train/policy_logprob_std": 0.639492742679826, "train/policy_randomness_mag": 0.6966099493467628, "train/policy_randomness_max": 0.6966099493467628, "train/policy_randomness_mean": 0.05200796009008609, "train/policy_randomness_min": 0.03324228525161743, "train/policy_randomness_std": 0.06703551699543119, "train/post_ent_mag": 28.620069618800176, "train/post_ent_max": 28.620069618800176, "train/post_ent_mean": 28.07253124486262, "train/post_ent_min": 27.702891479185478, "train/post_ent_std": 0.17927262456572834, "train/prior_ent_mag": 28.465856820494686, "train/prior_ent_max": 28.465856820494686, "train/prior_ent_mean": 27.975461911915534, "train/prior_ent_min": 27.12707941256576, "train/prior_ent_std": 0.19821957637317217, "train/rep_loss_mean": 1.0000000527156658, "train/rep_loss_std": 1.684168907088326e-06, "train/reward_avg": 0.001844764584599381, "train/reward_loss_mean": 0.013598595454530725, "train/reward_loss_std": 0.2157015445883194, "train/reward_max_data": 0.7329616817697209, "train/reward_max_pred": 0.23515012815370032, "train/reward_neg_acc": 0.9997293658591994, "train/reward_neg_loss": 0.002353552719531347, "train/reward_pos_acc": 0.14959256621924313, "train/reward_pos_loss": 4.293055397303984, "train/reward_pred": 0.001434426552302499, "train/reward_rate": 0.0026646906407035175, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.018432624638080597, "report/cont_loss_std": 0.2889210283756256, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.198798656463623, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0032111788168549538, "report/cont_pred": 0.9968287348747253, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.0937529057264328, "report/image_loss_std": 0.1083790585398674, "report/model_loss_mean": 0.7257309556007385, "report/model_loss_std": 0.5277077555656433, "report/post_ent_mag": 28.844810485839844, "report/post_ent_max": 28.844810485839844, "report/post_ent_mean": 28.241802215576172, "report/post_ent_min": 27.840312957763672, "report/post_ent_std": 0.17993934452533722, "report/prior_ent_mag": 28.488067626953125, "report/prior_ent_max": 28.488067626953125, "report/prior_ent_mean": 27.95673370361328, "report/prior_ent_min": 27.234464645385742, "report/prior_ent_std": 0.2143218219280243, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0013916015159338713, "report/reward_loss_mean": 0.01354542188346386, "report/reward_loss_std": 0.2524549961090088, "report/reward_max_data": 0.875, "report/reward_max_pred": 0.14366161823272705, "report/reward_neg_acc": 0.9990215301513672, "report/reward_neg_loss": 0.0025481542106717825, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 5.633149147033691, "report/reward_pred": 0.0012985580833628774, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.06559652835130692, "eval/cont_loss_std": 0.8409926295280457, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 10.761274337768555, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0025571798905730247, "eval/cont_pred": 0.997582733631134, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.1468982994556427, "eval/image_loss_std": 0.1305113434791565, "eval/model_loss_mean": 0.8357855081558228, "eval/model_loss_std": 1.2392606735229492, "eval/post_ent_mag": 28.844783782958984, "eval/post_ent_max": 28.844783782958984, "eval/post_ent_mean": 28.19717788696289, "eval/post_ent_min": 27.777408599853516, "eval/post_ent_std": 0.17854057252407074, "eval/prior_ent_mag": 28.488121032714844, "eval/prior_ent_max": 28.488121032714844, "eval/prior_ent_mean": 27.953319549560547, "eval/prior_ent_min": 27.056102752685547, "eval/prior_ent_std": 0.22676847875118256, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0012725830310955644, "eval/reward_loss_mean": 0.023290682584047318, "eval/reward_loss_std": 0.5236228108406067, "eval/reward_max_data": 0.753125011920929, "eval/reward_max_pred": 0.0480121374130249, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.000910657225176692, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 11.459482192993164, "eval/reward_pred": 0.00044480536598712206, "eval/reward_rate": 0.001953125, "replay/size": 673409.0, "replay/inserts": 31840.0, "replay/samples": 31840.0, "replay/insert_wait_avg": 1.4094476723790768e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.274961960375608e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4872.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.212890903742247e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0728836059570312e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2488234043121, "timer/env.step_count": 3980.0, "timer/env.step_total": 39.85019779205322, "timer/env.step_frac": 0.03984028459681108, "timer/env.step_avg": 0.010012612510566137, "timer/env.step_min": 0.007993936538696289, "timer/env.step_max": 0.0414576530456543, "timer/replay._sample_count": 31840.0, "timer/replay._sample_total": 17.165802717208862, "timer/replay._sample_frac": 0.017161532526262464, "timer/replay._sample_avg": 0.0005391269697615849, "timer/replay._sample_min": 0.0003819465637207031, "timer/replay._sample_max": 0.011871814727783203, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4589.0, "timer/agent.policy_total": 50.90165090560913, "timer/agent.policy_frac": 0.05088898853424004, "timer/agent.policy_avg": 0.011092100872871897, "timer/agent.policy_min": 0.009096860885620117, "timer/agent.policy_max": 0.09925198554992676, "timer/dataset_train_count": 1990.0, "timer/dataset_train_total": 0.230757474899292, "timer/dataset_train_frac": 0.00023070007132217055, "timer/dataset_train_avg": 0.00011595853010014672, "timer/dataset_train_min": 9.822845458984375e-05, "timer/dataset_train_max": 0.0003552436828613281, "timer/agent.train_count": 1990.0, "timer/agent.train_total": 896.6051032543182, "timer/agent.train_frac": 0.896382062417983, "timer/agent.train_avg": 0.45055532826850164, "timer/agent.train_min": 0.4374964237213135, "timer/agent.train_max": 2.2245891094207764, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47251272201538086, "timer/agent.report_frac": 0.0004723951790387518, "timer/agent.report_avg": 0.23625636100769043, "timer/agent.report_min": 0.22962260246276855, "timer/agent.report_max": 0.2428901195526123, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.1948089599609375e-05, "timer/dataset_eval_frac": 3.194014214470672e-08, "timer/dataset_eval_avg": 3.1948089599609375e-05, "timer/dataset_eval_min": 3.1948089599609375e-05, "timer/dataset_eval_max": 3.1948089599609375e-05, "fps": 31.831550398404023}
{"step": 674160, "time": 21270.01584649086, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 674256, "time": 21273.016030550003, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 674392, "time": 21277.08763742447, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 674816, "time": 21290.42335987091, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 674960, "time": 21294.864405870438, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 675112, "time": 21299.299181699753, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 675216, "time": 21302.742439985275, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 675392, "time": 21308.269761800766, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 675448, "time": 21309.761005163193, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 675472, "time": 21310.747042655945, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 675656, "time": 21316.23630976677, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 675928, "time": 21324.592561006546, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 675944, "time": 21325.1003742218, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 676112, "time": 21330.55377149582, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 676208, "time": 21333.525899648666, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 676472, "time": 21341.50885605812, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 676536, "time": 21343.469085931778, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 676808, "time": 21351.758948802948, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 676832, "time": 21352.708156108856, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 676872, "time": 21353.70064163208, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 677144, "time": 21361.92955803871, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 677320, "time": 21367.351729393005, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 677528, "time": 21373.74521255493, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 677536, "time": 21374.215800762177, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 677592, "time": 21375.72097969055, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 677632, "time": 21377.16434788704, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 677784, "time": 21381.55389022827, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 678056, "time": 21389.832013368607, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 678120, "time": 21391.767833709717, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 678384, "time": 21400.175011396408, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 678528, "time": 21404.53089952469, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 678560, "time": 21405.49812936783, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 678680, "time": 21408.913234233856, "episode/length": 18.0, "episode/score": 0.9437500238418579, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.0}
{"step": 678784, "time": 21412.30819129944, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 679184, "time": 21424.52747273445, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 679264, "time": 21427.057388544083, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 679632, "time": 21438.33786725998, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 679632, "time": 21438.358056545258, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 679744, "time": 21441.797926425934, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 679816, "time": 21443.795336961746, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 679904, "time": 21446.715913534164, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 679944, "time": 21447.90878009796, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 680056, "time": 21452.074766635895, "eval_episode/length": 20.0, "eval_episode/score": 0.9375, "eval_episode/reward_rate": 0.047619047619047616}
{"step": 680056, "time": 21452.421307325363, "eval_episode/length": 37.0, "eval_episode/score": 0.8843749761581421, "eval_episode/reward_rate": 0.02631578947368421}
{"step": 680056, "time": 21452.784014463425, "eval_episode/length": 54.0, "eval_episode/score": 0.831250011920929, "eval_episode/reward_rate": 0.01818181818181818}
{"step": 680056, "time": 21453.105538606644, "eval_episode/length": 31.0, "eval_episode/score": 0.903124988079071, "eval_episode/reward_rate": 0.03125}
{"step": 680056, "time": 21453.322392702103, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 680056, "time": 21453.427792787552, "eval_episode/length": 84.0, "eval_episode/score": 0.737500011920929, "eval_episode/reward_rate": 0.011764705882352941}
{"step": 680056, "time": 21454.152129411697, "eval_episode/length": 121.0, "eval_episode/score": 0.621874988079071, "eval_episode/reward_rate": 0.00819672131147541}
{"step": 680056, "time": 21454.873760461807, "eval_episode/length": 136.0, "eval_episode/score": 0.574999988079071, "eval_episode/reward_rate": 0.0072992700729927005}
{"step": 680376, "time": 21464.799550533295, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 680432, "time": 21466.756031513214, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 680600, "time": 21471.654246091843, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 680696, "time": 21474.57255768776, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 680720, "time": 21475.532871246338, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 680736, "time": 21476.02774119377, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 680784, "time": 21477.51003885269, "episode/length": 7.0, "episode/score": 0.9781249761581421, "episode/reward_rate": 0.125, "episode/intrinsic_return": 0.0}
{"step": 680832, "time": 21478.97668480873, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 680888, "time": 21480.45973920822, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 681296, "time": 21493.295724630356, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 681360, "time": 21495.269937992096, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 681376, "time": 21495.764959335327, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 681448, "time": 21497.748390197754, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 681664, "time": 21504.537603139877, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 681752, "time": 21507.015341997147, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 681968, "time": 21513.800720214844, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 682024, "time": 21515.29097390175, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 682432, "time": 21528.07637476921, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 682456, "time": 21528.59576678276, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 682544, "time": 21531.504653692245, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 683048, "time": 21546.818267583847, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 683200, "time": 21551.694212675095, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 683256, "time": 21553.165044784546, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 683296, "time": 21554.603068113327, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 683608, "time": 21563.886950731277, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 683760, "time": 21568.780677318573, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 684064, "time": 21578.163451194763, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 684144, "time": 21580.61564517021, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 684176, "time": 21581.59842300415, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 684240, "time": 21583.58224797249, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 684280, "time": 21584.599868535995, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 684312, "time": 21585.576322078705, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 684544, "time": 21592.87608909607, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 684744, "time": 21598.74696779251, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 684848, "time": 21602.1269698143, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 685040, "time": 21608.03503894806, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 685056, "time": 21608.520365953445, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 685200, "time": 21612.904232740402, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 685248, "time": 21614.38707447052, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 685312, "time": 21616.329140663147, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 685632, "time": 21626.090134859085, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 685752, "time": 21629.570512771606, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 685968, "time": 21636.421570539474, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 686224, "time": 21644.31532931328, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 686248, "time": 21644.824644088745, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 686376, "time": 21648.74708390236, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 686384, "time": 21649.221458911896, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 686600, "time": 21655.619946479797, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 686736, "time": 21660.030050754547, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 686816, "time": 21662.47868871689, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 686856, "time": 21663.526133537292, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 687008, "time": 21668.504910469055, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 687120, "time": 21671.91542506218, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 687160, "time": 21672.934492588043, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 687192, "time": 21673.91489839554, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 687248, "time": 21675.85777592659, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 687432, "time": 21681.2903008461, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 687440, "time": 21681.76553106308, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 687536, "time": 21684.71533036232, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 687672, "time": 21688.66367816925, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 687688, "time": 21689.1544444561, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 687856, "time": 21694.522663354874, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 687880, "time": 21695.04725575447, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 688032, "time": 21700.013906478882, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 688080, "time": 21701.49341750145, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 688480, "time": 21714.27396082878, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 688800, "time": 21724.13636445999, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 689112, "time": 21733.601135492325, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 689168, "time": 21735.52837753296, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 689344, "time": 21740.91003060341, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 689744, "time": 21753.163316249847, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 689984, "time": 21760.57062315941, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 690000, "time": 21761.071801900864, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 690008, "time": 21761.100563764572, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 690040, "time": 21763.629669189453, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 690040, "time": 21763.656057596207, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 690040, "time": 21764.33064389229, "eval_episode/length": 106.0, "eval_episode/score": 0.668749988079071, "eval_episode/reward_rate": 0.009345794392523364}
{"step": 690040, "time": 21764.526291131973, "eval_episode/length": 115.0, "eval_episode/score": 0.640625, "eval_episode/reward_rate": 0.008620689655172414}
{"step": 690040, "time": 21765.23073887825, "eval_episode/length": 149.0, "eval_episode/score": 0.534375011920929, "eval_episode/reward_rate": 0.006666666666666667}
{"step": 690040, "time": 21765.56202149391, "eval_episode/length": 91.0, "eval_episode/score": 0.715624988079071, "eval_episode/reward_rate": 0.010869565217391304}
{"step": 690040, "time": 21766.120465517044, "eval_episode/length": 85.0, "eval_episode/score": 0.734375, "eval_episode/reward_rate": 0.011627906976744186}
{"step": 690040, "time": 21766.821195602417, "eval_episode/length": 110.0, "eval_episode/score": 0.65625, "eval_episode/reward_rate": 0.009009009009009009}
{"step": 690088, "time": 21768.28469634056, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 690192, "time": 21771.712834835052, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 690720, "time": 21788.02274942398, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 690792, "time": 21789.990913152695, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 690936, "time": 21794.47291660309, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 691128, "time": 21800.375339508057, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 691296, "time": 21805.733395814896, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 691344, "time": 21807.226606607437, "episode/length": 199.0, "episode/score": 0.37812501192092896, "episode/reward_rate": 0.005, "episode/intrinsic_return": 0.0}
{"step": 691480, "time": 21811.137326717377, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 691560, "time": 21813.569098234177, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 691784, "time": 21820.467878580093, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 691792, "time": 21820.951505422592, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 691816, "time": 21821.456090927124, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 692224, "time": 21834.031422376633, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 692296, "time": 21836.004359960556, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 692296, "time": 21836.01434278488, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 692400, "time": 21839.38544869423, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 692568, "time": 21844.28355383873, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 692776, "time": 21850.73325228691, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 692944, "time": 21856.078960180283, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 692952, "time": 21856.108208417892, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 692960, "time": 21856.58306002617, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 692984, "time": 21857.10216474533, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 693008, "time": 21858.0639193058, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 693184, "time": 21863.44600367546, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 693328, "time": 21867.87137746811, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 693568, "time": 21875.19354367256, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 693664, "time": 21878.251120328903, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 693776, "time": 21881.681707143784, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 693800, "time": 21882.19642305374, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 693880, "time": 21884.657149791718, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 694112, "time": 21891.995189905167, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 694264, "time": 21896.409595251083, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 694288, "time": 21897.36134839058, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 694480, "time": 21903.24330019951, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 694632, "time": 21907.84462594986, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 694880, "time": 21915.686864614487, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 694984, "time": 21918.61659669876, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 695016, "time": 21919.609511613846, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 695088, "time": 21922.00604367256, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 695616, "time": 21938.12596678734, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 695624, "time": 21938.153285503387, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 695688, "time": 21940.111479759216, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 695968, "time": 21948.834564447403, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 696088, "time": 21952.25242471695, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 696112, "time": 21953.222569465637, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 696192, "time": 21955.633462190628, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 696360, "time": 21961.01547908783, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 696512, "time": 21965.8234937191, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 696872, "time": 21976.629128694534, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 696944, "time": 21979.055572271347, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 697040, "time": 21981.968620061874, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 697152, "time": 21985.39342856407, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 697160, "time": 21985.42205452919, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 697192, "time": 21986.40803384781, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 697640, "time": 22000.276492357254, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 697760, "time": 22004.168398857117, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 697864, "time": 22007.14524579048, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 697976, "time": 22010.679106235504, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 698000, "time": 22011.64257955551, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 698136, "time": 22015.628400564194, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 698192, "time": 22017.602286815643, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 698688, "time": 22033.09721970558, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 698768, "time": 22035.553678035736, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 698800, "time": 22036.531583309174, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 698872, "time": 22038.52709531784, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 699216, "time": 22049.287605285645, "episode/length": 196.0, "episode/score": 0.38749998807907104, "episode/reward_rate": 0.005076142131979695, "episode/intrinsic_return": 0.0}
{"step": 699472, "time": 22057.262400388718, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 699576, "time": 22060.266050577164, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 699840, "time": 22068.566735506058, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 700008, "time": 22073.482602357864, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 700024, "time": 22074.801367521286, "eval_episode/length": 38.0, "eval_episode/score": 0.8812500238418579, "eval_episode/reward_rate": 0.02564102564102564}
{"step": 700024, "time": 22075.264876127243, "eval_episode/length": 60.0, "eval_episode/score": 0.8125, "eval_episode/reward_rate": 0.01639344262295082}
{"step": 700024, "time": 22075.572127580643, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 700024, "time": 22075.959961652756, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 700024, "time": 22076.205102205276, "eval_episode/length": 104.0, "eval_episode/score": 0.675000011920929, "eval_episode/reward_rate": 0.009523809523809525}
{"step": 700024, "time": 22076.348385095596, "eval_episode/length": 111.0, "eval_episode/score": 0.653124988079071, "eval_episode/reward_rate": 0.008928571428571428}
{"step": 700024, "time": 22076.730674743652, "eval_episode/length": 130.0, "eval_episode/score": 0.59375, "eval_episode/reward_rate": 0.007633587786259542}
{"step": 700024, "time": 22076.950312376022, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 700192, "time": 22082.294563770294, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 700288, "time": 22085.237262248993, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 700312, "time": 22085.754385471344, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 700576, "time": 22094.170266866684, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 700680, "time": 22097.149570941925, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 700752, "time": 22099.59787774086, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 701112, "time": 22110.45566391945, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 701192, "time": 22112.915240764618, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 701528, "time": 22123.261474370956, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 701616, "time": 22126.167135477066, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 701696, "time": 22128.591499328613, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 701736, "time": 22129.61448955536, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 702120, "time": 22141.280395507812, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 702232, "time": 22144.673778295517, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 702304, "time": 22147.164979457855, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 702320, "time": 22147.654425144196, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 702600, "time": 22155.936346769333, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 702672, "time": 22158.348512887955, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 702680, "time": 22158.375826120377, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 703192, "time": 22173.8683218956, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 703408, "time": 22180.796633958817, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 703488, "time": 22183.257138729095, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 703568, "time": 22185.70808172226, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 703584, "time": 22186.20656299591, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 703728, "time": 22190.617247581482, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 703776, "time": 22192.088773727417, "episode/length": 259.0, "episode/score": 0.19062499701976776, "episode/reward_rate": 0.0038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 704336, "time": 22209.228600502014, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 704344, "time": 22209.258311271667, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 704432, "time": 22212.15401148796, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 704496, "time": 22214.09050679207, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 704952, "time": 22228.345324993134, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 705096, "time": 22232.73281764984, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 705312, "time": 22239.652435302734, "episode/length": 197.0, "episode/score": 0.3843750059604645, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.0}
{"step": 705392, "time": 22242.1146337986, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 705504, "time": 22245.524719953537, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 705720, "time": 22251.913313388824, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 705800, "time": 22254.354778051376, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 705952, "time": 22259.215096712112, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 706041, "time": 22262.662628650665, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.5459099764847637, "train/action_min": 0.0, "train/action_std": 1.7326399236176144, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.010141331327161681, "train/actor_opt_grad_steps": 43030.0, "train/actor_opt_loss": -15.943233448474562, "train/adv_mag": 1.0129326439615507, "train/adv_max": 0.45974250456587, "train/adv_mean": 0.0012745307444244976, "train/adv_min": -0.9516072006367925, "train/adv_std": 0.0288649088568726, "train/cont_avg": 0.9947965251865671, "train/cont_loss_mean": 0.01861917096611798, "train/cont_loss_std": 0.24394921587770851, "train/cont_neg_acc": 0.28970785190661746, "train/cont_neg_loss": 2.814515239712018, "train/cont_pos_acc": 0.999824136940401, "train/cont_pos_loss": 0.003863378876208592, "train/cont_pred": 0.9948280174933856, "train/cont_rate": 0.9947965251865671, "train/dyn_loss_mean": 1.0000019186171727, "train/dyn_loss_std": 6.040736809326567e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.1168052613902003, "train/extr_critic_critic_opt_grad_steps": 43030.0, "train/extr_critic_critic_opt_loss": 13241.381685323384, "train/extr_critic_mag": 1.4945441348042654, "train/extr_critic_max": 1.4945441348042654, "train/extr_critic_mean": 1.3942960696433908, "train/extr_critic_min": 0.858842107787061, "train/extr_critic_std": 0.02769038924456236, "train/extr_return_normed_mag": 1.058141828769475, "train/extr_return_normed_max": 0.29402332341493065, "train/extr_return_normed_mean": 0.05138852897642264, "train/extr_return_normed_min": -1.01140488172645, "train/extr_return_normed_std": 0.04025274177837135, "train/extr_return_rate": 0.999502204840456, "train/extr_return_raw_mag": 1.6382053111916157, "train/extr_return_raw_max": 1.6382053111916157, "train/extr_return_raw_mean": 1.3955705936868392, "train/extr_return_raw_min": 0.33277710605023514, "train/extr_return_raw_std": 0.040252742056378084, "train/extr_reward_mag": 0.2730867305205236, "train/extr_reward_max": 0.2730867305205236, "train/extr_reward_mean": 0.0019428888248946908, "train/extr_reward_min": 2.087645269745025e-07, "train/extr_reward_std": 0.00780820971197305, "train/image_loss_mean": 0.08488033513598774, "train/image_loss_std": 0.10027051009052429, "train/model_loss_mean": 0.7182456613773137, "train/model_loss_std": 0.4701189024753831, "train/model_opt_grad_norm": 20.88732564271386, "train/model_opt_grad_steps": 42992.05970149254, "train/model_opt_loss": 3644.2424486454447, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5074.626865671642, "train/policy_entropy_mag": 1.3576840031799393, "train/policy_entropy_max": 1.3576840031799393, "train/policy_entropy_mean": 0.10135816664096728, "train/policy_entropy_min": 0.06468649390176755, "train/policy_entropy_std": 0.13038110681137635, "train/policy_logprob_mag": 6.551080248249111, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.10160795161824915, "train/policy_logprob_min": -6.551080248249111, "train/policy_logprob_std": 0.6407635529242938, "train/policy_randomness_mag": 0.6977115999999924, "train/policy_randomness_max": 0.6977115999999924, "train/policy_randomness_mean": 0.05208779623111089, "train/policy_randomness_min": 0.03324228243448248, "train/policy_randomness_std": 0.06700263897058975, "train/post_ent_mag": 28.45552526065959, "train/post_ent_max": 28.45552526065959, "train/post_ent_mean": 27.96527836927727, "train/post_ent_min": 27.620775725711045, "train/post_ent_std": 0.1649664344627466, "train/prior_ent_mag": 28.42934790653969, "train/prior_ent_max": 28.42934790653969, "train/prior_ent_mean": 27.90420499014024, "train/prior_ent_min": 27.038838732894973, "train/prior_ent_std": 0.19977977946029968, "train/rep_loss_mean": 1.0000019186171727, "train/rep_loss_std": 6.040736809326567e-05, "train/reward_avg": 0.0019146364135320174, "train/reward_loss_mean": 0.014744982287862259, "train/reward_loss_std": 0.22690043401955373, "train/reward_max_data": 0.7574315931073469, "train/reward_max_pred": 0.2147914200872924, "train/reward_neg_acc": 0.9997174351369563, "train/reward_neg_loss": 0.0024802257365950232, "train/reward_pos_acc": 0.1653227801482702, "train/reward_pos_loss": 4.247880672056651, "train/reward_pred": 0.0014623440906349847, "train/reward_rate": 0.002847092661691542, "train_stats/mean_log_entropy": 0.08556734750668207, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.007518711034208536, "report/cont_loss_std": 0.1444302648305893, "report/cont_neg_acc": 0.5, "report/cont_neg_loss": 2.312168598175049, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.003008633153513074, "report/cont_pred": 0.9960549473762512, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.06922824680805206, "report/image_loss_std": 0.08008178323507309, "report/model_loss_mean": 0.6792231798171997, "report/model_loss_std": 0.16518089175224304, "report/post_ent_mag": 28.531421661376953, "report/post_ent_max": 28.531421661376953, "report/post_ent_mean": 27.998611450195312, "report/post_ent_min": 27.559350967407227, "report/post_ent_std": 0.1734209656715393, "report/prior_ent_mag": 28.328857421875, "report/prior_ent_max": 28.328857421875, "report/prior_ent_mean": 27.78407096862793, "report/prior_ent_min": 26.844472885131836, "report/prior_ent_std": 0.25344499945640564, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.0024761934764683247, "report/reward_loss_std": 0.008486228063702583, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.026794910430908203, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0024761934764683247, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0012445299653336406, "report/reward_rate": 0.0, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.018139047548174858, "eval/cont_loss_std": 0.43096840381622314, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 8.010321617126465, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0024987671058624983, "eval/cont_pred": 0.9975101351737976, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.16844789683818817, "eval/image_loss_std": 0.16432958841323853, "eval/model_loss_mean": 0.7917318344116211, "eval/model_loss_std": 0.49626654386520386, "eval/post_ent_mag": 28.520557403564453, "eval/post_ent_max": 28.520557403564453, "eval/post_ent_mean": 27.96871566772461, "eval/post_ent_min": 27.662233352661133, "eval/post_ent_std": 0.16175957024097443, "eval/prior_ent_mag": 28.342998504638672, "eval/prior_ent_max": 28.342998504638672, "eval/prior_ent_mean": 27.820701599121094, "eval/prior_ent_min": 26.837223052978516, "eval/prior_ent_std": 0.20905297994613647, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0006835937383584678, "eval/reward_loss_mean": 0.005144872236996889, "eval/reward_loss_std": 0.10998589545488358, "eval/reward_max_data": 0.699999988079071, "eval/reward_max_pred": 0.1699542999267578, "eval/reward_neg_acc": 0.9990224838256836, "eval/reward_neg_loss": 0.0017518470995128155, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 3.4762096405029297, "eval/reward_pred": 0.0008097172249108553, "eval/reward_rate": 0.0009765625, "replay/size": 705537.0, "replay/inserts": 32128.0, "replay/samples": 32128.0, "replay/insert_wait_avg": 1.3778824730223392e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.774879749077726e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4216.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1958818055646921e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.2069940567016602e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3127012252808, "timer/env.step_count": 4016.0, "timer/env.step_total": 39.93454933166504, "timer/env.step_frac": 0.039922065652819666, "timer/env.step_avg": 0.009943861885374761, "timer/env.step_min": 0.007887601852416992, "timer/env.step_max": 0.05220675468444824, "timer/replay._sample_count": 32128.0, "timer/replay._sample_total": 17.072394609451294, "timer/replay._sample_frac": 0.01706705771959044, "timer/replay._sample_avg": 0.0005313867844077221, "timer/replay._sample_min": 0.00042057037353515625, "timer/replay._sample_max": 0.025526762008666992, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4543.0, "timer/agent.policy_total": 49.434699296951294, "timer/agent.policy_frac": 0.04941924583822523, "timer/agent.policy_avg": 0.010881509860654039, "timer/agent.policy_min": 0.00911569595336914, "timer/agent.policy_max": 0.0768899917602539, "timer/dataset_train_count": 2008.0, "timer/dataset_train_total": 0.2304239273071289, "timer/dataset_train_frac": 0.00023035189598700803, "timer/dataset_train_avg": 0.00011475295184617973, "timer/dataset_train_min": 9.655952453613281e-05, "timer/dataset_train_max": 0.0010731220245361328, "timer/agent.train_count": 2008.0, "timer/agent.train_total": 899.1893255710602, "timer/agent.train_frac": 0.8989082358642905, "timer/agent.train_avg": 0.4478034489895718, "timer/agent.train_min": 0.4359285831451416, "timer/agent.train_max": 0.7009222507476807, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4733285903930664, "timer/agent.report_frac": 0.0004731806262314647, "timer/agent.report_avg": 0.2366642951965332, "timer/agent.report_min": 0.2275104522705078, "timer/agent.report_max": 0.2458181381225586, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.3855438232421875e-05, "timer/dataset_eval_frac": 3.3844854904823685e-08, "timer/dataset_eval_avg": 3.3855438232421875e-05, "timer/dataset_eval_min": 3.3855438232421875e-05, "timer/dataset_eval_max": 3.3855438232421875e-05, "fps": 32.11741355374292}
{"step": 706112, "time": 22264.817199230194, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 706304, "time": 22270.861083745956, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 706488, "time": 22276.302661895752, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 706568, "time": 22278.75938653946, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 706648, "time": 22281.192198991776, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 706712, "time": 22283.152658700943, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 706832, "time": 22287.044877767563, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 706936, "time": 22289.993267536163, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 707072, "time": 22294.36210513115, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 707104, "time": 22295.338258981705, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 707120, "time": 22295.828909635544, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 707264, "time": 22300.329700946808, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 707408, "time": 22304.711466550827, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 707496, "time": 22307.187031269073, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 707624, "time": 22311.064378499985, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 707880, "time": 22318.852061271667, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 707880, "time": 22318.871866941452, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 708064, "time": 22324.71025466919, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 708152, "time": 22327.310214281082, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 708328, "time": 22332.695489645004, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 708352, "time": 22333.659635782242, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 708456, "time": 22336.628796100616, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 708600, "time": 22341.035813331604, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 708648, "time": 22342.502321720123, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 708880, "time": 22349.82211279869, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 708928, "time": 22351.299331188202, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 708968, "time": 22352.300701379776, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 709024, "time": 22354.236615419388, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 709072, "time": 22355.736816883087, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 709096, "time": 22356.254451990128, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 709368, "time": 22364.715757846832, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 709504, "time": 22369.122312307358, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 709784, "time": 22377.594179868698, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 709968, "time": 22383.44637775421, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 710008, "time": 22386.164369106293, "eval_episode/length": 54.0, "eval_episode/score": 0.831250011920929, "eval_episode/reward_rate": 0.01818181818181818}
{"step": 710008, "time": 22386.752025842667, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 710008, "time": 22387.005763053894, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 710008, "time": 22387.611564159393, "eval_episode/length": 115.0, "eval_episode/score": 0.640625, "eval_episode/reward_rate": 0.008620689655172414}
{"step": 710008, "time": 22387.808680534363, "eval_episode/length": 124.0, "eval_episode/score": 0.612500011920929, "eval_episode/reward_rate": 0.008}
{"step": 710008, "time": 22388.039652109146, "eval_episode/length": 135.0, "eval_episode/score": 0.578125, "eval_episode/reward_rate": 0.007352941176470588}
{"step": 710008, "time": 22388.185727357864, "eval_episode/length": 142.0, "eval_episode/score": 0.5562499761581421, "eval_episode/reward_rate": 0.006993006993006993}
{"step": 710008, "time": 22388.792615890503, "eval_episode/length": 46.0, "eval_episode/score": 0.856249988079071, "eval_episode/reward_rate": 0.02127659574468085}
{"step": 710056, "time": 22390.280576467514, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 710120, "time": 22392.2225317955, "episode/length": 18.0, "episode/score": 0.9437500238418579, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.0}
{"step": 710232, "time": 22395.671801567078, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 710256, "time": 22396.640087127686, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 710640, "time": 22408.423961162567, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 710768, "time": 22412.319793462753, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 711088, "time": 22422.213116168976, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 711152, "time": 22424.18958091736, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 711240, "time": 22426.65591931343, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 711280, "time": 22428.10293149948, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 711616, "time": 22438.35707139969, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 711792, "time": 22443.731620550156, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 711848, "time": 22445.214857816696, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 712008, "time": 22450.250024795532, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 712096, "time": 22453.145344495773, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 712104, "time": 22453.173464775085, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 712136, "time": 22454.17562031746, "episode/length": 15.0, "episode/score": 0.953125, "episode/reward_rate": 0.0625, "episode/intrinsic_return": 0.0}
{"step": 712176, "time": 22455.625069856644, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 712408, "time": 22462.45796775818, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 712432, "time": 22463.43390226364, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 712512, "time": 22465.871994256973, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 712528, "time": 22466.36080598831, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 712648, "time": 22469.7891767025, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 712656, "time": 22470.256304979324, "episode/length": 15.0, "episode/score": 0.953125, "episode/reward_rate": 0.0625, "episode/intrinsic_return": 0.0}
{"step": 712696, "time": 22471.246862649918, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 712712, "time": 22471.935460329056, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 712992, "time": 22481.1539413929, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 713264, "time": 22489.476051807404, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 713400, "time": 22493.414886713028, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 713440, "time": 22494.86284828186, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 713648, "time": 22501.184010744095, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 713800, "time": 22505.617423534393, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 713936, "time": 22510.089707374573, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 714712, "time": 22533.58952188492, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 714720, "time": 22534.062016248703, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 714744, "time": 22534.57477068901, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 714944, "time": 22540.970103025436, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 715088, "time": 22545.37811422348, "episode/length": 210.0, "episode/score": 0.34375, "episode/reward_rate": 0.004739336492890996, "episode/intrinsic_return": 0.0}
{"step": 715176, "time": 22547.889711618423, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 715576, "time": 22560.15792965889, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 715752, "time": 22565.57805466652, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 715944, "time": 22571.521899461746, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 715960, "time": 22572.0351831913, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 715976, "time": 22572.527374267578, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 716112, "time": 22576.923117160797, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 716368, "time": 22584.706730365753, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 716464, "time": 22587.630434036255, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 716528, "time": 22589.585408210754, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 716752, "time": 22596.541064739227, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 717256, "time": 22611.73184990883, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 717384, "time": 22615.619887828827, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 717456, "time": 22618.038365364075, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 717528, "time": 22619.997312545776, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 717704, "time": 22625.41498565674, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 717736, "time": 22626.469566822052, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 718064, "time": 22636.734459877014, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 718272, "time": 22643.11510372162, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 718296, "time": 22643.62860941887, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 718520, "time": 22650.472095251083, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 718600, "time": 22652.90450310707, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 718680, "time": 22655.37460374832, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 718680, "time": 22655.38392186165, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 718768, "time": 22658.397450447083, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 719000, "time": 22665.24883747101, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 719000, "time": 22665.25817680359, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 719520, "time": 22681.3440117836, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 719528, "time": 22681.373681783676, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 719584, "time": 22683.29719519615, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 719784, "time": 22689.363815546036, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 719824, "time": 22690.828845739365, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 720096, "time": 22700.488129377365, "eval_episode/length": 58.0, "eval_episode/score": 0.8187500238418579, "eval_episode/reward_rate": 0.01694915254237288}
{"step": 720096, "time": 22700.860095739365, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 720096, "time": 22700.92707300186, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 720096, "time": 22701.03221321106, "eval_episode/length": 85.0, "eval_episode/score": 0.734375, "eval_episode/reward_rate": 0.011627906976744186}
{"step": 720096, "time": 22701.177524089813, "eval_episode/length": 33.0, "eval_episode/score": 0.8968750238418579, "eval_episode/reward_rate": 0.029411764705882353}
{"step": 720096, "time": 22701.22702050209, "eval_episode/length": 94.0, "eval_episode/score": 0.706250011920929, "eval_episode/reward_rate": 0.010526315789473684}
{"step": 720096, "time": 22701.440900802612, "eval_episode/length": 104.0, "eval_episode/score": 0.675000011920929, "eval_episode/reward_rate": 0.009523809523809525}
{"step": 720096, "time": 22702.069381713867, "eval_episode/length": 135.0, "eval_episode/score": 0.578125, "eval_episode/reward_rate": 0.007352941176470588}
{"step": 720224, "time": 22705.99924969673, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 720376, "time": 22710.452713489532, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 720504, "time": 22714.393702983856, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 720608, "time": 22717.94423890114, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 720664, "time": 22719.44075036049, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 720672, "time": 22719.915993452072, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 720752, "time": 22722.38634800911, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 721144, "time": 22734.708463907242, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 721312, "time": 22740.07623744011, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 721464, "time": 22744.4748108387, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 721648, "time": 22750.462453126907, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0}
{"step": 721784, "time": 22754.405494451523, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 721792, "time": 22754.877445459366, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 721800, "time": 22754.906463861465, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 721840, "time": 22756.34744811058, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 721864, "time": 22756.854904413223, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 722144, "time": 22765.653696775436, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 722416, "time": 22773.948094844818, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 722624, "time": 22780.425766468048, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 722640, "time": 22780.926940202713, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 722696, "time": 22782.45066523552, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 722720, "time": 22783.41947364807, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 723056, "time": 22793.633793592453, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 723064, "time": 22793.6623980999, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 723208, "time": 22798.03857111931, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 723328, "time": 22801.92231631279, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 723336, "time": 22801.950042963028, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 723400, "time": 22803.89926147461, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 723456, "time": 22805.841348171234, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 723472, "time": 22806.381670236588, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 723728, "time": 22814.27561235428, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 723824, "time": 22817.225383758545, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 724072, "time": 22824.59252357483, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 724176, "time": 22828.012198209763, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 724216, "time": 22829.01801276207, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 724240, "time": 22829.973620653152, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 724272, "time": 22830.97097182274, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 724360, "time": 22833.42153596878, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 724568, "time": 22839.9429666996, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 724640, "time": 22842.3772046566, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 724840, "time": 22848.262803077698, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 724952, "time": 22851.683490991592, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 725008, "time": 22853.596415281296, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 725128, "time": 22857.049896240234, "episode/length": 21.0, "episode/score": 0.934374988079071, "episode/reward_rate": 0.045454545454545456, "episode/intrinsic_return": 0.0}
{"step": 725240, "time": 22860.485055446625, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 725312, "time": 22862.884742736816, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 725504, "time": 22868.822913646698, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 725976, "time": 22883.054525375366, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 726056, "time": 22885.521638154984, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 726256, "time": 22891.858358621597, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 726264, "time": 22891.887797117233, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 726488, "time": 22898.830695152283, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 726584, "time": 22901.770611286163, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 726888, "time": 22911.077271938324, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 727112, "time": 22917.851372241974, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 727152, "time": 22919.31435608864, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 727656, "time": 22934.662158727646, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 727680, "time": 22935.639590978622, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 727744, "time": 22937.605221509933, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 727816, "time": 22939.59186077118, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 727832, "time": 22940.086356401443, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 727896, "time": 22942.04094004631, "episode/length": 9.0, "episode/score": 0.971875011920929, "episode/reward_rate": 0.1, "episode/intrinsic_return": 0.0}
{"step": 728376, "time": 22956.821682929993, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 728440, "time": 22958.784288167953, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 728568, "time": 22962.670367002487, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 728576, "time": 22963.141495466232, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 728624, "time": 22964.616812229156, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 728800, "time": 22969.995695352554, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 728832, "time": 22970.968781232834, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 728880, "time": 22972.434641599655, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 729280, "time": 22985.212964057922, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 729352, "time": 22987.308423757553, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 729608, "time": 22995.11037826538, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 729656, "time": 22996.580993652344, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 729864, "time": 23002.944144964218, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 730056, "time": 23008.847045898438, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 730080, "time": 23009.81015896797, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 730080, "time": 23011.223539829254, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 730080, "time": 23011.313449382782, "eval_episode/length": 72.0, "eval_episode/score": 0.7749999761581421, "eval_episode/reward_rate": 0.0136986301369863}
{"step": 730080, "time": 23011.606703281403, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 730080, "time": 23012.279586553574, "eval_episode/length": 119.0, "eval_episode/score": 0.628125011920929, "eval_episode/reward_rate": 0.008333333333333333}
{"step": 730080, "time": 23012.73606610298, "eval_episode/length": 142.0, "eval_episode/score": 0.5562499761581421, "eval_episode/reward_rate": 0.006993006993006993}
{"step": 730080, "time": 23012.80193400383, "eval_episode/length": 145.0, "eval_episode/score": 0.546875, "eval_episode/reward_rate": 0.00684931506849315}
{"step": 730080, "time": 23013.104392051697, "eval_episode/length": 160.0, "eval_episode/score": 0.5, "eval_episode/reward_rate": 0.006211180124223602}
{"step": 730080, "time": 23013.97336101532, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 730464, "time": 23025.804613113403, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 730736, "time": 23034.198730945587, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 730752, "time": 23034.697185993195, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 730824, "time": 23036.655984401703, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 730888, "time": 23038.627635002136, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 731112, "time": 23045.463889837265, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 731344, "time": 23052.866334676743, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 731512, "time": 23057.7710044384, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 731584, "time": 23060.206116437912, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 731648, "time": 23062.184922218323, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 731656, "time": 23062.213527679443, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 731968, "time": 23072.018617153168, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 732024, "time": 23073.508052110672, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 732368, "time": 23084.351534843445, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 732376, "time": 23084.37851691246, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 732696, "time": 23094.146026849747, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 732872, "time": 23099.555601596832, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 732944, "time": 23101.99247598648, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 733064, "time": 23105.40168595314, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 733200, "time": 23109.86115884781, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 733200, "time": 23109.87000155449, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 733488, "time": 23118.650898456573, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 733600, "time": 23122.065957069397, "episode/length": 243.0, "episode/score": 0.24062499403953552, "episode/reward_rate": 0.004098360655737705, "episode/intrinsic_return": 0.0}
{"step": 733872, "time": 23130.34050965309, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 733896, "time": 23130.8554418087, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 734296, "time": 23143.155650377274, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 734440, "time": 23147.541273593903, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 734512, "time": 23149.982620239258, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 735000, "time": 23164.65181541443, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 735008, "time": 23165.121089458466, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 735024, "time": 23165.611789226532, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 735176, "time": 23170.119562864304, "episode/length": 20.0, "episode/score": 0.9375, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.0}
{"step": 735256, "time": 23172.55841231346, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 735512, "time": 23180.356727838516, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 735744, "time": 23187.642288208008, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 735848, "time": 23190.588459968567, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 735920, "time": 23192.98611807823, "episode/length": 202.0, "episode/score": 0.3687500059604645, "episode/reward_rate": 0.0049261083743842365, "episode/intrinsic_return": 0.0}
{"step": 736160, "time": 23200.402866601944, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 736304, "time": 23204.797182559967, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 736400, "time": 23207.734569311142, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 736552, "time": 23212.154119491577, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 736752, "time": 23218.49039030075, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 736824, "time": 23220.467881202698, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 737016, "time": 23226.335626363754, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 737032, "time": 23226.936525583267, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 737040, "time": 23227.411819458008, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 737048, "time": 23227.44124174118, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 737192, "time": 23231.849586248398, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 737336, "time": 23236.750287532806, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 737648, "time": 23246.485583782196, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 737744, "time": 23249.434332370758, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 737744, "time": 23249.44389438629, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 738153, "time": 23262.811393499374, "train_stats/mean_log_entropy": 0.08347890270242364, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.54387939453125, "train/action_min": 0.0, "train/action_std": 1.7557993590831757, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.01023976954864338, "train/actor_opt_grad_steps": 45035.0, "train/actor_opt_loss": -16.945531958341597, "train/adv_mag": 0.9732367458939553, "train/adv_max": 0.4616239756345749, "train/adv_mean": -0.0008109730486830813, "train/adv_min": -0.9045445373654366, "train/adv_std": 0.027152288244105875, "train/cont_avg": 0.9946533203125, "train/cont_loss_mean": 0.019601953935343773, "train/cont_loss_std": 0.25603431419469413, "train/cont_neg_acc": 0.287049969881773, "train/cont_neg_loss": 2.945352498665452, "train/cont_pos_acc": 0.9998526629805565, "train/cont_pos_loss": 0.003947440962074325, "train/cont_pred": 0.9947162336111068, "train/cont_rate": 0.9946533203125, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.11396609421353787, "train/extr_critic_critic_opt_grad_steps": 45035.0, "train/extr_critic_critic_opt_loss": 13344.804521484375, "train/extr_critic_mag": 1.4863832986354828, "train/extr_critic_max": 1.4863832986354828, "train/extr_critic_mean": 1.378680334687233, "train/extr_critic_min": 0.8379545497894287, "train/extr_critic_std": 0.025217437837272882, "train/extr_return_normed_mag": 1.0224180233478546, "train/extr_return_normed_max": 0.2869883763790131, "train/extr_return_normed_mean": 0.04417865448631346, "train/extr_return_normed_min": -0.9721210390329361, "train/extr_return_normed_std": 0.037393228765577075, "train/extr_return_rate": 0.9996390372514725, "train/extr_return_raw_mag": 1.6206790739297867, "train/extr_return_raw_max": 1.6206790739297867, "train/extr_return_raw_mean": 1.3778694242238998, "train/extr_return_raw_min": 0.3615696585178375, "train/extr_return_raw_std": 0.03739322885870933, "train/extr_reward_mag": 0.2739599019289017, "train/extr_reward_max": 0.2739599019289017, "train/extr_reward_mean": 0.0018754226312739774, "train/extr_reward_min": 1.9788742065429687e-07, "train/extr_reward_std": 0.007948344089090825, "train/image_loss_mean": 0.0835435325652361, "train/image_loss_std": 0.0992581457644701, "train/model_loss_mean": 0.7177553728222847, "train/model_loss_std": 0.4723805521056056, "train/model_opt_grad_norm": 20.231083333192757, "train/model_opt_grad_steps": 44995.12, "train/model_opt_loss": 3731.6046850585935, "train/model_opt_model_opt_grad_overflow": 0.005, "train/model_opt_model_opt_grad_scale": 5175.0, "train/policy_entropy_mag": 1.3662502962350844, "train/policy_entropy_max": 1.3662502962350844, "train/policy_entropy_mean": 0.101818574257195, "train/policy_entropy_min": 0.06468649879097939, "train/policy_entropy_std": 0.13112457565963268, "train/policy_logprob_mag": 6.551080253124237, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.10231080017983914, "train/policy_logprob_min": -6.551080253124237, "train/policy_logprob_std": 0.6414608779549599, "train/policy_randomness_mag": 0.7021138048171998, "train/policy_randomness_max": 0.7021138048171998, "train/policy_randomness_mean": 0.052324399054050445, "train/policy_randomness_min": 0.033242285270243886, "train/policy_randomness_std": 0.06738470621407032, "train/post_ent_mag": 28.319305629730223, "train/post_ent_max": 28.319305629730223, "train/post_ent_mean": 27.839495782852172, "train/post_ent_min": 27.49335862159729, "train/post_ent_std": 0.16531813234090806, "train/prior_ent_mag": 28.382103443145752, "train/prior_ent_max": 28.382103443145752, "train/prior_ent_mean": 27.853894510269164, "train/prior_ent_min": 26.970672760009766, "train/prior_ent_std": 0.2100435322523117, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0020038909901631996, "train/reward_loss_mean": 0.014609861387871206, "train/reward_loss_std": 0.22288403050275518, "train/reward_max_data": 0.7612187498807907, "train/reward_max_pred": 0.2565822899341583, "train/reward_neg_acc": 0.9996327495574951, "train/reward_neg_loss": 0.002615254544070922, "train/reward_pos_acc": 0.16672484143710262, "train/reward_pos_loss": 4.088669504794775, "train/reward_pred": 0.0015851823461707681, "train/reward_rate": 0.002919921875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.024863146245479584, "report/cont_loss_std": 0.31930607557296753, "report/cont_neg_acc": 0.1666666716337204, "report/cont_neg_loss": 3.6879801750183105, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.003273066133260727, "report/cont_pred": 0.9957413673400879, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.08581849187612534, "report/image_loss_std": 0.10377057641744614, "report/model_loss_mean": 0.7285630106925964, "report/model_loss_std": 0.5788813829421997, "report/post_ent_mag": 28.490346908569336, "report/post_ent_max": 28.490346908569336, "report/post_ent_mean": 27.996137619018555, "report/post_ent_min": 27.693187713623047, "report/post_ent_std": 0.1673537790775299, "report/prior_ent_mag": 28.409643173217773, "report/prior_ent_max": 28.409643173217773, "report/prior_ent_mean": 27.810606002807617, "report/prior_ent_min": 26.71337127685547, "report/prior_ent_std": 0.20963922142982483, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0021697997581213713, "report/reward_loss_mean": 0.017881343141198158, "report/reward_loss_std": 0.28054752945899963, "report/reward_max_data": 0.846875011920929, "report/reward_max_pred": 0.05603528022766113, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0029336605221033096, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 5.105075836181641, "report/reward_pred": 0.0014839271316304803, "report/reward_rate": 0.0029296875, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.0259507168084383, "eval/cont_loss_std": 0.3772956430912018, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 4.767951488494873, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0026828062254935503, "eval/cont_pred": 0.9972119331359863, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.16582630574703217, "eval/image_loss_std": 0.1600550413131714, "eval/model_loss_mean": 0.8207335472106934, "eval/model_loss_std": 0.8037243485450745, "eval/post_ent_mag": 28.488719940185547, "eval/post_ent_max": 28.488719940185547, "eval/post_ent_mean": 27.972206115722656, "eval/post_ent_min": 27.629379272460938, "eval/post_ent_std": 0.16178205609321594, "eval/prior_ent_mag": 28.422677993774414, "eval/prior_ent_max": 28.422677993774414, "eval/prior_ent_mean": 27.8165283203125, "eval/prior_ent_min": 26.93206024169922, "eval/prior_ent_std": 0.21058908104896545, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0026092529296875, "eval/reward_loss_mean": 0.02895648218691349, "eval/reward_loss_std": 0.40168359875679016, "eval/reward_max_data": 0.753125011920929, "eval/reward_max_pred": 0.04705500602722168, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0017123935976997018, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.581301689147949, "eval/reward_pred": 0.0008896198123693466, "eval/reward_rate": 0.0048828125, "replay/size": 737649.0, "replay/inserts": 32112.0, "replay/samples": 32112.0, "replay/insert_wait_avg": 1.3828455778159013e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.905801122082842e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4104.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2276465432685718e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.043081283569336e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1318144798279, "timer/env.step_count": 4014.0, "timer/env.step_total": 39.80708575248718, "timer/env.step_frac": 0.039801839293744486, "timer/env.step_avg": 0.009917061722094465, "timer/env.step_min": 0.007828950881958008, "timer/env.step_max": 0.05454850196838379, "timer/replay._sample_count": 32112.0, "timer/replay._sample_total": 17.136483192443848, "timer/replay._sample_frac": 0.017134224653533887, "timer/replay._sample_avg": 0.0005336473340945393, "timer/replay._sample_min": 0.0004241466522216797, "timer/replay._sample_max": 0.03022289276123047, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4527.0, "timer/agent.policy_total": 49.631587743759155, "timer/agent.policy_frac": 0.04962504644407569, "timer/agent.policy_avg": 0.01096346095510474, "timer/agent.policy_min": 0.009047508239746094, "timer/agent.policy_max": 0.09427452087402344, "timer/dataset_train_count": 2007.0, "timer/dataset_train_total": 0.23021554946899414, "timer/dataset_train_frac": 0.00023018520772557371, "timer/dataset_train_avg": 0.0001147063026751341, "timer/dataset_train_min": 9.775161743164062e-05, "timer/dataset_train_max": 0.0005786418914794922, "timer/agent.train_count": 2007.0, "timer/agent.train_total": 898.939395904541, "timer/agent.train_frac": 0.8988209182927378, "timer/agent.train_avg": 0.44790204080943746, "timer/agent.train_min": 0.4370608329772949, "timer/agent.train_max": 0.708228588104248, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47885894775390625, "timer/agent.report_frac": 0.0004787958355299021, "timer/agent.report_avg": 0.23942947387695312, "timer/agent.report_min": 0.23234081268310547, "timer/agent.report_max": 0.24651813507080078, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 8.821487426757812e-05, "timer/dataset_eval_frac": 8.820324780234993e-08, "timer/dataset_eval_avg": 8.821487426757812e-05, "timer/dataset_eval_min": 8.821487426757812e-05, "timer/dataset_eval_max": 8.821487426757812e-05, "fps": 32.10723976923388}
{"step": 738240, "time": 23265.458616018295, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 738280, "time": 23266.4682700634, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 738384, "time": 23269.867005825043, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 738528, "time": 23274.262121915817, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 738624, "time": 23277.169553518295, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 739000, "time": 23288.572491407394, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 739016, "time": 23289.06865620613, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 739048, "time": 23290.05026602745, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 739064, "time": 23290.54283094406, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 739080, "time": 23291.03256726265, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 739360, "time": 23299.85550880432, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 739480, "time": 23303.311907052994, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 739576, "time": 23306.258016824722, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 739672, "time": 23309.187612771988, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 739840, "time": 23314.54948234558, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 739848, "time": 23314.580950021744, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 739984, "time": 23319.046355724335, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 740064, "time": 23322.830409765244, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 740064, "time": 23323.06442642212, "eval_episode/length": 72.0, "eval_episode/score": 0.7749999761581421, "eval_episode/reward_rate": 0.0136986301369863}
{"step": 740064, "time": 23323.34489274025, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 740064, "time": 23323.55602002144, "eval_episode/length": 96.0, "eval_episode/score": 0.699999988079071, "eval_episode/reward_rate": 0.010309278350515464}
{"step": 740064, "time": 23323.639095544815, "eval_episode/length": 100.0, "eval_episode/score": 0.6875, "eval_episode/reward_rate": 0.009900990099009901}
{"step": 740064, "time": 23323.64627456665, "eval_episode/length": 38.0, "eval_episode/score": 0.8812500238418579, "eval_episode/reward_rate": 0.02564102564102564}
{"step": 740064, "time": 23323.870570898056, "eval_episode/length": 111.0, "eval_episode/score": 0.653124988079071, "eval_episode/reward_rate": 0.008928571428571428}
{"step": 740064, "time": 23324.094369649887, "eval_episode/length": 49.0, "eval_episode/score": 0.846875011920929, "eval_episode/reward_rate": 0.02}
{"step": 740088, "time": 23324.60975766182, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 740160, "time": 23327.04198074341, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 740432, "time": 23335.353116750717, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 740592, "time": 23340.2421336174, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 740688, "time": 23343.19669508934, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 740704, "time": 23343.69513106346, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 740760, "time": 23345.21621966362, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 740872, "time": 23348.758870601654, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 741112, "time": 23356.455950975418, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 741176, "time": 23358.39611697197, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 741392, "time": 23365.216018676758, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 741576, "time": 23370.59238243103, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 741688, "time": 23373.977048158646, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 741792, "time": 23377.468732118607, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 742320, "time": 23393.522787332535, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 742680, "time": 23404.22318840027, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 742824, "time": 23408.72911310196, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 742904, "time": 23411.16832613945, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 743016, "time": 23414.588896512985, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 743072, "time": 23416.508669376373, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 743120, "time": 23417.967896938324, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 743424, "time": 23427.200760364532, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 743560, "time": 23431.1543905735, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 743640, "time": 23433.643062353134, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 743704, "time": 23435.621408224106, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 743736, "time": 23436.725148439407, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 743896, "time": 23441.580406665802, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 743904, "time": 23442.04977941513, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 744104, "time": 23447.983595132828, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 744296, "time": 23453.869122743607, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 744824, "time": 23470.06474328041, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 745136, "time": 23479.774057388306, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 745200, "time": 23481.72354388237, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 745736, "time": 23498.47205066681, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 745840, "time": 23501.843666553497, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 745872, "time": 23502.839589595795, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 746128, "time": 23510.58810377121, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 746208, "time": 23513.01820206642, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 746216, "time": 23513.046790599823, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 746608, "time": 23525.178317070007, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 746960, "time": 23536.075595378876, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 747008, "time": 23537.543364048004, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 747136, "time": 23541.422611236572, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 747448, "time": 23550.678598165512, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 747640, "time": 23556.577689409256, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 747736, "time": 23559.524327754974, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 747808, "time": 23561.94947361946, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 748032, "time": 23568.75065255165, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 748152, "time": 23572.229897499084, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 748408, "time": 23580.019444704056, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 748440, "time": 23581.018837690353, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 748520, "time": 23583.43526983261, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 748528, "time": 23583.909281492233, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 748680, "time": 23588.436920166016, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 748920, "time": 23595.854287147522, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 749064, "time": 23600.257381677628, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 749120, "time": 23602.193027973175, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 749160, "time": 23603.184467315674, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 749456, "time": 23612.413640499115, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 749712, "time": 23620.298393011093, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 749792, "time": 23622.718732833862, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 749848, "time": 23624.194937705994, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 749864, "time": 23624.68552494049, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 749912, "time": 23626.16516518593, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 750048, "time": 23631.642109394073, "eval_episode/length": 55.0, "eval_episode/score": 0.828125, "eval_episode/reward_rate": 0.017857142857142856}
{"step": 750048, "time": 23631.783700227737, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 750048, "time": 23632.063837766647, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 750048, "time": 23633.04402279854, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 750048, "time": 23633.32478618622, "eval_episode/length": 137.0, "eval_episode/score": 0.5718749761581421, "eval_episode/reward_rate": 0.007246376811594203}
{"step": 750048, "time": 23633.350801467896, "eval_episode/length": 138.0, "eval_episode/score": 0.5687500238418579, "eval_episode/reward_rate": 0.007194244604316547}
{"step": 750048, "time": 23634.894546747208, "eval_episode/length": 162.0, "eval_episode/score": 0.4937500059604645, "eval_episode/reward_rate": 0.006134969325153374}
{"step": 750048, "time": 23634.9604074955, "eval_episode/length": 97.0, "eval_episode/score": 0.6968749761581421, "eval_episode/reward_rate": 0.01020408163265306}
{"step": 750056, "time": 23634.987266778946, "episode/length": 205.0, "episode/score": 0.359375, "episode/reward_rate": 0.0048543689320388345, "episode/intrinsic_return": 0.0}
{"step": 750256, "time": 23641.29043531418, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 750344, "time": 23643.756731510162, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 750424, "time": 23646.217524051666, "episode/length": 20.0, "episode/score": 0.9375, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.0}
{"step": 750464, "time": 23647.786041259766, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 750648, "time": 23653.1462597847, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 750856, "time": 23659.519570350647, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 750936, "time": 23661.953425884247, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 750944, "time": 23662.42844438553, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 751232, "time": 23671.230618953705, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 751552, "time": 23681.212451934814, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 751744, "time": 23687.051882982254, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 751896, "time": 23691.468154668808, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 752160, "time": 23699.74525809288, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 752224, "time": 23701.69255399704, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 752240, "time": 23702.186623573303, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 752288, "time": 23703.667004346848, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 752776, "time": 23718.371317386627, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 752792, "time": 23718.86293721199, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 752880, "time": 23721.76236796379, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 752912, "time": 23722.75158905983, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 753008, "time": 23725.67908024788, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 753168, "time": 23730.54013466835, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 753176, "time": 23730.56839108467, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 753440, "time": 23739.007140159607, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 753616, "time": 23744.363497257233, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 753616, "time": 23744.37175297737, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 753632, "time": 23744.867354393005, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 753728, "time": 23748.285750865936, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 754160, "time": 23761.433890342712, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 754648, "time": 23776.189702749252, "episode/length": 216.0, "episode/score": 0.32499998807907104, "episode/reward_rate": 0.004608294930875576, "episode/intrinsic_return": 0.0}
{"step": 754800, "time": 23781.04296517372, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 754872, "time": 23783.042405605316, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 754920, "time": 23784.521673202515, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 755112, "time": 23790.364188432693, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 755320, "time": 23796.86833381653, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 755416, "time": 23799.804565906525, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 755488, "time": 23802.260026931763, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 755504, "time": 23802.751416683197, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 755776, "time": 23811.07295036316, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 755800, "time": 23811.604558467865, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 755912, "time": 23814.99866247177, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 755928, "time": 23815.491384744644, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 755944, "time": 23815.989567279816, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 755960, "time": 23816.499148130417, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 756096, "time": 23820.87112545967, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 756368, "time": 23829.297429800034, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 756440, "time": 23831.28840970993, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 756616, "time": 23836.678844213486, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 756880, "time": 23844.93869495392, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 756896, "time": 23845.4386074543, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 756904, "time": 23845.46753668785, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 757120, "time": 23852.304533481598, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 757592, "time": 23866.640419244766, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 757848, "time": 23874.4033639431, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 757912, "time": 23876.36674928665, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 758112, "time": 23882.708565473557, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 758192, "time": 23885.49516415596, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 758200, "time": 23885.522710323334, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 758216, "time": 23886.013340234756, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 758240, "time": 23887.678120851517, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 758344, "time": 23890.594668149948, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 758408, "time": 23892.54125547409, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 758848, "time": 23906.17441511154, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 758864, "time": 23906.665398597717, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 759040, "time": 23912.065970897675, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 759128, "time": 23914.531359910965, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 759168, "time": 23915.98927116394, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 759392, "time": 23922.869840860367, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 759536, "time": 23927.24956679344, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 759616, "time": 23929.68193912506, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 759640, "time": 23930.21014523506, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 759680, "time": 23931.642274856567, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 759832, "time": 23936.057136058807, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 759952, "time": 23939.920755147934, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 760032, "time": 23943.24485349655, "eval_episode/length": 45.0, "eval_episode/score": 0.859375, "eval_episode/reward_rate": 0.021739130434782608}
{"step": 760032, "time": 23943.75669813156, "eval_episode/length": 71.0, "eval_episode/score": 0.778124988079071, "eval_episode/reward_rate": 0.013888888888888888}
{"step": 760032, "time": 23944.130168437958, "eval_episode/length": 91.0, "eval_episode/score": 0.715624988079071, "eval_episode/reward_rate": 0.010869565217391304}
{"step": 760032, "time": 23944.31322836876, "eval_episode/length": 100.0, "eval_episode/score": 0.6875, "eval_episode/reward_rate": 0.009900990099009901}
{"step": 760032, "time": 23944.487221717834, "eval_episode/length": 109.0, "eval_episode/score": 0.659375011920929, "eval_episode/reward_rate": 0.00909090909090909}
{"step": 760032, "time": 23944.53154683113, "eval_episode/length": 111.0, "eval_episode/score": 0.653124988079071, "eval_episode/reward_rate": 0.008928571428571428}
{"step": 760032, "time": 23944.928064346313, "eval_episode/length": 131.0, "eval_episode/score": 0.590624988079071, "eval_episode/reward_rate": 0.007575757575757576}
{"step": 760032, "time": 23945.057315826416, "eval_episode/length": 65.0, "eval_episode/score": 0.796875, "eval_episode/reward_rate": 0.015151515151515152}
{"step": 760096, "time": 23947.072483301163, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 760176, "time": 23949.52597784996, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 760512, "time": 23959.719747066498, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 760648, "time": 23963.632271528244, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 760832, "time": 23969.45780801773, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 760872, "time": 23970.447465896606, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 760944, "time": 23972.879351854324, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 760944, "time": 23972.887760162354, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 761304, "time": 23983.75340461731, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 761320, "time": 23984.247000455856, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 761384, "time": 23986.19417309761, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 761528, "time": 23990.599929332733, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 761704, "time": 23996.001960277557, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 761752, "time": 23997.487238645554, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 761760, "time": 23997.95738887787, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 761992, "time": 24005.307147979736, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 762048, "time": 24007.356462478638, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 762320, "time": 24015.6716196537, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 762496, "time": 24021.049075841904, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 762752, "time": 24028.861487150192, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 762896, "time": 24033.29726791382, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 762968, "time": 24035.267043828964, "episode/length": 8.0, "episode/score": 0.9750000238418579, "episode/reward_rate": 0.1111111111111111, "episode/intrinsic_return": 0.0}
{"step": 763000, "time": 24036.268674373627, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 763280, "time": 24045.113052129745, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 763312, "time": 24046.113315582275, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 763424, "time": 24049.531227588654, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 763632, "time": 24055.86538362503, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 763840, "time": 24062.184322357178, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 763952, "time": 24065.578624010086, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 764016, "time": 24067.60575556755, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 764064, "time": 24069.066453933716, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 764144, "time": 24071.508538484573, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 764408, "time": 24079.313371658325, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 764600, "time": 24085.19261622429, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 764768, "time": 24090.558911323547, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 764848, "time": 24092.995540857315, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 764872, "time": 24093.503875494003, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 764944, "time": 24095.94580721855, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 765168, "time": 24102.85688471794, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 765296, "time": 24106.75566458702, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 765304, "time": 24106.785031080246, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 765544, "time": 24114.087745428085, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 765656, "time": 24117.53476500511, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 765736, "time": 24119.998995542526, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 766112, "time": 24131.77409505844, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 766192, "time": 24134.221208810806, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 766336, "time": 24138.59767127037, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 766352, "time": 24139.113080263138, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 766536, "time": 24144.5054063797, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 766560, "time": 24145.46065545082, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 766856, "time": 24154.21510577202, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 766968, "time": 24157.791172027588, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 766984, "time": 24158.282739639282, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 767256, "time": 24166.614525794983, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 767256, "time": 24166.62369775772, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 767480, "time": 24173.4574341774, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 767552, "time": 24175.860095500946, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 767608, "time": 24177.346952438354, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 767752, "time": 24181.767074108124, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 767784, "time": 24182.73953151703, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 768072, "time": 24191.622522115707, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 768128, "time": 24193.560546398163, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 768272, "time": 24197.954242944717, "episode/length": 259.0, "episode/score": 0.19062499701976776, "episode/reward_rate": 0.0038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 768416, "time": 24202.331205129623, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 768464, "time": 24203.814489603043, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 768688, "time": 24210.64661002159, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 768696, "time": 24210.674767017365, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 768920, "time": 24217.56166410446, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 768952, "time": 24218.532313108444, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 768976, "time": 24219.476432323456, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 769416, "time": 24232.670253753662, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 769456, "time": 24234.118661165237, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 769672, "time": 24240.457989692688, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 769752, "time": 24242.920340776443, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 769816, "time": 24244.87551689148, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 769920, "time": 24248.39057779312, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 770016, "time": 24252.268770217896, "eval_episode/length": 47.0, "eval_episode/score": 0.8531249761581421, "eval_episode/reward_rate": 0.020833333333333332}
{"step": 770016, "time": 24253.22152018547, "eval_episode/length": 63.0, "eval_episode/score": 0.8031250238418579, "eval_episode/reward_rate": 0.015625}
{"step": 770016, "time": 24253.78422641754, "eval_episode/length": 91.0, "eval_episode/score": 0.715624988079071, "eval_episode/reward_rate": 0.010869565217391304}
{"step": 770016, "time": 24253.99177145958, "eval_episode/length": 101.0, "eval_episode/score": 0.684374988079071, "eval_episode/reward_rate": 0.00980392156862745}
{"step": 770016, "time": 24254.206017255783, "eval_episode/length": 111.0, "eval_episode/score": 0.653124988079071, "eval_episode/reward_rate": 0.008928571428571428}
{"step": 770016, "time": 24254.25260400772, "eval_episode/length": 113.0, "eval_episode/score": 0.6468750238418579, "eval_episode/reward_rate": 0.008771929824561403}
{"step": 770016, "time": 24254.743044614792, "eval_episode/length": 137.0, "eval_episode/score": 0.5718749761581421, "eval_episode/reward_rate": 0.007246376811594203}
{"step": 770016, "time": 24254.983142375946, "eval_episode/length": 100.0, "eval_episode/score": 0.6875, "eval_episode/reward_rate": 0.009900990099009901}
{"step": 770024, "time": 24255.010139226913, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 770064, "time": 24256.945305109024, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 770208, "time": 24261.347131490707, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 770233, "time": 24262.855177640915, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.552851890450093, "train/action_min": 0.0, "train/action_std": 1.7514189552904955, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.010541661711993501, "train/actor_opt_grad_steps": 47040.0, "train/actor_opt_loss": -16.011521984688677, "train/adv_mag": 0.9201134336528494, "train/adv_max": 0.44255843209983103, "train/adv_mean": 0.0007473511149559027, "train/adv_min": -0.8534040575596824, "train/adv_std": 0.027159480354864502, "train/cont_avg": 0.9946313355099502, "train/cont_loss_mean": 0.019115286361453914, "train/cont_loss_std": 0.2448338470908243, "train/cont_neg_acc": 0.279862334812755, "train/cont_neg_loss": 2.8394581619372117, "train/cont_pos_acc": 0.9998925770100077, "train/cont_pos_loss": 0.004055353419609664, "train/cont_pred": 0.9945154009173759, "train/cont_rate": 0.9946313355099502, "train/dyn_loss_mean": 1.0000003896542449, "train/dyn_loss_std": 1.2451285937599304e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.10196295850423735, "train/extr_critic_critic_opt_grad_steps": 47040.0, "train/extr_critic_critic_opt_loss": 13285.907148826182, "train/extr_critic_mag": 1.4683639433846545, "train/extr_critic_max": 1.4683639433846545, "train/extr_critic_mean": 1.3623121947198364, "train/extr_critic_min": 0.8477960854620483, "train/extr_critic_std": 0.02590993245998722, "train/extr_return_normed_mag": 0.9870980260384024, "train/extr_return_normed_max": 0.30490077846678926, "train/extr_return_normed_mean": 0.04870296635697434, "train/extr_return_normed_min": -0.9226886716055039, "train/extr_return_normed_std": 0.037791966650616474, "train/extr_return_rate": 0.9995041474774109, "train/extr_return_raw_mag": 1.6192573807132777, "train/extr_return_raw_max": 1.6192573807132777, "train/extr_return_raw_mean": 1.3630596428961304, "train/extr_return_raw_min": 0.39166793064098454, "train/extr_return_raw_std": 0.03779196676181917, "train/extr_reward_mag": 0.29626338458179835, "train/extr_reward_max": 0.29626338458179835, "train/extr_reward_mean": 0.002088498443467033, "train/extr_reward_min": 3.000990075258473e-07, "train/extr_reward_std": 0.007803060969254419, "train/image_loss_mean": 0.08367371950205879, "train/image_loss_std": 0.09933844623874076, "train/model_loss_mean": 0.7177526414097838, "train/model_loss_std": 0.46777131797662425, "train/model_opt_grad_norm": 20.26590804576874, "train/model_opt_grad_steps": 46998.16915422885, "train/model_opt_loss": 3679.5455437655473, "train/model_opt_model_opt_grad_overflow": 0.004975124378109453, "train/model_opt_model_opt_grad_scale": 5099.502487562189, "train/policy_entropy_mag": 1.3750432961022676, "train/policy_entropy_max": 1.3750432961022676, "train/policy_entropy_mean": 0.09903211298570111, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.12663743730208174, "train/policy_logprob_mag": 6.551080257738407, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09908174942085399, "train/policy_logprob_min": -6.551080257738407, "train/policy_logprob_std": 0.6371703497805998, "train/policy_randomness_mag": 0.706632513311965, "train/policy_randomness_max": 0.706632513311965, "train/policy_randomness_mean": 0.05089244070411915, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.06507877267860061, "train/post_ent_mag": 28.157164587903377, "train/post_ent_max": 28.157164587903377, "train/post_ent_mean": 27.68380012322421, "train/post_ent_min": 27.326936532015825, "train/post_ent_std": 0.1706318502402424, "train/prior_ent_mag": 28.175277112135248, "train/prior_ent_max": 28.175277112135248, "train/prior_ent_mean": 27.54073311914852, "train/prior_ent_min": 26.468230593856887, "train/prior_ent_std": 0.25191563975751696, "train/rep_loss_mean": 1.0000003896542449, "train/rep_loss_std": 1.2451285937599304e-05, "train/reward_avg": 0.0020490048564124888, "train/reward_loss_mean": 0.014963375170488114, "train/reward_loss_std": 0.22529492173714571, "train/reward_max_data": 0.7589085824157468, "train/reward_max_pred": 0.23504268589304456, "train/reward_neg_acc": 0.9997124823171701, "train/reward_neg_loss": 0.0027527732517459054, "train/reward_pos_acc": 0.15300073835653127, "train/reward_pos_loss": 4.1410281415452665, "train/reward_pred": 0.0016491639657196268, "train/reward_rate": 0.0030074238184079603, "train_stats/mean_log_entropy": 0.0814927856972877, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.011935807764530182, "report/cont_loss_std": 0.18071520328521729, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 4.084590911865234, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.003965836018323898, "report/cont_pred": 0.9960865378379822, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.07122211158275604, "report/image_loss_std": 0.08072198182344437, "report/model_loss_mean": 0.6958141326904297, "report/model_loss_std": 0.41872501373291016, "report/post_ent_mag": 28.12258529663086, "report/post_ent_max": 28.12258529663086, "report/post_ent_mean": 27.65131378173828, "report/post_ent_min": 27.27657127380371, "report/post_ent_std": 0.1706998646259308, "report/prior_ent_mag": 28.11884307861328, "report/prior_ent_max": 28.11884307861328, "report/prior_ent_mean": 27.474916458129883, "report/prior_ent_min": 26.515018463134766, "report/prior_ent_std": 0.24252302944660187, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0015014648670330644, "report/reward_loss_mean": 0.012656155973672867, "report/reward_loss_std": 0.21417629718780518, "report/reward_max_data": 0.8125, "report/reward_max_pred": 0.02829575538635254, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0032046204432845116, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.842391014099121, "report/reward_pred": 0.0016835671849548817, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.053649067878723145, "eval/cont_loss_std": 0.738706111907959, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 9.370292663574219, "eval/cont_pos_acc": 0.999018669128418, "eval/cont_pos_loss": 0.00793442688882351, "eval/cont_pred": 0.9957927465438843, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.19568437337875366, "eval/image_loss_std": 0.1464327573776245, "eval/model_loss_mean": 0.8623591661453247, "eval/model_loss_std": 0.8391157984733582, "eval/post_ent_mag": 28.127382278442383, "eval/post_ent_max": 28.127382278442383, "eval/post_ent_mean": 27.616600036621094, "eval/post_ent_min": 27.27292823791504, "eval/post_ent_std": 0.1892639696598053, "eval/prior_ent_mag": 28.0734806060791, "eval/prior_ent_max": 28.0734806060791, "eval/prior_ent_mean": 27.459402084350586, "eval/prior_ent_min": 26.475067138671875, "eval/prior_ent_std": 0.27624374628067017, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0012939453590661287, "eval/reward_loss_mean": 0.01302570104598999, "eval/reward_loss_std": 0.22776375710964203, "eval/reward_max_data": 0.8125, "eval/reward_max_pred": 0.2149951457977295, "eval/reward_neg_acc": 0.9990215301513672, "eval/reward_neg_loss": 0.003022605087608099, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.124607563018799, "eval/reward_pred": 0.0013862928608432412, "eval/reward_rate": 0.001953125, "replay/size": 769729.0, "replay/inserts": 32080.0, "replay/samples": 32080.0, "replay/insert_wait_avg": 1.3818393027098696e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.831223347537833e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5056.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1943563630309285e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.2069940567016602e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0287802219391, "timer/env.step_count": 4010.0, "timer/env.step_total": 39.6681010723114, "timer/env.step_frac": 0.03966695944841483, "timer/env.step_avg": 0.00989229453174848, "timer/env.step_min": 0.008011817932128906, "timer/env.step_max": 0.04354500770568848, "timer/replay._sample_count": 32080.0, "timer/replay._sample_total": 17.06200671195984, "timer/replay._sample_frac": 0.017061515677752017, "timer/replay._sample_avg": 0.0005318580645872768, "timer/replay._sample_min": 0.0004057884216308594, "timer/replay._sample_max": 0.029448747634887695, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4642.0, "timer/agent.policy_total": 50.50004243850708, "timer/agent.policy_frac": 0.05049858907790581, "timer/agent.policy_avg": 0.01087894063733457, "timer/agent.policy_min": 0.009246826171875, "timer/agent.policy_max": 0.09060478210449219, "timer/dataset_train_count": 2005.0, "timer/dataset_train_total": 0.22788596153259277, "timer/dataset_train_frac": 0.00022787940311279583, "timer/dataset_train_avg": 0.00011365883368209116, "timer/dataset_train_min": 9.679794311523438e-05, "timer/dataset_train_max": 0.0004324913024902344, "timer/agent.train_count": 2005.0, "timer/agent.train_total": 897.1105470657349, "timer/agent.train_frac": 0.8970847287681427, "timer/agent.train_avg": 0.4474366818282967, "timer/agent.train_min": 0.4359710216522217, "timer/agent.train_max": 1.0710787773132324, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47464585304260254, "timer/agent.report_frac": 0.0004746321930227479, "timer/agent.report_avg": 0.23732292652130127, "timer/agent.report_min": 0.2299487590789795, "timer/agent.report_max": 0.24469709396362305, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9802322387695312e-05, "timer/dataset_eval_frac": 2.9801464694927283e-08, "timer/dataset_eval_avg": 2.9802322387695312e-05, "timer/dataset_eval_min": 2.9802322387695312e-05, "timer/dataset_eval_max": 2.9802322387695312e-05, "fps": 32.07853877320709}
{"step": 770376, "time": 24266.97471833229, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 770576, "time": 24273.252216100693, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 770616, "time": 24274.24458503723, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 770712, "time": 24277.318141937256, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 770952, "time": 24284.61467409134, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 771024, "time": 24287.04557776451, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 771104, "time": 24289.465468883514, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 771168, "time": 24291.432940721512, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 771232, "time": 24293.39681982994, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 771296, "time": 24295.340385198593, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 771432, "time": 24299.27755856514, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 771600, "time": 24304.63305902481, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 771640, "time": 24305.655193805695, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 771832, "time": 24311.631587982178, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 772056, "time": 24318.456372976303, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 772112, "time": 24320.41074490547, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 772336, "time": 24327.254619836807, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 772336, "time": 24327.26197195053, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 772400, "time": 24329.215651273727, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 772776, "time": 24340.584337949753, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 772872, "time": 24343.515959978104, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 773072, "time": 24349.861713171005, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 773112, "time": 24350.876494169235, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 773304, "time": 24356.772456645966, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 773432, "time": 24360.68728995323, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 773520, "time": 24363.589258670807, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 773608, "time": 24366.05785894394, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 773992, "time": 24377.890927553177, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 774144, "time": 24382.787145853043, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 774360, "time": 24389.219416856766, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 774376, "time": 24389.717106819153, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 774488, "time": 24393.133652687073, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 774496, "time": 24393.604212522507, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 774608, "time": 24397.178921699524, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 774648, "time": 24398.178436279297, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 774864, "time": 24404.989643335342, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 775000, "time": 24408.918530225754, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 775056, "time": 24410.84220647812, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 775288, "time": 24417.678701877594, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 775648, "time": 24429.0319981575, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 775792, "time": 24433.40075826645, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 775832, "time": 24434.39451265335, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 775864, "time": 24435.370541095734, "episode/length": 187.0, "episode/score": 0.4156250059604645, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.0}
{"step": 776232, "time": 24446.565882205963, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 776232, "time": 24446.573623895645, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 776296, "time": 24448.547657251358, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 776704, "time": 24461.43140769005, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 776736, "time": 24462.40349340439, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 776960, "time": 24469.252747774124, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 776984, "time": 24469.76622891426, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 777000, "time": 24470.257393598557, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 777160, "time": 24475.156739473343, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 777176, "time": 24475.653775453568, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 777368, "time": 24481.524575471878, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 777416, "time": 24483.01252222061, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 777440, "time": 24483.96967124939, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 777720, "time": 24492.416502952576, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 777888, "time": 24498.01347732544, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 777928, "time": 24499.014416456223, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 777944, "time": 24499.506009817123, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 778104, "time": 24504.39442205429, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 778160, "time": 24506.32574391365, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 778384, "time": 24513.65193581581, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 778608, "time": 24520.555515050888, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 778744, "time": 24524.47680735588, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 779048, "time": 24533.742312192917, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 779168, "time": 24537.624989748, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 779488, "time": 24547.583077192307, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 779680, "time": 24553.42664051056, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 779752, "time": 24555.428998231888, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 780000, "time": 24563.983601093292, "eval_episode/length": 36.0, "eval_episode/score": 0.887499988079071, "eval_episode/reward_rate": 0.02702702702702703}
{"step": 780000, "time": 24564.78996682167, "eval_episode/length": 75.0, "eval_episode/score": 0.765625, "eval_episode/reward_rate": 0.013157894736842105}
{"step": 780000, "time": 24565.274930477142, "eval_episode/length": 97.0, "eval_episode/score": 0.6968749761581421, "eval_episode/reward_rate": 0.01020408163265306}
{"step": 780000, "time": 24565.303237438202, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 780000, "time": 24565.70777463913, "eval_episode/length": 117.0, "eval_episode/score": 0.6343749761581421, "eval_episode/reward_rate": 0.00847457627118644}
{"step": 780000, "time": 24566.159781455994, "eval_episode/length": 101.0, "eval_episode/score": 0.684374988079071, "eval_episode/reward_rate": 0.00980392156862745}
{"step": 780000, "time": 24566.88990831375, "eval_episode/length": 75.0, "eval_episode/score": 0.765625, "eval_episode/reward_rate": 0.013157894736842105}
{"step": 780000, "time": 24567.014323711395, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 780032, "time": 24567.990426301956, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 780056, "time": 24568.51619696617, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 780176, "time": 24572.428050518036, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 780240, "time": 24574.37080001831, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 780584, "time": 24584.71132850647, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 780696, "time": 24588.140371322632, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 780704, "time": 24588.609049797058, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 780712, "time": 24588.6366648674, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 781104, "time": 24600.7981903553, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 781128, "time": 24601.31015253067, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 781224, "time": 24604.226865530014, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 781304, "time": 24606.830117702484, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 781480, "time": 24612.167995929718, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 781656, "time": 24617.520131349564, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 781696, "time": 24618.964749336243, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 782064, "time": 24630.285390615463, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 782128, "time": 24632.246772289276, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 782216, "time": 24634.738677978516, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 782336, "time": 24638.79097056389, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 782496, "time": 24643.702701091766, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 783008, "time": 24659.400500774384, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 783168, "time": 24664.317626953125, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 783256, "time": 24666.873207092285, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 783416, "time": 24671.717741966248, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 783464, "time": 24673.161001205444, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 783592, "time": 24677.057901859283, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 783904, "time": 24686.798804044724, "episode/length": 210.0, "episode/score": 0.34375, "episode/reward_rate": 0.004739336492890996, "episode/intrinsic_return": 0.0}
{"step": 784008, "time": 24689.761323451996, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 784240, "time": 24697.150481939316, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 784312, "time": 24699.153843402863, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 784328, "time": 24699.64761352539, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 784376, "time": 24701.12172627449, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 784392, "time": 24701.61100959778, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 784480, "time": 24704.540814876556, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 784648, "time": 24709.440844774246, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 785032, "time": 24721.093374490738, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 785160, "time": 24725.020105838776, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 785184, "time": 24725.977853298187, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 785288, "time": 24729.02094602585, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 785352, "time": 24730.982089042664, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 785440, "time": 24733.89226579666, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 785504, "time": 24735.839014530182, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 785936, "time": 24749.066154241562, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 785976, "time": 24750.064203500748, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 786112, "time": 24754.444744110107, "episode/length": 182.0, "episode/score": 0.4312500059604645, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.0}
{"step": 786152, "time": 24755.44406580925, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 786240, "time": 24758.483185768127, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 786272, "time": 24759.45873594284, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 786320, "time": 24760.922013282776, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 786560, "time": 24768.706467151642, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 786792, "time": 24775.522039175034, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 786880, "time": 24778.43625187874, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 787368, "time": 24793.202887773514, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 787432, "time": 24795.176738739014, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 787496, "time": 24797.14124274254, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 787600, "time": 24800.514806985855, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 787648, "time": 24801.98742580414, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 787736, "time": 24804.44857621193, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 787872, "time": 24808.8551132679, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 787992, "time": 24812.284067630768, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 788096, "time": 24815.66034603119, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 788160, "time": 24817.770301103592, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 788464, "time": 24827.046137571335, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 788576, "time": 24830.453747987747, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 788648, "time": 24832.440114974976, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 788720, "time": 24834.861283540726, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 788880, "time": 24839.778482437134, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 789112, "time": 24846.679875850677, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 789232, "time": 24850.537040233612, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 789336, "time": 24853.468863010406, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 789440, "time": 24856.869728803635, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 789704, "time": 24864.626244544983, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 790024, "time": 24874.36541390419, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 790048, "time": 24875.3447329998, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 790080, "time": 24876.326674461365, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 790088, "time": 24877.458611011505, "eval_episode/length": 46.0, "eval_episode/score": 0.856249988079071, "eval_episode/reward_rate": 0.02127659574468085}
{"step": 790088, "time": 24877.65227174759, "eval_episode/length": 56.0, "eval_episode/score": 0.824999988079071, "eval_episode/reward_rate": 0.017543859649122806}
{"step": 790088, "time": 24878.0356798172, "eval_episode/length": 75.0, "eval_episode/score": 0.765625, "eval_episode/reward_rate": 0.013157894736842105}
{"step": 790088, "time": 24878.33166217804, "eval_episode/length": 90.0, "eval_episode/score": 0.71875, "eval_episode/reward_rate": 0.01098901098901099}
{"step": 790088, "time": 24878.48957848549, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 790088, "time": 24878.554649591446, "eval_episode/length": 101.0, "eval_episode/score": 0.684374988079071, "eval_episode/reward_rate": 0.00980392156862745}
{"step": 790088, "time": 24878.6179625988, "eval_episode/length": 28.0, "eval_episode/score": 0.9125000238418579, "eval_episode/reward_rate": 0.034482758620689655}
{"step": 790088, "time": 24879.697177410126, "eval_episode/length": 60.0, "eval_episode/score": 0.8125, "eval_episode/reward_rate": 0.01639344262295082}
{"step": 790240, "time": 24884.558512449265, "episode/length": 19.0, "episode/score": 0.940625011920929, "episode/reward_rate": 0.05, "episode/intrinsic_return": 0.0}
{"step": 790504, "time": 24892.43842768669, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 790664, "time": 24897.333101272583, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 790720, "time": 24899.28198337555, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 790960, "time": 24906.808112621307, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 791192, "time": 24913.630935430527, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 791328, "time": 24918.00267982483, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 791416, "time": 24920.466948270798, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 791544, "time": 24924.356149196625, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 791544, "time": 24924.364342927933, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 791648, "time": 24927.772052288055, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 791936, "time": 24936.70680832863, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 792056, "time": 24940.153228998184, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 792064, "time": 24940.624591588974, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 792552, "time": 24955.338366508484, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 792600, "time": 24956.820830345154, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 792648, "time": 24958.29450392723, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 792688, "time": 24959.733688354492, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 792864, "time": 24967.18425631523, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 793024, "time": 24972.054955482483, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 793232, "time": 24978.394607782364, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 793272, "time": 24979.394968032837, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 793304, "time": 24980.37666130066, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 793472, "time": 24985.734709501266, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 793656, "time": 24991.16889810562, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 794016, "time": 25002.501828193665, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 794128, "time": 25005.94478392601, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 794176, "time": 25007.399174690247, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 794248, "time": 25009.370362997055, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 794568, "time": 25019.15564608574, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 794744, "time": 25025.019186019897, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 794992, "time": 25032.968969106674, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 795080, "time": 25035.4349629879, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 795288, "time": 25041.800724744797, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 795616, "time": 25052.01588845253, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 795624, "time": 25052.043402433395, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 795784, "time": 25057.008257865906, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 795824, "time": 25058.472544431686, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 795968, "time": 25062.859519720078, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 796176, "time": 25069.188267707825, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 796192, "time": 25069.677188158035, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 796224, "time": 25070.65289068222, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 796328, "time": 25073.607105970383, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 796432, "time": 25076.992482185364, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 796512, "time": 25079.40520119667, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 796744, "time": 25086.235823869705, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 796832, "time": 25089.27516078949, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 797200, "time": 25100.50068807602, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 797224, "time": 25101.01128768921, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 797584, "time": 25112.305653572083, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 797600, "time": 25112.801476716995, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 797840, "time": 25120.232783794403, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 797928, "time": 25122.733963012695, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 797952, "time": 25123.70192050934, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 798048, "time": 25126.662286520004, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 798488, "time": 25139.90638756752, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 798640, "time": 25144.785279512405, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 798680, "time": 25145.80401492119, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 798744, "time": 25147.84606695175, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 798832, "time": 25150.76260948181, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 798856, "time": 25151.279913663864, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 798896, "time": 25152.71685242653, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 799008, "time": 25156.136923074722, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 799056, "time": 25157.596340417862, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 799336, "time": 25165.88774752617, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 799392, "time": 25167.81731414795, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 799888, "time": 25182.952491998672, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 800072, "time": 25189.135003566742, "eval_episode/length": 40.0, "eval_episode/score": 0.875, "eval_episode/reward_rate": 0.024390243902439025}
{"step": 800072, "time": 25189.357065677643, "eval_episode/length": 51.0, "eval_episode/score": 0.840624988079071, "eval_episode/reward_rate": 0.019230769230769232}
{"step": 800072, "time": 25189.897492408752, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 800072, "time": 25190.20356655121, "eval_episode/length": 96.0, "eval_episode/score": 0.699999988079071, "eval_episode/reward_rate": 0.010309278350515464}
{"step": 800072, "time": 25190.488877773285, "eval_episode/length": 110.0, "eval_episode/score": 0.65625, "eval_episode/reward_rate": 0.009009009009009009}
{"step": 800072, "time": 25190.770425081253, "eval_episode/length": 13.0, "eval_episode/score": 0.9593750238418579, "eval_episode/reward_rate": 0.07142857142857142}
{"step": 800072, "time": 25190.816869735718, "eval_episode/length": 126.0, "eval_episode/score": 0.606249988079071, "eval_episode/reward_rate": 0.007874015748031496}
{"step": 800072, "time": 25191.153908729553, "eval_episode/length": 101.0, "eval_episode/score": 0.684374988079071, "eval_episode/reward_rate": 0.00980392156862745}
{"step": 800256, "time": 25196.99037885666, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 800272, "time": 25197.499475479126, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 800320, "time": 25198.95979833603, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 800584, "time": 25206.87813973427, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 800920, "time": 25217.118938446045, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 800952, "time": 25218.095485925674, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 801016, "time": 25220.05494737625, "episode/length": 7.0, "episode/score": 0.9781249761581421, "episode/reward_rate": 0.125, "episode/intrinsic_return": 0.0}
{"step": 801144, "time": 25223.96567583084, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 801208, "time": 25225.922787427902, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 801248, "time": 25227.387667894363, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 801320, "time": 25229.36349439621, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 801344, "time": 25230.32776594162, "episode/length": 16.0, "episode/score": 0.949999988079071, "episode/reward_rate": 0.058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 801368, "time": 25230.84004998207, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 801440, "time": 25233.26683163643, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 801536, "time": 25236.191658258438, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 801784, "time": 25243.727199792862, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 801784, "time": 25243.74598479271, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 801816, "time": 25244.746237516403, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 802024, "time": 25251.096745491028, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 802120, "time": 25254.035750865936, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 802160, "time": 25255.480157136917, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 802377, "time": 25262.888848781586, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.574373008006841, "train/action_min": 0.0, "train/action_std": 1.77832726993371, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.009381337841944908, "train/actor_opt_grad_steps": 49050.0, "train/actor_opt_loss": -16.743334694288265, "train/adv_mag": 0.8744772459144023, "train/adv_max": 0.4446254618725373, "train/adv_mean": -6.710502011673953e-05, "train/adv_min": -0.7810133769737547, "train/adv_std": 0.024075473811644228, "train/cont_avg": 0.994150342039801, "train/cont_loss_mean": 0.020795524384437214, "train/cont_loss_std": 0.25753494856221165, "train/cont_neg_acc": 0.28765247232137037, "train/cont_neg_loss": 2.818864500831201, "train/cont_pos_acc": 0.999868085728356, "train/cont_pos_loss": 0.004106220478812854, "train/cont_pred": 0.9943516838609876, "train/cont_rate": 0.994150342039801, "train/dyn_loss_mean": 1.0000045376630564, "train/dyn_loss_std": 0.00014512928490021927, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.09849233687183453, "train/extr_critic_critic_opt_grad_steps": 49050.0, "train/extr_critic_critic_opt_loss": 13331.928565181903, "train/extr_critic_mag": 1.4702071918183892, "train/extr_critic_max": 1.4702071918183892, "train/extr_critic_mean": 1.3684289645199752, "train/extr_critic_min": 0.8137192328770956, "train/extr_critic_std": 0.024736435833706785, "train/extr_return_normed_mag": 0.9597912700615119, "train/extr_return_normed_max": 0.26044508711022524, "train/extr_return_normed_mean": 0.04428996680424878, "train/extr_return_normed_min": -0.8965380968739144, "train/extr_return_normed_std": 0.03441208424000301, "train/extr_return_rate": 0.9996388877802227, "train/extr_return_raw_mag": 1.5845169095850702, "train/extr_return_raw_max": 1.5845169095850702, "train/extr_return_raw_mean": 1.3683618591792548, "train/extr_return_raw_min": 0.4275337256009306, "train/extr_return_raw_std": 0.03441208428633747, "train/extr_reward_mag": 0.24620587968114596, "train/extr_reward_max": 0.24620587968114596, "train/extr_reward_mean": 0.0020166711275933762, "train/extr_reward_min": 2.235915530380325e-07, "train/extr_reward_std": 0.00715684205112951, "train/image_loss_mean": 0.0863148896625979, "train/image_loss_std": 0.1019472473889441, "train/model_loss_mean": 0.7239492846958673, "train/model_loss_std": 0.5009002636988364, "train/model_opt_grad_norm": 19.43632009610608, "train/model_opt_grad_steps": 49006.26865671642, "train/model_opt_loss": 3928.413127234919, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5422.885572139304, "train/policy_entropy_mag": 1.3748909442578976, "train/policy_entropy_max": 1.3748909442578976, "train/policy_entropy_mean": 0.10162560059804822, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.13092380958558314, "train/policy_logprob_mag": 6.551080260110732, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.10220389965161755, "train/policy_logprob_min": -6.551080260110732, "train/policy_logprob_std": 0.6420545148019173, "train/policy_randomness_mag": 0.7065542165319718, "train/policy_randomness_max": 0.7065542165319718, "train/policy_randomness_mean": 0.05222522939986257, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.06728153281025033, "train/post_ent_mag": 28.18928651192888, "train/post_ent_max": 28.18928651192888, "train/post_ent_mean": 27.703926361615384, "train/post_ent_min": 27.325341181968575, "train/post_ent_std": 0.1804784811403028, "train/prior_ent_mag": 28.149266038961077, "train/prior_ent_max": 28.149266038961077, "train/prior_ent_mean": 27.443804479950103, "train/prior_ent_min": 26.43804948721359, "train/prior_ent_std": 0.28111855218659587, "train/rep_loss_mean": 1.0000045376630564, "train/rep_loss_std": 0.00014512928490021927, "train/reward_avg": 0.0023258645778515526, "train/reward_loss_mean": 0.016836123969591228, "train/reward_loss_std": 0.2438764728615014, "train/reward_max_data": 0.7894123136181737, "train/reward_max_pred": 0.2755327788158436, "train/reward_neg_acc": 0.9996685065440277, "train/reward_neg_loss": 0.002838128118078451, "train/reward_pos_acc": 0.156637809117033, "train/reward_pos_loss": 4.137424798926922, "train/reward_pred": 0.0017458531861911661, "train/reward_rate": 0.0033766713308457713, "train_stats/mean_log_entropy": 0.08276778229316417, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.025971580296754837, "report/cont_loss_std": 0.3471110761165619, "report/cont_neg_acc": 0.1666666716337204, "report/cont_neg_loss": 3.9268674850463867, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.002980050165206194, "report/cont_pred": 0.9960296154022217, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.07919654250144958, "report/image_loss_std": 0.09870141744613647, "report/model_loss_mean": 0.7282008528709412, "report/model_loss_std": 0.6758738160133362, "report/post_ent_mag": 27.977502822875977, "report/post_ent_max": 27.977502822875977, "report/post_ent_mean": 27.458677291870117, "report/post_ent_min": 27.061941146850586, "report/post_ent_std": 0.18247345089912415, "report/prior_ent_mag": 27.998708724975586, "report/prior_ent_max": 27.998708724975586, "report/prior_ent_mean": 27.327545166015625, "report/prior_ent_min": 26.25655746459961, "report/prior_ent_std": 0.2938956618309021, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0027465817984193563, "report/reward_loss_mean": 0.02303270995616913, "report/reward_loss_std": 0.33777689933776855, "report/reward_max_data": 0.9125000238418579, "report/reward_max_pred": 0.12457573413848877, "report/reward_neg_acc": 0.9990195631980896, "report/reward_neg_loss": 0.0022640356328338385, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 5.319045066833496, "report/reward_pred": 0.0012382379500195384, "report/reward_rate": 0.00390625, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.04697348177433014, "eval/cont_loss_std": 0.687904417514801, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 9.054430961608887, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0027759470976889133, "eval/cont_pred": 0.997310996055603, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.13787822425365448, "eval/image_loss_std": 0.12381138652563095, "eval/model_loss_mean": 0.8034876585006714, "eval/model_loss_std": 1.0383342504501343, "eval/post_ent_mag": 27.975765228271484, "eval/post_ent_max": 27.975765228271484, "eval/post_ent_mean": 27.443708419799805, "eval/post_ent_min": 27.061555862426758, "eval/post_ent_std": 0.18424159288406372, "eval/prior_ent_mag": 28.011791229248047, "eval/prior_ent_max": 28.011791229248047, "eval/prior_ent_mean": 27.352075576782227, "eval/prior_ent_min": 26.365272521972656, "eval/prior_ent_std": 0.26699569821357727, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0012084960471838713, "eval/reward_loss_mean": 0.018635952845215797, "eval/reward_loss_std": 0.4384286105632782, "eval/reward_max_data": 0.762499988079071, "eval/reward_max_pred": 0.04174458980560303, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0013091041473671794, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 8.872655868530273, "eval/reward_pred": 0.00071330601349473, "eval/reward_rate": 0.001953125, "replay/size": 801873.0, "replay/inserts": 32144.0, "replay/samples": 32144.0, "replay/insert_wait_avg": 1.3793476070557857e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.902794808045497e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3864.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1803694146513691e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.98377799987793e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0090947151184, "timer/env.step_count": 4018.0, "timer/env.step_total": 39.821948766708374, "timer/env.step_frac": 0.03982158660072268, "timer/env.step_avg": 0.009910888194800491, "timer/env.step_min": 0.007959365844726562, "timer/env.step_max": 0.03677797317504883, "timer/replay._sample_count": 32144.0, "timer/replay._sample_total": 17.27444362640381, "timer/replay._sample_frac": 0.01727428652168902, "timer/replay._sample_avg": 0.0005374080272027068, "timer/replay._sample_min": 0.0004146099090576172, "timer/replay._sample_max": 0.011893272399902344, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4501.0, "timer/agent.policy_total": 48.60909032821655, "timer/agent.policy_frac": 0.04860864824640846, "timer/agent.policy_avg": 0.010799620157346491, "timer/agent.policy_min": 0.009045600891113281, "timer/agent.policy_max": 0.08516144752502441, "timer/dataset_train_count": 2009.0, "timer/dataset_train_total": 0.22870707511901855, "timer/dataset_train_frac": 0.00022870499511224186, "timer/dataset_train_avg": 0.00011384125192584299, "timer/dataset_train_min": 9.775161743164062e-05, "timer/dataset_train_max": 0.0004973411560058594, "timer/agent.train_count": 2009.0, "timer/agent.train_total": 900.4896023273468, "timer/agent.train_frac": 0.9004814127054288, "timer/agent.train_avg": 0.4482277761709043, "timer/agent.train_min": 0.43521809577941895, "timer/agent.train_max": 2.410262107849121, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4772157669067383, "timer/agent.report_frac": 0.0004772114268047602, "timer/agent.report_avg": 0.23860788345336914, "timer/agent.report_min": 0.23076725006103516, "timer/agent.report_max": 0.24644851684570312, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0994415283203125e-05, "timer/dataset_eval_frac": 3.099413340038951e-08, "timer/dataset_eval_avg": 3.0994415283203125e-05, "timer/dataset_eval_min": 3.0994415283203125e-05, "timer/dataset_eval_max": 3.0994415283203125e-05, "fps": 32.143088402558625}
{"step": 802464, "time": 25265.533649921417, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 802544, "time": 25268.17549109459, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 802704, "time": 25273.063544750214, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 802896, "time": 25279.429264068604, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 802936, "time": 25280.441465377808, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 803136, "time": 25286.84619116783, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 803256, "time": 25290.305397748947, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 803480, "time": 25297.34955716133, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 803496, "time": 25297.838466882706, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 803504, "time": 25298.308252811432, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 803848, "time": 25308.57188463211, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 804216, "time": 25319.739398241043, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 804416, "time": 25326.056736707687, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 804640, "time": 25333.032327890396, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 804688, "time": 25334.4919860363, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 804856, "time": 25339.410981178284, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 804904, "time": 25340.880120754242, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 805016, "time": 25344.28940629959, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 805080, "time": 25346.26346206665, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 805112, "time": 25347.250190973282, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 805568, "time": 25361.48639011383, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 805688, "time": 25364.934185028076, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 805792, "time": 25368.3410449028, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 805792, "time": 25368.349264383316, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 805792, "time": 25368.36061358452, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 805896, "time": 25371.353460788727, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 806224, "time": 25381.569385766983, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 806360, "time": 25385.485604047775, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 806480, "time": 25389.45108485222, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 806512, "time": 25390.44121313095, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 806784, "time": 25398.777112960815, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 806904, "time": 25402.218173503876, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 806920, "time": 25402.707594156265, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 807168, "time": 25410.52435708046, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 807376, "time": 25416.951886177063, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 807544, "time": 25421.83465576172, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 808104, "time": 25438.959060907364, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 808288, "time": 25444.83208680153, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 808320, "time": 25445.807435035706, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 808672, "time": 25456.632405281067, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 808792, "time": 25460.0677216053, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 808856, "time": 25462.00106739998, "episode/length": 7.0, "episode/score": 0.9781249761581421, "episode/reward_rate": 0.125, "episode/intrinsic_return": 0.0}
{"step": 808928, "time": 25464.433768987656, "episode/length": 219.0, "episode/score": 0.31562501192092896, "episode/reward_rate": 0.004545454545454545, "episode/intrinsic_return": 0.0}
{"step": 809056, "time": 25468.331292152405, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 809216, "time": 25473.18728160858, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 809232, "time": 25473.692949295044, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 809248, "time": 25474.181222438812, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 809272, "time": 25474.69119167328, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 809560, "time": 25483.631943702698, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 809568, "time": 25484.105262041092, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 809816, "time": 25491.435327529907, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 809960, "time": 25495.85656118393, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 810056, "time": 25500.111767053604, "eval_episode/length": 65.0, "eval_episode/score": 0.796875, "eval_episode/reward_rate": 0.015151515151515152}
{"step": 810056, "time": 25500.281253814697, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 810056, "time": 25500.306888580322, "eval_episode/length": 75.0, "eval_episode/score": 0.765625, "eval_episode/reward_rate": 0.013157894736842105}
{"step": 810056, "time": 25500.447649240494, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 810056, "time": 25500.6526658535, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 810056, "time": 25500.67743587494, "eval_episode/length": 93.0, "eval_episode/score": 0.7093750238418579, "eval_episode/reward_rate": 0.010638297872340425}
{"step": 810056, "time": 25502.501792907715, "eval_episode/length": 113.0, "eval_episode/score": 0.6468750238418579, "eval_episode/reward_rate": 0.008771929824561403}
{"step": 810056, "time": 25502.668701171875, "eval_episode/length": 130.0, "eval_episode/score": 0.59375, "eval_episode/reward_rate": 0.007633587786259542}
{"step": 810112, "time": 25504.58771920204, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 810200, "time": 25507.15594291687, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 810464, "time": 25515.386873960495, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 810560, "time": 25518.31687283516, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 810584, "time": 25518.82933449745, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 810632, "time": 25520.298685073853, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 811096, "time": 25535.02072429657, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 811168, "time": 25537.560539484024, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 811296, "time": 25541.44962453842, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 811456, "time": 25546.330310583115, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 811528, "time": 25548.326317071915, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 811584, "time": 25550.250913858414, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 811880, "time": 25559.048666715622, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 811896, "time": 25559.539662599564, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 812400, "time": 25575.229211091995, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 812920, "time": 25590.83631849289, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 812944, "time": 25591.786886930466, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 812944, "time": 25591.796315193176, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 812952, "time": 25591.82941675186, "episode/length": 222.0, "episode/score": 0.3062500059604645, "episode/reward_rate": 0.004484304932735426, "episode/intrinsic_return": 0.0}
{"step": 813184, "time": 25599.21381497383, "episode/length": 199.0, "episode/score": 0.37812501192092896, "episode/reward_rate": 0.005, "episode/intrinsic_return": 0.0}
{"step": 813408, "time": 25606.08579802513, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 813768, "time": 25616.857804775238, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 813800, "time": 25617.840106248856, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 813800, "time": 25617.849509954453, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 814096, "time": 25627.235236406326, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 814336, "time": 25634.57254099846, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 814448, "time": 25637.994793653488, "episode/length": 187.0, "episode/score": 0.4156250059604645, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.0}
{"step": 814712, "time": 25645.82650923729, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 814952, "time": 25653.157883405685, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 815160, "time": 25659.684349536896, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 815496, "time": 25669.893137931824, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 815608, "time": 25673.267567396164, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 815720, "time": 25676.707208395004, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 816112, "time": 25688.985961914062, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 816112, "time": 25688.995319604874, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 816144, "time": 25689.969782829285, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 816240, "time": 25692.855031728745, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 816496, "time": 25700.690653324127, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 816760, "time": 25708.54482483864, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 816784, "time": 25709.49151945114, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 817024, "time": 25716.84029006958, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 817144, "time": 25720.29150366783, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 817320, "time": 25725.687211036682, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 817344, "time": 25726.655422210693, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 817400, "time": 25728.172057151794, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 817472, "time": 25730.592888355255, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 817768, "time": 25739.389813423157, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 817968, "time": 25745.633515119553, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 818016, "time": 25747.218612909317, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 818040, "time": 25747.746441841125, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 818048, "time": 25748.215966939926, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 818216, "time": 25753.073274612427, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 818232, "time": 25753.566744327545, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 818456, "time": 25760.434814929962, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 818472, "time": 25760.928480386734, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 818664, "time": 25766.79852628708, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 818712, "time": 25768.27441596985, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 818848, "time": 25772.648577928543, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 818888, "time": 25773.644125938416, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 819376, "time": 25789.33217406273, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 819504, "time": 25793.239033937454, "episode/length": 182.0, "episode/score": 0.4312500059604645, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.0}
{"step": 819512, "time": 25793.26909303665, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 819560, "time": 25794.744718790054, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 819904, "time": 25805.413835287094, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 819976, "time": 25807.514935016632, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 820040, "time": 25810.66462826729, "eval_episode/length": 63.0, "eval_episode/score": 0.8031250238418579, "eval_episode/reward_rate": 0.015625}
{"step": 820040, "time": 25810.782814741135, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 820040, "time": 25811.13441801071, "eval_episode/length": 87.0, "eval_episode/score": 0.7281249761581421, "eval_episode/reward_rate": 0.011363636363636364}
{"step": 820040, "time": 25811.53331565857, "eval_episode/length": 108.0, "eval_episode/score": 0.6625000238418579, "eval_episode/reward_rate": 0.009174311926605505}
{"step": 820040, "time": 25812.233309984207, "eval_episode/length": 81.0, "eval_episode/score": 0.746874988079071, "eval_episode/reward_rate": 0.012195121951219513}
{"step": 820040, "time": 25812.588947057724, "eval_episode/length": 164.0, "eval_episode/score": 0.48750001192092896, "eval_episode/reward_rate": 0.006060606060606061}
{"step": 820040, "time": 25813.73657464981, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 820040, "time": 25813.804581165314, "eval_episode/length": 119.0, "eval_episode/score": 0.628125011920929, "eval_episode/reward_rate": 0.008333333333333333}
{"step": 820216, "time": 25819.14122581482, "episode/length": 219.0, "episode/score": 0.31562501192092896, "episode/reward_rate": 0.004545454545454545, "episode/intrinsic_return": 0.0}
{"step": 820240, "time": 25820.09900856018, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 820344, "time": 25823.04363179207, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 820744, "time": 25835.244419813156, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 820768, "time": 25836.218144655228, "episode/length": 262.0, "episode/score": 0.18125000596046448, "episode/reward_rate": 0.0038022813688212928, "episode/intrinsic_return": 0.0}
{"step": 820784, "time": 25836.820803642273, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 821024, "time": 25844.164395332336, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 821160, "time": 25848.087554693222, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 821224, "time": 25850.04965019226, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 821648, "time": 25863.189599514008, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 821976, "time": 25873.053929567337, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 822280, "time": 25882.394073963165, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 822368, "time": 25885.304609060287, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 822528, "time": 25890.18337202072, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 822552, "time": 25890.69835639, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 822656, "time": 25894.06661772728, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 823080, "time": 25906.924716472626, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 823096, "time": 25907.421274900436, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 823176, "time": 25909.872083425522, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 823584, "time": 25922.49991416931, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 823704, "time": 25925.95997786522, "episode/length": 14.0, "episode/score": 0.956250011920929, "episode/reward_rate": 0.06666666666666667, "episode/intrinsic_return": 0.0}
{"step": 823960, "time": 25933.89323425293, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 824288, "time": 25944.095627069473, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 824592, "time": 25953.33763551712, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 824672, "time": 25955.76522064209, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 824840, "time": 25960.757645606995, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 824864, "time": 25961.723843336105, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 824968, "time": 25964.713677167892, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 825000, "time": 25965.705473661423, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 825136, "time": 25970.14111185074, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 825408, "time": 25978.46276450157, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 825488, "time": 25980.88442850113, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 825552, "time": 25982.842886686325, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 825808, "time": 25990.704887390137, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 825848, "time": 25991.700750112534, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 825904, "time": 25993.622728586197, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 826136, "time": 26000.45673060417, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 826160, "time": 26001.42055606842, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 826464, "time": 26010.678122758865, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 826488, "time": 26011.19030737877, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 826688, "time": 26017.577989578247, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 826776, "time": 26020.0326898098, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 826880, "time": 26023.433678388596, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 826896, "time": 26023.928879499435, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 827328, "time": 26037.083284139633, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 827568, "time": 26044.84722828865, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 827680, "time": 26048.364069461823, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 827720, "time": 26049.363747119904, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 827800, "time": 26051.820083856583, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 827832, "time": 26052.80335044861, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 828048, "time": 26059.679393529892, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 828336, "time": 26068.51036977768, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 828424, "time": 26070.970860004425, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 828720, "time": 26080.314399003983, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 828776, "time": 26081.822996854782, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 828784, "time": 26082.29691338539, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 828800, "time": 26082.789188861847, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 828800, "time": 26082.79872894287, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 828936, "time": 26086.732646226883, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 828968, "time": 26087.71821808815, "episode/length": 20.0, "episode/score": 0.9375, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.0}
{"step": 829088, "time": 26091.634118318558, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 829336, "time": 26099.019906759262, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 829472, "time": 26103.398049354553, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 829496, "time": 26103.908940792084, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 829584, "time": 26106.930081367493, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 829720, "time": 26110.88309764862, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 829944, "time": 26117.671766757965, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 830024, "time": 26120.83877158165, "eval_episode/length": 21.0, "eval_episode/score": 0.934374988079071, "eval_episode/reward_rate": 0.045454545454545456}
{"step": 830024, "time": 26122.135421276093, "eval_episode/length": 67.0, "eval_episode/score": 0.7906249761581421, "eval_episode/reward_rate": 0.014705882352941176}
{"step": 830024, "time": 26122.467234373093, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 830024, "time": 26123.238938093185, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 830024, "time": 26123.831792354584, "eval_episode/length": 81.0, "eval_episode/score": 0.746874988079071, "eval_episode/reward_rate": 0.012195121951219513}
{"step": 830024, "time": 26123.87824845314, "eval_episode/length": 151.0, "eval_episode/score": 0.528124988079071, "eval_episode/reward_rate": 0.006578947368421052}
{"step": 830024, "time": 26123.92634701729, "eval_episode/length": 153.0, "eval_episode/score": 0.5218750238418579, "eval_episode/reward_rate": 0.006493506493506494}
{"step": 830024, "time": 26124.17268013954, "eval_episode/length": 165.0, "eval_episode/score": 0.484375, "eval_episode/reward_rate": 0.006024096385542169}
{"step": 830360, "time": 26134.394065380096, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 830376, "time": 26134.886045455933, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 830440, "time": 26136.93869805336, "episode/length": 9.0, "episode/score": 0.971875011920929, "episode/reward_rate": 0.1, "episode/intrinsic_return": 0.0}
{"step": 830448, "time": 26137.40723133087, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 830488, "time": 26138.403652191162, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 830520, "time": 26139.39645409584, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 830872, "time": 26150.084215164185, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 831192, "time": 26159.830404520035, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 831216, "time": 26160.7886800766, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 831224, "time": 26160.817578077316, "episode/length": 204.0, "episode/score": 0.36250001192092896, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.0}
{"step": 831400, "time": 26166.208766937256, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 831688, "time": 26175.08224272728, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 831736, "time": 26176.54460978508, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 831808, "time": 26178.979787826538, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 832016, "time": 26185.301973104477, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 832032, "time": 26185.788658857346, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 832136, "time": 26188.727996349335, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 832232, "time": 26191.626786231995, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 832256, "time": 26192.581604242325, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 832432, "time": 26198.06582403183, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 832704, "time": 26206.34099125862, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 832880, "time": 26211.68500995636, "episode/length": 207.0, "episode/score": 0.3531250059604645, "episode/reward_rate": 0.004807692307692308, "episode/intrinsic_return": 0.0}
{"step": 832952, "time": 26213.663125753403, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 833080, "time": 26217.55964946747, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 833104, "time": 26218.515711545944, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 833520, "time": 26231.312712430954, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 833584, "time": 26233.285860061646, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 833712, "time": 26237.20577931404, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 834120, "time": 26249.42181611061, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 834192, "time": 26251.851628303528, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 834312, "time": 26255.276698112488, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 834328, "time": 26255.768466234207, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 834368, "time": 26257.335755825043, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 834416, "time": 26258.792055368423, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 834537, "time": 26263.222128868103, "train_stats/mean_log_entropy": 0.08197500765186931, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.4968380145172575, "train/action_min": 0.0, "train/action_std": 1.7430382456945543, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.01138237757904835, "train/actor_opt_grad_steps": 51060.0, "train/actor_opt_loss": -18.871653419228927, "train/adv_mag": 0.9026343632693314, "train/adv_max": 0.46530071835019693, "train/adv_mean": 0.0018123276637034811, "train/adv_min": -0.7946626932466802, "train/adv_std": 0.030667334679162026, "train/cont_avg": 0.9943932680348259, "train/cont_loss_mean": 0.020444761692958686, "train/cont_loss_std": 0.25679805018563767, "train/cont_neg_acc": 0.2694740640509188, "train/cont_neg_loss": 2.8830907232132716, "train/cont_pos_acc": 0.9998485600177328, "train/cont_pos_loss": 0.004287715151034926, "train/cont_pred": 0.9943636216927524, "train/cont_rate": 0.9943932680348259, "train/dyn_loss_mean": 1.0000024861957304, "train/dyn_loss_std": 7.91092040086749e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.12905882058933896, "train/extr_critic_critic_opt_grad_steps": 51060.0, "train/extr_critic_critic_opt_loss": 13099.553123056592, "train/extr_critic_mag": 1.5083747479453016, "train/extr_critic_max": 1.5083747479453016, "train/extr_critic_mean": 1.403416397559702, "train/extr_critic_min": 0.8323579842771464, "train/extr_critic_std": 0.029582310778399307, "train/extr_return_normed_mag": 0.9386211260041194, "train/extr_return_normed_max": 0.3087116135886653, "train/extr_return_normed_mean": 0.05707111431109668, "train/extr_return_normed_min": -0.8590004088273689, "train/extr_return_normed_std": 0.04331748001277447, "train/extr_return_rate": 0.9994989597975318, "train/extr_return_raw_mag": 1.6568692027039789, "train/extr_return_raw_max": 1.6568692027039789, "train/extr_return_raw_mean": 1.4052287624843085, "train/extr_return_raw_min": 0.48915718028794475, "train/extr_return_raw_std": 0.043317480161044725, "train/extr_reward_mag": 0.29067072761592583, "train/extr_reward_max": 0.29067072761592583, "train/extr_reward_mean": 0.0022490046248280107, "train/extr_reward_min": 1.9808906820876088e-07, "train/extr_reward_std": 0.00932401872531914, "train/image_loss_mean": 0.0832980613210308, "train/image_loss_std": 0.09856531264918361, "train/model_loss_mean": 0.7199866774663404, "train/model_loss_std": 0.4888690512126951, "train/model_opt_grad_norm": 19.41942242010316, "train/model_opt_grad_steps": 51014.36815920398, "train/model_opt_loss": 3670.1509493547887, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5099.502487562189, "train/policy_entropy_mag": 1.342258720848691, "train/policy_entropy_max": 1.342258720848691, "train/policy_entropy_mean": 0.09947804602520977, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.1265915358689294, "train/policy_logprob_mag": 6.551080252993759, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09924007084832262, "train/policy_logprob_min": -6.551080252993759, "train/policy_logprob_std": 0.6364952758770084, "train/policy_randomness_mag": 0.6897845716025699, "train/policy_randomness_max": 0.6897845716025699, "train/policy_randomness_mean": 0.051121604976369375, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.06505518477057937, "train/post_ent_mag": 28.156456733817485, "train/post_ent_max": 28.156456733817485, "train/post_ent_mean": 27.652857538479477, "train/post_ent_min": 27.262875694540604, "train/post_ent_std": 0.18900734890456222, "train/prior_ent_mag": 27.944145582208584, "train/prior_ent_max": 27.944145582208584, "train/prior_ent_mean": 27.206270559510187, "train/prior_ent_min": 26.2204684167359, "train/prior_ent_std": 0.28430391514479225, "train/rep_loss_mean": 1.0000024861957304, "train/rep_loss_std": 7.91092040086749e-05, "train/reward_avg": 0.002206921931912205, "train/reward_loss_mean": 0.016242340946134495, "train/reward_loss_std": 0.235920536836878, "train/reward_max_data": 0.7779384325096264, "train/reward_max_pred": 0.27119231757832996, "train/reward_neg_acc": 0.9996928789129305, "train/reward_neg_loss": 0.0029810665312005363, "train/reward_pos_acc": 0.14666587091870045, "train/reward_pos_loss": 4.062790899720024, "train/reward_pred": 0.00177209545911489, "train/reward_rate": 0.003250349813432836, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.01426590234041214, "report/cont_loss_std": 0.20615032315254211, "report/cont_neg_acc": 0.25, "report/cont_neg_loss": 2.8683271408081055, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0030735046602785587, "report/cont_pred": 0.9959970116615295, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.0756194069981575, "report/image_loss_std": 0.09249003231525421, "report/model_loss_mean": 0.7111145853996277, "report/model_loss_std": 0.5954535603523254, "report/post_ent_mag": 28.10953140258789, "report/post_ent_max": 28.10953140258789, "report/post_ent_mean": 27.583770751953125, "report/post_ent_min": 27.214977264404297, "report/post_ent_std": 0.19149230420589447, "report/prior_ent_mag": 27.928192138671875, "report/prior_ent_max": 27.928192138671875, "report/prior_ent_mean": 27.140214920043945, "report/prior_ent_min": 26.07046890258789, "report/prior_ent_std": 0.30151501297950745, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.001879882882349193, "report/reward_loss_mean": 0.02122925966978073, "report/reward_loss_std": 0.36021149158477783, "report/reward_max_data": 0.7250000238418579, "report/reward_max_pred": 0.5109059810638428, "report/reward_neg_acc": 0.9999999403953552, "report/reward_neg_loss": 0.0018260524375364184, "report/reward_pos_acc": 0.25, "report/reward_pos_loss": 4.969047546386719, "report/reward_pred": 0.0014974940568208694, "report/reward_rate": 0.00390625, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.040921326726675034, "eval/cont_loss_std": 0.6230766773223877, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 7.8453569412231445, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0026267440989613533, "eval/cont_pred": 0.9973628520965576, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.1229930967092514, "eval/image_loss_std": 0.13662058115005493, "eval/model_loss_mean": 0.7755170464515686, "eval/model_loss_std": 0.7430374026298523, "eval/post_ent_mag": 28.110767364501953, "eval/post_ent_max": 28.110767364501953, "eval/post_ent_mean": 27.54781723022461, "eval/post_ent_min": 27.139183044433594, "eval/post_ent_std": 0.194188192486763, "eval/prior_ent_mag": 27.915054321289062, "eval/prior_ent_max": 27.915054321289062, "eval/prior_ent_mean": 27.14627456665039, "eval/prior_ent_min": 26.098209381103516, "eval/prior_ent_std": 0.2957634925842285, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0011444091796875, "eval/reward_loss_mean": 0.011602604761719704, "eval/reward_loss_std": 0.23175960779190063, "eval/reward_max_data": 0.7281249761581421, "eval/reward_max_pred": 0.0675734281539917, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0013624090934172273, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.244342803955078, "eval/reward_pred": 0.0007477088365703821, "eval/reward_rate": 0.001953125, "replay/size": 834033.0, "replay/inserts": 32160.0, "replay/samples": 32160.0, "replay/insert_wait_avg": 1.3822717453116802e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.91749242051917e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4736.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1610320291003666e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.748603820800781e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3172783851624, "timer/env.step_count": 4020.0, "timer/env.step_total": 39.592092514038086, "timer/env.step_frac": 0.03957953478315661, "timer/env.step_avg": 0.009848779232347782, "timer/env.step_min": 0.007813215255737305, "timer/env.step_max": 0.036176204681396484, "timer/replay._sample_count": 32160.0, "timer/replay._sample_total": 17.18592381477356, "timer/replay._sample_frac": 0.017180472822100237, "timer/replay._sample_avg": 0.0005343881783200733, "timer/replay._sample_min": 0.00035762786865234375, "timer/replay._sample_max": 0.029994726181030273, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4612.0, "timer/agent.policy_total": 50.13108777999878, "timer/agent.policy_frac": 0.05011518731429559, "timer/agent.policy_avg": 0.010869706803989328, "timer/agent.policy_min": 0.009075164794921875, "timer/agent.policy_max": 0.095855712890625, "timer/dataset_train_count": 2010.0, "timer/dataset_train_total": 0.22657322883605957, "timer/dataset_train_frac": 0.00022650136484878328, "timer/dataset_train_avg": 0.00011272299942092516, "timer/dataset_train_min": 9.703636169433594e-05, "timer/dataset_train_max": 0.0003647804260253906, "timer/agent.train_count": 2010.0, "timer/agent.train_total": 898.5491979122162, "timer/agent.train_frac": 0.8982641980979945, "timer/agent.train_avg": 0.4470394019463762, "timer/agent.train_min": 0.43497514724731445, "timer/agent.train_max": 0.6985292434692383, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4746124744415283, "timer/agent.report_frac": 0.00047446193792404276, "timer/agent.report_avg": 0.23730623722076416, "timer/agent.report_min": 0.23064041137695312, "timer/agent.report_max": 0.2439720630645752, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.266334533691406e-05, "timer/dataset_eval_frac": 3.265298525048306e-08, "timer/dataset_eval_avg": 3.266334533691406e-05, "timer/dataset_eval_min": 3.266334533691406e-05, "timer/dataset_eval_max": 3.266334533691406e-05, "fps": 32.14923536274462}
{"step": 834544, "time": 26263.259199619293, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 834680, "time": 26267.585453033447, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 834800, "time": 26271.462886333466, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 834944, "time": 26275.863899469376, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 835032, "time": 26278.356034994125, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 835416, "time": 26290.30339741707, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 835656, "time": 26298.401629924774, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 835872, "time": 26305.284789562225, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 835968, "time": 26308.29402732849, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 836048, "time": 26310.784116268158, "episode/length": 21.0, "episode/score": 0.934374988079071, "episode/reward_rate": 0.045454545454545456, "episode/intrinsic_return": 0.0}
{"step": 836112, "time": 26312.773507118225, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 836344, "time": 26319.82741856575, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 836432, "time": 26322.81012892723, "episode/length": 235.0, "episode/score": 0.265625, "episode/reward_rate": 0.00423728813559322, "episode/intrinsic_return": 0.0}
{"step": 836432, "time": 26322.870407819748, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 836576, "time": 26327.333807229996, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 837016, "time": 26340.510624170303, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 837200, "time": 26346.37667989731, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 837256, "time": 26347.992763519287, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 837280, "time": 26348.95575451851, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 837344, "time": 26350.90472483635, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 837400, "time": 26352.4227643013, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 837912, "time": 26368.03575539589, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 837952, "time": 26369.474576234818, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 837976, "time": 26369.98507285118, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 838192, "time": 26376.90988111496, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 838232, "time": 26377.9127368927, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 838480, "time": 26385.703955173492, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 838496, "time": 26386.195159435272, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 838656, "time": 26391.099329710007, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 838744, "time": 26393.620557785034, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 839136, "time": 26405.921746730804, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 839184, "time": 26407.54597759247, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 839264, "time": 26409.971677541733, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 839400, "time": 26413.90061903, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 839568, "time": 26419.259800195694, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 839744, "time": 26424.63859152794, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 839816, "time": 26426.63674712181, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 839840, "time": 26427.59924173355, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 840008, "time": 26432.866073846817, "eval_episode/length": 18.0, "eval_episode/score": 0.9437500238418579, "eval_episode/reward_rate": 0.05263157894736842}
{"step": 840008, "time": 26434.278601169586, "eval_episode/length": 90.0, "eval_episode/score": 0.71875, "eval_episode/reward_rate": 0.01098901098901099}
{"step": 840008, "time": 26434.322996854782, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 840008, "time": 26434.765856981277, "eval_episode/length": 95.0, "eval_episode/score": 0.703125, "eval_episode/reward_rate": 0.010416666666666666}
{"step": 840008, "time": 26435.080982208252, "eval_episode/length": 129.0, "eval_episode/score": 0.596875011920929, "eval_episode/reward_rate": 0.007692307692307693}
{"step": 840008, "time": 26435.16949558258, "eval_episode/length": 133.0, "eval_episode/score": 0.5843750238418579, "eval_episode/reward_rate": 0.007462686567164179}
{"step": 840008, "time": 26436.09610247612, "eval_episode/length": 88.0, "eval_episode/score": 0.7250000238418579, "eval_episode/reward_rate": 0.011235955056179775}
{"step": 840008, "time": 26436.141265392303, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 840312, "time": 26445.543219804764, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 840424, "time": 26448.973441839218, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 840600, "time": 26454.364775657654, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 840792, "time": 26460.208377361298, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 840872, "time": 26462.647453784943, "episode/length": 216.0, "episode/score": 0.32499998807907104, "episode/reward_rate": 0.004608294930875576, "episode/intrinsic_return": 0.0}
{"step": 840912, "time": 26464.115913391113, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 840968, "time": 26465.601917505264, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 841032, "time": 26467.649364471436, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 841048, "time": 26468.146172761917, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 841056, "time": 26468.61811351776, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 841304, "time": 26475.967213869095, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 841912, "time": 26494.51895594597, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 842152, "time": 26501.965693712234, "episode/length": 229.0, "episode/score": 0.28437501192092896, "episode/reward_rate": 0.004347826086956522, "episode/intrinsic_return": 0.0}
{"step": 842536, "time": 26513.660094976425, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 842728, "time": 26519.501621484756, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 842920, "time": 26525.335012197495, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 843080, "time": 26530.351838827133, "episode/length": 255.0, "episode/score": 0.203125, "episode/reward_rate": 0.00390625, "episode/intrinsic_return": 0.0}
{"step": 843104, "time": 26531.30926322937, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 843184, "time": 26533.758138895035, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 843224, "time": 26534.755947351456, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 843368, "time": 26539.125779390335, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 843472, "time": 26542.525440454483, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 843560, "time": 26544.98397231102, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 843656, "time": 26547.943643331528, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 843896, "time": 26555.686355113983, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 843992, "time": 26558.79966211319, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 844192, "time": 26565.149654388428, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 844304, "time": 26568.60412287712, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 844408, "time": 26571.550239801407, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 844776, "time": 26582.831346273422, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 844848, "time": 26585.261543512344, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 845040, "time": 26591.311643362045, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 845080, "time": 26592.350829601288, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 845176, "time": 26595.329939842224, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 845264, "time": 26598.29572868347, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 845296, "time": 26599.278822422028, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 845440, "time": 26603.726460933685, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 845520, "time": 26606.201408147812, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 845720, "time": 26612.14711380005, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 845760, "time": 26613.598467111588, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 845856, "time": 26616.666112422943, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 845872, "time": 26617.20603275299, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 846048, "time": 26622.66666340828, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 846104, "time": 26624.152194023132, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 846360, "time": 26632.04254579544, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 846384, "time": 26633.015483140945, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 846512, "time": 26636.983467578888, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 846640, "time": 26640.91106390953, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 846656, "time": 26641.40805363655, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 846680, "time": 26641.944957256317, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 846744, "time": 26643.915987968445, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 846808, "time": 26645.88098716736, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 846896, "time": 26648.965088129044, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 847088, "time": 26654.908104658127, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 847272, "time": 26660.391304016113, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 847376, "time": 26663.829369306564, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 847416, "time": 26664.85326719284, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 847560, "time": 26669.35563468933, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 847616, "time": 26671.304827690125, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 847720, "time": 26674.319586277008, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 847736, "time": 26674.815148830414, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 847960, "time": 26681.928058862686, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 848032, "time": 26684.359476566315, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 848200, "time": 26689.333870887756, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 848224, "time": 26690.30684518814, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 848288, "time": 26692.292596578598, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 848512, "time": 26699.21170282364, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 848536, "time": 26699.730187654495, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 848800, "time": 26708.16103863716, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 848984, "time": 26713.614016532898, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 849168, "time": 26719.524786233902, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 849560, "time": 26731.47899746895, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 849632, "time": 26733.907024383545, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 850096, "time": 26749.794421434402, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 850096, "time": 26750.104480028152, "eval_episode/length": 81.0, "eval_episode/score": 0.746874988079071, "eval_episode/reward_rate": 0.012195121951219513}
{"step": 850096, "time": 26750.31405210495, "eval_episode/length": 91.0, "eval_episode/score": 0.715624988079071, "eval_episode/reward_rate": 0.010869565217391304}
{"step": 850096, "time": 26750.440277338028, "eval_episode/length": 97.0, "eval_episode/score": 0.6968749761581421, "eval_episode/reward_rate": 0.01020408163265306}
{"step": 850096, "time": 26750.547101020813, "eval_episode/length": 102.0, "eval_episode/score": 0.6812499761581421, "eval_episode/reward_rate": 0.009708737864077669}
{"step": 850096, "time": 26751.014670610428, "eval_episode/length": 125.0, "eval_episode/score": 0.609375, "eval_episode/reward_rate": 0.007936507936507936}
{"step": 850096, "time": 26751.52752685547, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 850096, "time": 26752.705800771713, "eval_episode/length": 118.0, "eval_episode/score": 0.6312500238418579, "eval_episode/reward_rate": 0.008403361344537815}
{"step": 850264, "time": 26757.633612394333, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 850272, "time": 26758.107040643692, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 850344, "time": 26760.08474779129, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 850392, "time": 26761.56908607483, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 850512, "time": 26765.47772526741, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 850536, "time": 26765.99487876892, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 850560, "time": 26767.052334070206, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 850592, "time": 26768.038400888443, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 850824, "time": 26774.8858230114, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 851128, "time": 26784.136091709137, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 851192, "time": 26786.089158535004, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 851240, "time": 26787.540947198868, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 851320, "time": 26789.965492248535, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 851408, "time": 26792.834173202515, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 851920, "time": 26808.570481300354, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 852088, "time": 26814.011120557785, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 852344, "time": 26821.807950019836, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 852704, "time": 26833.169863700867, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 852824, "time": 26836.609877586365, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 852832, "time": 26837.082474946976, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 853320, "time": 26851.73925757408, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 853552, "time": 26859.164794921875, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 853632, "time": 26861.597775697708, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 853696, "time": 26863.543702840805, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 853720, "time": 26864.080088853836, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 853896, "time": 26869.461353302002, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 853984, "time": 26872.379875421524, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 853992, "time": 26872.407089948654, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 854072, "time": 26874.87274813652, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 854400, "time": 26885.117632627487, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 854576, "time": 26890.581212997437, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 854608, "time": 26891.561621189117, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 854680, "time": 26893.55877351761, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 854816, "time": 26897.948656082153, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 854816, "time": 26897.95754313469, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 855096, "time": 26906.26825284958, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 855480, "time": 26918.05665588379, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 855752, "time": 26926.290479898453, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 855944, "time": 26932.115215063095, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 856032, "time": 26935.02748823166, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 856160, "time": 26938.938070058823, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 856296, "time": 26942.84357857704, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 856304, "time": 26943.312680482864, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 856328, "time": 26943.824706315994, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 856704, "time": 26955.555778265, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 856776, "time": 26957.532925367355, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 856920, "time": 26961.903935670853, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 856920, "time": 26961.91138792038, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 856992, "time": 26964.30691099167, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 857328, "time": 26974.54700946808, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 857408, "time": 26977.13211774826, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 857656, "time": 26984.443712949753, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 857744, "time": 26987.340750932693, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 857792, "time": 26988.782690048218, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 858152, "time": 26999.480054855347, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 858264, "time": 27002.912792682648, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 858608, "time": 27013.723436117172, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 858624, "time": 27014.21206831932, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 858872, "time": 27021.593081712723, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 858896, "time": 27022.54327225685, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 859032, "time": 27026.470340013504, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 859232, "time": 27032.780328035355, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 859304, "time": 27034.737193584442, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 859320, "time": 27035.246040582657, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 859376, "time": 27037.304829120636, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 859624, "time": 27044.604083538055, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 859632, "time": 27045.095467329025, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 860056, "time": 27057.750170230865, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 860080, "time": 27060.72922062874, "eval_episode/length": 102.0, "eval_episode/score": 0.6812499761581421, "eval_episode/reward_rate": 0.009708737864077669}
{"step": 860080, "time": 27060.79193019867, "eval_episode/length": 105.0, "eval_episode/score": 0.671875, "eval_episode/reward_rate": 0.009433962264150943}
{"step": 860080, "time": 27060.87446141243, "eval_episode/length": 109.0, "eval_episode/score": 0.659375011920929, "eval_episode/reward_rate": 0.00909090909090909}
{"step": 860080, "time": 27061.029064655304, "eval_episode/length": 117.0, "eval_episode/score": 0.6343749761581421, "eval_episode/reward_rate": 0.00847457627118644}
{"step": 860080, "time": 27061.035442352295, "eval_episode/length": 117.0, "eval_episode/score": 0.6343749761581421, "eval_episode/reward_rate": 0.00847457627118644}
{"step": 860080, "time": 27061.24128818512, "eval_episode/length": 127.0, "eval_episode/score": 0.6031249761581421, "eval_episode/reward_rate": 0.0078125}
{"step": 860080, "time": 27061.941236019135, "eval_episode/length": 56.0, "eval_episode/score": 0.824999988079071, "eval_episode/reward_rate": 0.017543859649122806}
{"step": 860080, "time": 27062.551624298096, "eval_episode/length": 90.0, "eval_episode/score": 0.71875, "eval_episode/reward_rate": 0.01098901098901099}
{"step": 860104, "time": 27063.07003045082, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 860192, "time": 27066.714991807938, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 860304, "time": 27070.12590789795, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 860424, "time": 27073.54307293892, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 860656, "time": 27080.821357250214, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 860712, "time": 27082.299352169037, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 860768, "time": 27084.26596045494, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 860984, "time": 27090.61660337448, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 861184, "time": 27097.047261238098, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 861408, "time": 27103.99181485176, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 861704, "time": 27112.832500219345, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 861760, "time": 27114.7753303051, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 861944, "time": 27120.207054376602, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 862064, "time": 27124.08922147751, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 862120, "time": 27125.57401919365, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 862304, "time": 27131.547233343124, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 862504, "time": 27137.47699689865, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 862552, "time": 27138.966806411743, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 862616, "time": 27140.91009092331, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 862800, "time": 27146.800204753876, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 862952, "time": 27151.218976020813, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 862968, "time": 27151.710084199905, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 863056, "time": 27154.61868906021, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 863296, "time": 27162.023876190186, "episode/length": 198.0, "episode/score": 0.3812499940395355, "episode/reward_rate": 0.005025125628140704, "episode/intrinsic_return": 0.0}
{"step": 863344, "time": 27163.49868440628, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 863472, "time": 27167.38811302185, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 864000, "time": 27183.41710972786, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 864040, "time": 27184.417083501816, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 864112, "time": 27186.970999240875, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 864360, "time": 27194.380521297455, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 864560, "time": 27200.77090859413, "episode/length": 187.0, "episode/score": 0.4156250059604645, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.0}
{"step": 864816, "time": 27208.630497455597, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 865264, "time": 27222.46990299225, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 865472, "time": 27228.826541423798, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 865504, "time": 27229.816764116287, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 865552, "time": 27231.31003665924, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 865632, "time": 27233.734860897064, "episode/length": 189.0, "episode/score": 0.40937501192092896, "episode/reward_rate": 0.005263157894736842, "episode/intrinsic_return": 0.0}
{"step": 865656, "time": 27234.252802848816, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 865728, "time": 27236.693929433823, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 866280, "time": 27253.33782172203, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 866312, "time": 27254.312901496887, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 866352, "time": 27255.77041363716, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 866352, "time": 27255.780287265778, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 866384, "time": 27256.756976127625, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 866440, "time": 27258.232828617096, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 866585, "time": 27263.649176120758, "train_stats/mean_log_entropy": 0.08283296769617923, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.554890441894531, "train/action_min": 0.0, "train/action_std": 1.749366867542267, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.010828223294811323, "train/actor_opt_grad_steps": 53065.0, "train/actor_opt_loss": -17.250742509365082, "train/adv_mag": 0.9593489378690719, "train/adv_max": 0.47350857615470887, "train/adv_mean": 0.000725863545997072, "train/adv_min": -0.8405504977703094, "train/adv_std": 0.029190743570216, "train/cont_avg": 0.994306640625, "train/cont_loss_mean": 0.020224249570164828, "train/cont_loss_std": 0.25178602323168886, "train/cont_neg_acc": 0.30527489811182024, "train/cont_neg_loss": 2.7591147120296955, "train/cont_pos_acc": 0.999837985932827, "train/cont_pos_loss": 0.004316236939048395, "train/cont_pred": 0.9942049726843833, "train/cont_rate": 0.994306640625, "train/dyn_loss_mean": 1.0000002241134645, "train/dyn_loss_std": 7.175798527896404e-06, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.11546642677858472, "train/extr_critic_critic_opt_grad_steps": 53065.0, "train/extr_critic_critic_opt_loss": 12780.088271484376, "train/extr_critic_mag": 1.5349469673633576, "train/extr_critic_max": 1.5349469673633576, "train/extr_critic_mean": 1.419677128791809, "train/extr_critic_min": 0.8140615892410278, "train/extr_critic_std": 0.028671746850013734, "train/extr_return_normed_mag": 0.9838470488786697, "train/extr_return_normed_max": 0.27862107336521147, "train/extr_return_normed_mean": 0.053187489584088324, "train/extr_return_normed_min": -0.916712681055069, "train/extr_return_normed_std": 0.041677556056529286, "train/extr_return_rate": 0.999486688375473, "train/extr_return_raw_mag": 1.6458365374803543, "train/extr_return_raw_max": 1.6458365374803543, "train/extr_return_raw_mean": 1.42040303170681, "train/extr_return_raw_min": 0.45050278306007385, "train/extr_return_raw_std": 0.041677555916830894, "train/extr_reward_mag": 0.25589812099933623, "train/extr_reward_max": 0.25589812099933623, "train/extr_reward_mean": 0.001987316487939097, "train/extr_reward_min": 2.592802047729492e-07, "train/extr_reward_std": 0.007944936285493896, "train/image_loss_mean": 0.0830009726062417, "train/image_loss_std": 0.09904960989952087, "train/model_loss_mean": 0.719827094078064, "train/model_loss_std": 0.48822294469922783, "train/model_opt_grad_norm": 19.032702391147613, "train/model_opt_grad_steps": 53017.45, "train/model_opt_loss": 3759.6942700195314, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5225.0, "train/policy_entropy_mag": 1.3875027006864549, "train/policy_entropy_max": 1.3875027006864549, "train/policy_entropy_mean": 0.10043730810284615, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.1305777707323432, "train/policy_logprob_mag": 6.551080255508423, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.10046596247702837, "train/policy_logprob_min": -6.551080255508423, "train/policy_logprob_std": 0.6394303813576698, "train/policy_randomness_mag": 0.7130353802442551, "train/policy_randomness_max": 0.7130353802442551, "train/policy_randomness_mean": 0.05161456884816289, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.0671037039719522, "train/post_ent_mag": 28.249783668518067, "train/post_ent_max": 28.249783668518067, "train/post_ent_mean": 27.73494059562683, "train/post_ent_min": 27.321134605407714, "train/post_ent_std": 0.19900825411081313, "train/prior_ent_mag": 27.87273811340332, "train/prior_ent_max": 27.87273811340332, "train/prior_ent_mean": 27.149131450653076, "train/prior_ent_min": 26.167912473678587, "train/prior_ent_std": 0.2723111969232559, "train/rep_loss_mean": 1.0000002241134645, "train/rep_loss_std": 7.175798527896404e-06, "train/reward_avg": 0.0022405242999957407, "train/reward_loss_mean": 0.01660171546158381, "train/reward_loss_std": 0.2371820742241107, "train/reward_max_data": 0.7681250013411045, "train/reward_max_pred": 0.2760948860645294, "train/reward_neg_acc": 0.9996865230798722, "train/reward_neg_loss": 0.0029623003053711725, "train/reward_pos_acc": 0.16614711357607054, "train/reward_pos_loss": 4.049537769605204, "train/reward_pred": 0.0018014766764827073, "train/reward_rate": 0.0033203125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.027572590857744217, "report/cont_loss_std": 0.3070843517780304, "report/cont_neg_acc": 0.1428571492433548, "report/cont_neg_loss": 3.379817485809326, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.004499126225709915, "report/cont_pred": 0.9944723844528198, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.08970403671264648, "report/image_loss_std": 0.10106257349252701, "report/model_loss_mean": 0.7330765724182129, "report/model_loss_std": 0.5211318731307983, "report/post_ent_mag": 28.481740951538086, "report/post_ent_max": 28.481740951538086, "report/post_ent_mean": 27.970067977905273, "report/post_ent_min": 27.503662109375, "report/post_ent_std": 0.2064572423696518, "report/prior_ent_mag": 27.909683227539062, "report/prior_ent_max": 27.909683227539062, "report/prior_ent_mean": 27.32305145263672, "report/prior_ent_min": 26.381946563720703, "report/prior_ent_std": 0.2338763177394867, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.002017212100327015, "report/reward_loss_mean": 0.015799900516867638, "report/reward_loss_std": 0.2385861873626709, "report/reward_max_data": 0.721875011920929, "report/reward_max_pred": 0.021666646003723145, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0028790717478841543, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.413188934326172, "report/reward_pred": 0.0015318876830860972, "report/reward_rate": 0.0029296875, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.02691691927611828, "eval/cont_loss_std": 0.3060775697231293, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 4.244027614593506, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.006224520970135927, "eval/cont_pred": 0.993808388710022, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.13716748356819153, "eval/image_loss_std": 0.1369895488023758, "eval/model_loss_mean": 0.7857043743133545, "eval/model_loss_std": 0.5919831991195679, "eval/post_ent_mag": 28.48143768310547, "eval/post_ent_max": 28.48143768310547, "eval/post_ent_mean": 27.967594146728516, "eval/post_ent_min": 27.515666961669922, "eval/post_ent_std": 0.208407923579216, "eval/prior_ent_mag": 27.912761688232422, "eval/prior_ent_max": 27.912761688232422, "eval/prior_ent_mean": 27.38625717163086, "eval/prior_ent_min": 26.431190490722656, "eval/prior_ent_std": 0.21877816319465637, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.002682494930922985, "eval/reward_loss_mean": 0.02161991037428379, "eval/reward_loss_std": 0.2907387316226959, "eval/reward_max_data": 0.8125, "eval/reward_max_pred": 0.056127071380615234, "eval/reward_neg_acc": 0.9999999403953552, "eval/reward_neg_loss": 0.003516977420076728, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 4.6378679275512695, "eval/reward_pred": 0.0018644366646185517, "eval/reward_rate": 0.00390625, "replay/size": 866081.0, "replay/inserts": 32048.0, "replay/samples": 32048.0, "replay/insert_wait_avg": 1.3872363599490597e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.885644997469616e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4696.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1720385218397722e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0728836059570312e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4088230133057, "timer/env.step_count": 4006.0, "timer/env.step_total": 39.86645221710205, "timer/env.step_frac": 0.03985016055438349, "timer/env.step_avg": 0.009951685525986532, "timer/env.step_min": 0.00802922248840332, "timer/env.step_max": 0.04025840759277344, "timer/replay._sample_count": 32048.0, "timer/replay._sample_total": 17.25799536705017, "timer/replay._sample_frac": 0.017250942784638592, "timer/replay._sample_avg": 0.0005385045983228336, "timer/replay._sample_min": 0.00042939186096191406, "timer/replay._sample_max": 0.01245570182800293, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4593.0, "timer/agent.policy_total": 49.7596001625061, "timer/agent.policy_frac": 0.04973926560606142, "timer/agent.policy_avg": 0.010833790586219487, "timer/agent.policy_min": 0.007860660552978516, "timer/agent.policy_max": 0.08739638328552246, "timer/dataset_train_count": 2003.0, "timer/dataset_train_total": 0.23208904266357422, "timer/dataset_train_frac": 0.000231994198096439, "timer/dataset_train_avg": 0.00011587071525889877, "timer/dataset_train_min": 9.822845458984375e-05, "timer/dataset_train_max": 0.0010838508605957031, "timer/agent.train_count": 2003.0, "timer/agent.train_total": 898.1285820007324, "timer/agent.train_frac": 0.8977615564160084, "timer/agent.train_avg": 0.4483917034451984, "timer/agent.train_min": 0.435835599899292, "timer/agent.train_max": 0.723944902420044, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47474217414855957, "timer/agent.report_frac": 0.00047454816793658503, "timer/agent.report_avg": 0.23737108707427979, "timer/agent.report_min": 0.22922730445861816, "timer/agent.report_max": 0.2455148696899414, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 4.2438507080078125e-05, "timer/dataset_eval_frac": 4.2421164331848046e-08, "timer/dataset_eval_avg": 4.2438507080078125e-05, "timer/dataset_eval_min": 4.2438507080078125e-05, "timer/dataset_eval_max": 4.2438507080078125e-05, "fps": 32.034362606859354}
{"step": 866696, "time": 27266.85208415985, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 866832, "time": 27271.24254322052, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 867120, "time": 27280.148415088654, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 867184, "time": 27282.136339187622, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 867248, "time": 27284.10299706459, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 867472, "time": 27290.994099378586, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 867640, "time": 27295.928222179413, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 867728, "time": 27298.8328397274, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 867888, "time": 27303.70498609543, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 867944, "time": 27305.19506406784, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 868192, "time": 27313.140043258667, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 868352, "time": 27318.19893169403, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 868432, "time": 27321.0338037014, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 868576, "time": 27325.39908695221, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 868608, "time": 27326.38636159897, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 868712, "time": 27329.317177295685, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 868936, "time": 27336.12634587288, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 868944, "time": 27336.70202279091, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 868944, "time": 27336.70995235443, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 869816, "time": 27363.04422044754, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 869936, "time": 27367.059479236603, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 869952, "time": 27367.55494070053, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 870040, "time": 27370.051404476166, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 870064, "time": 27371.888750076294, "eval_episode/length": 42.0, "eval_episode/score": 0.8687499761581421, "eval_episode/reward_rate": 0.023255813953488372}
{"step": 870064, "time": 27372.996399641037, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 870064, "time": 27373.366144895554, "eval_episode/length": 116.0, "eval_episode/score": 0.637499988079071, "eval_episode/reward_rate": 0.008547008547008548}
{"step": 870064, "time": 27373.61651325226, "eval_episode/length": 85.0, "eval_episode/score": 0.734375, "eval_episode/reward_rate": 0.011627906976744186}
{"step": 870064, "time": 27374.1676902771, "eval_episode/length": 154.0, "eval_episode/score": 0.518750011920929, "eval_episode/reward_rate": 0.0064516129032258064}
{"step": 870064, "time": 27374.3985786438, "eval_episode/length": 48.0, "eval_episode/score": 0.8500000238418579, "eval_episode/reward_rate": 0.02040816326530612}
{"step": 870064, "time": 27375.04066348076, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 870064, "time": 27375.99346256256, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 870104, "time": 27376.99115562439, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 870440, "time": 27387.314623594284, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 870472, "time": 27388.31156039238, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 870576, "time": 27391.75056362152, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 870664, "time": 27394.209789276123, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 870920, "time": 27402.216229200363, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 871024, "time": 27405.628677368164, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 871104, "time": 27408.056017160416, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0}
{"step": 871240, "time": 27411.981944322586, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 871456, "time": 27418.769893169403, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 871736, "time": 27427.16069126129, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 871904, "time": 27432.51459670067, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 872128, "time": 27439.377826929092, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 872176, "time": 27440.83789420128, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 872352, "time": 27446.189689159393, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 872568, "time": 27452.533505678177, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 872672, "time": 27455.922733545303, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 872808, "time": 27459.94837999344, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 872888, "time": 27462.39224767685, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 873184, "time": 27471.642525196075, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 873192, "time": 27471.66990828514, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 873336, "time": 27476.03127169609, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 873552, "time": 27482.823788881302, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 873824, "time": 27491.205942630768, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 873896, "time": 27493.20280098915, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 873960, "time": 27495.179010391235, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 874168, "time": 27501.520857572556, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 874224, "time": 27503.4673807621, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 874512, "time": 27512.338014125824, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 874664, "time": 27516.923944473267, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 874880, "time": 27523.791086912155, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 874984, "time": 27526.740894556046, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 875120, "time": 27531.119156360626, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 875272, "time": 27535.56554865837, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 875384, "time": 27538.998656749725, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 875608, "time": 27545.841567993164, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 875952, "time": 27556.669724225998, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 876136, "time": 27562.045560836792, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 876176, "time": 27563.4976375103, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 876272, "time": 27566.450393676758, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 876344, "time": 27568.426635742188, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 876440, "time": 27571.348930597305, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 876480, "time": 27572.78972029686, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 876480, "time": 27572.799557209015, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 877032, "time": 27590.02548098564, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 877072, "time": 27591.48379802704, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 877144, "time": 27593.453649044037, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 877296, "time": 27598.379747867584, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 877536, "time": 27605.713854312897, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 877552, "time": 27606.234629154205, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 877712, "time": 27611.245018720627, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 877816, "time": 27614.1908557415, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 877832, "time": 27614.68094277382, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 877848, "time": 27615.173398971558, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 878056, "time": 27621.57561135292, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 878144, "time": 27624.49160528183, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 878168, "time": 27625.00906920433, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 878264, "time": 27627.955897808075, "episode/length": 11.0, "episode/score": 0.965624988079071, "episode/reward_rate": 0.08333333333333333, "episode/intrinsic_return": 0.0}
{"step": 878448, "time": 27633.789652347565, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 878520, "time": 27635.80078792572, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 878568, "time": 27637.36363863945, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 878640, "time": 27639.782415628433, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 878688, "time": 27641.260544776917, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 878864, "time": 27646.62779355049, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 878904, "time": 27647.62603878975, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 878984, "time": 27650.052351236343, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 879192, "time": 27656.404437065125, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 879392, "time": 27662.69407582283, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 879992, "time": 27680.937859535217, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 880000, "time": 27681.40918111801, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 880016, "time": 27681.89861512184, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 880048, "time": 27684.726770877838, "eval_episode/length": 60.0, "eval_episode/score": 0.8125, "eval_episode/reward_rate": 0.01639344262295082}
{"step": 880048, "time": 27685.2422375679, "eval_episode/length": 85.0, "eval_episode/score": 0.734375, "eval_episode/reward_rate": 0.011627906976744186}
{"step": 880048, "time": 27686.177950382233, "eval_episode/length": 132.0, "eval_episode/score": 0.5874999761581421, "eval_episode/reward_rate": 0.007518796992481203}
{"step": 880048, "time": 27686.557109594345, "eval_episode/length": 152.0, "eval_episode/score": 0.5249999761581421, "eval_episode/reward_rate": 0.006535947712418301}
{"step": 880048, "time": 27687.59774208069, "eval_episode/length": 142.0, "eval_episode/score": 0.5562499761581421, "eval_episode/reward_rate": 0.006993006993006993}
{"step": 880048, "time": 27687.939943790436, "eval_episode/length": 133.0, "eval_episode/score": 0.5843750238418579, "eval_episode/reward_rate": 0.007462686567164179}
{"step": 880048, "time": 27688.289388656616, "eval_episode/length": 103.0, "eval_episode/score": 0.6781250238418579, "eval_episode/reward_rate": 0.009615384615384616}
{"step": 880048, "time": 27689.32624721527, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 880048, "time": 27689.334874391556, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 880048, "time": 27689.34418773651, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 880048, "time": 27689.3525993824, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 880384, "time": 27699.74175786972, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 880440, "time": 27701.24620127678, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 880576, "time": 27705.61242699623, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 880832, "time": 27713.414764881134, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 880880, "time": 27714.88168501854, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 881504, "time": 27734.057799100876, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 881704, "time": 27739.926003456116, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 882032, "time": 27750.13211941719, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 882328, "time": 27758.99966597557, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 882480, "time": 27763.838751077652, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 882640, "time": 27768.70701789856, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 882696, "time": 27770.21272444725, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 882752, "time": 27772.141986608505, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 882888, "time": 27776.057822704315, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 883144, "time": 27783.823924541473, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 883264, "time": 27787.78852891922, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 883464, "time": 27793.636581897736, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 883488, "time": 27794.61796283722, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 883552, "time": 27796.5912835598, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 883816, "time": 27804.442054986954, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 884016, "time": 27810.7852768898, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 884224, "time": 27817.274497032166, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 884352, "time": 27821.208520412445, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 884640, "time": 27830.017431735992, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 884712, "time": 27831.996040582657, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 884776, "time": 27834.482849359512, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 884816, "time": 27835.94604086876, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 884824, "time": 27835.973845243454, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 885008, "time": 27841.857568740845, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 885224, "time": 27848.385142803192, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 885384, "time": 27853.262814998627, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 885456, "time": 27855.698944330215, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 885480, "time": 27856.214666843414, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 885800, "time": 27866.046285629272, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 885936, "time": 27870.444814920425, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 886168, "time": 27877.421085357666, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 886440, "time": 27885.72295165062, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 886568, "time": 27889.62372994423, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 886576, "time": 27890.094499349594, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 886952, "time": 27901.39186668396, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 887008, "time": 27903.366761922836, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 887064, "time": 27904.861105918884, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 887088, "time": 27905.81907224655, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 887336, "time": 27913.26576924324, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 887440, "time": 27916.64706969261, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 887568, "time": 27920.557306051254, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 887568, "time": 27920.565875291824, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 887696, "time": 27924.506378173828, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 887864, "time": 27929.418845415115, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 887984, "time": 27933.29642391205, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 888008, "time": 27933.806544065475, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 888080, "time": 27936.223754405975, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 888096, "time": 27936.83195400238, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 888328, "time": 27943.70946264267, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 888480, "time": 27948.608365535736, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 888624, "time": 27953.021537542343, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 889008, "time": 27964.766850471497, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 889312, "time": 27974.144149780273, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 889680, "time": 27985.34983420372, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 889696, "time": 27985.845302820206, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 889880, "time": 27991.29328393936, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 889984, "time": 27994.69345140457, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 890008, "time": 27995.217064380646, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 890032, "time": 27997.44655108452, "eval_episode/length": 52.0, "eval_episode/score": 0.8374999761581421, "eval_episode/reward_rate": 0.018867924528301886}
{"step": 890032, "time": 27997.534351825714, "eval_episode/length": 56.0, "eval_episode/score": 0.824999988079071, "eval_episode/reward_rate": 0.017543859649122806}
{"step": 890032, "time": 27997.659033060074, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 890032, "time": 27998.579572439194, "eval_episode/length": 108.0, "eval_episode/score": 0.6625000238418579, "eval_episode/reward_rate": 0.009174311926605505}
{"step": 890032, "time": 27999.211762428284, "eval_episode/length": 140.0, "eval_episode/score": 0.5625, "eval_episode/reward_rate": 0.0070921985815602835}
{"step": 890032, "time": 27999.294738531113, "eval_episode/length": 91.0, "eval_episode/score": 0.715624988079071, "eval_episode/reward_rate": 0.010869565217391304}
{"step": 890032, "time": 27999.856073141098, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 890032, "time": 28000.057987689972, "eval_episode/length": 116.0, "eval_episode/score": 0.637499988079071, "eval_episode/reward_rate": 0.008547008547008548}
{"step": 890160, "time": 28003.98500394821, "episode/length": 228.0, "episode/score": 0.2874999940395355, "episode/reward_rate": 0.004366812227074236, "episode/intrinsic_return": 0.0}
{"step": 890168, "time": 28004.01491379738, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0}
{"step": 890176, "time": 28004.493398189545, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 890232, "time": 28006.020875692368, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 890288, "time": 28007.938344717026, "episode/length": 13.0, "episode/score": 0.9593750238418579, "episode/reward_rate": 0.07142857142857142, "episode/intrinsic_return": 0.0}
{"step": 890608, "time": 28017.711225032806, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 890680, "time": 28019.699954986572, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 890792, "time": 28023.109681606293, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 890880, "time": 28026.043734312057, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 890888, "time": 28026.073360204697, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 890968, "time": 28028.60125517845, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 891000, "time": 28029.598732948303, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 891064, "time": 28031.546597480774, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 891256, "time": 28037.39085006714, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 891624, "time": 28048.64103126526, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 891720, "time": 28051.59380173683, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 891800, "time": 28054.0477540493, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 891832, "time": 28055.03811264038, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 892336, "time": 28070.71150612831, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 892376, "time": 28071.713069200516, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 892424, "time": 28073.171815633774, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 892472, "time": 28074.65309858322, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 892728, "time": 28082.50520324707, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 892864, "time": 28086.996698141098, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 892920, "time": 28088.527653217316, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 893008, "time": 28091.90473842621, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 893280, "time": 28100.431092977524, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 893328, "time": 28101.892755508423, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 893336, "time": 28101.9206199646, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 893456, "time": 28105.822771310806, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 893672, "time": 28112.20397400856, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 893680, "time": 28112.676338672638, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 893768, "time": 28115.14076733589, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 893888, "time": 28119.149594545364, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 894080, "time": 28125.01097512245, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 894144, "time": 28126.959797620773, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 894144, "time": 28126.96798968315, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 894232, "time": 28129.443455696106, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 894432, "time": 28135.75827717781, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 894440, "time": 28135.786725997925, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 894632, "time": 28141.62102484703, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 894640, "time": 28142.0916659832, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 894760, "time": 28145.548362731934, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 895144, "time": 28157.380721330643, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 895192, "time": 28158.873102664948, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 895352, "time": 28163.761280298233, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 895448, "time": 28166.715277433395, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 895592, "time": 28171.15721130371, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 895856, "time": 28179.544016122818, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 896152, "time": 28188.33950138092, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 896336, "time": 28194.15128827095, "episode/length": 237.0, "episode/score": 0.2593750059604645, "episode/reward_rate": 0.004201680672268907, "episode/intrinsic_return": 0.0}
{"step": 896392, "time": 28195.650364637375, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 896632, "time": 28202.984436750412, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 896688, "time": 28204.907973766327, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 896752, "time": 28206.98054242134, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 896936, "time": 28212.351457357407, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 896968, "time": 28213.330413341522, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 897192, "time": 28220.177252054214, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 897352, "time": 28225.091618299484, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 897384, "time": 28226.072241544724, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 897456, "time": 28228.50910615921, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 897744, "time": 28237.443522930145, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 897904, "time": 28242.377146959305, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 898104, "time": 28248.272515058517, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 898216, "time": 28251.673894882202, "episode/length": 182.0, "episode/score": 0.4312500059604645, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.0}
{"step": 898528, "time": 28261.419417381287, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 898560, "time": 28262.394772291183, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 898585, "time": 28263.915185451508, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.610886535644531, "train/action_min": 0.0, "train/action_std": 1.7318961584568024, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.009487965516746045, "train/actor_opt_grad_steps": 55065.0, "train/actor_opt_loss": -17.044513521194457, "train/adv_mag": 0.9677465760707855, "train/adv_max": 0.4847049415111542, "train/adv_mean": 0.0009121728258878648, "train/adv_min": -0.8445409399271011, "train/adv_std": 0.025606843028217554, "train/cont_avg": 0.9944921875, "train/cont_loss_mean": 0.020010551450541245, "train/cont_loss_std": 0.2515743482578546, "train/cont_neg_acc": 0.2662945584207773, "train/cont_neg_loss": 2.8734680233895777, "train/cont_pos_acc": 0.9998871049284935, "train/cont_pos_loss": 0.004283099884632975, "train/cont_pred": 0.9943073999881744, "train/cont_rate": 0.9944921875, "train/dyn_loss_mean": 1.0000003135204316, "train/dyn_loss_std": 7.10891792550683e-06, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.0932722834404558, "train/extr_critic_critic_opt_grad_steps": 55065.0, "train/extr_critic_critic_opt_loss": 11859.769409179688, "train/extr_critic_mag": 1.5590509939193726, "train/extr_critic_max": 1.5590509939193726, "train/extr_critic_mean": 1.4495317929983138, "train/extr_critic_min": 0.8111236274242402, "train/extr_critic_std": 0.02777177550829947, "train/extr_return_normed_mag": 1.019880723953247, "train/extr_return_normed_max": 0.27619884550571444, "train/extr_return_normed_mean": 0.051124638682231306, "train/extr_return_normed_min": -0.956098981499672, "train/extr_return_normed_std": 0.03793357077986002, "train/extr_return_rate": 0.9996885141730308, "train/extr_return_raw_mag": 1.6755182445049286, "train/extr_return_raw_max": 1.6755182445049286, "train/extr_return_raw_mean": 1.4504441195726394, "train/extr_return_raw_min": 0.4432204174995422, "train/extr_return_raw_std": 0.037933570882305506, "train/extr_reward_mag": 0.2513716351985931, "train/extr_reward_max": 0.2513716351985931, "train/extr_reward_mean": 0.0020282499183667826, "train/extr_reward_min": 2.014636993408203e-07, "train/extr_reward_std": 0.007550411475822329, "train/image_loss_mean": 0.08352579953148961, "train/image_loss_std": 0.10009379899129271, "train/model_loss_mean": 0.7201050558686256, "train/model_loss_std": 0.49258370377123356, "train/model_opt_grad_norm": 18.38467604160309, "train/model_opt_grad_steps": 55015.53, "train/model_opt_loss": 3782.5777807617187, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5250.0, "train/policy_entropy_mag": 1.3864291310310364, "train/policy_entropy_max": 1.3864291310310364, "train/policy_entropy_mean": 0.09963000122457742, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.12922303047031164, "train/policy_logprob_mag": 6.5510802698135375, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.0993806903064251, "train/policy_logprob_min": -6.5510802698135375, "train/policy_logprob_std": 0.6370558959245681, "train/policy_randomness_mag": 0.7124836754798889, "train/policy_randomness_max": 0.7124836754798889, "train/policy_randomness_mean": 0.05119969552382827, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.06640750512480736, "train/post_ent_mag": 28.1245024394989, "train/post_ent_max": 28.1245024394989, "train/post_ent_mean": 27.614643106460573, "train/post_ent_min": 27.194358263015747, "train/post_ent_std": 0.20253362774848938, "train/prior_ent_mag": 27.924520435333253, "train/prior_ent_max": 27.924520435333253, "train/prior_ent_mean": 27.35326566696167, "train/prior_ent_min": 26.361768741607666, "train/prior_ent_std": 0.2684438359737396, "train/rep_loss_mean": 1.0000003135204316, "train/rep_loss_std": 7.10891792550683e-06, "train/reward_avg": 0.002249526968880673, "train/reward_loss_mean": 0.016568491514772177, "train/reward_loss_std": 0.24107941819820553, "train/reward_max_data": 0.773328127041459, "train/reward_max_pred": 0.2785940045118332, "train/reward_neg_acc": 0.9996275526285171, "train/reward_neg_loss": 0.0030128249907284046, "train/reward_pos_acc": 0.1616993006413358, "train/reward_pos_loss": 4.131172972887301, "train/reward_pred": 0.001835395061643794, "train/reward_rate": 0.0033056640625, "train_stats/mean_log_entropy": 0.08162965595589153, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.016658397391438484, "report/cont_loss_std": 0.2386539876461029, "report/cont_neg_acc": 0.5, "report/cont_neg_loss": 2.103464126586914, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.004358954261988401, "report/cont_pred": 0.9928464889526367, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.07837063074111938, "report/image_loss_std": 0.10167891532182693, "report/model_loss_mean": 0.7072755098342896, "report/model_loss_std": 0.41781118512153625, "report/post_ent_mag": 28.314334869384766, "report/post_ent_max": 28.314334869384766, "report/post_ent_mean": 27.7482967376709, "report/post_ent_min": 27.327863693237305, "report/post_ent_std": 0.21801221370697021, "report/prior_ent_mag": 27.419971466064453, "report/prior_ent_max": 27.419971466064453, "report/prior_ent_mean": 26.959335327148438, "report/prior_ent_min": 26.26903533935547, "report/prior_ent_std": 0.20747005939483643, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0020629882346838713, "report/reward_loss_mean": 0.012246501632034779, "report/reward_loss_std": 0.19889548420906067, "report/reward_max_data": 0.815625011920929, "report/reward_max_pred": 0.52219557762146, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0025873291306197643, "report/reward_pos_acc": 0.3333333432674408, "report/reward_pos_loss": 3.2995851039886475, "report/reward_pred": 0.0018559943418949842, "report/reward_rate": 0.0029296875, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.03592173382639885, "eval/cont_loss_std": 0.47250494360923767, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.269686698913574, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.00507440185174346, "eval/cont_pred": 0.9949637651443481, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.11948205530643463, "eval/image_loss_std": 0.12433937937021255, "eval/model_loss_mean": 0.7826120853424072, "eval/model_loss_std": 0.7753311395645142, "eval/post_ent_mag": 28.31230354309082, "eval/post_ent_max": 28.31230354309082, "eval/post_ent_mean": 27.792150497436523, "eval/post_ent_min": 27.349510192871094, "eval/post_ent_std": 0.217340350151062, "eval/prior_ent_mag": 27.4959716796875, "eval/prior_ent_max": 27.4959716796875, "eval/prior_ent_mean": 27.004074096679688, "eval/prior_ent_min": 26.263378143310547, "eval/prior_ent_std": 0.19913561642169952, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.003222656436264515, "eval/reward_loss_mean": 0.027208250015974045, "eval/reward_loss_std": 0.3550887107849121, "eval/reward_max_data": 0.7875000238418579, "eval/reward_max_pred": 0.02447688579559326, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0025211144238710403, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.058446407318115, "eval/reward_pred": 0.0013454071013256907, "eval/reward_rate": 0.0048828125, "replay/size": 898081.0, "replay/inserts": 32000.0, "replay/samples": 32000.0, "replay/insert_wait_avg": 1.3746768236160278e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.928701281547546e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5672.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2490073447503223e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.5367431640625e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.250848531723, "timer/env.step_count": 4000.0, "timer/env.step_total": 39.62729454040527, "timer/env.step_frac": 0.03961735658467526, "timer/env.step_avg": 0.009906823635101319, "timer/env.step_min": 0.00784444808959961, "timer/env.step_max": 0.04484200477600098, "timer/replay._sample_count": 32000.0, "timer/replay._sample_total": 17.31934881210327, "timer/replay._sample_frac": 0.017315005368429826, "timer/replay._sample_avg": 0.0005412296503782272, "timer/replay._sample_min": 0.00037479400634765625, "timer/replay._sample_max": 0.018341064453125, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4709.0, "timer/agent.policy_total": 51.34274768829346, "timer/agent.policy_frac": 0.051329871665352675, "timer/agent.policy_avg": 0.010903110573007743, "timer/agent.policy_min": 0.00914621353149414, "timer/agent.policy_max": 0.09536433219909668, "timer/dataset_train_count": 2000.0, "timer/dataset_train_total": 0.24982094764709473, "timer/dataset_train_frac": 0.0002497582961452211, "timer/dataset_train_avg": 0.00012491047382354737, "timer/dataset_train_min": 9.799003601074219e-05, "timer/dataset_train_max": 0.02452564239501953, "timer/agent.train_count": 2000.0, "timer/agent.train_total": 895.7303614616394, "timer/agent.train_frac": 0.8955057251653321, "timer/agent.train_avg": 0.4478651807308197, "timer/agent.train_min": 0.43428683280944824, "timer/agent.train_max": 0.6904928684234619, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4775252342224121, "timer/agent.report_frac": 0.00047740547775927965, "timer/agent.report_avg": 0.23876261711120605, "timer/agent.report_min": 0.2299795150756836, "timer/agent.report_max": 0.24754571914672852, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0994415283203125e-05, "timer/dataset_eval_frac": 3.098664232947175e-08, "timer/dataset_eval_avg": 3.0994415283203125e-05, "timer/dataset_eval_min": 3.0994415283203125e-05, "timer/dataset_eval_max": 3.0994415283203125e-05, "fps": 31.99141782963771}
{"step": 898760, "time": 28269.21177482605, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 898768, "time": 28269.69323348999, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 898800, "time": 28270.672925949097, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 899000, "time": 28276.640060186386, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 899208, "time": 28283.021825313568, "episode/length": 182.0, "episode/score": 0.4312500059604645, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.0}
{"step": 899248, "time": 28284.47206044197, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 899400, "time": 28288.900376319885, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 899608, "time": 28295.246762037277, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 899640, "time": 28296.259206533432, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 899656, "time": 28296.881143331528, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 899744, "time": 28299.794677972794, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 900016, "time": 28308.85765337944, "eval_episode/length": 33.0, "eval_episode/score": 0.8968750238418579, "eval_episode/reward_rate": 0.029411764705882353}
{"step": 900016, "time": 28309.177441835403, "eval_episode/length": 48.0, "eval_episode/score": 0.8500000238418579, "eval_episode/reward_rate": 0.02040816326530612}
{"step": 900016, "time": 28309.493708610535, "eval_episode/length": 63.0, "eval_episode/score": 0.8031250238418579, "eval_episode/reward_rate": 0.015625}
{"step": 900016, "time": 28309.578356981277, "eval_episode/length": 67.0, "eval_episode/score": 0.7906249761581421, "eval_episode/reward_rate": 0.014705882352941176}
{"step": 900016, "time": 28310.019592046738, "eval_episode/length": 89.0, "eval_episode/score": 0.721875011920929, "eval_episode/reward_rate": 0.011111111111111112}
{"step": 900016, "time": 28310.16653394699, "eval_episode/length": 96.0, "eval_episode/score": 0.699999988079071, "eval_episode/reward_rate": 0.010309278350515464}
{"step": 900016, "time": 28310.811514377594, "eval_episode/length": 129.0, "eval_episode/score": 0.596875011920929, "eval_episode/reward_rate": 0.007692307692307693}
{"step": 900016, "time": 28311.070692062378, "eval_episode/length": 108.0, "eval_episode/score": 0.6625000238418579, "eval_episode/reward_rate": 0.009174311926605505}
{"step": 900056, "time": 28312.073216438293, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 900064, "time": 28312.544891119003, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 900328, "time": 28320.379696130753, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 900336, "time": 28320.85138940811, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 900680, "time": 28331.258444309235, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 900752, "time": 28333.708958864212, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 900840, "time": 28336.16700387001, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 901080, "time": 28343.516387939453, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 901112, "time": 28344.49396443367, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 901432, "time": 28354.76696538925, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 901544, "time": 28358.29520392418, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 901584, "time": 28359.756148338318, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 901656, "time": 28361.719237327576, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 901664, "time": 28362.189638614655, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 901712, "time": 28363.671736955643, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 902272, "time": 28380.78343629837, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 902496, "time": 28387.763553380966, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 902552, "time": 28389.267897367477, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 902592, "time": 28390.715951919556, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 902608, "time": 28391.20876479149, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 902640, "time": 28392.188681840897, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 902920, "time": 28400.56275677681, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 903144, "time": 28407.401515245438, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 903152, "time": 28407.898748874664, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 903368, "time": 28414.281143903732, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 903376, "time": 28414.750378370285, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 903464, "time": 28417.348269701004, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 903968, "time": 28432.95670723915, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 904008, "time": 28433.948120117188, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 904024, "time": 28434.438329219818, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 904144, "time": 28438.32664680481, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 904264, "time": 28441.746262311935, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 904488, "time": 28448.749692201614, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 904800, "time": 28458.493178844452, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 904824, "time": 28459.010234832764, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 904944, "time": 28462.899653196335, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 904952, "time": 28462.929239988327, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 905192, "time": 28470.221432685852, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 905456, "time": 28478.602483272552, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 905464, "time": 28478.632553577423, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 905488, "time": 28479.590790987015, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 905744, "time": 28487.39072537422, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 906064, "time": 28497.152596473694, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 906120, "time": 28498.6583776474, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 906168, "time": 28500.133231163025, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 906288, "time": 28504.0231859684, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 906320, "time": 28505.00834298134, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 906680, "time": 28515.855841875076, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 906776, "time": 28518.793003082275, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 906928, "time": 28523.695601463318, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 907008, "time": 28526.17310833931, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 907112, "time": 28529.151163578033, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 907136, "time": 28530.124665737152, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 907264, "time": 28534.05701804161, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 907464, "time": 28540.148859500885, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 907888, "time": 28553.37545800209, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 907904, "time": 28553.865931749344, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 907920, "time": 28554.36571955681, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 907920, "time": 28554.372635364532, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 908000, "time": 28556.841908454895, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 908144, "time": 28561.240393400192, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 908624, "time": 28576.044746875763, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 908688, "time": 28578.013805150986, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 908776, "time": 28580.491175174713, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 908800, "time": 28581.446890354156, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 908992, "time": 28587.359099388123, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 909088, "time": 28590.309839725494, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 909552, "time": 28605.386790275574, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 909776, "time": 28612.2431910038, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 910000, "time": 28621.07796740532, "eval_episode/length": 100.0, "eval_episode/score": 0.6875, "eval_episode/reward_rate": 0.009900990099009901}
{"step": 910000, "time": 28621.87364244461, "eval_episode/length": 140.0, "eval_episode/score": 0.5625, "eval_episode/reward_rate": 0.0070921985815602835}
{"step": 910000, "time": 28622.120570898056, "eval_episode/length": 152.0, "eval_episode/score": 0.5249999761581421, "eval_episode/reward_rate": 0.006535947712418301}
{"step": 910000, "time": 28622.908314466476, "eval_episode/length": 189.0, "eval_episode/score": 0.40937501192092896, "eval_episode/reward_rate": 0.005263157894736842}
{"step": 910000, "time": 28624.06622695923, "eval_episode/length": 104.0, "eval_episode/score": 0.675000011920929, "eval_episode/reward_rate": 0.009523809523809525}
{"step": 910000, "time": 28624.72314977646, "eval_episode/length": 88.0, "eval_episode/score": 0.7250000238418579, "eval_episode/reward_rate": 0.011235955056179775}
{"step": 910000, "time": 28624.93235731125, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 910000, "time": 28624.94065308571, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 910000, "time": 28624.950192928314, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 910000, "time": 28624.959630012512, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 910160, "time": 28629.940385580063, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 910200, "time": 28630.967412233353, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 910232, "time": 28631.957574129105, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 910312, "time": 28634.41101169586, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 910328, "time": 28634.8983771801, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 910608, "time": 28643.646629810333, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 910680, "time": 28645.644633054733, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 910952, "time": 28653.909825325012, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 911088, "time": 28658.410440683365, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 911112, "time": 28658.92619419098, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 911128, "time": 28659.4128844738, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 911392, "time": 28667.647566080093, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 911400, "time": 28667.676986455917, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 911432, "time": 28668.652985334396, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 911800, "time": 28679.84969305992, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 911832, "time": 28680.825016260147, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 911872, "time": 28682.267099380493, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 911896, "time": 28682.780635118484, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 911912, "time": 28683.272204637527, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 912168, "time": 28691.22893857956, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 912640, "time": 28705.84154677391, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 912672, "time": 28706.82334804535, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 912832, "time": 28711.69956946373, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 913008, "time": 28717.129616498947, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 913352, "time": 28727.40490937233, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 913424, "time": 28729.831817150116, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 913440, "time": 28730.32656645775, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 913480, "time": 28731.32183289528, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 913512, "time": 28732.295128583908, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 913584, "time": 28734.73000049591, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 913784, "time": 28740.60506272316, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 913936, "time": 28745.446665763855, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 914208, "time": 28753.81919193268, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 914224, "time": 28754.3078892231, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 914432, "time": 28760.641406297684, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 914632, "time": 28766.528358459473, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 914672, "time": 28767.9935464859, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 914952, "time": 28776.284640550613, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 915136, "time": 28782.19885659218, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 915216, "time": 28784.637570619583, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 915320, "time": 28787.576627731323, "episode/length": 12.0, "episode/score": 0.9624999761581421, "episode/reward_rate": 0.07692307692307693, "episode/intrinsic_return": 0.0}
{"step": 915392, "time": 28789.982689857483, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 915504, "time": 28793.400198459625, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 915736, "time": 28800.265774011612, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 915760, "time": 28801.22755074501, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 915776, "time": 28801.71834754944, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 915896, "time": 28805.13712787628, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 916104, "time": 28811.594985961914, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 916112, "time": 28812.088871479034, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 916200, "time": 28814.551820993423, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 916528, "time": 28824.80419445038, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 916536, "time": 28824.838533878326, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 916664, "time": 28828.75260949135, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 916744, "time": 28831.178631544113, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 917032, "time": 28840.08635377884, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 917264, "time": 28847.418709516525, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 917296, "time": 28848.403655052185, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 917440, "time": 28852.799816846848, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 917744, "time": 28862.61708664894, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 917824, "time": 28865.057955026627, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 918088, "time": 28872.99166536331, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 918488, "time": 28885.222507476807, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 918560, "time": 28887.71171760559, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 918768, "time": 28894.086893081665, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 918976, "time": 28900.57180762291, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 919056, "time": 28903.067410469055, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 919096, "time": 28904.081372261047, "episode/length": 228.0, "episode/score": 0.2874999940395355, "episode/reward_rate": 0.004366812227074236, "episode/intrinsic_return": 0.0}
{"step": 919160, "time": 28906.065670728683, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 919576, "time": 28918.687002658844, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 919752, "time": 28924.05053806305, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 919920, "time": 28929.505251169205, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 920088, "time": 28935.064949035645, "eval_episode/length": 31.0, "eval_episode/score": 0.903124988079071, "eval_episode/reward_rate": 0.03125}
{"step": 920088, "time": 28935.52424120903, "eval_episode/length": 53.0, "eval_episode/score": 0.8343750238418579, "eval_episode/reward_rate": 0.018518518518518517}
{"step": 920088, "time": 28936.28849673271, "eval_episode/length": 90.0, "eval_episode/score": 0.71875, "eval_episode/reward_rate": 0.01098901098901099}
{"step": 920088, "time": 28937.09884905815, "eval_episode/length": 131.0, "eval_episode/score": 0.590624988079071, "eval_episode/reward_rate": 0.007575757575757576}
{"step": 920088, "time": 28937.566277980804, "eval_episode/length": 123.0, "eval_episode/score": 0.6156250238418579, "eval_episode/reward_rate": 0.008064516129032258}
{"step": 920088, "time": 28939.676444530487, "eval_episode/length": 175.0, "eval_episode/score": 0.453125, "eval_episode/reward_rate": 0.005681818181818182}
{"step": 920088, "time": 28939.836971521378, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 920088, "time": 28940.838516950607, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 920088, "time": 28940.845442295074, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 920088, "time": 28940.8534655571, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 920088, "time": 28940.860503911972, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 920088, "time": 28940.87015104294, "eval_episode/length": 156.0, "eval_episode/score": 0.512499988079071, "eval_episode/reward_rate": 0.006369426751592357}
{"step": 920136, "time": 28942.349363803864, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 920872, "time": 28964.85171532631, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 921080, "time": 28971.214616298676, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 921152, "time": 28973.625834703445, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 921336, "time": 28979.045328617096, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 921368, "time": 28980.028314590454, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 921408, "time": 28981.490264177322, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 921480, "time": 28983.44698214531, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 921888, "time": 28996.261819839478, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 922016, "time": 29000.169315576553, "episode/length": 261.0, "episode/score": 0.18437500298023224, "episode/reward_rate": 0.003816793893129771, "episode/intrinsic_return": 0.0}
{"step": 922064, "time": 29001.647421836853, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 922072, "time": 29001.67483329773, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 922496, "time": 29014.83390569687, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 922504, "time": 29014.86389017105, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 922704, "time": 29021.291892290115, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 922976, "time": 29029.554978132248, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 923352, "time": 29040.787024974823, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 923408, "time": 29042.70259666443, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 923464, "time": 29044.18481683731, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 923680, "time": 29051.09569787979, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 924200, "time": 29066.682792901993, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 924216, "time": 29067.176097154617, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 924328, "time": 29070.60195326805, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 924416, "time": 29073.5085003376, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 924640, "time": 29080.42664194107, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 924648, "time": 29080.455362319946, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 924704, "time": 29082.385719537735, "episode/length": 274.0, "episode/score": 0.14374999701976776, "episode/reward_rate": 0.0036363636363636364, "episode/intrinsic_return": 0.0}
{"step": 924912, "time": 29088.77268767357, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 925016, "time": 29091.713891983032, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 925080, "time": 29093.676963806152, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 925184, "time": 29097.086453437805, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 925288, "time": 29100.070821523666, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 925664, "time": 29111.831332206726, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 925880, "time": 29118.67356324196, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 925920, "time": 29120.119077444077, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 926152, "time": 29126.956535339355, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 926200, "time": 29128.437751054764, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 926264, "time": 29130.38708949089, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 926328, "time": 29132.332023859024, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 926368, "time": 29133.78626394272, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 927016, "time": 29153.448089122772, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 927192, "time": 29158.82586622238, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 927328, "time": 29163.221972227097, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 927344, "time": 29163.72300505638, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 927392, "time": 29165.208118915558, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 927624, "time": 29172.193352222443, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 927776, "time": 29177.022807836533, "episode/length": 196.0, "episode/score": 0.38749998807907104, "episode/reward_rate": 0.005076142131979695, "episode/intrinsic_return": 0.0}
{"step": 928232, "time": 29190.65790963173, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 928256, "time": 29191.6103618145, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 928280, "time": 29192.137902259827, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 928456, "time": 29197.565769195557, "episode/length": 21.0, "episode/score": 0.934374988079071, "episode/reward_rate": 0.045454545454545456, "episode/intrinsic_return": 0.0}
{"step": 928640, "time": 29203.391516923904, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 928664, "time": 29203.903507709503, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 929240, "time": 29221.489770174026, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 929328, "time": 29224.393178462982, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 929472, "time": 29228.898332118988, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 929512, "time": 29229.897433280945, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 929528, "time": 29230.388837337494, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 929616, "time": 29233.294713258743, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 929640, "time": 29233.809049844742, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 929936, "time": 29243.062109470367, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 930024, "time": 29245.504332304, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 930072, "time": 29248.560837984085, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 930072, "time": 29248.79094004631, "eval_episode/length": 88.0, "eval_episode/score": 0.7250000238418579, "eval_episode/reward_rate": 0.011235955056179775}
{"step": 930072, "time": 29249.781001091003, "eval_episode/length": 139.0, "eval_episode/score": 0.565625011920929, "eval_episode/reward_rate": 0.007142857142857143}
{"step": 930072, "time": 29250.116433143616, "eval_episode/length": 156.0, "eval_episode/score": 0.512499988079071, "eval_episode/reward_rate": 0.006369426751592357}
{"step": 930072, "time": 29252.199706077576, "eval_episode/length": 102.0, "eval_episode/score": 0.6812499761581421, "eval_episode/reward_rate": 0.009708737864077669}
{"step": 930072, "time": 29252.757358551025, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 930072, "time": 29252.764438152313, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 930072, "time": 29252.772980451584, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 930072, "time": 29252.78119444847, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 930136, "time": 29254.73104429245, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 930409, "time": 29264.180228471756, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.658400032388505, "train/action_min": 0.0, "train/action_std": 1.6994312246840204, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.010062219364446911, "train/actor_opt_grad_steps": 57060.0, "train/actor_opt_loss": -17.85239292269376, "train/adv_mag": 0.8718699624190978, "train/adv_max": 0.44417257824135786, "train/adv_mean": 0.0007615808203969099, "train/adv_min": -0.7543296208932772, "train/adv_std": 0.026079514059214735, "train/cont_avg": 0.9942927528266332, "train/cont_loss_mean": 0.02151217952782485, "train/cont_loss_std": 0.2633188554932873, "train/cont_neg_acc": 0.23843079651869722, "train/cont_neg_loss": 2.9924735420163553, "train/cont_pos_acc": 0.9998765818437739, "train/cont_pos_loss": 0.004438305215736916, "train/cont_pred": 0.9942674025818331, "train/cont_rate": 0.9942927528266332, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.09467306825327663, "train/extr_critic_critic_opt_grad_steps": 57060.0, "train/extr_critic_critic_opt_loss": 10702.1665088136, "train/extr_critic_mag": 1.5851841344306217, "train/extr_critic_max": 1.5851841344306217, "train/extr_critic_mean": 1.4729883754672717, "train/extr_critic_min": 0.9022582224266014, "train/extr_critic_std": 0.028355046301780634, "train/extr_return_normed_mag": 0.9166016045527242, "train/extr_return_normed_max": 0.2875142319118557, "train/extr_return_normed_mean": 0.052500341031419574, "train/extr_return_normed_min": -0.8200142737010017, "train/extr_return_normed_std": 0.03888404406794352, "train/extr_return_rate": 0.9996542268661998, "train/extr_return_raw_mag": 1.7087637593398741, "train/extr_return_raw_max": 1.7087637593398741, "train/extr_return_raw_mean": 1.4737499515015875, "train/extr_return_raw_min": 0.6012352537270167, "train/extr_return_raw_std": 0.03888404412410367, "train/extr_reward_mag": 0.2626798140942751, "train/extr_reward_max": 0.2626798140942751, "train/extr_reward_mean": 0.0021942648738295066, "train/extr_reward_min": 1.7791537184212075e-07, "train/extr_reward_std": 0.007851878102709675, "train/image_loss_mean": 0.08666205278892614, "train/image_loss_std": 0.102175798959768, "train/model_loss_mean": 0.7257690193066045, "train/model_loss_std": 0.5065005679600801, "train/model_opt_grad_norm": 18.714242652433004, "train/model_opt_grad_steps": 57008.582914572864, "train/model_opt_loss": 3666.445036461605, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5050.251256281407, "train/policy_entropy_mag": 1.3562186111756904, "train/policy_entropy_max": 1.3562186111756904, "train/policy_entropy_mean": 0.09958786551077761, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.12764396286340216, "train/policy_logprob_mag": 6.551080274821526, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09949318825000494, "train/policy_logprob_min": -6.551080274821526, "train/policy_logprob_std": 0.6372586761287709, "train/policy_randomness_mag": 0.6969585382758673, "train/policy_randomness_max": 0.6969585382758673, "train/policy_randomness_mean": 0.05117804096571764, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.06559602465087445, "train/post_ent_mag": 28.18899816005074, "train/post_ent_max": 28.18899816005074, "train/post_ent_mean": 27.6934964644849, "train/post_ent_min": 27.27353518692093, "train/post_ent_std": 0.1987026176560464, "train/prior_ent_mag": 27.482918724941847, "train/prior_ent_max": 27.482918724941847, "train/prior_ent_mean": 26.983853680404586, "train/prior_ent_min": 26.209605145094983, "train/prior_ent_std": 0.2040391022985305, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0024086343625855243, "train/reward_loss_mean": 0.017594766254354285, "train/reward_loss_std": 0.2455663057184549, "train/reward_max_data": 0.7813128143099685, "train/reward_max_pred": 0.2447045801871985, "train/reward_neg_acc": 0.9996798083410791, "train/reward_neg_loss": 0.0031634487320514556, "train/reward_pos_acc": 0.13170716957640402, "train/reward_pos_loss": 4.128862070054123, "train/reward_pred": 0.0018885748252628286, "train/reward_rate": 0.003494032663316583, "train_stats/mean_log_entropy": 0.08405729814946095, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.990234375, "report/cont_loss_mean": 0.021437546238303185, "report/cont_loss_std": 0.2376820147037506, "report/cont_neg_acc": 0.5, "report/cont_neg_loss": 1.6972063779830933, "report/cont_pos_acc": 0.9990138411521912, "report/cont_pos_loss": 0.004911227151751518, "report/cont_pred": 0.9904794692993164, "report/cont_rate": 0.990234375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.08661085367202759, "report/image_loss_std": 0.0969843789935112, "report/model_loss_mean": 0.7318763732910156, "report/model_loss_std": 0.5732088088989258, "report/post_ent_mag": 28.292102813720703, "report/post_ent_max": 28.292102813720703, "report/post_ent_mean": 27.79772186279297, "report/post_ent_min": 27.41985321044922, "report/post_ent_std": 0.2092333734035492, "report/prior_ent_mag": 27.462501525878906, "report/prior_ent_max": 27.462501525878906, "report/prior_ent_mean": 26.973957061767578, "report/prior_ent_min": 25.921234130859375, "report/prior_ent_std": 0.2098449319601059, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.003344726748764515, "report/reward_loss_mean": 0.023827914148569107, "report/reward_loss_std": 0.2991263270378113, "report/reward_max_data": 0.840624988079071, "report/reward_max_pred": 0.038132429122924805, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0029238136485219, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.284083843231201, "report/reward_pred": 0.0015683179954066873, "report/reward_rate": 0.0048828125, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.03672735393047333, "eval/cont_loss_std": 0.4765697121620178, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.504390716552734, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.004501442424952984, "eval/cont_pred": 0.9955074191093445, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.15326181054115295, "eval/image_loss_std": 0.13270126283168793, "eval/model_loss_mean": 0.8102108240127563, "eval/model_loss_std": 0.6868842840194702, "eval/post_ent_mag": 28.28935432434082, "eval/post_ent_max": 28.28935432434082, "eval/post_ent_mean": 27.800827026367188, "eval/post_ent_min": 27.40985107421875, "eval/post_ent_std": 0.1985441893339157, "eval/prior_ent_mag": 27.46903419494629, "eval/prior_ent_max": 27.46903419494629, "eval/prior_ent_mean": 26.971858978271484, "eval/prior_ent_min": 26.21493148803711, "eval/prior_ent_std": 0.2169959992170334, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0030029297340661287, "eval/reward_loss_mean": 0.02022167667746544, "eval/reward_loss_std": 0.2828666567802429, "eval/reward_max_data": 0.887499988079071, "eval/reward_max_pred": 0.042630910873413086, "eval/reward_neg_acc": 0.9999999403953552, "eval/reward_neg_loss": 0.002708852058276534, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 4.485992431640625, "eval/reward_pred": 0.0014473742339760065, "eval/reward_rate": 0.00390625, "replay/size": 929905.0, "replay/inserts": 31824.0, "replay/samples": 31824.0, "replay/insert_wait_avg": 1.3748924596756771e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.716992003765461e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 8080.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1555924273953579e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0281801223754883e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2495908737183, "timer/env.step_count": 3978.0, "timer/env.step_total": 39.335702419281006, "timer/env.step_frac": 0.03932588703677575, "timer/env.step_avg": 0.009888311317064104, "timer/env.step_min": 0.007984161376953125, "timer/env.step_max": 0.04413771629333496, "timer/replay._sample_count": 31824.0, "timer/replay._sample_total": 16.9822895526886, "timer/replay._sample_frac": 0.016978051985859412, "timer/replay._sample_avg": 0.0005336315218919243, "timer/replay._sample_min": 0.00039005279541015625, "timer/replay._sample_max": 0.011493444442749023, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4988.0, "timer/agent.policy_total": 54.092530250549316, "timer/agent.policy_frac": 0.05407903261754846, "timer/agent.policy_avg": 0.010844532929139799, "timer/agent.policy_min": 0.009161710739135742, "timer/agent.policy_max": 0.09531307220458984, "timer/dataset_train_count": 1989.0, "timer/dataset_train_total": 0.22622251510620117, "timer/dataset_train_frac": 0.0002261660661201528, "timer/dataset_train_avg": 0.00011373681000814538, "timer/dataset_train_min": 9.918212890625e-05, "timer/dataset_train_max": 0.000993490219116211, "timer/agent.train_count": 1989.0, "timer/agent.train_total": 890.4482305049896, "timer/agent.train_frac": 0.890226038210306, "timer/agent.train_avg": 0.4476863903996931, "timer/agent.train_min": 0.43752169609069824, "timer/agent.train_max": 0.7412285804748535, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4748506546020508, "timer/agent.report_frac": 0.0004747321657860101, "timer/agent.report_avg": 0.2374253273010254, "timer/agent.report_min": 0.23156404495239258, "timer/agent.report_max": 0.2432866096496582, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.170967102050781e-05, "timer/dataset_eval_frac": 3.170175855089269e-08, "timer/dataset_eval_avg": 3.170967102050781e-05, "timer/dataset_eval_min": 3.170967102050781e-05, "timer/dataset_eval_max": 3.170967102050781e-05, "fps": 31.81550508695176}
{"step": 930456, "time": 29265.378113746643, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 930472, "time": 29265.870552539825, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 931048, "time": 29283.402621030807, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 931400, "time": 29294.204909086227, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 931552, "time": 29299.100144147873, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 931736, "time": 29304.523453474045, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 931784, "time": 29305.994778871536, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 931840, "time": 29307.9503428936, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 931848, "time": 29307.978440523148, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 931928, "time": 29310.421441078186, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 932296, "time": 29321.801419496536, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 932336, "time": 29323.236645698547, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 932400, "time": 29325.184866666794, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 932592, "time": 29331.115810871124, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 932624, "time": 29332.097952365875, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 932848, "time": 29338.932160139084, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 932984, "time": 29342.85522890091, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 933008, "time": 29343.80621790886, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 933160, "time": 29348.333109378815, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 933360, "time": 29354.648405313492, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 933464, "time": 29357.60722708702, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 933472, "time": 29358.080387592316, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 933808, "time": 29368.328879594803, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 934376, "time": 29386.09598827362, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 934456, "time": 29388.527063846588, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 934608, "time": 29393.403985261917, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 934608, "time": 29393.413420915604, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 934712, "time": 29396.38154888153, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 934952, "time": 29403.67977333069, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 935320, "time": 29415.014678955078, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 935544, "time": 29421.849931001663, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 935672, "time": 29425.736801624298, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 935784, "time": 29429.12361598015, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 935808, "time": 29430.095906734467, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 935848, "time": 29431.093646526337, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 935928, "time": 29433.510187864304, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 936232, "time": 29442.858145713806, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 936264, "time": 29443.83157157898, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 936312, "time": 29445.310498952866, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 936520, "time": 29451.682611703873, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 936736, "time": 29458.511578321457, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 936880, "time": 29462.869911909103, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 936944, "time": 29464.83189702034, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 936960, "time": 29465.321869134903, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 937024, "time": 29467.361045598984, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 937216, "time": 29475.53546833992, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 937408, "time": 29481.40480709076, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 937664, "time": 29489.201885461807, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 937848, "time": 29494.557381153107, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 937880, "time": 29495.5436463356, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 938080, "time": 29501.944145441055, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 938112, "time": 29502.92187690735, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 938432, "time": 29512.75358605385, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 938480, "time": 29514.220366477966, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 938624, "time": 29518.62568449974, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 938680, "time": 29520.12969970703, "episode/length": 182.0, "episode/score": 0.4312500059604645, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.0}
{"step": 939048, "time": 29531.47330713272, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 939152, "time": 29534.887509822845, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 939192, "time": 29535.897459983826, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 939192, "time": 29535.916081905365, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 939336, "time": 29540.33331155777, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 939384, "time": 29541.80811190605, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 939392, "time": 29542.287981271744, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 939424, "time": 29543.279191732407, "episode/length": 196.0, "episode/score": 0.38749998807907104, "episode/reward_rate": 0.005076142131979695, "episode/intrinsic_return": 0.0}
{"step": 939760, "time": 29553.5648188591, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 939824, "time": 29555.534284591675, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 940040, "time": 29561.97053527832, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 940056, "time": 29564.125060796738, "eval_episode/length": 81.0, "eval_episode/score": 0.746874988079071, "eval_episode/reward_rate": 0.012195121951219513}
{"step": 940056, "time": 29564.312451839447, "eval_episode/length": 90.0, "eval_episode/score": 0.71875, "eval_episode/reward_rate": 0.01098901098901099}
{"step": 940056, "time": 29564.41828107834, "eval_episode/length": 95.0, "eval_episode/score": 0.703125, "eval_episode/reward_rate": 0.010416666666666666}
{"step": 940056, "time": 29564.78556537628, "eval_episode/length": 113.0, "eval_episode/score": 0.6468750238418579, "eval_episode/reward_rate": 0.008771929824561403}
{"step": 940056, "time": 29565.19882464409, "eval_episode/length": 134.0, "eval_episode/score": 0.581250011920929, "eval_episode/reward_rate": 0.007407407407407408}
{"step": 940056, "time": 29565.737379074097, "eval_episode/length": 161.0, "eval_episode/score": 0.49687498807907104, "eval_episode/reward_rate": 0.006172839506172839}
{"step": 940056, "time": 29566.00050163269, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 940056, "time": 29566.222895145416, "eval_episode/length": 89.0, "eval_episode/score": 0.721875011920929, "eval_episode/reward_rate": 0.011111111111111112}
{"step": 940136, "time": 29568.673586130142, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 940152, "time": 29569.1636633873, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 940264, "time": 29572.571586370468, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 940304, "time": 29574.02808189392, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 940912, "time": 29592.727553606033, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 941280, "time": 29604.039857387543, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 941504, "time": 29610.97000479698, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 941664, "time": 29615.883601903915, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 941696, "time": 29616.999683618546, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 942072, "time": 29628.26375079155, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 942160, "time": 29631.639493703842, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 942232, "time": 29633.671585083008, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 942408, "time": 29639.068884134293, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 942448, "time": 29640.51298880577, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 942464, "time": 29641.00937652588, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 942576, "time": 29644.43808913231, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 942656, "time": 29646.972831487656, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 942816, "time": 29651.865936517715, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 943056, "time": 29659.256046056747, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 943064, "time": 29659.284137010574, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 943224, "time": 29664.155191659927, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 943224, "time": 29664.166774749756, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 943432, "time": 29670.5241150856, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 943568, "time": 29674.891447544098, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 943744, "time": 29680.38677930832, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 943792, "time": 29681.869733333588, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 943816, "time": 29682.383600234985, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 944072, "time": 29690.15806412697, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 944144, "time": 29692.588838338852, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 944752, "time": 29711.349601745605, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 944776, "time": 29711.868609189987, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 944808, "time": 29712.853210687637, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 944832, "time": 29713.81346821785, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 944912, "time": 29716.290417194366, "episode/length": 12.0, "episode/score": 0.9624999761581421, "episode/reward_rate": 0.07692307692307693, "episode/intrinsic_return": 0.0}
{"step": 944912, "time": 29716.299914121628, "episode/length": 19.0, "episode/score": 0.940625011920929, "episode/reward_rate": 0.05, "episode/intrinsic_return": 0.0}
{"step": 945128, "time": 29722.73576426506, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 945344, "time": 29729.629648447037, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 945448, "time": 29732.59642624855, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 945536, "time": 29735.487002134323, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 945616, "time": 29738.029878616333, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 945720, "time": 29740.974201202393, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 945736, "time": 29741.463933944702, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 945880, "time": 29745.853562116623, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 946056, "time": 29751.20172905922, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 946096, "time": 29752.636194705963, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 946400, "time": 29761.89766216278, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 946752, "time": 29772.839057683945, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 946808, "time": 29774.341195583344, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 946832, "time": 29775.33116364479, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 947008, "time": 29780.708963871002, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 947064, "time": 29782.187812566757, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 947136, "time": 29784.599893808365, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 947496, "time": 29795.41494822502, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 947568, "time": 29797.970951795578, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 947656, "time": 29800.46131682396, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 947784, "time": 29804.355130672455, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 947896, "time": 29807.78774213791, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 948032, "time": 29812.203547239304, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 948048, "time": 29812.70473599434, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 948408, "time": 29823.54066681862, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 948752, "time": 29834.39329123497, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 948896, "time": 29838.789013385773, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 948936, "time": 29839.81378006935, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 949064, "time": 29843.727316856384, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 949072, "time": 29844.222373008728, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 949528, "time": 29858.054851293564, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 949696, "time": 29863.426571130753, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 949760, "time": 29865.39883041382, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 949760, "time": 29865.40819621086, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 949808, "time": 29866.88085436821, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 949880, "time": 29868.877759456635, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 950040, "time": 29874.357733011246, "eval_episode/length": 28.0, "eval_episode/score": 0.9125000238418579, "eval_episode/reward_rate": 0.034482758620689655}
{"step": 950040, "time": 29874.96090245247, "eval_episode/length": 57.0, "eval_episode/score": 0.8218749761581421, "eval_episode/reward_rate": 0.017241379310344827}
{"step": 950040, "time": 29875.861035823822, "eval_episode/length": 100.0, "eval_episode/score": 0.6875, "eval_episode/reward_rate": 0.009900990099009901}
{"step": 950040, "time": 29876.08813238144, "eval_episode/length": 111.0, "eval_episode/score": 0.653124988079071, "eval_episode/reward_rate": 0.008928571428571428}
{"step": 950040, "time": 29876.217453479767, "eval_episode/length": 88.0, "eval_episode/score": 0.7250000238418579, "eval_episode/reward_rate": 0.011235955056179775}
{"step": 950040, "time": 29876.265958070755, "eval_episode/length": 119.0, "eval_episode/score": 0.628125011920929, "eval_episode/reward_rate": 0.008333333333333333}
{"step": 950040, "time": 29877.298582553864, "eval_episode/length": 110.0, "eval_episode/score": 0.65625, "eval_episode/reward_rate": 0.009009009009009009}
{"step": 950040, "time": 29877.508566856384, "eval_episode/length": 60.0, "eval_episode/score": 0.8125, "eval_episode/reward_rate": 0.01639344262295082}
{"step": 950304, "time": 29886.231390953064, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 950344, "time": 29887.349531650543, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 950656, "time": 29897.29010772705, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 950736, "time": 29899.774030923843, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 950768, "time": 29900.76984333992, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 951240, "time": 29915.000413656235, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 951448, "time": 29921.432484149933, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 951712, "time": 29929.754730939865, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 951816, "time": 29932.733511924744, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 951840, "time": 29933.6948223114, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 951864, "time": 29934.212644338608, "episode/length": 189.0, "episode/score": 0.40937501192092896, "episode/reward_rate": 0.005263157894736842, "episode/intrinsic_return": 0.0}
{"step": 952008, "time": 29938.63993048668, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 952056, "time": 29940.101841926575, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 952120, "time": 29942.074743270874, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 952192, "time": 29944.484176397324, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 952248, "time": 29945.95893216133, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 952352, "time": 29949.41780233383, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 952368, "time": 29949.910996437073, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 952608, "time": 29957.278118371964, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 952880, "time": 29965.619472503662, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 952960, "time": 29968.089613437653, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 953008, "time": 29969.58224439621, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 953024, "time": 29970.072820425034, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 953048, "time": 29970.587440252304, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 953520, "time": 29985.333834409714, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 953696, "time": 29990.694626569748, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 953832, "time": 29994.62127327919, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 953984, "time": 29999.487484931946, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 954024, "time": 30000.492346286774, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 954128, "time": 30003.889800310135, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 954272, "time": 30008.413351774216, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 954392, "time": 30011.85480260849, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 954560, "time": 30017.197944879532, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 954776, "time": 30023.52684211731, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 954992, "time": 30030.358957767487, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 955048, "time": 30031.826894760132, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 955112, "time": 30033.751843452454, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 955192, "time": 30036.17830491066, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 955360, "time": 30041.642108917236, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 955408, "time": 30043.101880311966, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 955752, "time": 30053.351022720337, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 955824, "time": 30055.780447244644, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 955984, "time": 30060.640052080154, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 956000, "time": 30061.12926030159, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 956008, "time": 30061.157560110092, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 956088, "time": 30063.586319208145, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 956512, "time": 30076.77314400673, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 956584, "time": 30078.7314953804, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 956872, "time": 30087.492261648178, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 956912, "time": 30088.954587221146, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 956992, "time": 30091.38148331642, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 957088, "time": 30094.30740261078, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 957144, "time": 30095.786434412003, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 957408, "time": 30104.122618198395, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 957624, "time": 30110.455953359604, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 957888, "time": 30118.7291097641, "episode/length": 235.0, "episode/score": 0.265625, "episode/reward_rate": 0.00423728813559322, "episode/intrinsic_return": 0.0}
{"step": 957928, "time": 30119.72515654564, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 958024, "time": 30122.63163971901, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 958128, "time": 30126.012789011, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 958136, "time": 30126.043179035187, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 958584, "time": 30140.199027776718, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 958624, "time": 30141.645850419998, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 958664, "time": 30142.639622449875, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 958712, "time": 30144.12223148346, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 958824, "time": 30147.54723405838, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 959080, "time": 30155.32119369507, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 959120, "time": 30156.846957445145, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 959152, "time": 30157.840366840363, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 959288, "time": 30161.734877109528, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 959520, "time": 30169.023613214493, "episode/length": 236.0, "episode/score": 0.26249998807907104, "episode/reward_rate": 0.004219409282700422, "episode/intrinsic_return": 0.0}
{"step": 959840, "time": 30178.80170941353, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 959976, "time": 30182.711380958557, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 960024, "time": 30185.56293320656, "eval_episode/length": 71.0, "eval_episode/score": 0.778124988079071, "eval_episode/reward_rate": 0.013888888888888888}
{"step": 960024, "time": 30185.610543489456, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 960024, "time": 30186.5648522377, "eval_episode/length": 115.0, "eval_episode/score": 0.640625, "eval_episode/reward_rate": 0.008620689655172414}
{"step": 960024, "time": 30187.47475337982, "eval_episode/length": 89.0, "eval_episode/score": 0.721875011920929, "eval_episode/reward_rate": 0.011111111111111112}
{"step": 960024, "time": 30187.906458854675, "eval_episode/length": 67.0, "eval_episode/score": 0.7906249761581421, "eval_episode/reward_rate": 0.014705882352941176}
{"step": 960024, "time": 30190.490629196167, "eval_episode/length": 120.0, "eval_episode/score": 0.625, "eval_episode/reward_rate": 0.008264462809917356}
{"step": 960024, "time": 30190.616042375565, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 960024, "time": 30190.622727394104, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 960024, "time": 30190.628556251526, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 960024, "time": 30190.634479999542, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 960024, "time": 30190.64050745964, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 960448, "time": 30203.766956329346, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 960496, "time": 30205.22573375702, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 960752, "time": 30213.03547859192, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 960896, "time": 30217.52152132988, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 960936, "time": 30218.53543448448, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 961256, "time": 30228.239351272583, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 961392, "time": 30232.581836938858, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 961432, "time": 30233.579083919525, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 961472, "time": 30235.004743099213, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 961768, "time": 30243.705247163773, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 962152, "time": 30255.38639855385, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 962288, "time": 30259.728610277176, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 962425, "time": 30264.64827632904, "train_stats/mean_log_entropy": 0.08243249232570331, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.599104919433594, "train/action_min": 0.0, "train/action_std": 1.7270524877309799, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.011044061420252547, "train/actor_opt_grad_steps": 59055.0, "train/actor_opt_loss": -20.941961669921874, "train/adv_mag": 0.9696703478693962, "train/adv_max": 0.43317930221557616, "train/adv_mean": 0.0004947970699186044, "train/adv_min": -0.8786999627947807, "train/adv_std": 0.030032045347616075, "train/cont_avg": 0.9944140625, "train/cont_loss_mean": 0.021437304010614753, "train/cont_loss_std": 0.256105243479833, "train/cont_neg_acc": 0.21769246447831392, "train/cont_neg_loss": 3.0127058382180985, "train/cont_pos_acc": 0.9998771351575851, "train/cont_pos_loss": 0.0046037908806465565, "train/cont_pred": 0.9942906680703163, "train/cont_rate": 0.9944140625, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.10570988872786984, "train/extr_critic_critic_opt_grad_steps": 59055.0, "train/extr_critic_critic_opt_loss": 9475.44748046875, "train/extr_critic_mag": 1.613687732219696, "train/extr_critic_max": 1.613687732219696, "train/extr_critic_mean": 1.4931204563379288, "train/extr_critic_min": 0.9510932821035385, "train/extr_critic_std": 0.031634604651480915, "train/extr_return_normed_mag": 1.0030245327949523, "train/extr_return_normed_max": 0.31486562013626096, "train/extr_return_normed_mean": 0.06041421703062952, "train/extr_return_normed_min": -0.9114589232206345, "train/extr_return_normed_std": 0.044449484050273894, "train/extr_return_rate": 0.9996081069111824, "train/extr_return_raw_mag": 1.748066601753235, "train/extr_return_raw_max": 1.748066601753235, "train/extr_return_raw_mean": 1.4936152803897857, "train/extr_return_raw_min": 0.5217420583963395, "train/extr_return_raw_std": 0.044449484031647446, "train/extr_reward_mag": 0.28413163125514984, "train/extr_reward_max": 0.28413163125514984, "train/extr_reward_mean": 0.0023388348403386773, "train/extr_reward_min": 2.4437904357910154e-07, "train/extr_reward_std": 0.008750916153658181, "train/image_loss_mean": 0.08331056324765086, "train/image_loss_std": 0.09942713368684053, "train/model_loss_mean": 0.7230647212266922, "train/model_loss_std": 0.5077531883120536, "train/model_opt_grad_norm": 18.349164068698883, "train/model_opt_grad_steps": 59001.72, "train/model_opt_loss": 3864.4777172851564, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5350.0, "train/policy_entropy_mag": 1.3570883893966674, "train/policy_entropy_max": 1.3570883893966674, "train/policy_entropy_mean": 0.09686834599822759, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.12281829074025154, "train/policy_logprob_mag": 6.551080250740052, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09696118153631687, "train/policy_logprob_min": -6.551080250740052, "train/policy_logprob_std": 0.6347769394516944, "train/policy_randomness_mag": 0.6974055138230324, "train/policy_randomness_max": 0.6974055138230324, "train/policy_randomness_mean": 0.049780485052615404, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.06311611954122781, "train/post_ent_mag": 27.97536304473877, "train/post_ent_max": 27.97536304473877, "train/post_ent_mean": 27.4720050239563, "train/post_ent_min": 27.02176775932312, "train/post_ent_std": 0.20713718175888063, "train/prior_ent_mag": 27.816582460403442, "train/prior_ent_max": 27.816582460403442, "train/prior_ent_mean": 27.228579196929932, "train/prior_ent_min": 26.220647239685057, "train/prior_ent_std": 0.2646550700068474, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0024419860976922793, "train/reward_loss_mean": 0.01831683319527656, "train/reward_loss_std": 0.2497319151391275, "train/reward_max_data": 0.7730156229436398, "train/reward_max_pred": 0.24349045336246491, "train/reward_neg_acc": 0.9996323749423027, "train/reward_neg_loss": 0.003336147542577237, "train/reward_pos_acc": 0.12900302923985363, "train/reward_pos_loss": 4.16744743733062, "train/reward_pred": 0.0019416292977984995, "train/reward_rate": 0.0035888671875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.020033597946166992, "report/cont_loss_std": 0.251407653093338, "report/cont_neg_acc": 0.20000000298023224, "report/cont_neg_loss": 3.0859808921813965, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.004989697597920895, "report/cont_pred": 0.9941680431365967, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.08248480409383774, "report/image_loss_std": 0.1016303151845932, "report/model_loss_mean": 0.7185242772102356, "report/model_loss_std": 0.4463469684123993, "report/post_ent_mag": 27.77414321899414, "report/post_ent_max": 27.77414321899414, "report/post_ent_mean": 27.283809661865234, "report/post_ent_min": 26.794986724853516, "report/post_ent_std": 0.21602214872837067, "report/prior_ent_mag": 27.784046173095703, "report/prior_ent_max": 27.784046173095703, "report/prior_ent_mean": 27.168155670166016, "report/prior_ent_min": 26.030956268310547, "report/prior_ent_std": 0.26976141333580017, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0027618408203125, "report/reward_loss_mean": 0.016005851328372955, "report/reward_loss_std": 0.20868609845638275, "report/reward_max_data": 0.8062499761581421, "report/reward_max_pred": 0.649151086807251, "report/reward_neg_acc": 0.9990195631980896, "report/reward_neg_loss": 0.004244836047291756, "report/reward_pos_acc": 0.25, "report/reward_pos_loss": 3.0150644779205322, "report/reward_pred": 0.002818626817315817, "report/reward_rate": 0.00390625, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.024401061236858368, "eval/cont_loss_std": 0.4574373960494995, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.912692546844482, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.004161225166171789, "eval/cont_pred": 0.9958939552307129, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.14046598970890045, "eval/image_loss_std": 0.12839937210083008, "eval/model_loss_mean": 0.7908990979194641, "eval/model_loss_std": 0.9775651693344116, "eval/post_ent_mag": 27.776268005371094, "eval/post_ent_max": 27.776268005371094, "eval/post_ent_mean": 27.25306510925293, "eval/post_ent_min": 26.788341522216797, "eval/post_ent_std": 0.20487907528877258, "eval/prior_ent_mag": 27.812843322753906, "eval/prior_ent_max": 27.812843322753906, "eval/prior_ent_mean": 27.139944076538086, "eval/prior_ent_min": 26.24185562133789, "eval/prior_ent_std": 0.28858229517936707, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0019744872115552425, "eval/reward_loss_mean": 0.026031984016299248, "eval/reward_loss_std": 0.5011709332466125, "eval/reward_max_data": 0.75, "eval/reward_max_pred": 0.18383407592773438, "eval/reward_neg_acc": 0.999020516872406, "eval/reward_neg_loss": 0.0032953592017292976, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 7.764062404632568, "eval/reward_pred": 0.0017140732379630208, "eval/reward_rate": 0.0029296875, "replay/size": 961921.0, "replay/inserts": 32016.0, "replay/samples": 32016.0, "replay/insert_wait_avg": 1.3686504321119774e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.796972372959639e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5232.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1453387934133547e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.98377799987793e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4505529403687, "timer/env.step_count": 4002.0, "timer/env.step_total": 39.65398693084717, "timer/env.step_frac": 0.0396361287564911, "timer/env.step_avg": 0.00990854246148105, "timer/env.step_min": 0.007945060729980469, "timer/env.step_max": 0.0375056266784668, "timer/replay._sample_count": 32016.0, "timer/replay._sample_total": 17.262544631958008, "timer/replay._sample_frac": 0.0172547704443989, "timer/replay._sample_avg": 0.0005391849272850453, "timer/replay._sample_min": 0.0004227161407470703, "timer/replay._sample_max": 0.01125955581665039, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4656.0, "timer/agent.policy_total": 50.98867607116699, "timer/agent.policy_frac": 0.05096571331917305, "timer/agent.policy_avg": 0.010951176132123494, "timer/agent.policy_min": 0.008610725402832031, "timer/agent.policy_max": 0.08808231353759766, "timer/dataset_train_count": 2001.0, "timer/dataset_train_total": 0.22982311248779297, "timer/dataset_train_frac": 0.00022971961164130764, "timer/dataset_train_avg": 0.00011485412917930683, "timer/dataset_train_min": 9.894371032714844e-05, "timer/dataset_train_max": 0.0010726451873779297, "timer/agent.train_count": 2001.0, "timer/agent.train_total": 896.8209974765778, "timer/agent.train_frac": 0.8964171141100187, "timer/agent.train_avg": 0.44818640553552114, "timer/agent.train_min": 0.4342806339263916, "timer/agent.train_max": 2.732503890991211, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4825754165649414, "timer/agent.report_frac": 0.00048235808870976263, "timer/agent.report_avg": 0.2412877082824707, "timer/agent.report_min": 0.2338423728942871, "timer/agent.report_max": 0.2487330436706543, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.409385681152344e-05, "timer/dataset_eval_frac": 3.407850264195475e-08, "timer/dataset_eval_avg": 3.409385681152344e-05, "timer/dataset_eval_min": 3.409385681152344e-05, "timer/dataset_eval_max": 3.409385681152344e-05, "fps": 32.00105848100751}
{"step": 962432, "time": 30264.661244869232, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 962960, "time": 30281.153399944305, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 963176, "time": 30287.4918820858, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 963208, "time": 30288.48322868347, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 963248, "time": 30289.93653702736, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 963568, "time": 30299.77064347267, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 963744, "time": 30305.117082118988, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 963872, "time": 30309.121994018555, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 963944, "time": 30311.094845056534, "episode/length": 223.0, "episode/score": 0.3031249940395355, "episode/reward_rate": 0.004464285714285714, "episode/intrinsic_return": 0.0}
{"step": 963960, "time": 30311.608856916428, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 964160, "time": 30317.956550598145, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 964272, "time": 30321.43704175949, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 964296, "time": 30321.94998240471, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 964584, "time": 30330.747456550598, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 964600, "time": 30331.254502773285, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 964696, "time": 30334.15080857277, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 964696, "time": 30334.159855127335, "episode/length": 13.0, "episode/score": 0.9593750238418579, "episode/reward_rate": 0.07142857142857142, "episode/intrinsic_return": 0.0}
{"step": 964720, "time": 30335.121567487717, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 964744, "time": 30335.63669681549, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 964856, "time": 30339.17550754547, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 965112, "time": 30346.94430923462, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 965136, "time": 30347.905663490295, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 965208, "time": 30349.90136742592, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 965336, "time": 30353.853113889694, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 965792, "time": 30368.02525281906, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 965808, "time": 30368.519630670547, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 965944, "time": 30372.453176498413, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 966088, "time": 30376.848007917404, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 966120, "time": 30377.82497358322, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 966136, "time": 30378.316064596176, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 966144, "time": 30378.787445545197, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 966600, "time": 30392.432820558548, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 966728, "time": 30396.87943482399, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 966792, "time": 30398.822570323944, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 966880, "time": 30401.757291793823, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 966912, "time": 30402.722898960114, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 967520, "time": 30421.199043750763, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 967568, "time": 30422.654193878174, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 967880, "time": 30432.00750851631, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 968024, "time": 30436.374573230743, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 968048, "time": 30437.31694483757, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 968256, "time": 30443.617300271988, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 968432, "time": 30448.975536108017, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 968688, "time": 30456.80455827713, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 968712, "time": 30457.31151652336, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 968912, "time": 30463.566858053207, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 969096, "time": 30468.892105579376, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 969192, "time": 30471.776587724686, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 969224, "time": 30472.743451595306, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 969320, "time": 30475.661467313766, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 969336, "time": 30476.14919281006, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 969584, "time": 30483.8280377388, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 969632, "time": 30485.277467489243, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 969816, "time": 30490.74155497551, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 969960, "time": 30495.118206501007, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 970008, "time": 30498.266453504562, "eval_episode/length": 90.0, "eval_episode/score": 0.71875, "eval_episode/reward_rate": 0.01098901098901099}
{"step": 970008, "time": 30498.645173072815, "eval_episode/length": 110.0, "eval_episode/score": 0.65625, "eval_episode/reward_rate": 0.009009009009009009}
{"step": 970008, "time": 30498.834287643433, "eval_episode/length": 119.0, "eval_episode/score": 0.628125011920929, "eval_episode/reward_rate": 0.008333333333333333}
{"step": 970008, "time": 30498.984273672104, "eval_episode/length": 126.0, "eval_episode/score": 0.606249988079071, "eval_episode/reward_rate": 0.007874015748031496}
{"step": 970008, "time": 30499.052708864212, "eval_episode/length": 129.0, "eval_episode/score": 0.596875011920929, "eval_episode/reward_rate": 0.007692307692307693}
{"step": 970008, "time": 30499.71560907364, "eval_episode/length": 71.0, "eval_episode/score": 0.778124988079071, "eval_episode/reward_rate": 0.013888888888888888}
{"step": 970008, "time": 30500.230273246765, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 970008, "time": 30500.294317245483, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 970096, "time": 30503.21019911766, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 970192, "time": 30506.15437221527, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 970352, "time": 30511.00668001175, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 970392, "time": 30512.010588884354, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 970624, "time": 30519.39366555214, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 970920, "time": 30528.213943719864, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 971048, "time": 30532.139174461365, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 971088, "time": 30533.58449435234, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 971408, "time": 30543.434413433075, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 971680, "time": 30551.88275051117, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 971944, "time": 30559.737691164017, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 971984, "time": 30561.20512509346, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 972112, "time": 30565.10277581215, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 972224, "time": 30568.491453647614, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 972272, "time": 30569.971021413803, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 972624, "time": 30580.782770872116, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 972704, "time": 30583.21875858307, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 972880, "time": 30588.602561473846, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 972936, "time": 30590.12510585785, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 973000, "time": 30592.08855175972, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 973088, "time": 30595.02170920372, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 973240, "time": 30599.47279214859, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 973328, "time": 30602.39977145195, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 973408, "time": 30604.867778778076, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 973432, "time": 30605.38521051407, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 973448, "time": 30605.877509593964, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 973752, "time": 30615.269309043884, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 973904, "time": 30620.150708198547, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 973928, "time": 30620.66904759407, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 973984, "time": 30622.59300351143, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 974040, "time": 30624.090749025345, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 974072, "time": 30625.072023630142, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 974536, "time": 30639.39044070244, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 974608, "time": 30641.82910490036, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 974760, "time": 30646.2905960083, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 974912, "time": 30651.70295357704, "episode/length": 18.0, "episode/score": 0.9437500238418579, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.0}
{"step": 975000, "time": 30654.18095111847, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 975080, "time": 30656.622845172882, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 975408, "time": 30666.985718011856, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 975544, "time": 30670.940603017807, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 975552, "time": 30671.42160463333, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 975720, "time": 30676.359043121338, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 976208, "time": 30691.488141536713, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 976232, "time": 30691.999745845795, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 976240, "time": 30692.470193862915, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 976256, "time": 30692.95870065689, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 976424, "time": 30697.94989466667, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 976464, "time": 30699.414986610413, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 976832, "time": 30710.69750571251, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 976848, "time": 30711.19873857498, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 976888, "time": 30712.208245754242, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 976920, "time": 30713.202638864517, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 976976, "time": 30715.119844675064, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 977064, "time": 30717.57116985321, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 977496, "time": 30730.943353652954, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 977592, "time": 30733.881112098694, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 977592, "time": 30733.88931465149, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 977696, "time": 30737.272896766663, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 977712, "time": 30737.797450065613, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 977960, "time": 30745.148260593414, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 977984, "time": 30746.109734535217, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 978416, "time": 30759.438067913055, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 978496, "time": 30761.86258482933, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 978496, "time": 30761.873113393784, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 978504, "time": 30761.903458356857, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 978552, "time": 30763.38110947609, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 979096, "time": 30779.990421056747, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 979200, "time": 30783.385147333145, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 979200, "time": 30783.392059087753, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 979328, "time": 30787.416170597076, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 979480, "time": 30791.83620786667, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 979848, "time": 30803.425810098648, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 979928, "time": 30805.884412765503, "episode/length": 276.0, "episode/score": 0.13750000298023224, "episode/reward_rate": 0.0036101083032490976, "episode/intrinsic_return": 0.0}
{"step": 980096, "time": 30812.45952439308, "eval_episode/length": 58.0, "eval_episode/score": 0.8187500238418579, "eval_episode/reward_rate": 0.01694915254237288}
{"step": 980096, "time": 30812.578716039658, "eval_episode/length": 64.0, "eval_episode/score": 0.800000011920929, "eval_episode/reward_rate": 0.015384615384615385}
{"step": 980096, "time": 30812.6603808403, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 980096, "time": 30812.96550679207, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 980096, "time": 30813.028232336044, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 980096, "time": 30813.58356499672, "eval_episode/length": 45.0, "eval_episode/score": 0.859375, "eval_episode/reward_rate": 0.021739130434782608}
{"step": 980096, "time": 30814.57847070694, "eval_episode/length": 97.0, "eval_episode/score": 0.6968749761581421, "eval_episode/reward_rate": 0.01020408163265306}
{"step": 980096, "time": 30815.58807826042, "eval_episode/length": 211.0, "eval_episode/score": 0.34062498807907104, "eval_episode/reward_rate": 0.0047169811320754715}
{"step": 980096, "time": 30815.59721326828, "eval_episode/length": 127.0, "eval_episode/score": 0.6031249761581421, "eval_episode/reward_rate": 0.0078125}
{"step": 980104, "time": 30815.62739634514, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 980360, "time": 30823.61364221573, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 980368, "time": 30824.086899995804, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 980416, "time": 30825.559977054596, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 980864, "time": 30839.313863277435, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 981512, "time": 30859.04746031761, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 981584, "time": 30861.465868473053, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 982160, "time": 30878.96515583992, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 982208, "time": 30880.43202328682, "episode/length": 284.0, "episode/score": 0.11249999701976776, "episode/reward_rate": 0.0035087719298245615, "episode/intrinsic_return": 0.0}
{"step": 982416, "time": 30886.72983288765, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 982464, "time": 30888.196987628937, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 982672, "time": 30894.585752487183, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 982728, "time": 30896.075458049774, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 983176, "time": 30910.372457265854, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 983408, "time": 30917.665603399277, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 983432, "time": 30918.180340766907, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 983688, "time": 30926.00247168541, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 983824, "time": 30930.393618106842, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 983936, "time": 30933.800809383392, "episode/length": 189.0, "episode/score": 0.40937501192092896, "episode/reward_rate": 0.005263157894736842, "episode/intrinsic_return": 0.0}
{"step": 984176, "time": 30941.20126891136, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 984472, "time": 30949.996357679367, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 984512, "time": 30951.43182849884, "episode/length": 229.0, "episode/score": 0.28437501192092896, "episode/reward_rate": 0.004347826086956522, "episode/intrinsic_return": 0.0}
{"step": 984520, "time": 30951.459834337234, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 984584, "time": 30953.414335489273, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 984976, "time": 30965.498308181763, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 985016, "time": 30966.553673505783, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 985376, "time": 30977.832055807114, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 985392, "time": 30978.358605384827, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 985488, "time": 30981.325865983963, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 985560, "time": 30983.344254493713, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 985744, "time": 30989.233919620514, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 985864, "time": 30992.66772866249, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 985912, "time": 30994.1710190773, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 985936, "time": 30995.14136481285, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 986248, "time": 31004.67320752144, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 986320, "time": 31007.10734629631, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 986616, "time": 31015.965623140335, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 986696, "time": 31018.429986953735, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 986960, "time": 31026.950862169266, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 987184, "time": 31033.838725328445, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 987288, "time": 31036.80130982399, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 987440, "time": 31041.712258815765, "episode/length": 196.0, "episode/score": 0.38749998807907104, "episode/reward_rate": 0.005076142131979695, "episode/intrinsic_return": 0.0}
{"step": 987800, "time": 31052.626402378082, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 987984, "time": 31058.585973262787, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 988056, "time": 31060.561376810074, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 988152, "time": 31063.51863884926, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 988512, "time": 31074.86663532257, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 988576, "time": 31076.822244882584, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 988576, "time": 31076.83602809906, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 988736, "time": 31081.714415311813, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 988928, "time": 31087.757430315018, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 989008, "time": 31090.20841550827, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 989128, "time": 31093.649889707565, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 989160, "time": 31094.637189149857, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 989320, "time": 31099.642484664917, "episode/length": 19.0, "episode/score": 0.940625011920929, "episode/reward_rate": 0.05, "episode/intrinsic_return": 0.0}
{"step": 989336, "time": 31100.142058849335, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 989576, "time": 31107.49678182602, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 989664, "time": 31110.417100906372, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 989752, "time": 31112.890621185303, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 989800, "time": 31114.352323055267, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 989952, "time": 31119.332258701324, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 990080, "time": 31123.700439214706, "eval_episode/length": 19.0, "eval_episode/score": 0.940625011920929, "eval_episode/reward_rate": 0.05}
{"step": 990080, "time": 31124.576200723648, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 990080, "time": 31124.602133750916, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 990080, "time": 31125.0437772274, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 990080, "time": 31125.252243041992, "eval_episode/length": 93.0, "eval_episode/score": 0.7093750238418579, "eval_episode/reward_rate": 0.010638297872340425}
{"step": 990080, "time": 31126.84451842308, "eval_episode/length": 169.0, "eval_episode/score": 0.47187501192092896, "eval_episode/reward_rate": 0.0058823529411764705}
{"step": 990080, "time": 31127.276648759842, "eval_episode/length": 127.0, "eval_episode/score": 0.6031249761581421, "eval_episode/reward_rate": 0.0078125}
{"step": 990080, "time": 31127.5610101223, "eval_episode/length": 108.0, "eval_episode/score": 0.6625000238418579, "eval_episode/reward_rate": 0.009174311926605505}
{"step": 990136, "time": 31129.050420999527, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 990152, "time": 31129.541744232178, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 990240, "time": 31132.45931339264, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 990392, "time": 31136.874126911163, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 990464, "time": 31139.276193380356, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 990648, "time": 31144.652287483215, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 990824, "time": 31150.162515878677, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 990888, "time": 31152.146451234818, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 990912, "time": 31153.103345155716, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 991184, "time": 31161.48932504654, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 991288, "time": 31164.978593826294, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 991424, "time": 31169.39830136299, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 991512, "time": 31171.90024280548, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 991520, "time": 31172.37889289856, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 991536, "time": 31172.87573170662, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 991784, "time": 31180.375385522842, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 992064, "time": 31189.186928272247, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 992136, "time": 31191.219305992126, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 992160, "time": 31192.185762166977, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 992232, "time": 31194.19252371788, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 992256, "time": 31195.15626835823, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 992360, "time": 31198.156219244003, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 992512, "time": 31203.088715314865, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 992576, "time": 31205.044830560684, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 992632, "time": 31206.647212266922, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 992912, "time": 31215.45262646675, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 993080, "time": 31220.43089556694, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 993112, "time": 31221.41965842247, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 993224, "time": 31224.86001777649, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 993376, "time": 31229.75972867012, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 993840, "time": 31244.17487502098, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 993880, "time": 31245.21546602249, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 994024, "time": 31249.661529541016, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 994489, "time": 31264.862101078033, "train_stats/mean_log_entropy": 0.0778316407388932, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.6066680908203126, "train/action_min": 0.0, "train/action_std": 1.6811916416883468, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.010713377270149068, "train/actor_opt_grad_steps": 61055.0, "train/actor_opt_loss": -19.11766637802124, "train/adv_mag": 0.8895391741394997, "train/adv_max": 0.4560905998945236, "train/adv_mean": -0.0006368335269507952, "train/adv_min": -0.7766823667287827, "train/adv_std": 0.026863582441583277, "train/cont_avg": 0.9942578125, "train/cont_loss_mean": 0.021476664368528874, "train/cont_loss_std": 0.2604976567067206, "train/cont_neg_acc": 0.23516160722821952, "train/cont_neg_loss": 2.975714506059885, "train/cont_pos_acc": 0.9999017611145973, "train/cont_pos_loss": 0.004489665167639032, "train/cont_pred": 0.9942197313904763, "train/cont_rate": 0.9942578125, "train/dyn_loss_mean": 1.0000005429983139, "train/dyn_loss_std": 1.7366582178510725e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.0991384912841022, "train/extr_critic_critic_opt_grad_steps": 61055.0, "train/extr_critic_critic_opt_loss": 9776.056423339844, "train/extr_critic_mag": 1.6167993795871736, "train/extr_critic_max": 1.6167993795871736, "train/extr_critic_mean": 1.4893950510025025, "train/extr_critic_min": 0.9445889610052108, "train/extr_critic_std": 0.028602631008252503, "train/extr_return_normed_mag": 0.9547538155317307, "train/extr_return_normed_max": 0.3330151271820068, "train/extr_return_normed_mean": 0.05101176912896335, "train/extr_return_normed_min": -0.864279779791832, "train/extr_return_normed_std": 0.0398640675842762, "train/extr_return_rate": 0.9997422221302986, "train/extr_return_raw_mag": 1.7707615035772324, "train/extr_return_raw_max": 1.7707615035772324, "train/extr_return_raw_mean": 1.4887582105398178, "train/extr_return_raw_min": 0.5734665966033936, "train/extr_return_raw_std": 0.039864067379385235, "train/extr_reward_mag": 0.3192354166507721, "train/extr_reward_max": 0.3192354166507721, "train/extr_reward_mean": 0.0019355548251769506, "train/extr_reward_min": 2.2351741790771484e-07, "train/extr_reward_std": 0.008573502867948264, "train/image_loss_mean": 0.08273271894082428, "train/image_loss_std": 0.09997099328786135, "train/model_loss_mean": 0.7223386937379837, "train/model_loss_std": 0.5103918857499957, "train/model_opt_grad_norm": 16.72615565776825, "train/model_opt_grad_steps": 60999.84, "train/model_opt_loss": 3953.353282470703, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5475.0, "train/policy_entropy_mag": 1.3137161803245545, "train/policy_entropy_max": 1.3137161803245545, "train/policy_entropy_mean": 0.09687791962176562, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.12255749430507422, "train/policy_logprob_mag": 6.551080248355865, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.0963230361789465, "train/policy_logprob_min": -6.551080248355865, "train/policy_logprob_std": 0.6319263139367104, "train/policy_randomness_mag": 0.6751166066527367, "train/policy_randomness_max": 0.6751166066527367, "train/policy_randomness_mean": 0.04978540500625968, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.06298209730535746, "train/post_ent_mag": 28.209588413238524, "train/post_ent_max": 28.209588413238524, "train/post_ent_mean": 27.582606201171874, "train/post_ent_min": 27.053192234039308, "train/post_ent_std": 0.2520373871922493, "train/prior_ent_mag": 27.867745361328126, "train/prior_ent_max": 27.867745361328126, "train/prior_ent_mean": 27.159887008666992, "train/prior_ent_min": 26.12487726211548, "train/prior_ent_std": 0.293902815580368, "train/rep_loss_mean": 1.0000005429983139, "train/rep_loss_std": 1.7366582178510725e-05, "train/reward_avg": 0.0024668731822748667, "train/reward_loss_mean": 0.018128959501627833, "train/reward_loss_std": 0.25100789485499264, "train/reward_max_data": 0.7882500006258488, "train/reward_max_pred": 0.245831156373024, "train/reward_neg_acc": 0.9996177420020104, "train/reward_neg_loss": 0.003239428947563283, "train/reward_pos_acc": 0.13464806951356656, "train/reward_pos_loss": 4.110926807528794, "train/reward_pred": 0.0019215796305797994, "train/reward_rate": 0.003603515625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.014462480321526527, "report/cont_loss_std": 0.18295851349830627, "report/cont_neg_acc": 0.3333333432674408, "report/cont_neg_loss": 2.752831220626831, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.006416342221200466, "report/cont_pred": 0.9927462339401245, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.07269537448883057, "report/image_loss_std": 0.09376096725463867, "report/model_loss_mean": 0.7029584646224976, "report/model_loss_std": 0.4391331672668457, "report/post_ent_mag": 28.975257873535156, "report/post_ent_max": 28.975257873535156, "report/post_ent_mean": 27.86834144592285, "report/post_ent_min": 26.72580337524414, "report/post_ent_std": 0.4584648013114929, "report/prior_ent_mag": 27.60826873779297, "report/prior_ent_max": 27.60826873779297, "report/prior_ent_mean": 26.566301345825195, "report/prior_ent_min": 25.243427276611328, "report/prior_ent_std": 0.40441587567329407, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0019012452103197575, "report/reward_loss_mean": 0.01580062508583069, "report/reward_loss_std": 0.2267717719078064, "report/reward_max_data": 0.815625011920929, "report/reward_max_pred": 0.5123529434204102, "report/reward_neg_acc": 0.999020516872406, "report/reward_neg_loss": 0.004978397861123085, "report/reward_pos_acc": 0.3333333432674408, "report/reward_pos_loss": 3.698965072631836, "report/reward_pred": 0.003014664864167571, "report/reward_rate": 0.0029296875, "eval/cont_avg": 0.9931640625, "eval/cont_loss_mean": 0.03597455471754074, "eval/cont_loss_std": 0.38806426525115967, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 4.474984169006348, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.005420904606580734, "eval/cont_pred": 0.9945871233940125, "eval/cont_rate": 0.9931640625, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.11842143535614014, "eval/image_loss_std": 0.12346425652503967, "eval/model_loss_mean": 0.7871688604354858, "eval/model_loss_std": 0.7897570133209229, "eval/post_ent_mag": 29.059782028198242, "eval/post_ent_max": 29.059782028198242, "eval/post_ent_mean": 27.773765563964844, "eval/post_ent_min": 26.865589141845703, "eval/post_ent_std": 0.45689278841018677, "eval/prior_ent_mag": 27.612133026123047, "eval/prior_ent_max": 27.612133026123047, "eval/prior_ent_mean": 26.572656631469727, "eval/prior_ent_min": 25.268367767333984, "eval/prior_ent_std": 0.41921693086624146, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.004275512881577015, "eval/reward_loss_mean": 0.032772839069366455, "eval/reward_loss_std": 0.39483949542045593, "eval/reward_max_data": 0.875, "eval/reward_max_pred": 0.11972296237945557, "eval/reward_neg_acc": 0.9990177154541016, "eval/reward_neg_loss": 0.0033803563565015793, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.019697189331055, "eval/reward_pred": 0.0018002035794779658, "eval/reward_rate": 0.005859375, "replay/size": 993985.0, "replay/inserts": 32064.0, "replay/samples": 32064.0, "replay/insert_wait_avg": 1.3707135013953416e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.806556522727251e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4864.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.157830028157485e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.238719940185547e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1964275836945, "timer/env.step_count": 4008.0, "timer/env.step_total": 39.586602449417114, "timer/env.step_frac": 0.039578828075852716, "timer/env.step_avg": 0.009876896818716846, "timer/env.step_min": 0.0076558589935302734, "timer/env.step_max": 0.0379939079284668, "timer/replay._sample_count": 32064.0, "timer/replay._sample_total": 17.074839115142822, "timer/replay._sample_frac": 0.01707148580443618, "timer/replay._sample_avg": 0.0005325236749982167, "timer/replay._sample_min": 0.0004088878631591797, "timer/replay._sample_max": 0.011886835098266602, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4616.0, "timer/agent.policy_total": 49.913268089294434, "timer/agent.policy_frac": 0.04990346567211448, "timer/agent.policy_avg": 0.010813099672724097, "timer/agent.policy_min": 0.008865833282470703, "timer/agent.policy_max": 0.08535647392272949, "timer/dataset_train_count": 2004.0, "timer/dataset_train_total": 0.22915983200073242, "timer/dataset_train_frac": 0.00022911482752877238, "timer/dataset_train_avg": 0.00011435121357321977, "timer/dataset_train_min": 9.632110595703125e-05, "timer/dataset_train_max": 0.0010752677917480469, "timer/agent.train_count": 2004.0, "timer/agent.train_total": 897.9823851585388, "timer/agent.train_frac": 0.8978060312891863, "timer/agent.train_avg": 0.44809500257412116, "timer/agent.train_min": 0.4352993965148926, "timer/agent.train_max": 0.784379243850708, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4813058376312256, "timer/agent.report_frac": 0.00048121131445548064, "timer/agent.report_avg": 0.2406529188156128, "timer/agent.report_min": 0.23603415489196777, "timer/agent.report_max": 0.2452716827392578, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0994415283203125e-05, "timer/dataset_eval_frac": 3.098832832074835e-08, "timer/dataset_eval_avg": 3.0994415283203125e-05, "timer/dataset_eval_min": 3.0994415283203125e-05, "timer/dataset_eval_max": 3.0994415283203125e-05, "fps": 32.05717072014553}
{"step": 994536, "time": 31266.104071855545, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 994592, "time": 31268.12865614891, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 994672, "time": 31270.59620141983, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 994680, "time": 31270.626955747604, "episode/length": 270.0, "episode/score": 0.15625, "episode/reward_rate": 0.0036900369003690036, "episode/intrinsic_return": 0.0}
{"step": 994752, "time": 31273.068705797195, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 994784, "time": 31274.048274993896, "episode/length": 233.0, "episode/score": 0.2718749940395355, "episode/reward_rate": 0.004273504273504274, "episode/intrinsic_return": 0.0}
{"step": 995232, "time": 31287.69932293892, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 995296, "time": 31289.641379356384, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 995368, "time": 31291.62493300438, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 995424, "time": 31293.541373491287, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 995528, "time": 31296.5439286232, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 995680, "time": 31301.422015190125, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 995720, "time": 31302.41313934326, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 995840, "time": 31306.272490739822, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 996088, "time": 31313.56776380539, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 996112, "time": 31314.538440465927, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 996120, "time": 31314.56651353836, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 996224, "time": 31317.937823534012, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 996248, "time": 31318.448091983795, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 996592, "time": 31329.29033780098, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 996616, "time": 31329.803124427795, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 996768, "time": 31334.663402080536, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 996928, "time": 31339.550275564194, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 996992, "time": 31341.510921239853, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 997120, "time": 31345.405433177948, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 997296, "time": 31350.801306962967, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 997480, "time": 31356.183619260788, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 997600, "time": 31360.227336645126, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 997632, "time": 31361.20233297348, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 997752, "time": 31364.650286912918, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 997776, "time": 31365.631360292435, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 998152, "time": 31376.797503471375, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 998152, "time": 31376.80691933632, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 998280, "time": 31380.72416114807, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 998600, "time": 31390.539049386978, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 998640, "time": 31391.97383570671, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 998680, "time": 31392.984862804413, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 998848, "time": 31398.363752126694, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 998960, "time": 31401.783289432526, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 999032, "time": 31403.76760315895, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 999160, "time": 31407.67496085167, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 999712, "time": 31425.403823375702, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 999792, "time": 31427.853833198547, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 999832, "time": 31428.850761413574, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 999912, "time": 31431.27322769165, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 999944, "time": 31432.251007556915, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 999944, "time": 31432.258019208908, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1000048, "time": 31435.664396762848, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 1000064, "time": 31437.083191156387, "eval_episode/length": 44.0, "eval_episode/score": 0.862500011920929, "eval_episode/reward_rate": 0.022222222222222223}
{"step": 1000064, "time": 31437.86159014702, "eval_episode/length": 39.0, "eval_episode/score": 0.878125011920929, "eval_episode/reward_rate": 0.025}
{"step": 1000064, "time": 31438.19473361969, "eval_episode/length": 100.0, "eval_episode/score": 0.6875, "eval_episode/reward_rate": 0.009900990099009901}
{"step": 1000064, "time": 31438.26381778717, "eval_episode/length": 103.0, "eval_episode/score": 0.6781250238418579, "eval_episode/reward_rate": 0.009615384615384616}
{"step": 1000064, "time": 31438.80061340332, "eval_episode/length": 130.0, "eval_episode/score": 0.59375, "eval_episode/reward_rate": 0.007633587786259542}
{"step": 1000064, "time": 31439.399834156036, "eval_episode/length": 59.0, "eval_episode/score": 0.815625011920929, "eval_episode/reward_rate": 0.016666666666666666}
{"step": 1000064, "time": 31440.241950035095, "eval_episode/length": 120.0, "eval_episode/score": 0.625, "eval_episode/reward_rate": 0.008264462809917356}
{"step": 1000064, "time": 31440.396448612213, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 1000176, "time": 31443.799796819687, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1000272, "time": 31446.840613126755, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 1000296, "time": 31447.352129220963, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1000416, "time": 31451.186089992523, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1001096, "time": 31471.710023403168, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1001184, "time": 31474.60532593727, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 1001216, "time": 31475.577164411545, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1001384, "time": 31480.634848833084, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1001488, "time": 31484.059953689575, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 1001696, "time": 31490.384486436844, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 1001728, "time": 31491.378155469894, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 1002016, "time": 31500.111352205276, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 1002104, "time": 31502.592270374298, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1002128, "time": 31503.553119421005, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1002256, "time": 31507.545170545578, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1002336, "time": 31509.96836209297, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1002344, "time": 31509.99718761444, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1002608, "time": 31518.228260040283, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1002984, "time": 31529.391892910004, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1003008, "time": 31530.358018875122, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1003176, "time": 31535.236369132996, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1003176, "time": 31535.246063232422, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1003432, "time": 31543.15446138382, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1003600, "time": 31548.517376184464, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 1003696, "time": 31551.444138288498, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1003888, "time": 31557.30062007904, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1003944, "time": 31558.786227941513, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1004008, "time": 31560.749526023865, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1004256, "time": 31568.744150161743, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1004328, "time": 31570.728904485703, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1004528, "time": 31577.069928884506, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1004632, "time": 31580.09031677246, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1004848, "time": 31586.92096042633, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1005088, "time": 31594.24792432785, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1005248, "time": 31599.294076919556, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1005272, "time": 31599.818012475967, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1005320, "time": 31601.30059838295, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1005368, "time": 31602.761360168457, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1005432, "time": 31604.72763299942, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1005488, "time": 31606.675990343094, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1005960, "time": 31620.88306093216, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1006016, "time": 31622.814781427383, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1006056, "time": 31623.831232070923, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1006120, "time": 31625.788662195206, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1006184, "time": 31627.860144853592, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1006320, "time": 31632.239844322205, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1006624, "time": 31641.466383218765, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1006784, "time": 31646.3318502903, "episode/length": 211.0, "episode/score": 0.34062498807907104, "episode/reward_rate": 0.0047169811320754715, "episode/intrinsic_return": 0.0}
{"step": 1006840, "time": 31647.837638378143, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1006952, "time": 31651.240097284317, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1007392, "time": 31664.938652038574, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1007464, "time": 31666.90941786766, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1007608, "time": 31671.309846401215, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1007608, "time": 31671.319128513336, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1007992, "time": 31683.541227579117, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1008272, "time": 31692.36780142784, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1008328, "time": 31693.858483314514, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1008448, "time": 31697.815177679062, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1008496, "time": 31699.306418418884, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1008624, "time": 31703.245483398438, "episode/length": 287.0, "episode/score": 0.10312499850988388, "episode/reward_rate": 0.003472222222222222, "episode/intrinsic_return": 0.0}
{"step": 1008696, "time": 31705.20854663849, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1009032, "time": 31715.428473711014, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1009200, "time": 31720.88787126541, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1009264, "time": 31722.848379135132, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1009264, "time": 31722.85829949379, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1009344, "time": 31725.285244464874, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1009472, "time": 31729.185798168182, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1009704, "time": 31736.02913594246, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1010048, "time": 31746.866207122803, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1010048, "time": 31748.759340524673, "eval_episode/length": 96.0, "eval_episode/score": 0.699999988079071, "eval_episode/reward_rate": 0.010309278350515464}
{"step": 1010048, "time": 31749.055120944977, "eval_episode/length": 111.0, "eval_episode/score": 0.653124988079071, "eval_episode/reward_rate": 0.008928571428571428}
{"step": 1010048, "time": 31749.13804292679, "eval_episode/length": 115.0, "eval_episode/score": 0.640625, "eval_episode/reward_rate": 0.008620689655172414}
{"step": 1010048, "time": 31749.20189189911, "eval_episode/length": 118.0, "eval_episode/score": 0.6312500238418579, "eval_episode/reward_rate": 0.008403361344537815}
{"step": 1010048, "time": 31749.444781780243, "eval_episode/length": 130.0, "eval_episode/score": 0.59375, "eval_episode/reward_rate": 0.007633587786259542}
{"step": 1010048, "time": 31750.910900831223, "eval_episode/length": 58.0, "eval_episode/score": 0.8187500238418579, "eval_episode/reward_rate": 0.01694915254237288}
{"step": 1010048, "time": 31751.538738250732, "eval_episode/length": 75.0, "eval_episode/score": 0.765625, "eval_episode/reward_rate": 0.013157894736842105}
{"step": 1010048, "time": 31751.818489074707, "eval_episode/length": 108.0, "eval_episode/score": 0.6625000238418579, "eval_episode/reward_rate": 0.009174311926605505}
{"step": 1010304, "time": 31759.591096401215, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1010336, "time": 31760.56258702278, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1010560, "time": 31767.383281707764, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1010760, "time": 31773.252934217453, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 1011008, "time": 31781.211367607117, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1011200, "time": 31787.043486833572, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1011200, "time": 31787.052608013153, "episode/length": 241.0, "episode/score": 0.24687500298023224, "episode/reward_rate": 0.004132231404958678, "episode/intrinsic_return": 0.0}
{"step": 1011576, "time": 31798.298957824707, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1011600, "time": 31799.25158572197, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1012016, "time": 31811.978911161423, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1012360, "time": 31822.21026444435, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1012456, "time": 31825.142327070236, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 1012552, "time": 31828.06943297386, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1012616, "time": 31830.045334100723, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1012648, "time": 31831.023176908493, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1012848, "time": 31837.452578783035, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1013104, "time": 31845.282955408096, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1013376, "time": 31853.514934539795, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1013512, "time": 31857.436549425125, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1013608, "time": 31860.371943473816, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1013680, "time": 31862.789125680923, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1013768, "time": 31865.263176202774, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1014088, "time": 31875.157789468765, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1014480, "time": 31887.414710760117, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1014728, "time": 31894.71679210663, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1014768, "time": 31896.152129888535, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1014768, "time": 31896.15993142128, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1014872, "time": 31899.24197459221, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1014984, "time": 31902.62624168396, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 1015160, "time": 31907.966121435165, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1015416, "time": 31915.709852218628, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1015440, "time": 31916.65854883194, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1015528, "time": 31919.101914167404, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1015664, "time": 31923.43593430519, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1015688, "time": 31923.946428775787, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1015800, "time": 31927.438215255737, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1015872, "time": 31930.29781293869, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1016008, "time": 31934.20768046379, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1016120, "time": 31937.618955373764, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1016216, "time": 31940.533081531525, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1016528, "time": 31950.204236745834, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1016856, "time": 31960.191069841385, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1016920, "time": 31962.15278196335, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1017040, "time": 31966.002930641174, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1017240, "time": 31971.86452126503, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1017296, "time": 31973.773889780045, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1017576, "time": 31982.044608831406, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1017784, "time": 31988.459087610245, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1017840, "time": 31990.37893295288, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1017928, "time": 31992.834341049194, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1018024, "time": 31995.767226696014, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1018128, "time": 31999.143862485886, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1018144, "time": 31999.635828971863, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1018320, "time": 32004.96927213669, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1018632, "time": 32014.237010240555, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1018648, "time": 32014.727259397507, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1018824, "time": 32020.190964460373, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1018832, "time": 32020.678762197495, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1019168, "time": 32030.838793754578, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 1019224, "time": 32032.31029009819, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1019232, "time": 32032.777800798416, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1019392, "time": 32037.62943959236, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 1019600, "time": 32043.930810451508, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1019624, "time": 32044.438937425613, "episode/length": 199.0, "episode/score": 0.37812501192092896, "episode/reward_rate": 0.005, "episode/intrinsic_return": 0.0}
{"step": 1019728, "time": 32047.9058740139, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 1019960, "time": 32054.708997488022, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1020032, "time": 32058.11889052391, "eval_episode/length": 54.0, "eval_episode/score": 0.831250011920929, "eval_episode/reward_rate": 0.01818181818181818}
{"step": 1020032, "time": 32058.737728834152, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 1020032, "time": 32058.93611550331, "eval_episode/length": 41.0, "eval_episode/score": 0.871874988079071, "eval_episode/reward_rate": 0.023809523809523808}
{"step": 1020032, "time": 32059.116276979446, "eval_episode/length": 105.0, "eval_episode/score": 0.671875, "eval_episode/reward_rate": 0.009433962264150943}
{"step": 1020032, "time": 32059.307060956955, "eval_episode/length": 115.0, "eval_episode/score": 0.640625, "eval_episode/reward_rate": 0.008620689655172414}
{"step": 1020032, "time": 32059.525002241135, "eval_episode/length": 126.0, "eval_episode/score": 0.606249988079071, "eval_episode/reward_rate": 0.007874015748031496}
{"step": 1020032, "time": 32060.127588033676, "eval_episode/length": 41.0, "eval_episode/score": 0.871874988079071, "eval_episode/reward_rate": 0.023809523809523808}
{"step": 1020032, "time": 32060.478664159775, "eval_episode/length": 176.0, "eval_episode/score": 0.44999998807907104, "eval_episode/reward_rate": 0.005649717514124294}
{"step": 1020232, "time": 32066.301021814346, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1020288, "time": 32068.22592163086, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1020448, "time": 32073.060942411423, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1020624, "time": 32078.485046863556, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1020840, "time": 32084.795231103897, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 1020944, "time": 32088.171053409576, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1020960, "time": 32088.662135839462, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1021368, "time": 32100.747757434845, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1021480, "time": 32104.15119624138, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1021504, "time": 32105.099949359894, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1021640, "time": 32109.10151410103, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1021784, "time": 32113.479771137238, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 1021912, "time": 32117.37718963623, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1021936, "time": 32118.333713531494, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1022360, "time": 32130.97824573517, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1022408, "time": 32132.435258626938, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1022504, "time": 32135.339512586594, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1022544, "time": 32136.882180452347, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1022576, "time": 32137.849272966385, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 1022600, "time": 32138.356674671173, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1022752, "time": 32143.174976348877, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1022776, "time": 32143.681640148163, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1022792, "time": 32144.176805496216, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1022856, "time": 32146.128044605255, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 1023520, "time": 32166.547864437103, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1023616, "time": 32169.50663113594, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1023664, "time": 32170.98315358162, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1023680, "time": 32171.473685741425, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1023720, "time": 32172.465742349625, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1023880, "time": 32177.303052425385, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1024216, "time": 32187.904184103012, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 1024376, "time": 32192.72128844261, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1024568, "time": 32198.593670368195, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1024568, "time": 32198.6015086174, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1024584, "time": 32199.089779376984, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1024720, "time": 32203.428768396378, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1024800, "time": 32205.87373495102, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1024816, "time": 32206.361075639725, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1025304, "time": 32220.85337305069, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1025352, "time": 32222.29555630684, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1025416, "time": 32224.239402770996, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1025488, "time": 32226.790025234222, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1025912, "time": 32239.376306056976, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1025928, "time": 32239.87188768387, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1026184, "time": 32247.59386062622, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 1026328, "time": 32251.954396009445, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1026336, "time": 32252.41856431961, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1026729, "time": 32265.17892050743, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.553296381884282, "train/action_min": 0.0, "train/action_std": 1.7361009138645511, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.010617492101524063, "train/actor_opt_grad_steps": 63065.0, "train/actor_opt_loss": -20.192618034853794, "train/adv_mag": 0.8890129693663946, "train/adv_max": 0.4092440375007025, "train/adv_mean": 0.00026235331780740263, "train/adv_min": -0.7909029137970197, "train/adv_std": 0.026299569801897696, "train/cont_avg": 0.9940584390470297, "train/cont_loss_mean": 0.0216849389887129, "train/cont_loss_std": 0.2606314698437063, "train/cont_neg_acc": 0.24841127463496557, "train/cont_neg_loss": 2.915090621698021, "train/cont_pos_acc": 0.9998833973809044, "train/cont_pos_loss": 0.00449086814694623, "train/cont_pred": 0.9940713177813162, "train/cont_rate": 0.9940584390470297, "train/dyn_loss_mean": 1.0000015249346743, "train/dyn_loss_std": 4.8772090732461156e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.10427525573142685, "train/extr_critic_critic_opt_grad_steps": 63065.0, "train/extr_critic_critic_opt_loss": 10502.636244972153, "train/extr_critic_mag": 1.6027427545868524, "train/extr_critic_max": 1.6027427545868524, "train/extr_critic_mean": 1.4762266921524954, "train/extr_critic_min": 0.9080674270592114, "train/extr_critic_std": 0.03142038490254395, "train/extr_return_normed_mag": 0.9555629143620482, "train/extr_return_normed_max": 0.28053087173121993, "train/extr_return_normed_mean": 0.05886323418062512, "train/extr_return_normed_min": -0.8705272727673596, "train/extr_return_normed_std": 0.04170411827946358, "train/extr_return_rate": 0.9996741912742653, "train/extr_return_raw_mag": 1.6981566418515575, "train/extr_return_raw_max": 1.6981566418515575, "train/extr_return_raw_mean": 1.4764890889130016, "train/extr_return_raw_min": 0.5470984973529778, "train/extr_return_raw_std": 0.04170411832556866, "train/extr_reward_mag": 0.23515525017634475, "train/extr_reward_max": 0.23515525017634475, "train/extr_reward_mean": 0.0021804941715534297, "train/extr_reward_min": 1.6819132436620126e-07, "train/extr_reward_std": 0.007937938475169905, "train/image_loss_mean": 0.08288876339793205, "train/image_loss_std": 0.09926856135820399, "train/model_loss_mean": 0.7230772966205483, "train/model_loss_std": 0.5163867451840698, "train/model_opt_grad_norm": 16.985887459009, "train/model_opt_grad_steps": 63008.153465346535, "train/model_opt_loss": 4400.891431147509, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 6089.108910891089, "train/policy_entropy_mag": 1.326141636560459, "train/policy_entropy_max": 1.326141636560459, "train/policy_entropy_mean": 0.0962338230692514, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.12106222485994349, "train/policy_logprob_mag": 6.5510802528645735, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09639539414703256, "train/policy_logprob_min": -6.5510802528645735, "train/policy_logprob_std": 0.634840998319116, "train/policy_randomness_mag": 0.6815020288571273, "train/policy_randomness_max": 0.6815020288571273, "train/policy_randomness_mean": 0.0494544041149392, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.06221368019976238, "train/post_ent_mag": 28.30668105701409, "train/post_ent_max": 28.30668105701409, "train/post_ent_mean": 27.732830991839418, "train/post_ent_min": 27.240312481870745, "train/post_ent_std": 0.23524272655791575, "train/prior_ent_mag": 27.90446644018192, "train/prior_ent_max": 27.90446644018192, "train/prior_ent_mean": 27.205291398681037, "train/prior_ent_min": 26.288090715313903, "train/prior_ent_std": 0.2591028053424146, "train/rep_loss_mean": 1.0000015249346743, "train/rep_loss_std": 4.8772090732461156e-05, "train/reward_avg": 0.0025791734682354558, "train/reward_loss_mean": 0.01850265468641341, "train/reward_loss_std": 0.25466923894692617, "train/reward_max_data": 0.7886912139630554, "train/reward_max_pred": 0.3046080688438793, "train/reward_neg_acc": 0.9996748838094202, "train/reward_neg_loss": 0.003208359762205567, "train/reward_pos_acc": 0.15494027809061187, "train/reward_pos_loss": 4.049436151379287, "train/reward_pred": 0.001995243710156825, "train/reward_rate": 0.003775719368811881, "train_stats/mean_log_entropy": 0.07966518003655516, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.014711870811879635, "report/cont_loss_std": 0.17368100583553314, "report/cont_neg_acc": 0.3333333432674408, "report/cont_neg_loss": 2.750756025314331, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.006672564893960953, "report/cont_pred": 0.9928977489471436, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.07061126828193665, "report/image_loss_std": 0.08524452894926071, "report/model_loss_mean": 0.6960216760635376, "report/model_loss_std": 0.3033236861228943, "report/post_ent_mag": 28.28571891784668, "report/post_ent_max": 28.28571891784668, "report/post_ent_mean": 27.78417205810547, "report/post_ent_min": 27.357236862182617, "report/post_ent_std": 0.19826219975948334, "report/prior_ent_mag": 27.80246353149414, "report/prior_ent_max": 27.80246353149414, "report/prior_ent_mean": 27.15475082397461, "report/prior_ent_min": 26.298076629638672, "report/prior_ent_std": 0.2332661896944046, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0016021728515625, "report/reward_loss_mean": 0.01069855410605669, "report/reward_loss_std": 0.1375059336423874, "report/reward_max_data": 0.859375, "report/reward_max_pred": 0.303302526473999, "report/reward_neg_acc": 0.9990215301513672, "report/reward_neg_loss": 0.005326226353645325, "report/reward_pos_acc": 0.5, "report/reward_pos_loss": 2.755958080291748, "report/reward_pred": 0.0029387411195784807, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.017649374902248383, "eval/cont_loss_std": 0.2690078318119049, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 4.558259963989258, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.004307718947529793, "eval/cont_pred": 0.9957014322280884, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.10836825519800186, "eval/image_loss_std": 0.1290939599275589, "eval/model_loss_mean": 0.7368396520614624, "eval/model_loss_std": 0.43432560563087463, "eval/post_ent_mag": 28.279407501220703, "eval/post_ent_max": 28.279407501220703, "eval/post_ent_mean": 27.71656608581543, "eval/post_ent_min": 27.32320213317871, "eval/post_ent_std": 0.21064482629299164, "eval/prior_ent_mag": 27.883155822753906, "eval/prior_ent_max": 27.883155822753906, "eval/prior_ent_mean": 27.113765716552734, "eval/prior_ent_min": 26.21379852294922, "eval/prior_ent_std": 0.25143176317214966, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0015533447731286287, "eval/reward_loss_mean": 0.01082197017967701, "eval/reward_loss_std": 0.18723024427890778, "eval/reward_max_data": 0.8062499761581421, "eval/reward_max_pred": 0.07203936576843262, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.002558507490903139, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 4.233450889587402, "eval/reward_pred": 0.0013438635505735874, "eval/reward_rate": 0.001953125, "replay/size": 1000000.0, "replay/inserts": 32240.0, "replay/samples": 32240.0, "replay/insert_wait_avg": 1.323326645654721e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.551047990103218e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4896.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1544991162867328e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0728836059570312e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2560813426971, "timer/env.step_count": 4030.0, "timer/env.step_total": 39.831512689590454, "timer/env.step_frac": 0.039821315193727676, "timer/env.step_avg": 0.009883750047044778, "timer/env.step_min": 0.007836103439331055, "timer/env.step_max": 0.05318808555603027, "timer/replay._sample_count": 32240.0, "timer/replay._sample_total": 16.990439414978027, "timer/replay._sample_frac": 0.016986089594347532, "timer/replay._sample_avg": 0.0005269987411593681, "timer/replay._sample_min": 0.00041103363037109375, "timer/replay._sample_max": 0.025099754333496094, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4642.0, "timer/agent.policy_total": 50.12388515472412, "timer/agent.policy_frac": 0.05011105264907778, "timer/agent.policy_avg": 0.010797907185420966, "timer/agent.policy_min": 0.009067535400390625, "timer/agent.policy_max": 0.09627699851989746, "timer/dataset_train_count": 2015.0, "timer/dataset_train_total": 0.23391127586364746, "timer/dataset_train_frac": 0.0002338513908854779, "timer/dataset_train_avg": 0.00011608500042860916, "timer/dataset_train_min": 0.00010180473327636719, "timer/dataset_train_max": 0.000957489013671875, "timer/agent.train_count": 2015.0, "timer/agent.train_total": 897.8938920497894, "timer/agent.train_frac": 0.8976640170430141, "timer/agent.train_avg": 0.44560490920585083, "timer/agent.train_min": 0.4317350387573242, "timer/agent.train_max": 0.8318557739257812, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4792296886444092, "timer/agent.report_frac": 0.00047910699828099376, "timer/agent.report_avg": 0.2396148443222046, "timer/agent.report_min": 0.2308948040008545, "timer/agent.report_max": 0.2483348846435547, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.266334533691406e-05, "timer/dataset_eval_frac": 3.2654983005020386e-08, "timer/dataset_eval_avg": 3.266334533691406e-05, "timer/dataset_eval_min": 3.266334533691406e-05, "timer/dataset_eval_max": 3.266334533691406e-05, "fps": 32.23119135589995}
{"step": 1026800, "time": 32267.298516750336, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1026808, "time": 32267.327525377274, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 1026880, "time": 32269.736546754837, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1027160, "time": 32277.996464014053, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1027296, "time": 32282.310603618622, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1027528, "time": 32289.254173517227, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1027664, "time": 32293.589393138885, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1027712, "time": 32295.056713104248, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1027736, "time": 32295.57595181465, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1027888, "time": 32300.402057647705, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1028120, "time": 32307.219055891037, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1028176, "time": 32309.139122247696, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1028240, "time": 32311.082953214645, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1028280, "time": 32312.09870839119, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 1028496, "time": 32318.989346265793, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1028552, "time": 32320.47048521042, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1028584, "time": 32321.453402996063, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1028680, "time": 32324.3768222332, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1028848, "time": 32329.720898866653, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1028872, "time": 32330.23221206665, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1029280, "time": 32342.820649147034, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1029392, "time": 32346.2151055336, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1029400, "time": 32346.24291396141, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1029472, "time": 32348.74171590805, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1029672, "time": 32354.62046098709, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 1030016, "time": 32366.73166537285, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 1030016, "time": 32367.04878926277, "eval_episode/length": 100.0, "eval_episode/score": 0.6875, "eval_episode/reward_rate": 0.009900990099009901}
{"step": 1030016, "time": 32367.19497537613, "eval_episode/length": 108.0, "eval_episode/score": 0.6625000238418579, "eval_episode/reward_rate": 0.009174311926605505}
{"step": 1030016, "time": 32367.273784399033, "eval_episode/length": 112.0, "eval_episode/score": 0.6499999761581421, "eval_episode/reward_rate": 0.008849557522123894}
{"step": 1030016, "time": 32367.73145699501, "eval_episode/length": 137.0, "eval_episode/score": 0.5718749761581421, "eval_episode/reward_rate": 0.007246376811594203}
{"step": 1030016, "time": 32367.755921840668, "eval_episode/length": 138.0, "eval_episode/score": 0.5687500238418579, "eval_episode/reward_rate": 0.007194244604316547}
{"step": 1030016, "time": 32368.657782554626, "eval_episode/length": 88.0, "eval_episode/score": 0.7250000238418579, "eval_episode/reward_rate": 0.011235955056179775}
{"step": 1030016, "time": 32368.961818933487, "eval_episode/length": 97.0, "eval_episode/score": 0.6968749761581421, "eval_episode/reward_rate": 0.01020408163265306}
{"step": 1030024, "time": 32368.987157344818, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1030088, "time": 32370.93009519577, "episode/length": 187.0, "episode/score": 0.4156250059604645, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.0}
{"step": 1030176, "time": 32373.800492048264, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1030328, "time": 32378.282123327255, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1030552, "time": 32385.081845760345, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1030792, "time": 32392.33678841591, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1030808, "time": 32392.829837799072, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1030904, "time": 32395.733824968338, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1031000, "time": 32398.63565158844, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1031008, "time": 32399.099889039993, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1031160, "time": 32403.473752498627, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1031304, "time": 32407.910791158676, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1031368, "time": 32409.859404563904, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 1031616, "time": 32417.558687210083, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1031712, "time": 32420.478098154068, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1031784, "time": 32422.434309482574, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1031824, "time": 32423.88685274124, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1031904, "time": 32426.305828094482, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1031928, "time": 32426.816480636597, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1032040, "time": 32430.21362733841, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1032312, "time": 32439.019449710846, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1032400, "time": 32441.92032980919, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1032624, "time": 32448.76786160469, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 1032712, "time": 32451.213893413544, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 1032712, "time": 32451.219833135605, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1032760, "time": 32452.70369195938, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1032832, "time": 32455.097738981247, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1033000, "time": 32459.982878684998, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1033216, "time": 32466.882407426834, "episode/length": 187.0, "episode/score": 0.4156250059604645, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.0}
{"step": 1033336, "time": 32470.31606054306, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1033432, "time": 32473.23937177658, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1033560, "time": 32477.14470601082, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1033680, "time": 32480.999240636826, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1033752, "time": 32482.99361038208, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1033976, "time": 32489.803379774094, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1034136, "time": 32494.640242099762, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1034216, "time": 32497.15888619423, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1034232, "time": 32497.6507999897, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1034376, "time": 32502.01783323288, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1035256, "time": 32528.78044939041, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1035744, "time": 32543.783984184265, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1035992, "time": 32551.084983587265, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1036064, "time": 32553.487721681595, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1036280, "time": 32559.89171743393, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1036288, "time": 32560.361899852753, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1036432, "time": 32564.714902162552, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1036448, "time": 32565.199373483658, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1036544, "time": 32568.09869337082, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1036688, "time": 32572.463738441467, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1036736, "time": 32573.90714430809, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1037200, "time": 32588.00898194313, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1037312, "time": 32591.40168404579, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1037448, "time": 32595.347279548645, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1037520, "time": 32597.758388519287, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1037680, "time": 32602.618065595627, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 1037784, "time": 32605.564016342163, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1038304, "time": 32621.675548553467, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1038376, "time": 32623.651428461075, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1038600, "time": 32630.441443920135, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1038720, "time": 32634.310546875, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1038944, "time": 32641.098123788834, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 1039048, "time": 32644.034556627274, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1039088, "time": 32645.46835708618, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1039328, "time": 32652.884208917618, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1039528, "time": 32658.723714351654, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1039552, "time": 32659.673816919327, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1039624, "time": 32661.645885944366, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1040000, "time": 32674.48094201088, "eval_episode/length": 63.0, "eval_episode/score": 0.8031250238418579, "eval_episode/reward_rate": 0.015625}
{"step": 1040000, "time": 32674.714631557465, "eval_episode/length": 75.0, "eval_episode/score": 0.765625, "eval_episode/reward_rate": 0.013157894736842105}
{"step": 1040000, "time": 32674.87881708145, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 1040000, "time": 32674.983789920807, "eval_episode/length": 88.0, "eval_episode/score": 0.7250000238418579, "eval_episode/reward_rate": 0.011235955056179775}
{"step": 1040000, "time": 32675.048149824142, "eval_episode/length": 91.0, "eval_episode/score": 0.715624988079071, "eval_episode/reward_rate": 0.010869565217391304}
{"step": 1040000, "time": 32675.473989486694, "eval_episode/length": 114.0, "eval_episode/score": 0.643750011920929, "eval_episode/reward_rate": 0.008695652173913044}
{"step": 1040000, "time": 32676.322092056274, "eval_episode/length": 95.0, "eval_episode/score": 0.703125, "eval_episode/reward_rate": 0.010416666666666666}
{"step": 1040000, "time": 32676.763518571854, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 1040096, "time": 32679.667681217194, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1040136, "time": 32680.681158065796, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1040272, "time": 32685.020092248917, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1040336, "time": 32686.956119537354, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1040528, "time": 32693.227798461914, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 1040536, "time": 32693.254726409912, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1040616, "time": 32695.689564704895, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1041168, "time": 32712.71472454071, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1041400, "time": 32719.530993938446, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1041496, "time": 32722.43221092224, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1041696, "time": 32728.690695285797, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 1041864, "time": 32733.55243229866, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1041976, "time": 32737.072111845016, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1042120, "time": 32741.43796491623, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 1042216, "time": 32744.358063220978, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1042408, "time": 32750.200974225998, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1042648, "time": 32757.46636891365, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1042704, "time": 32759.41860628128, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 1042808, "time": 32762.400130033493, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1042928, "time": 32766.275528669357, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1043008, "time": 32768.82119035721, "episode/length": 229.0, "episode/score": 0.28437501192092896, "episode/reward_rate": 0.004347826086956522, "episode/intrinsic_return": 0.0}
{"step": 1043312, "time": 32778.04943609238, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1043456, "time": 32782.405007362366, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 1043824, "time": 32793.568507671356, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 1043968, "time": 32798.01231265068, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1044176, "time": 32804.27800965309, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1044296, "time": 32807.697521448135, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1044544, "time": 32815.398060798645, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 1044744, "time": 32821.22921156883, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1045016, "time": 32829.6051967144, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1045024, "time": 32830.07168483734, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1045080, "time": 32831.56573343277, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 1045120, "time": 32833.00254583359, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1045320, "time": 32838.82479476929, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1045592, "time": 32847.04075336456, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1045768, "time": 32852.34713053703, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1046184, "time": 32865.036125183105, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1046256, "time": 32867.4459939003, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1046280, "time": 32867.952028274536, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1046488, "time": 32874.26192998886, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1046568, "time": 32876.70012950897, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1046672, "time": 32880.09752035141, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1047008, "time": 32890.413893938065, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1047216, "time": 32896.75228762627, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1047328, "time": 32900.154554605484, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1047336, "time": 32900.18528819084, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1047560, "time": 32906.99506187439, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1047712, "time": 32911.83587098122, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1047904, "time": 32917.766870737076, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1047968, "time": 32919.73966550827, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 1048016, "time": 32921.19589972496, "episode/length": 219.0, "episode/score": 0.31562501192092896, "episode/reward_rate": 0.004545454545454545, "episode/intrinsic_return": 0.0}
{"step": 1048408, "time": 32932.84836983681, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1048624, "time": 32940.08705043793, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 1048696, "time": 32942.04319047928, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 1048768, "time": 32944.44413232803, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1049064, "time": 32953.26515460014, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1049168, "time": 32956.668176651, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1049224, "time": 32958.14344286919, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 1049320, "time": 32961.07604146004, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1049424, "time": 32964.45942187309, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 1049448, "time": 32964.96773505211, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1049728, "time": 32973.778049468994, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 1049784, "time": 32975.25670647621, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 1049872, "time": 32978.28995847702, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1050088, "time": 32984.60999941826, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 1050088, "time": 32986.3350815773, "eval_episode/length": 90.0, "eval_episode/score": 0.71875, "eval_episode/reward_rate": 0.01098901098901099}
{"step": 1050088, "time": 32987.03845047951, "eval_episode/length": 127.0, "eval_episode/score": 0.6031249761581421, "eval_episode/reward_rate": 0.0078125}
{"step": 1050088, "time": 32987.19001555443, "eval_episode/length": 135.0, "eval_episode/score": 0.578125, "eval_episode/reward_rate": 0.007352941176470588}
{"step": 1050088, "time": 32987.342886686325, "eval_episode/length": 143.0, "eval_episode/score": 0.5531250238418579, "eval_episode/reward_rate": 0.006944444444444444}
{"step": 1050088, "time": 32987.49783658981, "eval_episode/length": 151.0, "eval_episode/score": 0.528124988079071, "eval_episode/reward_rate": 0.006578947368421052}
{"step": 1050088, "time": 32987.6322658062, "eval_episode/length": 158.0, "eval_episode/score": 0.5062500238418579, "eval_episode/reward_rate": 0.006289308176100629}
{"step": 1050088, "time": 32989.06348156929, "eval_episode/length": 109.0, "eval_episode/score": 0.659375011920929, "eval_episode/reward_rate": 0.00909090909090909}
{"step": 1050088, "time": 32989.845028162, "eval_episode/length": 136.0, "eval_episode/score": 0.574999988079071, "eval_episode/reward_rate": 0.0072992700729927005}
{"step": 1050160, "time": 32992.2264111042, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1050184, "time": 32992.735620975494, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1050328, "time": 32997.09362244606, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1050496, "time": 33002.4031829834, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1051072, "time": 33019.93124985695, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1051208, "time": 33023.84267449379, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1051272, "time": 33025.771813869476, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1051296, "time": 33026.71644425392, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1051480, "time": 33032.08024549484, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1051544, "time": 33034.01191186905, "episode/length": 208.0, "episode/score": 0.3499999940395355, "episode/reward_rate": 0.004784688995215311, "episode/intrinsic_return": 0.0}
{"step": 1051728, "time": 33039.872525930405, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1052096, "time": 33050.98983454704, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1052096, "time": 33050.99782896042, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1052104, "time": 33051.029733181, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1052112, "time": 33051.51994609833, "episode/length": 201.0, "episode/score": 0.37187498807907104, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.0}
{"step": 1052424, "time": 33060.739941358566, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1052616, "time": 33066.67133498192, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1053144, "time": 33082.7026822567, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1053520, "time": 33094.30145359039, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1053680, "time": 33099.25497674942, "episode/length": 197.0, "episode/score": 0.3843750059604645, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.0}
{"step": 1053752, "time": 33101.25102901459, "episode/length": 206.0, "episode/score": 0.35624998807907104, "episode/reward_rate": 0.004830917874396135, "episode/intrinsic_return": 0.0}
{"step": 1053856, "time": 33104.617674827576, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1054184, "time": 33114.32561969757, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1054192, "time": 33114.81372857094, "episode/length": 196.0, "episode/score": 0.38749998807907104, "episode/reward_rate": 0.005076142131979695, "episode/intrinsic_return": 0.0}
{"step": 1054376, "time": 33120.14902639389, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1054416, "time": 33121.57750606537, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1054424, "time": 33121.60689544678, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1054720, "time": 33130.88102197647, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1055112, "time": 33142.50270652771, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1055272, "time": 33147.328255176544, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1055456, "time": 33153.12582039833, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1055648, "time": 33159.02122735977, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 1055832, "time": 33164.37963652611, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1055888, "time": 33166.28871202469, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1055896, "time": 33166.31653499603, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1056168, "time": 33174.64546227455, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1056392, "time": 33181.424570798874, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1056512, "time": 33185.27777194977, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1056664, "time": 33189.76860117912, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1056736, "time": 33192.177344083786, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1057032, "time": 33201.474411726, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1057200, "time": 33206.77724266052, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 1057272, "time": 33208.737986564636, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1057280, "time": 33209.204026699066, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1057344, "time": 33211.14617085457, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1057768, "time": 33223.85643911362, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1057944, "time": 33229.176847696304, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1058320, "time": 33240.78646349907, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1058424, "time": 33243.718202114105, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1058480, "time": 33245.63013482094, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1058504, "time": 33246.13766860962, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0}
{"step": 1058704, "time": 33252.52768731117, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1058720, "time": 33253.013402700424, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 1058776, "time": 33254.485258340836, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1059048, "time": 33262.71173477173, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1059097, "time": 33265.36164331436, "train_stats/mean_log_entropy": 0.08423177764382002, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.542930980720142, "train/action_min": 0.0, "train/action_std": 1.6757559233372754, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.012102809219418259, "train/actor_opt_grad_steps": 65085.0, "train/actor_opt_loss": -21.04556080610445, "train/adv_mag": 0.9097936835029338, "train/adv_max": 0.4277669917238821, "train/adv_mean": 0.002062800985294245, "train/adv_min": -0.806375122011298, "train/adv_std": 0.03003765738541537, "train/cont_avg": 0.9940245977722773, "train/cont_loss_mean": 0.02313451482315022, "train/cont_loss_std": 0.2678652329757662, "train/cont_neg_acc": 0.2140734311894025, "train/cont_neg_loss": 3.0219838371371277, "train/cont_pos_acc": 0.999849278147858, "train/cont_pos_loss": 0.005028402858118683, "train/cont_pred": 0.993829991852883, "train/cont_rate": 0.9940245977722773, "train/dyn_loss_mean": 1.0000020902935822, "train/dyn_loss_std": 5.0114673916204364e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.1387904119945251, "train/extr_critic_critic_opt_grad_steps": 65085.0, "train/extr_critic_critic_opt_loss": 7598.2428280669865, "train/extr_critic_mag": 1.6361001139820213, "train/extr_critic_max": 1.6361001139820213, "train/extr_critic_mean": 1.51923134657416, "train/extr_critic_min": 1.002450992565344, "train/extr_critic_std": 0.031506594030721355, "train/extr_return_normed_mag": 0.9725841212980818, "train/extr_return_normed_max": 0.3174394746818165, "train/extr_return_normed_mean": 0.06306390602621112, "train/extr_return_normed_min": -0.8754563650282303, "train/extr_return_normed_std": 0.04489690032188255, "train/extr_return_rate": 0.9996909499168396, "train/extr_return_raw_mag": 1.7756696603085735, "train/extr_return_raw_max": 1.7756696603085735, "train/extr_return_raw_mean": 1.5212941606446069, "train/extr_return_raw_min": 0.5827738205985268, "train/extr_return_raw_std": 0.04489690031266153, "train/extr_reward_mag": 0.27761993313779926, "train/extr_reward_max": 0.27761993313779926, "train/extr_reward_mean": 0.00250867519257959, "train/extr_reward_min": 1.5461798941734994e-07, "train/extr_reward_std": 0.010266136995857895, "train/image_loss_mean": 0.08526787410794508, "train/image_loss_std": 0.10146165760879469, "train/model_loss_mean": 0.7284048052117376, "train/model_loss_std": 0.5314814930062483, "train/model_opt_grad_norm": 17.6545673360919, "train/model_opt_grad_steps": 65026.5099009901, "train/model_opt_loss": 3983.976480314047, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5470.297029702971, "train/policy_entropy_mag": 1.3030120559258036, "train/policy_entropy_max": 1.3030120559258036, "train/policy_entropy_mean": 0.0998903799912717, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.12761342057054587, "train/policy_logprob_mag": 6.551080278830953, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09957359141052359, "train/policy_logprob_min": -6.551080278830953, "train/policy_logprob_std": 0.6354735735619422, "train/policy_randomness_mag": 0.6696157750516835, "train/policy_randomness_max": 0.6696157750516835, "train/policy_randomness_mean": 0.05133350348413581, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.0655803291846325, "train/post_ent_mag": 28.32975682173625, "train/post_ent_max": 28.32975682173625, "train/post_ent_mean": 27.794377157003574, "train/post_ent_min": 27.31479301074944, "train/post_ent_std": 0.22292597990224858, "train/prior_ent_mag": 27.911159779765818, "train/prior_ent_max": 27.911159779765818, "train/prior_ent_mean": 27.205303163811713, "train/prior_ent_min": 26.38589386892791, "train/prior_ent_std": 0.23762201812892858, "train/rep_loss_mean": 1.0000020902935822, "train/rep_loss_std": 5.0114673916204364e-05, "train/reward_avg": 0.002745101474442215, "train/reward_loss_mean": 0.02000114045308737, "train/reward_loss_std": 0.2629033547945985, "train/reward_max_data": 0.7989634903940824, "train/reward_max_pred": 0.29925206274089244, "train/reward_neg_acc": 0.9995825851317679, "train/reward_neg_loss": 0.0036663527561277887, "train/reward_pos_acc": 0.14570436742156745, "train/reward_pos_loss": 4.0478738716244695, "train/reward_pred": 0.00218691908533104, "train/reward_rate": 0.00401744275990099, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.016974247992038727, "report/cont_loss_std": 0.19084106385707855, "report/cont_neg_acc": 0.4000000059604645, "report/cont_neg_loss": 2.148721694946289, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.006514251697808504, "report/cont_pred": 0.9919946193695068, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.07725516706705093, "report/image_loss_std": 0.08920782804489136, "report/model_loss_mean": 0.708425760269165, "report/model_loss_std": 0.3457184433937073, "report/post_ent_mag": 27.752395629882812, "report/post_ent_max": 27.752395629882812, "report/post_ent_mean": 27.28532600402832, "report/post_ent_min": 26.824222564697266, "report/post_ent_std": 0.18521153926849365, "report/prior_ent_mag": 27.843982696533203, "report/prior_ent_max": 27.843982696533203, "report/prior_ent_mean": 27.24322509765625, "report/prior_ent_min": 26.47823143005371, "report/prior_ent_std": 0.2279691845178604, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0028747557662427425, "report/reward_loss_mean": 0.014196386560797691, "report/reward_loss_std": 0.16709023714065552, "report/reward_max_data": 0.949999988079071, "report/reward_max_pred": 0.4745755195617676, "report/reward_neg_acc": 0.9999999403953552, "report/reward_neg_loss": 0.005057954229414463, "report/reward_pos_acc": 0.5, "report/reward_pos_loss": 2.344496726989746, "report/reward_pred": 0.0035173005890101194, "report/reward_rate": 0.00390625, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.029509440064430237, "eval/cont_loss_std": 0.31396329402923584, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 4.040230751037598, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.005870611406862736, "eval/cont_pred": 0.9941476583480835, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.12511050701141357, "eval/image_loss_std": 0.12975938618183136, "eval/model_loss_mean": 0.7886183261871338, "eval/model_loss_std": 0.7363036870956421, "eval/post_ent_mag": 27.755359649658203, "eval/post_ent_max": 27.755359649658203, "eval/post_ent_mean": 27.29005241394043, "eval/post_ent_min": 26.831575393676758, "eval/post_ent_std": 0.202738955616951, "eval/prior_ent_mag": 27.93782615661621, "eval/prior_ent_max": 27.93782615661621, "eval/prior_ent_mean": 27.250202178955078, "eval/prior_ent_min": 26.39004135131836, "eval/prior_ent_std": 0.25020796060562134, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.004391479305922985, "eval/reward_loss_mean": 0.03399835154414177, "eval/reward_loss_std": 0.38594385981559753, "eval/reward_max_data": 0.84375, "eval/reward_max_pred": 0.11519753932952881, "eval/reward_neg_acc": 0.9990177154541016, "eval/reward_neg_loss": 0.004816290456801653, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 4.985221862792969, "eval/reward_pred": 0.0025900539476424456, "eval/reward_rate": 0.005859375, "replay/size": 1000000.0, "replay/inserts": 32368.0, "replay/samples": 32368.0, "replay/insert_wait_avg": 1.2708856395960915e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.296772093685676e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5304.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0829525655570972e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.5367431640625e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.014631986618, "timer/env.step_count": 4046.0, "timer/env.step_total": 39.29364490509033, "timer/env.step_frac": 0.03929306996941636, "timer/env.step_avg": 0.009711726372983275, "timer/env.step_min": 0.007714748382568359, "timer/env.step_max": 0.03601646423339844, "timer/replay._sample_count": 32368.0, "timer/replay._sample_total": 16.88588786125183, "timer/replay._sample_frac": 0.016885640790781743, "timer/replay._sample_avg": 0.0005216846225053087, "timer/replay._sample_min": 0.0004227161407470703, "timer/replay._sample_max": 0.0111083984375, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4709.0, "timer/agent.policy_total": 49.728513956069946, "timer/agent.policy_frac": 0.04972778633976568, "timer/agent.policy_avg": 0.010560313008296867, "timer/agent.policy_min": 0.008669376373291016, "timer/agent.policy_max": 0.0763247013092041, "timer/dataset_train_count": 2023.0, "timer/dataset_train_total": 0.23430776596069336, "timer/dataset_train_frac": 0.0002343043376227607, "timer/dataset_train_avg": 0.00011582193077641787, "timer/dataset_train_min": 9.989738464355469e-05, "timer/dataset_train_max": 0.001062631607055664, "timer/agent.train_count": 2023.0, "timer/agent.train_total": 898.8046424388885, "timer/agent.train_frac": 0.898791491333815, "timer/agent.train_avg": 0.44429295226835813, "timer/agent.train_min": 0.4327235221862793, "timer/agent.train_max": 0.6945803165435791, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48230695724487305, "timer/agent.report_frac": 0.00048229990023918685, "timer/agent.report_avg": 0.24115347862243652, "timer/agent.report_min": 0.23164772987365723, "timer/agent.report_max": 0.2506592273712158, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.1948089599609375e-05, "timer/dataset_eval_frac": 3.194762214242971e-08, "timer/dataset_eval_avg": 3.1948089599609375e-05, "timer/dataset_eval_min": 3.1948089599609375e-05, "timer/dataset_eval_max": 3.1948089599609375e-05, "fps": 32.36655634323104}
{"step": 1059104, "time": 33265.39741945267, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 1059512, "time": 33278.00016307831, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1059576, "time": 33279.941793203354, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1059600, "time": 33280.89259266853, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1059792, "time": 33286.7023601532, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 1059832, "time": 33287.68442821503, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1060072, "time": 33295.992628097534, "eval_episode/length": 55.0, "eval_episode/score": 0.828125, "eval_episode/reward_rate": 0.017857142857142856}
{"step": 1060072, "time": 33296.231352329254, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 1060072, "time": 33296.49762177467, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 1060072, "time": 33297.07773113251, "eval_episode/length": 113.0, "eval_episode/score": 0.6468750238418579, "eval_episode/reward_rate": 0.008771929824561403}
{"step": 1060072, "time": 33297.21703124046, "eval_episode/length": 120.0, "eval_episode/score": 0.625, "eval_episode/reward_rate": 0.008264462809917356}
{"step": 1060072, "time": 33298.19588184357, "eval_episode/length": 139.0, "eval_episode/score": 0.565625011920929, "eval_episode/reward_rate": 0.007142857142857143}
{"step": 1060072, "time": 33298.53223347664, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 1060072, "time": 33298.78339552879, "eval_episode/length": 113.0, "eval_episode/score": 0.6468750238418579, "eval_episode/reward_rate": 0.008771929824561403}
{"step": 1060208, "time": 33303.12486195564, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1060448, "time": 33310.48413658142, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1060480, "time": 33311.455105781555, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1060640, "time": 33316.33703684807, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1060792, "time": 33320.75587487221, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1060904, "time": 33324.1418762207, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 1061016, "time": 33327.57386612892, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1061032, "time": 33328.0637152195, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1061168, "time": 33332.41196632385, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1061216, "time": 33333.85887360573, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1061488, "time": 33342.174275398254, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1061592, "time": 33345.119348049164, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1061600, "time": 33345.59379673004, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1061792, "time": 33351.51054215431, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 1061976, "time": 33356.87233662605, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1062000, "time": 33357.81821012497, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 1062040, "time": 33358.82858777046, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1062072, "time": 33359.80853652954, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1062392, "time": 33369.55299401283, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1062504, "time": 33372.94185233116, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1062600, "time": 33375.860354185104, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1062688, "time": 33378.76026773453, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1062960, "time": 33387.03135538101, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1062976, "time": 33387.51682758331, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1063024, "time": 33388.98471403122, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1063216, "time": 33394.779918432236, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1063392, "time": 33400.234526634216, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1063464, "time": 33402.19544124603, "episode/length": 8.0, "episode/score": 0.9750000238418579, "episode/reward_rate": 0.1111111111111111, "episode/intrinsic_return": 0.0}
{"step": 1063480, "time": 33402.70700311661, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1063616, "time": 33407.04126048088, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1063872, "time": 33414.83263516426, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 1063912, "time": 33415.82269692421, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1064104, "time": 33421.644001960754, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1064104, "time": 33421.651574373245, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1064360, "time": 33429.494537591934, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 1064376, "time": 33429.98776960373, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1064568, "time": 33435.82741355896, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1065248, "time": 33457.28465747833, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1065336, "time": 33459.72981452942, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1065392, "time": 33461.66597247124, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 1065616, "time": 33468.43938803673, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1065792, "time": 33473.74795150757, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1065928, "time": 33477.644292354584, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1066192, "time": 33485.83261394501, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1066208, "time": 33486.317673921585, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1066224, "time": 33486.927152872086, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1066456, "time": 33493.711689949036, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1066520, "time": 33495.81675887108, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1066672, "time": 33500.690126895905, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1066744, "time": 33502.66367268562, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 1067008, "time": 33510.972131729126, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1067104, "time": 33513.952142477036, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1067560, "time": 33527.85402965546, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1067760, "time": 33534.168961286545, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 1067768, "time": 33534.19742894173, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1067856, "time": 33537.104398965836, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1067856, "time": 33537.11323547363, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1068200, "time": 33547.434579372406, "episode/length": 209.0, "episode/score": 0.34687501192092896, "episode/reward_rate": 0.004761904761904762, "episode/intrinsic_return": 0.0}
{"step": 1068240, "time": 33548.872987270355, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1068536, "time": 33557.62438368797, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1068600, "time": 33559.58097863197, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1068608, "time": 33560.04699277878, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1068608, "time": 33560.05619764328, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1068760, "time": 33564.462254047394, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1068976, "time": 33571.23095703125, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1069656, "time": 33591.71801996231, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1069808, "time": 33596.5429019928, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 1070000, "time": 33602.36650514603, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 1070056, "time": 33604.350583314896, "eval_episode/length": 26.0, "eval_episode/score": 0.918749988079071, "eval_episode/reward_rate": 0.037037037037037035}
{"step": 1070056, "time": 33604.46975302696, "eval_episode/length": 32.0, "eval_episode/score": 0.8999999761581421, "eval_episode/reward_rate": 0.030303030303030304}
{"step": 1070056, "time": 33605.52224111557, "eval_episode/length": 89.0, "eval_episode/score": 0.721875011920929, "eval_episode/reward_rate": 0.011111111111111112}
{"step": 1070056, "time": 33605.73053383827, "eval_episode/length": 100.0, "eval_episode/score": 0.6875, "eval_episode/reward_rate": 0.009900990099009901}
{"step": 1070056, "time": 33607.37875056267, "eval_episode/length": 155.0, "eval_episode/score": 0.515625, "eval_episode/reward_rate": 0.00641025641025641}
{"step": 1070056, "time": 33607.533061504364, "eval_episode/length": 190.0, "eval_episode/score": 0.40625, "eval_episode/reward_rate": 0.005235602094240838}
{"step": 1070056, "time": 33607.560060977936, "eval_episode/length": 101.0, "eval_episode/score": 0.684374988079071, "eval_episode/reward_rate": 0.00980392156862745}
{"step": 1070056, "time": 33609.07471418381, "eval_episode/length": 174.0, "eval_episode/score": 0.45625001192092896, "eval_episode/reward_rate": 0.005714285714285714}
{"step": 1070072, "time": 33609.559913396835, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1070080, "time": 33610.02475690842, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1070312, "time": 33616.83902716637, "episode/length": 212.0, "episode/score": 0.3375000059604645, "episode/reward_rate": 0.004694835680751174, "episode/intrinsic_return": 0.0}
{"step": 1070456, "time": 33621.225009441376, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1070848, "time": 33633.32988238335, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1070880, "time": 33634.30213832855, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1070912, "time": 33635.27748179436, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1070928, "time": 33635.764221429825, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1071160, "time": 33642.768213272095, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1071288, "time": 33646.63505101204, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1071504, "time": 33653.45470261574, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1071968, "time": 33667.61792588234, "episode/length": 206.0, "episode/score": 0.35624998807907104, "episode/reward_rate": 0.004830917874396135, "episode/intrinsic_return": 0.0}
{"step": 1072080, "time": 33670.9975297451, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1072120, "time": 33672.01726961136, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1072192, "time": 33674.42537665367, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 1072224, "time": 33675.40240073204, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1072432, "time": 33681.78975152969, "episode/length": 187.0, "episode/score": 0.4156250059604645, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.0}
{"step": 1072488, "time": 33683.26913714409, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 1072664, "time": 33688.6339366436, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1072928, "time": 33697.064569950104, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1073072, "time": 33701.47731280327, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1073184, "time": 33705.45330643654, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1073424, "time": 33712.73741054535, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1073496, "time": 33714.69838666916, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 1073816, "time": 33724.39809989929, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1073920, "time": 33727.89714741707, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 1073984, "time": 33729.833896160126, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1074096, "time": 33733.251061439514, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1074272, "time": 33738.5914850235, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1074304, "time": 33739.56210923195, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1074800, "time": 33754.58524847031, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1074960, "time": 33759.518728256226, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1075008, "time": 33760.993945121765, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1075320, "time": 33770.23105216026, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1075376, "time": 33772.14351439476, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 1075384, "time": 33772.17253565788, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1075488, "time": 33775.55609822273, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 1075496, "time": 33775.58401274681, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1075672, "time": 33780.938745737076, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1076184, "time": 33796.57316374779, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 1076296, "time": 33799.98194050789, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1076408, "time": 33803.3870279789, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1076416, "time": 33803.85214757919, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1076584, "time": 33808.73308944702, "episode/length": 21.0, "episode/score": 0.934374988079071, "episode/reward_rate": 0.045454545454545456, "episode/intrinsic_return": 0.0}
{"step": 1076848, "time": 33817.05783510208, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 1076904, "time": 33818.546634435654, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1076968, "time": 33820.50808739662, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1077608, "time": 33840.050466775894, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1077648, "time": 33841.47900915146, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1077688, "time": 33842.475001335144, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1077696, "time": 33842.94458079338, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1077984, "time": 33851.751730680466, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1078048, "time": 33853.707479953766, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 1078064, "time": 33854.198986530304, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1078496, "time": 33867.266921281815, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1078528, "time": 33868.26074934006, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 1078672, "time": 33872.623596429825, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1078688, "time": 33873.107604026794, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1079184, "time": 33888.17520570755, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1079208, "time": 33888.68348836899, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1079336, "time": 33892.57596826553, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 1079576, "time": 33899.850044727325, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1079632, "time": 33901.78603339195, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1079872, "time": 33909.14289498329, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1079904, "time": 33910.11015415192, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1079920, "time": 33910.59924173355, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1080008, "time": 33913.04841184616, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1080040, "time": 33915.48834657669, "eval_episode/length": 72.0, "eval_episode/score": 0.7749999761581421, "eval_episode/reward_rate": 0.0136986301369863}
{"step": 1080040, "time": 33915.8357899189, "eval_episode/length": 90.0, "eval_episode/score": 0.71875, "eval_episode/reward_rate": 0.01098901098901099}
{"step": 1080040, "time": 33916.03194689751, "eval_episode/length": 100.0, "eval_episode/score": 0.6875, "eval_episode/reward_rate": 0.009900990099009901}
{"step": 1080040, "time": 33916.09836268425, "eval_episode/length": 103.0, "eval_episode/score": 0.6781250238418579, "eval_episode/reward_rate": 0.009615384615384616}
{"step": 1080040, "time": 33916.357920885086, "eval_episode/length": 116.0, "eval_episode/score": 0.637499988079071, "eval_episode/reward_rate": 0.008547008547008548}
{"step": 1080040, "time": 33916.46091794968, "eval_episode/length": 121.0, "eval_episode/score": 0.621874988079071, "eval_episode/reward_rate": 0.00819672131147541}
{"step": 1080040, "time": 33916.67573428154, "eval_episode/length": 59.0, "eval_episode/score": 0.815625011920929, "eval_episode/reward_rate": 0.016666666666666666}
{"step": 1080040, "time": 33917.170728206635, "eval_episode/length": 158.0, "eval_episode/score": 0.5062500238418579, "eval_episode/reward_rate": 0.006289308176100629}
{"step": 1080416, "time": 33928.76920700073, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1080472, "time": 33930.26738333702, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1080792, "time": 33940.02414894104, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1080816, "time": 33940.96932554245, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1080864, "time": 33942.41960644722, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1080984, "time": 33945.833911180496, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1081464, "time": 33960.9137263298, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1081480, "time": 33961.410855054855, "episode/length": 196.0, "episode/score": 0.38749998807907104, "episode/reward_rate": 0.005076142131979695, "episode/intrinsic_return": 0.0}
{"step": 1081496, "time": 33961.90136599541, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1081520, "time": 33962.85801124573, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1081560, "time": 33963.86769962311, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1081632, "time": 33966.25861740112, "episode/length": 16.0, "episode/score": 0.949999988079071, "episode/reward_rate": 0.058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 1081856, "time": 33973.15139126778, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1082072, "time": 33979.52323818207, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1082296, "time": 33986.32500243187, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1082536, "time": 33993.61826848984, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1082592, "time": 33995.533878088, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1082728, "time": 33999.54193377495, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 1082728, "time": 33999.549839019775, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1082928, "time": 34005.830760240555, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1083048, "time": 34009.251483917236, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 1083080, "time": 34010.2247736454, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1083128, "time": 34011.68032383919, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1083608, "time": 34026.18450641632, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1083648, "time": 34027.775136232376, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1083760, "time": 34031.1629588604, "episode/length": 237.0, "episode/score": 0.2593750059604645, "episode/reward_rate": 0.004201680672268907, "episode/intrinsic_return": 0.0}
{"step": 1083832, "time": 34033.13536953926, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1083944, "time": 34036.52880477905, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1084104, "time": 34041.37174510956, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 1084192, "time": 34044.268788576126, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1084376, "time": 34049.602346897125, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1084640, "time": 34057.94262266159, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1084808, "time": 34062.81481194496, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1084896, "time": 34065.70808124542, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1084904, "time": 34065.7375061512, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1085200, "time": 34074.95325541496, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 1085216, "time": 34075.45227980614, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 1085248, "time": 34076.445571899414, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 1085584, "time": 34086.76996207237, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1085872, "time": 34095.56264209747, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1085920, "time": 34097.030146837234, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1086280, "time": 34107.695952653885, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1086352, "time": 34110.114803791046, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1086504, "time": 34114.48195195198, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1086584, "time": 34117.030047655106, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 1086664, "time": 34119.459305763245, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1086736, "time": 34121.86861419678, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1086952, "time": 34128.18964552879, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1087184, "time": 34135.46933889389, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 1087184, "time": 34135.47748017311, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1087392, "time": 34141.76954078674, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1087448, "time": 34143.246534109116, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1087560, "time": 34146.82906293869, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1087768, "time": 34153.114894390106, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 1087896, "time": 34157.042952775955, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1088080, "time": 34162.91307139397, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1088160, "time": 34165.35178685188, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1088192, "time": 34166.32408595085, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1088352, "time": 34171.16602683067, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1088432, "time": 34173.60064744949, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1088520, "time": 34176.03253817558, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1088592, "time": 34178.53173518181, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1088888, "time": 34187.25879430771, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1088984, "time": 34190.17290210724, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1089224, "time": 34197.4331908226, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 1089264, "time": 34198.88117790222, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1089488, "time": 34205.66834282875, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1089576, "time": 34208.81576657295, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 1089592, "time": 34209.3069934845, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 1089664, "time": 34211.74545741081, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1090024, "time": 34224.02753305435, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 1090024, "time": 34224.05169892311, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 1090024, "time": 34224.25533103943, "eval_episode/length": 94.0, "eval_episode/score": 0.706250011920929, "eval_episode/reward_rate": 0.010526315789473684}
{"step": 1090024, "time": 34224.84568500519, "eval_episode/length": 126.0, "eval_episode/score": 0.606249988079071, "eval_episode/reward_rate": 0.007874015748031496}
{"step": 1090024, "time": 34226.840757608414, "eval_episode/length": 106.0, "eval_episode/score": 0.668749988079071, "eval_episode/reward_rate": 0.009345794392523364}
{"step": 1090024, "time": 34227.394708395004, "eval_episode/length": 168.0, "eval_episode/score": 0.4749999940395355, "eval_episode/reward_rate": 0.005917159763313609}
{"step": 1090024, "time": 34227.60047316551, "eval_episode/length": 191.0, "eval_episode/score": 0.40312498807907104, "eval_episode/reward_rate": 0.005208333333333333}
{"step": 1090024, "time": 34227.865312337875, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1090024, "time": 34227.87148785591, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1090024, "time": 34227.877871990204, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1090024, "time": 34227.88419032097, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1090208, "time": 34233.70735812187, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1090256, "time": 34235.151653289795, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1090448, "time": 34241.04417037964, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 1090520, "time": 34243.00397229195, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1090560, "time": 34244.42214179039, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1090584, "time": 34244.927339315414, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1090592, "time": 34245.39243507385, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 1090832, "time": 34252.64934873581, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1090992, "time": 34257.49679684639, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1091032, "time": 34258.48315691948, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1091225, "time": 34265.345935344696, "train_stats/mean_log_entropy": 0.08130606960050121, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.5610081307330534, "train/action_min": 0.0, "train/action_std": 1.7383124994401316, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.009366552575968613, "train/actor_opt_grad_steps": 67100.0, "train/actor_opt_loss": -21.434153718141776, "train/adv_mag": 0.8304652823737605, "train/adv_max": 0.3524112861547897, "train/adv_mean": 1.8094930300009506e-05, "train/adv_min": -0.7505175266692887, "train/adv_std": 0.025222806978173813, "train/cont_avg": 0.9939074160447762, "train/cont_loss_mean": 0.023616268545092634, "train/cont_loss_std": 0.2736110655007078, "train/cont_neg_acc": 0.21330756490206837, "train/cont_neg_loss": 3.063652639958396, "train/cont_pos_acc": 0.9998778000992922, "train/cont_pos_loss": 0.0050689161358985, "train/cont_pred": 0.9937951152597494, "train/cont_rate": 0.9939074160447762, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.12347690981641338, "train/extr_critic_critic_opt_grad_steps": 67100.0, "train/extr_critic_critic_opt_loss": 5541.995009085432, "train/extr_critic_mag": 1.6462740850685842, "train/extr_critic_max": 1.6462740850685842, "train/extr_critic_mean": 1.5423875673493344, "train/extr_critic_min": 1.0538291759158842, "train/extr_critic_std": 0.028844264766840794, "train/extr_return_normed_mag": 0.9161847224876062, "train/extr_return_normed_max": 0.26910887132236616, "train/extr_return_normed_mean": 0.05680068383984898, "train/extr_return_normed_min": -0.8256829289061514, "train/extr_return_normed_std": 0.0394323815068054, "train/extr_return_rate": 0.9997843130310969, "train/extr_return_raw_mag": 1.754713827104711, "train/extr_return_raw_max": 1.754713827104711, "train/extr_return_raw_mean": 1.5424057180015602, "train/extr_return_raw_min": 0.6599220268761934, "train/extr_return_raw_std": 0.039432381441937156, "train/extr_reward_mag": 0.2374729926313334, "train/extr_reward_max": 0.2374729926313334, "train/extr_reward_mean": 0.00237353291045133, "train/extr_reward_min": 2.740034416540345e-07, "train/extr_reward_std": 0.008799153903675317, "train/image_loss_mean": 0.08391333723542702, "train/image_loss_std": 0.10089269095095829, "train/model_loss_mean": 0.7279527282240379, "train/model_loss_std": 0.5392404593045439, "train/model_opt_grad_norm": 16.28260225798953, "train/model_opt_grad_steps": 67039.5223880597, "train/model_opt_loss": 3676.902770085121, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5074.626865671642, "train/policy_entropy_mag": 1.2589761042476293, "train/policy_entropy_max": 1.2589761042476293, "train/policy_entropy_mean": 0.09300478888833108, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.11433998873429511, "train/policy_logprob_mag": 6.55108026485538, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09320637698642056, "train/policy_logprob_min": -6.55108026485538, "train/policy_logprob_std": 0.6310065667427595, "train/policy_randomness_mag": 0.6469857701614722, "train/policy_randomness_max": 0.6469857701614722, "train/policy_randomness_mean": 0.0477950092386547, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.05875913448520561, "train/post_ent_mag": 28.257374483554518, "train/post_ent_max": 28.257374483554518, "train/post_ent_mean": 27.69803392590575, "train/post_ent_min": 27.17873540090684, "train/post_ent_std": 0.23514559375706004, "train/prior_ent_mag": 27.895206356523047, "train/prior_ent_max": 27.895206356523047, "train/prior_ent_mean": 27.324321661422502, "train/prior_ent_min": 26.656489813505715, "train/prior_ent_std": 0.20033454086946612, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0027856627422435886, "train/reward_loss_mean": 0.020423099135664934, "train/reward_loss_std": 0.2652186533084037, "train/reward_max_data": 0.8049595778557792, "train/reward_max_pred": 0.30094196665939404, "train/reward_neg_acc": 0.9995754248467251, "train/reward_neg_loss": 0.003731073341934724, "train/reward_pos_acc": 0.15907936748117207, "train/reward_pos_loss": 4.028030765652656, "train/reward_pred": 0.0022029498446065545, "train/reward_rate": 0.0041005907960199005, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.990234375, "report/cont_loss_mean": 0.029443802312016487, "report/cont_loss_std": 0.31630656123161316, "report/cont_neg_acc": 0.30000001192092896, "report/cont_neg_loss": 2.6277968883514404, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0038190199993550777, "report/cont_pred": 0.9932045936584473, "report/cont_rate": 0.990234375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.0970437154173851, "report/image_loss_std": 0.1176343783736229, "report/model_loss_mean": 0.7578145265579224, "report/model_loss_std": 0.6835752129554749, "report/post_ent_mag": 28.488473892211914, "report/post_ent_max": 28.488473892211914, "report/post_ent_mean": 27.9042911529541, "report/post_ent_min": 27.439714431762695, "report/post_ent_std": 0.2528998851776123, "report/prior_ent_mag": 27.890613555908203, "report/prior_ent_max": 27.890613555908203, "report/prior_ent_mean": 27.36090850830078, "report/prior_ent_min": 26.794090270996094, "report/prior_ent_std": 0.1910182237625122, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0059600831009447575, "report/reward_loss_mean": 0.031327009201049805, "report/reward_loss_std": 0.35658586025238037, "report/reward_max_data": 0.987500011920929, "report/reward_max_pred": 0.8298722505569458, "report/reward_neg_acc": 0.998031497001648, "report/reward_neg_loss": 0.003374936990439892, "report/reward_pos_acc": 0.25, "report/reward_pos_loss": 3.581240177154541, "report/reward_pred": 0.0031119135674089193, "report/reward_rate": 0.0078125, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.025144264101982117, "eval/cont_loss_std": 0.2801971435546875, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 3.9812068939208984, "eval/cont_pos_acc": 0.999018669128418, "eval/cont_pos_loss": 0.005732768215239048, "eval/cont_pred": 0.9945378303527832, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.13663478195667267, "eval/image_loss_std": 0.12599052488803864, "eval/model_loss_mean": 0.790125846862793, "eval/model_loss_std": 0.6589937806129456, "eval/post_ent_mag": 28.49183464050293, "eval/post_ent_max": 28.49183464050293, "eval/post_ent_mean": 27.979536056518555, "eval/post_ent_min": 27.39072608947754, "eval/post_ent_std": 0.22842390835285187, "eval/prior_ent_mag": 27.884620666503906, "eval/prior_ent_max": 27.884620666503906, "eval/prior_ent_mean": 27.395050048828125, "eval/prior_ent_min": 26.791767120361328, "eval/prior_ent_std": 0.19074571132659912, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0034088133834302425, "eval/reward_loss_mean": 0.028346754610538483, "eval/reward_loss_std": 0.3488493263721466, "eval/reward_max_data": 0.8656250238418579, "eval/reward_max_pred": 0.16705942153930664, "eval/reward_neg_acc": 0.999018669128418, "eval/reward_neg_loss": 0.004020309075713158, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 4.986076354980469, "eval/reward_pred": 0.0021333748009055853, "eval/reward_rate": 0.0048828125, "replay/size": 1000000.0, "replay/inserts": 32128.0, "replay/samples": 32128.0, "replay/insert_wait_avg": 1.284045230344947e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.449284916380012e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 7152.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1637906900188267e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.2516975402832031e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.088189125061, "timer/env.step_count": 4016.0, "timer/env.step_total": 39.17557382583618, "timer/env.step_frac": 0.039172119270910896, "timer/env.step_avg": 0.009754873960616578, "timer/env.step_min": 0.0076291561126708984, "timer/env.step_max": 0.03643345832824707, "timer/replay._sample_count": 32128.0, "timer/replay._sample_total": 16.869082927703857, "timer/replay._sample_frac": 0.0168675953892246, "timer/replay._sample_avg": 0.0005250586070624956, "timer/replay._sample_min": 0.00042128562927246094, "timer/replay._sample_max": 0.011814117431640625, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4910.0, "timer/agent.policy_total": 52.37517809867859, "timer/agent.policy_frac": 0.052370559584849846, "timer/agent.policy_avg": 0.01066704238262293, "timer/agent.policy_min": 0.00872182846069336, "timer/agent.policy_max": 0.09117341041564941, "timer/dataset_train_count": 2008.0, "timer/dataset_train_total": 0.23309087753295898, "timer/dataset_train_frac": 0.00023307032326507255, "timer/dataset_train_avg": 0.00011608111430924252, "timer/dataset_train_min": 0.00010275840759277344, "timer/dataset_train_max": 0.0007135868072509766, "timer/agent.train_count": 2008.0, "timer/agent.train_total": 893.4787817001343, "timer/agent.train_frac": 0.8933999935363748, "timer/agent.train_avg": 0.4449595526395091, "timer/agent.train_min": 0.4305753707885742, "timer/agent.train_max": 0.7330272197723389, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47655367851257324, "timer/agent.report_frac": 0.00047651165536660505, "timer/agent.report_avg": 0.23827683925628662, "timer/agent.report_min": 0.23262333869934082, "timer/agent.report_max": 0.24393033981323242, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9802322387695312e-05, "timer/dataset_eval_frac": 2.9799694378720968e-08, "timer/dataset_eval_avg": 2.9802322387695312e-05, "timer/dataset_eval_min": 2.9802322387695312e-05, "timer/dataset_eval_max": 2.9802322387695312e-05, "fps": 32.124541378194166}
{"step": 1091264, "time": 34266.51267886162, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1091328, "time": 34268.575407743454, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1091368, "time": 34269.56883049011, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1091576, "time": 34275.905097961426, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1091584, "time": 34276.3811340332, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1091952, "time": 34287.59014558792, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1092000, "time": 34289.03567004204, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1092056, "time": 34290.51714968681, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 1092360, "time": 34299.818002939224, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1092456, "time": 34302.77523612976, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1092504, "time": 34304.22711634636, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1092568, "time": 34306.16928386688, "episode/length": 196.0, "episode/score": 0.38749998807907104, "episode/reward_rate": 0.005076142131979695, "episode/intrinsic_return": 0.0}
{"step": 1092608, "time": 34307.62631869316, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1092760, "time": 34312.00106668472, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1092832, "time": 34314.402560949326, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1093312, "time": 34329.021901130676, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1093336, "time": 34329.533848285675, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1093352, "time": 34330.02544474602, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1093376, "time": 34330.97207856178, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1093600, "time": 34337.758601903915, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1093736, "time": 34341.65946865082, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 1093888, "time": 34346.48902153969, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1093888, "time": 34346.49797511101, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 1094320, "time": 34359.69006562233, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1094352, "time": 34360.686852931976, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1094408, "time": 34362.176844358444, "episode/length": 255.0, "episode/score": 0.203125, "episode/reward_rate": 0.00390625, "episode/intrinsic_return": 0.0}
{"step": 1094792, "time": 34373.82599020004, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1094880, "time": 34376.72045254707, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1094912, "time": 34377.69024133682, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1095016, "time": 34380.62025856972, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1095288, "time": 34388.9727871418, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1095376, "time": 34391.88369059563, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 1095384, "time": 34391.9116165638, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1095456, "time": 34394.33206033707, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1095624, "time": 34399.25082683563, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1095664, "time": 34400.69942903519, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1095696, "time": 34401.66832232475, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1095896, "time": 34407.60251355171, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1096048, "time": 34412.44751691818, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 1096200, "time": 34416.921306848526, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1096256, "time": 34418.834312200546, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1096296, "time": 34419.839879989624, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1096384, "time": 34422.7222328186, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1096424, "time": 34423.71227431297, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1096832, "time": 34436.30054450035, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1097016, "time": 34441.66147327423, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1097288, "time": 34449.99305343628, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1097408, "time": 34453.84137606621, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1097728, "time": 34463.71397733688, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1097936, "time": 34470.44333076477, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1098208, "time": 34478.850002765656, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1098280, "time": 34480.80460476875, "episode/length": 236.0, "episode/score": 0.26249998807907104, "episode/reward_rate": 0.004219409282700422, "episode/intrinsic_return": 0.0}
{"step": 1098336, "time": 34482.719898700714, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1098496, "time": 34487.548107385635, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 1098512, "time": 34488.05338931084, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1098512, "time": 34488.061168432236, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1098608, "time": 34490.95239901543, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1098760, "time": 34495.33540058136, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1099024, "time": 34503.57789134979, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1099144, "time": 34507.05984520912, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1099432, "time": 34515.77974653244, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1099888, "time": 34529.78267431259, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1100008, "time": 34533.70355606079, "eval_episode/length": 26.0, "eval_episode/score": 0.918749988079071, "eval_episode/reward_rate": 0.037037037037037035}
{"step": 1100008, "time": 34533.91669130325, "eval_episode/length": 37.0, "eval_episode/score": 0.8843749761581421, "eval_episode/reward_rate": 0.02631578947368421}
{"step": 1100008, "time": 34534.14503073692, "eval_episode/length": 49.0, "eval_episode/score": 0.846875011920929, "eval_episode/reward_rate": 0.02}
{"step": 1100008, "time": 34534.40173411369, "eval_episode/length": 36.0, "eval_episode/score": 0.887499988079071, "eval_episode/reward_rate": 0.02702702702702703}
{"step": 1100008, "time": 34534.698622226715, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 1100008, "time": 34534.8464217186, "eval_episode/length": 87.0, "eval_episode/score": 0.7281249761581421, "eval_episode/reward_rate": 0.011363636363636364}
{"step": 1100008, "time": 34535.01484966278, "eval_episode/length": 96.0, "eval_episode/score": 0.699999988079071, "eval_episode/reward_rate": 0.010309278350515464}
{"step": 1100008, "time": 34535.48297023773, "eval_episode/length": 122.0, "eval_episode/score": 0.6187499761581421, "eval_episode/reward_rate": 0.008130081300813009}
{"step": 1100152, "time": 34539.93820786476, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1100344, "time": 34545.74691414833, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1100592, "time": 34553.49168300629, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1100648, "time": 34554.96344423294, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1100808, "time": 34559.793360710144, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1100920, "time": 34563.21072387695, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1101072, "time": 34568.126225948334, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1101288, "time": 34574.43076586723, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1101336, "time": 34575.88797664642, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1101640, "time": 34585.12600684166, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1101672, "time": 34586.102241277695, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1102360, "time": 34607.0834004879, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 1102464, "time": 34610.4534907341, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1102520, "time": 34611.94779467583, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1102528, "time": 34612.41641449928, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1102816, "time": 34621.09799671173, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 1102856, "time": 34622.10577964783, "episode/length": 241.0, "episode/score": 0.24687500298023224, "episode/reward_rate": 0.004132231404958678, "episode/intrinsic_return": 0.0}
{"step": 1102904, "time": 34623.56115436554, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1102960, "time": 34625.47774362564, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1103040, "time": 34628.016655921936, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1103592, "time": 34644.58207702637, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1103600, "time": 34645.052374601364, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1103880, "time": 34653.31652545929, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 1103896, "time": 34653.80784153938, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1103952, "time": 34655.75984811783, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1104232, "time": 34664.162060022354, "episode/length": 220.0, "episode/score": 0.3125, "episode/reward_rate": 0.004524886877828055, "episode/intrinsic_return": 0.0}
{"step": 1104448, "time": 34670.954453229904, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1104456, "time": 34670.983607292175, "episode/length": 241.0, "episode/score": 0.24687500298023224, "episode/reward_rate": 0.004132231404958678, "episode/intrinsic_return": 0.0}
{"step": 1104504, "time": 34672.45054721832, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1104848, "time": 34683.15237092972, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1104960, "time": 34686.74169635773, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1105056, "time": 34689.659350156784, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1105128, "time": 34691.64399886131, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1105216, "time": 34694.51920747757, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1105240, "time": 34695.06747531891, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1105352, "time": 34698.47062373161, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1105368, "time": 34698.96177124977, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1105568, "time": 34705.24893641472, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 1105640, "time": 34707.2042286396, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 1105824, "time": 34713.00816106796, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1105832, "time": 34713.03696060181, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1106104, "time": 34721.918284893036, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 1106168, "time": 34723.85033965111, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1106208, "time": 34725.3004629612, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1106264, "time": 34726.772720098495, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1106352, "time": 34729.6696600914, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1106512, "time": 34734.52528047562, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 1106592, "time": 34736.95574140549, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1106768, "time": 34742.26453113556, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1106944, "time": 34747.76275539398, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1107104, "time": 34752.614830732346, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1107232, "time": 34756.50308632851, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1107328, "time": 34759.408923625946, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1107368, "time": 34760.39951753616, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1107608, "time": 34767.66074371338, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1107880, "time": 34775.89760303497, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1107976, "time": 34778.90374493599, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1108184, "time": 34785.19989609718, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1108264, "time": 34787.61281132698, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 1108416, "time": 34792.43369722366, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1108664, "time": 34799.71945929527, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 1109032, "time": 34810.95609664917, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1109080, "time": 34812.42515587807, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1109136, "time": 34814.33332538605, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1109248, "time": 34817.74958777428, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1109280, "time": 34818.72100567818, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 1109640, "time": 34829.38894081116, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1109872, "time": 34836.80745148659, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1109928, "time": 34838.2787630558, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1110096, "time": 34844.33723735809, "eval_episode/length": 38.0, "eval_episode/score": 0.8812500238418579, "eval_episode/reward_rate": 0.02564102564102564}
{"step": 1110096, "time": 34844.75184178352, "eval_episode/length": 60.0, "eval_episode/score": 0.8125, "eval_episode/reward_rate": 0.01639344262295082}
{"step": 1110096, "time": 34844.87319421768, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 1110096, "time": 34845.239585638046, "eval_episode/length": 47.0, "eval_episode/score": 0.8531249761581421, "eval_episode/reward_rate": 0.020833333333333332}
{"step": 1110096, "time": 34845.32551121712, "eval_episode/length": 90.0, "eval_episode/score": 0.71875, "eval_episode/reward_rate": 0.01098901098901099}
{"step": 1110096, "time": 34845.39506483078, "eval_episode/length": 93.0, "eval_episode/score": 0.7093750238418579, "eval_episode/reward_rate": 0.010638297872340425}
{"step": 1110096, "time": 34845.95193004608, "eval_episode/length": 122.0, "eval_episode/score": 0.6187499761581421, "eval_episode/reward_rate": 0.008130081300813009}
{"step": 1110096, "time": 34847.53248333931, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 1110192, "time": 34850.51398897171, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1110288, "time": 34853.46399307251, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 1110408, "time": 34856.893451452255, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1110424, "time": 34857.3835811615, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 1110512, "time": 34860.294669151306, "episode/length": 230.0, "episode/score": 0.28125, "episode/reward_rate": 0.004329004329004329, "episode/intrinsic_return": 0.0}
{"step": 1110568, "time": 34861.766560554504, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1110592, "time": 34862.71736049652, "episode/length": 20.0, "episode/score": 0.9375, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.0}
{"step": 1110880, "time": 34871.55784249306, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1111152, "time": 34879.803639650345, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1111320, "time": 34884.751029253006, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1111560, "time": 34892.13664102554, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1111600, "time": 34893.58010530472, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1111616, "time": 34894.0729868412, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1111800, "time": 34899.56457400322, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1111952, "time": 34904.41560482979, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1112240, "time": 34913.143510103226, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1112280, "time": 34914.151282548904, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1112448, "time": 34919.4979493618, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1112904, "time": 34933.165821790695, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1113096, "time": 34939.06438970566, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1113120, "time": 34940.02131104469, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 1113216, "time": 34942.92676615715, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 1113544, "time": 34952.65515899658, "episode/length": 198.0, "episode/score": 0.3812499940395355, "episode/reward_rate": 0.005025125628140704, "episode/intrinsic_return": 0.0}
{"step": 1113568, "time": 34953.634629011154, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1113648, "time": 34956.06416654587, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1113912, "time": 34963.94378566742, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1114112, "time": 34970.37296009064, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1114136, "time": 34971.27688574791, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1114136, "time": 34971.28791189194, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1114320, "time": 34977.09489607811, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1114552, "time": 34983.925943136215, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1114696, "time": 34988.41344881058, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1114760, "time": 34990.35232710838, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1114968, "time": 34996.664878606796, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1115144, "time": 35001.99586200714, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1115264, "time": 35005.87404417992, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1115304, "time": 35006.86705470085, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1115512, "time": 35013.171303749084, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1115704, "time": 35019.08272767067, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1115904, "time": 35025.37184262276, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1115944, "time": 35026.365544080734, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1115960, "time": 35026.87987470627, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1116048, "time": 35029.791365385056, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1116048, "time": 35029.79757285118, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1116224, "time": 35035.15364193916, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1116272, "time": 35036.631301641464, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 1116512, "time": 35043.88640141487, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1116544, "time": 35044.85688829422, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1116664, "time": 35048.38010787964, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1116720, "time": 35050.30189037323, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1116760, "time": 35051.31498336792, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1116808, "time": 35052.77324509621, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1116984, "time": 35058.11771154404, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1117336, "time": 35068.77930212021, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1117344, "time": 35069.24834561348, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1117544, "time": 35075.171884059906, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1117608, "time": 35077.299431562424, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1117752, "time": 35081.67122220993, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1117808, "time": 35083.58089852333, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1118008, "time": 35089.41845393181, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1118176, "time": 35094.72681093216, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1118424, "time": 35102.02756810188, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1118504, "time": 35104.453738451004, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 1118584, "time": 35106.98373174667, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1118824, "time": 35114.2547082901, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1119288, "time": 35128.323348522186, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1119336, "time": 35129.803674936295, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1119488, "time": 35134.62932538986, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 1119648, "time": 35139.5457906723, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1119824, "time": 35144.85780954361, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 1119992, "time": 35149.715206861496, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1120064, "time": 35152.120918273926, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1120080, "time": 35153.20827102661, "eval_episode/length": 29.0, "eval_episode/score": 0.909375011920929, "eval_episode/reward_rate": 0.03333333333333333}
{"step": 1120080, "time": 35154.461782217026, "eval_episode/length": 64.0, "eval_episode/score": 0.800000011920929, "eval_episode/reward_rate": 0.015384615384615385}
{"step": 1120080, "time": 35154.4855260849, "eval_episode/length": 95.0, "eval_episode/score": 0.703125, "eval_episode/reward_rate": 0.010416666666666666}
{"step": 1120080, "time": 35154.579828977585, "eval_episode/length": 100.0, "eval_episode/score": 0.6875, "eval_episode/reward_rate": 0.009900990099009901}
{"step": 1120080, "time": 35155.12059760094, "eval_episode/length": 129.0, "eval_episode/score": 0.596875011920929, "eval_episode/reward_rate": 0.007692307692307693}
{"step": 1120080, "time": 35155.46408987045, "eval_episode/length": 146.0, "eval_episode/score": 0.543749988079071, "eval_episode/reward_rate": 0.006802721088435374}
{"step": 1120080, "time": 35155.911935567856, "eval_episode/length": 75.0, "eval_episode/score": 0.765625, "eval_episode/reward_rate": 0.013157894736842105}
{"step": 1120080, "time": 35157.04280042648, "eval_episode/length": 232.0, "eval_episode/score": 0.2750000059604645, "eval_episode/reward_rate": 0.004291845493562232}
{"step": 1120096, "time": 35157.530420303345, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1120120, "time": 35158.058770656586, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1120184, "time": 35159.992740392685, "episode/length": 219.0, "episode/score": 0.31562501192092896, "episode/reward_rate": 0.004545454545454545, "episode/intrinsic_return": 0.0}
{"step": 1120512, "time": 35170.28163313866, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1120624, "time": 35173.670380592346, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1121112, "time": 35188.262511730194, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1121248, "time": 35192.59699058533, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 1121288, "time": 35193.60284638405, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1121600, "time": 35203.36818814278, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1121616, "time": 35203.85852599144, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1121664, "time": 35205.31486964226, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1121856, "time": 35211.1272649765, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1121928, "time": 35213.1082880497, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 1121984, "time": 35215.017570734024, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 1122200, "time": 35221.349388599396, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1122256, "time": 35223.26699614525, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1122304, "time": 35224.87945008278, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1122376, "time": 35227.346472501755, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1122384, "time": 35227.81433677673, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1122496, "time": 35231.206424713135, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1122776, "time": 35239.49641251564, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1122800, "time": 35240.4516556263, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1122928, "time": 35244.34450030327, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 1123128, "time": 35250.208414554596, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1123168, "time": 35251.6705019474, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1123240, "time": 35253.62647008896, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1123352, "time": 35257.12037611008, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1123593, "time": 35265.587633132935, "train_stats/mean_log_entropy": 0.08135590848067532, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.46615207785427, "train/action_min": 0.0, "train/action_std": 1.7540379709536487, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0099795955742737, "train/actor_opt_grad_steps": 69115.0, "train/actor_opt_loss": -19.64736208113113, "train/adv_mag": 0.7905760979888463, "train/adv_max": 0.3578059927071675, "train/adv_mean": 0.000781977499448856, "train/adv_min": -0.6953622917137524, "train/adv_std": 0.02631478893598265, "train/cont_avg": 0.9936378403465347, "train/cont_loss_mean": 0.025633374796165984, "train/cont_loss_std": 0.290676380516869, "train/cont_neg_acc": 0.175260661409633, "train/cont_neg_loss": 3.2665903060743124, "train/cont_pos_acc": 0.9998930028759607, "train/cont_pos_loss": 0.005048946554698788, "train/cont_pred": 0.993909863847317, "train/cont_rate": 0.9936378403465347, "train/dyn_loss_mean": 1.0000000637356599, "train/dyn_loss_std": 2.0408120276037567e-06, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.12160348496630345, "train/extr_critic_critic_opt_grad_steps": 69115.0, "train/extr_critic_critic_opt_loss": 5984.406808381033, "train/extr_critic_mag": 1.653486415891364, "train/extr_critic_max": 1.653486415891364, "train/extr_critic_mean": 1.538763945645625, "train/extr_critic_min": 1.0707401875222082, "train/extr_critic_std": 0.028989622267977435, "train/extr_return_normed_mag": 0.8516523135770665, "train/extr_return_normed_max": 0.286076284281098, "train/extr_return_normed_mean": 0.05466413277542532, "train/extr_return_normed_min": -0.7461181471843531, "train/extr_return_normed_std": 0.040391716977009676, "train/extr_return_rate": 0.9997080272377128, "train/extr_return_raw_mag": 1.7709579874973487, "train/extr_return_raw_max": 1.7709579874973487, "train/extr_return_raw_mean": 1.5395459042917383, "train/extr_return_raw_min": 0.7387635560318975, "train/extr_return_raw_std": 0.04039171682947343, "train/extr_reward_mag": 0.25138543915040423, "train/extr_reward_max": 0.25138543915040423, "train/extr_reward_mean": 0.002430632838974753, "train/extr_reward_min": 2.2189451916383046e-07, "train/extr_reward_std": 0.009700658862562021, "train/image_loss_mean": 0.08586988553847416, "train/image_loss_std": 0.1022618789926614, "train/model_loss_mean": 0.733060613717183, "train/model_loss_std": 0.563604923536872, "train/model_opt_grad_norm": 16.85238803259217, "train/model_opt_grad_steps": 69052.60891089108, "train/model_opt_loss": 3828.541229550201, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5222.772277227723, "train/policy_entropy_mag": 1.258959692893642, "train/policy_entropy_max": 1.258959692893642, "train/policy_entropy_mean": 0.0918297243516634, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.11172124393063017, "train/policy_logprob_mag": 6.551080267028053, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09207166251864764, "train/policy_logprob_min": -6.551080267028053, "train/policy_logprob_std": 0.6309885913782781, "train/policy_randomness_mag": 0.6469773369850499, "train/policy_randomness_max": 0.6469773369850499, "train/policy_randomness_mean": 0.047191145654657096, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.057413366097624936, "train/post_ent_mag": 28.471328829774762, "train/post_ent_max": 28.471328829774762, "train/post_ent_mean": 27.895305000909485, "train/post_ent_min": 27.385132374149737, "train/post_ent_std": 0.23508298441325085, "train/prior_ent_mag": 27.92170274375689, "train/prior_ent_max": 27.92170274375689, "train/prior_ent_mean": 27.329034342624173, "train/prior_ent_min": 26.66989772154553, "train/prior_ent_std": 0.19674516159414066, "train/rep_loss_mean": 1.0000000637356599, "train/rep_loss_std": 2.0408120276037567e-06, "train/reward_avg": 0.0029885773696835235, "train/reward_loss_mean": 0.021557292838737665, "train/reward_loss_std": 0.2771739931823225, "train/reward_max_data": 0.8125154709461893, "train/reward_max_pred": 0.3012035075980838, "train/reward_neg_acc": 0.9994415575915044, "train/reward_neg_loss": 0.0037447925447255817, "train/reward_pos_acc": 0.15397669156244145, "train/reward_pos_loss": 4.081343343601891, "train/reward_pred": 0.002271521089040665, "train/reward_rate": 0.004365524443069307, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9912109375, "report/cont_loss_mean": 0.0239909365773201, "report/cont_loss_std": 0.2470332235097885, "report/cont_neg_acc": 0.3333333432674408, "report/cont_neg_loss": 2.1522226333618164, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.005119919311255217, "report/cont_pred": 0.9919429421424866, "report/cont_rate": 0.9912109375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.08429106324911118, "report/image_loss_std": 0.09814374893903732, "report/model_loss_mean": 0.736533522605896, "report/model_loss_std": 0.5930332541465759, "report/post_ent_mag": 28.159713745117188, "report/post_ent_max": 28.159713745117188, "report/post_ent_mean": 27.646507263183594, "report/post_ent_min": 27.185550689697266, "report/post_ent_std": 0.22596418857574463, "report/prior_ent_mag": 27.89256477355957, "report/prior_ent_max": 27.89256477355957, "report/prior_ent_mean": 27.4132137298584, "report/prior_ent_min": 26.804136276245117, "report/prior_ent_std": 0.17922112345695496, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.004589843563735485, "report/reward_loss_mean": 0.02825155481696129, "report/reward_loss_std": 0.3145700693130493, "report/reward_max_data": 0.765625, "report/reward_max_pred": 0.5667457580566406, "report/reward_neg_acc": 0.9999999403953552, "report/reward_neg_loss": 0.003368900390341878, "report/reward_pos_acc": 0.1428571492433548, "report/reward_pos_loss": 3.643345594406128, "report/reward_pred": 0.002410260494798422, "report/reward_rate": 0.0068359375, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.047265298664569855, "eval/cont_loss_std": 0.5556734800338745, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.522597312927246, "eval/cont_pos_acc": 0.9980353713035583, "eval/cont_pos_loss": 0.009100280702114105, "eval/cont_pred": 0.992005467414856, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.10016348958015442, "eval/image_loss_std": 0.11170194298028946, "eval/model_loss_mean": 0.7651568651199341, "eval/model_loss_std": 0.6920376420021057, "eval/post_ent_mag": 28.170021057128906, "eval/post_ent_max": 28.170021057128906, "eval/post_ent_mean": 27.717666625976562, "eval/post_ent_min": 27.184593200683594, "eval/post_ent_std": 0.20253436267375946, "eval/prior_ent_mag": 27.893672943115234, "eval/prior_ent_max": 27.893672943115234, "eval/prior_ent_mean": 27.414535522460938, "eval/prior_ent_min": 26.87393569946289, "eval/prior_ent_std": 0.17235314846038818, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.002246093936264515, "eval/reward_loss_mean": 0.01772802695631981, "eval/reward_loss_std": 0.23817095160484314, "eval/reward_max_data": 0.859375, "eval/reward_max_pred": 0.19438493251800537, "eval/reward_neg_acc": 0.999020516872406, "eval/reward_neg_loss": 0.004857288207858801, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 4.398069381713867, "eval/reward_pred": 0.0025601163506507874, "eval/reward_rate": 0.0029296875, "replay/size": 1000000.0, "replay/inserts": 32368.0, "replay/samples": 32368.0, "replay/insert_wait_avg": 1.2955318508440472e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.437754903992273e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4224.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1379068548029119e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0281801223754883e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1003112792969, "timer/env.step_count": 4046.0, "timer/env.step_total": 39.608834981918335, "timer/env.step_frac": 0.039604862167527934, "timer/env.step_avg": 0.009789628023212638, "timer/env.step_min": 0.007761955261230469, "timer/env.step_max": 0.039171457290649414, "timer/replay._sample_count": 32368.0, "timer/replay._sample_total": 17.04593777656555, "timer/replay._sample_frac": 0.017044228048245406, "timer/replay._sample_avg": 0.0005266293183565729, "timer/replay._sample_min": 0.00040340423583984375, "timer/replay._sample_max": 0.014151334762573242, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4574.0, "timer/agent.policy_total": 48.91322636604309, "timer/agent.policy_frac": 0.04890832030986455, "timer/agent.policy_avg": 0.010693753031491712, "timer/agent.policy_min": 0.008462667465209961, "timer/agent.policy_max": 0.08978486061096191, "timer/dataset_train_count": 2023.0, "timer/dataset_train_total": 0.23366451263427734, "timer/dataset_train_frac": 0.00023364107579906763, "timer/dataset_train_avg": 0.00011550396076830318, "timer/dataset_train_min": 0.00010204315185546875, "timer/dataset_train_max": 0.000514984130859375, "timer/agent.train_count": 2023.0, "timer/agent.train_total": 900.1826333999634, "timer/agent.train_frac": 0.9000923439854529, "timer/agent.train_avg": 0.44497411438455925, "timer/agent.train_min": 0.435596227645874, "timer/agent.train_max": 0.8069303035736084, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4755568504333496, "timer/agent.report_frac": 0.00047550915150204506, "timer/agent.report_avg": 0.2377784252166748, "timer/agent.report_min": 0.22848844528198242, "timer/agent.report_max": 0.2470684051513672, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 7.271766662597656e-05, "timer/dataset_eval_frac": 7.271037295544726e-08, "timer/dataset_eval_avg": 7.271766662597656e-05, "timer/dataset_eval_min": 7.271766662597656e-05, "timer/dataset_eval_max": 7.271766662597656e-05, "fps": 32.364034381387285}
{"step": 1123776, "time": 35271.14059853554, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1123824, "time": 35272.628858327866, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1124160, "time": 35282.81124353409, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1124464, "time": 35292.11790728569, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1124688, "time": 35298.9456307888, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1124696, "time": 35298.97567677498, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1124736, "time": 35300.414994716644, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1124808, "time": 35302.40152978897, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1125112, "time": 35311.71035575867, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1125480, "time": 35322.981816768646, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1125480, "time": 35322.988730192184, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1125792, "time": 35332.711481809616, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1125936, "time": 35337.11405110359, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1125944, "time": 35337.14115834236, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1126136, "time": 35342.99168086052, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1126776, "time": 35362.70890235901, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1126872, "time": 35365.668484687805, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1127048, "time": 35371.02389192581, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1127424, "time": 35382.84112286568, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1127456, "time": 35383.83014130592, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1127792, "time": 35394.06213140488, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1128104, "time": 35403.24194979668, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1128248, "time": 35407.73158955574, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1128256, "time": 35408.202558517456, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1128256, "time": 35408.21711373329, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1128696, "time": 35421.41067099571, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1129088, "time": 35433.55735254288, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1129160, "time": 35435.51358270645, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1129184, "time": 35436.479321956635, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1129464, "time": 35444.83086514473, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1129504, "time": 35446.273596286774, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1129584, "time": 35448.71377778053, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 1129736, "time": 35453.1054186821, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1130064, "time": 35463.96173596382, "eval_episode/length": 34.0, "eval_episode/score": 0.893750011920929, "eval_episode/reward_rate": 0.02857142857142857}
{"step": 1130064, "time": 35464.7207570076, "eval_episode/length": 75.0, "eval_episode/score": 0.765625, "eval_episode/reward_rate": 0.013157894736842105}
{"step": 1130064, "time": 35465.09368634224, "eval_episode/length": 95.0, "eval_episode/score": 0.703125, "eval_episode/reward_rate": 0.010416666666666666}
{"step": 1130064, "time": 35465.401173353195, "eval_episode/length": 111.0, "eval_episode/score": 0.653124988079071, "eval_episode/reward_rate": 0.008928571428571428}
{"step": 1130064, "time": 35465.527891635895, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 1130064, "time": 35466.93685793877, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 1130064, "time": 35466.9639775753, "eval_episode/length": 107.0, "eval_episode/score": 0.6656249761581421, "eval_episode/reward_rate": 0.009259259259259259}
{"step": 1130064, "time": 35467.59748721123, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 1130104, "time": 35468.59317946434, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1130432, "time": 35478.76961016655, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1130440, "time": 35478.798489809036, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1130568, "time": 35483.17773127556, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1130728, "time": 35488.03713417053, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 1130928, "time": 35494.34313797951, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1131016, "time": 35496.880627155304, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1131144, "time": 35500.75064492226, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1131192, "time": 35502.2221224308, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1131440, "time": 35509.9686832428, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 1131472, "time": 35510.96561741829, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1131480, "time": 35510.99258303642, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1131496, "time": 35511.48587346077, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1131744, "time": 35519.21420240402, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 1132088, "time": 35529.506474256516, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1132096, "time": 35529.9743373394, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1132456, "time": 35540.738097667694, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1132528, "time": 35543.14527463913, "episode/length": 199.0, "episode/score": 0.37812501192092896, "episode/reward_rate": 0.005, "episode/intrinsic_return": 0.0}
{"step": 1132672, "time": 35547.53023695946, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1132776, "time": 35550.51133394241, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1132944, "time": 35555.871639728546, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1132984, "time": 35556.96884918213, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1133072, "time": 35559.88720750809, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 1133256, "time": 35565.25363230705, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 1133328, "time": 35567.66712427139, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1133376, "time": 35569.127437353134, "episode/length": 236.0, "episode/score": 0.26249998807907104, "episode/reward_rate": 0.004219409282700422, "episode/intrinsic_return": 0.0}
{"step": 1133648, "time": 35577.36940956116, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1133752, "time": 35580.31353330612, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1133792, "time": 35581.74517130852, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1133800, "time": 35581.77241015434, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1133808, "time": 35582.24010682106, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1134384, "time": 35599.85567378998, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1134384, "time": 35599.86546301842, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1134608, "time": 35606.6755797863, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 1134704, "time": 35609.62007546425, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1134840, "time": 35613.54622745514, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1134992, "time": 35618.4961977005, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1135456, "time": 35632.7563021183, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1135544, "time": 35635.25914168358, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 1135584, "time": 35636.717935562134, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1135592, "time": 35636.747382164, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 1135688, "time": 35639.72314238548, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1135888, "time": 35646.05528450012, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1136048, "time": 35650.973290205, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1136064, "time": 35651.4635848999, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1136472, "time": 35663.78078699112, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1136504, "time": 35664.75104546547, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1136544, "time": 35666.182321071625, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1136800, "time": 35673.984996795654, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1137008, "time": 35680.39336395264, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1137016, "time": 35680.4215130806, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1137264, "time": 35688.23458361626, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1137536, "time": 35696.5387570858, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1137824, "time": 35705.31562924385, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1137896, "time": 35707.407358169556, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1138008, "time": 35710.800978422165, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1138200, "time": 35716.64803647995, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1138536, "time": 35726.842473745346, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 1138784, "time": 35735.098512887955, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1138816, "time": 35736.07006907463, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1138960, "time": 35740.536734580994, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 1139072, "time": 35743.94583821297, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 1139576, "time": 35759.06397128105, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1139856, "time": 35767.91353058815, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1139968, "time": 35771.31445169449, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1139984, "time": 35771.802554130554, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 1140048, "time": 35774.95169878006, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 1140048, "time": 35775.34369158745, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 1140048, "time": 35776.000131845474, "eval_episode/length": 119.0, "eval_episode/score": 0.628125011920929, "eval_episode/reward_rate": 0.008333333333333333}
{"step": 1140048, "time": 35776.20937085152, "eval_episode/length": 130.0, "eval_episode/score": 0.59375, "eval_episode/reward_rate": 0.007633587786259542}
{"step": 1140048, "time": 35776.37972021103, "eval_episode/length": 55.0, "eval_episode/score": 0.828125, "eval_episode/reward_rate": 0.017857142857142856}
{"step": 1140048, "time": 35776.46096587181, "eval_episode/length": 143.0, "eval_episode/score": 0.5531250238418579, "eval_episode/reward_rate": 0.006944444444444444}
{"step": 1140048, "time": 35777.2206120491, "eval_episode/length": 120.0, "eval_episode/score": 0.625, "eval_episode/reward_rate": 0.008264462809917356}
{"step": 1140048, "time": 35777.81273150444, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 1140136, "time": 35780.28872728348, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1140320, "time": 35786.07262587547, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1140456, "time": 35789.96933937073, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1140792, "time": 35800.24129033089, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1140848, "time": 35802.15743637085, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1140904, "time": 35803.627843141556, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1141096, "time": 35809.45891594887, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1141240, "time": 35813.91277575493, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1141352, "time": 35817.32634854317, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1141680, "time": 35827.54198551178, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1141704, "time": 35828.052886247635, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1141816, "time": 35831.45475959778, "episode/length": 209.0, "episode/score": 0.34687501192092896, "episode/reward_rate": 0.004761904761904762, "episode/intrinsic_return": 0.0}
{"step": 1141960, "time": 35835.8209733963, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1142296, "time": 35846.005608558655, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1142320, "time": 35846.96400642395, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1142608, "time": 35855.80144071579, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 1142632, "time": 35856.31595110893, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1142664, "time": 35857.37602639198, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1142696, "time": 35858.37098646164, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1143408, "time": 35880.18337345123, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1143448, "time": 35881.17664551735, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1143712, "time": 35889.548187971115, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1143784, "time": 35891.51716566086, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1144016, "time": 35898.828875780106, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1144072, "time": 35900.31126117706, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1144096, "time": 35901.261635541916, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1144272, "time": 35906.64890003204, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1144296, "time": 35907.158140420914, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 1144608, "time": 35916.95534348488, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1144640, "time": 35917.924496650696, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1144856, "time": 35924.26024603844, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1145008, "time": 35929.09404325485, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1145184, "time": 35934.44366264343, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 1145296, "time": 35937.84957432747, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1145480, "time": 35943.20430660248, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1145616, "time": 35947.67846870422, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1145720, "time": 35950.63315176964, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1145760, "time": 35952.0628118515, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1145824, "time": 35954.000547647476, "episode/length": 218.0, "episode/score": 0.3187499940395355, "episode/reward_rate": 0.0045662100456621, "episode/intrinsic_return": 0.0}
{"step": 1146304, "time": 35968.5821621418, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1146400, "time": 35971.529352903366, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1146408, "time": 35971.557569265366, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1146464, "time": 35973.47557139397, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1146640, "time": 35978.937049388885, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1146736, "time": 35981.8622481823, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 1147168, "time": 35995.48490715027, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1147168, "time": 35995.491946697235, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1147280, "time": 35998.89942622185, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1147456, "time": 36004.244904756546, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1147688, "time": 36011.19831228256, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 1147792, "time": 36014.59704518318, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 1147888, "time": 36017.491671562195, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 1147928, "time": 36018.47999429703, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1148128, "time": 36024.77549147606, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1148192, "time": 36026.735407829285, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1148272, "time": 36029.19082069397, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1148432, "time": 36034.05825662613, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1148496, "time": 36035.989403009415, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1148824, "time": 36045.80406689644, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1149048, "time": 36052.628500938416, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1149128, "time": 36055.077271938324, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1149184, "time": 36057.003833293915, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1149336, "time": 36061.419029951096, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1149648, "time": 36071.19671344757, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1150000, "time": 36081.98810863495, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1150032, "time": 36084.58787941933, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 1150032, "time": 36084.64966034889, "eval_episode/length": 89.0, "eval_episode/score": 0.721875011920929, "eval_episode/reward_rate": 0.011111111111111112}
{"step": 1150032, "time": 36085.15939593315, "eval_episode/length": 115.0, "eval_episode/score": 0.640625, "eval_episode/reward_rate": 0.008620689655172414}
{"step": 1150032, "time": 36085.59051179886, "eval_episode/length": 137.0, "eval_episode/score": 0.5718749761581421, "eval_episode/reward_rate": 0.007246376811594203}
{"step": 1150032, "time": 36085.879138708115, "eval_episode/length": 152.0, "eval_episode/score": 0.5249999761581421, "eval_episode/reward_rate": 0.006535947712418301}
{"step": 1150032, "time": 36087.2185280323, "eval_episode/length": 139.0, "eval_episode/score": 0.565625011920929, "eval_episode/reward_rate": 0.007142857142857143}
{"step": 1150032, "time": 36087.31519174576, "eval_episode/length": 115.0, "eval_episode/score": 0.640625, "eval_episode/reward_rate": 0.008620689655172414}
{"step": 1150032, "time": 36087.82334113121, "eval_episode/length": 106.0, "eval_episode/score": 0.668749988079071, "eval_episode/reward_rate": 0.009345794392523364}
{"step": 1150136, "time": 36090.74957728386, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1150208, "time": 36093.17197537422, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 1150344, "time": 36097.15965461731, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1150560, "time": 36103.955032110214, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 1150584, "time": 36104.463034152985, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1150808, "time": 36111.28754043579, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1151096, "time": 36120.03712081909, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1151096, "time": 36120.04619002342, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1151120, "time": 36120.99942493439, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 1151216, "time": 36123.920748233795, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1151248, "time": 36124.900866508484, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1151344, "time": 36127.946751117706, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 1151408, "time": 36129.870921611786, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 1151472, "time": 36131.84262943268, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 1151608, "time": 36135.73676609993, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1151736, "time": 36139.62253284454, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1151760, "time": 36140.576583623886, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1152168, "time": 36152.79248404503, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1152552, "time": 36164.57843351364, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1152688, "time": 36168.95728516579, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1152696, "time": 36168.98757529259, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 1153408, "time": 36190.985998392105, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1153528, "time": 36194.43648147583, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1153664, "time": 36198.83024287224, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1153688, "time": 36199.34712958336, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1153720, "time": 36200.34078168869, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1153736, "time": 36200.83342695236, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1153784, "time": 36202.29509687424, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1154072, "time": 36211.102747917175, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1154328, "time": 36219.051476716995, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1154736, "time": 36231.735592365265, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1154880, "time": 36236.11653184891, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1155032, "time": 36240.526494026184, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 1155264, "time": 36248.40336179733, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1155392, "time": 36252.28087186813, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 1155576, "time": 36257.63745427132, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1155640, "time": 36259.60032367706, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1155720, "time": 36262.04186415672, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1155801, "time": 36265.54388332367, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.5667428498220914, "train/action_min": 0.0, "train/action_std": 1.7492403801124874, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0096316013927802, "train/actor_opt_grad_steps": 71135.0, "train/actor_opt_loss": -24.31791671431891, "train/adv_mag": 0.8258494525262625, "train/adv_max": 0.38267171264875055, "train/adv_mean": 0.0025388472788991107, "train/adv_min": -0.7184321635430402, "train/adv_std": 0.0274460305837859, "train/cont_avg": 0.9936185024752475, "train/cont_loss_mean": 0.026068804329168974, "train/cont_loss_std": 0.2869606302258107, "train/cont_neg_acc": 0.1612472960928289, "train/cont_neg_loss": 3.221812155480395, "train/cont_pos_acc": 0.9998638202058207, "train/cont_pos_loss": 0.005486431394445498, "train/cont_pred": 0.9936060749068119, "train/cont_rate": 0.9936185024752475, "train/dyn_loss_mean": 1.0000000354087, "train/dyn_loss_std": 1.131050348613817e-06, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.13774210028350353, "train/extr_critic_critic_opt_grad_steps": 71135.0, "train/extr_critic_critic_opt_loss": 6502.754972250154, "train/extr_critic_mag": 1.7335055924878262, "train/extr_critic_max": 1.7335055924878262, "train/extr_critic_mean": 1.6022418985272397, "train/extr_critic_min": 1.134654149560645, "train/extr_critic_std": 0.03666145413523853, "train/extr_return_normed_mag": 0.8610795187478019, "train/extr_return_normed_max": 0.3172282576560974, "train/extr_return_normed_mean": 0.07610018774498217, "train/extr_return_normed_min": -0.7349931196411057, "train/extr_return_normed_std": 0.04692017813535905, "train/extr_return_rate": 0.9997802199703631, "train/extr_return_raw_mag": 1.8459087232551952, "train/extr_return_raw_max": 1.8459087232551952, "train/extr_return_raw_mean": 1.6047807253233277, "train/extr_return_raw_min": 0.7936873459579921, "train/extr_return_raw_std": 0.04692017813535905, "train/extr_reward_mag": 0.24590538220830482, "train/extr_reward_max": 0.24590538220830482, "train/extr_reward_mean": 0.0025802235295396703, "train/extr_reward_min": 2.0891132921275526e-07, "train/extr_reward_std": 0.008989567654022928, "train/image_loss_mean": 0.08585641455679836, "train/image_loss_std": 0.10211047305181475, "train/model_loss_mean": 0.7345489095343222, "train/model_loss_std": 0.5657229726341101, "train/model_opt_grad_norm": 16.141024480411662, "train/model_opt_grad_steps": 71070.71287128713, "train/model_opt_loss": 3932.829699827893, "train/model_opt_model_opt_grad_overflow": 0.0049504950495049506, "train/model_opt_model_opt_grad_scale": 5321.782178217822, "train/policy_entropy_mag": 1.2597143313672283, "train/policy_entropy_max": 1.2597143313672283, "train/policy_entropy_mean": 0.08838273352473089, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.10504710132090173, "train/policy_logprob_mag": 6.551080267028053, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.0881026412295823, "train/policy_logprob_min": -6.551080267028053, "train/policy_logprob_std": 0.6247600004224494, "train/policy_randomness_mag": 0.647365144573816, "train/policy_randomness_max": 0.647365144573816, "train/policy_randomness_mean": 0.04541974378251793, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.053983534455741986, "train/post_ent_mag": 28.437981482779627, "train/post_ent_max": 28.437981482779627, "train/post_ent_mean": 27.913026762480783, "train/post_ent_min": 27.420540979593106, "train/post_ent_std": 0.2168730770302291, "train/prior_ent_mag": 28.004823656365424, "train/prior_ent_max": 28.004823656365424, "train/prior_ent_mean": 27.54241123766002, "train/prior_ent_min": 26.883835292098546, "train/prior_ent_std": 0.17815496315165322, "train/rep_loss_mean": 1.0000000354087, "train/rep_loss_std": 1.131050348613817e-06, "train/reward_avg": 0.0030638440016491136, "train/reward_loss_mean": 0.022623645973917427, "train/reward_loss_std": 0.2815609708668129, "train/reward_max_data": 0.8101949272769513, "train/reward_max_pred": 0.30702447537148353, "train/reward_neg_acc": 0.9994902058993236, "train/reward_neg_loss": 0.004132983603256543, "train/reward_pos_acc": 0.13591206635362538, "train/reward_pos_loss": 4.109360803910835, "train/reward_pred": 0.0024109799927792114, "train/reward_rate": 0.004515392945544554, "train_stats/mean_log_entropy": 0.07880219016777407, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.01604144088923931, "report/cont_loss_std": 0.19477427005767822, "report/cont_neg_acc": 0.4000000059604645, "report/cont_neg_loss": 2.1513936519622803, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.005563755519688129, "report/cont_pred": 0.9924964904785156, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.09201093763113022, "report/image_loss_std": 0.10520362854003906, "report/model_loss_mean": 0.7208011150360107, "report/model_loss_std": 0.40651845932006836, "report/post_ent_mag": 28.510784149169922, "report/post_ent_max": 28.510784149169922, "report/post_ent_mean": 27.965377807617188, "report/post_ent_min": 27.417373657226562, "report/post_ent_std": 0.23088473081588745, "report/prior_ent_mag": 28.05666160583496, "report/prior_ent_max": 28.05666160583496, "report/prior_ent_mean": 27.63407325744629, "report/prior_ent_min": 26.88385772705078, "report/prior_ent_std": 0.1832762211561203, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0020080567337572575, "report/reward_loss_mean": 0.012748670764267445, "report/reward_loss_std": 0.19902899861335754, "report/reward_max_data": 0.8656250238418579, "report/reward_max_pred": 0.8469439744949341, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.003804989857599139, "report/reward_pos_acc": 0.3333333432674408, "report/reward_pos_loss": 3.0565812587738037, "report/reward_pred": 0.0027941521257162094, "report/reward_rate": 0.0029296875, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.02629036456346512, "eval/cont_loss_std": 0.37563443183898926, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.886414527893066, "eval/cont_pos_acc": 0.9980410933494568, "eval/cont_pos_loss": 0.009071585722267628, "eval/cont_pred": 0.9929083585739136, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.1028137058019638, "eval/image_loss_std": 0.10532096773386002, "eval/model_loss_mean": 0.7441256046295166, "eval/model_loss_std": 0.5350401997566223, "eval/post_ent_mag": 28.51178741455078, "eval/post_ent_max": 28.51178741455078, "eval/post_ent_mean": 28.040157318115234, "eval/post_ent_min": 27.54365348815918, "eval/post_ent_std": 0.1967529058456421, "eval/prior_ent_mag": 28.070953369140625, "eval/prior_ent_max": 28.070953369140625, "eval/prior_ent_mean": 27.654586791992188, "eval/prior_ent_min": 26.851001739501953, "eval/prior_ent_std": 0.17617952823638916, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0011566162575036287, "eval/reward_loss_mean": 0.015021486207842827, "eval/reward_loss_std": 0.233482226729393, "eval/reward_max_data": 0.793749988079071, "eval/reward_max_pred": 0.28037822246551514, "eval/reward_neg_acc": 0.9990215301513672, "eval/reward_neg_loss": 0.004792861174792051, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.241848945617676, "eval/reward_pred": 0.002465315628796816, "eval/reward_rate": 0.001953125, "replay/size": 1000000.0, "replay/inserts": 32208.0, "replay/samples": 32208.0, "replay/insert_wait_avg": 1.3005390015633853e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.442066702390274e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5528.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1039366770411712e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.98377799987793e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0584125518799, "timer/env.step_count": 4026.0, "timer/env.step_total": 39.436325550079346, "timer/env.step_frac": 0.039434022108217115, "timer/env.step_avg": 0.009795411214624775, "timer/env.step_min": 0.007657766342163086, "timer/env.step_max": 0.03617429733276367, "timer/replay._sample_count": 32208.0, "timer/replay._sample_total": 16.98798704147339, "timer/replay._sample_frac": 0.016986994787759065, "timer/replay._sample_avg": 0.0005274461947799736, "timer/replay._sample_min": 0.0004253387451171875, "timer/replay._sample_max": 0.030495882034301758, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4717.0, "timer/agent.policy_total": 50.071088552474976, "timer/agent.policy_frac": 0.05006816394325111, "timer/agent.policy_avg": 0.010615028313011443, "timer/agent.policy_min": 0.00907588005065918, "timer/agent.policy_max": 0.09342527389526367, "timer/dataset_train_count": 2013.0, "timer/dataset_train_total": 0.232346773147583, "timer/dataset_train_frac": 0.00023233320197236937, "timer/dataset_train_avg": 0.00011542313618856583, "timer/dataset_train_min": 0.00010013580322265625, "timer/dataset_train_max": 0.0003781318664550781, "timer/agent.train_count": 2013.0, "timer/agent.train_total": 897.7287158966064, "timer/agent.train_frac": 0.8976762803343101, "timer/agent.train_avg": 0.4459655816674647, "timer/agent.train_min": 0.4355504512786865, "timer/agent.train_max": 0.6964254379272461, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47847604751586914, "timer/agent.report_frac": 0.0004784481001413978, "timer/agent.report_avg": 0.23923802375793457, "timer/agent.report_min": 0.232558012008667, "timer/agent.report_max": 0.24591803550720215, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.337860107421875e-05, "timer/dataset_eval_frac": 3.3376651458833836e-08, "timer/dataset_eval_avg": 3.337860107421875e-05, "timer/dataset_eval_min": 3.337860107421875e-05, "timer/dataset_eval_max": 3.337860107421875e-05, "fps": 32.20545173060928}
{"step": 1155976, "time": 36270.595219135284, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1155984, "time": 36271.0654964447, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1156032, "time": 36272.53526592255, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1156096, "time": 36274.47452402115, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1156256, "time": 36279.43180465698, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1156288, "time": 36280.42373800278, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1156304, "time": 36280.914179325104, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1156408, "time": 36283.83749985695, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1156848, "time": 36297.40255713463, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1156920, "time": 36299.37974476814, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1157016, "time": 36302.316700935364, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1157128, "time": 36305.74661207199, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1157248, "time": 36309.749418497086, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1157288, "time": 36310.7427482605, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1157416, "time": 36314.63959860802, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1157888, "time": 36329.277842998505, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1157928, "time": 36330.27648854256, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1157992, "time": 36332.21512269974, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1158016, "time": 36333.17010164261, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1158256, "time": 36340.53889751434, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 1158344, "time": 36342.99225091934, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1158616, "time": 36351.342096328735, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1158744, "time": 36355.25695705414, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1159136, "time": 36367.45727086067, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1159160, "time": 36367.98835134506, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1159440, "time": 36376.70243000984, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1159496, "time": 36378.20383787155, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 1159888, "time": 36390.29167509079, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1160016, "time": 36395.97091960907, "eval_episode/length": 70.0, "eval_episode/score": 0.78125, "eval_episode/reward_rate": 0.014084507042253521}
{"step": 1160016, "time": 36396.3172454834, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 1160016, "time": 36397.285126924515, "eval_episode/length": 124.0, "eval_episode/score": 0.612500011920929, "eval_episode/reward_rate": 0.008}
{"step": 1160016, "time": 36397.3306081295, "eval_episode/length": 55.0, "eval_episode/score": 0.828125, "eval_episode/reward_rate": 0.017857142857142856}
{"step": 1160016, "time": 36397.4148709774, "eval_episode/length": 130.0, "eval_episode/score": 0.59375, "eval_episode/reward_rate": 0.007633587786259542}
{"step": 1160016, "time": 36397.4409930706, "eval_episode/length": 131.0, "eval_episode/score": 0.590624988079071, "eval_episode/reward_rate": 0.007575757575757576}
{"step": 1160016, "time": 36397.77934360504, "eval_episode/length": 67.0, "eval_episode/score": 0.7906249761581421, "eval_episode/reward_rate": 0.014705882352941176}
{"step": 1160016, "time": 36398.10802125931, "eval_episode/length": 165.0, "eval_episode/score": 0.484375, "eval_episode/reward_rate": 0.006024096385542169}
{"step": 1160240, "time": 36404.912675857544, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1160320, "time": 36407.372057914734, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 1160328, "time": 36407.40127801895, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1160544, "time": 36414.179793834686, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1160656, "time": 36417.60072350502, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1161056, "time": 36429.902790784836, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1161240, "time": 36435.29742646217, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1161568, "time": 36445.517792224884, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1161680, "time": 36448.91879224777, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1161752, "time": 36450.89788603783, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1161760, "time": 36451.36690711975, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1161808, "time": 36452.82627558708, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1161880, "time": 36454.819946050644, "episode/length": 204.0, "episode/score": 0.36250001192092896, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.0}
{"step": 1162176, "time": 36464.07352900505, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1162216, "time": 36465.08767366409, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1162400, "time": 36470.91194272041, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 1162416, "time": 36471.410024642944, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1162848, "time": 36484.68627500534, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1162872, "time": 36485.19416117668, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1162936, "time": 36487.27522730827, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1162968, "time": 36488.26047515869, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1163016, "time": 36489.74346494675, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1163552, "time": 36506.665108680725, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1163680, "time": 36510.54842424393, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1163704, "time": 36511.06320691109, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1163768, "time": 36513.01327109337, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1163888, "time": 36516.984988451004, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 1164072, "time": 36522.33711695671, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1164096, "time": 36523.29456400871, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1164232, "time": 36527.19557905197, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 1164264, "time": 36528.1724319458, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1164416, "time": 36533.02006864548, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1164720, "time": 36542.27874016762, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1164848, "time": 36546.174676179886, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1165112, "time": 36554.11299443245, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1165152, "time": 36555.55033969879, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1165184, "time": 36556.52010822296, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1165488, "time": 36565.696734428406, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 1165784, "time": 36574.4239897728, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1165864, "time": 36576.93830323219, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1165912, "time": 36578.40560865402, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1166160, "time": 36586.12576985359, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1166208, "time": 36587.60253953934, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1166344, "time": 36591.497999191284, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1166536, "time": 36597.3583817482, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1166552, "time": 36597.846032857895, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1166576, "time": 36598.80964374542, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1167000, "time": 36611.5857937336, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1167032, "time": 36612.56242394447, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1167160, "time": 36616.4809422493, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1167304, "time": 36620.853687524796, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1167544, "time": 36628.161527872086, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1167728, "time": 36633.95698261261, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1167784, "time": 36635.43590760231, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1167792, "time": 36635.924493551254, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 1167800, "time": 36635.95246219635, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1167936, "time": 36640.38871741295, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1168072, "time": 36644.35195016861, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1168176, "time": 36647.73716330528, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1168248, "time": 36649.7113339901, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1168288, "time": 36651.17222690582, "episode/length": 213.0, "episode/score": 0.3343749940395355, "episode/reward_rate": 0.004672897196261682, "episode/intrinsic_return": 0.0}
{"step": 1168392, "time": 36654.103667259216, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1168416, "time": 36655.06275677681, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1168424, "time": 36655.09119939804, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1168448, "time": 36656.069539785385, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1168664, "time": 36662.41262459755, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1168824, "time": 36667.384459495544, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1168872, "time": 36668.858498334885, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1168912, "time": 36670.32743859291, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1168984, "time": 36672.292862415314, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1169208, "time": 36679.11734580994, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1169272, "time": 36681.08242177963, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1169288, "time": 36681.57168126106, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1169856, "time": 36699.28209686279, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1169936, "time": 36701.75348806381, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1170000, "time": 36704.85005235672, "eval_episode/length": 56.0, "eval_episode/score": 0.824999988079071, "eval_episode/reward_rate": 0.017543859649122806}
{"step": 1170000, "time": 36705.221824884415, "eval_episode/length": 18.0, "eval_episode/score": 0.9437500238418579, "eval_episode/reward_rate": 0.05263157894736842}
{"step": 1170000, "time": 36705.450800418854, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 1170000, "time": 36705.83239507675, "eval_episode/length": 105.0, "eval_episode/score": 0.671875, "eval_episode/reward_rate": 0.009433962264150943}
{"step": 1170000, "time": 36706.28564405441, "eval_episode/length": 128.0, "eval_episode/score": 0.6000000238418579, "eval_episode/reward_rate": 0.007751937984496124}
{"step": 1170000, "time": 36707.66890311241, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 1170000, "time": 36709.45772123337, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1170000, "time": 36709.46547627449, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1170000, "time": 36709.47485947609, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1170000, "time": 36709.48274898529, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1170480, "time": 36724.131880283356, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1170672, "time": 36730.13826942444, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 1170688, "time": 36730.63402366638, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 1170792, "time": 36733.58413863182, "episode/length": 14.0, "episode/score": 0.956250011920929, "episode/reward_rate": 0.06666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1170832, "time": 36735.05977988243, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1170912, "time": 36737.50536441803, "episode/length": 14.0, "episode/score": 0.956250011920929, "episode/reward_rate": 0.06666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1170976, "time": 36739.470240831375, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1170992, "time": 36739.98972821236, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1171136, "time": 36744.36189746857, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1171184, "time": 36745.85510110855, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1171368, "time": 36751.27993392944, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1171368, "time": 36751.28634381294, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1171456, "time": 36754.35740852356, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1171520, "time": 36756.82465338707, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1171688, "time": 36761.74275994301, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1171720, "time": 36762.72381186485, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1172416, "time": 36784.16870164871, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1172456, "time": 36785.17965054512, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 1172504, "time": 36786.768014431, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1173304, "time": 36811.193435668945, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1173368, "time": 36813.14535522461, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1173512, "time": 36817.65031719208, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1173768, "time": 36825.54160308838, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1173832, "time": 36827.50456738472, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1174000, "time": 36832.88822841644, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1174032, "time": 36833.892595529556, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1174152, "time": 36837.341594696045, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1174152, "time": 36837.35194206238, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 1174184, "time": 36838.33208632469, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1174264, "time": 36840.784465789795, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1174320, "time": 36842.72194862366, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1174416, "time": 36845.65414762497, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1174584, "time": 36850.75002121925, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 1174768, "time": 36856.673666238785, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1174816, "time": 36858.17315721512, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1175040, "time": 36865.13939666748, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1175240, "time": 36871.090517520905, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 1175256, "time": 36871.5905148983, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1175288, "time": 36872.57872414589, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1175368, "time": 36875.05265331268, "episode/length": 15.0, "episode/score": 0.953125, "episode/reward_rate": 0.0625, "episode/intrinsic_return": 0.0}
{"step": 1175736, "time": 36886.47195959091, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1176184, "time": 36900.20271062851, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1176280, "time": 36903.14693427086, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1176464, "time": 36909.036286354065, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1176496, "time": 36910.018864154816, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1176728, "time": 36916.938907146454, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1176896, "time": 36922.340134859085, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 1176968, "time": 36924.35478043556, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1177000, "time": 36925.34508395195, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1177080, "time": 36927.809742450714, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1177296, "time": 36934.68741226196, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 1177344, "time": 36936.17106604576, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1177352, "time": 36936.20050764084, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1177376, "time": 36937.30509638786, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1177744, "time": 36948.63430047035, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1177824, "time": 36951.07202124596, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1177896, "time": 36953.07185578346, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1178016, "time": 36956.95327210426, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 1178648, "time": 36976.330006599426, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 1178760, "time": 36979.7781765461, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1178808, "time": 36981.2662858963, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1178984, "time": 36986.656692028046, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1179312, "time": 36997.03687167168, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1179344, "time": 36998.01690673828, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1179656, "time": 37007.54109072685, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1179904, "time": 37015.62622690201, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1180056, "time": 37020.03368282318, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1180064, "time": 37020.50889515877, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 1180088, "time": 37022.20327043533, "eval_episode/length": 55.0, "eval_episode/score": 0.828125, "eval_episode/reward_rate": 0.017857142857142856}
{"step": 1180088, "time": 37022.275331020355, "eval_episode/length": 58.0, "eval_episode/score": 0.8187500238418579, "eval_episode/reward_rate": 0.01694915254237288}
{"step": 1180088, "time": 37022.83167719841, "eval_episode/length": 84.0, "eval_episode/score": 0.737500011920929, "eval_episode/reward_rate": 0.011764705882352941}
{"step": 1180088, "time": 37023.502057790756, "eval_episode/length": 115.0, "eval_episode/score": 0.640625, "eval_episode/reward_rate": 0.008620689655172414}
{"step": 1180088, "time": 37023.82760477066, "eval_episode/length": 130.0, "eval_episode/score": 0.59375, "eval_episode/reward_rate": 0.007633587786259542}
{"step": 1180088, "time": 37024.10719323158, "eval_episode/length": 58.0, "eval_episode/score": 0.8187500238418579, "eval_episode/reward_rate": 0.01694915254237288}
{"step": 1180088, "time": 37024.17586040497, "eval_episode/length": 87.0, "eval_episode/score": 0.7281249761581421, "eval_episode/reward_rate": 0.011363636363636364}
{"step": 1180088, "time": 37024.93066096306, "eval_episode/length": 125.0, "eval_episode/score": 0.609375, "eval_episode/reward_rate": 0.007936507936507936}
{"step": 1180208, "time": 37028.93868947029, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1180344, "time": 37032.88911867142, "episode/length": 197.0, "episode/score": 0.3843750059604645, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.0}
{"step": 1180360, "time": 37033.38326835632, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1180440, "time": 37035.85626530647, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1180464, "time": 37036.820647239685, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1181072, "time": 37055.44569659233, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1181224, "time": 37059.95383787155, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1181296, "time": 37062.39027047157, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1181528, "time": 37069.271325588226, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 1181656, "time": 37073.18756198883, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1181712, "time": 37075.13456583023, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1181776, "time": 37077.11361479759, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1181808, "time": 37078.09856557846, "episode/length": 199.0, "episode/score": 0.37812501192092896, "episode/reward_rate": 0.005, "episode/intrinsic_return": 0.0}
{"step": 1181840, "time": 37079.08309817314, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1182008, "time": 37084.01673102379, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1182152, "time": 37088.565312862396, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1182288, "time": 37092.957887887955, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 1182312, "time": 37093.47474980354, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1182400, "time": 37096.44657897949, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1182656, "time": 37104.333359241486, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1182728, "time": 37106.370567560196, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1182752, "time": 37107.34528207779, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1183032, "time": 37115.85729122162, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 1183144, "time": 37119.43173766136, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1183176, "time": 37120.44626927376, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 1183216, "time": 37121.90883898735, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 1183584, "time": 37133.290095329285, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1183624, "time": 37134.30248904228, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1183656, "time": 37135.30762505531, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1184168, "time": 37151.28049850464, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1184240, "time": 37153.73196196556, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1184256, "time": 37154.231994867325, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1184472, "time": 37160.64038062096, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 1184536, "time": 37162.59558272362, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 1184600, "time": 37164.5764567852, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1184712, "time": 37167.99043226242, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1185040, "time": 37178.36125445366, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1185048, "time": 37178.39080905914, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1185456, "time": 37191.04069709778, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1185496, "time": 37192.041649103165, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1185528, "time": 37193.01324868202, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1185968, "time": 37206.61678624153, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1185968, "time": 37206.62770366669, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1186032, "time": 37208.59792351723, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1186088, "time": 37210.06785154343, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1186224, "time": 37214.4228284359, "episode/length": 210.0, "episode/score": 0.34375, "episode/reward_rate": 0.004739336492890996, "episode/intrinsic_return": 0.0}
{"step": 1186240, "time": 37214.91710090637, "episode/length": 204.0, "episode/score": 0.36250001192092896, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.0}
{"step": 1186432, "time": 37220.7885184288, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1186488, "time": 37222.273565769196, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1186784, "time": 37231.527222156525, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1187024, "time": 37239.010201215744, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1187192, "time": 37243.91418457031, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 1187368, "time": 37249.28926944733, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1187480, "time": 37252.730257987976, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 1187528, "time": 37254.201254844666, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1187808, "time": 37262.95715093613, "episode/length": 195.0, "episode/score": 0.390625, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.0}
{"step": 1187865, "time": 37268.60319662094, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.551593017578125, "train/action_min": 0.0, "train/action_std": 1.7210616207122802, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.01067802224191837, "train/actor_opt_grad_steps": 73145.0, "train/actor_opt_loss": -22.649267539978027, "train/adv_mag": 0.8772340631484985, "train/adv_max": 0.3479633492231369, "train/adv_mean": 0.00039920676464134887, "train/adv_min": -0.7930441105365753, "train/adv_std": 0.03057397875469178, "train/cont_avg": 0.9935546875, "train/cont_loss_mean": 0.026325120700057596, "train/cont_loss_std": 0.28910275852307676, "train/cont_neg_acc": 0.17235274851322174, "train/cont_neg_loss": 3.2038665364682672, "train/cont_pos_acc": 0.9998624393343926, "train/cont_pos_loss": 0.005484431749209762, "train/cont_pred": 0.993521540760994, "train/cont_rate": 0.9935546875, "train/dyn_loss_mean": 1.0000004929304123, "train/dyn_loss_std": 1.4143130974844099e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.1597651239670813, "train/extr_critic_critic_opt_grad_steps": 73145.0, "train/extr_critic_critic_opt_loss": 6452.6273046875, "train/extr_critic_mag": 1.751619508266449, "train/extr_critic_max": 1.751619508266449, "train/extr_critic_mean": 1.611184490919113, "train/extr_critic_min": 1.2093476164340973, "train/extr_critic_std": 0.03237579580396414, "train/extr_return_normed_mag": 0.924391473531723, "train/extr_return_normed_max": 0.32463505387306213, "train/extr_return_normed_mean": 0.06363046562299132, "train/extr_return_normed_min": -0.8091384202241898, "train/extr_return_normed_std": 0.04580565983429551, "train/extr_return_rate": 0.9997155258059501, "train/extr_return_raw_mag": 1.872588214278221, "train/extr_return_raw_max": 1.872588214278221, "train/extr_return_raw_mean": 1.6115836882591248, "train/extr_return_raw_min": 0.7388147401809693, "train/extr_return_raw_std": 0.04580565988086164, "train/extr_reward_mag": 0.27283424377441406, "train/extr_reward_max": 0.27283424377441406, "train/extr_reward_mean": 0.002507398602901958, "train/extr_reward_min": 1.5616416931152344e-07, "train/extr_reward_std": 0.009080974862445145, "train/image_loss_mean": 0.08481462191790343, "train/image_loss_std": 0.1013593758828938, "train/model_loss_mean": 0.7341824463009834, "train/model_loss_std": 0.5707941897585989, "train/model_opt_grad_norm": 16.56097434872958, "train/model_opt_grad_steps": 73078.93, "train/model_opt_loss": 4256.139786376953, "train/model_opt_model_opt_grad_overflow": 0.005, "train/model_opt_model_opt_grad_scale": 5775.0, "train/policy_entropy_mag": 1.2672703498601914, "train/policy_entropy_max": 1.2672703498601914, "train/policy_entropy_mean": 0.08867094036191701, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.1054424950480461, "train/policy_logprob_mag": 6.55108026266098, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.08829232815653086, "train/policy_logprob_min": -6.55108026266098, "train/policy_logprob_std": 0.6244767701625824, "train/policy_randomness_mag": 0.6512481707334519, "train/policy_randomness_max": 0.6512481707334519, "train/policy_randomness_mean": 0.04556785324588418, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.0541867264918983, "train/post_ent_mag": 28.66746883392334, "train/post_ent_max": 28.66746883392334, "train/post_ent_mean": 28.096624307632446, "train/post_ent_min": 27.588785781860352, "train/post_ent_std": 0.22782403603196144, "train/prior_ent_mag": 28.003439922332763, "train/prior_ent_max": 28.003439922332763, "train/prior_ent_mean": 27.53116849899292, "train/prior_ent_min": 26.855173845291137, "train/prior_ent_std": 0.1858704474568367, "train/rep_loss_mean": 1.0000004929304123, "train/rep_loss_std": 1.4143130974844099e-05, "train/reward_avg": 0.0032458953905734234, "train/reward_loss_mean": 0.02304238543147221, "train/reward_loss_std": 0.2840111650340259, "train/reward_max_data": 0.8180625000596047, "train/reward_max_pred": 0.3369452375173569, "train/reward_neg_acc": 0.9994455391168594, "train/reward_neg_loss": 0.004140792785910889, "train/reward_pos_acc": 0.1662519872188568, "train/reward_pos_loss": 3.976240081191063, "train/reward_pred": 0.002517529655015096, "train/reward_rate": 0.0047509765625, "train_stats/mean_log_entropy": 0.08122160341508589, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 0.04552704095840454, "report/cont_loss_std": 0.47044211626052856, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.179729461669922, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.005100249778479338, "report/cont_pred": 0.994922399520874, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.11736996471881866, "report/image_loss_std": 0.1203252300620079, "report/model_loss_mean": 0.7804405093193054, "report/model_loss_std": 0.646115779876709, "report/post_ent_mag": 28.76938819885254, "report/post_ent_max": 28.76938819885254, "report/post_ent_mean": 28.19342041015625, "report/post_ent_min": 27.655986785888672, "report/post_ent_std": 0.23532234132289886, "report/prior_ent_mag": 27.878787994384766, "report/prior_ent_max": 27.878787994384766, "report/prior_ent_mean": 27.412452697753906, "report/prior_ent_min": 26.86853790283203, "report/prior_ent_std": 0.18149898946285248, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.001757812569849193, "report/reward_loss_mean": 0.01754346489906311, "report/reward_loss_std": 0.25552839040756226, "report/reward_max_data": 0.6937500238418579, "report/reward_max_pred": 0.042470335960388184, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0037521873600780964, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.711174964904785, "report/reward_pred": 0.001893585198558867, "report/reward_rate": 0.0029296875, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.023846305906772614, "eval/cont_loss_std": 0.26092877984046936, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 4.070461273193359, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.007977228611707687, "eval/cont_pred": 0.9922720193862915, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.12509113550186157, "eval/image_loss_std": 0.12736035883426666, "eval/model_loss_mean": 0.7760803699493408, "eval/model_loss_std": 0.6447697281837463, "eval/post_ent_mag": 28.76755142211914, "eval/post_ent_max": 28.76755142211914, "eval/post_ent_mean": 28.212635040283203, "eval/post_ent_min": 27.731956481933594, "eval/post_ent_std": 0.214249387383461, "eval/prior_ent_mag": 27.87362289428711, "eval/prior_ent_max": 27.87362289428711, "eval/prior_ent_mean": 27.39643096923828, "eval/prior_ent_min": 26.74610710144043, "eval/prior_ent_std": 0.19084051251411438, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.003073120256885886, "eval/reward_loss_mean": 0.02714286930859089, "eval/reward_loss_std": 0.3499026894569397, "eval/reward_max_data": 0.8031250238418579, "eval/reward_max_pred": 0.3140749931335449, "eval/reward_neg_acc": 0.9980391263961792, "eval/reward_neg_loss": 0.0057426150888204575, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.4842071533203125, "eval/reward_pred": 0.0028615454211831093, "eval/reward_rate": 0.00390625, "replay/size": 1000000.0, "replay/inserts": 32064.0, "replay/samples": 32064.0, "replay/insert_wait_avg": 1.3111832137117366e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.238691412760112e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5096.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.174969426129639e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.238719940185547e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3982152938843, "timer/env.step_count": 4008.0, "timer/env.step_total": 40.12684512138367, "timer/env.step_frac": 0.04011087235855945, "timer/env.step_avg": 0.010011687904536843, "timer/env.step_min": 0.007835149765014648, "timer/env.step_max": 0.04654836654663086, "timer/replay._sample_count": 32064.0, "timer/replay._sample_total": 16.954638957977295, "timer/replay._sample_frac": 0.016947890048960728, "timer/replay._sample_avg": 0.0005287749176015872, "timer/replay._sample_min": 0.00041174888610839844, "timer/replay._sample_max": 0.026694536209106445, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4645.0, "timer/agent.policy_total": 50.734814405441284, "timer/agent.policy_frac": 0.05071461906850469, "timer/agent.policy_avg": 0.010922457353162817, "timer/agent.policy_min": 0.009100675582885742, "timer/agent.policy_max": 0.10487794876098633, "timer/dataset_train_count": 2004.0, "timer/dataset_train_total": 0.23869872093200684, "timer/dataset_train_frac": 0.00023860370528738393, "timer/dataset_train_avg": 0.00011911113818962416, "timer/dataset_train_min": 0.00010228157043457031, "timer/dataset_train_max": 0.0006339550018310547, "timer/agent.train_count": 2004.0, "timer/agent.train_total": 896.3643946647644, "timer/agent.train_frac": 0.8960075907386958, "timer/agent.train_avg": 0.44728762208820577, "timer/agent.train_min": 0.43576598167419434, "timer/agent.train_max": 0.682201623916626, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.472395658493042, "timer/agent.report_frac": 0.000472207618197587, "timer/agent.report_avg": 0.236197829246521, "timer/agent.report_min": 0.22823262214660645, "timer/agent.report_max": 0.24416303634643555, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0040740966796875e-05, "timer/dataset_eval_frac": 3.002878304613117e-08, "timer/dataset_eval_avg": 3.0040740966796875e-05, "timer/dataset_eval_min": 3.0040740966796875e-05, "timer/dataset_eval_max": 3.0040740966796875e-05, "fps": 32.050578604720286}
{"step": 1187928, "time": 37270.30018782616, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1188024, "time": 37273.23368692398, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 1188224, "time": 37279.591395139694, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1188232, "time": 37279.6204726696, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 1188344, "time": 37283.066668987274, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1188488, "time": 37287.46852326393, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1188536, "time": 37288.9403591156, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1188600, "time": 37290.923575401306, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1188800, "time": 37297.38694381714, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1189200, "time": 37309.61143326759, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1189216, "time": 37310.100922584534, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1189296, "time": 37312.53553271294, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1189304, "time": 37312.56392621994, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1189328, "time": 37313.51395988464, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1189352, "time": 37314.02842068672, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1189680, "time": 37324.215257406235, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1189936, "time": 37332.158487319946, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1189968, "time": 37333.12910962105, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 1190072, "time": 37337.197754859924, "eval_episode/length": 54.0, "eval_episode/score": 0.831250011920929, "eval_episode/reward_rate": 0.01818181818181818}
{"step": 1190072, "time": 37337.94654035568, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 1190072, "time": 37338.01217508316, "eval_episode/length": 95.0, "eval_episode/score": 0.703125, "eval_episode/reward_rate": 0.010416666666666666}
{"step": 1190072, "time": 37338.1711165905, "eval_episode/length": 103.0, "eval_episode/score": 0.6781250238418579, "eval_episode/reward_rate": 0.009615384615384616}
{"step": 1190072, "time": 37338.23620343208, "eval_episode/length": 106.0, "eval_episode/score": 0.668749988079071, "eval_episode/reward_rate": 0.009345794392523364}
{"step": 1190072, "time": 37338.28353333473, "eval_episode/length": 53.0, "eval_episode/score": 0.8343750238418579, "eval_episode/reward_rate": 0.018518518518518517}
{"step": 1190072, "time": 37338.96158409119, "eval_episode/length": 46.0, "eval_episode/score": 0.856249988079071, "eval_episode/reward_rate": 0.02127659574468085}
{"step": 1190072, "time": 37339.089069604874, "eval_episode/length": 148.0, "eval_episode/score": 0.5375000238418579, "eval_episode/reward_rate": 0.006711409395973154}
{"step": 1190176, "time": 37342.45839929581, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1190216, "time": 37343.47312736511, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1190544, "time": 37353.657635211945, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1190792, "time": 37361.04696512222, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1190880, "time": 37363.94072699547, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1190952, "time": 37365.89268517494, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1191120, "time": 37371.22848749161, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1191232, "time": 37374.67263031006, "episode/length": 13.0, "episode/score": 0.9593750238418579, "episode/reward_rate": 0.07142857142857142, "episode/intrinsic_return": 0.0}
{"step": 1191344, "time": 37378.10372424126, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1191528, "time": 37383.51268815994, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1191608, "time": 37385.9376707077, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1191616, "time": 37386.433003902435, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1191856, "time": 37393.81504178047, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1191872, "time": 37394.30814957619, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1192072, "time": 37400.20067334175, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 1192072, "time": 37400.21307349205, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 1192256, "time": 37406.084918022156, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0}
{"step": 1192280, "time": 37406.62458896637, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1192328, "time": 37408.10318803787, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1192368, "time": 37409.555211782455, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1192536, "time": 37414.50818181038, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1193264, "time": 37437.212411403656, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1193560, "time": 37446.050798654556, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 1193656, "time": 37449.10595870018, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1193856, "time": 37455.42691326141, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1194016, "time": 37460.32265663147, "episode/length": 267.0, "episode/score": 0.16562500596046448, "episode/reward_rate": 0.0037313432835820895, "episode/intrinsic_return": 0.0}
{"step": 1194208, "time": 37466.21861600876, "episode/length": 240.0, "episode/score": 0.25, "episode/reward_rate": 0.004149377593360996, "episode/intrinsic_return": 0.0}
{"step": 1194256, "time": 37467.68903708458, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1194384, "time": 37471.612182855606, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1194392, "time": 37471.641629457474, "episode/length": 16.0, "episode/score": 0.949999988079071, "episode/reward_rate": 0.058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 1194416, "time": 37472.60055351257, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1194424, "time": 37472.62907624245, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1194520, "time": 37475.56315636635, "episode/length": 12.0, "episode/score": 0.9624999761581421, "episode/reward_rate": 0.07692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1194640, "time": 37479.54244995117, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1194680, "time": 37480.56008529663, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1194848, "time": 37485.8994371891, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1194976, "time": 37489.77939033508, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1195072, "time": 37492.71514606476, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1195144, "time": 37494.68074297905, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1195440, "time": 37503.99323773384, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1195472, "time": 37504.992495298386, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1195480, "time": 37505.02162384987, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1195936, "time": 37519.27334666252, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1196320, "time": 37531.52385663986, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 1196544, "time": 37538.52727532387, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1196576, "time": 37539.51587295532, "episode/length": 268.0, "episode/score": 0.16249999403953552, "episode/reward_rate": 0.0037174721189591076, "episode/intrinsic_return": 0.0}
{"step": 1196640, "time": 37541.49998021126, "episode/length": 195.0, "episode/score": 0.390625, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.0}
{"step": 1196688, "time": 37542.966646909714, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1196704, "time": 37543.46389746666, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1197160, "time": 37557.25543999672, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1197272, "time": 37560.7369685173, "episode/length": 228.0, "episode/score": 0.2874999940395355, "episode/reward_rate": 0.004366812227074236, "episode/intrinsic_return": 0.0}
{"step": 1197512, "time": 37568.30403423309, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1197936, "time": 37581.631596803665, "episode/length": 249.0, "episode/score": 0.22187499701976776, "episode/reward_rate": 0.004, "episode/intrinsic_return": 0.0}
{"step": 1198136, "time": 37587.56606268883, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1198504, "time": 37598.98507666588, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1198632, "time": 37602.971980810165, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1198720, "time": 37605.91236948967, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1198888, "time": 37610.87469291687, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1198904, "time": 37611.37388801575, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1198952, "time": 37612.85282969475, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1199016, "time": 37614.83566212654, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1199408, "time": 37627.28160619736, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1199472, "time": 37629.2710609436, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1199752, "time": 37637.58686900139, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1199816, "time": 37639.55581712723, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1199872, "time": 37641.47406697273, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1199880, "time": 37641.501435279846, "episode/length": 7.0, "episode/score": 0.9781249761581421, "episode/reward_rate": 0.125, "episode/intrinsic_return": 0.0}
{"step": 1199936, "time": 37643.42385220528, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1200056, "time": 37647.679112911224, "eval_episode/length": 40.0, "eval_episode/score": 0.875, "eval_episode/reward_rate": 0.024390243902439025}
{"step": 1200056, "time": 37648.69554591179, "eval_episode/length": 90.0, "eval_episode/score": 0.71875, "eval_episode/reward_rate": 0.01098901098901099}
{"step": 1200056, "time": 37648.721948862076, "eval_episode/length": 91.0, "eval_episode/score": 0.715624988079071, "eval_episode/reward_rate": 0.010869565217391304}
{"step": 1200056, "time": 37650.646580696106, "eval_episode/length": 187.0, "eval_episode/score": 0.4156250059604645, "eval_episode/reward_rate": 0.005319148936170213}
{"step": 1200056, "time": 37651.09027028084, "eval_episode/length": 117.0, "eval_episode/score": 0.6343749761581421, "eval_episode/reward_rate": 0.00847457627118644}
{"step": 1200056, "time": 37651.38606214523, "eval_episode/length": 182.0, "eval_episode/score": 0.4312500059604645, "eval_episode/reward_rate": 0.00546448087431694}
{"step": 1200056, "time": 37652.2840154171, "eval_episode/length": 174.0, "eval_episode/score": 0.45625001192092896, "eval_episode/reward_rate": 0.005714285714285714}
{"step": 1200056, "time": 37652.768181324005, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1200056, "time": 37652.77686524391, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1200056, "time": 37652.78493642807, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1200056, "time": 37652.79320168495, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1200232, "time": 37658.26825547218, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1200288, "time": 37660.20873451233, "episode/length": 222.0, "episode/score": 0.3062500059604645, "episode/reward_rate": 0.004484304932735426, "episode/intrinsic_return": 0.0}
{"step": 1200384, "time": 37663.10605978966, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1200760, "time": 37674.329436302185, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1200800, "time": 37675.77532696724, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1201024, "time": 37682.552854299545, "episode/length": 264.0, "episode/score": 0.17499999701976776, "episode/reward_rate": 0.0037735849056603774, "episode/intrinsic_return": 0.0}
{"step": 1201080, "time": 37684.042172431946, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1201128, "time": 37685.48818182945, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1201208, "time": 37687.99800038338, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1201544, "time": 37698.27601528168, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1201744, "time": 37704.62960147858, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1201784, "time": 37705.631929159164, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1202128, "time": 37716.346245765686, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 1202248, "time": 37719.89947247505, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1202480, "time": 37727.22113084793, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1202536, "time": 37728.737240076065, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1202544, "time": 37729.21290850639, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1202600, "time": 37730.70679974556, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1202624, "time": 37731.6639919281, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 1202816, "time": 37737.52877140045, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 1202912, "time": 37740.46502614021, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 1203072, "time": 37745.33321475983, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1203472, "time": 37757.638664245605, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1203608, "time": 37761.53799676895, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1203776, "time": 37766.8622276783, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1204048, "time": 37775.14292550087, "episode/length": 187.0, "episode/score": 0.4156250059604645, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.0}
{"step": 1204064, "time": 37775.63626599312, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1204336, "time": 37784.50439167023, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1204440, "time": 37787.462208747864, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1204600, "time": 37792.35034418106, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1204680, "time": 37794.77545952797, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1204936, "time": 37802.50131917, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1204944, "time": 37802.97284054756, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 1205304, "time": 37813.86781477928, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1205320, "time": 37814.364938020706, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1205384, "time": 37816.32710528374, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1205600, "time": 37823.12877869606, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1205600, "time": 37823.13700795174, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 1205712, "time": 37826.5705678463, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1205744, "time": 37827.54976224899, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1205792, "time": 37829.022626161575, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1205904, "time": 37832.45238351822, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1206376, "time": 37846.76597523689, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1206424, "time": 37848.2319214344, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1206560, "time": 37852.613555669785, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1206616, "time": 37854.100184202194, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1206632, "time": 37854.59339785576, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 1206640, "time": 37855.065507650375, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1206952, "time": 37864.40646791458, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 1206984, "time": 37865.38738369942, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1207352, "time": 37876.74070930481, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1207376, "time": 37877.705121040344, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1207400, "time": 37878.223205804825, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1207672, "time": 37886.572578668594, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 1207808, "time": 37890.97293257713, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1207912, "time": 37893.93327307701, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1208304, "time": 37906.322717905045, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1208464, "time": 37911.224974155426, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1208520, "time": 37912.72121429443, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1208560, "time": 37914.17478775978, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1208592, "time": 37915.16509604454, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 1208672, "time": 37917.59749794006, "episode/length": 18.0, "episode/score": 0.9437500238418579, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.0}
{"step": 1208728, "time": 37919.093205690384, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 1208736, "time": 37919.57102870941, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1208944, "time": 37925.98081731796, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1209064, "time": 37929.50253486633, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 1209264, "time": 37935.86660647392, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1209376, "time": 37939.291486263275, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1209376, "time": 37939.300461530685, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1209776, "time": 37951.49237179756, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1209784, "time": 37951.52150154114, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 1209816, "time": 37952.505151987076, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1210040, "time": 37961.3228430748, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 1210040, "time": 37961.703694820404, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 1210040, "time": 37961.98449206352, "eval_episode/length": 94.0, "eval_episode/score": 0.706250011920929, "eval_episode/reward_rate": 0.010526315789473684}
{"step": 1210040, "time": 37962.09239625931, "eval_episode/length": 99.0, "eval_episode/score": 0.690625011920929, "eval_episode/reward_rate": 0.01}
{"step": 1210040, "time": 37962.280884981155, "eval_episode/length": 8.0, "eval_episode/score": 0.9750000238418579, "eval_episode/reward_rate": 0.1111111111111111}
{"step": 1210040, "time": 37963.31617951393, "eval_episode/length": 51.0, "eval_episode/score": 0.840624988079071, "eval_episode/reward_rate": 0.019230769230769232}
{"step": 1210040, "time": 37963.463082790375, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 1210040, "time": 37963.592950582504, "eval_episode/length": 173.0, "eval_episode/score": 0.4593749940395355, "eval_episode/reward_rate": 0.005747126436781609}
{"step": 1210152, "time": 37967.01718831062, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1210168, "time": 37967.52005600929, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1210328, "time": 37972.45170664787, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 1210376, "time": 37973.97247123718, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 1210384, "time": 37974.452407598495, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1210616, "time": 37981.34198522568, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1210904, "time": 37990.306689977646, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1210984, "time": 37992.77576684952, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1211064, "time": 37995.28073978424, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1211152, "time": 37998.23784041405, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1211176, "time": 37998.7560031414, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1211336, "time": 38003.679379463196, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1211376, "time": 38005.11011004448, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1211712, "time": 38015.29412603378, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1211776, "time": 38017.343153715134, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1211872, "time": 38020.26141476631, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1211968, "time": 38023.17588543892, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1212128, "time": 38028.05600357056, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1212408, "time": 38036.28866791725, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1212472, "time": 38038.79970264435, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1212584, "time": 38042.24955654144, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1212688, "time": 38045.66373848915, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1213224, "time": 38061.92761850357, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1213296, "time": 38064.35904598236, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1213376, "time": 38066.79506158829, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1213688, "time": 38076.029747247696, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1213784, "time": 38079.044637680054, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1213912, "time": 38082.96158075333, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 1214040, "time": 38086.88259148598, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1214184, "time": 38091.2562828064, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1214200, "time": 38091.766696214676, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1214304, "time": 38095.15059089661, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1214424, "time": 38098.5830886364, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1214440, "time": 38099.08090519905, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1214480, "time": 38100.51477408409, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1214640, "time": 38105.38512420654, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1214680, "time": 38106.47096037865, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1214776, "time": 38109.461250543594, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1214864, "time": 38112.37637400627, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1215296, "time": 38125.546306848526, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1215304, "time": 38125.574687957764, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1215664, "time": 38136.89206075668, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 1215752, "time": 38139.350847005844, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1216224, "time": 38154.01515960693, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1216488, "time": 38161.856738328934, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1216496, "time": 38162.33620238304, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1216648, "time": 38166.9672601223, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1216656, "time": 38167.45063829422, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1216752, "time": 38170.42583656311, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 1216752, "time": 38170.43374609947, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1216888, "time": 38174.35083389282, "episode/length": 275.0, "episode/score": 0.140625, "episode/reward_rate": 0.0036231884057971015, "episode/intrinsic_return": 0.0}
{"step": 1216952, "time": 38176.328353881836, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1217608, "time": 38196.42528986931, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1217624, "time": 38197.00141811371, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 1217800, "time": 38202.39583802223, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 1217864, "time": 38204.346698760986, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1218008, "time": 38208.76510596275, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1218024, "time": 38209.25822877884, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 1218104, "time": 38211.72373795509, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 1218120, "time": 38212.2195622921, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 1218312, "time": 38218.12048339844, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1218320, "time": 38218.59409761429, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1218392, "time": 38220.58864593506, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1218952, "time": 38237.98506450653, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1218960, "time": 38238.45522260666, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1219352, "time": 38250.178621292114, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 1219464, "time": 38253.58455300331, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 1219520, "time": 38255.52934861183, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 1219841, "time": 38265.95645022392, "train_stats/mean_log_entropy": 0.07946771594275416, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.547718811035156, "train/action_min": 0.0, "train/action_std": 1.7420585787296294, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.010576990967383609, "train/actor_opt_grad_steps": 75145.0, "train/actor_opt_loss": -23.535196957588195, "train/adv_mag": 0.7807058149576187, "train/adv_max": 0.3274241751432419, "train/adv_mean": -0.0010796143635116095, "train/adv_min": -0.7101155555248261, "train/adv_std": 0.029313455605879425, "train/cont_avg": 0.9934033203125, "train/cont_loss_mean": 0.027280169958248734, "train/cont_loss_std": 0.2973858660832047, "train/cont_neg_acc": 0.14880392126739025, "train/cont_neg_loss": 3.3069674944877625, "train/cont_pos_acc": 0.9998230355978012, "train/cont_pos_loss": 0.005590575448004529, "train/cont_pred": 0.993547640144825, "train/cont_rate": 0.9934033203125, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.15140894757583737, "train/extr_critic_critic_opt_grad_steps": 75145.0, "train/extr_critic_critic_opt_loss": 5024.84211303711, "train/extr_critic_mag": 1.7019621562957763, "train/extr_critic_max": 1.7019621562957763, "train/extr_critic_mean": 1.5837388694286347, "train/extr_critic_min": 1.2261951315402984, "train/extr_critic_std": 0.029504954516887665, "train/extr_return_normed_mag": 0.8340631777048111, "train/extr_return_normed_max": 0.3149187994003296, "train/extr_return_normed_mean": 0.057610606709495187, "train/extr_return_normed_min": -0.7082436162233353, "train/extr_return_normed_std": 0.043012173036113384, "train/extr_return_rate": 0.9997041273117065, "train/extr_return_raw_mag": 1.8399673783779145, "train/extr_return_raw_max": 1.8399673783779145, "train/extr_return_raw_mean": 1.5826592659950256, "train/extr_return_raw_min": 0.8168049627542495, "train/extr_return_raw_std": 0.043012172942981125, "train/extr_reward_mag": 0.2854867994785309, "train/extr_reward_max": 0.2854867994785309, "train/extr_reward_mean": 0.002628921656287275, "train/extr_reward_min": 1.6033649444580078e-07, "train/extr_reward_std": 0.00988597069401294, "train/image_loss_mean": 0.08646056842058897, "train/image_loss_std": 0.10157325200736522, "train/model_loss_mean": 0.7375761106610298, "train/model_loss_std": 0.58735536493361, "train/model_opt_grad_norm": 15.513287515496488, "train/model_opt_grad_steps": 75077.06, "train/model_opt_loss": 3761.6098181152342, "train/model_opt_model_opt_grad_overflow": 0.005, "train/model_opt_model_opt_grad_scale": 5075.0, "train/policy_entropy_mag": 1.2633150237798692, "train/policy_entropy_max": 1.2633150237798692, "train/policy_entropy_mean": 0.08929726578295231, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.10671581964939833, "train/policy_logprob_mag": 6.55108026266098, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.08967148151248694, "train/policy_logprob_min": -6.55108026266098, "train/policy_logprob_std": 0.628302591741085, "train/policy_randomness_mag": 0.6492155358195305, "train/policy_randomness_max": 0.6492155358195305, "train/policy_randomness_mean": 0.045889720525592564, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.05484108617529273, "train/post_ent_mag": 28.902606964111328, "train/post_ent_max": 28.902606964111328, "train/post_ent_mean": 28.279412240982055, "train/post_ent_min": 27.72482755661011, "train/post_ent_std": 0.2517349464446306, "train/prior_ent_mag": 27.93395444869995, "train/prior_ent_max": 27.93395444869995, "train/prior_ent_mean": 27.379089851379394, "train/prior_ent_min": 26.712204504013062, "train/prior_ent_std": 0.1887038068473339, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0033494110190076753, "train/reward_loss_mean": 0.023835347639396785, "train/reward_loss_std": 0.29317614337429404, "train/reward_max_data": 0.8313124990463256, "train/reward_max_pred": 0.3463085353374481, "train/reward_neg_acc": 0.9994994857907296, "train/reward_neg_loss": 0.004188627686817199, "train/reward_pos_acc": 0.15891865365207195, "train/reward_pos_loss": 4.0617812991142275, "train/reward_pred": 0.0025438975577708333, "train/reward_rate": 0.004873046875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.020915869623422623, "report/cont_loss_std": 0.21872322261333466, "report/cont_neg_acc": 0.2857142984867096, "report/cont_neg_loss": 2.1918282508850098, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.005973500199615955, "report/cont_pred": 0.9919396042823792, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.09599079191684723, "report/image_loss_std": 0.11033201962709427, "report/model_loss_mean": 0.7341418266296387, "report/model_loss_std": 0.4525162875652313, "report/post_ent_mag": 28.745010375976562, "report/post_ent_max": 28.745010375976562, "report/post_ent_mean": 28.169654846191406, "report/post_ent_min": 27.643680572509766, "report/post_ent_std": 0.24125570058822632, "report/prior_ent_mag": 27.89048194885254, "report/prior_ent_max": 27.89048194885254, "report/prior_ent_mean": 27.35974884033203, "report/prior_ent_min": 26.669803619384766, "report/prior_ent_std": 0.1976952850818634, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0028228759765625, "report/reward_loss_mean": 0.01723516546189785, "report/reward_loss_std": 0.22209157049655914, "report/reward_max_data": 0.784375011920929, "report/reward_max_pred": 0.7770355939865112, "report/reward_neg_acc": 0.9999999403953552, "report/reward_neg_loss": 0.004535588901489973, "report/reward_pos_acc": 0.25, "report/reward_pos_loss": 3.255627155303955, "report/reward_pred": 0.0031518933828920126, "report/reward_rate": 0.00390625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.019981320947408676, "eval/cont_loss_std": 0.21487067639827728, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 3.44277286529541, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.006558610592037439, "eval/cont_pred": 0.9934594035148621, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.09129735827445984, "eval/image_loss_std": 0.09953123331069946, "eval/model_loss_mean": 0.730398416519165, "eval/model_loss_std": 0.4771551191806793, "eval/post_ent_mag": 28.74989891052246, "eval/post_ent_max": 28.74989891052246, "eval/post_ent_mean": 28.218563079833984, "eval/post_ent_min": 27.599937438964844, "eval/post_ent_std": 0.21576449275016785, "eval/prior_ent_mag": 27.89048194885254, "eval/prior_ent_max": 27.89048194885254, "eval/prior_ent_mean": 27.355913162231445, "eval/prior_ent_min": 26.612876892089844, "eval/prior_ent_std": 0.19630460441112518, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.00177001953125, "eval/reward_loss_mean": 0.019119704142212868, "eval/reward_loss_std": 0.2541143596172333, "eval/reward_max_data": 0.753125011920929, "eval/reward_max_pred": 0.1178818941116333, "eval/reward_neg_acc": 0.999020516872406, "eval/reward_neg_loss": 0.005490800831466913, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 4.657489776611328, "eval/reward_pred": 0.002899251878261566, "eval/reward_rate": 0.0029296875, "replay/size": 1000000.0, "replay/inserts": 31976.0, "replay/samples": 31968.0, "replay/insert_wait_avg": 1.3319632396836385e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.733762323916018e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4896.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2232100262361415e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.4454126358032227e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 999.9904594421387, "timer/env.step_count": 3997.0, "timer/env.step_total": 40.22989106178284, "timer/env.step_frac": 0.04023027488104812, "timer/env.step_avg": 0.010065021531594404, "timer/env.step_min": 0.008285284042358398, "timer/env.step_max": 0.041121721267700195, "timer/replay._sample_count": 31968.0, "timer/replay._sample_total": 16.92199945449829, "timer/replay._sample_frac": 0.016922160901353508, "timer/replay._sample_avg": 0.0005293418247778494, "timer/replay._sample_min": 0.0003898143768310547, "timer/replay._sample_max": 0.02825021743774414, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4609.0, "timer/agent.policy_total": 50.49028396606445, "timer/agent.policy_frac": 0.05049076567613585, "timer/agent.policy_avg": 0.010954715549156965, "timer/agent.policy_min": 0.009120941162109375, "timer/agent.policy_max": 0.08770275115966797, "timer/dataset_train_count": 1998.0, "timer/dataset_train_total": 0.24000334739685059, "timer/dataset_train_frac": 0.00024000563718451918, "timer/dataset_train_avg": 0.00012012179549391921, "timer/dataset_train_min": 0.00010395050048828125, "timer/dataset_train_max": 0.00041604042053222656, "timer/agent.train_count": 1998.0, "timer/agent.train_total": 893.6806981563568, "timer/agent.train_frac": 0.8936892244501127, "timer/agent.train_avg": 0.4472876367148933, "timer/agent.train_min": 0.4356997013092041, "timer/agent.train_max": 0.7287611961364746, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47759342193603516, "timer/agent.report_frac": 0.0004775979784871834, "timer/agent.report_avg": 0.23879671096801758, "timer/agent.report_min": 0.22928500175476074, "timer/agent.report_max": 0.24830842018127441, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.314018249511719e-05, "timer/dataset_eval_frac": 3.314049867396234e-08, "timer/dataset_eval_avg": 3.314018249511719e-05, "timer/dataset_eval_min": 3.314018249511719e-05, "timer/dataset_eval_max": 3.314018249511719e-05, "fps": 31.975631742741744}
{"step": 1219936, "time": 38269.06815743446, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1220016, "time": 38271.51161694527, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1220024, "time": 38273.58646965027, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 1220024, "time": 38273.720036029816, "eval_episode/length": 104.0, "eval_episode/score": 0.675000011920929, "eval_episode/reward_rate": 0.009523809523809525}
{"step": 1220024, "time": 38274.09886407852, "eval_episode/length": 122.0, "eval_episode/score": 0.6187499761581421, "eval_episode/reward_rate": 0.008130081300813009}
{"step": 1220024, "time": 38274.18975543976, "eval_episode/length": 126.0, "eval_episode/score": 0.606249988079071, "eval_episode/reward_rate": 0.007874015748031496}
{"step": 1220024, "time": 38274.38160777092, "eval_episode/length": 135.0, "eval_episode/score": 0.578125, "eval_episode/reward_rate": 0.007352941176470588}
{"step": 1220024, "time": 38275.17118525505, "eval_episode/length": 173.0, "eval_episode/score": 0.4593749940395355, "eval_episode/reward_rate": 0.005747126436781609}
{"step": 1220024, "time": 38275.262301683426, "eval_episode/length": 177.0, "eval_episode/score": 0.4468750059604645, "eval_episode/reward_rate": 0.0056179775280898875}
{"step": 1220024, "time": 38275.50971698761, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 1220176, "time": 38280.35019373894, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1220408, "time": 38287.32624959946, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1220416, "time": 38287.80072760582, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1220568, "time": 38292.26212024689, "episode/length": 281.0, "episode/score": 0.12187500298023224, "episode/reward_rate": 0.0035460992907801418, "episode/intrinsic_return": 0.0}
{"step": 1220704, "time": 38297.146112680435, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 1220848, "time": 38301.542969703674, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1221088, "time": 38308.88743972778, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1221160, "time": 38310.85837435722, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1221184, "time": 38311.81604552269, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1221232, "time": 38313.30036401749, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1221368, "time": 38317.33876633644, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 1221784, "time": 38330.0478386879, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 1221832, "time": 38331.520315647125, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1221832, "time": 38331.52626466751, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1222272, "time": 38345.22078514099, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1222480, "time": 38351.696642160416, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1222512, "time": 38352.701704740524, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1222608, "time": 38355.64314675331, "episode/length": 219.0, "episode/score": 0.31562501192092896, "episode/reward_rate": 0.004545454545454545, "episode/intrinsic_return": 0.0}
{"step": 1222880, "time": 38363.93944191933, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1223208, "time": 38373.761004924774, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 1223264, "time": 38375.699288368225, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1223352, "time": 38378.310611248016, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1223352, "time": 38378.31793165207, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1223384, "time": 38379.29875421524, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1223400, "time": 38379.793216466904, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1223416, "time": 38380.286366701126, "episode/length": 278.0, "episode/score": 0.13124999403953552, "episode/reward_rate": 0.0035842293906810036, "episode/intrinsic_return": 0.0}
{"step": 1223680, "time": 38388.54806137085, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1223792, "time": 38391.970811128616, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1223800, "time": 38391.997629880905, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1224000, "time": 38398.307705163956, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1224072, "time": 38400.27193903923, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1224072, "time": 38400.27970123291, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1224088, "time": 38400.77221798897, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1224192, "time": 38404.17829179764, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1224376, "time": 38409.677038908005, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 1224472, "time": 38412.619317531586, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1224552, "time": 38415.07143473625, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 1224584, "time": 38416.053369283676, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1224632, "time": 38417.534549713135, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1224712, "time": 38419.96241283417, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1224832, "time": 38423.82687020302, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1225144, "time": 38433.06769871712, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1225360, "time": 38439.951412677765, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1225456, "time": 38442.8924241066, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1225592, "time": 38446.80882835388, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1225872, "time": 38455.62485432625, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1226024, "time": 38460.00804209709, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1226504, "time": 38474.73530745506, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1226560, "time": 38476.67992448807, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1226776, "time": 38483.031136751175, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 1226864, "time": 38485.950854063034, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1226896, "time": 38486.92460393906, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1226904, "time": 38486.95264959335, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1227080, "time": 38492.32100582123, "episode/length": 202.0, "episode/score": 0.3687500059604645, "episode/reward_rate": 0.0049261083743842365, "episode/intrinsic_return": 0.0}
{"step": 1227288, "time": 38498.781713724136, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1227320, "time": 38499.777841091156, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1227488, "time": 38505.08185648918, "episode/length": 201.0, "episode/score": 0.37187498807907104, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.0}
{"step": 1227584, "time": 38507.98338484764, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1227656, "time": 38509.970836400986, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1227776, "time": 38513.82934546471, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1227952, "time": 38519.19097352028, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 1228112, "time": 38524.05670046806, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1228128, "time": 38524.548221588135, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1228224, "time": 38527.560088157654, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1228464, "time": 38534.88250088692, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1228480, "time": 38535.37224602699, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1228520, "time": 38536.370106220245, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1229008, "time": 38552.00282406807, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1229112, "time": 38554.979244470596, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1229176, "time": 38557.036808013916, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1229216, "time": 38558.49492764473, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1229256, "time": 38559.535504341125, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1229264, "time": 38560.016052246094, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1229496, "time": 38566.93848013878, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1229624, "time": 38570.88426876068, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1229864, "time": 38578.195056438446, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1229888, "time": 38579.17616224289, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1229992, "time": 38582.166383981705, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1230008, "time": 38583.46785545349, "eval_episode/length": 38.0, "eval_episode/score": 0.8812500238418579, "eval_episode/reward_rate": 0.02564102564102564}
{"step": 1230008, "time": 38583.9308552742, "eval_episode/length": 60.0, "eval_episode/score": 0.8125, "eval_episode/reward_rate": 0.01639344262295082}
{"step": 1230008, "time": 38583.94190478325, "eval_episode/length": 60.0, "eval_episode/score": 0.8125, "eval_episode/reward_rate": 0.01639344262295082}
{"step": 1230008, "time": 38583.971606492996, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 1230008, "time": 38584.365304231644, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 1230008, "time": 38585.04885530472, "eval_episode/length": 115.0, "eval_episode/score": 0.640625, "eval_episode/reward_rate": 0.008620689655172414}
{"step": 1230008, "time": 38585.2068195343, "eval_episode/length": 42.0, "eval_episode/score": 0.8687499761581421, "eval_episode/reward_rate": 0.023255813953488372}
{"step": 1230008, "time": 38585.23185920715, "eval_episode/length": 85.0, "eval_episode/score": 0.734375, "eval_episode/reward_rate": 0.011627906976744186}
{"step": 1230080, "time": 38587.79570031166, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1230304, "time": 38594.65422439575, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 1230392, "time": 38597.14745807648, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1230488, "time": 38600.09823703766, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1230760, "time": 38608.48572206497, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1230776, "time": 38608.983989715576, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1231072, "time": 38618.38767385483, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1231152, "time": 38620.85244989395, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 1231568, "time": 38633.57949876785, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1231656, "time": 38636.06783723831, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1231672, "time": 38636.57596850395, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 1231688, "time": 38637.068096876144, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1231744, "time": 38639.01402449608, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 1231936, "time": 38644.87910270691, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1232000, "time": 38646.96191883087, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 1232216, "time": 38653.337829351425, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1232224, "time": 38653.80980563164, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1232264, "time": 38654.8148086071, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1232496, "time": 38662.14530324936, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1232656, "time": 38667.01884007454, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1232736, "time": 38669.45652151108, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1233128, "time": 38681.28715276718, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 1233136, "time": 38681.759429216385, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1233248, "time": 38685.18751215935, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1233384, "time": 38689.09157323837, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1233520, "time": 38693.45651555061, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1233776, "time": 38701.26968240738, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1233800, "time": 38701.78127336502, "episode/length": 232.0, "episode/score": 0.2750000059604645, "episode/reward_rate": 0.004291845493562232, "episode/intrinsic_return": 0.0}
{"step": 1233904, "time": 38705.1728041172, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1234080, "time": 38710.70522117615, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1234248, "time": 38715.61428666115, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1234640, "time": 38727.807029008865, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1234808, "time": 38732.71260595322, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1235000, "time": 38738.71495389938, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1235048, "time": 38740.1825428009, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1235136, "time": 38743.07912158966, "episode/length": 235.0, "episode/score": 0.265625, "episode/reward_rate": 0.00423728813559322, "episode/intrinsic_return": 0.0}
{"step": 1235216, "time": 38745.52883410454, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 1235360, "time": 38749.91189908981, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1235656, "time": 38758.720799684525, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 1235808, "time": 38763.57742238045, "episode/length": 18.0, "episode/score": 0.9437500238418579, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.0}
{"step": 1235808, "time": 38763.58499836922, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1236152, "time": 38773.96679830551, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1236216, "time": 38775.94431209564, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1236240, "time": 38776.91684126854, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 1236368, "time": 38780.85392045975, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1236408, "time": 38781.852135658264, "episode/length": 220.0, "episode/score": 0.3125, "episode/reward_rate": 0.004524886877828055, "episode/intrinsic_return": 0.0}
{"step": 1236560, "time": 38786.70202040672, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1236608, "time": 38788.16804933548, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1236832, "time": 38794.92901968956, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1236960, "time": 38798.91700387001, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1236968, "time": 38798.94479107857, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 1237352, "time": 38811.10726189613, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1237360, "time": 38811.57993245125, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1237480, "time": 38815.013620615005, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1237528, "time": 38816.47487998009, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1237576, "time": 38817.965118169785, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1238344, "time": 38841.50618267059, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1238536, "time": 38847.36587929726, "episode/length": 286.0, "episode/score": 0.10625000298023224, "episode/reward_rate": 0.003484320557491289, "episode/intrinsic_return": 0.0}
{"step": 1238616, "time": 38849.80583667755, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1238632, "time": 38850.29839658737, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1238784, "time": 38855.17507481575, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 1238872, "time": 38857.792384147644, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1238920, "time": 38859.25665521622, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1239120, "time": 38865.55341339111, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1239536, "time": 38878.209237098694, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1239576, "time": 38879.21105694771, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1239672, "time": 38882.14300322533, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1239824, "time": 38887.08809351921, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1239856, "time": 38888.071333646774, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 1240048, "time": 38893.93092775345, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1240080, "time": 38894.92433190346, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 1240096, "time": 38896.33124923706, "eval_episode/length": 40.0, "eval_episode/score": 0.875, "eval_episode/reward_rate": 0.024390243902439025}
{"step": 1240096, "time": 38896.8160803318, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 1240096, "time": 38896.91029906273, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 1240096, "time": 38897.67853307724, "eval_episode/length": 104.0, "eval_episode/score": 0.675000011920929, "eval_episode/reward_rate": 0.009523809523809525}
{"step": 1240096, "time": 38897.934716939926, "eval_episode/length": 116.0, "eval_episode/score": 0.637499988079071, "eval_episode/reward_rate": 0.008547008547008548}
{"step": 1240096, "time": 38898.02485895157, "eval_episode/length": 120.0, "eval_episode/score": 0.625, "eval_episode/reward_rate": 0.008264462809917356}
{"step": 1240096, "time": 38898.05157518387, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 1240096, "time": 38898.63596320152, "eval_episode/length": 28.0, "eval_episode/score": 0.9125000238418579, "eval_episode/reward_rate": 0.034482758620689655}
{"step": 1240376, "time": 38906.93581914902, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1240416, "time": 38908.3991317749, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 1240520, "time": 38911.35410404205, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 1240632, "time": 38914.77697515488, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1240656, "time": 38915.72954893112, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1240912, "time": 38923.64155983925, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1241032, "time": 38927.06501364708, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1241072, "time": 38928.52179288864, "episode/length": 191.0, "episode/score": 0.40312498807907104, "episode/reward_rate": 0.005208333333333333, "episode/intrinsic_return": 0.0}
{"step": 1241184, "time": 38931.929267168045, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1241488, "time": 38941.17528748512, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1241552, "time": 38943.14582157135, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1241616, "time": 38945.0933535099, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1241936, "time": 38954.97079753876, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1242032, "time": 38957.90763401985, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1242096, "time": 38959.85288763046, "episode/length": 19.0, "episode/score": 0.940625011920929, "episode/reward_rate": 0.05, "episode/intrinsic_return": 0.0}
{"step": 1242144, "time": 38961.31867361069, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1242200, "time": 38962.81513047218, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1242392, "time": 38968.68256521225, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1242480, "time": 38971.57590699196, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 1242608, "time": 38975.49123096466, "episode/length": 191.0, "episode/score": 0.40312498807907104, "episode/reward_rate": 0.005208333333333333, "episode/intrinsic_return": 0.0}
{"step": 1242760, "time": 38980.0016169548, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1242832, "time": 38982.449548482895, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1242864, "time": 38983.41700029373, "episode/length": 209.0, "episode/score": 0.34687501192092896, "episode/reward_rate": 0.004761904761904762, "episode/intrinsic_return": 0.0}
{"step": 1243112, "time": 38990.72758150101, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1243160, "time": 38992.204491853714, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1243240, "time": 38994.630116939545, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1243304, "time": 38996.56319832802, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1243328, "time": 38997.532445669174, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 1243384, "time": 38999.00492954254, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1243448, "time": 39000.94689846039, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 1243608, "time": 39005.81551146507, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1243896, "time": 39014.71772170067, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 1244032, "time": 39019.068345069885, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1244040, "time": 39019.09731245041, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1244288, "time": 39026.87879419327, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1244440, "time": 39031.270574092865, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1244528, "time": 39034.16276073456, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1244712, "time": 39039.618190288544, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1245056, "time": 39050.28812766075, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1245072, "time": 39050.811047792435, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1245176, "time": 39053.77870106697, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 1245328, "time": 39059.1271173954, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1245568, "time": 39066.49800133705, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 1245616, "time": 39068.060603141785, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1245696, "time": 39070.51312685013, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1245880, "time": 39075.92667102814, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1245976, "time": 39078.845334768295, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1246016, "time": 39080.301230192184, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1246352, "time": 39090.54294729233, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1246376, "time": 39091.05711197853, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1246472, "time": 39093.9873213768, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1246480, "time": 39094.459908008575, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1246856, "time": 39105.85038137436, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1247200, "time": 39116.5491874218, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1247368, "time": 39121.42096710205, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1247408, "time": 39122.851091623306, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1247656, "time": 39130.28316998482, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1247984, "time": 39140.516308784485, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1248008, "time": 39141.03389000893, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1248128, "time": 39144.89990353584, "episode/length": 17.0, "episode/score": 0.9468749761581421, "episode/reward_rate": 0.05555555555555555, "episode/intrinsic_return": 0.0}
{"step": 1248184, "time": 39146.37943267822, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1248192, "time": 39146.85038137436, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1248208, "time": 39147.34090542793, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1248328, "time": 39150.77771115303, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1248664, "time": 39161.09052991867, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1248800, "time": 39165.467037439346, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1249232, "time": 39178.715522289276, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1249264, "time": 39179.70911073685, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 1249512, "time": 39187.134860515594, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 1249576, "time": 39189.116253614426, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 1249720, "time": 39193.53616166115, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1249864, "time": 39197.96645259857, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1250080, "time": 39206.273047208786, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 1250080, "time": 39206.36066317558, "eval_episode/length": 72.0, "eval_episode/score": 0.7749999761581421, "eval_episode/reward_rate": 0.0136986301369863}
{"step": 1250080, "time": 39206.58314085007, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 1250080, "time": 39206.610491752625, "eval_episode/length": 84.0, "eval_episode/score": 0.737500011920929, "eval_episode/reward_rate": 0.011764705882352941}
{"step": 1250080, "time": 39206.69649672508, "eval_episode/length": 88.0, "eval_episode/score": 0.7250000238418579, "eval_episode/reward_rate": 0.011235955056179775}
{"step": 1250080, "time": 39207.17061448097, "eval_episode/length": 111.0, "eval_episode/score": 0.653124988079071, "eval_episode/reward_rate": 0.008928571428571428}
{"step": 1250080, "time": 39207.178139925, "eval_episode/length": 22.0, "eval_episode/score": 0.9312499761581421, "eval_episode/reward_rate": 0.043478260869565216}
{"step": 1250080, "time": 39207.243956804276, "eval_episode/length": 41.0, "eval_episode/score": 0.871874988079071, "eval_episode/reward_rate": 0.023809523809523808}
{"step": 1250304, "time": 39214.06709575653, "episode/length": 187.0, "episode/score": 0.4156250059604645, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.0}
{"step": 1250320, "time": 39214.56397271156, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1250504, "time": 39220.10214138031, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1250512, "time": 39220.599190950394, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1250976, "time": 39234.694130420685, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1251048, "time": 39236.68204212189, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1251096, "time": 39238.1305809021, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1251376, "time": 39246.94275307655, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1251544, "time": 39251.82166957855, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1251616, "time": 39254.220256567, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1251824, "time": 39260.567108392715, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1251977, "time": 39266.131366729736, "train_stats/mean_log_entropy": 0.07755457116370527, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.5613023748445274, "train/action_min": 0.0, "train/action_std": 1.7982046995589982, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.009590019478893546, "train/actor_opt_grad_steps": 77150.0, "train/actor_opt_loss": -21.679769008313837, "train/adv_mag": 0.6891044123255792, "train/adv_max": 0.3106725073572415, "train/adv_mean": 0.0009704544832287079, "train/adv_min": -0.5848384229697992, "train/adv_std": 0.02687246346410679, "train/cont_avg": 0.9935527440920398, "train/cont_loss_mean": 0.027620856307298686, "train/cont_loss_std": 0.2964625156563313, "train/cont_neg_acc": 0.12285739687544789, "train/cont_neg_loss": 3.386421579033581, "train/cont_pos_acc": 0.999833748708317, "train/cont_pos_loss": 0.00583032593802915, "train/cont_pred": 0.9934474016303447, "train/cont_rate": 0.9935527440920398, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.15945419784060758, "train/extr_critic_critic_opt_grad_steps": 77150.0, "train/extr_critic_critic_opt_loss": 4320.019650283738, "train/extr_critic_mag": 1.6963757128264774, "train/extr_critic_max": 1.6963757128264774, "train/extr_critic_mean": 1.5754551199538198, "train/extr_critic_min": 1.2546347148382841, "train/extr_critic_std": 0.02803444506517097, "train/extr_return_normed_mag": 0.7119893093607319, "train/extr_return_normed_max": 0.2837747133786406, "train/extr_return_normed_mean": 0.057093399136665446, "train/extr_return_normed_min": -0.5819510574364544, "train/extr_return_normed_std": 0.04037312644334575, "train/extr_return_rate": 0.999747055976545, "train/extr_return_raw_mag": 1.8031068257431486, "train/extr_return_raw_max": 1.8031068257431486, "train/extr_return_raw_mean": 1.576425590918432, "train/extr_return_raw_min": 0.9373810549280537, "train/extr_return_raw_std": 0.040373126498947094, "train/extr_reward_mag": 0.24004666425695467, "train/extr_reward_max": 0.24004666425695467, "train/extr_reward_mean": 0.00257752554326675, "train/extr_reward_min": 1.0378918244471005e-07, "train/extr_reward_std": 0.009112701359765595, "train/image_loss_mean": 0.08643312870863065, "train/image_loss_std": 0.10187841227176178, "train/model_loss_mean": 0.7383348921045142, "train/model_loss_std": 0.5874552094372943, "train/model_opt_grad_norm": 15.919871050326979, "train/model_opt_grad_steps": 77080.10447761194, "train/model_opt_loss": 3764.979142374067, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5099.502487562189, "train/policy_entropy_mag": 1.2386064132054646, "train/policy_entropy_max": 1.2386064132054646, "train/policy_entropy_mean": 0.08741413034609895, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.10179087697570004, "train/policy_logprob_mag": 6.551080271972353, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.0872327599359389, "train/policy_logprob_min": -6.551080271972353, "train/policy_logprob_std": 0.624112396690976, "train/policy_randomness_mag": 0.6365178197770569, "train/policy_randomness_max": 0.6365178197770569, "train/policy_randomness_mean": 0.044921980586959356, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.0523101661298702, "train/post_ent_mag": 28.839559868200503, "train/post_ent_max": 28.839559868200503, "train/post_ent_mean": 28.230473029672805, "train/post_ent_min": 27.648687495521052, "train/post_ent_std": 0.2510017019450961, "train/prior_ent_mag": 28.039499415687068, "train/prior_ent_max": 28.039499415687068, "train/prior_ent_mean": 27.327913711320107, "train/prior_ent_min": 26.64550643655198, "train/prior_ent_std": 0.22405187874587615, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0033361937854188813, "train/reward_loss_mean": 0.024280887451578876, "train/reward_loss_std": 0.2925605801726455, "train/reward_max_data": 0.8154695292017353, "train/reward_max_pred": 0.30554583238725047, "train/reward_neg_acc": 0.9995021221056506, "train/reward_neg_loss": 0.004359113047853928, "train/reward_pos_acc": 0.13987319856882097, "train/reward_pos_loss": 4.084221272021532, "train/reward_pred": 0.002551026734991453, "train/reward_rate": 0.004853661380597015, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.02182753197848797, "report/cont_loss_std": 0.24833375215530396, "report/cont_neg_acc": 0.1666666716337204, "report/cont_neg_loss": 3.0206103324890137, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.00415297644212842, "report/cont_pred": 0.995094358921051, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.0986279547214508, "report/image_loss_std": 0.12379901856184006, "report/model_loss_mean": 0.7415409088134766, "report/model_loss_std": 0.5487954616546631, "report/post_ent_mag": 28.923463821411133, "report/post_ent_max": 28.923463821411133, "report/post_ent_mean": 28.215559005737305, "report/post_ent_min": 27.68939208984375, "report/post_ent_std": 0.2617698609828949, "report/prior_ent_mag": 27.90711212158203, "report/prior_ent_max": 27.90711212158203, "report/prior_ent_mean": 27.253145217895508, "report/prior_ent_min": 26.540245056152344, "report/prior_ent_std": 0.26337698101997375, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0033020018599927425, "report/reward_loss_mean": 0.021085377782583237, "report/reward_loss_std": 0.27853134274482727, "report/reward_max_data": 0.796875, "report/reward_max_pred": 0.40248823165893555, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0026841885410249233, "report/reward_pos_acc": 0.20000000298023224, "report/reward_pos_loss": 3.771247625350952, "report/reward_pred": 0.0018373961793258786, "report/reward_rate": 0.0048828125, "eval/cont_avg": 0.9931640625, "eval/cont_loss_mean": 0.03584722802042961, "eval/cont_loss_std": 0.39423802495002747, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 4.57852840423584, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.004580001812428236, "eval/cont_pred": 0.9953888654708862, "eval/cont_rate": 0.9931640625, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.1724959760904312, "eval/image_loss_std": 0.14813050627708435, "eval/model_loss_mean": 0.8405752778053284, "eval/model_loss_std": 0.7605072855949402, "eval/post_ent_mag": 28.926767349243164, "eval/post_ent_max": 28.926767349243164, "eval/post_ent_mean": 28.276905059814453, "eval/post_ent_min": 27.633729934692383, "eval/post_ent_std": 0.27977731823921204, "eval/prior_ent_mag": 27.90994644165039, "eval/prior_ent_max": 27.90994644165039, "eval/prior_ent_mean": 27.279300689697266, "eval/prior_ent_min": 26.469654083251953, "eval/prior_ent_std": 0.26932770013809204, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.003924560733139515, "eval/reward_loss_mean": 0.03223205357789993, "eval/reward_loss_std": 0.3752899169921875, "eval/reward_max_data": 0.7437499761581421, "eval/reward_max_pred": 0.031084179878234863, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.003629932878538966, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 4.885058879852295, "eval/reward_pred": 0.0019465374061837792, "eval/reward_rate": 0.005859375, "replay/size": 1000000.0, "replay/inserts": 32136.0, "replay/samples": 32144.0, "replay/insert_wait_avg": 1.2981927243518331e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.535939938633996e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4648.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2272298848977802e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1175870895385742e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0328664779663, "timer/env.step_count": 4017.0, "timer/env.step_total": 39.78403282165527, "timer/env.step_frac": 0.039782725303590644, "timer/env.step_avg": 0.009903916560033674, "timer/env.step_min": 0.007852315902709961, "timer/env.step_max": 0.039418697357177734, "timer/replay._sample_count": 32144.0, "timer/replay._sample_total": 16.957823991775513, "timer/replay._sample_frac": 0.01695726666614426, "timer/replay._sample_avg": 0.0005275579887934144, "timer/replay._sample_min": 0.00041937828063964844, "timer/replay._sample_max": 0.011332511901855469, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4598.0, "timer/agent.policy_total": 49.344709396362305, "timer/agent.policy_frac": 0.049343087662858845, "timer/agent.policy_avg": 0.010731776728221468, "timer/agent.policy_min": 0.00914311408996582, "timer/agent.policy_max": 0.08569955825805664, "timer/dataset_train_count": 2009.0, "timer/dataset_train_total": 0.2360379695892334, "timer/dataset_train_frac": 0.0002360302121074678, "timer/dataset_train_avg": 0.00011749027854118139, "timer/dataset_train_min": 0.00010251998901367188, "timer/dataset_train_max": 0.001065969467163086, "timer/agent.train_count": 2009.0, "timer/agent.train_total": 898.3412127494812, "timer/agent.train_frac": 0.8983116884081672, "timer/agent.train_avg": 0.4471583936035247, "timer/agent.train_min": 0.4351792335510254, "timer/agent.train_max": 0.6693260669708252, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.473724365234375, "timer/agent.report_frac": 0.0004737087960946657, "timer/agent.report_avg": 0.2368621826171875, "timer/agent.report_min": 0.22986578941345215, "timer/agent.report_max": 0.24385857582092285, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0279159545898438e-05, "timer/dataset_eval_frac": 3.027816440927502e-08, "timer/dataset_eval_avg": 3.0279159545898438e-05, "timer/dataset_eval_min": 3.0279159545898438e-05, "timer/dataset_eval_max": 3.0279159545898438e-05, "fps": 32.134197857247166}
{"step": 1252056, "time": 39268.32771945, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1252392, "time": 39278.739073991776, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 1252512, "time": 39282.63443565369, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1252816, "time": 39291.90871691704, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1253144, "time": 39301.64164733887, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1253240, "time": 39304.57276511192, "episode/length": 202.0, "episode/score": 0.3687500059604645, "episode/reward_rate": 0.0049261083743842365, "episode/intrinsic_return": 0.0}
{"step": 1253360, "time": 39308.542753219604, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1253408, "time": 39310.504115343094, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1253592, "time": 39315.928067445755, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1253792, "time": 39322.259659051895, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1254136, "time": 39332.571686029434, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1254304, "time": 39338.0610973835, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1254336, "time": 39339.05557632446, "episode/length": 227.0, "episode/score": 0.2906250059604645, "episode/reward_rate": 0.0043859649122807015, "episode/intrinsic_return": 0.0}
{"step": 1254472, "time": 39343.03620195389, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1254512, "time": 39344.49009156227, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1254648, "time": 39348.38109588623, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1254704, "time": 39350.3184967041, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1255016, "time": 39359.71904397011, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1255136, "time": 39363.58914208412, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1255192, "time": 39365.103694438934, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1255344, "time": 39370.05852031708, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 1255552, "time": 39376.432983875275, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1255720, "time": 39381.32641553879, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1255824, "time": 39384.70262670517, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 1256448, "time": 39403.860973119736, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1256488, "time": 39404.86392760277, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1256736, "time": 39412.65220618248, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 1256824, "time": 39415.12240052223, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1256952, "time": 39419.013349056244, "episode/length": 280.0, "episode/score": 0.125, "episode/reward_rate": 0.0035587188612099642, "episode/intrinsic_return": 0.0}
{"step": 1256992, "time": 39420.449021816254, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1257112, "time": 39423.91448068619, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 1257360, "time": 39431.83532834053, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1257448, "time": 39434.32641458511, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1257448, "time": 39434.33420586586, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1257504, "time": 39436.266854286194, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1257520, "time": 39436.757090330124, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1257832, "time": 39446.08020734787, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1258016, "time": 39451.94082117081, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1258160, "time": 39456.382362127304, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1258320, "time": 39461.34494328499, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1258344, "time": 39461.862402915955, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1258464, "time": 39465.76676630974, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1258672, "time": 39472.118279218674, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1258800, "time": 39475.986095905304, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1258824, "time": 39476.49677467346, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1258920, "time": 39479.430762052536, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1259328, "time": 39492.22155070305, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1259520, "time": 39498.05870509148, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1259672, "time": 39502.53442454338, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1259936, "time": 39510.78172469139, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1260000, "time": 39512.76838135719, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1260064, "time": 39515.94916319847, "eval_episode/length": 63.0, "eval_episode/score": 0.8031250238418579, "eval_episode/reward_rate": 0.015625}
{"step": 1260064, "time": 39516.03270959854, "eval_episode/length": 67.0, "eval_episode/score": 0.7906249761581421, "eval_episode/reward_rate": 0.014705882352941176}
{"step": 1260064, "time": 39516.81695866585, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 1260064, "time": 39517.81922221184, "eval_episode/length": 85.0, "eval_episode/score": 0.734375, "eval_episode/reward_rate": 0.011627906976744186}
{"step": 1260064, "time": 39517.826033353806, "eval_episode/length": 149.0, "eval_episode/score": 0.534375011920929, "eval_episode/reward_rate": 0.006666666666666667}
{"step": 1260064, "time": 39518.07222366333, "eval_episode/length": 161.0, "eval_episode/score": 0.49687498807907104, "eval_episode/reward_rate": 0.006172839506172839}
{"step": 1260064, "time": 39518.159445762634, "eval_episode/length": 165.0, "eval_episode/score": 0.484375, "eval_episode/reward_rate": 0.006024096385542169}
{"step": 1260064, "time": 39519.22096800804, "eval_episode/length": 122.0, "eval_episode/score": 0.6187499761581421, "eval_episode/reward_rate": 0.008130081300813009}
{"step": 1260328, "time": 39527.02080702782, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1260656, "time": 39537.20900654793, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1260664, "time": 39537.23719596863, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1260776, "time": 39540.65079140663, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1260944, "time": 39545.97504353523, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 1261040, "time": 39548.96949648857, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1261048, "time": 39548.99825286865, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 1261160, "time": 39552.40505552292, "episode/length": 204.0, "episode/score": 0.36250001192092896, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.0}
{"step": 1261232, "time": 39554.83435130119, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1261840, "time": 39573.66893982887, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1261984, "time": 39578.17158269882, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1262048, "time": 39580.13751864433, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1262072, "time": 39580.65187048912, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 1262408, "time": 39590.78648877144, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 1262488, "time": 39593.20323562622, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 1262640, "time": 39598.048488378525, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1262776, "time": 39601.95839095116, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1262968, "time": 39607.881361722946, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1263496, "time": 39623.917836904526, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1263544, "time": 39625.38809132576, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1263592, "time": 39626.84265089035, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1263760, "time": 39632.139963150024, "episode/length": 221.0, "episode/score": 0.30937498807907104, "episode/reward_rate": 0.0045045045045045045, "episode/intrinsic_return": 0.0}
{"step": 1264152, "time": 39643.87546300888, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1264192, "time": 39645.304040670395, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1264552, "time": 39656.020344018936, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1264584, "time": 39657.00375318527, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1264704, "time": 39660.89641261101, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1264720, "time": 39661.3894033432, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1264800, "time": 39663.86536073685, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1265280, "time": 39678.62324666977, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1265344, "time": 39680.583233356476, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1265360, "time": 39681.08350753784, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1265424, "time": 39683.047672748566, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 1265488, "time": 39684.991359472275, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1265824, "time": 39695.26318860054, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1265856, "time": 39696.23387145996, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 1265904, "time": 39697.80943441391, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1265984, "time": 39700.234290361404, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 1266416, "time": 39713.3386554718, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1266432, "time": 39713.831493377686, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1266496, "time": 39715.782285928726, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1266592, "time": 39718.72739338875, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 1266736, "time": 39723.10300922394, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 1266808, "time": 39725.07904148102, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 1266888, "time": 39727.63546180725, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1267000, "time": 39731.06642484665, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 1267112, "time": 39734.48811483383, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1267408, "time": 39743.77881836891, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1267456, "time": 39745.23493719101, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1267456, "time": 39745.24373745918, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1267464, "time": 39745.276383161545, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1267568, "time": 39748.66520476341, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1267960, "time": 39760.471552848816, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1268168, "time": 39766.76296329498, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1268216, "time": 39768.21305298805, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1268216, "time": 39768.22061085701, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1268376, "time": 39773.06487369537, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1268488, "time": 39776.47100353241, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 1268808, "time": 39786.206956624985, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1268936, "time": 39790.225064992905, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1269136, "time": 39796.54740333557, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1269296, "time": 39801.42027235031, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 1269312, "time": 39801.913743019104, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 1269696, "time": 39813.587731838226, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1269712, "time": 39814.09762787819, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 1269720, "time": 39814.12764167786, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1269768, "time": 39815.83511686325, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1269864, "time": 39819.084649086, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1269976, "time": 39822.50367665291, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1270048, "time": 39826.02904844284, "eval_episode/length": 58.0, "eval_episode/score": 0.8187500238418579, "eval_episode/reward_rate": 0.01694915254237288}
{"step": 1270048, "time": 39826.864555597305, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 1270048, "time": 39826.87309193611, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 1270048, "time": 39826.882782936096, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 1270048, "time": 39827.10138130188, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 1270048, "time": 39827.16361260414, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 1270048, "time": 39827.679903030396, "eval_episode/length": 51.0, "eval_episode/score": 0.840624988079071, "eval_episode/reward_rate": 0.019230769230769232}
{"step": 1270048, "time": 39827.76362991333, "eval_episode/length": 114.0, "eval_episode/score": 0.643750011920929, "eval_episode/reward_rate": 0.008695652173913044}
{"step": 1270184, "time": 39831.655432224274, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1270240, "time": 39833.59886407852, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1270464, "time": 39840.382809877396, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1270560, "time": 39843.30765032768, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1270736, "time": 39848.78068232536, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1270744, "time": 39848.80893564224, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1270960, "time": 39855.59865665436, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1271080, "time": 39859.01705598831, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 1271128, "time": 39860.49023079872, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1271560, "time": 39873.67025113106, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 1271600, "time": 39875.120435237885, "episode/length": 234.0, "episode/score": 0.26875001192092896, "episode/reward_rate": 0.00425531914893617, "episode/intrinsic_return": 0.0}
{"step": 1271624, "time": 39875.63551712036, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1271624, "time": 39875.64376974106, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1271952, "time": 39885.99907016754, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1272040, "time": 39888.46405720711, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1272560, "time": 39904.60242819786, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1272768, "time": 39911.11206865311, "episode/length": 210.0, "episode/score": 0.34375, "episode/reward_rate": 0.004739336492890996, "episode/intrinsic_return": 0.0}
{"step": 1273048, "time": 39919.45348715782, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1273056, "time": 39919.9313249588, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1273112, "time": 39921.44059729576, "episode/length": 247.0, "episode/score": 0.22812500596046448, "episode/reward_rate": 0.004032258064516129, "episode/intrinsic_return": 0.0}
{"step": 1273336, "time": 39928.271428108215, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1273624, "time": 39937.13063097, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1273936, "time": 39946.95857810974, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1273936, "time": 39946.97481131554, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1274136, "time": 39952.84453845024, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1274144, "time": 39953.3183760643, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1274240, "time": 39956.2662293911, "episode/length": 274.0, "episode/score": 0.14374999701976776, "episode/reward_rate": 0.0036363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1274384, "time": 39960.671370744705, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 1274448, "time": 39962.619005680084, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1274864, "time": 39975.45001626015, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1274880, "time": 39975.9420979023, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1275040, "time": 39980.855949401855, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1275080, "time": 39981.846719264984, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1275088, "time": 39982.314364910126, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1275512, "time": 39995.028571128845, "episode/length": 235.0, "episode/score": 0.265625, "episode/reward_rate": 0.00423728813559322, "episode/intrinsic_return": 0.0}
{"step": 1275560, "time": 39996.52769422531, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1275752, "time": 40002.43864440918, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1275888, "time": 40006.79073834419, "episode/length": 187.0, "episode/score": 0.4156250059604645, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.0}
{"step": 1275928, "time": 40007.784207582474, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1276056, "time": 40011.6859087944, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 1276176, "time": 40015.568888902664, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 1276320, "time": 40019.954652547836, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1276496, "time": 40025.30637407303, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1276624, "time": 40029.30179691315, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1276928, "time": 40038.538220644, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1276976, "time": 40040.00312376022, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1277352, "time": 40051.264016628265, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1277520, "time": 40056.797716856, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1277856, "time": 40067.064709186554, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1277960, "time": 40070.23618340492, "episode/length": 12.0, "episode/score": 0.9624999761581421, "episode/reward_rate": 0.07692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1278008, "time": 40072.00094676018, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1278200, "time": 40077.878064870834, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1278208, "time": 40078.350600004196, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1278240, "time": 40079.33865356445, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1278376, "time": 40083.30671668053, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 1278488, "time": 40086.84238958359, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1278568, "time": 40089.29969263077, "episode/length": 242.0, "episode/score": 0.24375000596046448, "episode/reward_rate": 0.00411522633744856, "episode/intrinsic_return": 0.0}
{"step": 1278696, "time": 40093.224689006805, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1279160, "time": 40107.46756315231, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1279176, "time": 40107.95650935173, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1279320, "time": 40112.339203834534, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1279576, "time": 40120.2967672348, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1280032, "time": 40135.556656360626, "eval_episode/length": 57.0, "eval_episode/score": 0.8218749761581421, "eval_episode/reward_rate": 0.017241379310344827}
{"step": 1280032, "time": 40135.985627412796, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 1280032, "time": 40136.97595787048, "eval_episode/length": 131.0, "eval_episode/score": 0.590624988079071, "eval_episode/reward_rate": 0.007575757575757576}
{"step": 1280032, "time": 40137.07803821564, "eval_episode/length": 136.0, "eval_episode/score": 0.574999988079071, "eval_episode/reward_rate": 0.0072992700729927005}
{"step": 1280032, "time": 40137.229650735855, "eval_episode/length": 143.0, "eval_episode/score": 0.5531250238418579, "eval_episode/reward_rate": 0.006944444444444444}
{"step": 1280032, "time": 40137.67728328705, "eval_episode/length": 33.0, "eval_episode/score": 0.8968750238418579, "eval_episode/reward_rate": 0.029411764705882353}
{"step": 1280032, "time": 40137.94137239456, "eval_episode/length": 177.0, "eval_episode/score": 0.4468750059604645, "eval_episode/reward_rate": 0.0056179775280898875}
{"step": 1280032, "time": 40138.17963194847, "eval_episode/length": 52.0, "eval_episode/score": 0.8374999761581421, "eval_episode/reward_rate": 0.018867924528301886}
{"step": 1280040, "time": 40138.20607876778, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1280184, "time": 40142.60987329483, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1280320, "time": 40147.073008298874, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1280472, "time": 40151.51230978966, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1280512, "time": 40152.95576953888, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1280520, "time": 40152.986338853836, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1280552, "time": 40153.96018362045, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1280688, "time": 40158.31765675545, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1281152, "time": 40172.51548719406, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1281848, "time": 40193.61162376404, "episode/length": 207.0, "episode/score": 0.3531250059604645, "episode/reward_rate": 0.004807692307692308, "episode/intrinsic_return": 0.0}
{"step": 1282000, "time": 40198.48821353912, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 1282320, "time": 40208.36063790321, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 1282352, "time": 40209.35247182846, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1282664, "time": 40218.615231752396, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1282720, "time": 40220.55932021141, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1282784, "time": 40222.505717515945, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1282824, "time": 40223.51511502266, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1282832, "time": 40224.00459742546, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1282864, "time": 40224.98353886604, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1282960, "time": 40227.90663647652, "episode/length": 15.0, "episode/score": 0.953125, "episode/reward_rate": 0.0625, "episode/intrinsic_return": 0.0}
{"step": 1283360, "time": 40240.24681997299, "episode/length": 275.0, "episode/score": 0.140625, "episode/reward_rate": 0.0036231884057971015, "episode/intrinsic_return": 0.0}
{"step": 1283368, "time": 40240.275696992874, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1283408, "time": 40241.73114705086, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1283440, "time": 40242.71579527855, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1283600, "time": 40247.60623025894, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1283704, "time": 40250.56733870506, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1283712, "time": 40251.03779006004, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1283920, "time": 40257.3766708374, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1284000, "time": 40259.82108592987, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1284185, "time": 40266.29128718376, "train_stats/mean_log_entropy": 0.08085535720908811, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.546327505538713, "train/action_min": 0.0, "train/action_std": 1.7427593671267305, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.010297507191290012, "train/actor_opt_grad_steps": 79160.0, "train/actor_opt_loss": -25.716565872306255, "train/adv_mag": 0.712186517407052, "train/adv_max": 0.28426092121731583, "train/adv_mean": -3.169559330948216e-05, "train/adv_min": -0.645541049947786, "train/adv_std": 0.029429671757701618, "train/cont_avg": 0.9933778373756219, "train/cont_loss_mean": 0.02820890743415154, "train/cont_loss_std": 0.29697089527376846, "train/cont_neg_acc": 0.11738152924313475, "train/cont_neg_loss": 3.348437423729778, "train/cont_pos_acc": 0.9998776877104346, "train/cont_pos_loss": 0.006035789102547575, "train/cont_pred": 0.9932904827654065, "train/cont_rate": 0.9933778373756219, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.13636761575714865, "train/extr_critic_critic_opt_grad_steps": 79160.0, "train/extr_critic_critic_opt_loss": 4659.469300227379, "train/extr_critic_mag": 1.6882434448792567, "train/extr_critic_max": 1.6882434448792567, "train/extr_critic_mean": 1.5645305357169157, "train/extr_critic_min": 1.3103800418958143, "train/extr_critic_std": 0.028412974944606942, "train/extr_return_normed_mag": 0.74265418657616, "train/extr_return_normed_max": 0.30220203020086334, "train/extr_return_normed_mean": 0.059992364927459116, "train/extr_return_normed_min": -0.6099820641142812, "train/extr_return_normed_std": 0.042347403845532025, "train/extr_return_rate": 0.9997331283578825, "train/extr_return_raw_mag": 1.8067084307694317, "train/extr_return_raw_max": 1.8067084307694317, "train/extr_return_raw_mean": 1.5644988361282728, "train/extr_return_raw_min": 0.8945243364542871, "train/extr_return_raw_std": 0.04234740389186648, "train/extr_reward_mag": 0.2732676149007693, "train/extr_reward_max": 0.2732676149007693, "train/extr_reward_mean": 0.002752933019322728, "train/extr_reward_min": 6.168042842428482e-08, "train/extr_reward_std": 0.009980186959033582, "train/image_loss_mean": 0.08878607367772368, "train/image_loss_std": 0.10349484814785014, "train/model_loss_mean": 0.7420687319627449, "train/model_loss_std": 0.5933105878865541, "train/model_opt_grad_norm": 15.136319298056227, "train/model_opt_grad_steps": 79088.20895522388, "train/model_opt_loss": 3954.8285319010415, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5323.3830845771145, "train/policy_entropy_mag": 1.2356287264705297, "train/policy_entropy_max": 1.2356287264705297, "train/policy_entropy_mean": 0.08757537684926939, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.10227380185133189, "train/policy_logprob_mag": 6.551080260110732, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.08701599526464643, "train/policy_logprob_min": -6.551080260110732, "train/policy_logprob_std": 0.6224113210516783, "train/policy_randomness_mag": 0.6349875903248194, "train/policy_randomness_max": 0.6349875903248194, "train/policy_randomness_mean": 0.045004844609925994, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.05255834031757431, "train/post_ent_mag": 28.89940167896783, "train/post_ent_max": 28.89940167896783, "train/post_ent_mean": 28.265409573986755, "train/post_ent_min": 27.65907743083897, "train/post_ent_std": 0.2615725853994711, "train/prior_ent_mag": 27.93595531330773, "train/prior_ent_max": 27.93595531330773, "train/prior_ent_mean": 27.28226804970509, "train/prior_ent_min": 26.50033135675079, "train/prior_ent_std": 0.2576479859168257, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0033967127132725284, "train/reward_loss_mean": 0.025073725656045612, "train/reward_loss_std": 0.29752902475310794, "train/reward_max_data": 0.8240827108497051, "train/reward_max_pred": 0.31911944453396013, "train/reward_neg_acc": 0.9993700405851526, "train/reward_neg_loss": 0.004568578813234298, "train/reward_pos_acc": 0.13446655839829896, "train/reward_pos_loss": 4.062340397146804, "train/reward_pred": 0.0026737346767971466, "train/reward_rate": 0.00501885105721393, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.990234375, "report/cont_loss_mean": 0.042161229997873306, "report/cont_loss_std": 0.38850563764572144, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 3.8299148082733154, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.004806657787412405, "report/cont_pred": 0.9949617385864258, "report/cont_rate": 0.990234375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.10063526779413223, "report/image_loss_std": 0.1134645938873291, "report/model_loss_mean": 0.7810360193252563, "report/model_loss_std": 0.7810087203979492, "report/post_ent_mag": 29.995502471923828, "report/post_ent_max": 29.995502471923828, "report/post_ent_mean": 29.013731002807617, "report/post_ent_min": 28.158538818359375, "report/post_ent_std": 0.3955971598625183, "report/prior_ent_mag": 27.95391082763672, "report/prior_ent_max": 27.95391082763672, "report/prior_ent_mean": 27.308433532714844, "report/prior_ent_min": 26.365840911865234, "report/prior_ent_std": 0.27545666694641113, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0053161620162427425, "report/reward_loss_mean": 0.03823952376842499, "report/reward_loss_std": 0.39775213599205017, "report/reward_max_data": 0.7875000238418579, "report/reward_max_pred": 0.1316971778869629, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0035394197329878807, "report/reward_pos_acc": 0.125, "report/reward_pos_loss": 4.445152759552002, "report/reward_pred": 0.0020812097936868668, "report/reward_rate": 0.0078125, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.016472147777676582, "eval/cont_loss_std": 0.21391542255878448, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 3.8995304107666016, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.00506257452070713, "eval/cont_pred": 0.9949313402175903, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.08196469396352768, "eval/image_loss_std": 0.10054249316453934, "eval/model_loss_mean": 0.715577244758606, "eval/model_loss_std": 0.499268501996994, "eval/post_ent_mag": 29.997947692871094, "eval/post_ent_max": 29.997947692871094, "eval/post_ent_mean": 29.03980255126953, "eval/post_ent_min": 28.238300323486328, "eval/post_ent_std": 0.3603087365627289, "eval/prior_ent_mag": 27.956890106201172, "eval/prior_ent_max": 27.956890106201172, "eval/prior_ent_mean": 27.310773849487305, "eval/prior_ent_min": 26.356388092041016, "eval/prior_ent_std": 0.26700273156166077, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0022491454146802425, "eval/reward_loss_mean": 0.017140382900834084, "eval/reward_loss_std": 0.2532080411911011, "eval/reward_max_data": 0.887499988079071, "eval/reward_max_pred": 0.028397202491760254, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.003555946983397007, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 4.640377044677734, "eval/reward_pred": 0.0018856851384043694, "eval/reward_rate": 0.0029296875, "replay/size": 1000000.0, "replay/inserts": 32208.0, "replay/samples": 32208.0, "replay/insert_wait_avg": 1.295757009446532e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.593447102993446e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4216.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1727524889488148e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.642673492431641e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.240068435669, "timer/env.step_count": 4026.0, "timer/env.step_total": 39.77812671661377, "timer/env.step_frac": 0.0397685795359358, "timer/env.step_avg": 0.009880309666322347, "timer/env.step_min": 0.007814407348632812, "timer/env.step_max": 0.04109930992126465, "timer/replay._sample_count": 32208.0, "timer/replay._sample_total": 17.126801252365112, "timer/replay._sample_frac": 0.01712269063480997, "timer/replay._sample_avg": 0.000531756124328276, "timer/replay._sample_min": 0.0003876686096191406, "timer/replay._sample_max": 0.025342226028442383, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4553.0, "timer/agent.policy_total": 49.355128049850464, "timer/agent.policy_frac": 0.04934328228526147, "timer/agent.policy_avg": 0.010840133549275306, "timer/agent.policy_min": 0.009095191955566406, "timer/agent.policy_max": 0.08854985237121582, "timer/dataset_train_count": 2013.0, "timer/dataset_train_total": 0.2357020378112793, "timer/dataset_train_frac": 0.00023564546677269868, "timer/dataset_train_avg": 0.00011708993433247854, "timer/dataset_train_min": 0.00010204315185546875, "timer/dataset_train_max": 0.0003685951232910156, "timer/agent.train_count": 2013.0, "timer/agent.train_total": 899.1800601482391, "timer/agent.train_frac": 0.8989642472076896, "timer/agent.train_avg": 0.44668656738610985, "timer/agent.train_min": 0.4348642826080322, "timer/agent.train_max": 0.7128114700317383, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4786567687988281, "timer/agent.report_frac": 0.0004785418859968548, "timer/agent.report_avg": 0.23932838439941406, "timer/agent.report_min": 0.23246240615844727, "timer/agent.report_max": 0.24619436264038086, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.123283386230469e-05, "timer/dataset_eval_frac": 3.122533764434317e-08, "timer/dataset_eval_avg": 3.123283386230469e-05, "timer/dataset_eval_min": 3.123283386230469e-05, "timer/dataset_eval_max": 3.123283386230469e-05, "fps": 32.199562928759015}
{"step": 1284384, "time": 40272.475341796875, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1284480, "time": 40275.41752457619, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1284592, "time": 40278.87308430672, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1284648, "time": 40280.354041814804, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 1284744, "time": 40283.277173280716, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 1284824, "time": 40285.72917151451, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1284904, "time": 40288.165026426315, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1285384, "time": 40302.96127700806, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1285456, "time": 40305.443642139435, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1285600, "time": 40309.900646686554, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1285648, "time": 40311.35775184631, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1285912, "time": 40319.20450639725, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1286032, "time": 40323.09305024147, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 1286056, "time": 40323.607114076614, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1286296, "time": 40331.534507513046, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1286696, "time": 40343.83673095703, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1286784, "time": 40346.76109004021, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1286904, "time": 40350.21890377998, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1286960, "time": 40352.15675830841, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1287224, "time": 40360.10128951073, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1287344, "time": 40364.00543665886, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1287400, "time": 40365.499168634415, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 1287576, "time": 40370.8827855587, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1287768, "time": 40376.73095488548, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1287784, "time": 40377.22354364395, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 1287976, "time": 40383.15282034874, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1288064, "time": 40386.07200932503, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1288360, "time": 40394.99580740929, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1288368, "time": 40395.47132539749, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1288408, "time": 40396.47950839996, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1288496, "time": 40399.4375872612, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1288512, "time": 40399.93181371689, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1288544, "time": 40400.910255908966, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 1288712, "time": 40405.84173297882, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1288824, "time": 40409.28839755058, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1288960, "time": 40413.69841003418, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1289168, "time": 40420.24292731285, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1289192, "time": 40420.76030278206, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1289312, "time": 40424.70161342621, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1289368, "time": 40426.210943460464, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1289384, "time": 40426.709463357925, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1289472, "time": 40429.65772104263, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1289592, "time": 40433.161729097366, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1289664, "time": 40435.62545156479, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1289968, "time": 40444.91530394554, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1290016, "time": 40447.91054701805, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 1290016, "time": 40448.04935860634, "eval_episode/length": 75.0, "eval_episode/score": 0.765625, "eval_episode/reward_rate": 0.013157894736842105}
{"step": 1290016, "time": 40448.53453087807, "eval_episode/length": 99.0, "eval_episode/score": 0.690625011920929, "eval_episode/reward_rate": 0.01}
{"step": 1290016, "time": 40448.61901259422, "eval_episode/length": 103.0, "eval_episode/score": 0.6781250238418579, "eval_episode/reward_rate": 0.009615384615384616}
{"step": 1290016, "time": 40448.79847931862, "eval_episode/length": 112.0, "eval_episode/score": 0.6499999761581421, "eval_episode/reward_rate": 0.008849557522123894}
{"step": 1290016, "time": 40449.009979724884, "eval_episode/length": 23.0, "eval_episode/score": 0.9281250238418579, "eval_episode/reward_rate": 0.041666666666666664}
{"step": 1290016, "time": 40449.05454874039, "eval_episode/length": 125.0, "eval_episode/score": 0.609375, "eval_episode/reward_rate": 0.007936507936507936}
{"step": 1290016, "time": 40449.06082582474, "eval_episode/length": 125.0, "eval_episode/score": 0.609375, "eval_episode/reward_rate": 0.007936507936507936}
{"step": 1290096, "time": 40451.52680492401, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1290120, "time": 40452.04449248314, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1290136, "time": 40452.53789615631, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1290248, "time": 40455.98151421547, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1290392, "time": 40460.39056515694, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1290392, "time": 40460.39834833145, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1290416, "time": 40461.36204981804, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 1290528, "time": 40464.78235530853, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1290848, "time": 40474.5548722744, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1290888, "time": 40475.55355167389, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1290976, "time": 40478.52593803406, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1290992, "time": 40479.04070234299, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1291480, "time": 40493.7049510479, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1291496, "time": 40494.19635295868, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1291632, "time": 40498.578451156616, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1291696, "time": 40500.528670072556, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 1292264, "time": 40517.72943305969, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 1292272, "time": 40518.224539756775, "episode/length": 231.0, "episode/score": 0.27812498807907104, "episode/reward_rate": 0.004310344827586207, "episode/intrinsic_return": 0.0}
{"step": 1292328, "time": 40519.71817803383, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1292448, "time": 40523.63947582245, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1292696, "time": 40531.018760442734, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1292840, "time": 40535.45101761818, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1293336, "time": 40550.71836018562, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1293552, "time": 40557.529116630554, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1293792, "time": 40564.796380996704, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1293824, "time": 40565.77133870125, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1294008, "time": 40571.24109196663, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1294216, "time": 40577.64886903763, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1294400, "time": 40584.1264898777, "episode/length": 258.0, "episode/score": 0.19374999403953552, "episode/reward_rate": 0.003861003861003861, "episode/intrinsic_return": 0.0}
{"step": 1294480, "time": 40586.585755586624, "episode/length": 222.0, "episode/score": 0.3062500059604645, "episode/reward_rate": 0.004484304932735426, "episode/intrinsic_return": 0.0}
{"step": 1294576, "time": 40589.54130530357, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1294680, "time": 40592.501447200775, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1294792, "time": 40595.908022880554, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1295152, "time": 40607.23819255829, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1295248, "time": 40610.17295598984, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1295360, "time": 40613.60503935814, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1295416, "time": 40615.09765124321, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1295416, "time": 40615.10616159439, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 1295520, "time": 40618.507566690445, "episode/length": 215.0, "episode/score": 0.328125, "episode/reward_rate": 0.004629629629629629, "episode/intrinsic_return": 0.0}
{"step": 1295824, "time": 40627.89757204056, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 1296216, "time": 40639.65880870819, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1296320, "time": 40643.06791162491, "episode/length": 229.0, "episode/score": 0.28437501192092896, "episode/reward_rate": 0.004347826086956522, "episode/intrinsic_return": 0.0}
{"step": 1296384, "time": 40645.013484716415, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1296400, "time": 40645.506029844284, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1296528, "time": 40649.41304254532, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1296784, "time": 40657.322101831436, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1296792, "time": 40657.35095620155, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1296840, "time": 40658.837931871414, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 1297384, "time": 40675.59492135048, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1297560, "time": 40681.01006650925, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1297664, "time": 40684.40702795982, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1297728, "time": 40686.4256401062, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1297832, "time": 40689.486844301224, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1297912, "time": 40691.97132587433, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 1298072, "time": 40696.91519546509, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1298480, "time": 40709.63227391243, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1298584, "time": 40712.61347198486, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1298616, "time": 40713.59719276428, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1298928, "time": 40723.51415038109, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1299096, "time": 40728.50946640968, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1299104, "time": 40728.985381126404, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1299184, "time": 40731.41998100281, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1299200, "time": 40731.912259578705, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 1299352, "time": 40736.345623493195, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1299440, "time": 40739.24262714386, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1299552, "time": 40742.68550992012, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1299624, "time": 40744.65098166466, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1299688, "time": 40746.734743118286, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1299696, "time": 40747.207857847214, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1299792, "time": 40750.17762827873, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1299880, "time": 40752.633929014206, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 1299952, "time": 40755.09335923195, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1299992, "time": 40756.09685754776, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1300000, "time": 40757.00601863861, "eval_episode/length": 21.0, "eval_episode/score": 0.934374988079071, "eval_episode/reward_rate": 0.045454545454545456}
{"step": 1300000, "time": 40757.44171452522, "eval_episode/length": 43.0, "eval_episode/score": 0.8656250238418579, "eval_episode/reward_rate": 0.022727272727272728}
{"step": 1300000, "time": 40757.624089717865, "eval_episode/length": 52.0, "eval_episode/score": 0.8374999761581421, "eval_episode/reward_rate": 0.018867924528301886}
{"step": 1300000, "time": 40758.36862564087, "eval_episode/length": 89.0, "eval_episode/score": 0.721875011920929, "eval_episode/reward_rate": 0.011111111111111112}
{"step": 1300000, "time": 40758.88365030289, "eval_episode/length": 70.0, "eval_episode/score": 0.78125, "eval_episode/reward_rate": 0.014084507042253521}
{"step": 1300000, "time": 40759.005063295364, "eval_episode/length": 120.0, "eval_episode/score": 0.625, "eval_episode/reward_rate": 0.008264462809917356}
{"step": 1300000, "time": 40759.21666407585, "eval_episode/length": 130.0, "eval_episode/score": 0.59375, "eval_episode/reward_rate": 0.007633587786259542}
{"step": 1300000, "time": 40759.64750242233, "eval_episode/length": 150.0, "eval_episode/score": 0.53125, "eval_episode/reward_rate": 0.006622516556291391}
{"step": 1300368, "time": 40770.87244439125, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1300632, "time": 40778.885063648224, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1300632, "time": 40778.89470410347, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1300736, "time": 40782.292196035385, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1300824, "time": 40784.774220228195, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1300904, "time": 40787.214726924896, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 1301152, "time": 40794.97711896896, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 1301232, "time": 40797.41366171837, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 1301360, "time": 40801.29903006554, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1301544, "time": 40806.80995297432, "episode/length": 218.0, "episode/score": 0.3187499940395355, "episode/reward_rate": 0.0045662100456621, "episode/intrinsic_return": 0.0}
{"step": 1301560, "time": 40807.32014346123, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1301680, "time": 40811.202926158905, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 1301744, "time": 40813.167076826096, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1301752, "time": 40813.196150541306, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1301776, "time": 40814.164576768875, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1302016, "time": 40821.492909669876, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1302024, "time": 40821.52168536186, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1302080, "time": 40823.46494483948, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1302304, "time": 40830.33755540848, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1302496, "time": 40836.22749662399, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1302504, "time": 40836.256222486496, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1302704, "time": 40843.27022600174, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 1302744, "time": 40844.271950006485, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1302816, "time": 40846.70531988144, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1302872, "time": 40848.22239899635, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1302912, "time": 40849.67082834244, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 1303080, "time": 40854.60265612602, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1303176, "time": 40857.54427552223, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1303384, "time": 40863.883355140686, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1303432, "time": 40865.347730875015, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1303968, "time": 40882.03719139099, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1304048, "time": 40884.47022533417, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1304056, "time": 40884.49918842316, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1304056, "time": 40884.50809049606, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1304160, "time": 40887.9344933033, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 1304240, "time": 40890.35575175285, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 1304656, "time": 40903.17640423775, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1304664, "time": 40903.20310544968, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1305000, "time": 40913.43614768982, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1305168, "time": 40918.792543172836, "episode/length": 222.0, "episode/score": 0.3062500059604645, "episode/reward_rate": 0.004484304932735426, "episode/intrinsic_return": 0.0}
{"step": 1305200, "time": 40919.77661538124, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1305216, "time": 40920.268334150314, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1305224, "time": 40920.2973151207, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1305248, "time": 40921.273066043854, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1305304, "time": 40922.76288485527, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1305432, "time": 40926.83965969086, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1305752, "time": 40936.61954450607, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1305864, "time": 40940.051726579666, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1306040, "time": 40945.511643886566, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1306112, "time": 40947.93526554108, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1306144, "time": 40948.91026520729, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 1307056, "time": 40976.980190992355, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1307184, "time": 40980.908210515976, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1307312, "time": 40984.838975191116, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1307352, "time": 40985.84488940239, "episode/length": 272.0, "episode/score": 0.15000000596046448, "episode/reward_rate": 0.003663003663003663, "episode/intrinsic_return": 0.0}
{"step": 1307528, "time": 40991.31194925308, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1307616, "time": 40994.22586727142, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1307888, "time": 41002.623196840286, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1308064, "time": 41008.022930145264, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1308176, "time": 41011.46336603165, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1308352, "time": 41016.98823142052, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 1308360, "time": 41017.016108989716, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 1308368, "time": 41017.49178647995, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1308416, "time": 41018.97737622261, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1308488, "time": 41020.98002624512, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1308776, "time": 41029.754113674164, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1308976, "time": 41036.073063611984, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1309376, "time": 41048.256793022156, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1309376, "time": 41048.273434877396, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1309608, "time": 41055.111676454544, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1309624, "time": 41055.60259604454, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1309736, "time": 41059.04160094261, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1309968, "time": 41066.36586689949, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 1310088, "time": 41071.05300402641, "eval_episode/length": 63.0, "eval_episode/score": 0.8031250238418579, "eval_episode/reward_rate": 0.015625}
{"step": 1310088, "time": 41071.76030373573, "eval_episode/length": 99.0, "eval_episode/score": 0.690625011920929, "eval_episode/reward_rate": 0.01}
{"step": 1310088, "time": 41072.13896083832, "eval_episode/length": 118.0, "eval_episode/score": 0.6312500238418579, "eval_episode/reward_rate": 0.008403361344537815}
{"step": 1310088, "time": 41072.28723311424, "eval_episode/length": 125.0, "eval_episode/score": 0.609375, "eval_episode/reward_rate": 0.007936507936507936}
{"step": 1310088, "time": 41072.502022981644, "eval_episode/length": 134.0, "eval_episode/score": 0.581250011920929, "eval_episode/reward_rate": 0.007407407407407408}
{"step": 1310088, "time": 41073.469394207, "eval_episode/length": 47.0, "eval_episode/score": 0.8531249761581421, "eval_episode/reward_rate": 0.020833333333333332}
{"step": 1310088, "time": 41073.74794411659, "eval_episode/length": 131.0, "eval_episode/score": 0.590624988079071, "eval_episode/reward_rate": 0.007575757575757576}
{"step": 1310088, "time": 41074.18087220192, "eval_episode/length": 96.0, "eval_episode/score": 0.699999988079071, "eval_episode/reward_rate": 0.010309278350515464}
{"step": 1310200, "time": 41077.72308254242, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1310200, "time": 41077.73264837265, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 1310256, "time": 41079.68143725395, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1310368, "time": 41083.114366054535, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1310376, "time": 41083.14201593399, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1310376, "time": 41083.15169382095, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1310672, "time": 41092.404693603516, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1310760, "time": 41095.36246037483, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1311056, "time": 41104.591660022736, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1311352, "time": 41113.50936436653, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1311392, "time": 41114.95945739746, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1311592, "time": 41120.847168684006, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1311712, "time": 41124.73270893097, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1311912, "time": 41130.61367583275, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1312048, "time": 41135.00787568092, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1312048, "time": 41135.01922273636, "episode/length": 288.0, "episode/score": 0.10000000149011612, "episode/reward_rate": 0.0034602076124567475, "episode/intrinsic_return": 0.0}
{"step": 1312216, "time": 41140.051310777664, "episode/length": 251.0, "episode/score": 0.21562500298023224, "episode/reward_rate": 0.003968253968253968, "episode/intrinsic_return": 0.0}
{"step": 1312376, "time": 41144.998661994934, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1312736, "time": 41156.368272304535, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 1312864, "time": 41160.32250857353, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1312968, "time": 41163.31103134155, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1312984, "time": 41163.80492377281, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1313056, "time": 41166.21368765831, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1313488, "time": 41179.50160098076, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1313536, "time": 41180.9734852314, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1313904, "time": 41192.23899912834, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1313976, "time": 41194.22761011124, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1314024, "time": 41195.709659576416, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1314232, "time": 41202.25279164314, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 1314360, "time": 41206.19251513481, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1314512, "time": 41211.00852370262, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1314520, "time": 41211.03592085838, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1315120, "time": 41229.61802840233, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1315272, "time": 41234.03990197182, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1315280, "time": 41234.51235342026, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1315360, "time": 41236.967233896255, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1315472, "time": 41240.39125299454, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1315800, "time": 41250.17724108696, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1315952, "time": 41255.05653715134, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1316048, "time": 41258.05646586418, "episode/length": 258.0, "episode/score": 0.19374999403953552, "episode/reward_rate": 0.003861003861003861, "episode/intrinsic_return": 0.0}
{"step": 1316216, "time": 41262.94801592827, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1316296, "time": 41265.410823106766, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1316297, "time": 41266.479662656784, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.5637325457672575, "train/action_min": 0.0, "train/action_std": 1.772501479333906, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.01007035505652094, "train/actor_opt_grad_steps": 81170.0, "train/actor_opt_loss": -25.556207410138637, "train/adv_mag": 0.7532319918793825, "train/adv_max": 0.2877433056855083, "train/adv_mean": 0.0004010613769858184, "train/adv_min": -0.6899338171849796, "train/adv_std": 0.02890306574510253, "train/cont_avg": 0.993222364738806, "train/cont_loss_mean": 0.029826037539400864, "train/cont_loss_std": 0.3094679442655981, "train/cont_neg_acc": 0.09822765889749005, "train/cont_neg_loss": 3.478236098787678, "train/cont_pos_acc": 0.9998580929058701, "train/cont_pos_loss": 0.006188282231100608, "train/cont_pred": 0.9932692623257044, "train/cont_rate": 0.993222364738806, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.11633384611401985, "train/extr_critic_critic_opt_grad_steps": 81170.0, "train/extr_critic_critic_opt_loss": 5070.532907969916, "train/extr_critic_mag": 1.6860670568931162, "train/extr_critic_max": 1.6860670568931162, "train/extr_critic_mean": 1.5501518759561415, "train/extr_critic_min": 1.3031444680038375, "train/extr_critic_std": 0.02874418854972913, "train/extr_return_normed_mag": 0.7794912157960199, "train/extr_return_normed_max": 0.31835615931458733, "train/extr_return_normed_mean": 0.060055481242154964, "train/extr_return_normed_min": -0.6484733950439378, "train/extr_return_normed_std": 0.04203335364437222, "train/extr_return_rate": 0.9997567744990487, "train/extr_return_raw_mag": 1.8088535390683074, "train/extr_return_raw_max": 1.8088535390683074, "train/extr_return_raw_mean": 1.5505529262533235, "train/extr_return_raw_min": 0.8420239848580526, "train/extr_return_raw_std": 0.042033353690706675, "train/extr_reward_mag": 0.2807431226939111, "train/extr_reward_max": 0.2807431226939111, "train/extr_reward_mean": 0.0028810094050432914, "train/extr_reward_min": 1.0556842557233364e-07, "train/extr_reward_std": 0.009947695736935483, "train/image_loss_mean": 0.09109800182913073, "train/image_loss_std": 0.10525767816536462, "train/model_loss_mean": 0.7470263877318273, "train/model_loss_std": 0.6093400759779992, "train/model_opt_grad_norm": 15.234927720691434, "train/model_opt_grad_steps": 81096.3631840796, "train/model_opt_loss": 3992.7091009794776, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5348.258706467662, "train/policy_entropy_mag": 1.2305187666001012, "train/policy_entropy_max": 1.2305187666001012, "train/policy_entropy_mean": 0.08631259688542257, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.09961172293371229, "train/policy_logprob_mag": 6.551080286206298, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.08591474566738404, "train/policy_logprob_min": -6.551080286206298, "train/policy_logprob_std": 0.6216539402506245, "train/policy_randomness_mag": 0.6323615917518958, "train/policy_randomness_max": 0.6323615917518958, "train/policy_randomness_mean": 0.04435590430352818, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.05119030255435118, "train/post_ent_mag": 28.74955685933431, "train/post_ent_max": 28.74955685933431, "train/post_ent_mean": 28.143101725412244, "train/post_ent_min": 27.534167000310337, "train/post_ent_std": 0.2516469595888954, "train/prior_ent_mag": 27.941839265586133, "train/prior_ent_max": 27.941839265586133, "train/prior_ent_mean": 27.290284047672404, "train/prior_ent_min": 26.48169013635436, "train/prior_ent_std": 0.26056200184335754, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0035639368975013772, "train/reward_loss_mean": 0.026102328844442593, "train/reward_loss_std": 0.3031726433798226, "train/reward_max_data": 0.8244402991301978, "train/reward_max_pred": 0.335627654298621, "train/reward_neg_acc": 0.9994090160920253, "train/reward_neg_loss": 0.0046721411305966215, "train/reward_pos_acc": 0.1287781411781907, "train/reward_pos_loss": 4.112059098482132, "train/reward_pred": 0.0027549901799952137, "train/reward_rate": 0.005218050373134328, "train_stats/mean_log_entropy": 0.07852683408193833, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.026296259835362434, "report/cont_loss_std": 0.28380030393600464, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 3.1537582874298096, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.004769975319504738, "report/cont_pred": 0.9947319030761719, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.08933137357234955, "report/image_loss_std": 0.10900963097810745, "report/model_loss_mean": 0.7398706674575806, "report/model_loss_std": 0.5686612725257874, "report/post_ent_mag": 28.954444885253906, "report/post_ent_max": 28.954444885253906, "report/post_ent_mean": 28.209875106811523, "report/post_ent_min": 27.619701385498047, "report/post_ent_std": 0.2910704016685486, "report/prior_ent_mag": 27.883262634277344, "report/prior_ent_max": 27.883262634277344, "report/prior_ent_mean": 27.250829696655273, "report/prior_ent_min": 26.259010314941406, "report/prior_ent_std": 0.2622421085834503, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.004132079891860485, "report/reward_loss_mean": 0.024242978543043137, "report/reward_loss_std": 0.2840839922428131, "report/reward_max_data": 0.878125011920929, "report/reward_max_pred": 0.16180479526519775, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0034316065721213818, "report/reward_pos_acc": 0.3333333432674408, "report/reward_pos_loss": 3.555238723754883, "report/reward_pred": 0.00206093885935843, "report/reward_rate": 0.005859375, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.046815454959869385, "eval/cont_loss_std": 0.5902196764945984, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 7.112115383148193, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.005173217970877886, "eval/cont_pred": 0.994874119758606, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.09505176544189453, "eval/image_loss_std": 0.1140652447938919, "eval/model_loss_mean": 0.7802701592445374, "eval/model_loss_std": 1.0978628396987915, "eval/post_ent_mag": 28.944936752319336, "eval/post_ent_max": 28.944936752319336, "eval/post_ent_mean": 28.261075973510742, "eval/post_ent_min": 27.489898681640625, "eval/post_ent_std": 0.29539063572883606, "eval/prior_ent_mag": 27.930400848388672, "eval/prior_ent_max": 27.930400848388672, "eval/prior_ent_mean": 27.255298614501953, "eval/prior_ent_min": 26.417512893676758, "eval/prior_ent_std": 0.28326061367988586, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0035064697731286287, "eval/reward_loss_mean": 0.03840286657214165, "eval/reward_loss_std": 0.5210506319999695, "eval/reward_max_data": 0.768750011920929, "eval/reward_max_pred": 0.045409440994262695, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.003407118609175086, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 7.170536994934082, "eval/reward_pred": 0.0017742665950208902, "eval/reward_rate": 0.0048828125, "replay/size": 1000000.0, "replay/inserts": 32112.0, "replay/samples": 32112.0, "replay/insert_wait_avg": 1.288241394491533e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.512891580289908e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3944.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1867127602288979e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.2367963790893555e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1713831424713, "timer/env.step_count": 4014.0, "timer/env.step_total": 39.65435314178467, "timer/env.step_frac": 0.03964755821866584, "timer/env.step_avg": 0.009879011744340974, "timer/env.step_min": 0.007837057113647461, "timer/env.step_max": 0.03598952293395996, "timer/replay._sample_count": 32112.0, "timer/replay._sample_total": 17.06543278694153, "timer/replay._sample_frac": 0.01706250856060597, "timer/replay._sample_avg": 0.0005314347529565747, "timer/replay._sample_min": 0.0004220008850097656, "timer/replay._sample_max": 0.030266523361206055, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4507.0, "timer/agent.policy_total": 48.62705326080322, "timer/agent.policy_frac": 0.04861872083164416, "timer/agent.policy_avg": 0.010789228591258759, "timer/agent.policy_min": 0.009262800216674805, "timer/agent.policy_max": 0.08999514579772949, "timer/dataset_train_count": 2007.0, "timer/dataset_train_total": 0.2330632209777832, "timer/dataset_train_frac": 0.00023302328471497976, "timer/dataset_train_avg": 0.0001161251723855422, "timer/dataset_train_min": 9.894371032714844e-05, "timer/dataset_train_max": 0.00037932395935058594, "timer/agent.train_count": 2007.0, "timer/agent.train_total": 900.5097115039825, "timer/agent.train_frac": 0.9003554057652015, "timer/agent.train_avg": 0.44868446014149604, "timer/agent.train_min": 0.4372982978820801, "timer/agent.train_max": 0.7528212070465088, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4792003631591797, "timer/agent.report_frac": 0.00047911825036781627, "timer/agent.report_avg": 0.23960018157958984, "timer/agent.report_min": 0.23250603675842285, "timer/agent.report_max": 0.24669432640075684, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.123283386230469e-05, "timer/dataset_eval_frac": 3.122748199830835e-08, "timer/dataset_eval_avg": 3.123283386230469e-05, "timer/dataset_eval_min": 3.123283386230469e-05, "timer/dataset_eval_max": 3.123283386230469e-05, "fps": 32.1058034626017}
{"step": 1316312, "time": 41266.530994176865, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1316704, "time": 41279.11124396324, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 1316752, "time": 41280.59105491638, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1316832, "time": 41283.02919745445, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1317000, "time": 41288.069766521454, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1317136, "time": 41292.44317531586, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1317392, "time": 41300.338352918625, "episode/length": 264.0, "episode/score": 0.17499999701976776, "episode/reward_rate": 0.0037735849056603774, "episode/intrinsic_return": 0.0}
{"step": 1317592, "time": 41306.233181238174, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1317768, "time": 41311.6177585125, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1317952, "time": 41317.55802774429, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1317952, "time": 41317.56604361534, "episode/length": 237.0, "episode/score": 0.2593750059604645, "episode/reward_rate": 0.004201680672268907, "episode/intrinsic_return": 0.0}
{"step": 1318184, "time": 41324.41865444183, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 1318232, "time": 41325.894058942795, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1318480, "time": 41333.67942285538, "episode/length": 221.0, "episode/score": 0.30937498807907104, "episode/reward_rate": 0.0045045045045045045, "episode/intrinsic_return": 0.0}
{"step": 1318816, "time": 41343.876734972, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1318864, "time": 41345.35380291939, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1318872, "time": 41345.38088178635, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1318928, "time": 41347.987575531006, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 1319008, "time": 41350.446170568466, "episode/length": 250.0, "episode/score": 0.21875, "episode/reward_rate": 0.00398406374501992, "episode/intrinsic_return": 0.0}
{"step": 1319040, "time": 41351.4306101799, "episode/length": 237.0, "episode/score": 0.2593750059604645, "episode/reward_rate": 0.004201680672268907, "episode/intrinsic_return": 0.0}
{"step": 1319208, "time": 41356.37210249901, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1319360, "time": 41361.25834107399, "episode/length": 198.0, "episode/score": 0.3812499940395355, "episode/reward_rate": 0.005025125628140704, "episode/intrinsic_return": 0.0}
{"step": 1319672, "time": 41370.58976173401, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1319728, "time": 41372.51268577576, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1319832, "time": 41375.52139377594, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1319848, "time": 41376.02453684807, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1319936, "time": 41379.039487838745, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 1320000, "time": 41381.003851652145, "episode/length": 18.0, "episode/score": 0.9437500238418579, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.0}
{"step": 1320024, "time": 41381.51543831825, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1320072, "time": 41384.59904408455, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 1320072, "time": 41384.98032426834, "eval_episode/length": 103.0, "eval_episode/score": 0.6781250238418579, "eval_episode/reward_rate": 0.009615384615384616}
{"step": 1320072, "time": 41385.70356917381, "eval_episode/length": 140.0, "eval_episode/score": 0.5625, "eval_episode/reward_rate": 0.0070921985815602835}
{"step": 1320072, "time": 41386.160794734955, "eval_episode/length": 164.0, "eval_episode/score": 0.48750001192092896, "eval_episode/reward_rate": 0.006060606060606061}
{"step": 1320072, "time": 41386.89737343788, "eval_episode/length": 203.0, "eval_episode/score": 0.3656249940395355, "eval_episode/reward_rate": 0.004901960784313725}
{"step": 1320072, "time": 41387.27559161186, "eval_episode/length": 57.0, "eval_episode/score": 0.8218749761581421, "eval_episode/reward_rate": 0.017241379310344827}
{"step": 1320072, "time": 41387.79547262192, "eval_episode/length": 249.0, "eval_episode/score": 0.22187499701976776, "eval_episode/reward_rate": 0.004}
{"step": 1320072, "time": 41388.715056180954, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1320072, "time": 41388.80235123634, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1320096, "time": 41390.043580293655, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1320288, "time": 41395.91699838638, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 1320704, "time": 41408.740887880325, "episode/length": 211.0, "episode/score": 0.34062498807907104, "episode/reward_rate": 0.0047169811320754715, "episode/intrinsic_return": 0.0}
{"step": 1320704, "time": 41408.74882173538, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1320864, "time": 41413.63270401955, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1320968, "time": 41416.62768816948, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1321080, "time": 41420.07053279877, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 1321168, "time": 41422.96453285217, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1321288, "time": 41426.42059636116, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1321472, "time": 41432.268152952194, "episode/length": 282.0, "episode/score": 0.11874999850988388, "episode/reward_rate": 0.0035335689045936395, "episode/intrinsic_return": 0.0}
{"step": 1321672, "time": 41438.31347942352, "episode/length": 216.0, "episode/score": 0.32499998807907104, "episode/reward_rate": 0.004608294930875576, "episode/intrinsic_return": 0.0}
{"step": 1321736, "time": 41440.286588191986, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1321736, "time": 41440.2956802845, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1321840, "time": 41443.68112158775, "episode/length": 12.0, "episode/score": 0.9624999761581421, "episode/reward_rate": 0.07692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1322104, "time": 41451.522807598114, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1322192, "time": 41454.44140291214, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1322232, "time": 41455.446402311325, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1322240, "time": 41455.915267944336, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 1322512, "time": 41464.19930291176, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1323144, "time": 41483.41024160385, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1323368, "time": 41490.27737903595, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 1323376, "time": 41490.747555971146, "episode/length": 191.0, "episode/score": 0.40312498807907104, "episode/reward_rate": 0.005208333333333333, "episode/intrinsic_return": 0.0}
{"step": 1323424, "time": 41492.209471702576, "episode/length": 243.0, "episode/score": 0.24062499403953552, "episode/reward_rate": 0.004098360655737705, "episode/intrinsic_return": 0.0}
{"step": 1323488, "time": 41494.19356060028, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1323848, "time": 41505.11094045639, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1323856, "time": 41505.585831165314, "episode/length": 264.0, "episode/score": 0.17499999701976776, "episode/reward_rate": 0.0037735849056603774, "episode/intrinsic_return": 0.0}
{"step": 1324296, "time": 41518.80652093887, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1324384, "time": 41521.71335482597, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1324544, "time": 41526.72697353363, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1324600, "time": 41528.24096274376, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1324784, "time": 41534.10610485077, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 1324792, "time": 41534.13345503807, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1324824, "time": 41535.11444878578, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1325080, "time": 41542.95698547363, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1325344, "time": 41551.273223638535, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 1325736, "time": 41563.26906180382, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1325776, "time": 41564.71410322189, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1326104, "time": 41574.5134973526, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 1326200, "time": 41577.458008766174, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1326520, "time": 41587.33916139603, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 1326856, "time": 41597.74847602844, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1326912, "time": 41599.67986869812, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1326984, "time": 41601.67517089844, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 1327048, "time": 41603.67841219902, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 1327064, "time": 41604.18023896217, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 1327136, "time": 41607.1186504364, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1327288, "time": 41611.54741573334, "episode/length": 18.0, "episode/score": 0.9437500238418579, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.0}
{"step": 1327328, "time": 41613.016627788544, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 1327328, "time": 41613.02615571022, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 1327416, "time": 41615.501939058304, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1327424, "time": 41615.97458028793, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 1327688, "time": 41623.94832110405, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 1327760, "time": 41626.400127887726, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1327792, "time": 41627.41283535957, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1327904, "time": 41630.86715769768, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1327984, "time": 41633.31623530388, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1328104, "time": 41636.7600710392, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 1328280, "time": 41642.18593764305, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1328488, "time": 41648.62989926338, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1328504, "time": 41649.12551355362, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1328576, "time": 41651.535853624344, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1328832, "time": 41659.421865701675, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1329024, "time": 41665.33023715019, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 1329248, "time": 41672.186913490295, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1329408, "time": 41677.18795967102, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 1329408, "time": 41677.19615769386, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1329448, "time": 41678.20178127289, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1329672, "time": 41685.08604288101, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 1329744, "time": 41687.515001535416, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1329920, "time": 41692.887996912, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1330056, "time": 41697.99391961098, "eval_episode/length": 60.0, "eval_episode/score": 0.8125, "eval_episode/reward_rate": 0.01639344262295082}
{"step": 1330056, "time": 41698.25933933258, "eval_episode/length": 12.0, "eval_episode/score": 0.9624999761581421, "eval_episode/reward_rate": 0.07692307692307693}
{"step": 1330056, "time": 41698.79094290733, "eval_episode/length": 100.0, "eval_episode/score": 0.6875, "eval_episode/reward_rate": 0.009900990099009901}
{"step": 1330056, "time": 41698.81752228737, "eval_episode/length": 101.0, "eval_episode/score": 0.684374988079071, "eval_episode/reward_rate": 0.00980392156862745}
{"step": 1330056, "time": 41699.08461689949, "eval_episode/length": 114.0, "eval_episode/score": 0.643750011920929, "eval_episode/reward_rate": 0.008695652173913044}
{"step": 1330056, "time": 41699.229786634445, "eval_episode/length": 121.0, "eval_episode/score": 0.621874988079071, "eval_episode/reward_rate": 0.00819672131147541}
{"step": 1330056, "time": 41699.72955036163, "eval_episode/length": 31.0, "eval_episode/score": 0.903124988079071, "eval_episode/reward_rate": 0.03125}
{"step": 1330056, "time": 41700.085040569305, "eval_episode/length": 89.0, "eval_episode/score": 0.721875011920929, "eval_episode/reward_rate": 0.011111111111111112}
{"step": 1330352, "time": 41709.488011837006, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1330416, "time": 41711.46285510063, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1330528, "time": 41714.93429017067, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1330536, "time": 41714.96261429787, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 1330592, "time": 41716.908237457275, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1330928, "time": 41727.247824668884, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 1331160, "time": 41734.182611465454, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1331216, "time": 41736.13115692139, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1331224, "time": 41736.159326553345, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1331560, "time": 41746.65431690216, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1331904, "time": 41757.46633601189, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1331968, "time": 41759.45357275009, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1331984, "time": 41759.951051950455, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1332056, "time": 41761.92476320267, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1332240, "time": 41767.90543150902, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 1332320, "time": 41770.36351418495, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 1332320, "time": 41770.371765613556, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1332400, "time": 41772.816947460175, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1332456, "time": 41774.32608675957, "episode/length": 239.0, "episode/score": 0.25312501192092896, "episode/reward_rate": 0.004166666666666667, "episode/intrinsic_return": 0.0}
{"step": 1332544, "time": 41777.2275993824, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 1332576, "time": 41778.21038103104, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 1332600, "time": 41778.74282622337, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1332992, "time": 41791.017656087875, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1333280, "time": 41799.96780753136, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1333536, "time": 41807.83687853813, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1333536, "time": 41807.84691786766, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1333624, "time": 41810.345547914505, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 1333800, "time": 41815.756214380264, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 1333816, "time": 41816.25157427788, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1333904, "time": 41819.17579650879, "episode/length": 230.0, "episode/score": 0.28125, "episode/reward_rate": 0.004329004329004329, "episode/intrinsic_return": 0.0}
{"step": 1334136, "time": 41826.08115005493, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 1334296, "time": 41831.07444405556, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1334296, "time": 41831.08568429947, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1334456, "time": 41836.0018928051, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 1334544, "time": 41838.95001125336, "episode/length": 249.0, "episode/score": 0.22187499701976776, "episode/reward_rate": 0.004, "episode/intrinsic_return": 0.0}
{"step": 1334920, "time": 41850.323823690414, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 1335008, "time": 41853.27215719223, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 1335184, "time": 41858.810844659805, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1335264, "time": 41861.257967710495, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1335264, "time": 41861.26951742172, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1335496, "time": 41868.701105594635, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1335760, "time": 41876.987617492676, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1335848, "time": 41879.46912741661, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1335888, "time": 41880.919763326645, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1336128, "time": 41888.439807891846, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1336408, "time": 41896.83957695961, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1336488, "time": 41899.310344457626, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1336504, "time": 41899.81616067886, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 1336576, "time": 41902.22611093521, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1336808, "time": 41909.14737534523, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 1336856, "time": 41910.612733364105, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1336888, "time": 41911.59356164932, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 1337200, "time": 41921.45469522476, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1337272, "time": 41923.458328962326, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1337312, "time": 41924.90391755104, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1337576, "time": 41932.84374213219, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1337648, "time": 41935.308797836304, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1338208, "time": 41952.80235290527, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1338224, "time": 41953.305852890015, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1338520, "time": 41962.348454236984, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1338720, "time": 41968.766041994095, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1338816, "time": 41971.73453760147, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1338848, "time": 41972.741121053696, "episode/length": 254.0, "episode/score": 0.20624999701976776, "episode/reward_rate": 0.00392156862745098, "episode/intrinsic_return": 0.0}
{"step": 1338888, "time": 41973.76307272911, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1339176, "time": 41982.91846871376, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1339384, "time": 41989.37705755234, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1339488, "time": 41992.83593440056, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1339520, "time": 41993.82528471947, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1339624, "time": 41996.81525397301, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1339624, "time": 41996.828827142715, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1339688, "time": 41998.85089278221, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1339704, "time": 41999.349173784256, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1339912, "time": 42005.77951550484, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 1340040, "time": 42011.08860373497, "eval_episode/length": 58.0, "eval_episode/score": 0.8187500238418579, "eval_episode/reward_rate": 0.01694915254237288}
{"step": 1340040, "time": 42011.77937102318, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 1340040, "time": 42011.824486255646, "eval_episode/length": 94.0, "eval_episode/score": 0.706250011920929, "eval_episode/reward_rate": 0.010526315789473684}
{"step": 1340040, "time": 42011.97060227394, "eval_episode/length": 101.0, "eval_episode/score": 0.684374988079071, "eval_episode/reward_rate": 0.00980392156862745}
{"step": 1340040, "time": 42012.858438014984, "eval_episode/length": 144.0, "eval_episode/score": 0.550000011920929, "eval_episode/reward_rate": 0.006896551724137931}
{"step": 1340040, "time": 42013.00976777077, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 1340040, "time": 42014.07113265991, "eval_episode/length": 110.0, "eval_episode/score": 0.65625, "eval_episode/reward_rate": 0.009009009009009009}
{"step": 1340040, "time": 42014.39221787453, "eval_episode/length": 67.0, "eval_episode/score": 0.7906249761581421, "eval_episode/reward_rate": 0.014705882352941176}
{"step": 1340056, "time": 42014.887338638306, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1340520, "time": 42029.07723927498, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1340536, "time": 42029.570662498474, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1340728, "time": 42035.474147081375, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 1340760, "time": 42036.539737701416, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 1340904, "time": 42041.006843566895, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1340928, "time": 42041.996099710464, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1341280, "time": 42052.7670147419, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1341328, "time": 42054.23412895203, "episode/length": 225.0, "episode/score": 0.296875, "episode/reward_rate": 0.004424778761061947, "episode/intrinsic_return": 0.0}
{"step": 1341416, "time": 42056.713706731796, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1341800, "time": 42068.57306218147, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1341912, "time": 42072.02269077301, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1341976, "time": 42073.972923755646, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1342016, "time": 42075.42518520355, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1342256, "time": 42082.83099746704, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1342544, "time": 42091.672412872314, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1342896, "time": 42102.53494811058, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1343040, "time": 42106.92638158798, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1343072, "time": 42107.910200834274, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1343160, "time": 42110.40997886658, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1343456, "time": 42119.69623398781, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1343592, "time": 42124.178423166275, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1343728, "time": 42128.743498802185, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1344016, "time": 42137.61250734329, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1344128, "time": 42141.06977534294, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1344224, "time": 42144.0025165081, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1344288, "time": 42145.98694086075, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1344312, "time": 42146.497673511505, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1344728, "time": 42159.298827409744, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1344856, "time": 42163.26249074936, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1345008, "time": 42168.157953739166, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 1345168, "time": 42173.056834220886, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1345248, "time": 42175.53011631966, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1345336, "time": 42177.99004769325, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 1345384, "time": 42179.46435904503, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1345512, "time": 42183.428383111954, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1345832, "time": 42193.301617860794, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1346104, "time": 42201.68450856209, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1346168, "time": 42203.657516002655, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1346240, "time": 42206.11402249336, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 1346480, "time": 42213.48787474632, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1346536, "time": 42215.01949930191, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1346592, "time": 42217.06896209717, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1346600, "time": 42217.09862136841, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1346800, "time": 42223.570409059525, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1347256, "time": 42237.470056295395, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1347344, "time": 42240.39604997635, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1347536, "time": 42246.261615753174, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 1347592, "time": 42247.85498523712, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1347696, "time": 42251.27808737755, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1347752, "time": 42252.777916669846, "episode/length": 205.0, "episode/score": 0.359375, "episode/reward_rate": 0.0048543689320388345, "episode/intrinsic_return": 0.0}
{"step": 1347912, "time": 42257.72485136986, "episode/length": 19.0, "episode/score": 0.940625011920929, "episode/reward_rate": 0.05, "episode/intrinsic_return": 0.0}
{"step": 1348169, "time": 42266.84143567085, "train_stats/mean_log_entropy": 0.07942423956202609, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.55387226660647, "train/action_min": 0.0, "train/action_std": 1.84242300172547, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.009861335673149507, "train/actor_opt_grad_steps": 83170.0, "train/actor_opt_loss": -25.097911873055462, "train/adv_mag": 0.6881780079261741, "train/adv_max": 0.28620786043866797, "train/adv_mean": 9.894133894996782e-05, "train/adv_min": -0.6176347403071034, "train/adv_std": 0.03194390109567037, "train/cont_avg": 0.9931297110552764, "train/cont_loss_mean": 0.02971938065248518, "train/cont_loss_std": 0.3066752230252453, "train/cont_neg_acc": 0.08799468441374937, "train/cont_neg_loss": 3.4382996439334734, "train/cont_pos_acc": 0.9998468040820941, "train/cont_pos_loss": 0.006209381973024589, "train/cont_pred": 0.9931960468316198, "train/cont_rate": 0.9931297110552764, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.1806818562742304, "train/extr_critic_critic_opt_grad_steps": 83170.0, "train/extr_critic_critic_opt_loss": 4832.986705990892, "train/extr_critic_mag": 1.6644646666157785, "train/extr_critic_max": 1.6644646666157785, "train/extr_critic_mean": 1.556164312003246, "train/extr_critic_min": 1.3336340668213427, "train/extr_critic_std": 0.02742578688278869, "train/extr_return_normed_mag": 0.7179467019124247, "train/extr_return_normed_max": 0.3128199056165302, "train/extr_return_normed_mean": 0.06014378014109542, "train/extr_return_normed_min": -0.5813716847692901, "train/extr_return_normed_std": 0.04436025556981863, "train/extr_return_rate": 0.9996015450463223, "train/extr_return_raw_mag": 1.8089393503102824, "train/extr_return_raw_max": 1.8089393503102824, "train/extr_return_raw_mean": 1.5562633024388222, "train/extr_return_raw_min": 0.9147477599244621, "train/extr_return_raw_std": 0.04436025550429845, "train/extr_reward_mag": 0.27544082528981734, "train/extr_reward_max": 0.27544082528981734, "train/extr_reward_mean": 0.0028283406960445657, "train/extr_reward_min": 1.3957670585593986e-07, "train/extr_reward_std": 0.010049025567913025, "train/image_loss_mean": 0.09062751683982173, "train/image_loss_std": 0.10317343039129248, "train/model_loss_mean": 0.7473222822999236, "train/model_loss_std": 0.618710940132788, "train/model_opt_grad_norm": 15.31000262648616, "train/model_opt_grad_steps": 83094.4472361809, "train/model_opt_loss": 3907.3044409057, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5226.130653266332, "train/policy_entropy_mag": 1.190812533824288, "train/policy_entropy_max": 1.190812533824288, "train/policy_entropy_mean": 0.08617802114043403, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.09839731761858092, "train/policy_logprob_mag": 6.551080279613859, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.08622326507190962, "train/policy_logprob_min": -6.551080279613859, "train/policy_logprob_std": 0.6241667875692473, "train/policy_randomness_mag": 0.6119566242299487, "train/policy_randomness_max": 0.6119566242299487, "train/policy_randomness_mean": 0.04428674649428482, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.05056622158267989, "train/post_ent_mag": 28.755231148034483, "train/post_ent_max": 28.755231148034483, "train/post_ent_mean": 28.116999295488675, "train/post_ent_min": 27.46538707598969, "train/post_ent_std": 0.27029098248361944, "train/prior_ent_mag": 28.079016412322844, "train/prior_ent_max": 28.079016412322844, "train/prior_ent_mean": 27.25164400992082, "train/prior_ent_min": 26.396440592243444, "train/prior_ent_std": 0.27952117633879486, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.003643231445059985, "train/reward_loss_mean": 0.026975358920593058, "train/reward_loss_std": 0.31302805160682406, "train/reward_max_data": 0.8287374389231504, "train/reward_max_pred": 0.3141443975007714, "train/reward_neg_acc": 0.999363490085506, "train/reward_neg_loss": 0.004763856013048085, "train/reward_pos_acc": 0.1297979820987687, "train/reward_pos_loss": 4.15774763828546, "train/reward_pred": 0.002766282418766176, "train/reward_rate": 0.00534901067839196, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.027207622304558754, "report/cont_loss_std": 0.27865955233573914, "report/cont_neg_acc": 0.1428571492433548, "report/cont_neg_loss": 3.12579607963562, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.005880072247236967, "report/cont_pred": 0.9931941032409668, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.10600866377353668, "report/image_loss_std": 0.11418880522251129, "report/model_loss_mean": 0.7630263566970825, "report/model_loss_std": 0.6603155732154846, "report/post_ent_mag": 29.36062240600586, "report/post_ent_max": 29.36062240600586, "report/post_ent_mean": 28.58321762084961, "report/post_ent_min": 27.834026336669922, "report/post_ent_std": 0.32165801525115967, "report/prior_ent_mag": 28.352407455444336, "report/prior_ent_max": 28.352407455444336, "report/prior_ent_mean": 27.716697692871094, "report/prior_ent_min": 26.88329315185547, "report/prior_ent_std": 0.2770622670650482, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0031799315474927425, "report/reward_loss_mean": 0.02981003373861313, "report/reward_loss_std": 0.3569338619709015, "report/reward_max_data": 0.6968749761581421, "report/reward_max_pred": 0.4315396547317505, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.004378930665552616, "report/reward_pos_acc": 0.1666666716337204, "report/reward_pos_loss": 4.344620704650879, "report/reward_pred": 0.002706280443817377, "report/reward_rate": 0.005859375, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.018364835530519485, "eval/cont_loss_std": 0.2193356603384018, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 3.915069341659546, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.006915164180099964, "eval/cont_pred": 0.9931336641311646, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.11900585144758224, "eval/image_loss_std": 0.1224168911576271, "eval/model_loss_mean": 0.7567745447158813, "eval/model_loss_std": 0.5402010679244995, "eval/post_ent_mag": 29.353111267089844, "eval/post_ent_max": 29.353111267089844, "eval/post_ent_mean": 28.57218360900879, "eval/post_ent_min": 27.759033203125, "eval/post_ent_std": 0.2916884124279022, "eval/prior_ent_mag": 28.343351364135742, "eval/prior_ent_max": 28.343351364135742, "eval/prior_ent_mean": 27.707521438598633, "eval/prior_ent_min": 26.373851776123047, "eval/prior_ent_std": 0.2896202802658081, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.002172851702198386, "eval/reward_loss_mean": 0.01940377987921238, "eval/reward_loss_std": 0.28093981742858887, "eval/reward_max_data": 0.7875000238418579, "eval/reward_max_pred": 0.04138016700744629, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0047415620647370815, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.0094451904296875, "eval/reward_pred": 0.002448775339871645, "eval/reward_rate": 0.0029296875, "replay/size": 1000000.0, "replay/inserts": 31872.0, "replay/samples": 31872.0, "replay/insert_wait_avg": 1.3044276031624362e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.362896283467611e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5384.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1696858002207787e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1175870895385742e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1541390419006, "timer/env.step_count": 3984.0, "timer/env.step_total": 39.89375877380371, "timer/env.step_frac": 0.039887610535732025, "timer/env.step_avg": 0.010013493668123421, "timer/env.step_min": 0.007910013198852539, "timer/env.step_max": 0.05001211166381836, "timer/replay._sample_count": 31872.0, "timer/replay._sample_total": 17.114655256271362, "timer/replay._sample_frac": 0.017112017626269464, "timer/replay._sample_avg": 0.0005369809003599197, "timer/replay._sample_min": 0.0004227161407470703, "timer/replay._sample_max": 0.014619827270507812, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4657.0, "timer/agent.policy_total": 50.50463151931763, "timer/agent.policy_frac": 0.05049684798355044, "timer/agent.policy_avg": 0.010844885445419289, "timer/agent.policy_min": 0.007937431335449219, "timer/agent.policy_max": 0.07651638984680176, "timer/dataset_train_count": 1992.0, "timer/dataset_train_total": 0.2328503131866455, "timer/dataset_train_frac": 0.00023281442739386636, "timer/dataset_train_avg": 0.0001168927275033361, "timer/dataset_train_min": 0.00010085105895996094, "timer/dataset_train_max": 0.00035500526428222656, "timer/agent.train_count": 1992.0, "timer/agent.train_total": 896.1233847141266, "timer/agent.train_frac": 0.8959852784017567, "timer/agent.train_avg": 0.44986113690468205, "timer/agent.train_min": 0.4380488395690918, "timer/agent.train_max": 0.7273406982421875, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4781227111816406, "timer/agent.report_frac": 0.0004780490251629205, "timer/agent.report_avg": 0.2390613555908203, "timer/agent.report_min": 0.231797456741333, "timer/agent.report_max": 0.24632525444030762, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.743171691894531e-05, "timer/dataset_eval_frac": 3.742594811916e-08, "timer/dataset_eval_avg": 3.743171691894531e-05, "timer/dataset_eval_min": 3.743171691894531e-05, "timer/dataset_eval_max": 3.743171691894531e-05, "fps": 31.866418386713985}
{"step": 1348208, "time": 42268.04890656471, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 1348248, "time": 42269.07600021362, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1348264, "time": 42269.56996703148, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1348304, "time": 42271.03854775429, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1348424, "time": 42274.481107234955, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1348488, "time": 42276.54530096054, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1348792, "time": 42285.92415380478, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1348992, "time": 42292.28956031799, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1349328, "time": 42302.62986660004, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1349344, "time": 42303.12452220917, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1349480, "time": 42307.15325665474, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1349672, "time": 42313.0204102993, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1349912, "time": 42320.43716645241, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1350024, "time": 42325.399070978165, "eval_episode/length": 71.0, "eval_episode/score": 0.778124988079071, "eval_episode/reward_rate": 0.013888888888888888}
{"step": 1350024, "time": 42325.50685453415, "eval_episode/length": 76.0, "eval_episode/score": 0.762499988079071, "eval_episode/reward_rate": 0.012987012987012988}
{"step": 1350024, "time": 42326.29991912842, "eval_episode/length": 114.0, "eval_episode/score": 0.643750011920929, "eval_episode/reward_rate": 0.008695652173913044}
{"step": 1350024, "time": 42326.655629873276, "eval_episode/length": 131.0, "eval_episode/score": 0.590624988079071, "eval_episode/reward_rate": 0.007575757575757576}
{"step": 1350024, "time": 42326.8254442215, "eval_episode/length": 139.0, "eval_episode/score": 0.565625011920929, "eval_episode/reward_rate": 0.007142857142857143}
{"step": 1350024, "time": 42327.05751180649, "eval_episode/length": 78.0, "eval_episode/score": 0.7562500238418579, "eval_episode/reward_rate": 0.012658227848101266}
{"step": 1350024, "time": 42327.28944993019, "eval_episode/length": 161.0, "eval_episode/score": 0.49687498807907104, "eval_episode/reward_rate": 0.006172839506172839}
{"step": 1350024, "time": 42327.40143084526, "eval_episode/length": 166.0, "eval_episode/score": 0.48124998807907104, "eval_episode/reward_rate": 0.005988023952095809}
{"step": 1350216, "time": 42333.2862071991, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1350224, "time": 42333.75958490372, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1350464, "time": 42341.26583814621, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1350520, "time": 42342.790534734726, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1350560, "time": 42344.23502445221, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1350576, "time": 42344.729418992996, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1350808, "time": 42351.62355995178, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1350816, "time": 42352.09518170357, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 1351288, "time": 42366.332278728485, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1351504, "time": 42373.318635463715, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 1351632, "time": 42377.24349761009, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 1351784, "time": 42382.211891412735, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 1351792, "time": 42382.70567035675, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1351936, "time": 42387.14561748505, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1352256, "time": 42396.968547582626, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1352496, "time": 42404.300112724304, "episode/length": 241.0, "episode/score": 0.24687500298023224, "episode/reward_rate": 0.004132231404958678, "episode/intrinsic_return": 0.0}
{"step": 1352648, "time": 42408.73976778984, "episode/length": 228.0, "episode/score": 0.2874999940395355, "episode/reward_rate": 0.004366812227074236, "episode/intrinsic_return": 0.0}
{"step": 1352776, "time": 42412.64613223076, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1352912, "time": 42417.00747203827, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 1353120, "time": 42423.34672999382, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1353120, "time": 42423.35641002655, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 1353320, "time": 42429.36977958679, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1353432, "time": 42432.793048620224, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1353512, "time": 42435.256437540054, "episode/length": 196.0, "episode/score": 0.38749998807907104, "episode/reward_rate": 0.005076142131979695, "episode/intrinsic_return": 0.0}
{"step": 1353584, "time": 42437.71796631813, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1353944, "time": 42448.4926097393, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1353976, "time": 42449.471383571625, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1354008, "time": 42450.448316812515, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1354104, "time": 42453.40017938614, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1354224, "time": 42457.418816804886, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1354400, "time": 42462.791890621185, "episode/length": 218.0, "episode/score": 0.3187499940395355, "episode/reward_rate": 0.0045662100456621, "episode/intrinsic_return": 0.0}
{"step": 1354440, "time": 42463.79441690445, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1354704, "time": 42472.09739255905, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1354744, "time": 42473.10660433769, "episode/length": 202.0, "episode/score": 0.3687500059604645, "episode/reward_rate": 0.0049261083743842365, "episode/intrinsic_return": 0.0}
{"step": 1354960, "time": 42479.92633724213, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1355008, "time": 42481.412365436554, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1355064, "time": 42482.91124820709, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1355160, "time": 42485.87222266197, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1355368, "time": 42492.41128349304, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 1355464, "time": 42495.41466212273, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 1355496, "time": 42496.43239021301, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1355520, "time": 42497.397384405136, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1355528, "time": 42497.42599058151, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 1355536, "time": 42497.8991420269, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1355792, "time": 42505.754042863846, "episode/length": 226.0, "episode/score": 0.29374998807907104, "episode/reward_rate": 0.004405286343612335, "episode/intrinsic_return": 0.0}
{"step": 1356056, "time": 42513.59753060341, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1356104, "time": 42515.07193899155, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1356152, "time": 42516.647283792496, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1356336, "time": 42522.501510858536, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1356360, "time": 42523.01471781731, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1356520, "time": 42527.89650440216, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1356632, "time": 42531.33897900581, "episode/length": 13.0, "episode/score": 0.9593750238418579, "episode/reward_rate": 0.07142857142857142, "episode/intrinsic_return": 0.0}
{"step": 1356904, "time": 42539.65884399414, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1356936, "time": 42540.660900354385, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1357000, "time": 42542.62369227409, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1357056, "time": 42544.572672605515, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1357168, "time": 42548.13149189949, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1357504, "time": 42558.48234796524, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1357776, "time": 42566.84079456329, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1357800, "time": 42567.36459636688, "episode/length": 250.0, "episode/score": 0.21875, "episode/reward_rate": 0.00398406374501992, "episode/intrinsic_return": 0.0}
{"step": 1357864, "time": 42569.34130477905, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1358080, "time": 42576.19026494026, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1358104, "time": 42576.846678972244, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 1358152, "time": 42578.31308364868, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1358344, "time": 42584.19193673134, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1358368, "time": 42585.17046999931, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1358672, "time": 42594.49040675163, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1359232, "time": 42611.73799061775, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1359320, "time": 42614.24411153793, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 1359448, "time": 42618.15508842468, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1359544, "time": 42621.12073469162, "episode/length": 209.0, "episode/score": 0.34687501192092896, "episode/reward_rate": 0.004761904761904762, "episode/intrinsic_return": 0.0}
{"step": 1359560, "time": 42621.61769556999, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 1359576, "time": 42622.11112999916, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1359888, "time": 42632.42974591255, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1360000, "time": 42635.902191877365, "episode/length": 236.0, "episode/score": 0.26249998807907104, "episode/reward_rate": 0.004219409282700422, "episode/intrinsic_return": 0.0}
{"step": 1360008, "time": 42637.802709817886, "eval_episode/length": 88.0, "eval_episode/score": 0.7250000238418579, "eval_episode/reward_rate": 0.011235955056179775}
{"step": 1360008, "time": 42637.81012201309, "eval_episode/length": 88.0, "eval_episode/score": 0.7250000238418579, "eval_episode/reward_rate": 0.011235955056179775}
{"step": 1360008, "time": 42637.9094145298, "eval_episode/length": 93.0, "eval_episode/score": 0.7093750238418579, "eval_episode/reward_rate": 0.010638297872340425}
{"step": 1360008, "time": 42638.20567393303, "eval_episode/length": 108.0, "eval_episode/score": 0.6625000238418579, "eval_episode/reward_rate": 0.009174311926605505}
{"step": 1360008, "time": 42638.21391248703, "eval_episode/length": 108.0, "eval_episode/score": 0.6625000238418579, "eval_episode/reward_rate": 0.009174311926605505}
{"step": 1360008, "time": 42638.88539838791, "eval_episode/length": 55.0, "eval_episode/score": 0.828125, "eval_episode/reward_rate": 0.017857142857142856}
{"step": 1360008, "time": 42639.52706551552, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 1360008, "time": 42639.74686551094, "eval_episode/length": 188.0, "eval_episode/score": 0.4124999940395355, "eval_episode/reward_rate": 0.005291005291005291}
{"step": 1360088, "time": 42642.1676940918, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1360360, "time": 42650.455739974976, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1360440, "time": 42652.90044975281, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1360520, "time": 42655.32566738129, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 1360624, "time": 42658.71160316467, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1360640, "time": 42659.203258514404, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1360784, "time": 42663.58992910385, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1360904, "time": 42667.094455480576, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1361096, "time": 42672.97382712364, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1361144, "time": 42674.44299650192, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1361240, "time": 42677.38349413872, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1361888, "time": 42697.423971652985, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1361896, "time": 42697.452332019806, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1362032, "time": 42701.82703757286, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 1362112, "time": 42704.250338315964, "episode/length": 218.0, "episode/score": 0.3187499940395355, "episode/reward_rate": 0.0045662100456621, "episode/intrinsic_return": 0.0}
{"step": 1362152, "time": 42705.250497579575, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1362200, "time": 42706.72731757164, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1362432, "time": 42714.01116633415, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1362552, "time": 42717.45638561249, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1362752, "time": 42723.75977039337, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1362920, "time": 42728.78058433533, "episode/length": 251.0, "episode/score": 0.21562500298023224, "episode/reward_rate": 0.003968253968253968, "episode/intrinsic_return": 0.0}
{"step": 1362928, "time": 42729.252247571945, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1363040, "time": 42732.65885972977, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1363088, "time": 42734.12214636803, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1363120, "time": 42735.102053165436, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1363312, "time": 42740.9726190567, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1363472, "time": 42745.85149717331, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1363552, "time": 42748.276077747345, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1363584, "time": 42749.26403307915, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1363816, "time": 42756.09649991989, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1363816, "time": 42756.10672235489, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1363864, "time": 42757.67021560669, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1363984, "time": 42761.56849575043, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1364200, "time": 42767.92268872261, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1364208, "time": 42768.391728162766, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1364224, "time": 42768.88814711571, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1364352, "time": 42772.78701090813, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 1364464, "time": 42776.20030784607, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1364504, "time": 42777.193390607834, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1364592, "time": 42780.105387210846, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1364880, "time": 42788.931205034256, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1365072, "time": 42794.83071064949, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1365168, "time": 42797.77200007439, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1365512, "time": 42808.04020309448, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 1365536, "time": 42808.990577697754, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1365808, "time": 42817.401012420654, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1365944, "time": 42821.32719397545, "episode/length": 216.0, "episode/score": 0.32499998807907104, "episode/reward_rate": 0.004608294930875576, "episode/intrinsic_return": 0.0}
{"step": 1366168, "time": 42828.167743206024, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1366192, "time": 42829.15756392479, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1366296, "time": 42832.14284110069, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1366304, "time": 42832.621960401535, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 1366552, "time": 42840.017462968826, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1366856, "time": 42849.38620495796, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1366904, "time": 42850.85159778595, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1367096, "time": 42856.71017360687, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1367192, "time": 42859.642916440964, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1367232, "time": 42861.08757662773, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 1367296, "time": 42863.03988170624, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1367480, "time": 42868.47953271866, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1367600, "time": 42872.35399866104, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1367832, "time": 42879.37598800659, "episode/length": 207.0, "episode/score": 0.3531250059604645, "episode/reward_rate": 0.004807692307692308, "episode/intrinsic_return": 0.0}
{"step": 1367848, "time": 42879.86837339401, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 1367968, "time": 42883.7487680912, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1368176, "time": 42890.55346369743, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1368176, "time": 42890.56053733826, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1368272, "time": 42893.49803042412, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1368408, "time": 42897.40317893028, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1368424, "time": 42897.89573717117, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 1368592, "time": 42903.24900341034, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1368632, "time": 42904.25012302399, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 1368944, "time": 42914.1885945797, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1369160, "time": 42920.566415548325, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1369272, "time": 42924.00112056732, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1369544, "time": 42932.33119416237, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1369608, "time": 42934.28831076622, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1369624, "time": 42934.783464193344, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1369792, "time": 42940.242929935455, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1369792, "time": 42940.25195431709, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1370096, "time": 42951.09911775589, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 1370096, "time": 42951.48255729675, "eval_episode/length": 100.0, "eval_episode/score": 0.6875, "eval_episode/reward_rate": 0.009900990099009901}
{"step": 1370096, "time": 42951.68809366226, "eval_episode/length": 111.0, "eval_episode/score": 0.653124988079071, "eval_episode/reward_rate": 0.008928571428571428}
{"step": 1370096, "time": 42952.02014541626, "eval_episode/length": 128.0, "eval_episode/score": 0.6000000238418579, "eval_episode/reward_rate": 0.007751937984496124}
{"step": 1370096, "time": 42952.28780865669, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 1370096, "time": 42952.406507492065, "eval_episode/length": 148.0, "eval_episode/score": 0.5375000238418579, "eval_episode/reward_rate": 0.006711409395973154}
{"step": 1370096, "time": 42954.71511244774, "eval_episode/length": 120.0, "eval_episode/score": 0.625, "eval_episode/reward_rate": 0.008264462809917356}
{"step": 1370096, "time": 42955.691628456116, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1370096, "time": 42955.70279240608, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1370096, "time": 42955.723819732666, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1370264, "time": 42960.61731386185, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1370280, "time": 42961.106815338135, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1370280, "time": 42961.11470246315, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1370320, "time": 42962.56646633148, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1370376, "time": 42964.06992840767, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1370728, "time": 42974.8844602108, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1370872, "time": 42979.27915096283, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1370960, "time": 42982.176501750946, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1371232, "time": 42990.45251131058, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1371296, "time": 42992.40086507797, "episode/length": 266.0, "episode/score": 0.16875000298023224, "episode/reward_rate": 0.003745318352059925, "episode/intrinsic_return": 0.0}
{"step": 1371584, "time": 43001.25791096687, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1371840, "time": 43009.036333322525, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1372000, "time": 43013.88869762421, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 1372048, "time": 43015.3466258049, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1372136, "time": 43017.81101441383, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1372576, "time": 43031.52470779419, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1372592, "time": 43032.03767180443, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1372688, "time": 43034.95141005516, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1372768, "time": 43037.39481186867, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1373000, "time": 43044.224570035934, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1373080, "time": 43046.68100619316, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 1373224, "time": 43051.03504896164, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1373568, "time": 43061.84377908707, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1373608, "time": 43062.85801911354, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1373664, "time": 43064.82177186012, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1373872, "time": 43071.16021156311, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1374008, "time": 43075.08025050163, "episode/length": 270.0, "episode/score": 0.15625, "episode/reward_rate": 0.0036900369003690036, "episode/intrinsic_return": 0.0}
{"step": 1374192, "time": 43080.93228030205, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 1374376, "time": 43086.33957028389, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1374448, "time": 43088.878819942474, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1374688, "time": 43096.23664236069, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1374768, "time": 43098.679743766785, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1374792, "time": 43099.19473195076, "episode/length": 262.0, "episode/score": 0.18125000596046448, "episode/reward_rate": 0.0038022813688212928, "episode/intrinsic_return": 0.0}
{"step": 1374856, "time": 43101.166960954666, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1375328, "time": 43115.789993047714, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 1375480, "time": 43120.31623005867, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1375496, "time": 43120.80641555786, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1375752, "time": 43128.65274190903, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1375880, "time": 43132.58869886398, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1376112, "time": 43139.91794633865, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1376504, "time": 43152.20387792587, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1376736, "time": 43159.45240020752, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 1376768, "time": 43160.45539832115, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 1377000, "time": 43167.29358005524, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1377168, "time": 43172.648669719696, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1377368, "time": 43178.660955905914, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1377464, "time": 43181.64249563217, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1377632, "time": 43187.03794002533, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1377896, "time": 43194.849751234055, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 1377920, "time": 43195.80521893501, "episode/length": 225.0, "episode/score": 0.296875, "episode/reward_rate": 0.004424778761061947, "episode/intrinsic_return": 0.0}
{"step": 1378040, "time": 43199.24096894264, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1378064, "time": 43200.198112010956, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1378192, "time": 43204.102660655975, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1378328, "time": 43208.10771560669, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 1378384, "time": 43210.06476330757, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1378392, "time": 43210.09414482117, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1378688, "time": 43219.445748090744, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1378904, "time": 43225.81599831581, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1379056, "time": 43230.65894937515, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1379920, "time": 43257.067658662796, "episode/length": 249.0, "episode/score": 0.22187499701976776, "episode/reward_rate": 0.004, "episode/intrinsic_return": 0.0}
{"step": 1380080, "time": 43263.25685620308, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 1380080, "time": 43263.668449401855, "eval_episode/length": 91.0, "eval_episode/score": 0.715624988079071, "eval_episode/reward_rate": 0.010869565217391304}
{"step": 1380080, "time": 43263.843870162964, "eval_episode/length": 100.0, "eval_episode/score": 0.6875, "eval_episode/reward_rate": 0.009900990099009901}
{"step": 1380080, "time": 43264.035157203674, "eval_episode/length": 110.0, "eval_episode/score": 0.65625, "eval_episode/reward_rate": 0.009009009009009009}
{"step": 1380080, "time": 43264.390753507614, "eval_episode/length": 129.0, "eval_episode/score": 0.596875011920929, "eval_episode/reward_rate": 0.007692307692307693}
{"step": 1380080, "time": 43264.97295641899, "eval_episode/length": 89.0, "eval_episode/score": 0.721875011920929, "eval_episode/reward_rate": 0.011111111111111112}
{"step": 1380080, "time": 43265.33417344093, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 1380080, "time": 43265.64892530441, "eval_episode/length": 194.0, "eval_episode/score": 0.39375001192092896, "eval_episode/reward_rate": 0.005128205128205128}
{"step": 1380089, "time": 43266.80508041382, "train_stats/mean_log_entropy": 0.0816734457240168, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.5700643721537375, "train/action_min": 0.0, "train/action_std": 1.7652988943023298, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.011266886679006357, "train/actor_opt_grad_steps": 85160.0, "train/actor_opt_loss": -28.04110642054572, "train/adv_mag": 0.7151961374522453, "train/adv_max": 0.2893732894006087, "train/adv_mean": 0.0006594815021705458, "train/adv_min": -0.6524994121724038, "train/adv_std": 0.030181583691032687, "train/cont_avg": 0.9929334170854272, "train/cont_loss_mean": 0.030861251453995407, "train/cont_loss_std": 0.31275954883751556, "train/cont_neg_acc": 0.09016540571672832, "train/cont_neg_loss": 3.446179619910729, "train/cont_pos_acc": 0.999856687670377, "train/cont_pos_loss": 0.006426342905747082, "train/cont_pred": 0.9930086806790912, "train/cont_rate": 0.9929334170854272, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.13562478994641772, "train/extr_critic_critic_opt_grad_steps": 85160.0, "train/extr_critic_critic_opt_loss": 4275.897252375157, "train/extr_critic_mag": 1.6814717719303303, "train/extr_critic_max": 1.6814717719303303, "train/extr_critic_mean": 1.5687762570740589, "train/extr_critic_min": 1.3062121293053555, "train/extr_critic_std": 0.027821183813052562, "train/extr_return_normed_mag": 0.7328697964174664, "train/extr_return_normed_max": 0.3096299441016499, "train/extr_return_normed_mean": 0.06218940279816263, "train/extr_return_normed_min": -0.6034221888786584, "train/extr_return_normed_std": 0.042233989485094894, "train/extr_return_rate": 0.9996996923307677, "train/extr_return_raw_mag": 1.816876234121658, "train/extr_return_raw_max": 1.816876234121658, "train/extr_return_raw_mean": 1.5694357767776028, "train/extr_return_raw_min": 0.9038241011413497, "train/extr_return_raw_std": 0.04223398965357536, "train/extr_reward_mag": 0.2915327117670721, "train/extr_reward_max": 0.2915327117670721, "train/extr_reward_mean": 0.002932609799528616, "train/extr_reward_min": 1.0363420649389526e-07, "train/extr_reward_std": 0.009902385353630212, "train/image_loss_mean": 0.09176306834622244, "train/image_loss_std": 0.10453653286899155, "train/model_loss_mean": 0.7502257767035134, "train/model_loss_std": 0.6228013533593422, "train/model_opt_grad_norm": 14.790140001019042, "train/model_opt_grad_steps": 85082.52261306533, "train/model_opt_loss": 3900.174455038866, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5201.005025125628, "train/policy_entropy_mag": 1.2234051305444995, "train/policy_entropy_max": 1.2234051305444995, "train/policy_entropy_mean": 0.08689290876664109, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.1004206704434438, "train/policy_logprob_mag": 6.551080282010026, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.08738756172321549, "train/policy_logprob_min": -6.551080282010026, "train/policy_logprob_std": 0.626712580721582, "train/policy_randomness_mag": 0.6287059053104727, "train/policy_randomness_max": 0.6287059053104727, "train/policy_randomness_mean": 0.04465412608717554, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.05160601918197157, "train/post_ent_mag": 28.883798743013163, "train/post_ent_max": 28.883798743013163, "train/post_ent_mean": 28.229159455802574, "train/post_ent_min": 27.56907021220605, "train/post_ent_std": 0.27077660511186974, "train/prior_ent_mag": 28.26295729018935, "train/prior_ent_max": 28.26295729018935, "train/prior_ent_mean": 27.599154323788742, "train/prior_ent_min": 26.648099956799992, "train/prior_ent_std": 0.28398802771640186, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.003699267216391824, "train/reward_loss_mean": 0.027601434126140634, "train/reward_loss_std": 0.3141137364240897, "train/reward_max_data": 0.8238222371393712, "train/reward_max_pred": 0.3078641022869091, "train/reward_neg_acc": 0.9993587208153615, "train/reward_neg_loss": 0.004991060611908909, "train/reward_pos_acc": 0.12239426067426576, "train/reward_pos_loss": 4.120299436039661, "train/reward_pred": 0.002881074749546397, "train/reward_rate": 0.005496231155778895, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.02047838270664215, "report/cont_loss_std": 0.23033997416496277, "report/cont_neg_acc": 0.20000000298023224, "report/cont_neg_loss": 2.8168447017669678, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.006757252849638462, "report/cont_pred": 0.992432713508606, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.0822320282459259, "report/image_loss_std": 0.10080297291278839, "report/model_loss_mean": 0.7274547219276428, "report/model_loss_std": 0.5712324976921082, "report/post_ent_mag": 28.703685760498047, "report/post_ent_max": 28.703685760498047, "report/post_ent_mean": 28.12423324584961, "report/post_ent_min": 27.599273681640625, "report/post_ent_std": 0.21879522502422333, "report/prior_ent_mag": 28.257360458374023, "report/prior_ent_max": 28.257360458374023, "report/prior_ent_mean": 27.60300064086914, "report/prior_ent_min": 26.62124252319336, "report/prior_ent_std": 0.2838496267795563, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0031646727584302425, "report/reward_loss_mean": 0.024744275957345963, "report/reward_loss_std": 0.305908739566803, "report/reward_max_data": 0.8218749761581421, "report/reward_max_pred": 0.3111649751663208, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.005197334103286266, "report/reward_pos_acc": 0.4000000059604645, "report/reward_pos_loss": 4.008410930633545, "report/reward_pred": 0.0030321762897074223, "report/reward_rate": 0.0048828125, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.03548571467399597, "eval/cont_loss_std": 0.3657841682434082, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 4.3833818435668945, "eval/cont_pos_acc": 0.9990177154541016, "eval/cont_pos_loss": 0.009859606623649597, "eval/cont_pred": 0.9928305149078369, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.12048852443695068, "eval/image_loss_std": 0.1305627077817917, "eval/model_loss_mean": 0.795229971408844, "eval/model_loss_std": 0.8451292514801025, "eval/post_ent_mag": 28.689931869506836, "eval/post_ent_max": 28.689931869506836, "eval/post_ent_mean": 28.15553092956543, "eval/post_ent_min": 27.53179168701172, "eval/post_ent_std": 0.242202028632164, "eval/prior_ent_mag": 28.26286506652832, "eval/prior_ent_max": 28.26286506652832, "eval/prior_ent_mean": 27.600011825561523, "eval/prior_ent_min": 26.453163146972656, "eval/prior_ent_std": 0.3025989532470703, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.004336548037827015, "eval/reward_loss_mean": 0.03925565630197525, "eval/reward_loss_std": 0.4383176267147064, "eval/reward_max_data": 0.893750011920929, "eval/reward_max_pred": 0.6151456832885742, "eval/reward_neg_acc": 0.9990177154541016, "eval/reward_neg_loss": 0.007655074819922447, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.400821685791016, "eval/reward_pred": 0.00304077984765172, "eval/reward_rate": 0.005859375, "replay/size": 1000000.0, "replay/inserts": 31920.0, "replay/samples": 31920.0, "replay/insert_wait_avg": 1.2986940847602405e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.396636274524201e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 6720.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.157358998344058e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1324882507324219e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1257793903351, "timer/env.step_count": 3990.0, "timer/env.step_total": 39.612857818603516, "timer/env.step_frac": 0.039607875964112284, "timer/env.step_avg": 0.009928034541003387, "timer/env.step_min": 0.007866621017456055, "timer/env.step_max": 0.049750566482543945, "timer/replay._sample_count": 31920.0, "timer/replay._sample_total": 16.92217493057251, "timer/replay._sample_frac": 0.016920046737409437, "timer/replay._sample_avg": 0.0005301433248926225, "timer/replay._sample_min": 0.0004024505615234375, "timer/replay._sample_max": 0.02502131462097168, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4830.0, "timer/agent.policy_total": 52.08147168159485, "timer/agent.policy_frac": 0.05207492172968794, "timer/agent.policy_avg": 0.010782913391634544, "timer/agent.policy_min": 0.009183406829833984, "timer/agent.policy_max": 0.08671164512634277, "timer/dataset_train_count": 1995.0, "timer/dataset_train_total": 0.23239874839782715, "timer/dataset_train_frac": 0.0002323695211011306, "timer/dataset_train_avg": 0.00011649060070066524, "timer/dataset_train_min": 9.822845458984375e-05, "timer/dataset_train_max": 0.0004298686981201172, "timer/agent.train_count": 1995.0, "timer/agent.train_total": 893.387659072876, "timer/agent.train_frac": 0.8932753034498067, "timer/agent.train_avg": 0.4478133629437975, "timer/agent.train_min": 0.4349660873413086, "timer/agent.train_max": 0.721238374710083, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.5518324375152588, "timer/agent.report_frac": 0.0005517630370968433, "timer/agent.report_avg": 0.2759162187576294, "timer/agent.report_min": 0.2729802131652832, "timer/agent.report_max": 0.2788522243499756, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9087066650390625e-05, "timer/dataset_eval_frac": 2.908340855699346e-08, "timer/dataset_eval_avg": 2.9087066650390625e-05, "timer/dataset_eval_min": 2.9087066650390625e-05, "timer/dataset_eval_max": 2.9087066650390625e-05, "fps": 31.915351159125493}
{"step": 1380208, "time": 43270.43947172165, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1380232, "time": 43270.94579792023, "episode/length": 229.0, "episode/score": 0.28437501192092896, "episode/reward_rate": 0.004347826086956522, "episode/intrinsic_return": 0.0}
{"step": 1380448, "time": 43277.73839688301, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1380504, "time": 43279.217494249344, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1380640, "time": 43283.59332489967, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1380760, "time": 43287.07368302345, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1381000, "time": 43294.3491768837, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1381048, "time": 43295.8040459156, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 1381048, "time": 43295.81232905388, "episode/length": 267.0, "episode/score": 0.16562500596046448, "episode/reward_rate": 0.0037313432835820895, "episode/intrinsic_return": 0.0}
{"step": 1381368, "time": 43305.60015654564, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1381512, "time": 43309.95354652405, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1381536, "time": 43310.89758968353, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1381600, "time": 43312.85636115074, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1381656, "time": 43314.330599308014, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1381888, "time": 43321.61355137825, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 1382128, "time": 43328.985447883606, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1382320, "time": 43334.79276609421, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1382544, "time": 43341.58758997917, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1382560, "time": 43342.07315158844, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1382640, "time": 43344.4920334816, "episode/length": 273.0, "episode/score": 0.14687499403953552, "episode/reward_rate": 0.0036496350364963502, "episode/intrinsic_return": 0.0}
{"step": 1382880, "time": 43351.77820777893, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 1383048, "time": 43356.79556298256, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1383312, "time": 43365.02728867531, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1383392, "time": 43367.455891132355, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1383552, "time": 43372.318699359894, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1383680, "time": 43376.25376582146, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1383728, "time": 43377.72714352608, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1383896, "time": 43382.660990953445, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1383920, "time": 43383.611754179, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1384064, "time": 43388.03205227852, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1384440, "time": 43399.34394145012, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1384440, "time": 43399.35761928558, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1384488, "time": 43401.32012629509, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1384536, "time": 43402.778225421906, "episode/length": 206.0, "episode/score": 0.35624998807907104, "episode/reward_rate": 0.004830917874396135, "episode/intrinsic_return": 0.0}
{"step": 1384592, "time": 43404.73153233528, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1384632, "time": 43405.725753068924, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1385096, "time": 43419.91602373123, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1385288, "time": 43425.751828193665, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1385344, "time": 43427.67991423607, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 1385368, "time": 43428.1913831234, "episode/length": 204.0, "episode/score": 0.36250001192092896, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.0}
{"step": 1385464, "time": 43431.12401366234, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1385616, "time": 43436.018827438354, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 1385800, "time": 43441.448013067245, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 1385912, "time": 43444.86870408058, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1386008, "time": 43447.87731766701, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1386504, "time": 43462.930440187454, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1386536, "time": 43463.92852258682, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1386752, "time": 43470.657140016556, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1386800, "time": 43472.13956594467, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1386856, "time": 43473.667976379395, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1387128, "time": 43482.040845155716, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 1387280, "time": 43486.869930028915, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 1387360, "time": 43489.3007440567, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1387400, "time": 43490.28698849678, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1387408, "time": 43490.754340171814, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1387416, "time": 43490.78073835373, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1387688, "time": 43499.11823773384, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 1387768, "time": 43501.534861803055, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1387824, "time": 43503.472683906555, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1388296, "time": 43517.73875904083, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1388432, "time": 43522.102444410324, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1388568, "time": 43525.9990003109, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 1388848, "time": 43534.79299449921, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1389112, "time": 43542.69090175629, "episode/length": 218.0, "episode/score": 0.3187499940395355, "episode/reward_rate": 0.0045662100456621, "episode/intrinsic_return": 0.0}
{"step": 1389120, "time": 43543.16176152229, "episode/length": 212.0, "episode/score": 0.3375000059604645, "episode/reward_rate": 0.004694835680751174, "episode/intrinsic_return": 0.0}
{"step": 1389248, "time": 43547.04437661171, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 1389248, "time": 43547.05369782448, "episode/length": 230.0, "episode/score": 0.28125, "episode/reward_rate": 0.004329004329004329, "episode/intrinsic_return": 0.0}
{"step": 1389336, "time": 43549.48949480057, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1389440, "time": 43552.918548345566, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1389880, "time": 43566.11559987068, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1389888, "time": 43566.71073579788, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1389984, "time": 43569.63087749481, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 1390064, "time": 43572.92965865135, "eval_episode/length": 44.0, "eval_episode/score": 0.862500011920929, "eval_episode/reward_rate": 0.022222222222222223}
{"step": 1390064, "time": 43573.68860435486, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 1390064, "time": 43573.71855020523, "eval_episode/length": 84.0, "eval_episode/score": 0.737500011920929, "eval_episode/reward_rate": 0.011764705882352941}
{"step": 1390064, "time": 43574.019107341766, "eval_episode/length": 99.0, "eval_episode/score": 0.690625011920929, "eval_episode/reward_rate": 0.01}
{"step": 1390064, "time": 43574.549944877625, "eval_episode/length": 126.0, "eval_episode/score": 0.606249988079071, "eval_episode/reward_rate": 0.007874015748031496}
{"step": 1390064, "time": 43574.71641635895, "eval_episode/length": 134.0, "eval_episode/score": 0.581250011920929, "eval_episode/reward_rate": 0.007407407407407408}
{"step": 1390064, "time": 43575.10444498062, "eval_episode/length": 26.0, "eval_episode/score": 0.918749988079071, "eval_episode/reward_rate": 0.037037037037037035}
{"step": 1390064, "time": 43575.21211743355, "eval_episode/length": 113.0, "eval_episode/score": 0.6468750238418579, "eval_episode/reward_rate": 0.008771929824561403}
{"step": 1390120, "time": 43576.699612140656, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 1390328, "time": 43583.05606818199, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1390600, "time": 43591.380910396576, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1390696, "time": 43594.31052398682, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1390704, "time": 43594.78191590309, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 1390952, "time": 43602.214158535004, "episode/length": 212.0, "episode/score": 0.3375000059604645, "episode/reward_rate": 0.004694835680751174, "episode/intrinsic_return": 0.0}
{"step": 1391240, "time": 43610.97707653046, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1391336, "time": 43613.919264793396, "episode/length": 277.0, "episode/score": 0.13437500596046448, "episode/reward_rate": 0.0035971223021582736, "episode/intrinsic_return": 0.0}
{"step": 1391536, "time": 43620.21845507622, "episode/length": 261.0, "episode/score": 0.18437500298023224, "episode/reward_rate": 0.003816793893129771, "episode/intrinsic_return": 0.0}
{"step": 1391584, "time": 43621.68315863609, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1391592, "time": 43621.71326446533, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1391816, "time": 43628.64551138878, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1391872, "time": 43630.5603723526, "episode/length": 235.0, "episode/score": 0.265625, "episode/reward_rate": 0.00423728813559322, "episode/intrinsic_return": 0.0}
{"step": 1392064, "time": 43636.459545612335, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1392616, "time": 43653.01689910889, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1392640, "time": 43654.137789964676, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1392792, "time": 43659.009536743164, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1392912, "time": 43662.912125110626, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1393024, "time": 43666.32923531532, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1393024, "time": 43666.33785486221, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1393048, "time": 43666.86485004425, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 1393112, "time": 43668.84679269791, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1393144, "time": 43669.81681227684, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1393264, "time": 43673.68891263008, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1393640, "time": 43684.94946265221, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1393816, "time": 43690.400961875916, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1393904, "time": 43693.32286763191, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 1393936, "time": 43694.29979252815, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1393944, "time": 43694.328607559204, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1394048, "time": 43697.74918150902, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1394432, "time": 43709.537370443344, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 1394544, "time": 43712.94387412071, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 1394552, "time": 43712.971546411514, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1394576, "time": 43713.91883683205, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1394816, "time": 43721.3105700016, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1395216, "time": 43733.51812791824, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1395264, "time": 43734.9816737175, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 1395336, "time": 43736.95855140686, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1395528, "time": 43742.78462386131, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1395528, "time": 43742.79297852516, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1395608, "time": 43745.21713805199, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1395752, "time": 43749.7698931694, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1396144, "time": 43761.926807403564, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1396176, "time": 43762.901539087296, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1396320, "time": 43767.294478178024, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1396328, "time": 43767.322607040405, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1396360, "time": 43768.291521549225, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1396408, "time": 43769.75094676018, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1396576, "time": 43775.06778001785, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1396968, "time": 43786.81489825249, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1397088, "time": 43790.68687963486, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1397424, "time": 43800.89221525192, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1397544, "time": 43804.308868169785, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1397552, "time": 43804.799211502075, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1397680, "time": 43808.76107096672, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1397840, "time": 43813.635365486145, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1397920, "time": 43816.08761835098, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1398032, "time": 43819.50396037102, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1398064, "time": 43820.47780132294, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1398072, "time": 43820.50533103943, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1398096, "time": 43821.4548060894, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 1398136, "time": 43822.453201532364, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1398352, "time": 43829.27192568779, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 1398672, "time": 43839.28768777847, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1398824, "time": 43843.66288924217, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1399552, "time": 43865.918307065964, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 1399560, "time": 43865.946199417114, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 1399616, "time": 43867.95823454857, "episode/length": 221.0, "episode/score": 0.30937498807907104, "episode/reward_rate": 0.0045045045045045045, "episode/intrinsic_return": 0.0}
{"step": 1399960, "time": 43878.24258303642, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1400048, "time": 43881.14905500412, "episode/length": 211.0, "episode/score": 0.34062498807907104, "episode/reward_rate": 0.0047169811320754715, "episode/intrinsic_return": 0.0}
{"step": 1400048, "time": 43881.6252746582, "eval_episode/length": 23.0, "eval_episode/score": 0.9281250238418579, "eval_episode/reward_rate": 0.041666666666666664}
{"step": 1400048, "time": 43882.34399604797, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 1400048, "time": 43882.462785720825, "eval_episode/length": 67.0, "eval_episode/score": 0.7906249761581421, "eval_episode/reward_rate": 0.014705882352941176}
{"step": 1400048, "time": 43882.65373110771, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 1400048, "time": 43882.91537189484, "eval_episode/length": 67.0, "eval_episode/score": 0.7906249761581421, "eval_episode/reward_rate": 0.014705882352941176}
{"step": 1400048, "time": 43883.049399375916, "eval_episode/length": 36.0, "eval_episode/score": 0.887499988079071, "eval_episode/reward_rate": 0.02702702702702703}
{"step": 1400048, "time": 43883.07491874695, "eval_episode/length": 99.0, "eval_episode/score": 0.690625011920929, "eval_episode/reward_rate": 0.01}
{"step": 1400048, "time": 43883.20218491554, "eval_episode/length": 105.0, "eval_episode/score": 0.671875, "eval_episode/reward_rate": 0.009433962264150943}
{"step": 1400368, "time": 43892.968401670456, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1400376, "time": 43892.99709510803, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1400448, "time": 43895.4180495739, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1400552, "time": 43898.45573115349, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1400560, "time": 43898.92573618889, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1400568, "time": 43898.95346689224, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1400688, "time": 43902.82990384102, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 1400840, "time": 43907.46703481674, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1400984, "time": 43912.08235311508, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1401144, "time": 43916.94684553146, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1401240, "time": 43919.86059975624, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1401344, "time": 43923.22792363167, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1401488, "time": 43927.751316547394, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1401568, "time": 43930.19021821022, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1401624, "time": 43931.6654150486, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1401736, "time": 43935.06063699722, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1401848, "time": 43938.448666095734, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1402080, "time": 43945.6926317215, "episode/length": 189.0, "episode/score": 0.40937501192092896, "episode/reward_rate": 0.005263157894736842, "episode/intrinsic_return": 0.0}
{"step": 1402088, "time": 43945.72015285492, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1402144, "time": 43947.63460946083, "episode/length": 220.0, "episode/score": 0.3125, "episode/reward_rate": 0.004524886877828055, "episode/intrinsic_return": 0.0}
{"step": 1402288, "time": 43952.026039123535, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1402584, "time": 43960.928364515305, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1402936, "time": 43971.64717721939, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 1403024, "time": 43974.580181121826, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1403464, "time": 43987.89289212227, "episode/length": 201.0, "episode/score": 0.37187498807907104, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.0}
{"step": 1403624, "time": 43992.769747018814, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1403800, "time": 43998.21362495422, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1404048, "time": 44005.99131846428, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1404296, "time": 44013.32023048401, "episode/length": 250.0, "episode/score": 0.21875, "episode/reward_rate": 0.00398406374501992, "episode/intrinsic_return": 0.0}
{"step": 1404392, "time": 44016.24136900902, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1404400, "time": 44016.816844940186, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1404520, "time": 44020.25409221649, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1404560, "time": 44021.69500160217, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1404752, "time": 44027.514659404755, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1404936, "time": 44032.88358068466, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1404936, "time": 44032.89786982536, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1405032, "time": 44035.82712101936, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1405088, "time": 44037.77699494362, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1405160, "time": 44039.75368523598, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1405312, "time": 44044.61553478241, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1405336, "time": 44045.12765836716, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1405504, "time": 44050.568950653076, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1405624, "time": 44054.011528491974, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 1405784, "time": 44058.884554862976, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1405944, "time": 44063.75472664833, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1406000, "time": 44065.68454384804, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1406048, "time": 44067.165620326996, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1406056, "time": 44067.19353604317, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1406096, "time": 44068.622648239136, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1406232, "time": 44072.51948571205, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 1406568, "time": 44082.856985569, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1406936, "time": 44094.07380390167, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1406952, "time": 44094.572474479675, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 1407040, "time": 44097.52632308006, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 1407128, "time": 44100.02055764198, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1407168, "time": 44101.50839161873, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1407208, "time": 44102.522401571274, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 1407272, "time": 44104.46220612526, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1407368, "time": 44107.48601055145, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 1407440, "time": 44109.88516712189, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 1407528, "time": 44112.3626306057, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1407632, "time": 44115.77436232567, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 1407648, "time": 44116.265384197235, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1407696, "time": 44117.7255795002, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1407840, "time": 44122.09486365318, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1408056, "time": 44128.445197343826, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1408296, "time": 44135.70051956177, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 1408984, "time": 44156.75851941109, "episode/length": 213.0, "episode/score": 0.3343749940395355, "episode/reward_rate": 0.004672897196261682, "episode/intrinsic_return": 0.0}
{"step": 1409000, "time": 44157.25361537933, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 1409864, "time": 44184.23632764816, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1409944, "time": 44186.68325972557, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1409960, "time": 44187.172359228134, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1410008, "time": 44188.63114309311, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1410032, "time": 44190.50032162666, "eval_episode/length": 48.0, "eval_episode/score": 0.8500000238418579, "eval_episode/reward_rate": 0.02040816326530612}
{"step": 1410032, "time": 44191.36850619316, "eval_episode/length": 95.0, "eval_episode/score": 0.703125, "eval_episode/reward_rate": 0.010416666666666666}
{"step": 1410032, "time": 44191.45027136803, "eval_episode/length": 99.0, "eval_episode/score": 0.690625011920929, "eval_episode/reward_rate": 0.01}
{"step": 1410032, "time": 44191.8182156086, "eval_episode/length": 118.0, "eval_episode/score": 0.6312500238418579, "eval_episode/reward_rate": 0.008403361344537815}
{"step": 1410032, "time": 44191.902842998505, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 1410032, "time": 44192.06402182579, "eval_episode/length": 130.0, "eval_episode/score": 0.59375, "eval_episode/reward_rate": 0.007633587786259542}
{"step": 1410032, "time": 44192.704446554184, "eval_episode/length": 164.0, "eval_episode/score": 0.48750001192092896, "eval_episode/reward_rate": 0.006060606060606061}
{"step": 1410032, "time": 44193.06435966492, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 1410152, "time": 44196.53281354904, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1410304, "time": 44201.446637392044, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 1410368, "time": 44203.409445762634, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1410544, "time": 44208.78952383995, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1410608, "time": 44210.7322204113, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1410784, "time": 44216.09102296829, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1410792, "time": 44216.11845397949, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1410896, "time": 44219.51350021362, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1411192, "time": 44228.444888830185, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1411280, "time": 44231.339572906494, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1411344, "time": 44233.30496954918, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1411416, "time": 44235.27623486519, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1411712, "time": 44244.52423906326, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1412136, "time": 44257.452949762344, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 1412176, "time": 44258.907314777374, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1412296, "time": 44262.344984292984, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1412320, "time": 44263.308598041534, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1412344, "time": 44263.823749542236, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1412409, "time": 44266.96723866463, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.5315763265779703, "train/action_min": 0.0, "train/action_std": 1.8515335126678543, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.010008380012955554, "train/actor_opt_grad_steps": 87165.0, "train/actor_opt_loss": -23.997418467361147, "train/adv_mag": 0.6538485843356293, "train/adv_max": 0.2963976252197039, "train/adv_mean": 0.0012686921464673203, "train/adv_min": -0.5713327296889654, "train/adv_std": 0.028021286163331553, "train/cont_avg": 0.9932075727103961, "train/cont_loss_mean": 0.030192221542543703, "train/cont_loss_std": 0.31045006355731797, "train/cont_neg_acc": 0.09646500517973805, "train/cont_neg_loss": 3.5004329575170385, "train/cont_pos_acc": 0.9999027001385642, "train/cont_pos_loss": 0.00631119179571656, "train/cont_pred": 0.9931393401457531, "train/cont_rate": 0.9932075727103961, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.16551859437091515, "train/extr_critic_critic_opt_grad_steps": 87165.0, "train/extr_critic_critic_opt_loss": 4210.283351784886, "train/extr_critic_mag": 1.6956271747551341, "train/extr_critic_max": 1.6956271747551341, "train/extr_critic_mean": 1.5786521517404235, "train/extr_critic_min": 1.2778782449146309, "train/extr_critic_std": 0.02644161671160324, "train/extr_return_normed_mag": 0.6875106291015549, "train/extr_return_normed_max": 0.2945944655059588, "train/extr_return_normed_mean": 0.055497384537933486, "train/extr_return_normed_min": -0.548291013382449, "train/extr_return_normed_std": 0.040188167668362654, "train/extr_return_rate": 0.9997096285961642, "train/extr_return_raw_mag": 1.8190178664604035, "train/extr_return_raw_max": 1.8190178664604035, "train/extr_return_raw_mean": 1.5799208637511377, "train/extr_return_raw_min": 0.9761323875719958, "train/extr_return_raw_std": 0.040188167391732185, "train/extr_reward_mag": 0.2722101902017499, "train/extr_reward_max": 0.2722101902017499, "train/extr_reward_mean": 0.0030978835697313494, "train/extr_reward_min": 8.144000969310799e-08, "train/extr_reward_std": 0.010156848958905527, "train/image_loss_mean": 0.09158292088178124, "train/image_loss_std": 0.10504823030516652, "train/model_loss_mean": 0.7481822262306025, "train/model_loss_std": 0.6109999797795669, "train/model_opt_grad_norm": 14.705699733240687, "train/model_opt_grad_steps": 87085.83663366336, "train/model_opt_loss": 4481.609244469369, "train/model_opt_model_opt_grad_overflow": 0.0049504950495049506, "train/model_opt_model_opt_grad_scale": 5965.346534653465, "train/policy_entropy_mag": 1.1846829537707981, "train/policy_entropy_max": 1.1846829537707981, "train/policy_entropy_mean": 0.0842883523074117, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.09395646654290728, "train/policy_logprob_mag": 6.551080281191533, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.08410264820893212, "train/policy_logprob_min": -6.551080281191533, "train/policy_logprob_std": 0.620964513556792, "train/policy_randomness_mag": 0.6088066418277155, "train/policy_randomness_max": 0.6088066418277155, "train/policy_randomness_mean": 0.043315648885056526, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.048284075471876874, "train/post_ent_mag": 29.167404127593088, "train/post_ent_max": 29.167404127593088, "train/post_ent_mean": 28.358468508956456, "train/post_ent_min": 27.584054861918535, "train/post_ent_std": 0.32463696289180527, "train/prior_ent_mag": 28.264044497272756, "train/prior_ent_max": 28.264044497272756, "train/prior_ent_mean": 27.598806919437823, "train/prior_ent_min": 26.662073040952777, "train/prior_ent_std": 0.2821077121661441, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.003479321169122906, "train/reward_loss_mean": 0.026407061827064742, "train/reward_loss_std": 0.3051327238191325, "train/reward_max_data": 0.8164603975739809, "train/reward_max_pred": 0.2906748121327693, "train/reward_neg_acc": 0.9994605676372452, "train/reward_neg_loss": 0.004957691415923067, "train/reward_pos_acc": 0.11938521899838946, "train/reward_pos_loss": 4.163434744177766, "train/reward_pred": 0.002803034249965175, "train/reward_rate": 0.005143873762376238, "train_stats/mean_log_entropy": 0.07872460258109375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.021892335265874863, "report/cont_loss_std": 0.21370598673820496, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 3.0286545753479004, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.007138839922845364, "report/cont_pred": 0.9927910566329956, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.07312887907028198, "report/image_loss_std": 0.09387404471635818, "report/model_loss_mean": 0.7167969942092896, "report/model_loss_std": 0.4913061559200287, "report/post_ent_mag": 28.947227478027344, "report/post_ent_max": 28.947227478027344, "report/post_ent_mean": 28.211963653564453, "report/post_ent_min": 27.487598419189453, "report/post_ent_std": 0.311058908700943, "report/prior_ent_mag": 28.263229370117188, "report/prior_ent_max": 28.263229370117188, "report/prior_ent_mean": 27.567750930786133, "report/prior_ent_min": 26.588045120239258, "report/prior_ent_std": 0.29627054929733276, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0027191161643713713, "report/reward_loss_mean": 0.021775756031274796, "report/reward_loss_std": 0.25693896412849426, "report/reward_max_data": 0.765625, "report/reward_max_pred": 0.11700558662414551, "report/reward_neg_acc": 0.9990195631980896, "report/reward_neg_loss": 0.005821481347084045, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.090115547180176, "report/reward_pred": 0.0030201775953173637, "report/reward_rate": 0.00390625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.018543429672718048, "eval/cont_loss_std": 0.19073596596717834, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 3.0526089668273926, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.0066451323218643665, "eval/cont_pred": 0.9933298826217651, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.11745714396238327, "eval/image_loss_std": 0.1192285418510437, "eval/model_loss_mean": 0.7561615705490112, "eval/model_loss_std": 0.4647778868675232, "eval/post_ent_mag": 28.977054595947266, "eval/post_ent_max": 28.977054595947266, "eval/post_ent_mean": 28.274253845214844, "eval/post_ent_min": 27.471721649169922, "eval/post_ent_std": 0.30226418375968933, "eval/prior_ent_mag": 28.269433975219727, "eval/prior_ent_max": 28.269433975219727, "eval/prior_ent_mean": 27.58465003967285, "eval/prior_ent_min": 26.642791748046875, "eval/prior_ent_std": 0.28404825925827026, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0026214600075036287, "eval/reward_loss_mean": 0.02016095258295536, "eval/reward_loss_std": 0.2398073822259903, "eval/reward_max_data": 0.7562500238418579, "eval/reward_max_pred": 0.12381494045257568, "eval/reward_neg_acc": 0.9990195631980896, "eval/reward_neg_loss": 0.005189647898077965, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 3.8378429412841797, "eval/reward_pred": 0.002804637886583805, "eval/reward_rate": 0.00390625, "replay/size": 1000000.0, "replay/inserts": 32320.0, "replay/samples": 32320.0, "replay/insert_wait_avg": 1.2850923703448606e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.39776331835454e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3584.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.187369759593691e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.043081283569336e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0286448001862, "timer/env.step_count": 4040.0, "timer/env.step_total": 39.69547414779663, "timer/env.step_frac": 0.039694337111441554, "timer/env.step_avg": 0.009825612412820948, "timer/env.step_min": 0.007897138595581055, "timer/env.step_max": 0.049712419509887695, "timer/replay._sample_count": 32320.0, "timer/replay._sample_total": 17.110971927642822, "timer/replay._sample_frac": 0.017110481801310536, "timer/replay._sample_avg": 0.0005294236363750873, "timer/replay._sample_min": 0.00040078163146972656, "timer/replay._sample_max": 0.030318021774291992, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4488.0, "timer/agent.policy_total": 47.97200345993042, "timer/agent.policy_frac": 0.04797062935083786, "timer/agent.policy_avg": 0.010688949077524603, "timer/agent.policy_min": 0.009199142456054688, "timer/agent.policy_max": 0.07988524436950684, "timer/dataset_train_count": 2020.0, "timer/dataset_train_total": 0.2273881435394287, "timer/dataset_train_frac": 0.00022738163023806453, "timer/dataset_train_avg": 0.00011256838789080629, "timer/dataset_train_min": 9.846687316894531e-05, "timer/dataset_train_max": 0.0010616779327392578, "timer/agent.train_count": 2020.0, "timer/agent.train_total": 901.630199432373, "timer/agent.train_frac": 0.9016043731552571, "timer/agent.train_avg": 0.4463515838774124, "timer/agent.train_min": 0.43335628509521484, "timer/agent.train_max": 0.6710929870605469, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4755387306213379, "timer/agent.report_frac": 0.0004755251092995985, "timer/agent.report_avg": 0.23776936531066895, "timer/agent.report_min": 0.23081374168395996, "timer/agent.report_max": 0.24472498893737793, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.838539123535156e-05, "timer/dataset_eval_frac": 3.8384291724984815e-08, "timer/dataset_eval_avg": 3.838539123535156e-05, "timer/dataset_eval_min": 3.838539123535156e-05, "timer/dataset_eval_max": 3.838539123535156e-05, "fps": 32.318426914032685}
{"step": 1412696, "time": 44275.57493567467, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1412760, "time": 44277.51153254509, "episode/length": 195.0, "episode/score": 0.390625, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.0}
{"step": 1412904, "time": 44281.838124513626, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1412944, "time": 44283.290408849716, "episode/length": 199.0, "episode/score": 0.37812501192092896, "episode/reward_rate": 0.005, "episode/intrinsic_return": 0.0}
{"step": 1413000, "time": 44284.771775484085, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1413208, "time": 44291.26301240921, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1413456, "time": 44299.12088418007, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1413504, "time": 44300.58377814293, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1413536, "time": 44301.559884786606, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1413792, "time": 44309.44539761543, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 1414024, "time": 44316.34402036667, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1414072, "time": 44317.94380784035, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1414080, "time": 44318.41395306587, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1414448, "time": 44329.66662931442, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1414560, "time": 44333.08696293831, "episode/length": 201.0, "episode/score": 0.37187498807907104, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.0}
{"step": 1414584, "time": 44333.601595163345, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1414928, "time": 44344.29370188713, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1415008, "time": 44346.85288357735, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1415312, "time": 44356.18076086044, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1415344, "time": 44357.15783715248, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1415416, "time": 44359.12237739563, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 1415520, "time": 44362.51678419113, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1415840, "time": 44372.241406440735, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 1415952, "time": 44375.690722703934, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1416064, "time": 44379.26074004173, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1416136, "time": 44381.27755641937, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1416200, "time": 44383.22769284248, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1416392, "time": 44389.080260276794, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1416448, "time": 44391.033779382706, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1416640, "time": 44396.88902115822, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1416736, "time": 44399.809003829956, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 1416832, "time": 44402.74567103386, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1416896, "time": 44404.690665245056, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1417016, "time": 44408.283441782, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1417320, "time": 44418.029239177704, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1417384, "time": 44419.97895884514, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1417448, "time": 44421.975970983505, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1417496, "time": 44423.43964385986, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1418080, "time": 44441.47243261337, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1418152, "time": 44443.422169685364, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1418344, "time": 44449.268626213074, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1418352, "time": 44449.75386977196, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 1418352, "time": 44449.76190471649, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1418496, "time": 44454.15298700333, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 1418512, "time": 44454.67544221878, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1418600, "time": 44457.15260767937, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 1418896, "time": 44466.44158554077, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1418928, "time": 44467.518513679504, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1418952, "time": 44468.04394865036, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1419208, "time": 44475.854377985, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1419288, "time": 44478.29292631149, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1419336, "time": 44479.77695918083, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1419584, "time": 44487.526471138, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1419728, "time": 44491.88877367973, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1420016, "time": 44501.463832855225, "eval_episode/length": 32.0, "eval_episode/score": 0.8999999761581421, "eval_episode/reward_rate": 0.030303030303030304}
{"step": 1420016, "time": 44502.492146253586, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 1420016, "time": 44502.577320575714, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 1420016, "time": 44502.79782438278, "eval_episode/length": 97.0, "eval_episode/score": 0.6968749761581421, "eval_episode/reward_rate": 0.01020408163265306}
{"step": 1420016, "time": 44502.993379592896, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 1420016, "time": 44503.642855644226, "eval_episode/length": 54.0, "eval_episode/score": 0.831250011920929, "eval_episode/reward_rate": 0.01818181818181818}
{"step": 1420016, "time": 44503.84790468216, "eval_episode/length": 151.0, "eval_episode/score": 0.528124988079071, "eval_episode/reward_rate": 0.006578947368421052}
{"step": 1420016, "time": 44504.74359822273, "eval_episode/length": 44.0, "eval_episode/score": 0.862500011920929, "eval_episode/reward_rate": 0.022222222222222223}
{"step": 1420392, "time": 44515.97447729111, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1420608, "time": 44522.83213400841, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 1420760, "time": 44527.37351799011, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 1421208, "time": 44540.983640909195, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1421240, "time": 44541.98973798752, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1421240, "time": 44541.9988617897, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1421264, "time": 44542.962695121765, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1421600, "time": 44553.19497156143, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1421640, "time": 44554.19660568237, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1421648, "time": 44554.67057657242, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1421832, "time": 44560.23176217079, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1421912, "time": 44562.68526005745, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1422040, "time": 44566.60486602783, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1422168, "time": 44570.502066612244, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1422168, "time": 44570.5088968277, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1422536, "time": 44581.74809765816, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1422568, "time": 44582.722866773605, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1422968, "time": 44595.038140535355, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1423056, "time": 44597.98026108742, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 1423464, "time": 44610.20307588577, "episode/length": 226.0, "episode/score": 0.29374998807907104, "episode/reward_rate": 0.004405286343612335, "episode/intrinsic_return": 0.0}
{"step": 1423552, "time": 44613.12375020981, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1423648, "time": 44616.093750715256, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1423824, "time": 44621.58843779564, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1423912, "time": 44624.05042743683, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1424120, "time": 44630.40570425987, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1424480, "time": 44641.58518409729, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1424480, "time": 44641.596074581146, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1424952, "time": 44655.840212106705, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 1425368, "time": 44668.5172290802, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1425424, "time": 44670.939997434616, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1425536, "time": 44674.33011126518, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 1425864, "time": 44684.19805312157, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1425880, "time": 44684.7113404274, "episode/length": 245.0, "episode/score": 0.234375, "episode/reward_rate": 0.0040650406504065045, "episode/intrinsic_return": 0.0}
{"step": 1426136, "time": 44692.5088763237, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1426264, "time": 44696.476756095886, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1426368, "time": 44699.90939426422, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1426536, "time": 44704.84593772888, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1426552, "time": 44705.339490652084, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1426640, "time": 44708.33783149719, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1426792, "time": 44712.743188619614, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1426920, "time": 44716.67648386955, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1427232, "time": 44726.407192230225, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1427264, "time": 44727.392458200455, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1427384, "time": 44730.834607601166, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1427384, "time": 44730.845036029816, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1427552, "time": 44736.2233774662, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1427592, "time": 44737.327347278595, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1427912, "time": 44747.08498096466, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1428256, "time": 44757.82112121582, "episode/length": 264.0, "episode/score": 0.17499999701976776, "episode/reward_rate": 0.0037735849056603774, "episode/intrinsic_return": 0.0}
{"step": 1428352, "time": 44760.75227832794, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1428368, "time": 44761.25103878975, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1428392, "time": 44761.76878595352, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1428544, "time": 44766.795451402664, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 1428576, "time": 44767.77688717842, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1428824, "time": 44775.14474225044, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1428952, "time": 44779.04645228386, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1429072, "time": 44782.94647812843, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1429080, "time": 44782.97400403023, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1429152, "time": 44785.37646770477, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1429424, "time": 44793.67636489868, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1429432, "time": 44793.70463848114, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1429808, "time": 44805.48620200157, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1430000, "time": 44812.29785013199, "eval_episode/length": 52.0, "eval_episode/score": 0.8374999761581421, "eval_episode/reward_rate": 0.018867924528301886}
{"step": 1430000, "time": 44812.54143476486, "eval_episode/length": 65.0, "eval_episode/score": 0.796875, "eval_episode/reward_rate": 0.015151515151515152}
{"step": 1430000, "time": 44812.6840031147, "eval_episode/length": 72.0, "eval_episode/score": 0.7749999761581421, "eval_episode/reward_rate": 0.0136986301369863}
{"step": 1430000, "time": 44813.30671000481, "eval_episode/length": 105.0, "eval_episode/score": 0.671875, "eval_episode/reward_rate": 0.009433962264150943}
{"step": 1430000, "time": 44813.316217422485, "eval_episode/length": 105.0, "eval_episode/score": 0.671875, "eval_episode/reward_rate": 0.009433962264150943}
{"step": 1430000, "time": 44813.51021909714, "eval_episode/length": 115.0, "eval_episode/score": 0.640625, "eval_episode/reward_rate": 0.008620689655172414}
{"step": 1430000, "time": 44813.70464324951, "eval_episode/length": 72.0, "eval_episode/score": 0.7749999761581421, "eval_episode/reward_rate": 0.0136986301369863}
{"step": 1430000, "time": 44813.90249657631, "eval_episode/length": 135.0, "eval_episode/score": 0.578125, "eval_episode/reward_rate": 0.007352941176470588}
{"step": 1430096, "time": 44816.82893753052, "episode/length": 189.0, "episode/score": 0.40937501192092896, "episode/reward_rate": 0.005263157894736842, "episode/intrinsic_return": 0.0}
{"step": 1430104, "time": 44816.85612297058, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 1430128, "time": 44817.803250551224, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1430168, "time": 44818.79094696045, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1430208, "time": 44820.23738503456, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1430384, "time": 44825.56080746651, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 1430472, "time": 44828.08629107475, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1430704, "time": 44835.388577222824, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1431224, "time": 44851.027451753616, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1431384, "time": 44855.890323638916, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1431440, "time": 44857.914284944534, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1431464, "time": 44858.43087673187, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1431816, "time": 44869.1405813694, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1431832, "time": 44869.63007688522, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 1432248, "time": 44882.271248817444, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1432280, "time": 44883.26333618164, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1432304, "time": 44884.21581888199, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1432320, "time": 44884.7040309906, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1432480, "time": 44889.719975709915, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1432520, "time": 44890.71259188652, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1432696, "time": 44896.08800959587, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1432784, "time": 44899.0191757679, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 1432864, "time": 44901.44113564491, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1432912, "time": 44902.91286897659, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1432952, "time": 44903.90858530998, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1433000, "time": 44905.363662958145, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1433384, "time": 44917.10473227501, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1433656, "time": 44925.86640739441, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1433832, "time": 44931.21357297897, "episode/length": 197.0, "episode/score": 0.3843750059604645, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.0}
{"step": 1433912, "time": 44933.656895160675, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1434048, "time": 44938.0162756443, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1434072, "time": 44938.526678562164, "episode/length": 19.0, "episode/score": 0.940625011920929, "episode/reward_rate": 0.05, "episode/intrinsic_return": 0.0}
{"step": 1434256, "time": 44944.32716846466, "episode/length": 216.0, "episode/score": 0.32499998807907104, "episode/reward_rate": 0.004608294930875576, "episode/intrinsic_return": 0.0}
{"step": 1434520, "time": 44952.28679871559, "episode/length": 189.0, "episode/score": 0.40937501192092896, "episode/reward_rate": 0.005263157894736842, "episode/intrinsic_return": 0.0}
{"step": 1434688, "time": 44957.62464261055, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1434784, "time": 44960.53025317192, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1434840, "time": 44962.02777862549, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1435096, "time": 44969.806185245514, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1435176, "time": 44972.24882507324, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1435208, "time": 44973.22373223305, "episode/length": 13.0, "episode/score": 0.9593750238418579, "episode/reward_rate": 0.07142857142857142, "episode/intrinsic_return": 0.0}
{"step": 1435472, "time": 44981.59338116646, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1435792, "time": 44991.31835603714, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 1435904, "time": 44994.72091841698, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1435968, "time": 44996.67795610428, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1436120, "time": 45001.071503162384, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 1436232, "time": 45004.46697759628, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 1436568, "time": 45014.81238436699, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1436608, "time": 45016.27395105362, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1436656, "time": 45017.72957253456, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1437304, "time": 45037.32863378525, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1437480, "time": 45042.68197274208, "episode/length": 287.0, "episode/score": 0.10312499850988388, "episode/reward_rate": 0.003472222222222222, "episode/intrinsic_return": 0.0}
{"step": 1437568, "time": 45045.578520298004, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 1437736, "time": 45050.47355389595, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 1437784, "time": 45051.92739844322, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1438248, "time": 45065.98566842079, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1438280, "time": 45067.06701016426, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1438400, "time": 45070.9732735157, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1438496, "time": 45073.88698911667, "episode/length": 282.0, "episode/score": 0.11874999850988388, "episode/reward_rate": 0.0035335689045936395, "episode/intrinsic_return": 0.0}
{"step": 1438568, "time": 45075.881048202515, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 1438584, "time": 45076.37467503548, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1438792, "time": 45082.70913529396, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 1438880, "time": 45085.62597036362, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1438888, "time": 45085.652505636215, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 1439064, "time": 45090.990092754364, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1439400, "time": 45101.30411505699, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1439400, "time": 45101.30972480774, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 1439432, "time": 45102.284284353256, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1440048, "time": 45121.275733709335, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1440088, "time": 45122.986085653305, "eval_episode/length": 36.0, "eval_episode/score": 0.887499988079071, "eval_episode/reward_rate": 0.02702702702702703}
{"step": 1440088, "time": 45124.12483239174, "eval_episode/length": 26.0, "eval_episode/score": 0.918749988079071, "eval_episode/reward_rate": 0.037037037037037035}
{"step": 1440088, "time": 45124.45864582062, "eval_episode/length": 81.0, "eval_episode/score": 0.746874988079071, "eval_episode/reward_rate": 0.012195121951219513}
{"step": 1440088, "time": 45124.84230852127, "eval_episode/length": 100.0, "eval_episode/score": 0.6875, "eval_episode/reward_rate": 0.009900990099009901}
{"step": 1440088, "time": 45125.364085674286, "eval_episode/length": 126.0, "eval_episode/score": 0.606249988079071, "eval_episode/reward_rate": 0.007874015748031496}
{"step": 1440088, "time": 45125.563255786896, "eval_episode/length": 136.0, "eval_episode/score": 0.574999988079071, "eval_episode/reward_rate": 0.0072992700729927005}
{"step": 1440088, "time": 45125.93113279343, "eval_episode/length": 90.0, "eval_episode/score": 0.71875, "eval_episode/reward_rate": 0.01098901098901099}
{"step": 1440088, "time": 45126.33055615425, "eval_episode/length": 174.0, "eval_episode/score": 0.45625001192092896, "eval_episode/reward_rate": 0.005714285714285714}
{"step": 1440224, "time": 45130.76770687103, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1440408, "time": 45136.14048790932, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1440504, "time": 45139.07470870018, "episode/length": 250.0, "episode/score": 0.21875, "episode/reward_rate": 0.00398406374501992, "episode/intrinsic_return": 0.0}
{"step": 1440560, "time": 45141.021099328995, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1440712, "time": 45145.41940307617, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1440784, "time": 45147.82825112343, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1440864, "time": 45150.249688625336, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 1441016, "time": 45154.628403663635, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 1441104, "time": 45157.6376452446, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1441104, "time": 45157.64573407173, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1441240, "time": 45161.58131194115, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1441376, "time": 45165.92968773842, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1441592, "time": 45172.26716327667, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1441712, "time": 45176.16458129883, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1441800, "time": 45178.80709838867, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1441840, "time": 45180.54493021965, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1441872, "time": 45181.53299355507, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1442328, "time": 45195.34737634659, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1442664, "time": 45205.59732627869, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1442928, "time": 45213.915053367615, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 1443072, "time": 45218.3854932785, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 1443096, "time": 45218.89481878281, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1443416, "time": 45228.663348674774, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1443656, "time": 45235.94346475601, "episode/length": 284.0, "episode/score": 0.11249999701976776, "episode/reward_rate": 0.0035087719298245615, "episode/intrinsic_return": 0.0}
{"step": 1443784, "time": 45239.814049720764, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1443816, "time": 45240.802129268646, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1443992, "time": 45246.144079208374, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 1444184, "time": 45252.13226604462, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1444600, "time": 45264.83150219917, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1444624, "time": 45265.78374195099, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 1444633, "time": 45266.85018515587, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.5741281037283414, "train/action_min": 0.0, "train/action_std": 1.7776197897325647, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.009217986325263092, "train/actor_opt_grad_steps": 89185.0, "train/actor_opt_loss": -26.124822630740628, "train/adv_mag": 0.7244930869281883, "train/adv_max": 0.2801494090863974, "train/adv_mean": 0.000310278930492762, "train/adv_min": -0.6711010862104964, "train/adv_std": 0.028871434302723938, "train/cont_avg": 0.9929706837871287, "train/cont_loss_mean": 0.030819524849516035, "train/cont_loss_std": 0.3115583066229183, "train/cont_neg_acc": 0.07877156020391106, "train/cont_neg_loss": 3.464298188686371, "train/cont_pos_acc": 0.9998491530371184, "train/cont_pos_loss": 0.00649591788677222, "train/cont_pred": 0.9930123819573091, "train/cont_rate": 0.9929706837871287, "train/dyn_loss_mean": 1.0000001357333494, "train/dyn_loss_std": 4.3493824651335725e-06, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.16320021421012312, "train/extr_critic_critic_opt_grad_steps": 89185.0, "train/extr_critic_critic_opt_loss": 5464.597313002785, "train/extr_critic_mag": 1.7334364156911868, "train/extr_critic_max": 1.7334364156911868, "train/extr_critic_mean": 1.6012195112681624, "train/extr_critic_min": 1.367133613270108, "train/extr_critic_std": 0.027046859587109326, "train/extr_return_normed_mag": 0.7440223103702659, "train/extr_return_normed_max": 0.2880269743428372, "train/extr_return_normed_mean": 0.05658687807914644, "train/extr_return_normed_min": -0.627590540021953, "train/extr_return_normed_std": 0.04065148501039142, "train/extr_return_rate": 0.9997454079070894, "train/extr_return_raw_mag": 1.8329698307679432, "train/extr_return_raw_max": 1.8329698307679432, "train/extr_return_raw_mean": 1.601529824851763, "train/extr_return_raw_min": 0.917352316403153, "train/extr_return_raw_std": 0.04065148497350735, "train/extr_reward_mag": 0.25199005509367084, "train/extr_reward_max": 0.25199005509367084, "train/extr_reward_mean": 0.0028553144196002272, "train/extr_reward_min": 9.855421462861618e-08, "train/extr_reward_std": 0.009356417656313665, "train/image_loss_mean": 0.09242225429135384, "train/image_loss_std": 0.10449015094649673, "train/model_loss_mean": 0.751212607220848, "train/model_loss_std": 0.6257313562206702, "train/model_opt_grad_norm": 14.567679808871581, "train/model_opt_grad_steps": 89104.02970297029, "train/model_opt_loss": 3962.68611855082, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5272.277227722772, "train/policy_entropy_mag": 1.2083818328262557, "train/policy_entropy_max": 1.2083818328262557, "train/policy_entropy_mean": 0.08568033952229094, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.09809956854522818, "train/policy_logprob_mag": 6.551080269388633, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.08553687641673749, "train/policy_logprob_min": -6.551080269388633, "train/policy_logprob_std": 0.6224933771213682, "train/policy_randomness_mag": 0.6209854575076906, "train/policy_randomness_max": 0.6209854575076906, "train/policy_randomness_mean": 0.044030989197516204, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.0504132086724633, "train/post_ent_mag": 29.03378644320044, "train/post_ent_max": 29.03378644320044, "train/post_ent_mean": 28.25031623273793, "train/post_ent_min": 27.454354626117368, "train/post_ent_std": 0.32159546283212037, "train/prior_ent_mag": 28.304709283432157, "train/prior_ent_max": 28.304709283432157, "train/prior_ent_mean": 27.63940669522427, "train/prior_ent_min": 26.697633261727816, "train/prior_ent_std": 0.2823640443015807, "train/rep_loss_mean": 1.0000001357333494, "train/rep_loss_std": 4.3493824651335725e-06, "train/reward_avg": 0.0037287646382447737, "train/reward_loss_mean": 0.027970724610040094, "train/reward_loss_std": 0.31630077604019996, "train/reward_max_data": 0.826562501416348, "train/reward_max_pred": 0.29317540933590125, "train/reward_neg_acc": 0.9994265071236261, "train/reward_neg_loss": 0.00512134599831361, "train/reward_pos_acc": 0.11593713187197648, "train/reward_pos_loss": 4.147646214702342, "train/reward_pred": 0.002914368263722425, "train/reward_rate": 0.005535465655940594, "train_stats/mean_log_entropy": 0.07993815106418088, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 0.029059603810310364, "report/cont_loss_std": 0.30462566018104553, "report/cont_neg_acc": 0.25, "report/cont_neg_loss": 2.8614325523376465, "report/cont_pos_acc": 0.999015748500824, "report/cont_pos_loss": 0.006757454480975866, "report/cont_pred": 0.9919766187667847, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.09527750313282013, "report/image_loss_std": 0.10756079852581024, "report/model_loss_mean": 0.747348427772522, "report/model_loss_std": 0.5731365084648132, "report/post_ent_mag": 28.714174270629883, "report/post_ent_max": 28.714174270629883, "report/post_ent_mean": 27.917236328125, "report/post_ent_min": 27.077157974243164, "report/post_ent_std": 0.3617091774940491, "report/prior_ent_mag": 30.31739044189453, "report/prior_ent_max": 30.31739044189453, "report/prior_ent_mean": 27.668426513671875, "report/prior_ent_min": 26.75566291809082, "report/prior_ent_std": 0.31716427206993103, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0040954588912427425, "report/reward_loss_mean": 0.023011349141597748, "report/reward_loss_std": 0.2719864845275879, "report/reward_max_data": 0.859375, "report/reward_max_pred": 0.5907876491546631, "report/reward_neg_acc": 0.9980353713035583, "report/reward_neg_loss": 0.00533671397715807, "report/reward_pos_acc": 0.3333333432674408, "report/reward_pos_loss": 3.02180814743042, "report/reward_pred": 0.0037074254360049963, "report/reward_rate": 0.005859375, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.038949575275182724, "eval/cont_loss_std": 0.4785727262496948, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.549379348754883, "eval/cont_pos_acc": 0.9990177154541016, "eval/cont_pos_loss": 0.0064716036431491375, "eval/cont_pred": 0.9940330386161804, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.09950842708349228, "eval/image_loss_std": 0.09745500236749649, "eval/model_loss_mean": 0.7802265286445618, "eval/model_loss_std": 1.0478405952453613, "eval/post_ent_mag": 28.712444305419922, "eval/post_ent_max": 28.712444305419922, "eval/post_ent_mean": 27.925827026367188, "eval/post_ent_min": 27.137142181396484, "eval/post_ent_std": 0.34576553106307983, "eval/prior_ent_mag": 28.386621475219727, "eval/prior_ent_max": 28.386621475219727, "eval/prior_ent_mean": 27.686439514160156, "eval/prior_ent_min": 26.691640853881836, "eval/prior_ent_std": 0.3092121481895447, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.003997802734375, "eval/reward_loss_mean": 0.04176852107048035, "eval/reward_loss_std": 0.542713463306427, "eval/reward_max_data": 0.793749988079071, "eval/reward_max_pred": 0.04358065128326416, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.004457446746528149, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 6.372214317321777, "eval/reward_pred": 0.002342106541618705, "eval/reward_rate": 0.005859375, "replay/size": 1000000.0, "replay/inserts": 32224.0, "replay/samples": 32224.0, "replay/insert_wait_avg": 1.280952352279466e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.370841981874559e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4064.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1570693001033752e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.087784767150879e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 999.9841103553772, "timer/env.step_count": 4028.0, "timer/env.step_total": 39.49208211898804, "timer/env.step_frac": 0.039492709644109475, "timer/env.step_avg": 0.009804389801139035, "timer/env.step_min": 0.007725954055786133, "timer/env.step_max": 0.037290334701538086, "timer/replay._sample_count": 32224.0, "timer/replay._sample_total": 16.893251180648804, "timer/replay._sample_frac": 0.016893519612671878, "timer/replay._sample_avg": 0.0005242443886745533, "timer/replay._sample_min": 0.0003731250762939453, "timer/replay._sample_max": 0.01461648941040039, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4536.0, "timer/agent.policy_total": 48.91355919837952, "timer/agent.policy_frac": 0.04891433642980235, "timer/agent.policy_avg": 0.010783412521688606, "timer/agent.policy_min": 0.00863790512084961, "timer/agent.policy_max": 0.09969258308410645, "timer/dataset_train_count": 2014.0, "timer/dataset_train_total": 0.23044395446777344, "timer/dataset_train_frac": 0.00023044761619849902, "timer/dataset_train_avg": 0.00011442103002372067, "timer/dataset_train_min": 9.72747802734375e-05, "timer/dataset_train_max": 0.00044608116149902344, "timer/agent.train_count": 2014.0, "timer/agent.train_total": 900.1039032936096, "timer/agent.train_frac": 0.9001182058520191, "timer/agent.train_avg": 0.4469234872361518, "timer/agent.train_min": 0.43536806106567383, "timer/agent.train_max": 0.671912431716919, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4756934642791748, "timer/agent.report_frac": 0.00047570102299937696, "timer/agent.report_avg": 0.2378467321395874, "timer/agent.report_min": 0.22960519790649414, "timer/agent.report_max": 0.24608826637268066, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.1948089599609375e-05, "timer/dataset_eval_frac": 3.1948597251465895e-08, "timer/dataset_eval_avg": 3.1948089599609375e-05, "timer/dataset_eval_min": 3.1948089599609375e-05, "timer/dataset_eval_max": 3.1948089599609375e-05, "fps": 32.22394569805903}
{"step": 1444640, "time": 45266.87255501747, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1444800, "time": 45272.138061761856, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1445056, "time": 45280.06469082832, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1445152, "time": 45283.038707494736, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1445384, "time": 45289.844405174255, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1445408, "time": 45290.810725450516, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1446032, "time": 45309.9404733181, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1446048, "time": 45310.42912054062, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 1446136, "time": 45312.87148761749, "episode/length": 267.0, "episode/score": 0.16562500596046448, "episode/reward_rate": 0.0037313432835820895, "episode/intrinsic_return": 0.0}
{"step": 1446160, "time": 45313.829042196274, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 1446240, "time": 45316.284532547, "episode/length": 256.0, "episode/score": 0.20000000298023224, "episode/reward_rate": 0.0038910505836575876, "episode/intrinsic_return": 0.0}
{"step": 1446424, "time": 45321.67354297638, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 1446776, "time": 45332.354615688324, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 1447168, "time": 45344.64342069626, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1447176, "time": 45344.67106628418, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1447368, "time": 45350.54091978073, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1447536, "time": 45355.871131420135, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 1447600, "time": 45357.810861349106, "episode/length": 276.0, "episode/score": 0.13750000298023224, "episode/reward_rate": 0.0036101083032490976, "episode/intrinsic_return": 0.0}
{"step": 1447656, "time": 45359.298184633255, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1447760, "time": 45362.67966938019, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1448184, "time": 45375.41100549698, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1448336, "time": 45380.26724052429, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1448344, "time": 45380.296030282974, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1448376, "time": 45381.2739276886, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 1448392, "time": 45381.7686457634, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1448688, "time": 45390.97596502304, "episode/length": 282.0, "episode/score": 0.11874999850988388, "episode/reward_rate": 0.0035335689045936395, "episode/intrinsic_return": 0.0}
{"step": 1448920, "time": 45397.87361741066, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1449120, "time": 45404.15909695625, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1449344, "time": 45410.919273138046, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1449592, "time": 45418.21219468117, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1449608, "time": 45418.70309495926, "episode/length": 230.0, "episode/score": 0.28125, "episode/reward_rate": 0.004329004329004329, "episode/intrinsic_return": 0.0}
{"step": 1449680, "time": 45421.109268665314, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1449912, "time": 45428.04919934273, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1450072, "time": 45433.91640710831, "eval_episode/length": 23.0, "eval_episode/score": 0.9281250238418579, "eval_episode/reward_rate": 0.041666666666666664}
{"step": 1450072, "time": 45434.27736401558, "eval_episode/length": 41.0, "eval_episode/score": 0.871874988079071, "eval_episode/reward_rate": 0.023809523809523808}
{"step": 1450072, "time": 45435.25438332558, "eval_episode/length": 94.0, "eval_episode/score": 0.706250011920929, "eval_episode/reward_rate": 0.010526315789473684}
{"step": 1450072, "time": 45435.58455443382, "eval_episode/length": 88.0, "eval_episode/score": 0.7250000238418579, "eval_episode/reward_rate": 0.011235955056179775}
{"step": 1450072, "time": 45435.737208127975, "eval_episode/length": 120.0, "eval_episode/score": 0.625, "eval_episode/reward_rate": 0.008264462809917356}
{"step": 1450072, "time": 45436.59559059143, "eval_episode/length": 166.0, "eval_episode/score": 0.48124998807907104, "eval_episode/reward_rate": 0.005988023952095809}
{"step": 1450072, "time": 45436.993218660355, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 1450072, "time": 45437.01956653595, "eval_episode/length": 21.0, "eval_episode/score": 0.934374988079071, "eval_episode/reward_rate": 0.045454545454545456}
{"step": 1450216, "time": 45441.43307352066, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 1450384, "time": 45446.745972156525, "episode/length": 20.0, "episode/score": 0.9375, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.0}
{"step": 1450464, "time": 45449.16447544098, "episode/length": 221.0, "episode/score": 0.30937498807907104, "episode/reward_rate": 0.0045045045045045045, "episode/intrinsic_return": 0.0}
{"step": 1450496, "time": 45450.136068582535, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1450536, "time": 45451.14630627632, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1450680, "time": 45455.51396942139, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1450784, "time": 45458.97212219238, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 1450816, "time": 45459.943950891495, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 1450824, "time": 45459.97117090225, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1451080, "time": 45467.74454379082, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 1451120, "time": 45469.17736554146, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1451200, "time": 45471.627610206604, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1451432, "time": 45478.45279574394, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1451592, "time": 45483.392470121384, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1451688, "time": 45486.37505698204, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1451776, "time": 45489.326206207275, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1451936, "time": 45494.193964481354, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 1452200, "time": 45501.988365888596, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1452224, "time": 45502.94408535957, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1452432, "time": 45509.26989078522, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 1452552, "time": 45512.68875980377, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 1452600, "time": 45514.1571495533, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1452664, "time": 45516.097076654434, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1452952, "time": 45524.95287203789, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1452992, "time": 45526.38690185547, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1453216, "time": 45533.16568374634, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1453216, "time": 45533.173441410065, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 1453408, "time": 45539.01825928688, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1453752, "time": 45549.299932956696, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1453808, "time": 45551.22645020485, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1453840, "time": 45552.20383429527, "episode/length": 204.0, "episode/score": 0.36250001192092896, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.0}
{"step": 1454088, "time": 45559.50682044029, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1454184, "time": 45562.41874361038, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1454464, "time": 45571.186205387115, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 1454752, "time": 45580.00883412361, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1454864, "time": 45583.408100128174, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1455056, "time": 45589.23154258728, "episode/length": 257.0, "episode/score": 0.19687500596046448, "episode/reward_rate": 0.003875968992248062, "episode/intrinsic_return": 0.0}
{"step": 1455072, "time": 45589.71948289871, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 1455120, "time": 45591.17474603653, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 1455160, "time": 45592.18315720558, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1455256, "time": 45595.0795583725, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1455424, "time": 45600.43214678764, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1455512, "time": 45602.90518307686, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1455720, "time": 45609.32661938667, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1456056, "time": 45619.55215215683, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1456072, "time": 45620.04796624184, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1456600, "time": 45636.1333322525, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 1456608, "time": 45636.71047592163, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1456784, "time": 45642.091233968735, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 1457088, "time": 45651.39885187149, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1457280, "time": 45657.2281434536, "episode/length": 269.0, "episode/score": 0.15937499701976776, "episode/reward_rate": 0.003703703703703704, "episode/intrinsic_return": 0.0}
{"step": 1457360, "time": 45659.65053796768, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 1457368, "time": 45659.67916178703, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1457384, "time": 45660.17032504082, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1457560, "time": 45665.571895837784, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1457584, "time": 45666.61136221886, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 1457736, "time": 45671.01803731918, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1457744, "time": 45671.483805418015, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0}
{"step": 1457816, "time": 45673.44649839401, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1458152, "time": 45683.68204164505, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1458272, "time": 45688.034474372864, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1458344, "time": 45690.02818894386, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1458440, "time": 45693.00929927826, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1458456, "time": 45693.50679898262, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0}
{"step": 1458664, "time": 45699.98423957825, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 1458672, "time": 45700.47423863411, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 1458920, "time": 45707.74273657799, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1459104, "time": 45713.59557580948, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1459288, "time": 45718.948974609375, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1459408, "time": 45722.81738495827, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1459448, "time": 45723.80957245827, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1459680, "time": 45731.186213970184, "episode/length": 232.0, "episode/score": 0.2750000059604645, "episode/reward_rate": 0.004291845493562232, "episode/intrinsic_return": 0.0}
{"step": 1459680, "time": 45731.19460940361, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1459688, "time": 45731.22594189644, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1459728, "time": 45732.660482406616, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 1459936, "time": 45738.98984718323, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1460016, "time": 45741.4369661808, "episode/length": 208.0, "episode/score": 0.3499999940395355, "episode/reward_rate": 0.004784688995215311, "episode/intrinsic_return": 0.0}
{"step": 1460056, "time": 45743.13650178909, "eval_episode/length": 34.0, "eval_episode/score": 0.893750011920929, "eval_episode/reward_rate": 0.02857142857142857}
{"step": 1460056, "time": 45743.47179174423, "eval_episode/length": 51.0, "eval_episode/score": 0.840624988079071, "eval_episode/reward_rate": 0.019230769230769232}
{"step": 1460056, "time": 45744.53540611267, "eval_episode/length": 107.0, "eval_episode/score": 0.6656249761581421, "eval_episode/reward_rate": 0.009259259259259259}
{"step": 1460056, "time": 45744.93985247612, "eval_episode/length": 93.0, "eval_episode/score": 0.7093750238418579, "eval_episode/reward_rate": 0.010638297872340425}
{"step": 1460056, "time": 45745.0846157074, "eval_episode/length": 135.0, "eval_episode/score": 0.578125, "eval_episode/reward_rate": 0.007352941176470588}
{"step": 1460056, "time": 45745.66223526001, "eval_episode/length": 164.0, "eval_episode/score": 0.48750001192092896, "eval_episode/reward_rate": 0.006060606060606061}
{"step": 1460056, "time": 45745.70891833305, "eval_episode/length": 166.0, "eval_episode/score": 0.48124998807907104, "eval_episode/reward_rate": 0.005988023952095809}
{"step": 1460056, "time": 45746.54346227646, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 1460216, "time": 45751.42701268196, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1460264, "time": 45752.887233257294, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1460712, "time": 45766.621349811554, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1460760, "time": 45768.10641670227, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1460816, "time": 45770.02612042427, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1460888, "time": 45771.98702955246, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1460976, "time": 45774.89499139786, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 1461192, "time": 45781.21841573715, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 1461456, "time": 45789.5360455513, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1461464, "time": 45789.56453371048, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1461592, "time": 45793.47641849518, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1461600, "time": 45793.947404146194, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1462032, "time": 45807.13534235954, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1462080, "time": 45808.594643592834, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 1462152, "time": 45810.559114694595, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1462248, "time": 45813.495690107346, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1462464, "time": 45820.39938187599, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1462528, "time": 45822.373864889145, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1462632, "time": 45825.303257226944, "episode/length": 217.0, "episode/score": 0.3218750059604645, "episode/reward_rate": 0.0045871559633027525, "episode/intrinsic_return": 0.0}
{"step": 1462656, "time": 45826.249802351, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1462744, "time": 45828.7165017128, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 1462856, "time": 45832.132083415985, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 1463112, "time": 45839.91391301155, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1463184, "time": 45842.345215797424, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1463272, "time": 45844.79551434517, "episode/length": 19.0, "episode/score": 0.940625011920929, "episode/reward_rate": 0.05, "episode/intrinsic_return": 0.0}
{"step": 1463824, "time": 45861.894817352295, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1463832, "time": 45861.924602508545, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 1464120, "time": 45870.69204950333, "episode/length": 198.0, "episode/score": 0.3812499940395355, "episode/reward_rate": 0.005025125628140704, "episode/intrinsic_return": 0.0}
{"step": 1464208, "time": 45873.568695783615, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1464320, "time": 45877.06859540939, "episode/length": 182.0, "episode/score": 0.4312500059604645, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.0}
{"step": 1464344, "time": 45877.57944369316, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1464544, "time": 45883.85192298889, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 1464552, "time": 45883.87877511978, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1464576, "time": 45884.82735610008, "episode/length": 242.0, "episode/score": 0.24375000596046448, "episode/reward_rate": 0.00411522633744856, "episode/intrinsic_return": 0.0}
{"step": 1464624, "time": 45886.29940319061, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 1464880, "time": 45894.036704063416, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1465016, "time": 45897.946011304855, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1465312, "time": 45907.283007860184, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1465440, "time": 45911.19247150421, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1465496, "time": 45912.67123627663, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1465608, "time": 45916.089617967606, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1465776, "time": 45921.444957494736, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1465936, "time": 45926.34424304962, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1466440, "time": 45942.05356502533, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1466576, "time": 45946.39828681946, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1466736, "time": 45951.23023200035, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 1466864, "time": 45955.15026283264, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1466920, "time": 45956.624584674835, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 1466936, "time": 45957.11413645744, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1467088, "time": 45961.90342140198, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1467192, "time": 45964.81875991821, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1467328, "time": 45969.25736808777, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1467600, "time": 45977.45446014404, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1467696, "time": 45980.37383699417, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1467808, "time": 45983.75988531113, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1467864, "time": 45985.225856781006, "episode/length": 20.0, "episode/score": 0.9375, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.0}
{"step": 1467912, "time": 45986.67105579376, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1468360, "time": 46000.32387185097, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1468456, "time": 46003.290677547455, "episode/length": 198.0, "episode/score": 0.3812499940395355, "episode/reward_rate": 0.005025125628140704, "episode/intrinsic_return": 0.0}
{"step": 1468544, "time": 46006.228774785995, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1468688, "time": 46010.63980817795, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1468888, "time": 46016.46179437637, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1468944, "time": 46018.38811445236, "episode/length": 252.0, "episode/score": 0.21250000596046448, "episode/reward_rate": 0.003952569169960474, "episode/intrinsic_return": 0.0}
{"step": 1469280, "time": 46028.737478256226, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1469296, "time": 46029.23171758652, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 1469352, "time": 46030.710735321045, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1469392, "time": 46032.16365671158, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1469552, "time": 46037.017350673676, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1469808, "time": 46044.81175494194, "episode/length": 236.0, "episode/score": 0.26249998807907104, "episode/reward_rate": 0.004219409282700422, "episode/intrinsic_return": 0.0}
{"step": 1470040, "time": 46053.42800664902, "eval_episode/length": 89.0, "eval_episode/score": 0.721875011920929, "eval_episode/reward_rate": 0.011111111111111112}
{"step": 1470040, "time": 46053.472702503204, "eval_episode/length": 91.0, "eval_episode/score": 0.715624988079071, "eval_episode/reward_rate": 0.010869565217391304}
{"step": 1470040, "time": 46054.84384727478, "eval_episode/length": 163.0, "eval_episode/score": 0.4906249940395355, "eval_episode/reward_rate": 0.006097560975609756}
{"step": 1470040, "time": 46054.890622377396, "eval_episode/length": 165.0, "eval_episode/score": 0.484375, "eval_episode/reward_rate": 0.006024096385542169}
{"step": 1470040, "time": 46055.35920667648, "eval_episode/length": 190.0, "eval_episode/score": 0.40625, "eval_episode/reward_rate": 0.005235602094240838}
{"step": 1470040, "time": 46055.536314964294, "eval_episode/length": 109.0, "eval_episode/score": 0.659375011920929, "eval_episode/reward_rate": 0.00909090909090909}
{"step": 1470040, "time": 46056.28261947632, "eval_episode/length": 70.0, "eval_episode/score": 0.78125, "eval_episode/reward_rate": 0.014084507042253521}
{"step": 1470040, "time": 46057.44253778458, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1470040, "time": 46057.450015068054, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1470040, "time": 46057.45975756645, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1470656, "time": 46076.421751737595, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1470728, "time": 46078.40976524353, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 1470904, "time": 46083.75965809822, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1471200, "time": 46093.13034057617, "episode/length": 281.0, "episode/score": 0.12187500298023224, "episode/reward_rate": 0.0035460992907801418, "episode/intrinsic_return": 0.0}
{"step": 1471200, "time": 46093.13779091835, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1471288, "time": 46095.610731840134, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1471296, "time": 46096.091156959534, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1471592, "time": 46104.864559412, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1471608, "time": 46105.35610079765, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1471704, "time": 46108.28159594536, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1471776, "time": 46110.69033551216, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1471936, "time": 46115.586812734604, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 1472024, "time": 46118.17718076706, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1472048, "time": 46119.1354265213, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1472144, "time": 46122.07920002937, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1472160, "time": 46122.573489665985, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1472296, "time": 46126.498274087906, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1472344, "time": 46127.94538474083, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1472576, "time": 46135.17304229736, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1472992, "time": 46147.961983919144, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1473016, "time": 46148.474667072296, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 1473112, "time": 46151.39573049545, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1473288, "time": 46156.74670433998, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 1473416, "time": 46160.65625691414, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1473432, "time": 46161.147579193115, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 1473472, "time": 46162.58854293823, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 1473680, "time": 46168.91688537598, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1474032, "time": 46179.81017136574, "episode/length": 216.0, "episode/score": 0.32499998807907104, "episode/reward_rate": 0.004608294930875576, "episode/intrinsic_return": 0.0}
{"step": 1474088, "time": 46181.30164813995, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1474344, "time": 46189.13968420029, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 1474496, "time": 46194.01423239708, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1474608, "time": 46197.97795820236, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1474736, "time": 46201.926777124405, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1474784, "time": 46203.39503240585, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1474960, "time": 46208.87066221237, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1475304, "time": 46219.11563825607, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1475360, "time": 46221.050334692, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1475368, "time": 46221.07856249809, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1475368, "time": 46221.08450269699, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1475600, "time": 46228.30580687523, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1475744, "time": 46232.67013311386, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1475920, "time": 46238.11239051819, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1476136, "time": 46244.455057621, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1476160, "time": 46245.40467071533, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1476216, "time": 46246.88401556015, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 1476592, "time": 46258.5617480278, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1476672, "time": 46260.98836684227, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1476824, "time": 46265.39816856384, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 1476841, "time": 46267.11383962631, "train_stats/mean_log_entropy": 0.07963643956617637, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.5471127638176307, "train/action_min": 0.0, "train/action_std": 1.8246478138871454, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.010181463485704133, "train/actor_opt_grad_steps": 91200.0, "train/actor_opt_loss": -28.427090360157525, "train/adv_mag": 0.7141000145110324, "train/adv_max": 0.30409548353793014, "train/adv_mean": 0.0009151070725107022, "train/adv_min": -0.6419700016429768, "train/adv_std": 0.028735301902156268, "train/cont_avg": 0.9930620335820896, "train/cont_loss_mean": 0.030019650777885272, "train/cont_loss_std": 0.30620292103409175, "train/cont_neg_acc": 0.09974003598019851, "train/cont_neg_loss": 3.402168974651033, "train/cont_pos_acc": 0.9998728090257787, "train/cont_pos_loss": 0.006423810942895451, "train/cont_pred": 0.9929977305492952, "train/cont_rate": 0.9930620335820896, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.15209394096586834, "train/extr_critic_critic_opt_grad_steps": 91200.0, "train/extr_critic_critic_opt_loss": 5163.348895172575, "train/extr_critic_mag": 1.7342289739580297, "train/extr_critic_max": 1.7342289739580297, "train/extr_critic_mean": 1.5950728103296081, "train/extr_critic_min": 1.308527390755231, "train/extr_critic_std": 0.028884634153166815, "train/extr_return_normed_mag": 0.7415765372674856, "train/extr_return_normed_max": 0.30362116934648203, "train/extr_return_normed_mean": 0.060393461707367826, "train/extr_return_normed_min": -0.6043689645344938, "train/extr_return_normed_std": 0.04198825253701922, "train/extr_return_rate": 0.9997765297320351, "train/extr_return_raw_mag": 1.839215579910658, "train/extr_return_raw_max": 1.839215579910658, "train/extr_return_raw_mean": 1.5959879533568424, "train/extr_return_raw_min": 0.931225446029682, "train/extr_return_raw_std": 0.041988252509218546, "train/extr_reward_mag": 0.2893795148650212, "train/extr_reward_max": 0.2893795148650212, "train/extr_reward_mean": 0.002702228426678449, "train/extr_reward_min": 9.489296680659204e-09, "train/extr_reward_std": 0.009609028780415876, "train/image_loss_mean": 0.09181003405976651, "train/image_loss_std": 0.10381276219786696, "train/model_loss_mean": 0.749016521581963, "train/model_loss_std": 0.6119686170152171, "train/model_opt_grad_norm": 14.755773766040802, "train/model_opt_grad_steps": 91117.03980099503, "train/model_opt_loss": 3800.409377672186, "train/model_opt_model_opt_grad_overflow": 0.004975124378109453, "train/model_opt_model_opt_grad_scale": 5074.626865671642, "train/policy_entropy_mag": 1.1718774835268657, "train/policy_entropy_max": 1.1718774835268657, "train/policy_entropy_mean": 0.08380956647556219, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.09333987252332678, "train/policy_logprob_mag": 6.55108029332327, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.08350625211623178, "train/policy_logprob_min": -6.55108029332327, "train/policy_logprob_std": 0.6197001299454798, "train/policy_randomness_mag": 0.6022259312779156, "train/policy_randomness_max": 0.6022259312779156, "train/policy_randomness_mean": 0.04306960235632474, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.04796720896639041, "train/post_ent_mag": 29.14945108973565, "train/post_ent_max": 29.14945108973565, "train/post_ent_mean": 28.356022051910855, "train/post_ent_min": 27.596654455460126, "train/post_ent_std": 0.3239783663951342, "train/prior_ent_mag": 28.598136588708677, "train/prior_ent_max": 28.598136588708677, "train/prior_ent_mean": 27.94504418064706, "train/prior_ent_min": 26.861887348231985, "train/prior_ent_std": 0.3088375874864521, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.003636829886326001, "train/reward_loss_mean": 0.02718681693355094, "train/reward_loss_std": 0.30826811431281603, "train/reward_max_data": 0.8168998755032744, "train/reward_max_pred": 0.31152060909650814, "train/reward_neg_acc": 0.9993650850965016, "train/reward_neg_loss": 0.005078097347828063, "train/reward_pos_acc": 0.12593488719314336, "train/reward_pos_loss": 4.071087801456452, "train/reward_pred": 0.0029130087110135166, "train/reward_rate": 0.0054269667288557215, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9873046875, "report/cont_loss_mean": 0.045544084161520004, "report/cont_loss_std": 0.4035079777240753, "report/cont_neg_acc": 0.1538461595773697, "report/cont_neg_loss": 3.187872886657715, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.00513827707618475, "report/cont_pred": 0.9933109283447266, "report/cont_rate": 0.9873046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.10121405869722366, "report/image_loss_std": 0.10821818560361862, "report/model_loss_mean": 0.7888799905776978, "report/model_loss_std": 0.7669028639793396, "report/post_ent_mag": 29.71242904663086, "report/post_ent_max": 29.71242904663086, "report/post_ent_mean": 28.813060760498047, "report/post_ent_min": 27.919544219970703, "report/post_ent_std": 0.42055824398994446, "report/prior_ent_mag": 28.563831329345703, "report/prior_ent_max": 28.563831329345703, "report/prior_ent_mean": 27.925193786621094, "report/prior_ent_min": 26.871292114257812, "report/prior_ent_std": 0.364628404378891, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.005645751953125, "report/reward_loss_mean": 0.04212190583348274, "report/reward_loss_std": 0.39677128195762634, "report/reward_max_data": 0.8218749761581421, "report/reward_max_pred": 0.2890605926513672, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.004384573083370924, "report/reward_pos_acc": 0.20000000298023224, "report/reward_pos_loss": 3.868687152862549, "report/reward_pred": 0.0028938972391188145, "report/reward_rate": 0.009765625, "eval/cont_avg": 0.9921875, "eval/cont_loss_mean": 0.03374498337507248, "eval/cont_loss_std": 0.3057612478733063, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 3.456183433532715, "eval/cont_pos_acc": 0.999015748500824, "eval/cont_pos_loss": 0.006796647794544697, "eval/cont_pred": 0.9934144020080566, "eval/cont_rate": 0.9921875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.10453356802463531, "eval/image_loss_std": 0.10794432461261749, "eval/model_loss_mean": 0.7771308422088623, "eval/model_loss_std": 0.713887631893158, "eval/post_ent_mag": 29.712024688720703, "eval/post_ent_max": 29.712024688720703, "eval/post_ent_mean": 28.89615249633789, "eval/post_ent_min": 27.96027374267578, "eval/post_ent_std": 0.3525576889514923, "eval/prior_ent_mag": 28.562074661254883, "eval/prior_ent_max": 28.562074661254883, "eval/prior_ent_mean": 27.975372314453125, "eval/prior_ent_min": 26.92450714111328, "eval/prior_ent_std": 0.3436194360256195, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.004986572079360485, "eval/reward_loss_mean": 0.038852300494909286, "eval/reward_loss_std": 0.3754928410053253, "eval/reward_max_data": 0.75, "eval/reward_max_pred": 0.3093867301940918, "eval/reward_neg_acc": 0.999015748500824, "eval/reward_neg_loss": 0.005654357839375734, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 4.254990577697754, "eval/reward_pred": 0.002860607346519828, "eval/reward_rate": 0.0078125, "replay/size": 1000000.0, "replay/inserts": 32208.0, "replay/samples": 32208.0, "replay/insert_wait_avg": 1.264844317372261e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.917380013160307e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5504.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1322716640871625e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.195638656616211e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.119131565094, "timer/env.step_count": 4026.0, "timer/env.step_total": 39.11590909957886, "timer/env.step_frac": 0.03911124971518751, "timer/env.step_avg": 0.009715824416189484, "timer/env.step_min": 0.00782012939453125, "timer/env.step_max": 0.03646707534790039, "timer/replay._sample_count": 32208.0, "timer/replay._sample_total": 16.418806314468384, "timer/replay._sample_frac": 0.016416850549368523, "timer/replay._sample_avg": 0.0005097741652529926, "timer/replay._sample_min": 0.00040340423583984375, "timer/replay._sample_max": 0.033136844635009766, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4714.0, "timer/agent.policy_total": 49.843559980392456, "timer/agent.policy_frac": 0.04983762274639411, "timer/agent.policy_avg": 0.010573517178700139, "timer/agent.policy_min": 0.008584022521972656, "timer/agent.policy_max": 0.07677483558654785, "timer/dataset_train_count": 2013.0, "timer/dataset_train_total": 0.22087788581848145, "timer/dataset_train_frac": 0.00022085157542464765, "timer/dataset_train_avg": 0.00010972572569224116, "timer/dataset_train_min": 9.298324584960938e-05, "timer/dataset_train_max": 0.0002853870391845703, "timer/agent.train_count": 2013.0, "timer/agent.train_total": 897.9397552013397, "timer/agent.train_frac": 0.8978327949752816, "timer/agent.train_avg": 0.4460704198715051, "timer/agent.train_min": 0.43513965606689453, "timer/agent.train_max": 0.6919012069702148, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.49306631088256836, "timer/agent.report_frac": 0.0004930075781181839, "timer/agent.report_avg": 0.24653315544128418, "timer/agent.report_min": 0.2440650463104248, "timer/agent.report_max": 0.24900126457214355, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9087066650390625e-05, "timer/dataset_eval_frac": 2.908360187538064e-08, "timer/dataset_eval_avg": 2.9087066650390625e-05, "timer/dataset_eval_min": 2.9087066650390625e-05, "timer/dataset_eval_max": 2.9087066650390625e-05, "fps": 32.203506761690846}
{"step": 1476920, "time": 46269.29941558838, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1477080, "time": 46274.19736671448, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 1477312, "time": 46281.51867508888, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1477384, "time": 46283.507367134094, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1477384, "time": 46283.516691446304, "episode/length": 251.0, "episode/score": 0.21562500298023224, "episode/reward_rate": 0.003968253968253968, "episode/intrinsic_return": 0.0}
{"step": 1477416, "time": 46284.52820825577, "episode/length": 12.0, "episode/score": 0.9624999761581421, "episode/reward_rate": 0.07692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1477616, "time": 46290.870896577835, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1477632, "time": 46291.36175823212, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1477792, "time": 46296.23793339729, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1477912, "time": 46299.77899098396, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1478320, "time": 46312.51963233948, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1478448, "time": 46316.440752744675, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1478512, "time": 46318.40623188019, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 1478576, "time": 46320.344870090485, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 1478768, "time": 46326.178970098495, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1478808, "time": 46327.31038236618, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1478864, "time": 46329.27444553375, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1478920, "time": 46330.761320114136, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 1479248, "time": 46340.97112631798, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1479272, "time": 46341.480838775635, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1479480, "time": 46347.8222155571, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1479608, "time": 46351.703120708466, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1479728, "time": 46355.56377196312, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1479736, "time": 46355.591344594955, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1479888, "time": 46360.53440761566, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1480024, "time": 46365.328795194626, "eval_episode/length": 46.0, "eval_episode/score": 0.856249988079071, "eval_episode/reward_rate": 0.02127659574468085}
{"step": 1480024, "time": 46365.75661158562, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 1480024, "time": 46366.03573036194, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 1480024, "time": 46366.365755558014, "eval_episode/length": 30.0, "eval_episode/score": 0.90625, "eval_episode/reward_rate": 0.03225806451612903}
{"step": 1480024, "time": 46366.788096904755, "eval_episode/length": 75.0, "eval_episode/score": 0.765625, "eval_episode/reward_rate": 0.013157894736842105}
{"step": 1480024, "time": 46366.951874017715, "eval_episode/length": 130.0, "eval_episode/score": 0.59375, "eval_episode/reward_rate": 0.007633587786259542}
{"step": 1480024, "time": 46366.97801017761, "eval_episode/length": 131.0, "eval_episode/score": 0.590624988079071, "eval_episode/reward_rate": 0.007575757575757576}
{"step": 1480024, "time": 46367.71091794968, "eval_episode/length": 167.0, "eval_episode/score": 0.4781250059604645, "eval_episode/reward_rate": 0.005952380952380952}
{"step": 1480208, "time": 46373.55886602402, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1480216, "time": 46373.58591365814, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1480240, "time": 46374.53936481476, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 1480280, "time": 46375.55601835251, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1480576, "time": 46384.73763680458, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1480592, "time": 46385.24495100975, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1480840, "time": 46392.66787648201, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1480936, "time": 46395.60672068596, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1481080, "time": 46399.992694854736, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1481248, "time": 46405.31502008438, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1481344, "time": 46408.23318552971, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1481384, "time": 46409.234234809875, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1481704, "time": 46419.04620218277, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1481792, "time": 46421.99477338791, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1481800, "time": 46422.02368426323, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 1481808, "time": 46422.49888539314, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1482184, "time": 46433.66610574722, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1482192, "time": 46434.15406394005, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1482224, "time": 46435.12546157837, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 1482376, "time": 46439.51223921776, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1482960, "time": 46458.11948490143, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1483152, "time": 46464.03361296654, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1483312, "time": 46468.933187007904, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1483344, "time": 46469.90766000748, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1483344, "time": 46469.916280031204, "episode/length": 249.0, "episode/score": 0.22187499701976776, "episode/reward_rate": 0.004, "episode/intrinsic_return": 0.0}
{"step": 1483888, "time": 46486.65538740158, "episode/length": 261.0, "episode/score": 0.18437500298023224, "episode/reward_rate": 0.003816793893129771, "episode/intrinsic_return": 0.0}
{"step": 1483888, "time": 46486.66348695755, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1484016, "time": 46490.605665683746, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1484096, "time": 46493.04842400551, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1484224, "time": 46496.96371126175, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1484384, "time": 46501.85114073753, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 1484496, "time": 46505.27416229248, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1484520, "time": 46505.78825879097, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1484576, "time": 46507.84256315231, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 1484688, "time": 46511.26331949234, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1484784, "time": 46514.20357966423, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1484952, "time": 46519.11573147774, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1484984, "time": 46520.0918533802, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1485304, "time": 46529.81781697273, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1485464, "time": 46534.68172240257, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1485888, "time": 46547.99256825447, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1485952, "time": 46549.937030792236, "episode/length": 195.0, "episode/score": 0.390625, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.0}
{"step": 1486008, "time": 46551.424265384674, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 1486200, "time": 46557.2839012146, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1486232, "time": 46558.26543998718, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1486264, "time": 46559.244955062866, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 1486736, "time": 46573.92121505737, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1486944, "time": 46580.23656177521, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1487000, "time": 46581.74544382095, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1487024, "time": 46582.689591407776, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1487088, "time": 46584.62186861038, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1487096, "time": 46584.65093564987, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1487608, "time": 46600.240691423416, "episode/length": 267.0, "episode/score": 0.16562500596046448, "episode/reward_rate": 0.0037313432835820895, "episode/intrinsic_return": 0.0}
{"step": 1487712, "time": 46603.62403678894, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1487728, "time": 46604.12004208565, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1487768, "time": 46605.12137031555, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1488168, "time": 46617.29878997803, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1488304, "time": 46621.637118816376, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1488328, "time": 46622.147157907486, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 1488576, "time": 46629.9611825943, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1488600, "time": 46630.49137496948, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1488632, "time": 46631.46989607811, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 1488656, "time": 46632.42623233795, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1488792, "time": 46636.36422085762, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1488992, "time": 46642.65752649307, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 1489064, "time": 46644.60920166969, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1489216, "time": 46649.436316251755, "episode/length": 273.0, "episode/score": 0.14687499403953552, "episode/reward_rate": 0.0036496350364963502, "episode/intrinsic_return": 0.0}
{"step": 1489304, "time": 46651.89139294624, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1489464, "time": 46656.884205818176, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1489608, "time": 46661.27095532417, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1489672, "time": 46663.20643115044, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1489736, "time": 46665.167986392975, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1490000, "time": 46673.38787269592, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1490008, "time": 46673.41494703293, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1490008, "time": 46675.321477651596, "eval_episode/length": 67.0, "eval_episode/score": 0.7906249761581421, "eval_episode/reward_rate": 0.014705882352941176}
{"step": 1490008, "time": 46675.50354003906, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 1490008, "time": 46675.99709153175, "eval_episode/length": 104.0, "eval_episode/score": 0.675000011920929, "eval_episode/reward_rate": 0.009523809523809525}
{"step": 1490008, "time": 46676.094777822495, "eval_episode/length": 109.0, "eval_episode/score": 0.659375011920929, "eval_episode/reward_rate": 0.00909090909090909}
{"step": 1490008, "time": 46676.25995707512, "eval_episode/length": 118.0, "eval_episode/score": 0.6312500238418579, "eval_episode/reward_rate": 0.008403361344537815}
{"step": 1490008, "time": 46676.38674616814, "eval_episode/length": 125.0, "eval_episode/score": 0.609375, "eval_episode/reward_rate": 0.007936507936507936}
{"step": 1490008, "time": 46676.39182686806, "eval_episode/length": 125.0, "eval_episode/score": 0.609375, "eval_episode/reward_rate": 0.007936507936507936}
{"step": 1490008, "time": 46676.54349040985, "eval_episode/length": 65.0, "eval_episode/score": 0.796875, "eval_episode/reward_rate": 0.015151515151515152}
{"step": 1490120, "time": 46679.934037446976, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1490168, "time": 46681.38133430481, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1490472, "time": 46690.679992198944, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1490912, "time": 46704.31998872757, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1490920, "time": 46704.34751343727, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 1490968, "time": 46706.28756117821, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1491152, "time": 46712.11846446991, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1491240, "time": 46714.56171345711, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1491320, "time": 46717.116951942444, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1491408, "time": 46719.99222636223, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1491552, "time": 46724.35510969162, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 1491928, "time": 46735.54655241966, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1492104, "time": 46740.865813970566, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1492296, "time": 46746.82504296303, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1492312, "time": 46747.316492795944, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1492336, "time": 46748.26659989357, "episode/length": 232.0, "episode/score": 0.2750000059604645, "episode/reward_rate": 0.004291845493562232, "episode/intrinsic_return": 0.0}
{"step": 1492528, "time": 46754.08508491516, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1492576, "time": 46755.53815793991, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1492856, "time": 46763.80242109299, "episode/length": 201.0, "episode/score": 0.37187498807907104, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.0}
{"step": 1492888, "time": 46764.775069236755, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1493272, "time": 46776.4699511528, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1493440, "time": 46781.86552357674, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1493624, "time": 46787.23414039612, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 1493632, "time": 46787.71087384224, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1493744, "time": 46791.1275036335, "episode/length": 204.0, "episode/score": 0.36250001192092896, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.0}
{"step": 1493832, "time": 46793.57016849518, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 1493872, "time": 46795.02193260193, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1494376, "time": 46810.13569664955, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1494464, "time": 46813.022304058075, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1494568, "time": 46815.99212360382, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 1494584, "time": 46816.4811270237, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1494624, "time": 46817.912616968155, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1494832, "time": 46824.21532154083, "episode/length": 246.0, "episode/score": 0.23125000298023224, "episode/reward_rate": 0.004048582995951417, "episode/intrinsic_return": 0.0}
{"step": 1494888, "time": 46825.71387529373, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1494936, "time": 46827.19203352928, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1495136, "time": 46833.43571424484, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1495376, "time": 46840.85589337349, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1495488, "time": 46844.27443194389, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1495560, "time": 46846.24055504799, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1495760, "time": 46852.518315553665, "episode/length": 240.0, "episode/score": 0.25, "episode/reward_rate": 0.004149377593360996, "episode/intrinsic_return": 0.0}
{"step": 1495760, "time": 46852.52512216568, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1495968, "time": 46858.848860025406, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 1496120, "time": 46863.212165117264, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1496192, "time": 46865.615213871, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1496432, "time": 46873.05759215355, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1496520, "time": 46875.501556396484, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1496568, "time": 46876.953978300095, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1496880, "time": 46886.66146969795, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1496880, "time": 46886.67092204094, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1497120, "time": 46893.95450043678, "episode/length": 247.0, "episode/score": 0.22812500596046448, "episode/reward_rate": 0.004032258064516129, "episode/intrinsic_return": 0.0}
{"step": 1497152, "time": 46894.92993879318, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1497496, "time": 46905.24203276634, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1497600, "time": 46908.624168395996, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1497640, "time": 46909.614521980286, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1497864, "time": 46916.36299276352, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 1498128, "time": 46924.59735560417, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1498224, "time": 46927.62735629082, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1498432, "time": 46933.97393298149, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1498536, "time": 46936.970340013504, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1498664, "time": 46940.910796403885, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1498672, "time": 46941.39810657501, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 1498880, "time": 46947.71035408974, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1498968, "time": 46950.149832725525, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1499192, "time": 46957.669634103775, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1499304, "time": 46961.06457519531, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1499328, "time": 46962.03377914429, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1499512, "time": 46967.396780729294, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1499616, "time": 46970.7592048645, "episode/length": 12.0, "episode/score": 0.9624999761581421, "episode/reward_rate": 0.07692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1499736, "time": 46974.20165729523, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1500096, "time": 46985.98608279228, "eval_episode/length": 35.0, "eval_episode/score": 0.890625, "eval_episode/reward_rate": 0.027777777777777776}
{"step": 1500096, "time": 46986.5242497921, "eval_episode/length": 58.0, "eval_episode/score": 0.8187500238418579, "eval_episode/reward_rate": 0.01694915254237288}
{"step": 1500096, "time": 46986.896104335785, "eval_episode/length": 76.0, "eval_episode/score": 0.762499988079071, "eval_episode/reward_rate": 0.012987012987012988}
{"step": 1500096, "time": 46987.00828123093, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 1500096, "time": 46987.32558989525, "eval_episode/length": 99.0, "eval_episode/score": 0.690625011920929, "eval_episode/reward_rate": 0.01}
{"step": 1500096, "time": 46987.790222644806, "eval_episode/length": 124.0, "eval_episode/score": 0.612500011920929, "eval_episode/reward_rate": 0.008}
{"step": 1500096, "time": 46987.87012696266, "eval_episode/length": 128.0, "eval_episode/score": 0.6000000238418579, "eval_episode/reward_rate": 0.007751937984496124}
{"step": 1500096, "time": 46987.98673534393, "eval_episode/length": 134.0, "eval_episode/score": 0.581250011920929, "eval_episode/reward_rate": 0.007407407407407408}
{"step": 1500184, "time": 46990.44182801247, "episode/length": 218.0, "episode/score": 0.3187499940395355, "episode/reward_rate": 0.0045662100456621, "episode/intrinsic_return": 0.0}
{"step": 1500248, "time": 46992.38479113579, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1500320, "time": 46994.85461783409, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1500536, "time": 47001.2402279377, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1500688, "time": 47006.04814052582, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1500792, "time": 47008.970791339874, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1500888, "time": 47011.86411499977, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 1500984, "time": 47014.80895614624, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1501072, "time": 47017.836176157, "episode/length": 220.0, "episode/score": 0.3125, "episode/reward_rate": 0.004524886877828055, "episode/intrinsic_return": 0.0}
{"step": 1501312, "time": 47025.09811115265, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1501448, "time": 47029.01336789131, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 1501544, "time": 47031.91191077232, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1501648, "time": 47035.308715581894, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1501824, "time": 47040.68044066429, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1501936, "time": 47044.10814523697, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1502136, "time": 47050.01876997948, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1502304, "time": 47055.34803175926, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1502360, "time": 47056.84264469147, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1502488, "time": 47060.721937417984, "episode/length": 279.0, "episode/score": 0.12812499701976776, "episode/reward_rate": 0.0035714285714285713, "episode/intrinsic_return": 0.0}
{"step": 1502528, "time": 47062.185630083084, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1502568, "time": 47063.18981385231, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 1502608, "time": 47064.648044109344, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1502792, "time": 47070.05328941345, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1502848, "time": 47072.01283955574, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1502976, "time": 47075.87707448006, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1503056, "time": 47078.4425239563, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1503152, "time": 47081.377203941345, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1503328, "time": 47086.68145442009, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1503336, "time": 47086.70790600777, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1503648, "time": 47096.36820459366, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1503704, "time": 47097.8536233902, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1503832, "time": 47101.74351787567, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1504128, "time": 47111.073894023895, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1504192, "time": 47113.00055217743, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1504248, "time": 47114.48137116432, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1504440, "time": 47120.33648586273, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1504448, "time": 47120.80710148811, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1504880, "time": 47133.87905716896, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1504920, "time": 47134.89549922943, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1505016, "time": 47137.95718359947, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1505032, "time": 47138.4485104084, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1505040, "time": 47138.914529800415, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1505272, "time": 47145.71444487572, "episode/length": 195.0, "episode/score": 0.390625, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.0}
{"step": 1505608, "time": 47155.886194229126, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 1505672, "time": 47157.823810338974, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1505736, "time": 47159.79312252998, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1506040, "time": 47169.11313843727, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1506112, "time": 47171.5194709301, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1506240, "time": 47175.45258283615, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1506392, "time": 47179.89239382744, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1506440, "time": 47181.34944367409, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1506536, "time": 47184.26339530945, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1506960, "time": 47197.4411816597, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1507096, "time": 47201.43444252014, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1507136, "time": 47202.88708400726, "episode/length": 182.0, "episode/score": 0.4312500059604645, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.0}
{"step": 1507168, "time": 47203.88311600685, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1507360, "time": 47210.226231098175, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1507776, "time": 47222.82557320595, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1507872, "time": 47225.75151968002, "episode/length": 203.0, "episode/score": 0.3656249940395355, "episode/reward_rate": 0.004901960784313725, "episode/intrinsic_return": 0.0}
{"step": 1507920, "time": 47227.294783592224, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1507960, "time": 47228.3255238533, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1508032, "time": 47230.728847026825, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1508200, "time": 47235.61685562134, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1508208, "time": 47236.085111141205, "episode/length": 220.0, "episode/score": 0.3125, "episode/reward_rate": 0.004524886877828055, "episode/intrinsic_return": 0.0}
{"step": 1508440, "time": 47242.88582253456, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1508672, "time": 47250.10688614845, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1508712, "time": 47251.0903236866, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 1508792, "time": 47253.51614904404, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 1508808, "time": 47254.001101017, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1509056, "time": 47261.80729150772, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1509144, "time": 47264.27265071869, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 1509160, "time": 47264.75938653946, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1509209, "time": 47267.245326280594, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.547942510925897, "train/action_min": 0.0, "train/action_std": 1.8275194681516969, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.009150736846518473, "train/actor_opt_grad_steps": 93215.0, "train/actor_opt_loss": -26.806174736211794, "train/adv_mag": 0.6059278249740601, "train/adv_max": 0.2657159667203922, "train/adv_mean": -1.041694259124642e-05, "train/adv_min": -0.536618451670845, "train/adv_std": 0.025245597489215066, "train/cont_avg": 0.9933042620668316, "train/cont_loss_mean": 0.029191200033586363, "train/cont_loss_std": 0.29986474595244716, "train/cont_neg_acc": 0.09007470065088415, "train/cont_neg_loss": 3.420314016033761, "train/cont_pos_acc": 0.9998589063634967, "train/cont_pos_loss": 0.006385274787000058, "train/cont_pred": 0.9930880028422516, "train/cont_rate": 0.9933042620668316, "train/dyn_loss_mean": 1.0000001982887192, "train/dyn_loss_std": 6.348923964444363e-06, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.1304933590685377, "train/extr_critic_critic_opt_grad_steps": 93215.0, "train/extr_critic_critic_opt_loss": 4218.5157277324415, "train/extr_critic_mag": 1.70088794679925, "train/extr_critic_max": 1.70088794679925, "train/extr_critic_mean": 1.5736151508765646, "train/extr_critic_min": 1.337382979912333, "train/extr_critic_std": 0.027106734232442215, "train/extr_return_normed_mag": 0.6108334111695243, "train/extr_return_normed_max": 0.2680790300416474, "train/extr_return_normed_mean": 0.056862962533636846, "train/extr_return_normed_min": -0.48110961855048, "train/extr_return_normed_std": 0.037828619250714186, "train/extr_return_rate": 0.9998085726015639, "train/extr_return_raw_mag": 1.7848207348644143, "train/extr_return_raw_max": 1.7848207348644143, "train/extr_return_raw_mean": 1.5736047489808338, "train/extr_return_raw_min": 1.035632086272287, "train/extr_return_raw_std": 0.03782861916772505, "train/extr_reward_mag": 0.23482473888019523, "train/extr_reward_max": 0.23482473888019523, "train/extr_reward_mean": 0.0028873721926039693, "train/extr_reward_min": 6.668638474870437e-08, "train/extr_reward_std": 0.008866466936830542, "train/image_loss_mean": 0.09095476475535053, "train/image_loss_std": 0.10302921847467965, "train/model_loss_mean": 0.7474799622403513, "train/model_loss_std": 0.6135007872587384, "train/model_opt_grad_norm": 14.212724449610945, "train/model_opt_grad_steps": 93130.11881188118, "train/model_opt_loss": 3975.5877625116027, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5346.534653465346, "train/policy_entropy_mag": 1.179929502529673, "train/policy_entropy_max": 1.179929502529673, "train/policy_entropy_mean": 0.08227548574899683, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.08917752417302367, "train/policy_logprob_mag": 6.551080295355013, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.08227288357839727, "train/policy_logprob_min": -6.551080295355013, "train/policy_logprob_std": 0.6197753229943832, "train/policy_randomness_mag": 0.6063638490320432, "train/policy_randomness_max": 0.6063638490320432, "train/policy_randomness_mean": 0.042281240796541227, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.04582818453707317, "train/post_ent_mag": 28.93933108301446, "train/post_ent_max": 28.93933108301446, "train/post_ent_mean": 28.251057558720653, "train/post_ent_min": 27.526100026498927, "train/post_ent_std": 0.29881036406991507, "train/prior_ent_mag": 28.443315789251045, "train/prior_ent_max": 28.443315789251045, "train/prior_ent_mean": 27.881769425798172, "train/prior_ent_min": 26.935150571388775, "train/prior_ent_std": 0.2552060143339752, "train/rep_loss_mean": 1.0000001982887192, "train/rep_loss_std": 6.348923964444363e-06, "train/reward_avg": 0.00362755803219596, "train/reward_loss_mean": 0.0273338527381789, "train/reward_loss_std": 0.3117167895364732, "train/reward_max_data": 0.820003095239696, "train/reward_max_pred": 0.31305179914625564, "train/reward_neg_acc": 0.9993632680708819, "train/reward_neg_loss": 0.005059775966680655, "train/reward_pos_acc": 0.11790309112463425, "train/reward_pos_loss": 4.11712556039516, "train/reward_pred": 0.0028987429513927954, "train/reward_rate": 0.005424272896039604, "train_stats/mean_log_entropy": 0.07585582424265642, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.019421467557549477, "report/cont_loss_std": 0.19874122738838196, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 3.1612610816955566, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.007100527640432119, "report/cont_pred": 0.9929212331771851, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.06203895062208176, "report/image_loss_std": 0.0785866379737854, "report/model_loss_mean": 0.7037781476974487, "report/model_loss_std": 0.48950889706611633, "report/post_ent_mag": 28.660375595092773, "report/post_ent_max": 28.660375595092773, "report/post_ent_mean": 28.041915893554688, "report/post_ent_min": 27.35623550415039, "report/post_ent_std": 0.29897651076316833, "report/prior_ent_mag": 28.45168685913086, "report/prior_ent_max": 28.45168685913086, "report/prior_ent_mean": 27.951467514038086, "report/prior_ent_min": 27.049999237060547, "report/prior_ent_std": 0.22330494225025177, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0025848387740552425, "report/reward_loss_mean": 0.022317741066217422, "report/reward_loss_std": 0.26022666692733765, "report/reward_max_data": 0.828125, "report/reward_max_pred": 0.08458006381988525, "report/reward_neg_acc": 0.9999999403953552, "report/reward_neg_loss": 0.006159662734717131, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.142627716064453, "report/reward_pred": 0.0031476502772420645, "report/reward_rate": 0.00390625, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.03547566756606102, "eval/cont_loss_std": 0.37544316053390503, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 4.632029056549072, "eval/cont_pos_acc": 0.9990177154541016, "eval/cont_pos_loss": 0.008383998647332191, "eval/cont_pred": 0.9932162165641785, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.13502489030361176, "eval/image_loss_std": 0.14153514802455902, "eval/model_loss_mean": 0.811734676361084, "eval/model_loss_std": 0.8744197487831116, "eval/post_ent_mag": 28.65851402282715, "eval/post_ent_max": 28.65851402282715, "eval/post_ent_mean": 28.065650939941406, "eval/post_ent_min": 27.31861686706543, "eval/post_ent_std": 0.32193195819854736, "eval/prior_ent_mag": 28.492938995361328, "eval/prior_ent_max": 28.492938995361328, "eval/prior_ent_mean": 27.962656021118164, "eval/prior_ent_min": 27.122241973876953, "eval/prior_ent_std": 0.22917237877845764, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.00437011756002903, "eval/reward_loss_mean": 0.04123412445187569, "eval/reward_loss_std": 0.4638421833515167, "eval/reward_max_data": 0.8531249761581421, "eval/reward_max_pred": 0.5837953090667725, "eval/reward_neg_acc": 0.9970530867576599, "eval/reward_neg_loss": 0.007457926869392395, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.771929740905762, "eval/reward_pred": 0.0033344211988151073, "eval/reward_rate": 0.005859375, "replay/size": 1000000.0, "replay/inserts": 32368.0, "replay/samples": 32368.0, "replay/insert_wait_avg": 1.1987811082433605e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.347679350320737e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3496.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0791577790912829e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.748603820800781e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2384243011475, "timer/env.step_count": 4046.0, "timer/env.step_total": 39.33105731010437, "timer/env.step_frac": 0.039321682065537954, "timer/env.step_avg": 0.00972097313645684, "timer/env.step_min": 0.0076160430908203125, "timer/env.step_max": 0.05576133728027344, "timer/replay._sample_count": 32368.0, "timer/replay._sample_total": 16.439871549606323, "timer/replay._sample_frac": 0.01643595281904175, "timer/replay._sample_avg": 0.0005079050775335616, "timer/replay._sample_min": 0.00040340423583984375, "timer/replay._sample_max": 0.011085748672485352, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4483.0, "timer/agent.policy_total": 47.428781270980835, "timer/agent.policy_frac": 0.04741747579245284, "timer/agent.policy_avg": 0.010579696915231059, "timer/agent.policy_min": 0.008712530136108398, "timer/agent.policy_max": 0.08412456512451172, "timer/dataset_train_count": 2023.0, "timer/dataset_train_total": 0.20850300788879395, "timer/dataset_train_frac": 0.00020845330755461835, "timer/dataset_train_avg": 0.00010306624215956201, "timer/dataset_train_min": 8.702278137207031e-05, "timer/dataset_train_max": 0.0003287792205810547, "timer/agent.train_count": 2023.0, "timer/agent.train_total": 902.8952579498291, "timer/agent.train_frac": 0.9026800370928255, "timer/agent.train_avg": 0.4463150064012996, "timer/agent.train_min": 0.4346020221710205, "timer/agent.train_max": 0.8075964450836182, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47051286697387695, "timer/agent.report_frac": 0.000470400712012856, "timer/agent.report_avg": 0.23525643348693848, "timer/agent.report_min": 0.22808504104614258, "timer/agent.report_max": 0.24242782592773438, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8133392333984375e-05, "timer/dataset_eval_frac": 2.812668624847199e-08, "timer/dataset_eval_avg": 2.8133392333984375e-05, "timer/dataset_eval_min": 2.8133392333984375e-05, "timer/dataset_eval_max": 2.8133392333984375e-05, "fps": 32.359748484173046}
{"step": 1509216, "time": 47267.26635360718, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1509248, "time": 47268.6026763916, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1509720, "time": 47282.78125047684, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 1509760, "time": 47284.22158789635, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1510032, "time": 47292.76669716835, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1510072, "time": 47293.77234125137, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1510080, "time": 47295.490496873856, "eval_episode/length": 56.0, "eval_episode/score": 0.824999988079071, "eval_episode/reward_rate": 0.017543859649122806}
{"step": 1510080, "time": 47295.62540960312, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 1510080, "time": 47296.11626410484, "eval_episode/length": 85.0, "eval_episode/score": 0.734375, "eval_episode/reward_rate": 0.011627906976744186}
{"step": 1510080, "time": 47296.72955536842, "eval_episode/length": 117.0, "eval_episode/score": 0.6343749761581421, "eval_episode/reward_rate": 0.00847457627118644}
{"step": 1510080, "time": 47296.95296740532, "eval_episode/length": 128.0, "eval_episode/score": 0.6000000238418579, "eval_episode/reward_rate": 0.007751937984496124}
{"step": 1510080, "time": 47297.43089175224, "eval_episode/length": 152.0, "eval_episode/score": 0.5249999761581421, "eval_episode/reward_rate": 0.006535947712418301}
{"step": 1510080, "time": 47297.4381480217, "eval_episode/length": 95.0, "eval_episode/score": 0.703125, "eval_episode/reward_rate": 0.010416666666666666}
{"step": 1510080, "time": 47297.48820281029, "eval_episode/length": 154.0, "eval_episode/score": 0.518750011920929, "eval_episode/reward_rate": 0.0064516129032258064}
{"step": 1510160, "time": 47299.961842536926, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1510216, "time": 47301.483906030655, "episode/length": 286.0, "episode/score": 0.10625000298023224, "episode/reward_rate": 0.003484320557491289, "episode/intrinsic_return": 0.0}
{"step": 1510256, "time": 47302.94728755951, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1510520, "time": 47310.73173260689, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1510624, "time": 47314.09805226326, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1510848, "time": 47321.01095581055, "episode/length": 210.0, "episode/score": 0.34375, "episode/reward_rate": 0.004739336492890996, "episode/intrinsic_return": 0.0}
{"step": 1511056, "time": 47327.307921886444, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1511120, "time": 47329.24144864082, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1511336, "time": 47335.57947063446, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1511400, "time": 47337.51876950264, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 1511744, "time": 47348.36777591705, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1511768, "time": 47348.889276981354, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1512328, "time": 47365.94582915306, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 1512352, "time": 47366.908408880234, "episode/length": 266.0, "episode/score": 0.16875000298023224, "episode/reward_rate": 0.003745318352059925, "episode/intrinsic_return": 0.0}
{"step": 1512384, "time": 47367.87749671936, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1512472, "time": 47370.335044145584, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1512656, "time": 47376.23128938675, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 1512808, "time": 47380.74604725838, "episode/length": 272.0, "episode/score": 0.15000000596046448, "episode/reward_rate": 0.003663003663003663, "episode/intrinsic_return": 0.0}
{"step": 1513032, "time": 47387.51447844505, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1513096, "time": 47389.46511006355, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 1513440, "time": 47400.07377099991, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1513552, "time": 47403.47550415993, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 1513648, "time": 47406.419123888016, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1513712, "time": 47408.45191812515, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1513864, "time": 47412.82210826874, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1514080, "time": 47419.621076345444, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1514200, "time": 47423.04868340492, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1514208, "time": 47423.51670217514, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 1514208, "time": 47423.525084495544, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1514568, "time": 47434.22366786003, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1514784, "time": 47441.09473848343, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1514840, "time": 47442.58147549629, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1514840, "time": 47442.58925461769, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1514864, "time": 47443.53945326805, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 1515344, "time": 47458.09870648384, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1515496, "time": 47462.49460601807, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1515856, "time": 47474.18310666084, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1515864, "time": 47474.210216999054, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1515872, "time": 47474.683779239655, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1515960, "time": 47477.1444208622, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1515968, "time": 47477.613736629486, "episode/length": 219.0, "episode/score": 0.31562501192092896, "episode/reward_rate": 0.004545454545454545, "episode/intrinsic_return": 0.0}
{"step": 1516024, "time": 47479.08396410942, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1516152, "time": 47482.95997977257, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 1516320, "time": 47488.245326280594, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1516616, "time": 47497.07985472679, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1516664, "time": 47498.534808158875, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1516752, "time": 47501.43355870247, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1516800, "time": 47502.88083410263, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1516832, "time": 47503.851647377014, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 1516848, "time": 47504.34378385544, "episode/length": 247.0, "episode/score": 0.22812500596046448, "episode/reward_rate": 0.004032258064516129, "episode/intrinsic_return": 0.0}
{"step": 1516968, "time": 47507.76746439934, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1517648, "time": 47528.719321489334, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1517648, "time": 47528.735171318054, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1517672, "time": 47529.258942604065, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1517952, "time": 47538.04832029343, "episode/length": 247.0, "episode/score": 0.22812500596046448, "episode/reward_rate": 0.004032258064516129, "episode/intrinsic_return": 0.0}
{"step": 1518032, "time": 47540.49943304062, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1518056, "time": 47541.007939338684, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 1518176, "time": 47544.86273241043, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1518320, "time": 47549.21007394791, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1518584, "time": 47557.09690928459, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1518704, "time": 47560.997441768646, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1518768, "time": 47562.96071124077, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1518856, "time": 47565.4546353817, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1519056, "time": 47571.72594809532, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1519112, "time": 47573.202112197876, "episode/length": 182.0, "episode/score": 0.4312500059604645, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.0}
{"step": 1519128, "time": 47573.68987107277, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1519144, "time": 47574.17778158188, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1519144, "time": 47574.18554854393, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1519280, "time": 47578.53846240044, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 1519856, "time": 47596.19944906235, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1519952, "time": 47599.11363148689, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1519984, "time": 47600.08160114288, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1519992, "time": 47600.10807991028, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1520008, "time": 47600.594442129135, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1520056, "time": 47602.05578994751, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 1520064, "time": 47603.72146272659, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 1520064, "time": 47603.83245706558, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 1520064, "time": 47603.96035385132, "eval_episode/length": 75.0, "eval_episode/score": 0.765625, "eval_episode/reward_rate": 0.013157894736842105}
{"step": 1520064, "time": 47604.14039826393, "eval_episode/length": 85.0, "eval_episode/score": 0.734375, "eval_episode/reward_rate": 0.011627906976744186}
{"step": 1520064, "time": 47604.26878285408, "eval_episode/length": 29.0, "eval_episode/score": 0.909375011920929, "eval_episode/reward_rate": 0.03333333333333333}
{"step": 1520064, "time": 47604.69620680809, "eval_episode/length": 46.0, "eval_episode/score": 0.856249988079071, "eval_episode/reward_rate": 0.02127659574468085}
{"step": 1520064, "time": 47605.27757191658, "eval_episode/length": 146.0, "eval_episode/score": 0.543749988079071, "eval_episode/reward_rate": 0.006802721088435374}
{"step": 1520064, "time": 47605.85995388031, "eval_episode/length": 101.0, "eval_episode/score": 0.684374988079071, "eval_episode/reward_rate": 0.00980392156862745}
{"step": 1520072, "time": 47605.884902477264, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 1520120, "time": 47607.350311756134, "episode/length": 15.0, "episode/score": 0.953125, "episode/reward_rate": 0.0625, "episode/intrinsic_return": 0.0}
{"step": 1520728, "time": 47625.83742976189, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1520784, "time": 47627.77259230614, "episode/length": 206.0, "episode/score": 0.35624998807907104, "episode/reward_rate": 0.004830917874396135, "episode/intrinsic_return": 0.0}
{"step": 1520880, "time": 47630.6792216301, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1521056, "time": 47635.98681998253, "episode/length": 238.0, "episode/score": 0.2562499940395355, "episode/reward_rate": 0.0041841004184100415, "episode/intrinsic_return": 0.0}
{"step": 1521112, "time": 47637.47737002373, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 1521128, "time": 47637.967659950256, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1521248, "time": 47641.82691526413, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 1521376, "time": 47645.68138003349, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 1521784, "time": 47657.909713983536, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1522000, "time": 47664.63112783432, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1522120, "time": 47668.05432629585, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 1522216, "time": 47670.97841715813, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1522232, "time": 47671.47090911865, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1522368, "time": 47675.80638933182, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1522576, "time": 47682.21001982689, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 1522800, "time": 47688.9793612957, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1523136, "time": 47699.13696408272, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1523152, "time": 47699.644355773926, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1523376, "time": 47706.41264343262, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 1523424, "time": 47707.95759296417, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1523440, "time": 47708.44867515564, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1523576, "time": 47712.34523844719, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1523648, "time": 47714.757367134094, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1524032, "time": 47726.83374047279, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1524048, "time": 47727.32292628288, "episode/length": 209.0, "episode/score": 0.34687501192092896, "episode/reward_rate": 0.004761904761904762, "episode/intrinsic_return": 0.0}
{"step": 1524096, "time": 47728.786650419235, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1524152, "time": 47730.28529906273, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1524264, "time": 47733.67789196968, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 1524312, "time": 47735.144765138626, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1524392, "time": 47737.65515065193, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1524504, "time": 47741.10185647011, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1524688, "time": 47746.87495326996, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1524792, "time": 47749.803560972214, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 1524896, "time": 47753.14084172249, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1524912, "time": 47753.64440369606, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1525160, "time": 47760.91603255272, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1525504, "time": 47771.63159775734, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1525616, "time": 47775.02817249298, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 1525688, "time": 47776.98717355728, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1525688, "time": 47776.993475437164, "episode/length": 206.0, "episode/score": 0.35624998807907104, "episode/reward_rate": 0.004830917874396135, "episode/intrinsic_return": 0.0}
{"step": 1526000, "time": 47786.67592549324, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1526248, "time": 47793.94637775421, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1526488, "time": 47801.31665086746, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1526592, "time": 47804.694910526276, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1526632, "time": 47805.688529491425, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 1526672, "time": 47807.14475560188, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 1526704, "time": 47808.11404514313, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1526736, "time": 47809.08758020401, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1526768, "time": 47810.05661416054, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 1526896, "time": 47813.942235946655, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1527224, "time": 47823.625380039215, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1527392, "time": 47829.00026702881, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1527416, "time": 47829.50766324997, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1527592, "time": 47834.82025694847, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1527640, "time": 47836.287727594376, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1527680, "time": 47837.71940493584, "episode/length": 10.0, "episode/score": 0.96875, "episode/reward_rate": 0.09090909090909091, "episode/intrinsic_return": 0.0}
{"step": 1527896, "time": 47844.030344724655, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1527992, "time": 47846.957825899124, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1528080, "time": 47849.85960936546, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1528096, "time": 47850.34745836258, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1528128, "time": 47851.33453798294, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 1528248, "time": 47854.74189257622, "episode/length": 206.0, "episode/score": 0.35624998807907104, "episode/reward_rate": 0.004830917874396135, "episode/intrinsic_return": 0.0}
{"step": 1528424, "time": 47860.2148938179, "episode/length": 218.0, "episode/score": 0.3187499940395355, "episode/reward_rate": 0.0045662100456621, "episode/intrinsic_return": 0.0}
{"step": 1528864, "time": 47873.79248547554, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1528904, "time": 47874.78395938873, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1528984, "time": 47877.218101501465, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1529072, "time": 47880.11363363266, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1529216, "time": 47884.46751356125, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1529728, "time": 47900.21231484413, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1529752, "time": 47900.724415779114, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1529792, "time": 47902.158901929855, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1529952, "time": 47907.03159451485, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1529992, "time": 47908.02792072296, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1530048, "time": 47910.86092209816, "eval_episode/length": 42.0, "eval_episode/score": 0.8687499761581421, "eval_episode/reward_rate": 0.023255813953488372}
{"step": 1530048, "time": 47911.18178629875, "eval_episode/length": 58.0, "eval_episode/score": 0.8187500238418579, "eval_episode/reward_rate": 0.01694915254237288}
{"step": 1530048, "time": 47911.87135696411, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 1530048, "time": 47911.897095918655, "eval_episode/length": 93.0, "eval_episode/score": 0.7093750238418579, "eval_episode/reward_rate": 0.010638297872340425}
{"step": 1530048, "time": 47912.002707481384, "eval_episode/length": 55.0, "eval_episode/score": 0.828125, "eval_episode/reward_rate": 0.017857142857142856}
{"step": 1530048, "time": 47912.14980626106, "eval_episode/length": 46.0, "eval_episode/score": 0.856249988079071, "eval_episode/reward_rate": 0.02127659574468085}
{"step": 1530048, "time": 47912.45564198494, "eval_episode/length": 120.0, "eval_episode/score": 0.625, "eval_episode/reward_rate": 0.008264462809917356}
{"step": 1530048, "time": 47912.78731131554, "eval_episode/length": 136.0, "eval_episode/score": 0.574999988079071, "eval_episode/reward_rate": 0.0072992700729927005}
{"step": 1530152, "time": 47915.72302722931, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1530192, "time": 47917.32249689102, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1530304, "time": 47920.75079870224, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1530520, "time": 47927.10986685753, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1530664, "time": 47931.45855689049, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1530768, "time": 47934.844739198685, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 1530880, "time": 47938.235048770905, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1530928, "time": 47939.69303703308, "episode/length": 252.0, "episode/score": 0.21250000596046448, "episode/reward_rate": 0.003952569169960474, "episode/intrinsic_return": 0.0}
{"step": 1531000, "time": 47941.66965198517, "episode/length": 14.0, "episode/score": 0.956250011920929, "episode/reward_rate": 0.06666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1531008, "time": 47942.13712596893, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1531016, "time": 47942.16384124756, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1531048, "time": 47943.12904167175, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1531072, "time": 47944.07448911667, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1531088, "time": 47944.564950466156, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1531656, "time": 47961.646144390106, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1531824, "time": 47966.96063041687, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1531840, "time": 47967.44866466522, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1531968, "time": 47971.80693387985, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1532168, "time": 47977.81891083717, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 1532600, "time": 47991.12073755264, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 1532688, "time": 47994.00252890587, "episode/length": 209.0, "episode/score": 0.34687501192092896, "episode/reward_rate": 0.004761904761904762, "episode/intrinsic_return": 0.0}
{"step": 1532752, "time": 47995.95571923256, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1532912, "time": 48000.793217659, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1532968, "time": 48002.271161317825, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1533280, "time": 48012.05379605293, "episode/length": 284.0, "episode/score": 0.11249999701976776, "episode/reward_rate": 0.0035087719298245615, "episode/intrinsic_return": 0.0}
{"step": 1533720, "time": 48025.23859524727, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1533736, "time": 48025.73168540001, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1534136, "time": 48037.98919916153, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1534152, "time": 48038.48213362694, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1534184, "time": 48039.45720410347, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 1534240, "time": 48041.40837574005, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 1534312, "time": 48043.35774087906, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1534704, "time": 48055.50323176384, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1534720, "time": 48055.99882268906, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1534728, "time": 48056.02816224098, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1534736, "time": 48056.50413060188, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1534904, "time": 48061.46504020691, "episode/length": 241.0, "episode/score": 0.24687500298023224, "episode/reward_rate": 0.004132231404958678, "episode/intrinsic_return": 0.0}
{"step": 1534912, "time": 48061.9408929348, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1535128, "time": 48068.321967840195, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1535368, "time": 48075.60013747215, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1535616, "time": 48083.34741401672, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 1535792, "time": 48088.6947324276, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1535856, "time": 48090.625256061554, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1535952, "time": 48093.56776857376, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 1536176, "time": 48100.51941943169, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 1536256, "time": 48102.96898460388, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1536376, "time": 48106.3915476799, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 1537056, "time": 48127.27805042267, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1537056, "time": 48127.290534973145, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1537088, "time": 48128.29928827286, "episode/length": 244.0, "episode/score": 0.23749999701976776, "episode/reward_rate": 0.004081632653061225, "episode/intrinsic_return": 0.0}
{"step": 1537216, "time": 48132.197408914566, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1537224, "time": 48132.22530698776, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1537392, "time": 48137.53974342346, "episode/length": 221.0, "episode/score": 0.30937498807907104, "episode/reward_rate": 0.0045045045045045045, "episode/intrinsic_return": 0.0}
{"step": 1537560, "time": 48142.39181017876, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 1537760, "time": 48148.672751665115, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1538104, "time": 48158.958941459656, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1538200, "time": 48161.87777471542, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1538232, "time": 48162.8438770771, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1538240, "time": 48163.30921292305, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1538472, "time": 48170.079971790314, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 1538592, "time": 48173.97072339058, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1539176, "time": 48191.50647711754, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1539192, "time": 48191.99691796303, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1539368, "time": 48197.38414335251, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1539392, "time": 48198.34040117264, "episode/length": 203.0, "episode/score": 0.3656249940395355, "episode/reward_rate": 0.004901960784313725, "episode/intrinsic_return": 0.0}
{"step": 1539472, "time": 48200.782210826874, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 1539600, "time": 48204.66539621353, "episode/length": 15.0, "episode/score": 0.953125, "episode/reward_rate": 0.0625, "episode/intrinsic_return": 0.0}
{"step": 1539712, "time": 48208.070996046066, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1539872, "time": 48212.92763090134, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1539872, "time": 48212.93739461899, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1540008, "time": 48216.96492600441, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 1540032, "time": 48219.51147532463, "eval_episode/length": 87.0, "eval_episode/score": 0.7281249761581421, "eval_episode/reward_rate": 0.011363636363636364}
{"step": 1540032, "time": 48219.80276155472, "eval_episode/length": 103.0, "eval_episode/score": 0.6781250238418579, "eval_episode/reward_rate": 0.009615384615384616}
{"step": 1540032, "time": 48220.32560014725, "eval_episode/length": 130.0, "eval_episode/score": 0.59375, "eval_episode/reward_rate": 0.007633587786259542}
{"step": 1540032, "time": 48220.36928343773, "eval_episode/length": 132.0, "eval_episode/score": 0.5874999761581421, "eval_episode/reward_rate": 0.007518796992481203}
{"step": 1540032, "time": 48220.627457141876, "eval_episode/length": 145.0, "eval_episode/score": 0.546875, "eval_episode/reward_rate": 0.00684931506849315}
{"step": 1540032, "time": 48221.25042104721, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 1540032, "time": 48221.56703853607, "eval_episode/length": 193.0, "eval_episode/score": 0.3968749940395355, "eval_episode/reward_rate": 0.005154639175257732}
{"step": 1540032, "time": 48221.70664477348, "eval_episode/length": 200.0, "eval_episode/score": 0.375, "eval_episode/reward_rate": 0.004975124378109453}
{"step": 1540128, "time": 48225.08518624306, "episode/length": 206.0, "episode/score": 0.35624998807907104, "episode/reward_rate": 0.004830917874396135, "episode/intrinsic_return": 0.0}
{"step": 1540216, "time": 48227.56347632408, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1540320, "time": 48231.00312066078, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1540384, "time": 48232.95031142235, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1540408, "time": 48233.46281695366, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 1540480, "time": 48235.89180469513, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1540544, "time": 48237.83292198181, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1541024, "time": 48252.54528880119, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1541168, "time": 48256.92105937004, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1541184, "time": 48257.41100478172, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1541224, "time": 48258.40809464455, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 1541304, "time": 48260.83930492401, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1541344, "time": 48262.27234363556, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1541472, "time": 48266.17307424545, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1541489, "time": 48267.3916516304, "train_stats/mean_log_entropy": 0.07833097510318043, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.549320636409344, "train/action_min": 0.0, "train/action_std": 1.8175446373401303, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.011357379028352328, "train/actor_opt_grad_steps": 95235.0, "train/actor_opt_loss": -30.679859208588553, "train/adv_mag": 0.7734749036850316, "train/adv_max": 0.27441586362253323, "train/adv_mean": 0.00189996363045307, "train/adv_min": -0.7306418528061102, "train/adv_std": 0.03185300506411655, "train/cont_avg": 0.9931060488861386, "train/cont_loss_mean": 0.03040267286434917, "train/cont_loss_std": 0.30749114964267993, "train/cont_neg_acc": 0.08690458491887196, "train/cont_neg_loss": 3.459177221992228, "train/cont_pos_acc": 0.999829640482912, "train/cont_pos_loss": 0.006496296755250285, "train/cont_pred": 0.9930288298885421, "train/cont_rate": 0.9931060488861386, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.15316296473956933, "train/extr_critic_critic_opt_grad_steps": 95235.0, "train/extr_critic_critic_opt_loss": 6218.219494508045, "train/extr_critic_mag": 1.746474831411154, "train/extr_critic_max": 1.746474831411154, "train/extr_critic_mean": 1.6069581349297326, "train/extr_critic_min": 1.3613445398831132, "train/extr_critic_std": 0.03251396834223282, "train/extr_return_normed_mag": 0.8004259564498863, "train/extr_return_normed_max": 0.2992587101341474, "train/extr_return_normed_mean": 0.07038802908051132, "train/extr_return_normed_min": -0.6839153669258156, "train/extr_return_normed_std": 0.04676890353865848, "train/extr_return_rate": 0.9996819171575037, "train/extr_return_raw_mag": 1.8377286844914502, "train/extr_return_raw_max": 1.8377286844914502, "train/extr_return_raw_mean": 1.608858084324563, "train/extr_return_raw_min": 0.8545546074314873, "train/extr_return_raw_std": 0.046768903630868636, "train/extr_reward_mag": 0.26058778373321684, "train/extr_reward_max": 0.26058778373321684, "train/extr_reward_mean": 0.0030865498627121054, "train/extr_reward_min": 4.0720004846553994e-08, "train/extr_reward_std": 0.010053232932315753, "train/image_loss_mean": 0.09150093083850819, "train/image_loss_std": 0.10375906929078668, "train/model_loss_mean": 0.7498019148807714, "train/model_loss_std": 0.6223179769545498, "train/model_opt_grad_norm": 14.413033428476817, "train/model_opt_grad_steps": 95148.36633663367, "train/model_opt_loss": 4345.726639851485, "train/model_opt_model_opt_grad_overflow": 0.0049504950495049506, "train/model_opt_model_opt_grad_scale": 5767.3267326732675, "train/policy_entropy_mag": 1.1617038745691282, "train/policy_entropy_max": 1.1617038745691282, "train/policy_entropy_mean": 0.08223051695835472, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.08935092850634367, "train/policy_logprob_mag": 6.551080307157913, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.0827328518844477, "train/policy_logprob_min": -6.551080307157913, "train/policy_logprob_std": 0.6223910539457114, "train/policy_randomness_mag": 0.5969977333108978, "train/policy_randomness_max": 0.5969977333108978, "train/policy_randomness_mean": 0.042258131161037056, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.04591729687434612, "train/post_ent_mag": 29.155531552758546, "train/post_ent_max": 29.155531552758546, "train/post_ent_mean": 28.351229629894295, "train/post_ent_min": 27.547613738787057, "train/post_ent_std": 0.34061482430684686, "train/prior_ent_mag": 28.457265608381515, "train/prior_ent_max": 28.457265608381515, "train/prior_ent_mean": 27.953931053086084, "train/prior_ent_min": 27.126686624961323, "train/prior_ent_std": 0.21215214565543844, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.00370134408660648, "train/reward_loss_mean": 0.027898289931772072, "train/reward_loss_std": 0.31448682500879366, "train/reward_max_data": 0.8220606434463275, "train/reward_max_pred": 0.3248414149378786, "train/reward_neg_acc": 0.9994121323717703, "train/reward_neg_loss": 0.005182124236321981, "train/reward_pos_acc": 0.12306177269409199, "train/reward_pos_loss": 4.113582220407996, "train/reward_pred": 0.0029452809623654675, "train/reward_rate": 0.005530631188118812, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.03223061189055443, "report/cont_loss_std": 0.3355099856853485, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 3.900822162628174, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0056031388230621815, "report/cont_pred": 0.9943554401397705, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.09154287725687027, "report/image_loss_std": 0.10498090088367462, "report/model_loss_mean": 0.7417207360267639, "report/model_loss_std": 0.5395574569702148, "report/post_ent_mag": 29.997478485107422, "report/post_ent_max": 29.997478485107422, "report/post_ent_mean": 28.83161163330078, "report/post_ent_min": 27.805389404296875, "report/post_ent_std": 0.45310917496681213, "report/prior_ent_mag": 28.47417449951172, "report/prior_ent_max": 28.47417449951172, "report/prior_ent_mean": 27.97158432006836, "report/prior_ent_min": 27.227272033691406, "report/prior_ent_std": 0.20100125670433044, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0019348144996911287, "report/reward_loss_mean": 0.017947198823094368, "report/reward_loss_std": 0.24565564095973969, "report/reward_max_data": 0.8031250238418579, "report/reward_max_pred": 0.12141501903533936, "report/reward_neg_acc": 0.9980410933494568, "report/reward_neg_loss": 0.004670002963393927, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.536620140075684, "report/reward_pred": 0.002426587510854006, "report/reward_rate": 0.0029296875, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.03314574807882309, "eval/cont_loss_std": 0.3792648911476135, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 4.641055107116699, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.005987147334963083, "eval/cont_pred": 0.9940424561500549, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.092303067445755, "eval/image_loss_std": 0.09881320595741272, "eval/model_loss_mean": 0.7556073665618896, "eval/model_loss_std": 0.7668026089668274, "eval/post_ent_mag": 29.972854614257812, "eval/post_ent_max": 29.972854614257812, "eval/post_ent_mean": 28.866573333740234, "eval/post_ent_min": 27.832670211791992, "eval/post_ent_std": 0.45220082998275757, "eval/prior_ent_mag": 28.481904983520508, "eval/prior_ent_max": 28.481904983520508, "eval/prior_ent_mean": 27.982322692871094, "eval/prior_ent_min": 27.187807083129883, "eval/prior_ent_std": 0.21363948285579681, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0035675049293786287, "eval/reward_loss_mean": 0.030158545821905136, "eval/reward_loss_std": 0.3868322968482971, "eval/reward_max_data": 0.8125, "eval/reward_max_pred": 0.061211228370666504, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.004591279197484255, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.240767002105713, "eval/reward_pred": 0.0024151799734681845, "eval/reward_rate": 0.0048828125, "replay/size": 1000000.0, "replay/inserts": 32280.0, "replay/samples": 32272.0, "replay/insert_wait_avg": 1.1787243196659962e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.183364434116952e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5368.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.108770754227162e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.344650268554688e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0076336860657, "timer/env.step_count": 4035.0, "timer/env.step_total": 38.897167444229126, "timer/env.step_frac": 0.03889687051773066, "timer/env.step_avg": 0.009639942365360378, "timer/env.step_min": 0.007584571838378906, "timer/env.step_max": 0.03555011749267578, "timer/replay._sample_count": 32272.0, "timer/replay._sample_total": 16.34989070892334, "timer/replay._sample_frac": 0.016349765899943212, "timer/replay._sample_avg": 0.0005066277487891466, "timer/replay._sample_min": 0.0004200935363769531, "timer/replay._sample_max": 0.025228261947631836, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4706.0, "timer/agent.policy_total": 49.25830602645874, "timer/agent.policy_frac": 0.049257930006884824, "timer/agent.policy_avg": 0.010467128352413672, "timer/agent.policy_min": 0.008707523345947266, "timer/agent.policy_max": 0.07469606399536133, "timer/dataset_train_count": 2017.0, "timer/dataset_train_total": 0.2100389003753662, "timer/dataset_train_frac": 0.0002100372970165787, "timer/dataset_train_avg": 0.00010413430856488162, "timer/dataset_train_min": 8.988380432128906e-05, "timer/dataset_train_max": 0.000865936279296875, "timer/agent.train_count": 2017.0, "timer/agent.train_total": 898.8306887149811, "timer/agent.train_frac": 0.8988238273760546, "timer/agent.train_avg": 0.4456275105180868, "timer/agent.train_min": 0.4362201690673828, "timer/agent.train_max": 0.6691124439239502, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4766385555267334, "timer/agent.report_frac": 0.0004766349170454087, "timer/agent.report_avg": 0.2383192777633667, "timer/agent.report_min": 0.23000144958496094, "timer/agent.report_max": 0.24663710594177246, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0279159545898438e-05, "timer/dataset_eval_frac": 3.0278928406064584e-08, "timer/dataset_eval_avg": 3.0279159545898438e-05, "timer/dataset_eval_min": 3.0279159545898438e-05, "timer/dataset_eval_max": 3.0279159545898438e-05, "fps": 32.27917915702589}
{"step": 1541520, "time": 48268.54101395607, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1541544, "time": 48269.05431389809, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 1541712, "time": 48274.39098024368, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1541816, "time": 48277.37610530853, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1541944, "time": 48281.25176978111, "episode/length": 15.0, "episode/score": 0.953125, "episode/reward_rate": 0.0625, "episode/intrinsic_return": 0.0}
{"step": 1542128, "time": 48287.04633760452, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1542720, "time": 48305.007682323456, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1542744, "time": 48305.51693844795, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1542936, "time": 48311.41641139984, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1542992, "time": 48313.35645222664, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 1543128, "time": 48317.263659477234, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 1543184, "time": 48319.2306330204, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1543368, "time": 48324.68839478493, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1543504, "time": 48329.06545209885, "episode/length": 247.0, "episode/score": 0.22812500596046448, "episode/reward_rate": 0.004032258064516129, "episode/intrinsic_return": 0.0}
{"step": 1543624, "time": 48332.466609478, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1543656, "time": 48333.466093063354, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1543784, "time": 48337.458705186844, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1544120, "time": 48347.60220360756, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1544168, "time": 48349.065742731094, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1544200, "time": 48350.0361559391, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1544392, "time": 48355.84565091133, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1544480, "time": 48358.78772687912, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1545176, "time": 48379.89053726196, "episode/length": 248.0, "episode/score": 0.22499999403953552, "episode/reward_rate": 0.004016064257028112, "episode/intrinsic_return": 0.0}
{"step": 1545248, "time": 48382.30636191368, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1545344, "time": 48385.196531534195, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1545440, "time": 48388.10794758797, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1545520, "time": 48390.52883934975, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 1545680, "time": 48395.38419628143, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1546024, "time": 48405.80345869064, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1546024, "time": 48405.81230998039, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1546168, "time": 48410.23650884628, "episode/length": 210.0, "episode/score": 0.34375, "episode/reward_rate": 0.004739336492890996, "episode/intrinsic_return": 0.0}
{"step": 1546184, "time": 48410.72663664818, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1546432, "time": 48418.48868227005, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1546464, "time": 48419.45794391632, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1546480, "time": 48419.948123693466, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1546800, "time": 48429.71347641945, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 1547096, "time": 48438.447056770325, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1547120, "time": 48439.40213108063, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1547176, "time": 48440.8959915638, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1547176, "time": 48440.90487265587, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1547176, "time": 48440.91242170334, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1547208, "time": 48441.876866817474, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1547208, "time": 48441.88544034958, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1547384, "time": 48447.199769973755, "episode/length": 212.0, "episode/score": 0.3375000059604645, "episode/reward_rate": 0.004694835680751174, "episode/intrinsic_return": 0.0}
{"step": 1547432, "time": 48448.64919257164, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 1547768, "time": 48458.89719367027, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1547912, "time": 48463.26796531677, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1547968, "time": 48465.205914735794, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1548048, "time": 48467.61832475662, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1548072, "time": 48468.12353396416, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 1548168, "time": 48471.03678536415, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1548280, "time": 48474.430215358734, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1548568, "time": 48483.60154891014, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1548712, "time": 48488.04292225838, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1548832, "time": 48491.8837184906, "episode/length": 202.0, "episode/score": 0.3687500059604645, "episode/reward_rate": 0.0049261083743842365, "episode/intrinsic_return": 0.0}
{"step": 1548992, "time": 48496.78542518616, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 1549008, "time": 48497.2802233696, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1549128, "time": 48500.74960231781, "episode/length": 217.0, "episode/score": 0.3218750059604645, "episode/reward_rate": 0.0045871559633027525, "episode/intrinsic_return": 0.0}
{"step": 1549152, "time": 48501.69998073578, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1549272, "time": 48505.14295339584, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1549760, "time": 48520.24496412277, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1550016, "time": 48529.61104154587, "eval_episode/length": 93.0, "eval_episode/score": 0.7093750238418579, "eval_episode/reward_rate": 0.010638297872340425}
{"step": 1550016, "time": 48529.77590918541, "eval_episode/length": 102.0, "eval_episode/score": 0.6812499761581421, "eval_episode/reward_rate": 0.009708737864077669}
{"step": 1550016, "time": 48530.87196516991, "eval_episode/length": 128.0, "eval_episode/score": 0.6000000238418579, "eval_episode/reward_rate": 0.007751937984496124}
{"step": 1550016, "time": 48531.007556438446, "eval_episode/length": 135.0, "eval_episode/score": 0.578125, "eval_episode/reward_rate": 0.007352941176470588}
{"step": 1550016, "time": 48531.03065633774, "eval_episode/length": 136.0, "eval_episode/score": 0.574999988079071, "eval_episode/reward_rate": 0.0072992700729927005}
{"step": 1550016, "time": 48531.51327204704, "eval_episode/length": 27.0, "eval_episode/score": 0.9156249761581421, "eval_episode/reward_rate": 0.03571428571428571}
{"step": 1550016, "time": 48531.62735414505, "eval_episode/length": 169.0, "eval_episode/score": 0.47187501192092896, "eval_episode/reward_rate": 0.0058823529411764705}
{"step": 1550016, "time": 48531.79594731331, "eval_episode/length": 49.0, "eval_episode/score": 0.846875011920929, "eval_episode/reward_rate": 0.02}
{"step": 1550224, "time": 48538.10000824928, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1550472, "time": 48545.364319086075, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 1550592, "time": 48549.33518362045, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1550704, "time": 48552.73087835312, "episode/length": 211.0, "episode/score": 0.34062498807907104, "episode/reward_rate": 0.0047169811320754715, "episode/intrinsic_return": 0.0}
{"step": 1550720, "time": 48553.22243928909, "episode/length": 235.0, "episode/score": 0.265625, "episode/reward_rate": 0.00423728813559322, "episode/intrinsic_return": 0.0}
{"step": 1551056, "time": 48563.41976237297, "episode/length": 240.0, "episode/score": 0.25, "episode/reward_rate": 0.004149377593360996, "episode/intrinsic_return": 0.0}
{"step": 1551232, "time": 48568.751146793365, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1551536, "time": 48578.01489973068, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1551584, "time": 48579.46446490288, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1551640, "time": 48580.95989441872, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1551840, "time": 48587.21305537224, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 1552072, "time": 48593.99681711197, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1552360, "time": 48602.69395279884, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 1552384, "time": 48603.640233278275, "episode/length": 207.0, "episode/score": 0.3531250059604645, "episode/reward_rate": 0.004807692307692308, "episode/intrinsic_return": 0.0}
{"step": 1552440, "time": 48605.127938747406, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1552464, "time": 48606.074654340744, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1552600, "time": 48610.050372600555, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1552656, "time": 48611.95863032341, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1553152, "time": 48627.0624358654, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1553328, "time": 48632.42003822327, "episode/length": 223.0, "episode/score": 0.3031249940395355, "episode/reward_rate": 0.004464285714285714, "episode/intrinsic_return": 0.0}
{"step": 1553336, "time": 48632.447101831436, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1553368, "time": 48633.41990375519, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1553656, "time": 48642.27560520172, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 1553920, "time": 48650.49249148369, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 1553920, "time": 48650.50147652626, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1554112, "time": 48656.340933799744, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1554232, "time": 48659.796825647354, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1554392, "time": 48664.68409895897, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 1554496, "time": 48668.169290304184, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1554680, "time": 48673.5448076725, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1554752, "time": 48675.942858695984, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1554856, "time": 48678.87863135338, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1554968, "time": 48682.270577430725, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1555248, "time": 48690.99285244942, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 1555400, "time": 48695.35879802704, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1555440, "time": 48696.87457680702, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 1555504, "time": 48698.83163237572, "episode/length": 266.0, "episode/score": 0.16875000298023224, "episode/reward_rate": 0.003745318352059925, "episode/intrinsic_return": 0.0}
{"step": 1555528, "time": 48699.33935189247, "episode/length": 233.0, "episode/score": 0.2718749940395355, "episode/reward_rate": 0.004273504273504274, "episode/intrinsic_return": 0.0}
{"step": 1555696, "time": 48704.669783353806, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1555704, "time": 48704.69695854187, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1555816, "time": 48708.083183288574, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1556080, "time": 48716.25013113022, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1556352, "time": 48724.464247465134, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1556560, "time": 48731.372717380524, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1556648, "time": 48733.87753582001, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1556648, "time": 48733.884963274, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 1557000, "time": 48744.535974025726, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 1557000, "time": 48744.54352402687, "episode/length": 280.0, "episode/score": 0.125, "episode/reward_rate": 0.0035587188612099642, "episode/intrinsic_return": 0.0}
{"step": 1557640, "time": 48763.94388818741, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1557832, "time": 48769.73520255089, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1557840, "time": 48770.20214486122, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 1557856, "time": 48770.69143605232, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1557864, "time": 48770.72044634819, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 1558016, "time": 48775.52977848053, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1558088, "time": 48777.48674559593, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 1558200, "time": 48780.86659836769, "episode/length": 13.0, "episode/score": 0.9593750238418579, "episode/reward_rate": 0.07142857142857142, "episode/intrinsic_return": 0.0}
{"step": 1558384, "time": 48786.79338431358, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1558392, "time": 48786.82188796997, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1558608, "time": 48793.601091623306, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1558664, "time": 48795.10702943802, "episode/length": 251.0, "episode/score": 0.21562500298023224, "episode/reward_rate": 0.003968253968253968, "episode/intrinsic_return": 0.0}
{"step": 1558680, "time": 48795.622004032135, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 1558896, "time": 48802.41998386383, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1559096, "time": 48808.24930405617, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 1559104, "time": 48808.71799993515, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1559176, "time": 48810.6959528923, "episode/length": 191.0, "episode/score": 0.40312498807907104, "episode/reward_rate": 0.005208333333333333, "episode/intrinsic_return": 0.0}
{"step": 1559376, "time": 48817.03021478653, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 1559464, "time": 48819.47611451149, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1559672, "time": 48825.78157663345, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1559800, "time": 48829.683573246, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 1559944, "time": 48834.055064201355, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1560000, "time": 48836.40438199043, "eval_episode/length": 19.0, "eval_episode/score": 0.940625011920929, "eval_episode/reward_rate": 0.05}
{"step": 1560000, "time": 48837.02820849419, "eval_episode/length": 51.0, "eval_episode/score": 0.840624988079071, "eval_episode/reward_rate": 0.019230769230769232}
{"step": 1560000, "time": 48837.0355758667, "eval_episode/length": 51.0, "eval_episode/score": 0.840624988079071, "eval_episode/reward_rate": 0.019230769230769232}
{"step": 1560000, "time": 48837.76802921295, "eval_episode/length": 37.0, "eval_episode/score": 0.8843749761581421, "eval_episode/reward_rate": 0.02631578947368421}
{"step": 1560000, "time": 48837.853658914566, "eval_episode/length": 93.0, "eval_episode/score": 0.7093750238418579, "eval_episode/reward_rate": 0.010638297872340425}
{"step": 1560000, "time": 48837.9595143795, "eval_episode/length": 78.0, "eval_episode/score": 0.7562500238418579, "eval_episode/reward_rate": 0.012658227848101266}
{"step": 1560000, "time": 48838.478833436966, "eval_episode/length": 72.0, "eval_episode/score": 0.7749999761581421, "eval_episode/reward_rate": 0.0136986301369863}
{"step": 1560000, "time": 48838.48653912544, "eval_episode/length": 25.0, "eval_episode/score": 0.921875, "eval_episode/reward_rate": 0.038461538461538464}
{"step": 1560032, "time": 48839.46659350395, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1560112, "time": 48841.938398599625, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1560272, "time": 48846.84868788719, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1560408, "time": 48850.739483356476, "episode/length": 215.0, "episode/score": 0.328125, "episode/reward_rate": 0.004629629629629629, "episode/intrinsic_return": 0.0}
{"step": 1560464, "time": 48852.667274951935, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 1560512, "time": 48854.12354874611, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1560712, "time": 48860.00211787224, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1560872, "time": 48864.86353421211, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 1560968, "time": 48867.77421951294, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1560976, "time": 48868.24240517616, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1561160, "time": 48873.56686282158, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 1561208, "time": 48875.01818013191, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1561232, "time": 48875.988996744156, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1561240, "time": 48876.300577402115, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1561552, "time": 48886.077667951584, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1562048, "time": 48901.12701010704, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1562216, "time": 48906.0094435215, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1562256, "time": 48907.51332139969, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1562744, "time": 48922.06425285339, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1562792, "time": 48923.51625108719, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1562896, "time": 48926.89975833893, "episode/length": 239.0, "episode/score": 0.25312501192092896, "episode/reward_rate": 0.004166666666666667, "episode/intrinsic_return": 0.0}
{"step": 1563184, "time": 48935.60271668434, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1563224, "time": 48936.67200136185, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1563280, "time": 48938.59289765358, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1563352, "time": 48940.571264743805, "episode/length": 263.0, "episode/score": 0.17812499403953552, "episode/reward_rate": 0.003787878787878788, "episode/intrinsic_return": 0.0}
{"step": 1563472, "time": 48944.41817474365, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1563672, "time": 48950.248478889465, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1564248, "time": 48967.78174781799, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 1564320, "time": 48970.23476409912, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1564360, "time": 48971.23943376541, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1564488, "time": 48975.17556142807, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 1564504, "time": 48975.66667628288, "episode/length": 17.0, "episode/score": 0.9468749761581421, "episode/reward_rate": 0.05555555555555555, "episode/intrinsic_return": 0.0}
{"step": 1564728, "time": 48982.93190217018, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1564984, "time": 48990.74256539345, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 1565048, "time": 48992.6799929142, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1565208, "time": 48997.573932647705, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1565400, "time": 49003.4006857872, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 1565496, "time": 49006.30341434479, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1565592, "time": 49009.22866868973, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1565784, "time": 49015.05125164986, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1565912, "time": 49018.92281341553, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1565960, "time": 49020.38097000122, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1565984, "time": 49021.33812904358, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1566128, "time": 49025.70664525032, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1566384, "time": 49033.57561826706, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1566520, "time": 49037.49727988243, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1566528, "time": 49037.96937298775, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1566688, "time": 49042.82704091072, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1566800, "time": 49046.207607507706, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1567064, "time": 49054.05034852028, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1567184, "time": 49058.02441596985, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 1567296, "time": 49061.40556550026, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1567312, "time": 49061.91382932663, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1567928, "time": 49080.23773288727, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1568056, "time": 49084.107513427734, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 1568120, "time": 49086.04229044914, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1568136, "time": 49086.58292913437, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 1568160, "time": 49087.555981874466, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1568392, "time": 49094.36394095421, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 1568440, "time": 49095.839843034744, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1568616, "time": 49101.15431809425, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1568664, "time": 49102.61105751991, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1568840, "time": 49107.90561032295, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1569024, "time": 49113.64440727234, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1569376, "time": 49124.353675842285, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1569384, "time": 49124.379882097244, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1569440, "time": 49126.295003414154, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1569480, "time": 49127.27611017227, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 1569768, "time": 49135.96297740936, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 1569976, "time": 49142.2503592968, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1570088, "time": 49146.06891775131, "eval_episode/length": 20.0, "eval_episode/score": 0.9375, "eval_episode/reward_rate": 0.047619047619047616}
{"step": 1570088, "time": 49146.6594479084, "eval_episode/length": 44.0, "eval_episode/score": 0.862500011920929, "eval_episode/reward_rate": 0.022222222222222223}
{"step": 1570088, "time": 49147.37546634674, "eval_episode/length": 81.0, "eval_episode/score": 0.746874988079071, "eval_episode/reward_rate": 0.012195121951219513}
{"step": 1570088, "time": 49147.64701461792, "eval_episode/length": 96.0, "eval_episode/score": 0.699999988079071, "eval_episode/reward_rate": 0.010309278350515464}
{"step": 1570088, "time": 49147.974142313, "eval_episode/length": 114.0, "eval_episode/score": 0.643750011920929, "eval_episode/reward_rate": 0.008695652173913044}
{"step": 1570088, "time": 49148.03294968605, "eval_episode/length": 117.0, "eval_episode/score": 0.6343749761581421, "eval_episode/reward_rate": 0.00847457627118644}
{"step": 1570088, "time": 49148.34570837021, "eval_episode/length": 112.0, "eval_episode/score": 0.6499999761581421, "eval_episode/reward_rate": 0.008849557522123894}
{"step": 1570088, "time": 49148.79356622696, "eval_episode/length": 156.0, "eval_episode/score": 0.512499988079071, "eval_episode/reward_rate": 0.006369426751592357}
{"step": 1570176, "time": 49151.6846101284, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1570216, "time": 49152.700652360916, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1570672, "time": 49166.76771116257, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1570704, "time": 49167.738352775574, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1570760, "time": 49169.21451377869, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1570936, "time": 49174.57365441322, "episode/length": 238.0, "episode/score": 0.2562499940395355, "episode/reward_rate": 0.0041841004184100415, "episode/intrinsic_return": 0.0}
{"step": 1570960, "time": 49175.52318263054, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 1570976, "time": 49176.011826992035, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1571152, "time": 49181.39869880676, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 1571680, "time": 49197.375707149506, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1571752, "time": 49199.3524582386, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1571840, "time": 49202.2604060173, "episode/length": 258.0, "episode/score": 0.19374999403953552, "episode/reward_rate": 0.003861003861003861, "episode/intrinsic_return": 0.0}
{"step": 1572008, "time": 49207.26651406288, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1572120, "time": 49210.68442630768, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 1572272, "time": 49215.53113698959, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1572416, "time": 49219.93944358826, "episode/length": 217.0, "episode/score": 0.3218750059604645, "episode/reward_rate": 0.0045871559633027525, "episode/intrinsic_return": 0.0}
{"step": 1572496, "time": 49222.3913795948, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1572560, "time": 49224.33450913429, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 1572672, "time": 49227.794459581375, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1573032, "time": 49239.255450725555, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1573128, "time": 49242.18357586861, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1573216, "time": 49245.0529153347, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1573232, "time": 49245.55811524391, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1573272, "time": 49246.54999470711, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1573808, "time": 49263.041504859924, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1573929, "time": 49267.665746450424, "train_stats/mean_log_entropy": 0.07717695303129411, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.575332716768011, "train/action_min": 0.0, "train/action_std": 1.8100839536178288, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.011683346291893881, "train/actor_opt_grad_steps": 97260.0, "train/actor_opt_loss": -34.46359273600461, "train/adv_mag": 0.7627683948413492, "train/adv_max": 0.30291419604728964, "train/adv_mean": 0.0001955654613326269, "train/adv_min": -0.6860217971754778, "train/adv_std": 0.03234267922971636, "train/cont_avg": 0.9930678494458128, "train/cont_loss_mean": 0.0303015659099876, "train/cont_loss_std": 0.3066434686627294, "train/cont_neg_acc": 0.08099549755527469, "train/cont_neg_loss": 3.46032198074416, "train/cont_pos_acc": 0.9998594912989386, "train/cont_pos_loss": 0.006410008094507485, "train/cont_pred": 0.9930716594451754, "train/cont_rate": 0.9930678494458128, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.12074432277070184, "train/extr_critic_critic_opt_grad_steps": 97260.0, "train/extr_critic_critic_opt_loss": 8420.839836534022, "train/extr_critic_mag": 1.7798478027869915, "train/extr_critic_max": 1.7798478027869915, "train/extr_critic_mean": 1.6373205789791538, "train/extr_critic_min": 1.3517512182884028, "train/extr_critic_std": 0.032505146369998676, "train/extr_return_normed_mag": 0.7648273465668627, "train/extr_return_normed_max": 0.3105772175812369, "train/extr_return_normed_mean": 0.072211053038906, "train/extr_return_normed_min": -0.6282946317653938, "train/extr_return_normed_std": 0.04679687401931274, "train/extr_return_rate": 0.9996966293879918, "train/extr_return_raw_mag": 1.8758822591433972, "train/extr_return_raw_max": 1.8758822591433972, "train/extr_return_raw_mean": 1.6375161767593158, "train/extr_return_raw_min": 0.9370104097967664, "train/extr_return_raw_std": 0.04679687402848833, "train/extr_reward_mag": 0.26155729364291785, "train/extr_reward_max": 0.26155729364291785, "train/extr_reward_mean": 0.0029447140754773993, "train/extr_reward_min": 2.2315039423298952e-08, "train/extr_reward_std": 0.009147725116204599, "train/image_loss_mean": 0.09213430696887336, "train/image_loss_std": 0.10401033261433024, "train/model_loss_mean": 0.7510336012088606, "train/model_loss_std": 0.6292553072052048, "train/model_opt_grad_norm": 13.762574207606574, "train/model_opt_grad_steps": 97171.49753694581, "train/model_opt_loss": 3865.2717429475833, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5147.783251231527, "train/policy_entropy_mag": 1.1667440665766524, "train/policy_entropy_max": 1.1667440665766524, "train/policy_entropy_mean": 0.08162728568603253, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.08802693880397111, "train/policy_logprob_mag": 6.551080278575127, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.08174930512905121, "train/policy_logprob_min": -6.551080278575127, "train/policy_logprob_std": 0.6198123320570132, "train/policy_randomness_mag": 0.5995878760744198, "train/policy_randomness_max": 0.5995878760744198, "train/policy_randomness_mean": 0.04194813183155553, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.045236900742418075, "train/post_ent_mag": 29.275913727107305, "train/post_ent_max": 29.275913727107305, "train/post_ent_mean": 28.361423483035836, "train/post_ent_min": 27.45377518978025, "train/post_ent_std": 0.3913472460702135, "train/prior_ent_mag": 28.34674560847541, "train/prior_ent_max": 28.34674560847541, "train/prior_ent_mean": 27.820009438275118, "train/prior_ent_min": 26.908912141922073, "train/prior_ent_std": 0.22655359747374587, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.003753301321375161, "train/reward_loss_mean": 0.02859770396513305, "train/reward_loss_std": 0.3202833100887282, "train/reward_max_data": 0.819350369751747, "train/reward_max_pred": 0.30136899172966114, "train/reward_neg_acc": 0.9994050311337551, "train/reward_neg_loss": 0.005147445271378888, "train/reward_pos_acc": 0.10226612161881853, "train/reward_pos_loss": 4.187174267107897, "train/reward_pred": 0.002912189012044683, "train/reward_rate": 0.00561403171182266, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.024925783276557922, "report/cont_loss_std": 0.29228416085243225, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 3.792945146560669, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.006436975207179785, "report/cont_pred": 0.9933633208274841, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.0705103799700737, "report/image_loss_std": 0.08827974647283554, "report/model_loss_mean": 0.7160041332244873, "report/model_loss_std": 0.5348015427589417, "report/post_ent_mag": 31.572696685791016, "report/post_ent_max": 31.572696685791016, "report/post_ent_mean": 29.14862060546875, "report/post_ent_min": 27.650814056396484, "report/post_ent_std": 0.810651957988739, "report/prior_ent_mag": 28.129831314086914, "report/prior_ent_max": 28.129831314086914, "report/prior_ent_mean": 27.555906295776367, "report/prior_ent_min": 26.720947265625, "report/prior_ent_std": 0.23523712158203125, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0028320313431322575, "report/reward_loss_mean": 0.020567983388900757, "report/reward_loss_std": 0.25922706723213196, "report/reward_max_data": 0.871874988079071, "report/reward_max_pred": 0.12664222717285156, "report/reward_neg_acc": 0.9999999403953552, "report/reward_neg_loss": 0.004785310477018356, "report/reward_pos_acc": 0.25, "report/reward_pos_loss": 4.045149803161621, "report/reward_pred": 0.002531830221414566, "report/reward_rate": 0.00390625, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.027815166860818863, "eval/cont_loss_std": 0.3198273777961731, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 4.335757732391357, "eval/cont_pos_acc": 0.999018669128418, "eval/cont_pos_loss": 0.006677077617496252, "eval/cont_pred": 0.9937799572944641, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.09407015889883041, "eval/image_loss_std": 0.11000006645917892, "eval/model_loss_mean": 0.7554807662963867, "eval/model_loss_std": 0.7943354845046997, "eval/post_ent_mag": 31.631359100341797, "eval/post_ent_max": 31.631359100341797, "eval/post_ent_mean": 29.148479461669922, "eval/post_ent_min": 27.857934951782227, "eval/post_ent_std": 0.8810760378837585, "eval/prior_ent_mag": 28.129831314086914, "eval/prior_ent_max": 28.129831314086914, "eval/prior_ent_mean": 27.53220558166504, "eval/prior_ent_min": 26.734859466552734, "eval/prior_ent_std": 0.24872684478759766, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0034454348497092724, "eval/reward_loss_mean": 0.03359542042016983, "eval/reward_loss_std": 0.4376218914985657, "eval/reward_max_data": 0.878125011920929, "eval/reward_max_pred": 0.3480011224746704, "eval/reward_neg_acc": 0.999018669128418, "eval/reward_neg_loss": 0.005136291496455669, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.833565711975098, "eval/reward_pred": 0.0025800159201025963, "eval/reward_rate": 0.0048828125, "replay/size": 1000000.0, "replay/inserts": 32440.0, "replay/samples": 32448.0, "replay/insert_wait_avg": 1.1836188936057133e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.247783728605191e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3688.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2067031446609993e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.940696716308594e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3722107410431, "timer/env.step_count": 4055.0, "timer/env.step_total": 39.04730439186096, "timer/env.step_frac": 0.039032775973390936, "timer/env.step_avg": 0.009629421551630324, "timer/env.step_min": 0.007593393325805664, "timer/env.step_max": 0.03606820106506348, "timer/replay._sample_count": 32448.0, "timer/replay._sample_total": 16.40902280807495, "timer/replay._sample_frac": 0.016402917466009657, "timer/replay._sample_avg": 0.0005057021328918563, "timer/replay._sample_min": 0.00038623809814453125, "timer/replay._sample_max": 0.02469921112060547, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4516.0, "timer/agent.policy_total": 47.97930359840393, "timer/agent.policy_frac": 0.04796145183087646, "timer/agent.policy_avg": 0.01062429220513816, "timer/agent.policy_min": 0.00856924057006836, "timer/agent.policy_max": 0.09418535232543945, "timer/dataset_train_count": 2028.0, "timer/dataset_train_total": 0.21240496635437012, "timer/dataset_train_frac": 0.0002123259363602548, "timer/dataset_train_avg": 0.00010473617670333832, "timer/dataset_train_min": 9.107589721679688e-05, "timer/dataset_train_max": 0.0010838508605957031, "timer/agent.train_count": 2028.0, "timer/agent.train_total": 902.2701256275177, "timer/agent.train_frac": 0.9019344159501846, "timer/agent.train_avg": 0.4449063735835886, "timer/agent.train_min": 0.43457508087158203, "timer/agent.train_max": 0.7080428600311279, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47716450691223145, "timer/agent.report_frac": 0.00047698696723968726, "timer/agent.report_avg": 0.23858225345611572, "timer/agent.report_min": 0.23033642768859863, "timer/agent.report_max": 0.2468280792236328, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8133392333984375e-05, "timer/dataset_eval_frac": 2.8122924679349175e-08, "timer/dataset_eval_avg": 2.8133392333984375e-05, "timer/dataset_eval_min": 2.8133392333984375e-05, "timer/dataset_eval_max": 2.8133392333984375e-05, "fps": 32.42723468484105}
{"step": 1573992, "time": 49269.351784944534, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1574176, "time": 49275.2092397213, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1574216, "time": 49276.22148633003, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1574360, "time": 49280.583062410355, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1574584, "time": 49287.349761009216, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1574728, "time": 49291.71348118782, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1574904, "time": 49297.12684011459, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1574936, "time": 49298.09818649292, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1574984, "time": 49299.553537368774, "episode/length": 9.0, "episode/score": 0.971875011920929, "episode/reward_rate": 0.1, "episode/intrinsic_return": 0.0}
{"step": 1575048, "time": 49301.52917432785, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1575192, "time": 49305.92456364632, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1575344, "time": 49310.767035484314, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1575440, "time": 49313.6758286953, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1575912, "time": 49328.031489133835, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1575976, "time": 49330.02965092659, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1576000, "time": 49330.994660139084, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1576552, "time": 49347.71168613434, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 1576568, "time": 49348.207248449326, "episode/length": 203.0, "episode/score": 0.3656249940395355, "episode/reward_rate": 0.004901960784313725, "episode/intrinsic_return": 0.0}
{"step": 1576672, "time": 49351.65017604828, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1576720, "time": 49353.12845349312, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1577008, "time": 49362.13130927086, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1577040, "time": 49363.1160492897, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1577040, "time": 49363.12513613701, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1577176, "time": 49367.07925415039, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1577400, "time": 49373.93062877655, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 1577488, "time": 49376.83907365799, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1577504, "time": 49377.33478116989, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1577624, "time": 49380.81678843498, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1577680, "time": 49382.7609808445, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1577856, "time": 49388.28988075256, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1577936, "time": 49390.74132514, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1578248, "time": 49400.127760887146, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 1578424, "time": 49405.53919839859, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1578472, "time": 49407.010771512985, "episode/length": 218.0, "episode/score": 0.3187499940395355, "episode/reward_rate": 0.0045662100456621, "episode/intrinsic_return": 0.0}
{"step": 1578480, "time": 49407.48442530632, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1579008, "time": 49423.83408355713, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 1579056, "time": 49425.309383153915, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 1579272, "time": 49431.717237234116, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1579336, "time": 49433.70271348953, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1579488, "time": 49438.54055452347, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1579528, "time": 49439.53125, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1579576, "time": 49440.982335567474, "episode/length": 204.0, "episode/score": 0.36250001192092896, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.0}
{"step": 1579648, "time": 49443.40583205223, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 1579816, "time": 49448.40235757828, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1580072, "time": 49457.45303988457, "eval_episode/length": 65.0, "eval_episode/score": 0.796875, "eval_episode/reward_rate": 0.015151515151515152}
{"step": 1580072, "time": 49457.810894966125, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 1580072, "time": 49457.858896017075, "eval_episode/length": 85.0, "eval_episode/score": 0.734375, "eval_episode/reward_rate": 0.011627906976744186}
{"step": 1580072, "time": 49458.19847416878, "eval_episode/length": 102.0, "eval_episode/score": 0.6812499761581421, "eval_episode/reward_rate": 0.009708737864077669}
{"step": 1580072, "time": 49459.08398413658, "eval_episode/length": 60.0, "eval_episode/score": 0.8125, "eval_episode/reward_rate": 0.01639344262295082}
{"step": 1580072, "time": 49459.15408182144, "eval_episode/length": 149.0, "eval_episode/score": 0.534375011920929, "eval_episode/reward_rate": 0.006666666666666667}
{"step": 1580072, "time": 49459.40324020386, "eval_episode/length": 95.0, "eval_episode/score": 0.703125, "eval_episode/reward_rate": 0.010416666666666666}
{"step": 1580072, "time": 49459.49074792862, "eval_episode/length": 165.0, "eval_episode/score": 0.484375, "eval_episode/reward_rate": 0.006024096385542169}
{"step": 1580096, "time": 49460.447098493576, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1580176, "time": 49462.87257933617, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1580264, "time": 49465.301902770996, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1580296, "time": 49466.28825211525, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1580352, "time": 49468.22584652901, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1580408, "time": 49469.71049642563, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1580616, "time": 49476.12207341194, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 1580800, "time": 49482.140864133835, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1581048, "time": 49489.5112349987, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 1581072, "time": 49490.993378162384, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1581096, "time": 49491.509989500046, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1581256, "time": 49496.441635131836, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1581648, "time": 49508.75837492943, "episode/length": 228.0, "episode/score": 0.2874999940395355, "episode/reward_rate": 0.004366812227074236, "episode/intrinsic_return": 0.0}
{"step": 1581728, "time": 49511.20573067665, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1581984, "time": 49519.03066945076, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1582176, "time": 49524.9170396328, "episode/length": 238.0, "episode/score": 0.2562499940395355, "episode/reward_rate": 0.0041841004184100415, "episode/intrinsic_return": 0.0}
{"step": 1582400, "time": 49531.82279062271, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 1582488, "time": 49534.29721593857, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1582504, "time": 49534.79760551453, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1582560, "time": 49536.8508605957, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1582736, "time": 49542.284969091415, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1582776, "time": 49543.294169425964, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 1582904, "time": 49547.26233959198, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 1583024, "time": 49551.179986953735, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1583304, "time": 49559.54634022713, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1583360, "time": 49561.5090777874, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1583472, "time": 49564.96071267128, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1583528, "time": 49566.488498687744, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1583592, "time": 49568.51391911507, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1583752, "time": 49573.39848279953, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1583784, "time": 49574.3861041069, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1583840, "time": 49576.33035707474, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1583864, "time": 49576.84195327759, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 1583968, "time": 49580.253079891205, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1584112, "time": 49584.64051532745, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1584208, "time": 49587.56604409218, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1584416, "time": 49593.9180727005, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1584728, "time": 49603.363459825516, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1584744, "time": 49603.857865810394, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1584792, "time": 49605.341930150986, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1584832, "time": 49606.792014837265, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1584864, "time": 49607.77293610573, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1585160, "time": 49616.60676193237, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 1585512, "time": 49627.59390425682, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1585520, "time": 49628.073850393295, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1585784, "time": 49635.990016222, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1585856, "time": 49638.421065330505, "episode/length": 235.0, "episode/score": 0.265625, "episode/reward_rate": 0.00423728813559322, "episode/intrinsic_return": 0.0}
{"step": 1585952, "time": 49641.39047241211, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1585968, "time": 49641.881932497025, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1585992, "time": 49642.394720077515, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 1586040, "time": 49643.886875629425, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 1586536, "time": 49659.274022102356, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1586736, "time": 49665.69056344032, "episode/length": 248.0, "episode/score": 0.22499999403953552, "episode/reward_rate": 0.004016064257028112, "episode/intrinsic_return": 0.0}
{"step": 1586808, "time": 49667.67451429367, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1586840, "time": 49668.685232400894, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1586896, "time": 49670.64161491394, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1586976, "time": 49673.11225271225, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1587160, "time": 49678.59550976753, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 1587304, "time": 49683.00856804848, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1587624, "time": 49692.99885034561, "episode/length": 197.0, "episode/score": 0.3843750059604645, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.0}
{"step": 1587752, "time": 49697.05069518089, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1587832, "time": 49699.54972934723, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1587832, "time": 49699.557284832, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1588120, "time": 49708.49615597725, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 1588360, "time": 49715.86677694321, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1588400, "time": 49717.41240286827, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1588528, "time": 49721.385202884674, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1588536, "time": 49721.41363072395, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 1588600, "time": 49723.3932595253, "episode/length": 223.0, "episode/score": 0.3031249940395355, "episode/reward_rate": 0.004464285714285714, "episode/intrinsic_return": 0.0}
{"step": 1588808, "time": 49729.78456187248, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1588936, "time": 49733.71278357506, "episode/length": 15.0, "episode/score": 0.953125, "episode/reward_rate": 0.0625, "episode/intrinsic_return": 0.0}
{"step": 1589000, "time": 49735.67844629288, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1589096, "time": 49738.668075323105, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1589104, "time": 49739.14843702316, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1589440, "time": 49750.11600160599, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1589672, "time": 49757.03202152252, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 1589760, "time": 49759.969089746475, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 1589944, "time": 49765.39647769928, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 1590056, "time": 49770.2414894104, "eval_episode/length": 65.0, "eval_episode/score": 0.796875, "eval_episode/reward_rate": 0.015151515151515152}
{"step": 1590056, "time": 49770.37631917, "eval_episode/length": 71.0, "eval_episode/score": 0.778124988079071, "eval_episode/reward_rate": 0.013888888888888888}
{"step": 1590056, "time": 49770.81979370117, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 1590056, "time": 49771.043405056, "eval_episode/length": 103.0, "eval_episode/score": 0.6781250238418579, "eval_episode/reward_rate": 0.009615384615384616}
{"step": 1590056, "time": 49771.3363699913, "eval_episode/length": 117.0, "eval_episode/score": 0.6343749761581421, "eval_episode/reward_rate": 0.00847457627118644}
{"step": 1590056, "time": 49771.46549153328, "eval_episode/length": 123.0, "eval_episode/score": 0.6156250238418579, "eval_episode/reward_rate": 0.008064516129032258}
{"step": 1590056, "time": 49772.02586936951, "eval_episode/length": 84.0, "eval_episode/score": 0.737500011920929, "eval_episode/reward_rate": 0.011764705882352941}
{"step": 1590056, "time": 49772.353657484055, "eval_episode/length": 166.0, "eval_episode/score": 0.48124998807907104, "eval_episode/reward_rate": 0.005988023952095809}
{"step": 1590128, "time": 49774.78344511986, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1590256, "time": 49778.84171462059, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1590528, "time": 49787.21663212776, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1590672, "time": 49791.70230984688, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1590728, "time": 49793.20548415184, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 1590912, "time": 49799.065363407135, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 1591312, "time": 49811.47771549225, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1591360, "time": 49812.94890975952, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 1591560, "time": 49818.89139509201, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1591816, "time": 49826.806195020676, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 1591824, "time": 49827.28006196022, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1592072, "time": 49834.67198514938, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1592248, "time": 49840.23203277588, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1592256, "time": 49840.71147656441, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1592376, "time": 49844.1935839653, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1592496, "time": 49848.12126040459, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1592504, "time": 49848.14837431908, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 1592528, "time": 49849.119862794876, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1592760, "time": 49856.023374557495, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 1592984, "time": 49862.89425969124, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1593216, "time": 49870.35830140114, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1593440, "time": 49877.249648332596, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1593456, "time": 49877.74435162544, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1593712, "time": 49885.62271928787, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1594128, "time": 49898.48504090309, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1594152, "time": 49899.002494335175, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1594160, "time": 49899.476041316986, "episode/length": 206.0, "episode/score": 0.35624998807907104, "episode/reward_rate": 0.004830917874396135, "episode/intrinsic_return": 0.0}
{"step": 1594272, "time": 49902.91203713417, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1594288, "time": 49903.40688085556, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1594568, "time": 49911.79303264618, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1594848, "time": 49920.63907408714, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1595296, "time": 49934.54909014702, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1595376, "time": 49937.02076649666, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1595424, "time": 49938.49144530296, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1595424, "time": 49938.49889945984, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 1595480, "time": 49940.02752995491, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 1595528, "time": 49941.50970029831, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1595704, "time": 49946.92848563194, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1595904, "time": 49953.299364089966, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1595976, "time": 49955.3021709919, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1596008, "time": 49956.29170465469, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1596016, "time": 49956.85875439644, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1596080, "time": 49958.82602405548, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1596368, "time": 49967.686156988144, "episode/length": 224.0, "episode/score": 0.30000001192092896, "episode/reward_rate": 0.0044444444444444444, "episode/intrinsic_return": 0.0}
{"step": 1596408, "time": 49968.70020389557, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1596816, "time": 49981.50698637962, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1596936, "time": 49984.98699259758, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1596976, "time": 49986.47449660301, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1597136, "time": 49991.46374607086, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1597320, "time": 49996.9369289875, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1597456, "time": 50001.82823348045, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1597672, "time": 50008.276754140854, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1597776, "time": 50011.737839221954, "episode/length": 219.0, "episode/score": 0.31562501192092896, "episode/reward_rate": 0.004545454545454545, "episode/intrinsic_return": 0.0}
{"step": 1597792, "time": 50012.23491191864, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1597800, "time": 50012.2635910511, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1598016, "time": 50019.28832983971, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1598376, "time": 50030.12224316597, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1598456, "time": 50032.553788900375, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1598568, "time": 50035.97261619568, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1598576, "time": 50036.44281196594, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 1598624, "time": 50037.90622258186, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1598752, "time": 50041.80532288551, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1598896, "time": 50046.181861400604, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1598936, "time": 50047.30585813522, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 1599264, "time": 50057.54215693474, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1599328, "time": 50059.512591362, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1599728, "time": 50071.70027947426, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1599744, "time": 50072.20160984993, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1599776, "time": 50073.1852312088, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 1599784, "time": 50073.2113339901, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 1600040, "time": 50082.10763192177, "eval_episode/length": 52.0, "eval_episode/score": 0.8374999761581421, "eval_episode/reward_rate": 0.018867924528301886}
{"step": 1600040, "time": 50082.29208660126, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 1600040, "time": 50083.10633158684, "eval_episode/length": 108.0, "eval_episode/score": 0.6625000238418579, "eval_episode/reward_rate": 0.009174311926605505}
{"step": 1600040, "time": 50083.87559008598, "eval_episode/length": 152.0, "eval_episode/score": 0.5249999761581421, "eval_episode/reward_rate": 0.006535947712418301}
{"step": 1600040, "time": 50084.06977891922, "eval_episode/length": 110.0, "eval_episode/score": 0.65625, "eval_episode/reward_rate": 0.009009009009009009}
{"step": 1600040, "time": 50084.17742753029, "eval_episode/length": 106.0, "eval_episode/score": 0.668749988079071, "eval_episode/reward_rate": 0.009345794392523364}
{"step": 1600040, "time": 50084.18496179581, "eval_episode/length": 169.0, "eval_episode/score": 0.47187501192092896, "eval_episode/reward_rate": 0.0058823529411764705}
{"step": 1600040, "time": 50084.54033637047, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 1600144, "time": 50087.93342065811, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 1600216, "time": 50089.90334391594, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1600544, "time": 50100.129922151566, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1600560, "time": 50100.62058591843, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 1600584, "time": 50101.13062238693, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1600744, "time": 50106.014823913574, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1600872, "time": 50110.05786347389, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 1600888, "time": 50110.55298161507, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1600904, "time": 50111.04707336426, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1601096, "time": 50116.91836833954, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1601320, "time": 50123.78791022301, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1601336, "time": 50124.27656173706, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1601416, "time": 50126.73205828667, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1601648, "time": 50133.99593448639, "episode/length": 232.0, "episode/score": 0.2750000059604645, "episode/reward_rate": 0.004291845493562232, "episode/intrinsic_return": 0.0}
{"step": 1602088, "time": 50147.255111694336, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1602312, "time": 50154.08975625038, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1602352, "time": 50155.55128931999, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1602360, "time": 50155.57785987854, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1602680, "time": 50165.34309720993, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1602752, "time": 50167.85926246643, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1602888, "time": 50171.778928518295, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 1602896, "time": 50172.25285410881, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1602920, "time": 50172.76556587219, "episode/length": 227.0, "episode/score": 0.2906250059604645, "episode/reward_rate": 0.0043859649122807015, "episode/intrinsic_return": 0.0}
{"step": 1603016, "time": 50175.687911748886, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1603056, "time": 50177.12728857994, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1603184, "time": 50181.02712607384, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1603272, "time": 50183.46925663948, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1603288, "time": 50183.95921897888, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1603368, "time": 50186.40630698204, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1603520, "time": 50191.23860526085, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1603992, "time": 50205.64845776558, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1604024, "time": 50206.63006424904, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1604048, "time": 50207.58771467209, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1604184, "time": 50211.50917482376, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1604192, "time": 50211.982496500015, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 1604248, "time": 50213.472708940506, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1604328, "time": 50215.928763866425, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 1604392, "time": 50217.87674188614, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1604544, "time": 50222.73736023903, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1604864, "time": 50232.6366481781, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1605008, "time": 50237.01947426796, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1605128, "time": 50240.472934007645, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1605152, "time": 50241.42414665222, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1605160, "time": 50241.45127224922, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1605376, "time": 50248.27775597572, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 1605512, "time": 50252.20821380615, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 1605760, "time": 50260.622398376465, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1605800, "time": 50261.621494054794, "episode/length": 284.0, "episode/score": 0.11249999701976776, "episode/reward_rate": 0.0035087719298245615, "episode/intrinsic_return": 0.0}
{"step": 1605977, "time": 50268.17388510704, "train_stats/mean_log_entropy": 0.07749225355995198, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.5783181762695313, "train/action_min": 0.0, "train/action_std": 1.798263949751854, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.013020330717554316, "train/actor_opt_grad_steps": 99275.0, "train/actor_opt_loss": -37.560764684677125, "train/adv_mag": 0.7867157447338105, "train/adv_max": 0.3059584838151932, "train/adv_mean": 0.0015671421349179582, "train/adv_min": -0.7344627344608307, "train/adv_std": 0.03369246580637991, "train/cont_avg": 0.9930078125, "train/cont_loss_mean": 0.03022007619962096, "train/cont_loss_std": 0.3032753603905439, "train/cont_neg_acc": 0.08837734650820493, "train/cont_neg_loss": 3.374543956518173, "train/cont_pos_acc": 0.999891820549965, "train/cont_pos_loss": 0.006515286043286324, "train/cont_pred": 0.992932590842247, "train/cont_rate": 0.9930078125, "train/dyn_loss_mean": 1.0000002837181092, "train/dyn_loss_std": 5.709933466278017e-06, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.10859248140826822, "train/extr_critic_critic_opt_grad_steps": 99275.0, "train/extr_critic_critic_opt_loss": 9665.939504394531, "train/extr_critic_mag": 1.8033412849903108, "train/extr_critic_max": 1.8033412849903108, "train/extr_critic_mean": 1.6583320593833923, "train/extr_critic_min": 1.356318034529686, "train/extr_critic_std": 0.03680251107551157, "train/extr_return_normed_mag": 0.8054162323474884, "train/extr_return_normed_max": 0.30815492510795595, "train/extr_return_normed_mean": 0.08381221510469913, "train/extr_return_normed_min": -0.6847289115190506, "train/extr_return_normed_std": 0.050409372122958304, "train/extr_return_rate": 0.9997441655397415, "train/extr_return_raw_mag": 1.8842417615652085, "train/extr_return_raw_max": 1.8842417615652085, "train/extr_return_raw_mean": 1.6598991394042968, "train/extr_return_raw_min": 0.8913579249382019, "train/extr_return_raw_std": 0.05040937210433185, "train/extr_reward_mag": 0.251660036444664, "train/extr_reward_max": 0.251660036444664, "train/extr_reward_mean": 0.0029580873675877227, "train/extr_reward_min": 8.821487426757812e-08, "train/extr_reward_std": 0.009206511578522623, "train/image_loss_mean": 0.09269388414919376, "train/image_loss_std": 0.10392001818865537, "train/model_loss_mean": 0.7511472472548485, "train/model_loss_std": 0.6190060825645923, "train/model_opt_grad_norm": 14.159687280654907, "train/model_opt_grad_steps": 99184.565, "train/model_opt_loss": 3927.91458984375, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5225.0, "train/policy_entropy_mag": 1.1767727482318877, "train/policy_entropy_max": 1.1767727482318877, "train/policy_entropy_mean": 0.0819019003212452, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.08819551710039378, "train/policy_logprob_mag": 6.551080284118652, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.08188050784170628, "train/policy_logprob_min": -6.551080284118652, "train/policy_logprob_std": 0.6191770222783088, "train/policy_randomness_mag": 0.6047416013479233, "train/policy_randomness_max": 0.6047416013479233, "train/policy_randomness_mean": 0.04208925584331155, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.04532353283837438, "train/post_ent_mag": 29.455130100250244, "train/post_ent_max": 29.455130100250244, "train/post_ent_mean": 28.448017835617065, "train/post_ent_min": 27.485968933105468, "train/post_ent_std": 0.4188822840154171, "train/prior_ent_mag": 28.509612607955933, "train/prior_ent_max": 28.509612607955933, "train/prior_ent_mean": 27.77375238418579, "train/prior_ent_min": 26.606796255111693, "train/prior_ent_std": 0.31798814848065377, "train/rep_loss_mean": 1.0000002837181092, "train/rep_loss_std": 5.709933466278017e-06, "train/reward_avg": 0.0037606658891309055, "train/reward_loss_mean": 0.028233093935996295, "train/reward_loss_std": 0.3152018577605486, "train/reward_max_data": 0.8218593761324883, "train/reward_max_pred": 0.30851730167865754, "train/reward_neg_acc": 0.9994500881433487, "train/reward_neg_loss": 0.005229933536611497, "train/reward_pos_acc": 0.11986508179455996, "train/reward_pos_loss": 4.101531486511231, "train/reward_pred": 0.002965829386957921, "train/reward_rate": 0.0055908203125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.03228747099637985, "report/cont_loss_std": 0.3255132734775543, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 3.8847334384918213, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0057711293920874596, "report/cont_pred": 0.994174599647522, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.08540099859237671, "report/image_loss_std": 0.0977095440030098, "report/model_loss_mean": 0.7548741102218628, "report/model_loss_std": 0.7547828555107117, "report/post_ent_mag": 29.503860473632812, "report/post_ent_max": 29.503860473632812, "report/post_ent_mean": 28.49306869506836, "report/post_ent_min": 27.666738510131836, "report/post_ent_std": 0.40114864706993103, "report/prior_ent_mag": 28.720134735107422, "report/prior_ent_max": 28.720134735107422, "report/prior_ent_mean": 27.835363388061523, "report/prior_ent_min": 26.533348083496094, "report/prior_ent_std": 0.3634994328022003, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00457763671875, "report/reward_loss_mean": 0.0371856689453125, "report/reward_loss_std": 0.3969360888004303, "report/reward_max_data": 0.846875011920929, "report/reward_max_pred": 0.043172597885131836, "report/reward_neg_acc": 0.9999999403953552, "report/reward_neg_loss": 0.004677219782024622, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.760199546813965, "report/reward_pred": 0.0024015256203711033, "report/reward_rate": 0.0068359375, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.016786351799964905, "eval/cont_loss_std": 0.1903742551803589, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 3.492776393890381, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0065728663466870785, "eval/cont_pred": 0.9935277700424194, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.07752667367458344, "eval/image_loss_std": 0.09732648730278015, "eval/model_loss_mean": 0.7122647166252136, "eval/model_loss_std": 0.458529531955719, "eval/post_ent_mag": 29.503847122192383, "eval/post_ent_max": 29.503847122192383, "eval/post_ent_mean": 28.485740661621094, "eval/post_ent_min": 27.63178253173828, "eval/post_ent_std": 0.39537808299064636, "eval/prior_ent_mag": 28.593433380126953, "eval/prior_ent_max": 28.593433380126953, "eval/prior_ent_mean": 27.819517135620117, "eval/prior_ent_min": 26.36001968383789, "eval/prior_ent_std": 0.3841295540332794, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0019714355003088713, "eval/reward_loss_mean": 0.017951708287000656, "eval/reward_loss_std": 0.23150013387203217, "eval/reward_max_data": 0.737500011920929, "eval/reward_max_pred": 0.17244231700897217, "eval/reward_neg_acc": 0.999020516872406, "eval/reward_neg_loss": 0.0054649231024086475, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 4.267621040344238, "eval/reward_pred": 0.002717618364840746, "eval/reward_rate": 0.0029296875, "replay/size": 1000000.0, "replay/inserts": 32048.0, "replay/samples": 32048.0, "replay/insert_wait_avg": 1.2039587727440517e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.14124945242049e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4184.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.089978628359151e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.046627044677734e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.375417470932, "timer/env.step_count": 4006.0, "timer/env.step_total": 39.515076875686646, "timer/env.step_frac": 0.03950024779255917, "timer/env.step_avg": 0.009863973259033113, "timer/env.step_min": 0.007671833038330078, "timer/env.step_max": 0.0433497428894043, "timer/replay._sample_count": 32048.0, "timer/replay._sample_total": 16.315592527389526, "timer/replay._sample_frac": 0.016309469667534698, "timer/replay._sample_avg": 0.000509098618553093, "timer/replay._sample_min": 0.00041675567626953125, "timer/replay._sample_max": 0.011035442352294922, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4529.0, "timer/agent.policy_total": 48.40883159637451, "timer/agent.policy_frac": 0.048390664895342786, "timer/agent.policy_avg": 0.01068863581284489, "timer/agent.policy_min": 0.008357763290405273, "timer/agent.policy_max": 0.10715627670288086, "timer/dataset_train_count": 2003.0, "timer/dataset_train_total": 0.2112903594970703, "timer/dataset_train_frac": 0.0002112110671723996, "timer/dataset_train_avg": 0.00010548694932454833, "timer/dataset_train_min": 9.179115295410156e-05, "timer/dataset_train_max": 0.0002722740173339844, "timer/agent.train_count": 2003.0, "timer/agent.train_total": 901.1570372581482, "timer/agent.train_frac": 0.9008188541221658, "timer/agent.train_avg": 0.4499036631343725, "timer/agent.train_min": 0.4309422969818115, "timer/agent.train_max": 0.7646825313568115, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47680211067199707, "timer/agent.report_frac": 0.00047662317800392325, "timer/agent.report_avg": 0.23840105533599854, "timer/agent.report_min": 0.23393988609313965, "timer/agent.report_max": 0.24286222457885742, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 4.2438507080078125e-05, "timer/dataset_eval_frac": 4.242258090204547e-08, "timer/dataset_eval_avg": 4.2438507080078125e-05, "timer/dataset_eval_min": 4.2438507080078125e-05, "timer/dataset_eval_max": 4.2438507080078125e-05, "fps": 32.03543102217596}
{"step": 1606056, "time": 50270.383357048035, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 1606080, "time": 50271.33846759796, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1606272, "time": 50277.18087387085, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 1606360, "time": 50279.66073489189, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1606376, "time": 50280.153671979904, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1606376, "time": 50280.16146492958, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1606496, "time": 50284.025136470795, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1607104, "time": 50302.73468923569, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1607152, "time": 50304.21664190292, "episode/length": 249.0, "episode/score": 0.22187499701976776, "episode/reward_rate": 0.004, "episode/intrinsic_return": 0.0}
{"step": 1607192, "time": 50305.21251988411, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1607568, "time": 50317.00181269646, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1607632, "time": 50318.996148109436, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1608176, "time": 50335.551221847534, "episode/length": 261.0, "episode/score": 0.18437500298023224, "episode/reward_rate": 0.003816793893129771, "episode/intrinsic_return": 0.0}
{"step": 1608328, "time": 50340.02105093002, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 1608368, "time": 50341.4769589901, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1608376, "time": 50341.5063393116, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1608448, "time": 50343.97338557243, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1608488, "time": 50344.986721515656, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1608536, "time": 50346.501685380936, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 1608584, "time": 50348.019927978516, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1608672, "time": 50350.94459486008, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1608720, "time": 50352.40153121948, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 1608720, "time": 50352.409751176834, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 1609232, "time": 50368.06770515442, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1609264, "time": 50369.05382180214, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1609272, "time": 50369.081169605255, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1609296, "time": 50370.0438272953, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1609320, "time": 50370.559752464294, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1609560, "time": 50377.99537038803, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1609656, "time": 50380.914521455765, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1609968, "time": 50390.661151885986, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1610024, "time": 50393.35463356972, "eval_episode/length": 64.0, "eval_episode/score": 0.800000011920929, "eval_episode/reward_rate": 0.015384615384615385}
{"step": 1610024, "time": 50393.523277044296, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 1610024, "time": 50393.95836234093, "eval_episode/length": 96.0, "eval_episode/score": 0.699999988079071, "eval_episode/reward_rate": 0.010309278350515464}
{"step": 1610024, "time": 50393.963678598404, "eval_episode/length": 96.0, "eval_episode/score": 0.699999988079071, "eval_episode/reward_rate": 0.010309278350515464}
{"step": 1610024, "time": 50394.17743611336, "eval_episode/length": 107.0, "eval_episode/score": 0.6656249761581421, "eval_episode/reward_rate": 0.009259259259259259}
{"step": 1610024, "time": 50394.44270849228, "eval_episode/length": 121.0, "eval_episode/score": 0.621874988079071, "eval_episode/reward_rate": 0.00819672131147541}
{"step": 1610024, "time": 50394.84766244888, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 1610024, "time": 50395.031675577164, "eval_episode/length": 56.0, "eval_episode/score": 0.824999988079071, "eval_episode/reward_rate": 0.017543859649122806}
{"step": 1610040, "time": 50395.54431962967, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1610208, "time": 50400.875338077545, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1610280, "time": 50402.8548977375, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1610392, "time": 50406.28054332733, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1610432, "time": 50407.80317735672, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1610688, "time": 50415.66006946564, "episode/length": 268.0, "episode/score": 0.16249999403953552, "episode/reward_rate": 0.0037174721189591076, "episode/intrinsic_return": 0.0}
{"step": 1610904, "time": 50422.03704047203, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1610928, "time": 50422.99016833305, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1610952, "time": 50423.50409722328, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1611096, "time": 50427.89071536064, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 1611352, "time": 50435.72386884689, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1611416, "time": 50437.81535601616, "episode/length": 261.0, "episode/score": 0.18437500298023224, "episode/reward_rate": 0.003816793893129771, "episode/intrinsic_return": 0.0}
{"step": 1611792, "time": 50449.51372504234, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1611944, "time": 50453.90278553963, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1612080, "time": 50458.270021915436, "episode/length": 205.0, "episode/score": 0.359375, "episode/reward_rate": 0.0048543689320388345, "episode/intrinsic_return": 0.0}
{"step": 1612112, "time": 50459.259578704834, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1612336, "time": 50466.11000871658, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1612448, "time": 50469.64134931564, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 1612568, "time": 50473.06114649773, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 1612680, "time": 50476.47365403175, "episode/length": 248.0, "episode/score": 0.22499999403953552, "episode/reward_rate": 0.004016064257028112, "episode/intrinsic_return": 0.0}
{"step": 1612904, "time": 50483.291568517685, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1612976, "time": 50485.73063182831, "episode/length": 255.0, "episode/score": 0.203125, "episode/reward_rate": 0.00390625, "episode/intrinsic_return": 0.0}
{"step": 1613056, "time": 50488.16834640503, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1613160, "time": 50491.130172252655, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1613232, "time": 50493.561150312424, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1613376, "time": 50497.99900197983, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1613408, "time": 50498.99475121498, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 1613440, "time": 50499.96926188469, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 1613600, "time": 50504.83182621002, "episode/length": 19.0, "episode/score": 0.940625011920929, "episode/reward_rate": 0.05, "episode/intrinsic_return": 0.0}
{"step": 1613640, "time": 50505.82332897186, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1613880, "time": 50513.64492845535, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1613904, "time": 50514.61592245102, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 1613928, "time": 50515.13664269447, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1614168, "time": 50522.480852365494, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1614424, "time": 50530.465062856674, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1614600, "time": 50535.83827996254, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1614672, "time": 50538.27958059311, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 1614880, "time": 50544.63355731964, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1614960, "time": 50547.07893681526, "episode/length": 256.0, "episode/score": 0.20000000298023224, "episode/reward_rate": 0.0038910505836575876, "episode/intrinsic_return": 0.0}
{"step": 1615056, "time": 50550.02723169327, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1615120, "time": 50551.97746539116, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1615200, "time": 50554.42714905739, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1615272, "time": 50556.467198610306, "episode/length": 276.0, "episode/score": 0.13750000298023224, "episode/reward_rate": 0.0036101083032490976, "episode/intrinsic_return": 0.0}
{"step": 1615632, "time": 50567.74791145325, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1615912, "time": 50576.03452658653, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1615944, "time": 50577.0167658329, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1616056, "time": 50580.42736506462, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1616216, "time": 50585.31516742706, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 1616328, "time": 50588.81720161438, "episode/length": 215.0, "episode/score": 0.328125, "episode/reward_rate": 0.004629629629629629, "episode/intrinsic_return": 0.0}
{"step": 1616520, "time": 50594.67923593521, "episode/length": 182.0, "episode/score": 0.4312500059604645, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.0}
{"step": 1616656, "time": 50599.113649606705, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 1616720, "time": 50601.06034326553, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1616872, "time": 50605.4570479393, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1617168, "time": 50614.68361783028, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1617608, "time": 50628.01332998276, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 1617736, "time": 50631.92449593544, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1617864, "time": 50635.821120262146, "episode/length": 239.0, "episode/score": 0.25312501192092896, "episode/reward_rate": 0.004166666666666667, "episode/intrinsic_return": 0.0}
{"step": 1617896, "time": 50636.81839132309, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 1617896, "time": 50636.831132888794, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1618184, "time": 50645.613290548325, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 1618528, "time": 50656.46931672096, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1618640, "time": 50659.87445354462, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1618712, "time": 50661.85568547249, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1618960, "time": 50669.624222278595, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1619016, "time": 50671.13601183891, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1619056, "time": 50672.59903001785, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1619120, "time": 50674.55606842041, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1619712, "time": 50692.69207262993, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1619760, "time": 50694.15640902519, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 1619920, "time": 50699.03995680809, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1620008, "time": 50703.85756397247, "eval_episode/length": 91.0, "eval_episode/score": 0.715624988079071, "eval_episode/reward_rate": 0.010869565217391304}
{"step": 1620008, "time": 50704.10510158539, "eval_episode/length": 104.0, "eval_episode/score": 0.675000011920929, "eval_episode/reward_rate": 0.009523809523809525}
{"step": 1620008, "time": 50704.435156822205, "eval_episode/length": 30.0, "eval_episode/score": 0.90625, "eval_episode/reward_rate": 0.03225806451612903}
{"step": 1620008, "time": 50704.951724767685, "eval_episode/length": 149.0, "eval_episode/score": 0.534375011920929, "eval_episode/reward_rate": 0.006666666666666667}
{"step": 1620008, "time": 50705.47795009613, "eval_episode/length": 177.0, "eval_episode/score": 0.4468750059604645, "eval_episode/reward_rate": 0.0056179775280898875}
{"step": 1620008, "time": 50705.87577056885, "eval_episode/length": 75.0, "eval_episode/score": 0.765625, "eval_episode/reward_rate": 0.013157894736842105}
{"step": 1620008, "time": 50705.94008421898, "eval_episode/length": 201.0, "eval_episode/score": 0.37187498807907104, "eval_episode/reward_rate": 0.0049504950495049506}
{"step": 1620008, "time": 50706.04082560539, "eval_episode/length": 101.0, "eval_episode/score": 0.684374988079071, "eval_episode/reward_rate": 0.00980392156862745}
{"step": 1620272, "time": 50714.40243911743, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1620416, "time": 50718.7927570343, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 1620432, "time": 50719.307878255844, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 1620440, "time": 50719.33512496948, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1620448, "time": 50719.810302734375, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1620456, "time": 50719.83766269684, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1620504, "time": 50721.30276083946, "episode/length": 223.0, "episode/score": 0.3031249940395355, "episode/reward_rate": 0.004464285714285714, "episode/intrinsic_return": 0.0}
{"step": 1620552, "time": 50722.77091217041, "episode/length": 198.0, "episode/score": 0.3812499940395355, "episode/reward_rate": 0.005025125628140704, "episode/intrinsic_return": 0.0}
{"step": 1620968, "time": 50735.465468883514, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1621024, "time": 50737.480748176575, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1621128, "time": 50740.4537665844, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1621176, "time": 50741.93558168411, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1621352, "time": 50747.32399368286, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1621360, "time": 50747.79723262787, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1621528, "time": 50752.71089529991, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1621736, "time": 50759.04778671265, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 1621760, "time": 50760.002833366394, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1621944, "time": 50765.39743232727, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1622192, "time": 50773.75548648834, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1622400, "time": 50780.089329242706, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1622400, "time": 50780.10146999359, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1622440, "time": 50781.10684657097, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1622456, "time": 50781.60250234604, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1622552, "time": 50784.54001522064, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 1622584, "time": 50785.52300596237, "episode/length": 201.0, "episode/score": 0.37187498807907104, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.0}
{"step": 1623112, "time": 50801.70982456207, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 1623264, "time": 50806.56994390488, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1623408, "time": 50810.957456588745, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1623440, "time": 50811.93236374855, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1623472, "time": 50812.9285261631, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 1623520, "time": 50814.39057922363, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1623664, "time": 50818.786132097244, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1623888, "time": 50825.6103515625, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 1624088, "time": 50831.59200549126, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1624360, "time": 50839.89369940758, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1624376, "time": 50840.38728070259, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1624384, "time": 50840.85804057121, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1624768, "time": 50852.57009291649, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1625176, "time": 50864.898827791214, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 1625264, "time": 50867.82565712929, "episode/length": 217.0, "episode/score": 0.3218750059604645, "episode/reward_rate": 0.0045871559633027525, "episode/intrinsic_return": 0.0}
{"step": 1625280, "time": 50868.320848703384, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1625456, "time": 50873.72555208206, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1625568, "time": 50877.170756578445, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 1625784, "time": 50883.545207738876, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1626032, "time": 50891.45794868469, "episode/length": 206.0, "episode/score": 0.35624998807907104, "episode/reward_rate": 0.004830917874396135, "episode/intrinsic_return": 0.0}
{"step": 1626176, "time": 50895.84697055817, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1626424, "time": 50903.25406002998, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1626512, "time": 50906.22574496269, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1626624, "time": 50909.682220220566, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 1626648, "time": 50910.204317331314, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1626976, "time": 50920.60386323929, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1627000, "time": 50921.1436355114, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 1627080, "time": 50923.59462809563, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1627232, "time": 50928.4572057724, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1627280, "time": 50929.91787624359, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1627496, "time": 50936.29308462143, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1627664, "time": 50941.63846683502, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1627704, "time": 50942.63910460472, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 1627864, "time": 50947.62988805771, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1627864, "time": 50947.63628864288, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 1627928, "time": 50949.58872818947, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 1628104, "time": 50954.96763801575, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 1628216, "time": 50958.4022500515, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1628224, "time": 50958.873163700104, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1628320, "time": 50961.81504178047, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1628432, "time": 50965.24621844292, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1628568, "time": 50969.164915800095, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 1628784, "time": 50976.000138282776, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1628888, "time": 50979.04789209366, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1628904, "time": 50979.53932547569, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1629112, "time": 50985.880006313324, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1629424, "time": 50995.59553647041, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1629624, "time": 51001.46332836151, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1629640, "time": 51001.95474529266, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1629872, "time": 51009.35981178284, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1630008, "time": 51013.261853933334, "episode/length": 259.0, "episode/score": 0.19062499701976776, "episode/reward_rate": 0.0038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 1630096, "time": 51017.96630907059, "eval_episode/length": 95.0, "eval_episode/score": 0.703125, "eval_episode/reward_rate": 0.010416666666666666}
{"step": 1630096, "time": 51018.85443472862, "eval_episode/length": 139.0, "eval_episode/score": 0.565625011920929, "eval_episode/reward_rate": 0.007142857142857143}
{"step": 1630096, "time": 51018.902940273285, "eval_episode/length": 141.0, "eval_episode/score": 0.559374988079071, "eval_episode/reward_rate": 0.007042253521126761}
{"step": 1630096, "time": 51019.26539707184, "eval_episode/length": 160.0, "eval_episode/score": 0.5, "eval_episode/reward_rate": 0.006211180124223602}
{"step": 1630096, "time": 51019.41151714325, "eval_episode/length": 167.0, "eval_episode/score": 0.4781250059604645, "eval_episode/reward_rate": 0.005952380952380952}
{"step": 1630096, "time": 51019.67331838608, "eval_episode/length": 181.0, "eval_episode/score": 0.43437498807907104, "eval_episode/reward_rate": 0.005494505494505495}
{"step": 1630096, "time": 51020.83622145653, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 1630096, "time": 51021.18076848984, "eval_episode/length": 81.0, "eval_episode/score": 0.746874988079071, "eval_episode/reward_rate": 0.012195121951219513}
{"step": 1630128, "time": 51022.154198646545, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1630496, "time": 51033.91257810593, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1630536, "time": 51034.93043613434, "episode/length": 203.0, "episode/score": 0.3656249940395355, "episode/reward_rate": 0.004901960784313725, "episode/intrinsic_return": 0.0}
{"step": 1630640, "time": 51038.408484220505, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1630784, "time": 51042.80405330658, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1630952, "time": 51047.70663309097, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1631000, "time": 51049.19500350952, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 1631096, "time": 51052.10893249512, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1631280, "time": 51057.94900274277, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1631296, "time": 51058.443170785904, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1631408, "time": 51061.8799636364, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 1631440, "time": 51062.863335609436, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1631768, "time": 51072.788343667984, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 1631816, "time": 51074.27036547661, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1632216, "time": 51086.440739393234, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1632336, "time": 51090.30500841141, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1632392, "time": 51091.774539232254, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1632584, "time": 51097.672364234924, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 1632632, "time": 51099.15894937515, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1632680, "time": 51100.62055039406, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 1632784, "time": 51104.013797044754, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1632952, "time": 51108.87559580803, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1633096, "time": 51113.255685806274, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1633176, "time": 51115.69497013092, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1633232, "time": 51117.64238667488, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 1633240, "time": 51117.669439554214, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1633400, "time": 51122.55385041237, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1633472, "time": 51124.9693710804, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1633512, "time": 51125.968990564346, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 1633784, "time": 51134.361124277115, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1633856, "time": 51136.77369976044, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 1633952, "time": 51139.71019434929, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1633976, "time": 51140.2296936512, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1634216, "time": 51147.56861138344, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1634240, "time": 51148.52837347984, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1634616, "time": 51159.83616709709, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 1634688, "time": 51162.25805044174, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1634944, "time": 51169.98938679695, "episode/length": 220.0, "episode/score": 0.3125, "episode/reward_rate": 0.004524886877828055, "episode/intrinsic_return": 0.0}
{"step": 1634944, "time": 51169.99935531616, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1635024, "time": 51172.43004155159, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1635056, "time": 51173.394956827164, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1635176, "time": 51176.80869555473, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1635344, "time": 51182.10469412804, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1635808, "time": 51196.345695495605, "episode/length": 252.0, "episode/score": 0.21250000596046448, "episode/reward_rate": 0.003952569169960474, "episode/intrinsic_return": 0.0}
{"step": 1636024, "time": 51202.72009420395, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1636192, "time": 51208.05995321274, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1636216, "time": 51208.56604242325, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 1636264, "time": 51210.02263092995, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1636272, "time": 51210.51100873947, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1636552, "time": 51218.85331583023, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1636832, "time": 51227.54610848427, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1636840, "time": 51227.57284641266, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1636920, "time": 51230.01190209389, "episode/length": 246.0, "episode/score": 0.23125000298023224, "episode/reward_rate": 0.004048582995951417, "episode/intrinsic_return": 0.0}
{"step": 1636952, "time": 51230.97872877121, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 1637056, "time": 51234.3479385376, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1637064, "time": 51234.37611079216, "episode/length": 17.0, "episode/score": 0.9468749761581421, "episode/reward_rate": 0.05555555555555555, "episode/intrinsic_return": 0.0}
{"step": 1637064, "time": 51234.38482761383, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1637176, "time": 51237.823415994644, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1637240, "time": 51239.80034041405, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1637440, "time": 51246.135821819305, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1637632, "time": 51252.14688420296, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1637840, "time": 51258.52634882927, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1638008, "time": 51263.4203107357, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1638136, "time": 51267.332327604294, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 1638137, "time": 51268.39137864113, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.550682561314521, "train/action_min": 0.0, "train/action_std": 1.821065750881214, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.012746465693584723, "train/actor_opt_grad_steps": 101280.0, "train/actor_opt_loss": -38.83470857914408, "train/adv_mag": 0.7346556020613334, "train/adv_max": 0.2774956908392076, "train/adv_mean": 0.0015498660415802865, "train/adv_min": -0.688019482057486, "train/adv_std": 0.03285535916092977, "train/cont_avg": 0.993057175062189, "train/cont_loss_mean": 0.030536862808414063, "train/cont_loss_std": 0.3108733034048656, "train/cont_neg_acc": 0.0821296913921833, "train/cont_neg_loss": 3.466731544137001, "train/cont_pos_acc": 0.9998972249861381, "train/cont_pos_loss": 0.0063929014679378095, "train/cont_pred": 0.9930976048037781, "train/cont_rate": 0.993057175062189, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.1019770902030133, "train/extr_critic_critic_opt_grad_steps": 101280.0, "train/extr_critic_critic_opt_loss": 11801.31844196984, "train/extr_critic_mag": 1.8503874569983032, "train/extr_critic_max": 1.8503874569983032, "train/extr_critic_mean": 1.7059229381048857, "train/extr_critic_min": 1.4401228285547514, "train/extr_critic_std": 0.03887193226510316, "train/extr_return_normed_mag": 0.75575156650733, "train/extr_return_normed_max": 0.3198839657342256, "train/extr_return_normed_mean": 0.08719214787753067, "train/extr_return_normed_min": -0.6205226046528982, "train/extr_return_normed_std": 0.051513202303084565, "train/extr_return_rate": 0.9997998496786279, "train/extr_return_raw_mag": 1.9401645476545268, "train/extr_return_raw_max": 1.9401645476545268, "train/extr_return_raw_mean": 1.7074728184078463, "train/extr_return_raw_min": 0.9997579772674029, "train/extr_return_raw_std": 0.051513201932408915, "train/extr_reward_mag": 0.2549159289592534, "train/extr_reward_max": 0.2549159289592534, "train/extr_reward_mean": 0.0027884249731814905, "train/extr_reward_min": 8.362442699830924e-08, "train/extr_reward_std": 0.00896525253722472, "train/image_loss_mean": 0.09114637615075752, "train/image_loss_std": 0.1027626785546986, "train/model_loss_mean": 0.7494355579513815, "train/model_loss_std": 0.6180286132800046, "train/model_opt_grad_norm": 13.77865828037262, "train/model_opt_grad_steps": 101187.6616915423, "train/model_opt_loss": 3989.85887457245, "train/model_opt_model_opt_grad_overflow": 0.004975124378109453, "train/model_opt_model_opt_grad_scale": 5298.507462686567, "train/policy_entropy_mag": 1.145330443014553, "train/policy_entropy_max": 1.145330443014553, "train/policy_entropy_mean": 0.08141752017374655, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.08706311177258468, "train/policy_logprob_mag": 6.551080307557215, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.08141270887792407, "train/policy_logprob_min": -6.551080307557215, "train/policy_logprob_std": 0.61872547331141, "train/policy_randomness_mag": 0.5885834507088163, "train/policy_randomness_max": 0.5885834507088163, "train/policy_randomness_mean": 0.04184033401050971, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.04474159183712741, "train/post_ent_mag": 29.381390158809833, "train/post_ent_max": 29.381390158809833, "train/post_ent_mean": 28.372053886527446, "train/post_ent_min": 27.38848133941195, "train/post_ent_std": 0.4190696790740265, "train/prior_ent_mag": 28.534408056913918, "train/prior_ent_max": 28.534408056913918, "train/prior_ent_mean": 27.741507013045734, "train/prior_ent_min": 26.43482952212813, "train/prior_ent_std": 0.3398564005669077, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0036662391164520784, "train/reward_loss_mean": 0.02775229733502168, "train/reward_loss_std": 0.31133454237411273, "train/reward_max_data": 0.8178016160851094, "train/reward_max_pred": 0.32154872464896433, "train/reward_neg_acc": 0.9995212305837603, "train/reward_neg_loss": 0.005139579735835319, "train/reward_pos_acc": 0.1256944465264678, "train/reward_pos_loss": 4.0616097581386565, "train/reward_pred": 0.0029321540898842673, "train/reward_rate": 0.005528995646766169, "train_stats/mean_log_entropy": 0.07735781773492013, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 0.03503246605396271, "report/cont_loss_std": 0.3293880522251129, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 3.568732261657715, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.007208057679235935, "report/cont_pred": 0.9927166700363159, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.10954020172357559, "report/image_loss_std": 0.1155647411942482, "report/model_loss_mean": 0.7762253880500793, "report/model_loss_std": 0.6595603227615356, "report/post_ent_mag": 28.73027801513672, "report/post_ent_max": 28.73027801513672, "report/post_ent_mean": 28.039390563964844, "report/post_ent_min": 27.278532028198242, "report/post_ent_std": 0.3004220724105835, "report/prior_ent_mag": 28.506790161132812, "report/prior_ent_max": 28.506790161132812, "report/prior_ent_mean": 27.725563049316406, "report/prior_ent_min": 26.52123260498047, "report/prior_ent_std": 0.32833266258239746, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.004391479305922985, "report/reward_loss_mean": 0.031652674078941345, "report/reward_loss_std": 0.33443978428840637, "report/reward_max_data": 0.8687499761581421, "report/reward_max_pred": 0.18775725364685059, "report/reward_neg_acc": 0.9990177154541016, "report/reward_neg_loss": 0.006232736632227898, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.344568729400635, "report/reward_pred": 0.0032410956919193268, "report/reward_rate": 0.005859375, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.023959975689649582, "eval/cont_loss_std": 0.23052676022052765, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 3.243523359298706, "eval/cont_pos_acc": 0.999018669128418, "eval/cont_pos_loss": 0.00816231407225132, "eval/cont_pred": 0.9923004508018494, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.11421135812997818, "eval/image_loss_std": 0.12341443449258804, "eval/model_loss_mean": 0.7657709121704102, "eval/model_loss_std": 0.5634639859199524, "eval/post_ent_mag": 28.730274200439453, "eval/post_ent_max": 28.730274200439453, "eval/post_ent_mean": 27.975080490112305, "eval/post_ent_min": 27.080738067626953, "eval/post_ent_std": 0.32059991359710693, "eval/prior_ent_mag": 28.506790161132812, "eval/prior_ent_max": 28.506790161132812, "eval/prior_ent_mean": 27.649192810058594, "eval/prior_ent_min": 26.357872009277344, "eval/prior_ent_std": 0.35039615631103516, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0033325194381177425, "eval/reward_loss_mean": 0.02759953774511814, "eval/reward_loss_std": 0.2977767884731293, "eval/reward_max_data": 0.7875000238418579, "eval/reward_max_pred": 0.19364047050476074, "eval/reward_neg_acc": 0.9980372786521912, "eval/reward_neg_loss": 0.007032935973256826, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 4.2190728187561035, "eval/reward_pred": 0.0031101410277187824, "eval/reward_rate": 0.0048828125, "replay/size": 1000000.0, "replay/inserts": 32160.0, "replay/samples": 32160.0, "replay/insert_wait_avg": 1.1894462713554724e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.20571226148463e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5000.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0833263397216797e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.642673492431641e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3153443336487, "timer/env.step_count": 4020.0, "timer/env.step_total": 38.986112117767334, "timer/env.step_frac": 0.03897382194385671, "timer/env.step_avg": 0.00969803784024063, "timer/env.step_min": 0.007730722427368164, "timer/env.step_max": 0.04389238357543945, "timer/replay._sample_count": 32160.0, "timer/replay._sample_total": 16.26431941986084, "timer/replay._sample_frac": 0.016259192175738516, "timer/replay._sample_avg": 0.0005057313252444291, "timer/replay._sample_min": 0.000385284423828125, "timer/replay._sample_max": 0.010818243026733398, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4645.0, "timer/agent.policy_total": 48.863595485687256, "timer/agent.policy_frac": 0.04884819148529338, "timer/agent.policy_avg": 0.01051961151467971, "timer/agent.policy_min": 0.008944988250732422, "timer/agent.policy_max": 0.09009265899658203, "timer/dataset_train_count": 2010.0, "timer/dataset_train_total": 0.20949554443359375, "timer/dataset_train_frac": 0.00020942950202683071, "timer/dataset_train_avg": 0.00010422663902168843, "timer/dataset_train_min": 9.131431579589844e-05, "timer/dataset_train_max": 0.0006299018859863281, "timer/agent.train_count": 2010.0, "timer/agent.train_total": 900.3513939380646, "timer/agent.train_frac": 0.900067562732256, "timer/agent.train_avg": 0.44793601688460927, "timer/agent.train_min": 0.436145544052124, "timer/agent.train_max": 0.6968348026275635, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4783899784088135, "timer/agent.report_frac": 0.00047823916839693066, "timer/agent.report_avg": 0.23919498920440674, "timer/agent.report_min": 0.23234963417053223, "timer/agent.report_max": 0.24604034423828125, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8133392333984375e-05, "timer/dataset_eval_frac": 2.8124523424885767e-08, "timer/dataset_eval_avg": 2.8133392333984375e-05, "timer/dataset_eval_min": 2.8133392333984375e-05, "timer/dataset_eval_max": 2.8133392333984375e-05, "fps": 32.149319672456166}
{"step": 1638160, "time": 51269.039052248, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1638392, "time": 51275.92347884178, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1638392, "time": 51275.93247127533, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1638392, "time": 51275.94121146202, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 1638416, "time": 51277.465522289276, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 1638528, "time": 51280.8774125576, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1638544, "time": 51281.37434744835, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1638688, "time": 51285.74655342102, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1638696, "time": 51285.774671792984, "episode/length": 203.0, "episode/score": 0.3656249940395355, "episode/reward_rate": 0.004901960784313725, "episode/intrinsic_return": 0.0}
{"step": 1638880, "time": 51291.550763607025, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 1639136, "time": 51299.290798425674, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1639368, "time": 51306.10676550865, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1639736, "time": 51317.32460784912, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 1639744, "time": 51317.79301953316, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1639768, "time": 51318.30427980423, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1639816, "time": 51319.78340387344, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 1639888, "time": 51322.17816066742, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1640080, "time": 51328.76449370384, "eval_episode/length": 42.0, "eval_episode/score": 0.8687499761581421, "eval_episode/reward_rate": 0.023255813953488372}
{"step": 1640080, "time": 51329.27622270584, "eval_episode/length": 71.0, "eval_episode/score": 0.778124988079071, "eval_episode/reward_rate": 0.013888888888888888}
{"step": 1640080, "time": 51329.38487267494, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 1640080, "time": 51329.739075899124, "eval_episode/length": 97.0, "eval_episode/score": 0.6968749761581421, "eval_episode/reward_rate": 0.01020408163265306}
{"step": 1640080, "time": 51329.88506937027, "eval_episode/length": 105.0, "eval_episode/score": 0.671875, "eval_episode/reward_rate": 0.009433962264150943}
{"step": 1640080, "time": 51330.54872369766, "eval_episode/length": 36.0, "eval_episode/score": 0.887499988079071, "eval_episode/reward_rate": 0.02702702702702703}
{"step": 1640080, "time": 51330.99956512451, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 1640080, "time": 51331.408857584, "eval_episode/length": 146.0, "eval_episode/score": 0.543749988079071, "eval_episode/reward_rate": 0.006802721088435374}
{"step": 1640328, "time": 51338.80922484398, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1640640, "time": 51348.47489762306, "episode/length": 280.0, "episode/score": 0.125, "episode/reward_rate": 0.0035587188612099642, "episode/intrinsic_return": 0.0}
{"step": 1640704, "time": 51350.412497758865, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1640864, "time": 51355.286853313446, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1641000, "time": 51359.207845687866, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 1641000, "time": 51359.21653342247, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1641008, "time": 51359.68868494034, "episode/length": 288.0, "episode/score": 0.10000000149011612, "episode/reward_rate": 0.0034602076124567475, "episode/intrinsic_return": 0.0}
{"step": 1641032, "time": 51360.19750905037, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1641104, "time": 51362.629352808, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1641216, "time": 51366.01636719704, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1641328, "time": 51369.49423623085, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 1641544, "time": 51375.81474065781, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1641704, "time": 51380.670057058334, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1641752, "time": 51382.154507398605, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1641768, "time": 51382.641573667526, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1641880, "time": 51386.04514622688, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1642048, "time": 51391.39457941055, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1642280, "time": 51398.30376315117, "episode/length": 196.0, "episode/score": 0.38749998807907104, "episode/reward_rate": 0.005076142131979695, "episode/intrinsic_return": 0.0}
{"step": 1642360, "time": 51400.74815988541, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1642384, "time": 51401.71676826477, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 1642616, "time": 51408.50987672806, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1642688, "time": 51410.91952967644, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 1642864, "time": 51416.2552793026, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1642976, "time": 51419.66443896294, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1643072, "time": 51422.57596039772, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 1643200, "time": 51426.504851818085, "episode/length": 247.0, "episode/score": 0.22812500596046448, "episode/reward_rate": 0.004032258064516129, "episode/intrinsic_return": 0.0}
{"step": 1643360, "time": 51431.41250824928, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1643384, "time": 51431.92331171036, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1643656, "time": 51440.180439949036, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1643688, "time": 51441.14784836769, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 1643968, "time": 51449.81743693352, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1644312, "time": 51460.0102789402, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1644352, "time": 51461.436160087585, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 1644440, "time": 51463.86707043648, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1644536, "time": 51466.737162828445, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1644680, "time": 51471.05200910568, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1644728, "time": 51472.48657536507, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1644832, "time": 51475.83954954147, "episode/length": 245.0, "episode/score": 0.234375, "episode/reward_rate": 0.0040650406504065045, "episode/intrinsic_return": 0.0}
{"step": 1645088, "time": 51483.595631837845, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 1645160, "time": 51485.54409980774, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1645208, "time": 51487.065730810165, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1645400, "time": 51492.9186296463, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1645400, "time": 51492.92431497574, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1645552, "time": 51497.81351804733, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1645720, "time": 51502.69400477409, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1645992, "time": 51510.99892401695, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1646008, "time": 51511.494322538376, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1646176, "time": 51517.065814733505, "episode/length": 227.0, "episode/score": 0.2906250059604645, "episode/reward_rate": 0.0043859649122807015, "episode/intrinsic_return": 0.0}
{"step": 1646216, "time": 51518.08684134483, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1646376, "time": 51522.96243405342, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1646536, "time": 51527.797949552536, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1646664, "time": 51532.1884803772, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1646776, "time": 51535.61668539047, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1646776, "time": 51535.62611055374, "episode/length": 195.0, "episode/score": 0.390625, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.0}
{"step": 1646840, "time": 51537.59236550331, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1646840, "time": 51537.599039554596, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1647120, "time": 51546.29940152168, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1647152, "time": 51547.380039691925, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 1647192, "time": 51548.380779743195, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1647288, "time": 51551.29633188248, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1647648, "time": 51562.5852432251, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1647776, "time": 51566.50286149979, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1647864, "time": 51568.97206544876, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1647880, "time": 51569.46364879608, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1647944, "time": 51571.40415096283, "episode/length": 220.0, "episode/score": 0.3125, "episode/reward_rate": 0.004524886877828055, "episode/intrinsic_return": 0.0}
{"step": 1648216, "time": 51579.76753401756, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1648352, "time": 51584.11904859543, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1648376, "time": 51584.625326156616, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 1648808, "time": 51597.71796178818, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1649056, "time": 51605.42919230461, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1649080, "time": 51605.95878410339, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1649104, "time": 51607.00185918808, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 1649112, "time": 51607.03106546402, "episode/length": 244.0, "episode/score": 0.23749999701976776, "episode/reward_rate": 0.004081632653061225, "episode/intrinsic_return": 0.0}
{"step": 1649368, "time": 51614.783812999725, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1649640, "time": 51623.06720352173, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 1649776, "time": 51627.43018436432, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1649792, "time": 51627.918744802475, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1649816, "time": 51628.43282079697, "episode/length": 199.0, "episode/score": 0.37812501192092896, "episode/reward_rate": 0.005, "episode/intrinsic_return": 0.0}
{"step": 1649984, "time": 51633.75594305992, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1650016, "time": 51634.73110675812, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1650064, "time": 51637.13022899628, "eval_episode/length": 39.0, "eval_episode/score": 0.878125011920929, "eval_episode/reward_rate": 0.025}
{"step": 1650064, "time": 51637.193479299545, "eval_episode/length": 42.0, "eval_episode/score": 0.8687499761581421, "eval_episode/reward_rate": 0.023255813953488372}
{"step": 1650064, "time": 51637.21872496605, "eval_episode/length": 43.0, "eval_episode/score": 0.8656250238418579, "eval_episode/reward_rate": 0.022727272727272728}
{"step": 1650064, "time": 51637.54841566086, "eval_episode/length": 60.0, "eval_episode/score": 0.8125, "eval_episode/reward_rate": 0.01639344262295082}
{"step": 1650064, "time": 51638.00012111664, "eval_episode/length": 23.0, "eval_episode/score": 0.9281250238418579, "eval_episode/reward_rate": 0.041666666666666664}
{"step": 1650064, "time": 51638.15158987045, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 1650064, "time": 51638.29351043701, "eval_episode/length": 99.0, "eval_episode/score": 0.690625011920929, "eval_episode/reward_rate": 0.01}
{"step": 1650064, "time": 51638.70813059807, "eval_episode/length": 119.0, "eval_episode/score": 0.628125011920929, "eval_episode/reward_rate": 0.008333333333333333}
{"step": 1650168, "time": 51641.645592451096, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1650304, "time": 51645.988981962204, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1650376, "time": 51647.95537638664, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1650432, "time": 51649.85824203491, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 1650472, "time": 51650.84577012062, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1650696, "time": 51657.627616882324, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1650896, "time": 51663.88560819626, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1651056, "time": 51668.784031152725, "episode/length": 19.0, "episode/score": 0.940625011920929, "episode/reward_rate": 0.05, "episode/intrinsic_return": 0.0}
{"step": 1651328, "time": 51676.96737384796, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1651384, "time": 51678.422447919846, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 1651520, "time": 51682.75103139877, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 1651576, "time": 51684.214183568954, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 1651808, "time": 51691.44588184357, "episode/length": 253.0, "episode/score": 0.20937499403953552, "episode/reward_rate": 0.003937007874015748, "episode/intrinsic_return": 0.0}
{"step": 1651856, "time": 51692.89719891548, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 1651912, "time": 51694.36485219002, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 1651952, "time": 51695.81130480766, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1651992, "time": 51696.90423536301, "episode/length": 201.0, "episode/score": 0.37187498807907104, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.0}
{"step": 1652056, "time": 51698.843015909195, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1652232, "time": 51704.16583251953, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1652376, "time": 51708.52520942688, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1652472, "time": 51711.44287252426, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1652560, "time": 51714.31024813652, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1652648, "time": 51716.75147771835, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1652824, "time": 51722.070700883865, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1653288, "time": 51736.199419260025, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1653360, "time": 51738.58675289154, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1653600, "time": 51745.86670565605, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 1653832, "time": 51752.66446185112, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 1653864, "time": 51753.627254247665, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 1653960, "time": 51756.5727314949, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1654120, "time": 51761.41771674156, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1654224, "time": 51764.784885168076, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1654264, "time": 51765.77672767639, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1654352, "time": 51768.67245078087, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1654736, "time": 51780.25602173805, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1654800, "time": 51782.657249212265, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1654880, "time": 51785.079345703125, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1655056, "time": 51790.445746183395, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1655120, "time": 51792.3801817894, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 1655224, "time": 51795.33599114418, "episode/length": 202.0, "episode/score": 0.3687500059604645, "episode/reward_rate": 0.0049261083743842365, "episode/intrinsic_return": 0.0}
{"step": 1655520, "time": 51804.524522304535, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1655536, "time": 51805.0132689476, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1655728, "time": 51810.817142248154, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1655728, "time": 51810.82537484169, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1655824, "time": 51813.73664975166, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1655936, "time": 51817.25251078606, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1656040, "time": 51820.20965719223, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 1656120, "time": 51822.654650211334, "episode/length": 281.0, "episode/score": 0.12187500298023224, "episode/reward_rate": 0.0035460992907801418, "episode/intrinsic_return": 0.0}
{"step": 1656192, "time": 51825.07975554466, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1656336, "time": 51829.44489598274, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1656384, "time": 51830.89022350311, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 1656408, "time": 51831.39627575874, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1656720, "time": 51841.06742167473, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1656824, "time": 51844.013070344925, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1656920, "time": 51847.074352264404, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1656952, "time": 51848.04598093033, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1657008, "time": 51849.95902657509, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1657160, "time": 51854.326328754425, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1657208, "time": 51855.78887438774, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1657472, "time": 51864.021064043045, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 1657576, "time": 51866.96471261978, "episode/length": 204.0, "episode/score": 0.36250001192092896, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.0}
{"step": 1657584, "time": 51867.43114566803, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1657728, "time": 51871.78407597542, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1657752, "time": 51872.29157209396, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1657784, "time": 51873.25566291809, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 1657976, "time": 51879.18659877777, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1658112, "time": 51883.52006459236, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 1658296, "time": 51888.848422288895, "episode/length": 235.0, "episode/score": 0.265625, "episode/reward_rate": 0.00423728813559322, "episode/intrinsic_return": 0.0}
{"step": 1658320, "time": 51889.78984093666, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1658328, "time": 51889.81686925888, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1658328, "time": 51889.82334256172, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1658536, "time": 51896.09082722664, "episode/length": 213.0, "episode/score": 0.3343749940395355, "episode/reward_rate": 0.004672897196261682, "episode/intrinsic_return": 0.0}
{"step": 1658536, "time": 51896.09875154495, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1658912, "time": 51907.79188704491, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1658952, "time": 51908.78389167786, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1659288, "time": 51918.95859503746, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1659304, "time": 51919.447451114655, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 1659424, "time": 51923.284205675125, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1659528, "time": 51926.21319079399, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 1659568, "time": 51927.635137081146, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 1659688, "time": 51931.05063319206, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1659888, "time": 51937.392622470856, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 1659992, "time": 51940.33310484886, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1660048, "time": 51943.84971380234, "eval_episode/length": 85.0, "eval_episode/score": 0.734375, "eval_episode/reward_rate": 0.011627906976744186}
{"step": 1660048, "time": 51944.05878686905, "eval_episode/length": 96.0, "eval_episode/score": 0.699999988079071, "eval_episode/reward_rate": 0.010309278350515464}
{"step": 1660048, "time": 51944.847893476486, "eval_episode/length": 139.0, "eval_episode/score": 0.565625011920929, "eval_episode/reward_rate": 0.007142857142857143}
{"step": 1660048, "time": 51944.90874385834, "eval_episode/length": 142.0, "eval_episode/score": 0.5562499761581421, "eval_episode/reward_rate": 0.006993006993006993}
{"step": 1660048, "time": 51945.08738064766, "eval_episode/length": 151.0, "eval_episode/score": 0.528124988079071, "eval_episode/reward_rate": 0.006578947368421052}
{"step": 1660048, "time": 51945.113419532776, "eval_episode/length": 152.0, "eval_episode/score": 0.5249999761581421, "eval_episode/reward_rate": 0.006535947712418301}
{"step": 1660048, "time": 51946.04248094559, "eval_episode/length": 116.0, "eval_episode/score": 0.637499988079071, "eval_episode/reward_rate": 0.008547008547008548}
{"step": 1660048, "time": 51946.06622862816, "eval_episode/length": 63.0, "eval_episode/score": 0.8031250238418579, "eval_episode/reward_rate": 0.015625}
{"step": 1660504, "time": 51959.64949178696, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1660520, "time": 51960.13461828232, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1660592, "time": 51962.54413819313, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1661040, "time": 51976.16441988945, "episode/length": 218.0, "episode/score": 0.3187499940395355, "episode/reward_rate": 0.0045662100456621, "episode/intrinsic_return": 0.0}
{"step": 1661048, "time": 51976.19212460518, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 1661184, "time": 51980.550434589386, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1661464, "time": 51988.83259034157, "episode/length": 254.0, "episode/score": 0.20624999701976776, "episode/reward_rate": 0.00392156862745098, "episode/intrinsic_return": 0.0}
{"step": 1661760, "time": 51998.03147149086, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 1661840, "time": 52000.47025561333, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1661912, "time": 52002.48221755028, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1662000, "time": 52005.39540886879, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1662688, "time": 52026.14212679863, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1662704, "time": 52026.766507864, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 1662776, "time": 52028.7405936718, "episode/length": 215.0, "episode/score": 0.328125, "episode/reward_rate": 0.004629629629629629, "episode/intrinsic_return": 0.0}
{"step": 1662816, "time": 52030.18969678879, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1662816, "time": 52030.196868896484, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1662920, "time": 52033.17614722252, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 1663104, "time": 52039.409831762314, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1663352, "time": 52046.74120759964, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1663528, "time": 52052.10818910599, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1663560, "time": 52053.078446149826, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1663720, "time": 52058.01421689987, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1663952, "time": 52065.27271127701, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1664208, "time": 52072.99240064621, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 1664320, "time": 52076.37258553505, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1664408, "time": 52078.79361248016, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 1664464, "time": 52080.7247710228, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1664664, "time": 52086.56201457977, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1664848, "time": 52092.348266124725, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 1664984, "time": 52096.269948244095, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1665000, "time": 52096.76101446152, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1665056, "time": 52098.67111968994, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1665368, "time": 52107.896228551865, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 1665480, "time": 52111.297703266144, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1665512, "time": 52112.2713663578, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1665808, "time": 52121.634231090546, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1665872, "time": 52123.58593463898, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1666000, "time": 52127.42900633812, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1666064, "time": 52129.38894367218, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1666192, "time": 52133.26965093613, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 1666216, "time": 52133.781274318695, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1666520, "time": 52143.000540971756, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1666688, "time": 52148.42093515396, "episode/length": 210.0, "episode/score": 0.34375, "episode/reward_rate": 0.004739336492890996, "episode/intrinsic_return": 0.0}
{"step": 1666872, "time": 52153.772461891174, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1667272, "time": 52165.89157438278, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 1667280, "time": 52166.35684013367, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1667312, "time": 52167.34724569321, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1667368, "time": 52168.825776576996, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 1667680, "time": 52178.58201956749, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1667768, "time": 52181.01809716225, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1667792, "time": 52181.98579096794, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1668120, "time": 52191.68860936165, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1668392, "time": 52199.88856339455, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1668528, "time": 52204.25045633316, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1668656, "time": 52208.23239374161, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 1668768, "time": 52211.63067650795, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 1669056, "time": 52220.3249373436, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1669184, "time": 52224.18856930733, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1669248, "time": 52226.13453292847, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 1669312, "time": 52228.058727264404, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1669464, "time": 52232.43243432045, "episode/length": 273.0, "episode/score": 0.14687499403953552, "episode/reward_rate": 0.0036496350364963502, "episode/intrinsic_return": 0.0}
{"step": 1669696, "time": 52239.717587947845, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1669704, "time": 52239.74406003952, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1669704, "time": 52239.75320506096, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1669992, "time": 52248.48501610756, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1670032, "time": 52249.94756436348, "episode/length": 187.0, "episode/score": 0.4156250059604645, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.0}
{"step": 1670032, "time": 52250.16147851944, "eval_episode/length": 10.0, "eval_episode/score": 0.96875, "eval_episode/reward_rate": 0.09090909090909091}
{"step": 1670032, "time": 52252.09425139427, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 1670032, "time": 52252.332854270935, "eval_episode/length": 93.0, "eval_episode/score": 0.7093750238418579, "eval_episode/reward_rate": 0.010638297872340425}
{"step": 1670032, "time": 52252.73501420021, "eval_episode/length": 115.0, "eval_episode/score": 0.640625, "eval_episode/reward_rate": 0.008620689655172414}
{"step": 1670032, "time": 52253.14011716843, "eval_episode/length": 137.0, "eval_episode/score": 0.5718749761581421, "eval_episode/reward_rate": 0.007246376811594203}
{"step": 1670032, "time": 52253.481882572174, "eval_episode/length": 156.0, "eval_episode/score": 0.512499988079071, "eval_episode/reward_rate": 0.006369426751592357}
{"step": 1670032, "time": 52253.6841135025, "eval_episode/length": 156.0, "eval_episode/score": 0.512499988079071, "eval_episode/reward_rate": 0.006369426751592357}
{"step": 1670032, "time": 52254.16596484184, "eval_episode/length": 99.0, "eval_episode/score": 0.690625011920929, "eval_episode/reward_rate": 0.01}
{"step": 1670240, "time": 52260.47972416878, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1670240, "time": 52260.48995280266, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 1670248, "time": 52260.51945114136, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1670328, "time": 52262.926929712296, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1670328, "time": 52262.93612289429, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 1670416, "time": 52265.83163690567, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 1670473, "time": 52268.56239485741, "train_stats/mean_log_entropy": 0.07517993785736579, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.529093525197246, "train/action_min": 0.0, "train/action_std": 1.8218802254978974, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.012489134570270186, "train/actor_opt_grad_steps": 103295.0, "train/actor_opt_loss": -36.64131183435421, "train/adv_mag": 0.8573225571377443, "train/adv_max": 0.32901801331208486, "train/adv_mean": 0.0019240509381288034, "train/adv_min": -0.7810993058846729, "train/adv_std": 0.03514334198898903, "train/cont_avg": 0.9928643254950495, "train/cont_loss_mean": 0.02990590363261428, "train/cont_loss_std": 0.30442575925942694, "train/cont_neg_acc": 0.11017780581323228, "train/cont_neg_loss": 3.289498964158615, "train/cont_pos_acc": 0.9998831598475428, "train/cont_pos_loss": 0.006389011923998299, "train/cont_pred": 0.992861934522591, "train/cont_rate": 0.9928643254950495, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.11157096126162917, "train/extr_critic_critic_opt_grad_steps": 103295.0, "train/extr_critic_critic_opt_loss": 13080.383615021658, "train/extr_critic_mag": 1.9082737382095638, "train/extr_critic_max": 1.9082737382095638, "train/extr_critic_mean": 1.7701778110891286, "train/extr_critic_min": 1.4412726576965633, "train/extr_critic_std": 0.03860772987551028, "train/extr_return_normed_mag": 0.8655733171075878, "train/extr_return_normed_max": 0.3444083539566191, "train/extr_return_normed_mean": 0.08584522439332881, "train/extr_return_normed_min": -0.7226401083540208, "train/extr_return_normed_std": 0.053032139353085275, "train/extr_return_rate": 0.99971672243411, "train/extr_return_raw_mag": 2.03066482579354, "train/extr_return_raw_max": 2.03066482579354, "train/extr_return_raw_mean": 1.7721017711233384, "train/extr_return_raw_min": 0.9636163634829001, "train/extr_return_raw_std": 0.05303213953750559, "train/extr_reward_mag": 0.283013376859155, "train/extr_reward_max": 0.283013376859155, "train/extr_reward_mean": 0.0031179264625811045, "train/extr_reward_min": 1.0032464962194462e-08, "train/extr_reward_std": 0.009863064008866353, "train/image_loss_mean": 0.09260956944879328, "train/image_loss_std": 0.10361907966803796, "train/model_loss_mean": 0.7505538661291103, "train/model_loss_std": 0.6166844846736087, "train/model_opt_grad_norm": 13.443293813449234, "train/model_opt_grad_steps": 103200.75247524753, "train/model_opt_loss": 3881.086544225712, "train/model_opt_model_opt_grad_overflow": 0.0049504950495049506, "train/model_opt_model_opt_grad_scale": 5148.514851485149, "train/policy_entropy_mag": 1.1719298374534834, "train/policy_entropy_max": 1.1719298374534834, "train/policy_entropy_mean": 0.08115188928671402, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.08655413727063944, "train/policy_logprob_mag": 6.551080292994433, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.08117473977479604, "train/policy_logprob_min": -6.551080292994433, "train/policy_logprob_std": 0.6189190299794225, "train/policy_randomness_mag": 0.6022528371598461, "train/policy_randomness_max": 0.6022528371598461, "train/policy_randomness_mean": 0.041703826701729604, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.0444800303050197, "train/post_ent_mag": 29.1332000411383, "train/post_ent_max": 29.1332000411383, "train/post_ent_mean": 28.294195949441136, "train/post_ent_min": 27.440777485913568, "train/post_ent_std": 0.3591884246999674, "train/prior_ent_mag": 28.510923442274038, "train/prior_ent_max": 28.510923442274038, "train/prior_ent_mean": 27.697832636313862, "train/prior_ent_min": 26.46524986418167, "train/prior_ent_std": 0.3380578807970085, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.003795873065419163, "train/reward_loss_mean": 0.028038374701570168, "train/reward_loss_std": 0.3132872315547844, "train/reward_max_data": 0.8216274758376697, "train/reward_max_pred": 0.3568380339310901, "train/reward_neg_acc": 0.9993680385079714, "train/reward_neg_loss": 0.0052254598986560315, "train/reward_pos_acc": 0.14296715658637557, "train/reward_pos_loss": 3.975572948998744, "train/reward_pred": 0.0030300864652444675, "train/reward_rate": 0.005724009900990099, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.02761802263557911, "report/cont_loss_std": 0.3242783844470978, "report/cont_neg_acc": 0.2857142984867096, "report/cont_neg_loss": 3.083998203277588, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.006580992601811886, "report/cont_pred": 0.9915978908538818, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.07597043365240097, "report/image_loss_std": 0.09325449913740158, "report/model_loss_mean": 0.7213261127471924, "report/model_loss_std": 0.47528544068336487, "report/post_ent_mag": 28.754241943359375, "report/post_ent_max": 28.754241943359375, "report/post_ent_mean": 28.069896697998047, "report/post_ent_min": 27.31814956665039, "report/post_ent_std": 0.32850441336631775, "report/prior_ent_mag": 28.446868896484375, "report/prior_ent_max": 28.446868896484375, "report/prior_ent_mean": 27.785184860229492, "report/prior_ent_min": 26.647294998168945, "report/prior_ent_std": 0.30608099699020386, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0035644532181322575, "report/reward_loss_mean": 0.01773761212825775, "report/reward_loss_std": 0.20292508602142334, "report/reward_max_data": 0.784375011920929, "report/reward_max_pred": 0.629990816116333, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.005236684810370207, "report/reward_pos_acc": 0.4000000059604645, "report/reward_pos_loss": 2.56542706489563, "report/reward_pred": 0.003910694271326065, "report/reward_rate": 0.0048828125, "eval/cont_avg": 0.9921875, "eval/cont_loss_mean": 0.044941991567611694, "eval/cont_loss_std": 0.4770844578742981, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.025003433227539, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.005728910677134991, "eval/cont_pred": 0.994270920753479, "eval/cont_rate": 0.9921875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.13316386938095093, "eval/image_loss_std": 0.13184231519699097, "eval/model_loss_mean": 0.8291590213775635, "eval/model_loss_std": 1.0545753240585327, "eval/post_ent_mag": 28.754173278808594, "eval/post_ent_max": 28.754173278808594, "eval/post_ent_mean": 28.05878448486328, "eval/post_ent_min": 27.291494369506836, "eval/post_ent_std": 0.32527583837509155, "eval/prior_ent_mag": 29.356853485107422, "eval/prior_ent_max": 29.356853485107422, "eval/prior_ent_mean": 27.760475158691406, "eval/prior_ent_min": 26.68825912475586, "eval/prior_ent_std": 0.30402687191963196, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0051666260696947575, "eval/reward_loss_mean": 0.051053114235401154, "eval/reward_loss_std": 0.5422619581222534, "eval/reward_max_data": 0.828125, "eval/reward_max_pred": 0.06689584255218506, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.004618417471647263, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.9482598304748535, "eval/reward_pred": 0.002344300737604499, "eval/reward_rate": 0.0078125, "replay/size": 1000000.0, "replay/inserts": 32336.0, "replay/samples": 32336.0, "replay/insert_wait_avg": 1.187418310551405e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.342784962755569e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5664.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0654330253601074e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.450580596923828e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0358655452728, "timer/env.step_count": 4042.0, "timer/env.step_total": 39.01220417022705, "timer/env.step_frac": 0.03901080502643325, "timer/env.step_avg": 0.00965170810742876, "timer/env.step_min": 0.0076296329498291016, "timer/env.step_max": 0.03502297401428223, "timer/replay._sample_count": 32336.0, "timer/replay._sample_total": 16.44422221183777, "timer/replay._sample_frac": 0.016443632451993612, "timer/replay._sample_avg": 0.0005085422504897875, "timer/replay._sample_min": 0.00039958953857421875, "timer/replay._sample_max": 0.02885603904724121, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4750.0, "timer/agent.policy_total": 50.027846813201904, "timer/agent.policy_frac": 0.0500260526015475, "timer/agent.policy_avg": 0.010532178276463558, "timer/agent.policy_min": 0.008881330490112305, "timer/agent.policy_max": 0.0863490104675293, "timer/dataset_train_count": 2021.0, "timer/dataset_train_total": 0.20933985710144043, "timer/dataset_train_frac": 0.00020933234928259016, "timer/dataset_train_avg": 0.00010358231425108384, "timer/dataset_train_min": 9.012222290039062e-05, "timer/dataset_train_max": 0.0003256797790527344, "timer/agent.train_count": 2021.0, "timer/agent.train_total": 898.0983216762543, "timer/agent.train_frac": 0.8980661120454547, "timer/agent.train_avg": 0.4443831378902792, "timer/agent.train_min": 0.43397045135498047, "timer/agent.train_max": 0.6727261543273926, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4722898006439209, "timer/agent.report_frac": 0.00047227286232019624, "timer/agent.report_avg": 0.23614490032196045, "timer/agent.report_min": 0.23032045364379883, "timer/agent.report_max": 0.24196934700012207, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7179718017578125e-05, "timer/dataset_eval_frac": 2.7178743237132094e-08, "timer/dataset_eval_avg": 2.7179718017578125e-05, "timer/dataset_eval_min": 2.7179718017578125e-05, "timer/dataset_eval_max": 2.7179718017578125e-05, "fps": 32.334299056988186}
{"step": 1670536, "time": 52270.259502887726, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1670808, "time": 52278.48330616951, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1670840, "time": 52279.473331213, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1670912, "time": 52281.87535715103, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1670936, "time": 52282.381598711014, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1671152, "time": 52289.14615535736, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 1671288, "time": 52293.50965118408, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1671344, "time": 52295.44810080528, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1671680, "time": 52305.72570490837, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1671824, "time": 52310.11056280136, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 1671848, "time": 52310.626242399216, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1672256, "time": 52323.209000110626, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1672320, "time": 52325.17687010765, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1672552, "time": 52332.15335512161, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1672720, "time": 52337.4870493412, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1672728, "time": 52337.51977062225, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1672896, "time": 52342.84032583237, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1672904, "time": 52342.86800909042, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 1673008, "time": 52346.2470433712, "episode/length": 231.0, "episode/score": 0.27812498807907104, "episode/reward_rate": 0.004310344827586207, "episode/intrinsic_return": 0.0}
{"step": 1673184, "time": 52351.583706855774, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1673248, "time": 52353.53779792786, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1673416, "time": 52358.49824595451, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1673640, "time": 52365.30250620842, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1673888, "time": 52373.058411836624, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1673920, "time": 52374.034090042114, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1674072, "time": 52378.42433476448, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1674144, "time": 52380.81797814369, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1674272, "time": 52384.71531367302, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1674280, "time": 52384.74290275574, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1674560, "time": 52393.673456430435, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1674696, "time": 52397.796033382416, "episode/length": 210.0, "episode/score": 0.34375, "episode/reward_rate": 0.004739336492890996, "episode/intrinsic_return": 0.0}
{"step": 1674864, "time": 52403.20203065872, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1675088, "time": 52410.06050348282, "episode/length": 229.0, "episode/score": 0.28437501192092896, "episode/reward_rate": 0.004347826086956522, "episode/intrinsic_return": 0.0}
{"step": 1675104, "time": 52410.55482959747, "episode/length": 275.0, "episode/score": 0.140625, "episode/reward_rate": 0.0036231884057971015, "episode/intrinsic_return": 0.0}
{"step": 1675192, "time": 52413.02967405319, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1675200, "time": 52413.50132608414, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1675280, "time": 52415.92602968216, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1675360, "time": 52418.47752356529, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1675376, "time": 52418.97074007988, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1675632, "time": 52426.88837122917, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1675808, "time": 52432.2868514061, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1676264, "time": 52446.017860651016, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1676288, "time": 52447.085374355316, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1676328, "time": 52448.08896493912, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 1676448, "time": 52451.99676299095, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0}
{"step": 1676488, "time": 52453.008773088455, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 1676512, "time": 52453.98038625717, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 1676544, "time": 52454.96839094162, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 1676728, "time": 52460.39193701744, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1676912, "time": 52466.27891731262, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0}
{"step": 1677496, "time": 52483.89122390747, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1677520, "time": 52484.84103512764, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1677568, "time": 52486.305034160614, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 1677784, "time": 52492.61962008476, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 1677944, "time": 52497.49199819565, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1678024, "time": 52499.89923930168, "episode/length": 276.0, "episode/score": 0.13750000298023224, "episode/reward_rate": 0.0036101083032490976, "episode/intrinsic_return": 0.0}
{"step": 1678352, "time": 52510.22887444496, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 1678528, "time": 52515.56590151787, "episode/length": 254.0, "episode/score": 0.20624999701976776, "episode/reward_rate": 0.00392156862745098, "episode/intrinsic_return": 0.0}
{"step": 1678624, "time": 52518.478066682816, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1678784, "time": 52523.354194164276, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 1678792, "time": 52523.38160610199, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1678864, "time": 52525.80681014061, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1678880, "time": 52526.2948114872, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 1679056, "time": 52531.62299799919, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 1679168, "time": 52535.02908706665, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 1679296, "time": 52539.014615774155, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1679352, "time": 52540.518062114716, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1679544, "time": 52546.82011795044, "episode/length": 199.0, "episode/score": 0.37812501192092896, "episode/reward_rate": 0.005, "episode/intrinsic_return": 0.0}
{"step": 1679640, "time": 52549.73820185661, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1679704, "time": 52551.68772125244, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1679848, "time": 52556.072674036026, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1680016, "time": 52562.5527985096, "eval_episode/length": 59.0, "eval_episode/score": 0.815625011920929, "eval_episode/reward_rate": 0.016666666666666666}
{"step": 1680016, "time": 52562.86102151871, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 1680016, "time": 52563.25059604645, "eval_episode/length": 93.0, "eval_episode/score": 0.7093750238418579, "eval_episode/reward_rate": 0.010638297872340425}
{"step": 1680016, "time": 52563.37997674942, "eval_episode/length": 99.0, "eval_episode/score": 0.690625011920929, "eval_episode/reward_rate": 0.01}
{"step": 1680016, "time": 52563.5458612442, "eval_episode/length": 107.0, "eval_episode/score": 0.6656249761581421, "eval_episode/reward_rate": 0.009259259259259259}
{"step": 1680016, "time": 52563.78261947632, "eval_episode/length": 119.0, "eval_episode/score": 0.628125011920929, "eval_episode/reward_rate": 0.008333333333333333}
{"step": 1680016, "time": 52563.88171339035, "eval_episode/length": 49.0, "eval_episode/score": 0.846875011920929, "eval_episode/reward_rate": 0.02}
{"step": 1680016, "time": 52564.10670733452, "eval_episode/length": 27.0, "eval_episode/score": 0.9156249761581421, "eval_episode/reward_rate": 0.03571428571428571}
{"step": 1680136, "time": 52567.593760252, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1680136, "time": 52567.60217809677, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1680288, "time": 52572.44932842255, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1680360, "time": 52574.407908439636, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 1680504, "time": 52578.7878472805, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1680632, "time": 52582.68473291397, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1680944, "time": 52592.407500743866, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1681080, "time": 52596.33053135872, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1681104, "time": 52597.365700006485, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1681200, "time": 52600.3090069294, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1681576, "time": 52611.54385089874, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1681632, "time": 52613.467550992966, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1681648, "time": 52613.95953416824, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1681664, "time": 52614.45082497597, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1681824, "time": 52619.33095383644, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1681920, "time": 52622.27136301994, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 1682008, "time": 52624.72677206993, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1682016, "time": 52625.201533317566, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1682224, "time": 52631.681992053986, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1682232, "time": 52631.7096824646, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1682256, "time": 52632.66269207001, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1682264, "time": 52632.68935918808, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1682544, "time": 52641.4609041214, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 1682592, "time": 52642.913962602615, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1682600, "time": 52642.94105362892, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1682608, "time": 52643.4064207077, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1682688, "time": 52645.846415281296, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 1682816, "time": 52649.71240711212, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1682864, "time": 52651.18710041046, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 1683056, "time": 52657.11214661598, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1683144, "time": 52659.58818483353, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 1683792, "time": 52679.4622900486, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1683856, "time": 52681.4028904438, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1683904, "time": 52682.856634140015, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 1683944, "time": 52683.84675884247, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1684168, "time": 52690.73772716522, "episode/length": 202.0, "episode/score": 0.3687500059604645, "episode/reward_rate": 0.0049261083743842365, "episode/intrinsic_return": 0.0}
{"step": 1684288, "time": 52694.575874090195, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 1684456, "time": 52699.44444203377, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1684592, "time": 52703.8050057888, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1684640, "time": 52705.24202919006, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1684912, "time": 52713.44512581825, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1685056, "time": 52717.90608334541, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1685096, "time": 52718.92187690735, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1685360, "time": 52727.147844314575, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1685368, "time": 52727.17587304115, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1685448, "time": 52729.61562728882, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1685456, "time": 52730.08274412155, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1685504, "time": 52731.55637860298, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 1685664, "time": 52736.46299910545, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1685856, "time": 52742.29041028023, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1685944, "time": 52744.74767589569, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 1686152, "time": 52751.16905260086, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1686464, "time": 52760.862860918045, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1686520, "time": 52762.354387283325, "episode/length": 182.0, "episode/score": 0.4312500059604645, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.0}
{"step": 1686896, "time": 52773.94281697273, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1686952, "time": 52775.41397500038, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1687312, "time": 52786.63714647293, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 1687376, "time": 52788.581681489944, "episode/length": 250.0, "episode/score": 0.21875, "episode/reward_rate": 0.00398406374501992, "episode/intrinsic_return": 0.0}
{"step": 1687408, "time": 52789.552869558334, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1687712, "time": 52799.202033281326, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1687760, "time": 52800.6578540802, "episode/length": 287.0, "episode/score": 0.10312499850988388, "episode/reward_rate": 0.003472222222222222, "episode/intrinsic_return": 0.0}
{"step": 1687784, "time": 52801.16292834282, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1688016, "time": 52808.46612739563, "episode/length": 269.0, "episode/score": 0.15937499701976776, "episode/reward_rate": 0.003703703703703704, "episode/intrinsic_return": 0.0}
{"step": 1688064, "time": 52809.91557073593, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1688120, "time": 52811.40696597099, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 1688184, "time": 52813.33920621872, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1688240, "time": 52815.255487680435, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1688664, "time": 52827.94433069229, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1688832, "time": 52833.257486104965, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1688896, "time": 52835.19216966629, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1688904, "time": 52835.21943736076, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1689376, "time": 52849.92624402046, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 1689480, "time": 52852.88752126694, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 1689600, "time": 52856.788403987885, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 1689720, "time": 52860.208340168, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1689944, "time": 52867.11657834053, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1690000, "time": 52870.33727693558, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 1690000, "time": 52870.873727321625, "eval_episode/length": 87.0, "eval_episode/score": 0.7281249761581421, "eval_episode/reward_rate": 0.011363636363636364}
{"step": 1690000, "time": 52871.117782115936, "eval_episode/length": 99.0, "eval_episode/score": 0.690625011920929, "eval_episode/reward_rate": 0.01}
{"step": 1690000, "time": 52871.35775542259, "eval_episode/length": 111.0, "eval_episode/score": 0.653124988079071, "eval_episode/reward_rate": 0.008928571428571428}
{"step": 1690000, "time": 52872.10375738144, "eval_episode/length": 148.0, "eval_episode/score": 0.5375000238418579, "eval_episode/reward_rate": 0.006711409395973154}
{"step": 1690000, "time": 52872.42107582092, "eval_episode/length": 15.0, "eval_episode/score": 0.953125, "eval_episode/reward_rate": 0.0625}
{"step": 1690000, "time": 52872.884356975555, "eval_episode/length": 188.0, "eval_episode/score": 0.4124999940395355, "eval_episode/reward_rate": 0.005291005291005291}
{"step": 1690000, "time": 52872.99046754837, "eval_episode/length": 81.0, "eval_episode/score": 0.746874988079071, "eval_episode/reward_rate": 0.012195121951219513}
{"step": 1690112, "time": 52876.388417720795, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1690248, "time": 52880.30767583847, "episode/length": 197.0, "episode/score": 0.3843750059604645, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.0}
{"step": 1690376, "time": 52884.195282936096, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1690408, "time": 52885.172042131424, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1690688, "time": 52893.9239320755, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 1690832, "time": 52898.381633758545, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1690872, "time": 52899.41060709953, "episode/length": 254.0, "episode/score": 0.20624999701976776, "episode/reward_rate": 0.00392156862745098, "episode/intrinsic_return": 0.0}
{"step": 1690904, "time": 52900.40635251999, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1691040, "time": 52904.7910194397, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1691120, "time": 52907.21350598335, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1691256, "time": 52911.113357543945, "episode/length": 206.0, "episode/score": 0.35624998807907104, "episode/reward_rate": 0.004830917874396135, "episode/intrinsic_return": 0.0}
{"step": 1691480, "time": 52917.91907572746, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1691520, "time": 52919.3570497036, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1691688, "time": 52924.24778795242, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1691688, "time": 52924.25661087036, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1691792, "time": 52927.796203136444, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1692128, "time": 52937.95594573021, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 1692136, "time": 52937.983057022095, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 1692840, "time": 52959.40540575981, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 1692840, "time": 52959.417109012604, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1693032, "time": 52965.24831485748, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1693048, "time": 52965.73910665512, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 1693216, "time": 52971.057433366776, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 1693352, "time": 52974.96950650215, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1693496, "time": 52979.340644836426, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1693688, "time": 52985.1723446846, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1693832, "time": 52989.68879318237, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1694096, "time": 52997.92332434654, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1694448, "time": 53008.565138578415, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1694464, "time": 53009.05099153519, "episode/length": 202.0, "episode/score": 0.3687500059604645, "episode/reward_rate": 0.0049261083743842365, "episode/intrinsic_return": 0.0}
{"step": 1695176, "time": 53030.52155256271, "episode/length": 227.0, "episode/score": 0.2906250059604645, "episode/reward_rate": 0.0043859649122807015, "episode/intrinsic_return": 0.0}
{"step": 1695280, "time": 53033.896606206894, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 1695376, "time": 53036.80753207207, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 1695480, "time": 53039.74338197708, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1695520, "time": 53041.178500413895, "episode/length": 228.0, "episode/score": 0.2874999940395355, "episode/reward_rate": 0.004366812227074236, "episode/intrinsic_return": 0.0}
{"step": 1695528, "time": 53041.206676483154, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1695696, "time": 53046.519263744354, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1695808, "time": 53050.45831346512, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1695976, "time": 53055.32837986946, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1696240, "time": 53063.53510785103, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1696240, "time": 53063.54424738884, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1696760, "time": 53079.208805561066, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1696808, "time": 53080.694341659546, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1696896, "time": 53083.624920368195, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1697080, "time": 53089.019565582275, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0}
{"step": 1697192, "time": 53092.37769985199, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1697240, "time": 53093.841309547424, "episode/length": 214.0, "episode/score": 0.33125001192092896, "episode/reward_rate": 0.004651162790697674, "episode/intrinsic_return": 0.0}
{"step": 1697512, "time": 53102.01017951965, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1697792, "time": 53110.75340938568, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1698112, "time": 53120.390912771225, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1698120, "time": 53120.418733119965, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1698176, "time": 53122.32994556427, "episode/length": 241.0, "episode/score": 0.24687500298023224, "episode/reward_rate": 0.004132231404958678, "episode/intrinsic_return": 0.0}
{"step": 1698216, "time": 53123.34053206444, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1698312, "time": 53126.256751298904, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1698328, "time": 53126.74983596802, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1698688, "time": 53138.01774120331, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 1698760, "time": 53139.98496007919, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1698792, "time": 53140.96041703224, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1698952, "time": 53145.82361292839, "episode/length": 267.0, "episode/score": 0.16562500596046448, "episode/reward_rate": 0.0037313432835820895, "episode/intrinsic_return": 0.0}
{"step": 1699176, "time": 53152.60055565834, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1699264, "time": 53155.46708917618, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1699304, "time": 53156.46179461479, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1699392, "time": 53159.37038755417, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1699440, "time": 53160.8315114975, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1699656, "time": 53167.321734428406, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1699664, "time": 53167.792768239975, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1699920, "time": 53175.57639837265, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1699928, "time": 53175.60377430916, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1700088, "time": 53182.215312957764, "eval_episode/length": 91.0, "eval_episode/score": 0.715624988079071, "eval_episode/reward_rate": 0.010869565217391304}
{"step": 1700088, "time": 53182.293560266495, "eval_episode/length": 95.0, "eval_episode/score": 0.703125, "eval_episode/reward_rate": 0.010416666666666666}
{"step": 1700088, "time": 53182.35359597206, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 1700088, "time": 53182.39511013031, "eval_episode/length": 100.0, "eval_episode/score": 0.6875, "eval_episode/reward_rate": 0.009900990099009901}
{"step": 1700088, "time": 53182.587052583694, "eval_episode/length": 110.0, "eval_episode/score": 0.65625, "eval_episode/reward_rate": 0.009009009009009009}
{"step": 1700088, "time": 53182.64816713333, "eval_episode/length": 113.0, "eval_episode/score": 0.6468750238418579, "eval_episode/reward_rate": 0.008771929824561403}
{"step": 1700088, "time": 53182.94682216644, "eval_episode/length": 129.0, "eval_episode/score": 0.596875011920929, "eval_episode/reward_rate": 0.007692307692307693}
{"step": 1700088, "time": 53184.08929038048, "eval_episode/length": 96.0, "eval_episode/score": 0.699999988079071, "eval_episode/reward_rate": 0.010309278350515464}
{"step": 1700088, "time": 53184.09583377838, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 1700104, "time": 53184.58980846405, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1700120, "time": 53185.1096971035, "episode/length": 237.0, "episode/score": 0.2593750059604645, "episode/reward_rate": 0.004201680672268907, "episode/intrinsic_return": 0.0}
{"step": 1700232, "time": 53188.5310986042, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1700312, "time": 53190.96632170677, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1700336, "time": 53191.91186594963, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 1700456, "time": 53195.30900001526, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1700648, "time": 53201.19156455994, "episode/length": 211.0, "episode/score": 0.34062498807907104, "episode/reward_rate": 0.0047169811320754715, "episode/intrinsic_return": 0.0}
{"step": 1700696, "time": 53202.63985657692, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 1700912, "time": 53209.369799137115, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 1701000, "time": 53211.798062086105, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1701072, "time": 53214.20554637909, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1701368, "time": 53222.90877866745, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1701568, "time": 53229.296708106995, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1701624, "time": 53230.76994252205, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1701640, "time": 53231.25604605675, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 1701800, "time": 53236.09609055519, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 1702136, "time": 53246.24810218811, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1702232, "time": 53249.16148328781, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1702432, "time": 53255.4158411026, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1702624, "time": 53261.319121837616, "episode/length": 240.0, "episode/score": 0.25, "episode/reward_rate": 0.004149377593360996, "episode/intrinsic_return": 0.0}
{"step": 1702712, "time": 53263.77688407898, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1702744, "time": 53264.743876457214, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1702768, "time": 53265.691854953766, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1702841, "time": 53268.713126182556, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.5041098007427647, "train/action_min": 0.0, "train/action_std": 1.813660599328027, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.011305401824286273, "train/actor_opt_grad_steps": 105320.0, "train/actor_opt_loss": -42.513894085813625, "train/adv_mag": 0.6950050372208281, "train/adv_max": 0.2976881870495275, "train/adv_mean": 0.001162323421671801, "train/adv_min": -0.6286614308216302, "train/adv_std": 0.03267252370898653, "train/cont_avg": 0.9928658020320197, "train/cont_loss_mean": 0.029925535905537346, "train/cont_loss_std": 0.3020102786166327, "train/cont_neg_acc": 0.10092436536926354, "train/cont_neg_loss": 3.2866269819842184, "train/cont_pos_acc": 0.9998643715393367, "train/cont_pos_loss": 0.006375702139302134, "train/cont_pred": 0.992988417301272, "train/cont_rate": 0.9928658020320197, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.10070477196203517, "train/extr_critic_critic_opt_grad_steps": 105320.0, "train/extr_critic_critic_opt_loss": 12682.013234105603, "train/extr_critic_mag": 1.9672474931613566, "train/extr_critic_max": 1.9672474931613566, "train/extr_critic_mean": 1.828483253864232, "train/extr_critic_min": 1.5336681087616042, "train/extr_critic_std": 0.04212854630107363, "train/extr_return_normed_mag": 0.7109186572981585, "train/extr_return_normed_max": 0.32660724259362434, "train/extr_return_normed_mean": 0.09069333768683702, "train/extr_return_normed_min": -0.5462910524142787, "train/extr_return_normed_std": 0.05391729646935839, "train/extr_return_rate": 0.9998351702549187, "train/extr_return_raw_mag": 2.0655593425769525, "train/extr_return_raw_max": 2.0655593425769525, "train/extr_return_raw_mean": 1.8296455221223127, "train/extr_return_raw_min": 1.1926610475690493, "train/extr_return_raw_std": 0.05391729650606075, "train/extr_reward_mag": 0.2536497239408822, "train/extr_reward_max": 0.2536497239408822, "train/extr_reward_mean": 0.0030686548736698818, "train/extr_reward_min": 1.1744757591209976e-09, "train/extr_reward_std": 0.009202991807236901, "train/image_loss_mean": 0.09214774897239478, "train/image_loss_std": 0.10421026479728117, "train/model_loss_mean": 0.7506587766661432, "train/model_loss_std": 0.6214243547963392, "train/model_opt_grad_norm": 13.52512211635195, "train/model_opt_grad_steps": 105223.9408866995, "train/model_opt_loss": 4325.62248282597, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5763.546798029557, "train/policy_entropy_mag": 1.1449881325214368, "train/policy_entropy_max": 1.1449881325214368, "train/policy_entropy_mean": 0.07848890371657358, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.07922014309634716, "train/policy_logprob_mag": 6.55108028327303, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.07885403868746875, "train/policy_logprob_min": -6.55108028327303, "train/policy_logprob_std": 0.6180763746717294, "train/policy_randomness_mag": 0.588407537032818, "train/policy_randomness_max": 0.588407537032818, "train/policy_randomness_mean": 0.04033532243203647, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.0407111027594564, "train/post_ent_mag": 29.071067424830545, "train/post_ent_max": 29.071067424830545, "train/post_ent_mean": 28.237967260952654, "train/post_ent_min": 27.376884638969536, "train/post_ent_std": 0.35335899485743105, "train/prior_ent_mag": 28.49994032723563, "train/prior_ent_max": 28.49994032723563, "train/prior_ent_mean": 27.7985027576315, "train/prior_ent_min": 26.754277121257314, "train/prior_ent_std": 0.295374955302976, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.003825340858715692, "train/reward_loss_mean": 0.028585467294886195, "train/reward_loss_std": 0.31679261963942956, "train/reward_max_data": 0.8175338668189025, "train/reward_max_pred": 0.3355848061040117, "train/reward_neg_acc": 0.9994242053313795, "train/reward_neg_loss": 0.00519799570704402, "train/reward_pos_acc": 0.12972085640348238, "train/reward_pos_loss": 4.002457464857055, "train/reward_pred": 0.002986847419576178, "train/reward_rate": 0.005830511083743843, "train_stats/mean_log_entropy": 0.07282119870436292, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.01816822960972786, "report/cont_loss_std": 0.22724846005439758, "report/cont_neg_acc": 0.4000000059604645, "report/cont_neg_loss": 2.4753811359405518, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.006111247930675745, "report/cont_pred": 0.9922156929969788, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.07123284786939621, "report/image_loss_std": 0.08409569412469864, "report/model_loss_mean": 0.7068464159965515, "report/model_loss_std": 0.49114280939102173, "report/post_ent_mag": 29.4384708404541, "report/post_ent_max": 29.4384708404541, "report/post_ent_mean": 28.435070037841797, "report/post_ent_min": 27.64255142211914, "report/post_ent_std": 0.37080368399620056, "report/prior_ent_mag": 28.537261962890625, "report/prior_ent_max": 28.537261962890625, "report/prior_ent_mean": 27.949548721313477, "report/prior_ent_min": 27.071643829345703, "report/prior_ent_std": 0.25754135847091675, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.002703857608139515, "report/reward_loss_mean": 0.017445296049118042, "report/reward_loss_std": 0.25299322605133057, "report/reward_max_data": 0.862500011920929, "report/reward_max_pred": 0.707685112953186, "report/reward_neg_acc": 0.9999999403953552, "report/reward_neg_loss": 0.004997455980628729, "report/reward_pos_acc": 0.5, "report/reward_pos_loss": 3.1916451454162598, "report/reward_pred": 0.0035449147690087557, "report/reward_rate": 0.00390625, "eval/cont_avg": 0.9892578125, "eval/cont_loss_mean": 0.05362458527088165, "eval/cont_loss_std": 0.49171334505081177, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 4.454319953918457, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0058381627313792706, "eval/cont_pred": 0.9942041039466858, "eval/cont_rate": 0.9892578125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.12267036736011505, "eval/image_loss_std": 0.11749441921710968, "eval/model_loss_mean": 0.8392422199249268, "eval/model_loss_std": 1.1137609481811523, "eval/post_ent_mag": 29.43858528137207, "eval/post_ent_max": 29.43858528137207, "eval/post_ent_mean": 28.496707916259766, "eval/post_ent_min": 27.70737648010254, "eval/post_ent_std": 0.4058545231819153, "eval/prior_ent_mag": 28.559890747070312, "eval/prior_ent_max": 28.559890747070312, "eval/prior_ent_mean": 27.94989776611328, "eval/prior_ent_min": 26.950403213500977, "eval/prior_ent_std": 0.2980634272098541, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.007907104678452015, "eval/reward_loss_mean": 0.06294724345207214, "eval/reward_loss_std": 0.5822959542274475, "eval/reward_max_data": 0.918749988079071, "eval/reward_max_pred": 0.14596927165985107, "eval/reward_neg_acc": 0.9990128874778748, "eval/reward_neg_loss": 0.005039883777499199, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.395689010620117, "eval/reward_pred": 0.002457167487591505, "eval/reward_rate": 0.0107421875, "replay/size": 1000000.0, "replay/inserts": 32368.0, "replay/samples": 32368.0, "replay/insert_wait_avg": 1.215781543258388e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.402186810940843e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4152.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1328902088378435e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.046627044677734e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2533948421478, "timer/env.step_count": 4046.0, "timer/env.step_total": 39.32290005683899, "timer/env.step_frac": 0.03931293836102863, "timer/env.step_avg": 0.009718957008610724, "timer/env.step_min": 0.007694244384765625, "timer/env.step_max": 0.038515329360961914, "timer/replay._sample_count": 32368.0, "timer/replay._sample_total": 16.49193811416626, "timer/replay._sample_frac": 0.016487760200772812, "timer/replay._sample_avg": 0.0005095136589893185, "timer/replay._sample_min": 0.0004115104675292969, "timer/replay._sample_max": 0.020959854125976562, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4565.0, "timer/agent.policy_total": 48.170764446258545, "timer/agent.policy_frac": 0.04815856131521601, "timer/agent.policy_avg": 0.010552193745073065, "timer/agent.policy_min": 0.00904536247253418, "timer/agent.policy_max": 0.08269786834716797, "timer/dataset_train_count": 2023.0, "timer/dataset_train_total": 0.2105698585510254, "timer/dataset_train_frac": 0.0002105165147520003, "timer/dataset_train_avg": 0.00010408791821602837, "timer/dataset_train_min": 9.107589721679688e-05, "timer/dataset_train_max": 0.00054168701171875, "timer/agent.train_count": 2023.0, "timer/agent.train_total": 901.2950155735016, "timer/agent.train_frac": 0.9010666899218441, "timer/agent.train_avg": 0.4455239819938218, "timer/agent.train_min": 0.4341573715209961, "timer/agent.train_max": 0.6652021408081055, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47863054275512695, "timer/agent.report_frac": 0.00047850929096887563, "timer/agent.report_avg": 0.23931527137756348, "timer/agent.report_min": 0.2314441204071045, "timer/agent.report_max": 0.24718642234802246, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7894973754882812e-05, "timer/dataset_eval_frac": 2.7887907103064598e-08, "timer/dataset_eval_avg": 2.7894973754882812e-05, "timer/dataset_eval_min": 2.7894973754882812e-05, "timer/dataset_eval_max": 2.7894973754882812e-05, "fps": 32.35924334697932}
{"step": 1703224, "time": 53280.007648706436, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1703256, "time": 53280.981539011, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 1703328, "time": 53283.386952638626, "episode/length": 281.0, "episode/score": 0.12187500298023224, "episode/reward_rate": 0.0035460992907801418, "episode/intrinsic_return": 0.0}
{"step": 1703584, "time": 53291.276540756226, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1703664, "time": 53293.76405453682, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 1703672, "time": 53293.79638838768, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1703896, "time": 53300.69645810127, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 1703920, "time": 53301.6588807106, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 1704016, "time": 53305.139328718185, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 1704080, "time": 53307.075694561005, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1704648, "time": 53324.05207037926, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1704648, "time": 53324.06123876572, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1704712, "time": 53326.00110960007, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1704720, "time": 53326.46745634079, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1705008, "time": 53335.20153975487, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1705128, "time": 53338.62463212013, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1705264, "time": 53342.96552848816, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1705320, "time": 53344.43979215622, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 1705440, "time": 53348.41043162346, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1705512, "time": 53350.35953640938, "episode/length": 201.0, "episode/score": 0.37187498807907104, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.0}
{"step": 1705568, "time": 53352.29269504547, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1705592, "time": 53352.798134088516, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 1705704, "time": 53356.17289733887, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 1705792, "time": 53359.055425167084, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1705840, "time": 53360.51645374298, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 1705840, "time": 53360.52637553215, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1705888, "time": 53361.99216461182, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1706208, "time": 53371.65411734581, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1706256, "time": 53373.09389233589, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1706272, "time": 53373.57682466507, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1706328, "time": 53375.04428577423, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1706368, "time": 53376.51039338112, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1706720, "time": 53387.21179533005, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1706744, "time": 53387.71546411514, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1706752, "time": 53388.1792640686, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1706904, "time": 53392.52853298187, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 1707104, "time": 53398.77670812607, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1707136, "time": 53399.73555111885, "episode/length": 195.0, "episode/score": 0.390625, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.0}
{"step": 1707200, "time": 53401.67578840256, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1707312, "time": 53405.05412840843, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1707360, "time": 53406.54093050957, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1707504, "time": 53410.96455836296, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1707552, "time": 53412.415590286255, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1707776, "time": 53419.17495036125, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 1707776, "time": 53419.183735609055, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1707872, "time": 53422.12790608406, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1708096, "time": 53428.89804506302, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1708312, "time": 53435.21890902519, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 1708408, "time": 53438.24933719635, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1708456, "time": 53439.7218413353, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 1708512, "time": 53441.63977217674, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1708560, "time": 53443.07812047005, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1708736, "time": 53448.36402177811, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1708792, "time": 53449.84638977051, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 1709072, "time": 53458.57503223419, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1709256, "time": 53463.95332837105, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1709264, "time": 53464.43245410919, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 1709296, "time": 53465.406856775284, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1709424, "time": 53469.4213783741, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1709536, "time": 53472.80955719948, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 1709608, "time": 53474.78655457497, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1709656, "time": 53476.24858903885, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 1709656, "time": 53476.2568359375, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1709696, "time": 53477.69820904732, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1709864, "time": 53482.59809947014, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1709928, "time": 53484.566034555435, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1710072, "time": 53489.89221572876, "eval_episode/length": 51.0, "eval_episode/score": 0.840624988079071, "eval_episode/reward_rate": 0.019230769230769232}
{"step": 1710072, "time": 53490.128774642944, "eval_episode/length": 64.0, "eval_episode/score": 0.800000011920929, "eval_episode/reward_rate": 0.015384615384615385}
{"step": 1710072, "time": 53490.33953881264, "eval_episode/length": 75.0, "eval_episode/score": 0.765625, "eval_episode/reward_rate": 0.013157894736842105}
{"step": 1710072, "time": 53490.46114349365, "eval_episode/length": 81.0, "eval_episode/score": 0.746874988079071, "eval_episode/reward_rate": 0.012195121951219513}
{"step": 1710072, "time": 53490.55947422981, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 1710072, "time": 53490.67160439491, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 1710072, "time": 53490.79991674423, "eval_episode/length": 34.0, "eval_episode/score": 0.893750011920929, "eval_episode/reward_rate": 0.02857142857142857}
{"step": 1710072, "time": 53490.9506816864, "eval_episode/length": 107.0, "eval_episode/score": 0.6656249761581421, "eval_episode/reward_rate": 0.009259259259259259}
{"step": 1710160, "time": 53493.824420928955, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1710176, "time": 53494.312203645706, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1710488, "time": 53503.65366387367, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1710600, "time": 53507.07661128044, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1710816, "time": 53513.85589313507, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 1710848, "time": 53514.849398612976, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1710872, "time": 53515.36186313629, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 1710888, "time": 53515.851988077164, "episode/length": 202.0, "episode/score": 0.3687500059604645, "episode/reward_rate": 0.0049261083743842365, "episode/intrinsic_return": 0.0}
{"step": 1710952, "time": 53517.788049936295, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1710984, "time": 53518.762498378754, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1711048, "time": 53520.71293091774, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1711320, "time": 53529.03262281418, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1711496, "time": 53534.36372900009, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1711584, "time": 53537.25107526779, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1711672, "time": 53539.71420741081, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1711712, "time": 53541.14687371254, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1711776, "time": 53543.094165086746, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1711784, "time": 53543.122188806534, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1711944, "time": 53547.96494984627, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1712064, "time": 53551.832812547684, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1712232, "time": 53557.28859210014, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1712240, "time": 53557.75646185875, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1712256, "time": 53558.25025177002, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1712680, "time": 53570.89838194847, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1712688, "time": 53571.369260549545, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1712800, "time": 53574.77739930153, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 1712984, "time": 53580.1520690918, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1713032, "time": 53581.6139318943, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1713152, "time": 53585.48835873604, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 1713544, "time": 53597.252140283585, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1713664, "time": 53601.12996673584, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 1713776, "time": 53604.540910959244, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1713792, "time": 53605.0372877121, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 1713968, "time": 53610.399560928345, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 1714088, "time": 53613.829659700394, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1714120, "time": 53614.80475282669, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1714120, "time": 53614.81478238106, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1714216, "time": 53617.85460996628, "episode/length": 11.0, "episode/score": 0.965624988079071, "episode/reward_rate": 0.08333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1714344, "time": 53621.75002527237, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1714392, "time": 53623.232315540314, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 1714648, "time": 53631.01330256462, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1714712, "time": 53632.97052693367, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1714776, "time": 53634.915508270264, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1714936, "time": 53639.77601194382, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 1715040, "time": 53643.17469596863, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1715088, "time": 53644.62951493263, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1715208, "time": 53648.15502500534, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1715232, "time": 53649.108268260956, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 1715240, "time": 53649.13488197327, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1715368, "time": 53653.045115470886, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1715520, "time": 53657.89794206619, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 1715528, "time": 53657.926117897034, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1715744, "time": 53664.70665931702, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1715752, "time": 53664.73414731026, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1715968, "time": 53671.53631448746, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1716208, "time": 53678.90646004677, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1716272, "time": 53680.8753490448, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1716296, "time": 53681.38587975502, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1716584, "time": 53690.117389678955, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1716704, "time": 53693.992005348206, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1716752, "time": 53695.46445918083, "episode/length": 207.0, "episode/score": 0.3531250059604645, "episode/reward_rate": 0.004807692307692308, "episode/intrinsic_return": 0.0}
{"step": 1716824, "time": 53697.43374586105, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1716976, "time": 53702.29085588455, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 1717064, "time": 53704.75524544716, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1717080, "time": 53705.27019882202, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1717144, "time": 53707.30642032623, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 1717512, "time": 53718.47497177124, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1717552, "time": 53719.93524646759, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 1717744, "time": 53725.78084874153, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1717768, "time": 53726.29067325592, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1717896, "time": 53730.23726320267, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1718056, "time": 53735.105486392975, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1718424, "time": 53746.34973406792, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1718520, "time": 53749.27968478203, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1718608, "time": 53752.166875362396, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1718664, "time": 53753.64204001427, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1718952, "time": 53762.3644554615, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1718960, "time": 53762.83491897583, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1719000, "time": 53763.84997987747, "episode/length": 239.0, "episode/score": 0.25312501192092896, "episode/reward_rate": 0.004166666666666667, "episode/intrinsic_return": 0.0}
{"step": 1719064, "time": 53765.79844927788, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1719136, "time": 53768.29086637497, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1719232, "time": 53771.246787548065, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1719752, "time": 53786.84095430374, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1719760, "time": 53787.313202142715, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1719760, "time": 53787.31999588013, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1720040, "time": 53795.642729759216, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1720056, "time": 53797.90076780319, "eval_episode/length": 85.0, "eval_episode/score": 0.734375, "eval_episode/reward_rate": 0.011627906976744186}
{"step": 1720056, "time": 53797.92501592636, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 1720056, "time": 53798.1822886467, "eval_episode/length": 100.0, "eval_episode/score": 0.6875, "eval_episode/reward_rate": 0.009900990099009901}
{"step": 1720056, "time": 53798.36981534958, "eval_episode/length": 110.0, "eval_episode/score": 0.65625, "eval_episode/reward_rate": 0.009009009009009009}
{"step": 1720056, "time": 53799.174329042435, "eval_episode/length": 154.0, "eval_episode/score": 0.518750011920929, "eval_episode/reward_rate": 0.0064516129032258064}
{"step": 1720056, "time": 53799.43242955208, "eval_episode/length": 167.0, "eval_episode/score": 0.4781250059604645, "eval_episode/reward_rate": 0.005952380952380952}
{"step": 1720056, "time": 53799.70157790184, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 1720056, "time": 53799.97430109978, "eval_episode/length": 107.0, "eval_episode/score": 0.6656249761581421, "eval_episode/reward_rate": 0.009259259259259259}
{"step": 1720392, "time": 53810.67241549492, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 1720416, "time": 53811.626017570496, "episode/length": 182.0, "episode/score": 0.4312500059604645, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.0}
{"step": 1720424, "time": 53811.653270959854, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1720552, "time": 53815.54092717171, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1720608, "time": 53817.473428964615, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1721008, "time": 53829.72784781456, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1721312, "time": 53838.9490237236, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1721344, "time": 53839.92794275284, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1721368, "time": 53840.439190626144, "episode/length": 266.0, "episode/score": 0.16875000298023224, "episode/reward_rate": 0.003745318352059925, "episode/intrinsic_return": 0.0}
{"step": 1721368, "time": 53840.44739961624, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1721536, "time": 53845.77632164955, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1721704, "time": 53850.65470910072, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 1721800, "time": 53853.58923506737, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1721864, "time": 53855.535485744476, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1721960, "time": 53858.55964446068, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 1722072, "time": 53861.97740340233, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1722160, "time": 53864.85830760002, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1722200, "time": 53865.87059235573, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1722248, "time": 53867.327322244644, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1722280, "time": 53868.30747246742, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1722328, "time": 53869.768260240555, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1722352, "time": 53870.74074816704, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1722688, "time": 53880.93469667435, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1722824, "time": 53884.84313797951, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1722848, "time": 53885.81294798851, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1723360, "time": 53901.49371886253, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1723392, "time": 53902.46753692627, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1723408, "time": 53902.96496796608, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 1723424, "time": 53903.455941438675, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 1723424, "time": 53903.46584868431, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1723488, "time": 53905.437128305435, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1723752, "time": 53913.29127192497, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1723768, "time": 53913.78552699089, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 1723864, "time": 53916.82882642746, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 1724088, "time": 53923.61283326149, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1724104, "time": 53924.10318279266, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1724416, "time": 53933.80993819237, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1724448, "time": 53934.79710841179, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1724536, "time": 53937.24895954132, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1724936, "time": 53949.44207382202, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1724936, "time": 53949.45215320587, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1724960, "time": 53950.41185259819, "episode/length": 191.0, "episode/score": 0.40312498807907104, "episode/reward_rate": 0.005208333333333333, "episode/intrinsic_return": 0.0}
{"step": 1724960, "time": 53950.421924591064, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1725016, "time": 53951.89952301979, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1725088, "time": 53954.31767082214, "episode/length": 15.0, "episode/score": 0.953125, "episode/reward_rate": 0.0625, "episode/intrinsic_return": 0.0}
{"step": 1725632, "time": 53970.80468416214, "episode/length": 220.0, "episode/score": 0.3125, "episode/reward_rate": 0.004524886877828055, "episode/intrinsic_return": 0.0}
{"step": 1725832, "time": 53976.723816394806, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1725856, "time": 53977.67304301262, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1726064, "time": 53983.96763706207, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1726216, "time": 53988.343197107315, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 1726240, "time": 53989.29018330574, "episode/length": 21.0, "episode/score": 0.934374988079071, "episode/reward_rate": 0.045454545454545456, "episode/intrinsic_return": 0.0}
{"step": 1726272, "time": 53990.260684251785, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1726344, "time": 53992.21105694771, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1726536, "time": 53998.03008913994, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1726640, "time": 54001.41829133034, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1726704, "time": 54003.37957239151, "episode/length": 220.0, "episode/score": 0.3125, "episode/reward_rate": 0.004524886877828055, "episode/intrinsic_return": 0.0}
{"step": 1726728, "time": 54003.90002036095, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1726904, "time": 54009.32706665993, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1726904, "time": 54009.334822654724, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1726984, "time": 54011.76015639305, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 1727376, "time": 54023.89545798302, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1727456, "time": 54026.31922459602, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1727592, "time": 54030.207817554474, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1727712, "time": 54034.073068380356, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1727776, "time": 54036.005029439926, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1727880, "time": 54039.006830215454, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1728104, "time": 54045.82502269745, "episode/length": 195.0, "episode/score": 0.390625, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.0}
{"step": 1728272, "time": 54051.15487194061, "episode/length": 240.0, "episode/score": 0.25, "episode/reward_rate": 0.004149377593360996, "episode/intrinsic_return": 0.0}
{"step": 1728360, "time": 54053.603892326355, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1728416, "time": 54055.516387462616, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1728544, "time": 54059.893362760544, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1728752, "time": 54066.22505092621, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1728920, "time": 54071.182351350784, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1729048, "time": 54075.0576980114, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 1729048, "time": 54075.065237522125, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1729216, "time": 54080.38911819458, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1729312, "time": 54083.32187271118, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1729352, "time": 54084.314618349075, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 1729408, "time": 54086.24989438057, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1729640, "time": 54093.0368168354, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 1729768, "time": 54097.006998062134, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1729784, "time": 54097.49532485008, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1729856, "time": 54099.90140604973, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1730040, "time": 54106.14511799812, "eval_episode/length": 43.0, "eval_episode/score": 0.8656250238418579, "eval_episode/reward_rate": 0.022727272727272728}
{"step": 1730040, "time": 54106.23911166191, "eval_episode/length": 48.0, "eval_episode/score": 0.8500000238418579, "eval_episode/reward_rate": 0.02040816326530612}
{"step": 1730040, "time": 54107.13342142105, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 1730040, "time": 54107.81040477753, "eval_episode/length": 99.0, "eval_episode/score": 0.690625011920929, "eval_episode/reward_rate": 0.01}
{"step": 1730040, "time": 54107.9317381382, "eval_episode/length": 105.0, "eval_episode/score": 0.671875, "eval_episode/reward_rate": 0.009433962264150943}
{"step": 1730040, "time": 54108.3894264698, "eval_episode/length": 130.0, "eval_episode/score": 0.59375, "eval_episode/reward_rate": 0.007633587786259542}
{"step": 1730040, "time": 54108.41383457184, "eval_episode/length": 131.0, "eval_episode/score": 0.590624988079071, "eval_episode/reward_rate": 0.007575757575757576}
{"step": 1730040, "time": 54108.51271939278, "eval_episode/length": 87.0, "eval_episode/score": 0.7281249761581421, "eval_episode/reward_rate": 0.011363636363636364}
{"step": 1730072, "time": 54109.48750567436, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1730136, "time": 54111.43011593819, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1730200, "time": 54113.38383102417, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1730328, "time": 54117.244555950165, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1730432, "time": 54120.64152097702, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1730880, "time": 54134.371713638306, "episode/length": 207.0, "episode/score": 0.3531250059604645, "episode/reward_rate": 0.004807692307692308, "episode/intrinsic_return": 0.0}
{"step": 1730976, "time": 54137.2840218544, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1731024, "time": 54138.76079702377, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1731112, "time": 54141.23353242874, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1731192, "time": 54143.66894555092, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1731400, "time": 54149.990577697754, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 1731512, "time": 54153.38014817238, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1731552, "time": 54154.81497550011, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 1731552, "time": 54154.82428908348, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1731600, "time": 54156.30502295494, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1731784, "time": 54161.76684165001, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1731800, "time": 54162.275706768036, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1731800, "time": 54162.28421139717, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1732360, "time": 54179.253142118454, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1732424, "time": 54181.190061330795, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1732432, "time": 54181.679923057556, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1732672, "time": 54189.09585022926, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1732800, "time": 54193.00725388527, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 1733000, "time": 54198.94456601143, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1733040, "time": 54200.39725494385, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1733128, "time": 54202.854061603546, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1733216, "time": 54205.744720458984, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1733344, "time": 54209.62091135979, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1733712, "time": 54220.88373041153, "episode/length": 238.0, "episode/score": 0.2562499940395355, "episode/reward_rate": 0.0041841004184100415, "episode/intrinsic_return": 0.0}
{"step": 1733792, "time": 54223.30403017998, "episode/length": 250.0, "episode/score": 0.21875, "episode/reward_rate": 0.00398406374501992, "episode/intrinsic_return": 0.0}
{"step": 1733864, "time": 54225.256709337234, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1733888, "time": 54226.22279906273, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1734072, "time": 54231.60077834129, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1734168, "time": 54234.496797800064, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 1734248, "time": 54236.94835352898, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 1734304, "time": 54238.87395429611, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 1734544, "time": 54246.182671785355, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1734592, "time": 54247.74584197998, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1734648, "time": 54249.226373910904, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1734864, "time": 54256.016431331635, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1734920, "time": 54257.49390697479, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1734992, "time": 54259.91522717476, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1735064, "time": 54261.877200841904, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1735168, "time": 54265.29094910622, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1735257, "time": 54268.78441500664, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.464965518158261, "train/action_min": 0.0, "train/action_std": 1.8597786066555742, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.013080346992811059, "train/actor_opt_grad_steps": 107345.0, "train/actor_opt_loss": -41.620134051483454, "train/adv_mag": 0.8304516230479325, "train/adv_max": 0.3126063382271493, "train/adv_mean": 0.00022473158746338817, "train/adv_min": -0.7720201865281209, "train/adv_std": 0.03612893516437547, "train/cont_avg": 0.9927918084777227, "train/cont_loss_mean": 0.030095821472419664, "train/cont_loss_std": 0.30315653160952105, "train/cont_neg_acc": 0.09933415213876431, "train/cont_neg_loss": 3.2886268443400315, "train/cont_pos_acc": 0.9998442064417471, "train/cont_pos_loss": 0.0064371660752867415, "train/cont_pred": 0.9929002904065765, "train/cont_rate": 0.9927918084777227, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.10561582951409983, "train/extr_critic_critic_opt_grad_steps": 107345.0, "train/extr_critic_critic_opt_loss": 12445.069543819616, "train/extr_critic_mag": 1.970881691073427, "train/extr_critic_max": 1.970881691073427, "train/extr_critic_mean": 1.8452975525714383, "train/extr_critic_min": 1.5136693562611494, "train/extr_critic_std": 0.03793136408497201, "train/extr_return_normed_mag": 0.8321962967367456, "train/extr_return_normed_max": 0.30395822123725813, "train/extr_return_normed_mean": 0.08345261494638306, "train/extr_return_normed_min": -0.7060414036311725, "train/extr_return_normed_std": 0.053154743396409666, "train/extr_return_rate": 0.9997753796010914, "train/extr_return_raw_mag": 2.0660277422111815, "train/extr_return_raw_max": 2.0660277422111815, "train/extr_return_raw_mean": 1.8455222420173116, "train/extr_return_raw_min": 1.0560281173427506, "train/extr_return_raw_std": 0.053154743617714044, "train/extr_reward_mag": 0.2557515968190561, "train/extr_reward_max": 0.2557515968190561, "train/extr_reward_mean": 0.0030553651562117336, "train/extr_reward_min": 4.012985984877785e-08, "train/extr_reward_std": 0.00971905682650902, "train/image_loss_mean": 0.09207867141259779, "train/image_loss_std": 0.10336389883172394, "train/model_loss_mean": 0.7510551379458739, "train/model_loss_std": 0.6241328928730275, "train/model_opt_grad_norm": 13.429131245849156, "train/model_opt_grad_steps": 107247.06930693069, "train/model_opt_loss": 3866.1610059077198, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5148.514851485149, "train/policy_entropy_mag": 1.1302347555018888, "train/policy_entropy_max": 1.1302347555018888, "train/policy_entropy_mean": 0.07910831855370266, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.08082479043024601, "train/policy_logprob_mag": 6.551080292994433, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.07957107123762074, "train/policy_logprob_min": -6.551080292994433, "train/policy_logprob_std": 0.6188120514449507, "train/policy_randomness_mag": 0.580825800057685, "train/policy_randomness_max": 0.580825800057685, "train/policy_randomness_mean": 0.04065363857858252, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.041535728491178835, "train/post_ent_mag": 29.077710113903084, "train/post_ent_max": 29.077710113903084, "train/post_ent_mean": 28.20723299460836, "train/post_ent_min": 27.318921466865163, "train/post_ent_std": 0.36741298776451903, "train/prior_ent_mag": 28.583704278020576, "train/prior_ent_max": 28.583704278020576, "train/prior_ent_mean": 27.97799014100934, "train/prior_ent_min": 26.91747026160212, "train/prior_ent_std": 0.28269814921192604, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0038928796806935186, "train/reward_loss_mean": 0.028880621228219553, "train/reward_loss_std": 0.3189432491907979, "train/reward_max_data": 0.8155940605862306, "train/reward_max_pred": 0.33544840966120804, "train/reward_neg_acc": 0.999362987161863, "train/reward_neg_loss": 0.0052378170738586844, "train/reward_pos_acc": 0.13430164699064623, "train/reward_pos_loss": 3.994032387686248, "train/reward_pred": 0.003021029557797615, "train/reward_rate": 0.005936726485148515, "train_stats/mean_log_entropy": 0.07354876322932141, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.990234375, "report/cont_loss_mean": 0.04439229518175125, "report/cont_loss_std": 0.42772379517555237, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 3.9278130531311035, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.006094262003898621, "report/cont_pred": 0.9935975074768066, "report/cont_rate": 0.990234375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.10044193267822266, "report/image_loss_std": 0.10865858197212219, "report/model_loss_mean": 0.7879805564880371, "report/model_loss_std": 0.8178939819335938, "report/post_ent_mag": 28.590206146240234, "report/post_ent_max": 28.590206146240234, "report/post_ent_mean": 27.829307556152344, "report/post_ent_min": 26.876388549804688, "report/post_ent_std": 0.36487525701522827, "report/prior_ent_mag": 28.63899040222168, "report/prior_ent_max": 28.63899040222168, "report/prior_ent_mean": 27.98398780822754, "report/prior_ent_min": 26.934303283691406, "report/prior_ent_std": 0.2835780680179596, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.006420898716896772, "report/reward_loss_mean": 0.04314631223678589, "report/reward_loss_std": 0.4037613868713379, "report/reward_max_data": 0.8812500238418579, "report/reward_max_pred": 0.20147299766540527, "report/reward_neg_acc": 0.9990147948265076, "report/reward_neg_loss": 0.006062144413590431, "report/reward_pos_acc": 0.1111111119389534, "report/reward_pos_loss": 4.22541618347168, "report/reward_pred": 0.0032295144628733397, "report/reward_rate": 0.0087890625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.019077934324741364, "eval/cont_loss_std": 0.21322272717952728, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 3.4081058502197266, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.00578762823715806, "eval/cont_pred": 0.9942221641540527, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.09698489308357239, "eval/image_loss_std": 0.11503855139017105, "eval/model_loss_mean": 0.7382909655570984, "eval/model_loss_std": 0.519032895565033, "eval/post_ent_mag": 28.605443954467773, "eval/post_ent_max": 28.605443954467773, "eval/post_ent_mean": 27.793155670166016, "eval/post_ent_min": 26.883441925048828, "eval/post_ent_std": 0.34104815125465393, "eval/prior_ent_mag": 28.601181030273438, "eval/prior_ent_max": 28.601181030273438, "eval/prior_ent_mean": 27.978816986083984, "eval/prior_ent_min": 26.497770309448242, "eval/prior_ent_std": 0.28654083609580994, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0029052733443677425, "eval/reward_loss_mean": 0.022228095680475235, "eval/reward_loss_std": 0.27000898122787476, "eval/reward_max_data": 0.765625, "eval/reward_max_pred": 0.11962378025054932, "eval/reward_neg_acc": 0.9990195631980896, "eval/reward_neg_loss": 0.00536175025627017, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 4.323145866394043, "eval/reward_pred": 0.0026909462176263332, "eval/reward_rate": 0.00390625, "replay/size": 1000000.0, "replay/inserts": 32416.0, "replay/samples": 32416.0, "replay/insert_wait_avg": 1.1946230038250305e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.320838996006024e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3512.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0687425087687638e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.642673492431641e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0520420074463, "timer/env.step_count": 4052.0, "timer/env.step_total": 39.12444186210632, "timer/env.step_frac": 0.039122405853569575, "timer/env.step_avg": 0.009655587823816961, "timer/env.step_min": 0.007607698440551758, "timer/env.step_max": 0.049078941345214844, "timer/replay._sample_count": 32416.0, "timer/replay._sample_total": 16.628497838974, "timer/replay._sample_frac": 0.016627632503599433, "timer/replay._sample_avg": 0.0005129719224757527, "timer/replay._sample_min": 0.00039696693420410156, "timer/replay._sample_max": 0.027903079986572266, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4491.0, "timer/agent.policy_total": 47.55634427070618, "timer/agent.policy_frac": 0.04755386947187702, "timer/agent.policy_avg": 0.010589255014630634, "timer/agent.policy_min": 0.008720636367797852, "timer/agent.policy_max": 0.08687829971313477, "timer/dataset_train_count": 2026.0, "timer/dataset_train_total": 0.2119121551513672, "timer/dataset_train_frac": 0.00021190112739131762, "timer/dataset_train_avg": 0.00010459632534618321, "timer/dataset_train_min": 9.1552734375e-05, "timer/dataset_train_max": 0.0010602474212646484, "timer/agent.train_count": 2026.0, "timer/agent.train_total": 902.7602353096008, "timer/agent.train_frac": 0.9027132562995946, "timer/agent.train_avg": 0.4455874804094772, "timer/agent.train_min": 0.43459033966064453, "timer/agent.train_max": 0.7376861572265625, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4754519462585449, "timer/agent.report_frac": 0.0004754272040724504, "timer/agent.report_avg": 0.23772597312927246, "timer/agent.report_min": 0.22906708717346191, "timer/agent.report_max": 0.246384859085083, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.5987625122070312e-05, "timer/dataset_eval_frac": 2.5986272744270655e-08, "timer/dataset_eval_avg": 2.5987625122070312e-05, "timer/dataset_eval_min": 2.5987625122070312e-05, "timer/dataset_eval_max": 2.5987625122070312e-05, "fps": 32.41373528338617}
{"step": 1735680, "time": 54281.660732507706, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1735736, "time": 54283.13624835014, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1735896, "time": 54287.974735975266, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 1735984, "time": 54290.86821937561, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 1736016, "time": 54291.84064269066, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 1736064, "time": 54293.29296708107, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1736104, "time": 54294.296688079834, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1736112, "time": 54294.790504693985, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1736400, "time": 54303.52446079254, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 1736592, "time": 54309.48947787285, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1736640, "time": 54310.94683122635, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1736888, "time": 54318.699203014374, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 1736920, "time": 54319.693490982056, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1736952, "time": 54320.67456197739, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1736984, "time": 54321.65732359886, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1737328, "time": 54332.49810910225, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 1737360, "time": 54333.478501319885, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1737408, "time": 54334.95663881302, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1737520, "time": 54338.43427848816, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1737544, "time": 54338.94620847702, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1738016, "time": 54353.47233200073, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1738064, "time": 54354.95340704918, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1738248, "time": 54360.296543598175, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1738456, "time": 54366.68849182129, "episode/length": 191.0, "episode/score": 0.40312498807907104, "episode/reward_rate": 0.005208333333333333, "episode/intrinsic_return": 0.0}
{"step": 1738496, "time": 54368.12526130676, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1738512, "time": 54368.635417699814, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1738616, "time": 54371.56451892853, "episode/length": 207.0, "episode/score": 0.3531250059604645, "episode/reward_rate": 0.004807692307692308, "episode/intrinsic_return": 0.0}
{"step": 1738688, "time": 54374.00439810753, "episode/length": 21.0, "episode/score": 0.934374988079071, "episode/reward_rate": 0.045454545454545456, "episode/intrinsic_return": 0.0}
{"step": 1738744, "time": 54375.480565071106, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1738840, "time": 54378.38634419441, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 1738984, "time": 54382.73286151886, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1739144, "time": 54387.61377739906, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1739280, "time": 54392.016028642654, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1739384, "time": 54394.99736762047, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1739448, "time": 54397.01432442665, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 1739512, "time": 54398.96748161316, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1739544, "time": 54399.940655231476, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 1739552, "time": 54400.41757655144, "episode/length": 250.0, "episode/score": 0.21875, "episode/reward_rate": 0.00398406374501992, "episode/intrinsic_return": 0.0}
{"step": 1739624, "time": 54402.37574887276, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1739896, "time": 54410.66478013992, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 1739912, "time": 54411.15644645691, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 1739920, "time": 54411.62491798401, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1740024, "time": 54414.86344265938, "eval_episode/length": 15.0, "eval_episode/score": 0.953125, "eval_episode/reward_rate": 0.0625}
{"step": 1740024, "time": 54416.19767141342, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 1740024, "time": 54416.61747121811, "eval_episode/length": 112.0, "eval_episode/score": 0.6499999761581421, "eval_episode/reward_rate": 0.008849557522123894}
{"step": 1740024, "time": 54416.677252054214, "eval_episode/length": 25.0, "eval_episode/score": 0.921875, "eval_episode/reward_rate": 0.038461538461538464}
{"step": 1740024, "time": 54416.70205235481, "eval_episode/length": 116.0, "eval_episode/score": 0.637499988079071, "eval_episode/reward_rate": 0.008547008547008548}
{"step": 1740024, "time": 54416.74577450752, "eval_episode/length": 118.0, "eval_episode/score": 0.6312500238418579, "eval_episode/reward_rate": 0.008403361344537815}
{"step": 1740024, "time": 54416.94463443756, "eval_episode/length": 129.0, "eval_episode/score": 0.596875011920929, "eval_episode/reward_rate": 0.007692307692307693}
{"step": 1740024, "time": 54417.44243454933, "eval_episode/length": 157.0, "eval_episode/score": 0.5093749761581421, "eval_episode/reward_rate": 0.006329113924050633}
{"step": 1740048, "time": 54418.39423894882, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1740128, "time": 54420.816900491714, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 1740184, "time": 54422.288162231445, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1740480, "time": 54431.53426337242, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1740600, "time": 54434.94170022011, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1740720, "time": 54438.76370406151, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 1740736, "time": 54439.25285458565, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1740808, "time": 54441.254831552505, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1740912, "time": 54444.63790512085, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1741016, "time": 54447.53620100021, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 1741392, "time": 54459.199987888336, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1741400, "time": 54459.22658276558, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 1741680, "time": 54467.90139746666, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1741928, "time": 54475.16733312607, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1742016, "time": 54478.049570798874, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 1742296, "time": 54486.3270740509, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1742440, "time": 54490.79186177254, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1742808, "time": 54501.95092511177, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 1743072, "time": 54510.19157743454, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1743120, "time": 54511.653497457504, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1743224, "time": 54514.60268974304, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1743328, "time": 54518.05347919464, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1743536, "time": 54524.36340594292, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1743584, "time": 54525.81592798233, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1743672, "time": 54528.27838873863, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1743840, "time": 54533.59004878998, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1744072, "time": 54540.39335799217, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 1744104, "time": 54541.36842465401, "episode/length": 225.0, "episode/score": 0.296875, "episode/reward_rate": 0.004424778761061947, "episode/intrinsic_return": 0.0}
{"step": 1744240, "time": 54545.721235990524, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1744256, "time": 54546.21012187004, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1744392, "time": 54550.21770620346, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1744448, "time": 54552.17543673515, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1744472, "time": 54552.694829940796, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1744928, "time": 54567.21325778961, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1745376, "time": 54580.868619441986, "episode/length": 191.0, "episode/score": 0.40312498807907104, "episode/reward_rate": 0.005208333333333333, "episode/intrinsic_return": 0.0}
{"step": 1745496, "time": 54584.2835817337, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1745720, "time": 54591.07574605942, "episode/length": 201.0, "episode/score": 0.37187498807907104, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.0}
{"step": 1745728, "time": 54591.54200053215, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 1745752, "time": 54592.04830741882, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 1745808, "time": 54593.96600174904, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 1745856, "time": 54595.41478919983, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1745944, "time": 54597.8758764267, "episode/length": 210.0, "episode/score": 0.34375, "episode/reward_rate": 0.004739336492890996, "episode/intrinsic_return": 0.0}
{"step": 1746016, "time": 54600.26711654663, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1746096, "time": 54602.71575427055, "episode/length": 205.0, "episode/score": 0.359375, "episode/reward_rate": 0.0048543689320388345, "episode/intrinsic_return": 0.0}
{"step": 1746160, "time": 54604.654985666275, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1746320, "time": 54609.62604212761, "episode/length": 19.0, "episode/score": 0.940625011920929, "episode/reward_rate": 0.05, "episode/intrinsic_return": 0.0}
{"step": 1746408, "time": 54612.08448386192, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1746552, "time": 54616.469036102295, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1746768, "time": 54623.27440905571, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1746776, "time": 54623.30198812485, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1746800, "time": 54624.263471364975, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1746992, "time": 54630.108483076096, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1747136, "time": 54634.42217159271, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 1747320, "time": 54639.85069012642, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1747320, "time": 54639.860031843185, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 1747544, "time": 54646.63661932945, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1747592, "time": 54648.09855389595, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1747624, "time": 54649.066752910614, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1747736, "time": 54652.465705394745, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1747840, "time": 54655.84671354294, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 1747960, "time": 54659.26330828667, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1747968, "time": 54659.73219013214, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1748008, "time": 54660.72535157204, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1748256, "time": 54668.50897979736, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1748448, "time": 54674.37278532982, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1748512, "time": 54676.30128669739, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1748592, "time": 54678.7246632576, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1748920, "time": 54688.44523215294, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1748928, "time": 54688.914051771164, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1749000, "time": 54690.90914940834, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1749072, "time": 54693.36400794983, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 1749272, "time": 54699.37345099449, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1749272, "time": 54699.383091688156, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 1749656, "time": 54710.99362826347, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 1749680, "time": 54711.95159864426, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1749760, "time": 54714.39041829109, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1750008, "time": 54722.10709095001, "eval_episode/length": 19.0, "eval_episode/score": 0.940625011920929, "eval_episode/reward_rate": 0.05}
{"step": 1750008, "time": 54723.01202702522, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 1750008, "time": 54723.19343686104, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 1750008, "time": 54723.277915239334, "eval_episode/length": 81.0, "eval_episode/score": 0.746874988079071, "eval_episode/reward_rate": 0.012195121951219513}
{"step": 1750008, "time": 54723.32215332985, "eval_episode/length": 63.0, "eval_episode/score": 0.8031250238418579, "eval_episode/reward_rate": 0.015625}
{"step": 1750008, "time": 54723.454545497894, "eval_episode/length": 90.0, "eval_episode/score": 0.71875, "eval_episode/reward_rate": 0.01098901098901099}
{"step": 1750008, "time": 54723.97723889351, "eval_episode/length": 117.0, "eval_episode/score": 0.6343749761581421, "eval_episode/reward_rate": 0.00847457627118644}
{"step": 1750008, "time": 54724.639218091965, "eval_episode/length": 152.0, "eval_episode/score": 0.5249999761581421, "eval_episode/reward_rate": 0.006535947712418301}
{"step": 1750008, "time": 54724.64674568176, "eval_episode/length": 152.0, "eval_episode/score": 0.5249999761581421, "eval_episode/reward_rate": 0.006535947712418301}
{"step": 1750064, "time": 54726.69272542, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 1750152, "time": 54729.13020205498, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1750184, "time": 54730.09948325157, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1750384, "time": 54736.38768005371, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 1750464, "time": 54738.79749536514, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 1750496, "time": 54739.76248526573, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 1750728, "time": 54746.58092164993, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1751008, "time": 54755.30498409271, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1751216, "time": 54761.729342222214, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1751272, "time": 54763.22229027748, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1751488, "time": 54770.046627521515, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1751520, "time": 54771.038598775864, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1751560, "time": 54772.054154872894, "episode/length": 234.0, "episode/score": 0.26875001192092896, "episode/reward_rate": 0.00425531914893617, "episode/intrinsic_return": 0.0}
{"step": 1751584, "time": 54773.016464948654, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1751624, "time": 54774.022263765335, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1752000, "time": 54785.76735830307, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1752376, "time": 54796.985723018646, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1752408, "time": 54797.95133423805, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1752424, "time": 54798.4387049675, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1752448, "time": 54799.4043571949, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1752520, "time": 54801.34902095795, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1752736, "time": 54808.078130960464, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 1752736, "time": 54808.08678436279, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1752816, "time": 54810.537668943405, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 1753016, "time": 54816.43299818039, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1753056, "time": 54817.92754769325, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1753176, "time": 54821.827318668365, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1753344, "time": 54827.14645051956, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 1753384, "time": 54828.13883662224, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1753512, "time": 54832.02720928192, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1753632, "time": 54835.911877155304, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1753752, "time": 54839.34520030022, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 1754296, "time": 54855.89644241333, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1754312, "time": 54856.388714551926, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1754320, "time": 54856.85793495178, "episode/length": 238.0, "episode/score": 0.2562499940395355, "episode/reward_rate": 0.0041841004184100415, "episode/intrinsic_return": 0.0}
{"step": 1754384, "time": 54858.81672787666, "episode/length": 195.0, "episode/score": 0.390625, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.0}
{"step": 1754464, "time": 54861.244379758835, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1754680, "time": 54867.594499349594, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 1754680, "time": 54867.60194134712, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1754736, "time": 54869.50186252594, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1754784, "time": 54870.94862174988, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1755152, "time": 54882.28142595291, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1755176, "time": 54882.790318250656, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1755408, "time": 54890.089040994644, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1755640, "time": 54896.92444181442, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1756016, "time": 54908.78003191948, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1756152, "time": 54912.72586488724, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 1756160, "time": 54913.19366145134, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 1756328, "time": 54918.07198882103, "episode/length": 198.0, "episode/score": 0.3812499940395355, "episode/reward_rate": 0.005025125628140704, "episode/intrinsic_return": 0.0}
{"step": 1756392, "time": 54920.01288151741, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1756392, "time": 54920.03151345253, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 1756608, "time": 54926.83315491676, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1756632, "time": 54927.34534358978, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1756736, "time": 54930.70434451103, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1756760, "time": 54931.23034238815, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1756960, "time": 54937.55872797966, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1757072, "time": 54940.966071128845, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1757088, "time": 54941.45420074463, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1757392, "time": 54950.62927341461, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1757624, "time": 54957.39250397682, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1757688, "time": 54959.31017827988, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1757872, "time": 54965.098286151886, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1758024, "time": 54969.52497959137, "episode/length": 203.0, "episode/score": 0.3656249940395355, "episode/reward_rate": 0.004901960784313725, "episode/intrinsic_return": 0.0}
{"step": 1758096, "time": 54971.930742025375, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1758392, "time": 54980.66274905205, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 1758416, "time": 54981.620346307755, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1758672, "time": 54989.37971615791, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1758760, "time": 54991.81978607178, "episode/length": 224.0, "episode/score": 0.30000001192092896, "episode/reward_rate": 0.0044444444444444444, "episode/intrinsic_return": 0.0}
{"step": 1758888, "time": 54995.69606566429, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1758912, "time": 54996.78038525581, "episode/length": 268.0, "episode/score": 0.16249999403953552, "episode/reward_rate": 0.0037174721189591076, "episode/intrinsic_return": 0.0}
{"step": 1758960, "time": 54998.22528386116, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 1759104, "time": 55002.593879938126, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1759192, "time": 55005.04017353058, "episode/length": 10.0, "episode/score": 0.96875, "episode/reward_rate": 0.09090909090909091, "episode/intrinsic_return": 0.0}
{"step": 1759328, "time": 55009.35389614105, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1759424, "time": 55012.21966123581, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1759472, "time": 55013.68331837654, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1759480, "time": 55013.71000003815, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1759728, "time": 55021.409539699554, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 1759752, "time": 55021.916375637054, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1759760, "time": 55022.38235116005, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1759784, "time": 55022.888704776764, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1759912, "time": 55026.84957718849, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1760024, "time": 55030.270339250565, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1760096, "time": 55033.11746263504, "eval_episode/length": 24.0, "eval_episode/score": 0.925000011920929, "eval_episode/reward_rate": 0.04}
{"step": 1760096, "time": 55033.12616324425, "eval_episode/length": 24.0, "eval_episode/score": 0.925000011920929, "eval_episode/reward_rate": 0.04}
{"step": 1760096, "time": 55033.31750679016, "eval_episode/length": 34.0, "eval_episode/score": 0.893750011920929, "eval_episode/reward_rate": 0.02857142857142857}
{"step": 1760096, "time": 55033.825385570526, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 1760096, "time": 55033.90681409836, "eval_episode/length": 40.0, "eval_episode/score": 0.875, "eval_episode/reward_rate": 0.024390243902439025}
{"step": 1760096, "time": 55034.28082752228, "eval_episode/length": 60.0, "eval_episode/score": 0.8125, "eval_episode/reward_rate": 0.01639344262295082}
{"step": 1760096, "time": 55035.03157091141, "eval_episode/length": 58.0, "eval_episode/score": 0.8187500238418579, "eval_episode/reward_rate": 0.01694915254237288}
{"step": 1760096, "time": 55035.1640586853, "eval_episode/length": 131.0, "eval_episode/score": 0.590624988079071, "eval_episode/reward_rate": 0.007575757575757576}
{"step": 1760128, "time": 55036.15151596069, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 1760192, "time": 55038.08570551872, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1760352, "time": 55042.94161558151, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1760448, "time": 55045.855921030045, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1760504, "time": 55047.32715892792, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1760688, "time": 55053.09715294838, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1760768, "time": 55055.52538776398, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1760880, "time": 55058.98093867302, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1760920, "time": 55059.9892642498, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1761368, "time": 55074.00642514229, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1761488, "time": 55077.86327576637, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 1761512, "time": 55078.37918138504, "episode/length": 260.0, "episode/score": 0.1875, "episode/reward_rate": 0.0038314176245210726, "episode/intrinsic_return": 0.0}
{"step": 1761728, "time": 55085.1431851387, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1761832, "time": 55088.172632455826, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 1761912, "time": 55090.62161207199, "episode/length": 214.0, "episode/score": 0.33125001192092896, "episode/reward_rate": 0.004651162790697674, "episode/intrinsic_return": 0.0}
{"step": 1762024, "time": 55094.014983177185, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1762104, "time": 55096.50691604614, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1762168, "time": 55098.44124031067, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 1762312, "time": 55102.821167469025, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1762528, "time": 55109.584792137146, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1762576, "time": 55111.05870652199, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1762592, "time": 55111.54987645149, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1762600, "time": 55111.57920598984, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1762696, "time": 55114.5714404583, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1762912, "time": 55121.43981575966, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 1763008, "time": 55124.3568148613, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1763056, "time": 55125.81044912338, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1763056, "time": 55125.81919527054, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1763176, "time": 55129.22296118736, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1763368, "time": 55135.00470638275, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1763488, "time": 55138.86242699623, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1763768, "time": 55147.208013534546, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1763808, "time": 55148.677386283875, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1763872, "time": 55150.6104221344, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1763880, "time": 55150.648099184036, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 1764040, "time": 55155.50871729851, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 1764104, "time": 55157.44734334946, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1764152, "time": 55158.92687869072, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1764536, "time": 55170.54180049896, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 1764904, "time": 55181.75759983063, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1764920, "time": 55182.2669377327, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1764968, "time": 55183.71775364876, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1764984, "time": 55184.20578598976, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1765376, "time": 55196.25855374336, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 1765576, "time": 55202.075421094894, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1765648, "time": 55204.464725494385, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1765752, "time": 55207.490841150284, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1765792, "time": 55208.91908121109, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1765800, "time": 55208.94747424126, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1766016, "time": 55215.664861917496, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1766032, "time": 55216.16827368736, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 1766192, "time": 55221.00398373604, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1766408, "time": 55227.32194066048, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1766416, "time": 55227.79127407074, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1766576, "time": 55232.636868953705, "episode/length": 19.0, "episode/score": 0.940625011920929, "episode/reward_rate": 0.05, "episode/intrinsic_return": 0.0}
{"step": 1766584, "time": 55232.665471315384, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1766584, "time": 55232.671571969986, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1766600, "time": 55233.16723656654, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1766648, "time": 55234.630865097046, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1766936, "time": 55243.53695321083, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 1767144, "time": 55249.850182533264, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1767192, "time": 55251.330070495605, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1767296, "time": 55254.680429935455, "episode/length": 12.0, "episode/score": 0.9624999761581421, "episode/reward_rate": 0.07692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1767320, "time": 55255.20323777199, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1767480, "time": 55260.070907354355, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1767480, "time": 55260.08200955391, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1767512, "time": 55261.07271671295, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1767544, "time": 55262.036351919174, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1767624, "time": 55264.45713162422, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1767737, "time": 55271.54897451401, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.4454114190463363, "train/action_min": 0.0, "train/action_std": 1.8566572437145439, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.011031422764062881, "train/actor_opt_grad_steps": 109370.0, "train/actor_opt_loss": -37.70838338166035, "train/adv_mag": 0.8041733221467493, "train/adv_max": 0.3413317467778774, "train/adv_mean": 0.0015600374374000168, "train/adv_min": -0.7267765875520378, "train/adv_std": 0.03383371644089081, "train/cont_avg": 0.9927792102832512, "train/cont_loss_mean": 0.030099419032778647, "train/cont_loss_std": 0.29860230083829664, "train/cont_neg_acc": 0.09623235489787726, "train/cont_neg_loss": 3.2734081991787614, "train/cont_pos_acc": 0.9998448828758277, "train/cont_pos_loss": 0.006557479585644794, "train/cont_pred": 0.9928326712453307, "train/cont_rate": 0.9927792102832512, "train/dyn_loss_mean": 1.0000000986559638, "train/dyn_loss_std": 3.1523124356134774e-06, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.10964283533853117, "train/extr_critic_critic_opt_grad_steps": 109370.0, "train/extr_critic_critic_opt_loss": 11843.476831896553, "train/extr_critic_mag": 1.9950986566214726, "train/extr_critic_max": 1.9950986566214726, "train/extr_critic_mean": 1.8638853075469068, "train/extr_critic_min": 1.506854640439226, "train/extr_critic_std": 0.038171882057571646, "train/extr_return_normed_mag": 0.8303244128603066, "train/extr_return_normed_max": 0.3283147876485815, "train/extr_return_normed_mean": 0.08325841576962048, "train/extr_return_normed_min": -0.688079497790689, "train/extr_return_normed_std": 0.051375237041212655, "train/extr_return_rate": 0.9997893140233797, "train/extr_return_raw_mag": 2.1105014896157925, "train/extr_return_raw_max": 2.1105014896157925, "train/extr_return_raw_mean": 1.8654452016200926, "train/extr_return_raw_min": 1.0941072043233318, "train/extr_return_raw_std": 0.05137523729812923, "train/extr_reward_mag": 0.24886983368784335, "train/extr_reward_max": 0.24886983368784335, "train/extr_reward_mean": 0.003217042056761058, "train/extr_reward_min": 1.526818486857297e-08, "train/extr_reward_std": 0.00973011081662084, "train/image_loss_mean": 0.09199304087775681, "train/image_loss_std": 0.10356796848509699, "train/model_loss_mean": 0.7517958744406112, "train/model_loss_std": 0.6264048648878858, "train/model_opt_grad_norm": 12.827025944376226, "train/model_opt_grad_steps": 109270.23645320197, "train/model_opt_loss": 4223.844269550493, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5640.394088669951, "train/policy_entropy_mag": 1.1044768514891563, "train/policy_entropy_max": 1.1044768514891563, "train/policy_entropy_mean": 0.07910343505478845, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.08052097316005546, "train/policy_logprob_mag": 6.551080276226175, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.0796114357527841, "train/policy_logprob_min": -6.551080276226175, "train/policy_logprob_std": 0.6195265207384607, "train/policy_randomness_mag": 0.5675888547462783, "train/policy_randomness_max": 0.5675888547462783, "train/policy_randomness_mean": 0.04065112927423909, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.041379597074732995, "train/post_ent_mag": 29.679101427200393, "train/post_ent_max": 29.679101427200393, "train/post_ent_mean": 28.365033671186474, "train/post_ent_min": 27.22965593760824, "train/post_ent_std": 0.4986577169061294, "train/prior_ent_mag": 28.778023771464532, "train/prior_ent_max": 28.778023771464532, "train/prior_ent_mean": 27.997458039833408, "train/prior_ent_min": 26.810684175914144, "train/prior_ent_std": 0.3210334294094828, "train/rep_loss_mean": 1.0000000986559638, "train/rep_loss_std": 3.1523124356134774e-06, "train/reward_avg": 0.003985776103175075, "train/reward_loss_mean": 0.029703332166292985, "train/reward_loss_std": 0.32164162037701444, "train/reward_max_data": 0.8253540643330278, "train/reward_max_pred": 0.33865848139589055, "train/reward_neg_acc": 0.9993804408411674, "train/reward_neg_loss": 0.005417022110866795, "train/reward_pos_acc": 0.11492600409414967, "train/reward_pos_loss": 4.04591040423351, "train/reward_pred": 0.0030685712932035547, "train/reward_rate": 0.006032558497536946, "train_stats/mean_log_entropy": 0.07509633938747423, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.017352577298879623, "report/cont_loss_std": 0.1905101239681244, "report/cont_neg_acc": 0.20000000298023224, "report/cont_neg_loss": 2.4507997035980225, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.005412209313362837, "report/cont_pred": 0.9935849905014038, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.09134781360626221, "report/image_loss_std": 0.09910373389720917, "report/model_loss_mean": 0.7300882935523987, "report/model_loss_std": 0.4750880002975464, "report/post_ent_mag": 29.31412124633789, "report/post_ent_max": 29.31412124633789, "report/post_ent_mean": 28.004167556762695, "report/post_ent_min": 26.926151275634766, "report/post_ent_std": 0.47075197100639343, "report/prior_ent_mag": 28.785560607910156, "report/prior_ent_max": 28.785560607910156, "report/prior_ent_mean": 27.603771209716797, "report/prior_ent_min": 25.825855255126953, "report/prior_ent_std": 0.37206923961639404, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0035095217172056437, "report/reward_loss_mean": 0.021387875080108643, "report/reward_loss_std": 0.25511234998703003, "report/reward_max_data": 0.796875, "report/reward_max_pred": 0.6753668785095215, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0047685978934168816, "report/reward_pos_acc": 0.20000000298023224, "report/reward_pos_loss": 3.4083964824676514, "report/reward_pred": 0.003053892869502306, "report/reward_rate": 0.0048828125, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.025481706485152245, "eval/cont_loss_std": 0.3197886049747467, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 4.968935012817383, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.0060956161469221115, "eval/cont_pred": 0.9940030574798584, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.10359670966863632, "eval/image_loss_std": 0.10734342783689499, "eval/model_loss_mean": 0.7576515078544617, "eval/model_loss_std": 0.7286972403526306, "eval/post_ent_mag": 29.36086654663086, "eval/post_ent_max": 29.36086654663086, "eval/post_ent_mean": 27.999805450439453, "eval/post_ent_min": 26.807117462158203, "eval/post_ent_std": 0.5109161734580994, "eval/prior_ent_mag": 28.785560607910156, "eval/prior_ent_max": 28.785560607910156, "eval/prior_ent_mean": 27.565715789794922, "eval/prior_ent_min": 25.912525177001953, "eval/prior_ent_std": 0.4204893410205841, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0032775879371911287, "eval/reward_loss_mean": 0.02857307530939579, "eval/reward_loss_std": 0.38278186321258545, "eval/reward_max_data": 0.9281250238418579, "eval/reward_max_pred": 0.06340336799621582, "eval/reward_neg_acc": 0.9999999403953552, "eval/reward_neg_loss": 0.005041149444878101, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 6.029214382171631, "eval/reward_pred": 0.002503168536350131, "eval/reward_rate": 0.00390625, "replay/size": 1000000.0, "replay/inserts": 32480.0, "replay/samples": 32480.0, "replay/insert_wait_avg": 1.2019584918844288e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.258553810307545e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3544.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0708653899939818e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1175870895385742e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2324430942535, "timer/env.step_count": 4060.0, "timer/env.step_total": 39.37047457695007, "timer/env.step_frac": 0.0393613253087014, "timer/env.step_avg": 0.009697161225849772, "timer/env.step_min": 0.007726430892944336, "timer/env.step_max": 0.03557300567626953, "timer/replay._sample_count": 32480.0, "timer/replay._sample_total": 16.502137899398804, "timer/replay._sample_frac": 0.01649830298280355, "timer/replay._sample_avg": 0.0005080707481341997, "timer/replay._sample_min": 0.0004253387451171875, "timer/replay._sample_max": 0.01183462142944336, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4503.0, "timer/agent.policy_total": 47.30416512489319, "timer/agent.policy_frac": 0.047293172153620736, "timer/agent.policy_avg": 0.010505033338861467, "timer/agent.policy_min": 0.008567094802856445, "timer/agent.policy_max": 0.0739450454711914, "timer/dataset_train_count": 2030.0, "timer/dataset_train_total": 0.2118213176727295, "timer/dataset_train_frac": 0.00021177209271222293, "timer/dataset_train_avg": 0.00010434547668607365, "timer/dataset_train_min": 9.059906005859375e-05, "timer/dataset_train_max": 0.0003762245178222656, "timer/agent.train_count": 2030.0, "timer/agent.train_total": 903.1811211109161, "timer/agent.train_frac": 0.9029712316838017, "timer/agent.train_avg": 0.4449168084290227, "timer/agent.train_min": 0.4340484142303467, "timer/agent.train_max": 0.6811037063598633, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47581028938293457, "timer/agent.report_frac": 0.0004756997162689495, "timer/agent.report_avg": 0.23790514469146729, "timer/agent.report_min": 0.23155808448791504, "timer/agent.report_max": 0.24425220489501953, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7894973754882812e-05, "timer/dataset_eval_frac": 2.788849126767849e-08, "timer/dataset_eval_avg": 2.7894973754882812e-05, "timer/dataset_eval_min": 2.7894973754882812e-05, "timer/dataset_eval_max": 2.7894973754882812e-05, "fps": 32.47188303568811}
{"step": 1768104, "time": 55282.40611410141, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1768184, "time": 55284.82525753975, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1768232, "time": 55286.2761259079, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1768336, "time": 55289.65489411354, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1768344, "time": 55289.6863014698, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1768424, "time": 55292.103684425354, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1768464, "time": 55293.55416512489, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 1768776, "time": 55302.87276554108, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1768776, "time": 55302.87865495682, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 1769008, "time": 55310.10991191864, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1769192, "time": 55315.48558998108, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1769472, "time": 55324.3274037838, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1769544, "time": 55326.77903699875, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1769656, "time": 55330.24065947533, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 1769744, "time": 55333.15599679947, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1769896, "time": 55337.58095526695, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1769960, "time": 55339.520642519, "episode/length": 215.0, "episode/score": 0.328125, "episode/reward_rate": 0.004629629629629629, "episode/intrinsic_return": 0.0}
{"step": 1770000, "time": 55340.95160007477, "episode/length": 191.0, "episode/score": 0.40312498807907104, "episode/reward_rate": 0.005208333333333333, "episode/intrinsic_return": 0.0}
{"step": 1770064, "time": 55342.90553188324, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1770080, "time": 55343.94129061699, "eval_episode/length": 28.0, "eval_episode/score": 0.9125000238418579, "eval_episode/reward_rate": 0.034482758620689655}
{"step": 1770080, "time": 55345.441046476364, "eval_episode/length": 109.0, "eval_episode/score": 0.659375011920929, "eval_episode/reward_rate": 0.00909090909090909}
{"step": 1770080, "time": 55345.5929415226, "eval_episode/length": 117.0, "eval_episode/score": 0.6343749761581421, "eval_episode/reward_rate": 0.00847457627118644}
{"step": 1770080, "time": 55345.73373913765, "eval_episode/length": 124.0, "eval_episode/score": 0.612500011920929, "eval_episode/reward_rate": 0.008}
{"step": 1770080, "time": 55345.9965569973, "eval_episode/length": 138.0, "eval_episode/score": 0.5687500238418579, "eval_episode/reward_rate": 0.007194244604316547}
{"step": 1770080, "time": 55346.09678506851, "eval_episode/length": 114.0, "eval_episode/score": 0.643750011920929, "eval_episode/reward_rate": 0.008695652173913044}
{"step": 1770080, "time": 55346.13926768303, "eval_episode/length": 145.0, "eval_episode/score": 0.546875, "eval_episode/reward_rate": 0.00684931506849315}
{"step": 1770080, "time": 55346.44914793968, "eval_episode/length": 43.0, "eval_episode/score": 0.8656250238418579, "eval_episode/reward_rate": 0.022727272727272728}
{"step": 1770256, "time": 55351.78748583794, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 1770328, "time": 55353.75096344948, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1770400, "time": 55356.17612147331, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1770512, "time": 55359.704104185104, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1770552, "time": 55360.70348024368, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 1770640, "time": 55363.59906196594, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1771128, "time": 55378.258628606796, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 1771224, "time": 55381.201963186264, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1771264, "time": 55382.63159060478, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1771368, "time": 55385.572368621826, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 1771544, "time": 55391.0352909565, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1771824, "time": 55399.773970365524, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1771872, "time": 55401.23910999298, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 1771944, "time": 55403.21694278717, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1772008, "time": 55405.196507930756, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1772064, "time": 55407.13379883766, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1772232, "time": 55412.02995085716, "episode/length": 198.0, "episode/score": 0.3812499940395355, "episode/reward_rate": 0.005025125628140704, "episode/intrinsic_return": 0.0}
{"step": 1772312, "time": 55414.47581386566, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1772632, "time": 55424.33602643013, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1772808, "time": 55429.69684386253, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1772872, "time": 55431.66460609436, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1772984, "time": 55435.12796163559, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1773072, "time": 55438.03522372246, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1773200, "time": 55441.9222612381, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1773232, "time": 55442.91940307617, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 1773512, "time": 55451.27062058449, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 1773512, "time": 55451.27880740166, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1773536, "time": 55452.23151898384, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1773792, "time": 55460.00931382179, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1773880, "time": 55462.462906360626, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1774032, "time": 55467.292983055115, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 1774160, "time": 55471.1616191864, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1774216, "time": 55472.64919781685, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1774496, "time": 55481.391350746155, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1774544, "time": 55482.865961551666, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1774600, "time": 55484.34396672249, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1774696, "time": 55487.26084804535, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1774856, "time": 55492.133570194244, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1775136, "time": 55500.87724900246, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1775216, "time": 55503.30968618393, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1775360, "time": 55507.76381921768, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 1775600, "time": 55515.03060460091, "episode/length": 257.0, "episode/score": 0.19687500596046448, "episode/reward_rate": 0.003875968992248062, "episode/intrinsic_return": 0.0}
{"step": 1775616, "time": 55515.51708030701, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1775656, "time": 55516.524946928024, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 1775960, "time": 55525.763568639755, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1776000, "time": 55527.200372457504, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1776240, "time": 55534.460547447205, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1776320, "time": 55537.0069899559, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1776376, "time": 55538.487706422806, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1776384, "time": 55538.961285591125, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1776400, "time": 55539.4502928257, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1776728, "time": 55549.242594480515, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1776896, "time": 55554.63689827919, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1776912, "time": 55555.15151309967, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1776960, "time": 55556.61957502365, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1777328, "time": 55567.91740489006, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1777368, "time": 55568.90902686119, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1777376, "time": 55569.37824392319, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1777728, "time": 55580.49344468117, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1777816, "time": 55582.92713904381, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 1777864, "time": 55584.387766838074, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1777904, "time": 55585.832424879074, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 1778128, "time": 55592.60992717743, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1778304, "time": 55598.013573884964, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1778472, "time": 55602.874769210815, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1778576, "time": 55606.25160217285, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1778576, "time": 55606.25992012024, "episode/length": 201.0, "episode/score": 0.37187498807907104, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.0}
{"step": 1778616, "time": 55607.24917650223, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 1778824, "time": 55613.55671906471, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 1778824, "time": 55613.57541465759, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1778840, "time": 55614.09787774086, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1779008, "time": 55619.498643398285, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1779360, "time": 55630.27991652489, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1779360, "time": 55630.28632545471, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1779656, "time": 55639.04700756073, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1779688, "time": 55640.02956986427, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1779896, "time": 55646.34533190727, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 1780064, "time": 55651.64202451706, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1780064, "time": 55652.37314248085, "eval_episode/length": 37.0, "eval_episode/score": 0.8843749761581421, "eval_episode/reward_rate": 0.02631578947368421}
{"step": 1780064, "time": 55652.612303972244, "eval_episode/length": 50.0, "eval_episode/score": 0.84375, "eval_episode/reward_rate": 0.0196078431372549}
{"step": 1780064, "time": 55653.421417951584, "eval_episode/length": 94.0, "eval_episode/score": 0.706250011920929, "eval_episode/reward_rate": 0.010526315789473684}
{"step": 1780064, "time": 55653.5008225441, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 1780064, "time": 55653.985662937164, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 1780064, "time": 55654.34731340408, "eval_episode/length": 143.0, "eval_episode/score": 0.5531250238418579, "eval_episode/reward_rate": 0.006944444444444444}
{"step": 1780064, "time": 55654.51599383354, "eval_episode/length": 152.0, "eval_episode/score": 0.5249999761581421, "eval_episode/reward_rate": 0.006535947712418301}
{"step": 1780064, "time": 55654.56172275543, "eval_episode/length": 154.0, "eval_episode/score": 0.518750011920929, "eval_episode/reward_rate": 0.0064516129032258064}
{"step": 1780128, "time": 55656.54542660713, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 1780240, "time": 55659.96725320816, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1780280, "time": 55660.9792740345, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1780296, "time": 55661.47236561775, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 1780360, "time": 55663.4014878273, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1780416, "time": 55665.32073688507, "episode/length": 196.0, "episode/score": 0.38749998807907104, "episode/reward_rate": 0.005076142131979695, "episode/intrinsic_return": 0.0}
{"step": 1780728, "time": 55674.58667373657, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1780768, "time": 55676.045251607895, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1780840, "time": 55677.99852561951, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1781144, "time": 55687.33333444595, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1781304, "time": 55692.220026254654, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1781432, "time": 55696.13391637802, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1781568, "time": 55700.55596780777, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 1781656, "time": 55702.991913080215, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1781672, "time": 55703.4811565876, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1781744, "time": 55705.89971828461, "episode/length": 187.0, "episode/score": 0.4156250059604645, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.0}
{"step": 1781888, "time": 55710.2459256649, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 1781968, "time": 55712.653717041016, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 1782168, "time": 55718.5658082962, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1782336, "time": 55723.901423454285, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1782384, "time": 55725.396102428436, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1782504, "time": 55728.79220867157, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1782640, "time": 55733.18762087822, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 1782768, "time": 55737.09143996239, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1782872, "time": 55740.087784290314, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1783112, "time": 55747.53348135948, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1783360, "time": 55755.29074025154, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1783360, "time": 55755.300679922104, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 1783472, "time": 55758.7138068676, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1783528, "time": 55760.193803310394, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1783552, "time": 55761.143337488174, "episode/length": 234.0, "episode/score": 0.26875001192092896, "episode/reward_rate": 0.00425531914893617, "episode/intrinsic_return": 0.0}
{"step": 1783832, "time": 55769.435938835144, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1784176, "time": 55780.19089126587, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1784200, "time": 55780.70050406456, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1784344, "time": 55785.07959294319, "episode/length": 212.0, "episode/score": 0.3375000059604645, "episode/reward_rate": 0.004694835680751174, "episode/intrinsic_return": 0.0}
{"step": 1784424, "time": 55787.49580287933, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1784608, "time": 55793.31363463402, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1784624, "time": 55793.80300617218, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1784720, "time": 55796.727457761765, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1784896, "time": 55802.08861351013, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1784936, "time": 55803.10064482689, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1784936, "time": 55803.11050200462, "episode/length": 196.0, "episode/score": 0.38749998807907104, "episode/reward_rate": 0.005076142131979695, "episode/intrinsic_return": 0.0}
{"step": 1785040, "time": 55806.49840378761, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 1785184, "time": 55810.952370643616, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1785264, "time": 55813.39489984512, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1785360, "time": 55816.30728459358, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1785552, "time": 55822.136728048325, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1785696, "time": 55826.4844315052, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1785712, "time": 55826.98874807358, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1785760, "time": 55828.44344615936, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1785808, "time": 55829.896045446396, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1785856, "time": 55831.509016513824, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1785872, "time": 55832.4203414917, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1786000, "time": 55836.27557682991, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 1786064, "time": 55838.31432843208, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 1786184, "time": 55841.73931598663, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1786408, "time": 55848.51368904114, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1786624, "time": 55855.33096933365, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1786728, "time": 55858.31708955765, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1786744, "time": 55858.81610560417, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1786872, "time": 55862.70296502113, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1787056, "time": 55868.576288461685, "episode/length": 187.0, "episode/score": 0.4156250059604645, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.0}
{"step": 1787104, "time": 55870.03107762337, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 1787352, "time": 55877.32447767258, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1787608, "time": 55885.07238101959, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1787984, "time": 55896.81425213814, "episode/length": 224.0, "episode/score": 0.30000001192092896, "episode/reward_rate": 0.0044444444444444444, "episode/intrinsic_return": 0.0}
{"step": 1788024, "time": 55897.810639858246, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1788032, "time": 55898.27894806862, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1788152, "time": 55901.70865440369, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 1788176, "time": 55902.655657052994, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 1788208, "time": 55903.62306761742, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1788328, "time": 55907.031821250916, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1788432, "time": 55910.38806653023, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1788752, "time": 55920.03469538689, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1788784, "time": 55921.00052857399, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1788816, "time": 55921.966143369675, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1788912, "time": 55924.88487482071, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1788928, "time": 55925.37425947189, "episode/length": 21.0, "episode/score": 0.934374988079071, "episode/reward_rate": 0.045454545454545456, "episode/intrinsic_return": 0.0}
{"step": 1789024, "time": 55928.39016842842, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1789152, "time": 55932.270612478256, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1789288, "time": 55936.171662569046, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 1789480, "time": 55942.00306725502, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1789496, "time": 55942.488273620605, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1789784, "time": 55951.19228744507, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1789792, "time": 55951.65639543533, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1789792, "time": 55951.6627266407, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1790048, "time": 55960.516191482544, "eval_episode/length": 50.0, "eval_episode/score": 0.84375, "eval_episode/reward_rate": 0.0196078431372549}
{"step": 1790048, "time": 55961.321348428726, "eval_episode/length": 89.0, "eval_episode/score": 0.721875011920929, "eval_episode/reward_rate": 0.011111111111111112}
{"step": 1790048, "time": 55961.56531071663, "eval_episode/length": 101.0, "eval_episode/score": 0.684374988079071, "eval_episode/reward_rate": 0.00980392156862745}
{"step": 1790048, "time": 55961.6538643837, "eval_episode/length": 54.0, "eval_episode/score": 0.831250011920929, "eval_episode/reward_rate": 0.01818181818181818}
{"step": 1790048, "time": 55962.17159175873, "eval_episode/length": 131.0, "eval_episode/score": 0.590624988079071, "eval_episode/reward_rate": 0.007575757575757576}
{"step": 1790048, "time": 55962.2519056797, "eval_episode/length": 135.0, "eval_episode/score": 0.578125, "eval_episode/reward_rate": 0.007352941176470588}
{"step": 1790048, "time": 55962.60733127594, "eval_episode/length": 52.0, "eval_episode/score": 0.8374999761581421, "eval_episode/reward_rate": 0.018867924528301886}
{"step": 1790048, "time": 55962.965552568436, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 1790240, "time": 55968.78827881813, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 1790352, "time": 55972.19291472435, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1790384, "time": 55973.16040682793, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1790552, "time": 55978.01673364639, "episode/length": 264.0, "episode/score": 0.17499999701976776, "episode/reward_rate": 0.0037735849056603774, "episode/intrinsic_return": 0.0}
{"step": 1790688, "time": 55982.347393512726, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1790720, "time": 55983.31606602669, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 1790968, "time": 55990.70785689354, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1791240, "time": 55999.0259013176, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 1791376, "time": 56003.42977166176, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1791448, "time": 56005.376546144485, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1791520, "time": 56007.78090453148, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1791560, "time": 56008.77087378502, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 1791568, "time": 56009.23673868179, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1791720, "time": 56013.620725631714, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1791936, "time": 56020.45324921608, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1792208, "time": 56028.70478892326, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1792360, "time": 56033.12152314186, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1792392, "time": 56034.122389793396, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1792472, "time": 56036.570451021194, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1792488, "time": 56037.060358285904, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1792552, "time": 56038.99304842949, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1792656, "time": 56042.378101587296, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1792816, "time": 56047.32628941536, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1792936, "time": 56050.7531747818, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1793104, "time": 56056.08568453789, "episode/length": 197.0, "episode/score": 0.3843750059604645, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.0}
{"step": 1793192, "time": 56058.53391671181, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1793328, "time": 56062.895285367966, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1793408, "time": 56065.34378743172, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1793432, "time": 56065.863256692886, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1793520, "time": 56068.78756761551, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1793656, "time": 56072.6946709156, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1793848, "time": 56078.57318234444, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1793848, "time": 56078.5820710659, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1793920, "time": 56081.002629995346, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1794080, "time": 56086.35126066208, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1794104, "time": 56086.86041045189, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1794416, "time": 56096.505012989044, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1794568, "time": 56100.87500190735, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1794600, "time": 56101.84961938858, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1794864, "time": 56110.21685218811, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1794896, "time": 56111.1891784668, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1794968, "time": 56113.1626932621, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1795056, "time": 56116.105887413025, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1795376, "time": 56125.78449463844, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 1795416, "time": 56126.78195166588, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1795440, "time": 56127.74339771271, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1795528, "time": 56130.20850944519, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1795848, "time": 56140.000829935074, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1796008, "time": 56144.8628385067, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1796088, "time": 56147.29366230965, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1796144, "time": 56149.24088263512, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1796216, "time": 56151.190813302994, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1796248, "time": 56152.1604142189, "episode/length": 209.0, "episode/score": 0.34687501192092896, "episode/reward_rate": 0.004761904761904762, "episode/intrinsic_return": 0.0}
{"step": 1796312, "time": 56154.12812113762, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 1796488, "time": 56159.46362948418, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1796600, "time": 56162.85915827751, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1796648, "time": 56164.317695856094, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1796776, "time": 56168.303444862366, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1796872, "time": 56171.215520858765, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1797128, "time": 56178.99945425987, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1797336, "time": 56185.320387363434, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1797368, "time": 56186.31036949158, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1797392, "time": 56187.30367279053, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1797424, "time": 56188.294892311096, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1797776, "time": 56199.03010034561, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1797880, "time": 56201.96926140785, "episode/length": 207.0, "episode/score": 0.3531250059604645, "episode/reward_rate": 0.004807692307692308, "episode/intrinsic_return": 0.0}
{"step": 1797888, "time": 56202.43566226959, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1797968, "time": 56204.873016119, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1798096, "time": 56208.79884314537, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 1798344, "time": 56216.05941748619, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1798384, "time": 56217.5124604702, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1798416, "time": 56218.47113132477, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1798496, "time": 56220.885934352875, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1798744, "time": 56228.262325286865, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1798896, "time": 56233.07613706589, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1798976, "time": 56235.49377608299, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1799120, "time": 56239.86638665199, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1799496, "time": 56251.10932326317, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1799648, "time": 56255.94089460373, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1799704, "time": 56257.51169633865, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1799720, "time": 56258.000871658325, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 1800032, "time": 56269.11824584007, "eval_episode/length": 42.0, "eval_episode/score": 0.8687499761581421, "eval_episode/reward_rate": 0.023255813953488372}
{"step": 1800032, "time": 56269.19561624527, "eval_episode/length": 46.0, "eval_episode/score": 0.856249988079071, "eval_episode/reward_rate": 0.02127659574468085}
{"step": 1800032, "time": 56269.36852121353, "eval_episode/length": 55.0, "eval_episode/score": 0.828125, "eval_episode/reward_rate": 0.017857142857142856}
{"step": 1800032, "time": 56270.3013613224, "eval_episode/length": 106.0, "eval_episode/score": 0.668749988079071, "eval_episode/reward_rate": 0.009345794392523364}
{"step": 1800032, "time": 56270.309074640274, "eval_episode/length": 106.0, "eval_episode/score": 0.668749988079071, "eval_episode/reward_rate": 0.009345794392523364}
{"step": 1800032, "time": 56270.42573904991, "eval_episode/length": 65.0, "eval_episode/score": 0.796875, "eval_episode/reward_rate": 0.015151515151515152}
{"step": 1800032, "time": 56270.584408044815, "eval_episode/length": 120.0, "eval_episode/score": 0.625, "eval_episode/reward_rate": 0.008264462809917356}
{"step": 1800032, "time": 56270.71823596954, "eval_episode/length": 71.0, "eval_episode/score": 0.778124988079071, "eval_episode/reward_rate": 0.013888888888888888}
{"step": 1800033, "time": 56271.29485869408, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.435788900545328, "train/action_min": 0.0, "train/action_std": 1.8477478056851, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.010193614443616555, "train/actor_opt_grad_steps": 111395.0, "train/actor_opt_loss": -40.798129714361515, "train/adv_mag": 0.8001209774819931, "train/adv_max": 0.3139161066253587, "train/adv_mean": 0.0008732215526961654, "train/adv_min": -0.7366458732302826, "train/adv_std": 0.03594634145276972, "train/cont_avg": 0.9930722076113861, "train/cont_loss_mean": 0.029397051449459376, "train/cont_loss_std": 0.29664196206791565, "train/cont_neg_acc": 0.10012505557572488, "train/cont_neg_loss": 3.2908962599121696, "train/cont_pos_acc": 0.99982485558727, "train/cont_pos_loss": 0.006517954972932245, "train/cont_pred": 0.9929307418884618, "train/cont_rate": 0.9930722076113861, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.1078039777123987, "train/extr_critic_critic_opt_grad_steps": 111395.0, "train/extr_critic_critic_opt_loss": 10055.640789371906, "train/extr_critic_mag": 2.0415872536083257, "train/extr_critic_max": 2.0415872536083257, "train/extr_critic_mean": 1.9064275887933109, "train/extr_critic_min": 1.5971649236018115, "train/extr_critic_std": 0.03877905065581055, "train/extr_return_normed_mag": 0.8269017987912244, "train/extr_return_normed_max": 0.3302770369123704, "train/extr_return_normed_mean": 0.0872570907346683, "train/extr_return_normed_min": -0.6788486531465361, "train/extr_return_normed_std": 0.0537748626516302, "train/extr_return_rate": 0.9997979390739214, "train/extr_return_raw_mag": 2.1503207742577732, "train/extr_return_raw_max": 2.1503207742577732, "train/extr_return_raw_mean": 1.9073009195894297, "train/extr_return_raw_min": 1.1411950841988667, "train/extr_return_raw_std": 0.05377486257786208, "train/extr_reward_mag": 0.2648378079480464, "train/extr_reward_max": 0.2648378079480464, "train/extr_reward_mean": 0.0033923029809692267, "train/extr_reward_min": 8.852174966642172e-09, "train/extr_reward_std": 0.010635332278169618, "train/image_loss_mean": 0.09169810943969406, "train/image_loss_std": 0.10315198285302313, "train/model_loss_mean": 0.749501632581843, "train/model_loss_std": 0.6133374710484306, "train/model_opt_grad_norm": 13.022926417907867, "train/model_opt_grad_steps": 111293.38613861386, "train/model_opt_loss": 3952.113363435953, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5272.277227722772, "train/policy_entropy_mag": 1.1295347550127766, "train/policy_entropy_max": 1.1295347550127766, "train/policy_entropy_mean": 0.07848197586908198, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.07876093456945797, "train/policy_logprob_mag": 6.551080271749213, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.07846289417604999, "train/policy_logprob_min": -6.551080271749213, "train/policy_logprob_std": 0.6156721988526901, "train/policy_randomness_mag": 0.5804660714203769, "train/policy_randomness_max": 0.5804660714203769, "train/policy_randomness_mean": 0.04033176221027233, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.04047511582548666, "train/post_ent_mag": 29.456524008571513, "train/post_ent_max": 29.456524008571513, "train/post_ent_mean": 28.032533881687883, "train/post_ent_min": 26.662394957967322, "train/post_ent_std": 0.5589005331886877, "train/prior_ent_mag": 28.87972613608483, "train/prior_ent_max": 28.87972613608483, "train/prior_ent_mean": 27.7848534159141, "train/prior_ent_min": 26.500797092324436, "train/prior_ent_std": 0.37348609867662486, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.003827040284263468, "train/reward_loss_mean": 0.028406449178657908, "train/reward_loss_std": 0.3126875633871791, "train/reward_max_data": 0.8286819307520839, "train/reward_max_pred": 0.34760438156600043, "train/reward_neg_acc": 0.9992950614726189, "train/reward_neg_loss": 0.00546033376491269, "train/reward_pos_acc": 0.12533217882460887, "train/reward_pos_loss": 3.9997707522741637, "train/reward_pred": 0.0030782605973210665, "train/reward_rate": 0.005743347772277228, "train_stats/mean_log_entropy": 0.07330249272512668, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.018244273960590363, "report/cont_loss_std": 0.19196757674217224, "report/cont_neg_acc": 0.4285714626312256, "report/cont_neg_loss": 1.7409467697143555, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.006386930588632822, "report/cont_pred": 0.9907659292221069, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.0842113345861435, "report/image_loss_std": 0.10456130653619766, "report/model_loss_mean": 0.7196967005729675, "report/model_loss_std": 0.399820476770401, "report/post_ent_mag": 29.40950584411621, "report/post_ent_max": 29.40950584411621, "report/post_ent_mean": 27.998722076416016, "report/post_ent_min": 26.64242935180664, "report/post_ent_std": 0.5519254207611084, "report/prior_ent_mag": 28.97065544128418, "report/prior_ent_max": 28.97065544128418, "report/prior_ent_mean": 27.513263702392578, "report/prior_ent_min": 26.121618270874023, "report/prior_ent_std": 0.5131967067718506, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0030609131790697575, "report/reward_loss_mean": 0.01724109798669815, "report/reward_loss_std": 0.2022157460451126, "report/reward_max_data": 0.8125, "report/reward_max_pred": 0.547558069229126, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.005063912365585566, "report/reward_pos_acc": 0.4000000059604645, "report/reward_pos_loss": 2.4989514350891113, "report/reward_pred": 0.0032997028902173042, "report/reward_rate": 0.0048828125, "eval/cont_avg": 0.9931640625, "eval/cont_loss_mean": 0.035878606140613556, "eval/cont_loss_std": 0.36821481585502625, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 4.184582710266113, "eval/cont_pos_acc": 0.9990166425704956, "eval/cont_pos_loss": 0.007323117461055517, "eval/cont_pred": 0.9932923913002014, "eval/cont_rate": 0.9931640625, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.1584528684616089, "eval/image_loss_std": 0.13833513855934143, "eval/model_loss_mean": 0.8298710584640503, "eval/model_loss_std": 0.7903429865837097, "eval/post_ent_mag": 29.378341674804688, "eval/post_ent_max": 29.378341674804688, "eval/post_ent_mean": 27.984941482543945, "eval/post_ent_min": 26.53355598449707, "eval/post_ent_std": 0.606475830078125, "eval/prior_ent_mag": 29.02435302734375, "eval/prior_ent_max": 29.02435302734375, "eval/prior_ent_mean": 27.502696990966797, "eval/prior_ent_min": 26.05155372619629, "eval/prior_ent_std": 0.545015275478363, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0042938231490552425, "eval/reward_loss_mean": 0.035539571195840836, "eval/reward_loss_std": 0.41213667392730713, "eval/reward_max_data": 0.934374988079071, "eval/reward_max_pred": 0.2511913776397705, "eval/reward_neg_acc": 0.9980353713035583, "eval/reward_neg_loss": 0.005369164980947971, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.154451847076416, "eval/reward_pred": 0.0025121374055743217, "eval/reward_rate": 0.005859375, "replay/size": 1000000.0, "replay/inserts": 32296.0, "replay/samples": 32288.0, "replay/insert_wait_avg": 1.1904244969792965e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.280598074286379e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4952.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.111641068836021e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.791685104370117e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1002.2740287780762, "timer/env.step_count": 4037.0, "timer/env.step_total": 39.220903396606445, "timer/env.step_frac": 0.039131916292815316, "timer/env.step_avg": 0.00971535878043261, "timer/env.step_min": 0.0076825618743896484, "timer/env.step_max": 0.04424905776977539, "timer/replay._sample_count": 32288.0, "timer/replay._sample_total": 16.427547693252563, "timer/replay._sample_frac": 0.01639027573455159, "timer/replay._sample_avg": 0.0005087818289535606, "timer/replay._sample_min": 0.00040268898010253906, "timer/replay._sample_max": 0.029265642166137695, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4656.0, "timer/agent.policy_total": 49.34052324295044, "timer/agent.policy_frac": 0.04922857604432194, "timer/agent.policy_avg": 0.010597191418159459, "timer/agent.policy_min": 0.009119749069213867, "timer/agent.policy_max": 0.0909261703491211, "timer/dataset_train_count": 2018.0, "timer/dataset_train_total": 0.21017861366271973, "timer/dataset_train_frac": 0.0002097017458578262, "timer/dataset_train_avg": 0.00010415193937696716, "timer/dataset_train_min": 9.059906005859375e-05, "timer/dataset_train_max": 0.0005393028259277344, "timer/agent.train_count": 2018.0, "timer/agent.train_total": 898.9287943840027, "timer/agent.train_frac": 0.8968892424359564, "timer/agent.train_avg": 0.44545529949653256, "timer/agent.train_min": 0.4330563545227051, "timer/agent.train_max": 0.7397968769073486, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47117114067077637, "timer/agent.report_frac": 0.0004701021149327847, "timer/agent.report_avg": 0.23558557033538818, "timer/agent.report_min": 0.22865533828735352, "timer/agent.report_max": 0.24251580238342285, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0517578125e-05, "timer/dataset_eval_frac": 3.0448337728760215e-08, "timer/dataset_eval_avg": 3.0517578125e-05, "timer/dataset_eval_min": 3.0517578125e-05, "timer/dataset_eval_max": 3.0517578125e-05, "fps": 32.222179443718666}
{"step": 1800200, "time": 56276.36457490921, "episode/length": 288.0, "episode/score": 0.10000000149011612, "episode/reward_rate": 0.0034602076124567475, "episode/intrinsic_return": 0.0}
{"step": 1800296, "time": 56279.29210758209, "episode/length": 224.0, "episode/score": 0.30000001192092896, "episode/reward_rate": 0.0044444444444444444, "episode/intrinsic_return": 0.0}
{"step": 1800360, "time": 56281.22620654106, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1800376, "time": 56281.715230464935, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 1800480, "time": 56285.10573863983, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1800592, "time": 56288.59023475647, "episode/length": 230.0, "episode/score": 0.28125, "episode/reward_rate": 0.004329004329004329, "episode/intrinsic_return": 0.0}
{"step": 1800728, "time": 56292.51403403282, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1800816, "time": 56295.43688058853, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1800840, "time": 56295.94934082031, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1800872, "time": 56296.920265197754, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 1801088, "time": 56303.70569944382, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1801104, "time": 56304.191484212875, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1801520, "time": 56316.87419462204, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1801544, "time": 56317.380950927734, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1801544, "time": 56317.389659166336, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1801584, "time": 56318.84186387062, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1801640, "time": 56320.32087993622, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1801760, "time": 56324.19170713425, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1802136, "time": 56335.32998394966, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1802200, "time": 56337.28058385849, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1802248, "time": 56338.92264127731, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1802328, "time": 56341.606969594955, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1802480, "time": 56346.4664850235, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1802512, "time": 56347.543108701706, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1802656, "time": 56351.95885396004, "episode/length": 195.0, "episode/score": 0.390625, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.0}
{"step": 1802872, "time": 56358.29858994484, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 1802872, "time": 56358.31209683418, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1803064, "time": 56364.14201903343, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1803088, "time": 56365.09531164169, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1803384, "time": 56373.839637994766, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1803584, "time": 56380.22015666962, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 1803648, "time": 56382.18095135689, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1803848, "time": 56388.0133895874, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 1804056, "time": 56394.29144477844, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1804056, "time": 56394.29910874367, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1804128, "time": 56396.72071433067, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1804168, "time": 56397.71187996864, "episode/length": 210.0, "episode/score": 0.34375, "episode/reward_rate": 0.004739336492890996, "episode/intrinsic_return": 0.0}
{"step": 1804328, "time": 56402.55840134621, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1804352, "time": 56403.50799846649, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 1804416, "time": 56405.46316289902, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1804632, "time": 56411.8977997303, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1804648, "time": 56412.389901161194, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1804736, "time": 56415.27636837959, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1804744, "time": 56415.30287313461, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1804960, "time": 56422.08380198479, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1805080, "time": 56425.535032749176, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1805096, "time": 56426.02436733246, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 1805192, "time": 56428.939559698105, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1805200, "time": 56429.41541981697, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1805272, "time": 56431.39125418663, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1805632, "time": 56442.605239629745, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1805656, "time": 56443.110832452774, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1805944, "time": 56451.876212358475, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 1805968, "time": 56452.839903354645, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 1806056, "time": 56455.35146737099, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1806064, "time": 56455.82445383072, "episode/length": 241.0, "episode/score": 0.24687500298023224, "episode/reward_rate": 0.004132231404958678, "episode/intrinsic_return": 0.0}
{"step": 1806416, "time": 56466.58049225807, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 1806616, "time": 56472.46420454979, "episode/length": 233.0, "episode/score": 0.2718749940395355, "episode/reward_rate": 0.004273504273504274, "episode/intrinsic_return": 0.0}
{"step": 1806672, "time": 56474.39506530762, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 1806688, "time": 56474.88009214401, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1806896, "time": 56481.17039847374, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1807032, "time": 56485.082621097565, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 1807080, "time": 56486.54478955269, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1807088, "time": 56487.01329231262, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1807248, "time": 56491.902522563934, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 1807512, "time": 56499.8858294487, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1807528, "time": 56500.38683652878, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1807616, "time": 56503.29387140274, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1807784, "time": 56508.193462610245, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1807792, "time": 56508.68435072899, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1808032, "time": 56516.01547574997, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1808216, "time": 56521.40508699417, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1808216, "time": 56521.41083216667, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1808424, "time": 56527.85366177559, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1808448, "time": 56528.83387708664, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1808928, "time": 56543.50057840347, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1808944, "time": 56543.99666786194, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1808968, "time": 56544.508363723755, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1809072, "time": 56547.907549381256, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 1809168, "time": 56550.848019599915, "episode/length": 206.0, "episode/score": 0.35624998807907104, "episode/reward_rate": 0.004830917874396135, "episode/intrinsic_return": 0.0}
{"step": 1809312, "time": 56555.262647390366, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1809584, "time": 56563.71475028992, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 1809752, "time": 56568.60904979706, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 1809776, "time": 56569.56124353409, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1810016, "time": 56578.04992413521, "eval_episode/length": 54.0, "eval_episode/score": 0.831250011920929, "eval_episode/reward_rate": 0.01818181818181818}
{"step": 1810016, "time": 56578.478083372116, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 1810016, "time": 56578.66079235077, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 1810016, "time": 56578.88226437569, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 1810016, "time": 56579.68980193138, "eval_episode/length": 131.0, "eval_episode/score": 0.590624988079071, "eval_episode/reward_rate": 0.007575757575757576}
{"step": 1810016, "time": 56579.755648612976, "eval_episode/length": 134.0, "eval_episode/score": 0.581250011920929, "eval_episode/reward_rate": 0.007407407407407408}
{"step": 1810016, "time": 56579.78144478798, "eval_episode/length": 135.0, "eval_episode/score": 0.578125, "eval_episode/reward_rate": 0.007352941176470588}
{"step": 1810016, "time": 56580.452182769775, "eval_episode/length": 114.0, "eval_episode/score": 0.643750011920929, "eval_episode/reward_rate": 0.008695652173913044}
{"step": 1810144, "time": 56584.35224175453, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1810256, "time": 56587.85342478752, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1810312, "time": 56589.336544275284, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 1810368, "time": 56591.28222870827, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1810424, "time": 56592.76072239876, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 1810432, "time": 56593.37694692612, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1810760, "time": 56603.546585559845, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1810960, "time": 56609.86859583855, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1810968, "time": 56609.896384716034, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1811136, "time": 56615.24872159958, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1811176, "time": 56616.279757499695, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1811216, "time": 56617.826276540756, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1811248, "time": 56618.80074310303, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 1811384, "time": 56622.73781180382, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1811464, "time": 56625.15878486633, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 1811528, "time": 56627.121753931046, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1811744, "time": 56633.88875579834, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 1811920, "time": 56639.25142168999, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1812104, "time": 56644.623847961426, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 1812160, "time": 56646.70247936249, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1812168, "time": 56646.73033094406, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1812224, "time": 56648.65836644173, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1812320, "time": 56651.5983145237, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1812448, "time": 56655.52923083305, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1812464, "time": 56656.02297115326, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1812656, "time": 56661.8804268837, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1813048, "time": 56673.6075489521, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1813080, "time": 56674.59968185425, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1813112, "time": 56675.58417725563, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1813216, "time": 56679.05897831917, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1813264, "time": 56680.53264641762, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1813400, "time": 56684.47274303436, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1813648, "time": 56692.26615047455, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1813656, "time": 56692.29344749451, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1813712, "time": 56694.243465662, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1813904, "time": 56700.11565184593, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1814096, "time": 56705.98532581329, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1814112, "time": 56706.51242184639, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1814216, "time": 56709.54848718643, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1814424, "time": 56715.92061543465, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1814448, "time": 56716.87441253662, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1814760, "time": 56726.19549393654, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1815008, "time": 56733.981414318085, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1815128, "time": 56737.50923037529, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 1815144, "time": 56738.004434108734, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1815192, "time": 56739.49089503288, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1815328, "time": 56743.90296268463, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1815416, "time": 56746.37119269371, "episode/length": 219.0, "episode/score": 0.31562501192092896, "episode/reward_rate": 0.004545454545454545, "episode/intrinsic_return": 0.0}
{"step": 1815632, "time": 56753.19430041313, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1815792, "time": 56758.065536260605, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1815880, "time": 56760.52394270897, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1816024, "time": 56764.93247294426, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1816032, "time": 56765.406856775284, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1816192, "time": 56770.421216487885, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1816200, "time": 56770.44818353653, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1816344, "time": 56774.82791876793, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1816512, "time": 56780.17180919647, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1816568, "time": 56781.66034460068, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1816648, "time": 56784.10360765457, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1816664, "time": 56784.59211349487, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1816960, "time": 56793.815923929214, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1816968, "time": 56793.84477472305, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1816984, "time": 56794.338743925095, "episode/length": 206.0, "episode/score": 0.35624998807907104, "episode/reward_rate": 0.004830917874396135, "episode/intrinsic_return": 0.0}
{"step": 1817104, "time": 56798.33448791504, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1817208, "time": 56801.30158853531, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1817600, "time": 56813.52362012863, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1817616, "time": 56814.01978182793, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1817848, "time": 56820.89917635918, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 1817888, "time": 56822.36646580696, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1817888, "time": 56822.37560534477, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1818168, "time": 56830.89724731445, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1818264, "time": 56833.86017370224, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 1818312, "time": 56835.33373975754, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 1818472, "time": 56840.23550605774, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1818584, "time": 56843.67614078522, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1818712, "time": 56848.07371068001, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1819216, "time": 56863.81441092491, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 1819416, "time": 56869.70985412598, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1819520, "time": 56873.09784579277, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1819648, "time": 56877.00359964371, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 1819784, "time": 56880.91420984268, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 1820000, "time": 56889.6600317955, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 1820000, "time": 56890.206436395645, "eval_episode/length": 113.0, "eval_episode/score": 0.6468750238418579, "eval_episode/reward_rate": 0.008771929824561403}
{"step": 1820000, "time": 56890.27307033539, "eval_episode/length": 116.0, "eval_episode/score": 0.637499988079071, "eval_episode/reward_rate": 0.008547008547008548}
{"step": 1820000, "time": 56890.42339301109, "eval_episode/length": 123.0, "eval_episode/score": 0.6156250238418579, "eval_episode/reward_rate": 0.008064516129032258}
{"step": 1820000, "time": 56890.62972474098, "eval_episode/length": 133.0, "eval_episode/score": 0.5843750238418579, "eval_episode/reward_rate": 0.007462686567164179}
{"step": 1820000, "time": 56890.943707466125, "eval_episode/length": 148.0, "eval_episode/score": 0.5375000238418579, "eval_episode/reward_rate": 0.006711409395973154}
{"step": 1820000, "time": 56891.05137467384, "eval_episode/length": 153.0, "eval_episode/score": 0.5218750238418579, "eval_episode/reward_rate": 0.006493506493506494}
{"step": 1820000, "time": 56891.5993976593, "eval_episode/length": 93.0, "eval_episode/score": 0.7093750238418579, "eval_episode/reward_rate": 0.010638297872340425}
{"step": 1820200, "time": 56897.53158068657, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1820368, "time": 56902.857959747314, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1820568, "time": 56908.7191119194, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 1820744, "time": 56914.057581186295, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 1820744, "time": 56914.06477189064, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1820800, "time": 56916.02056622505, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1820808, "time": 56916.04914736748, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1820896, "time": 56919.04483151436, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1821024, "time": 56922.95511984825, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1821128, "time": 56925.94815206528, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 1821408, "time": 56934.74942612648, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1821680, "time": 56943.04934716225, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 1821720, "time": 56944.06816196442, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1821824, "time": 56947.55055499077, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1821824, "time": 56947.5596973896, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1821992, "time": 56952.48891735077, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 1822056, "time": 56954.46651029587, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1822128, "time": 56956.88289356232, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1822400, "time": 56965.16646695137, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1822600, "time": 56971.053495407104, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1822744, "time": 56975.52681684494, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1823144, "time": 56987.844621896744, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1823152, "time": 56988.3384001255, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1823176, "time": 56988.85307955742, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1823208, "time": 56989.82852101326, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 1823208, "time": 56989.834698200226, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1823272, "time": 56991.78265118599, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 1823440, "time": 56997.136862277985, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1823448, "time": 56997.16527700424, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 1823608, "time": 57002.07168149948, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1823848, "time": 57009.50908660889, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1823992, "time": 57013.91603970528, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1824160, "time": 57019.291176080704, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1824176, "time": 57019.78784966469, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1824280, "time": 57022.74339938164, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1824512, "time": 57030.06878781319, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 1824568, "time": 57031.56746220589, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1824640, "time": 57033.99896359444, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1824680, "time": 57034.99675107002, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1824728, "time": 57036.49499773979, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1824856, "time": 57040.483397722244, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1824880, "time": 57041.44355964661, "episode/length": 208.0, "episode/score": 0.3499999940395355, "episode/reward_rate": 0.004784688995215311, "episode/intrinsic_return": 0.0}
{"step": 1824896, "time": 57041.936619997025, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1824944, "time": 57043.424588918686, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 1825184, "time": 57050.72633981705, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1825336, "time": 57055.12219500542, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1825400, "time": 57057.10387849808, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1825744, "time": 57068.017721414566, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1825864, "time": 57071.452969789505, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1826024, "time": 57076.34158992767, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1826040, "time": 57076.856469631195, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1826072, "time": 57077.83711266518, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 1826080, "time": 57078.30780386925, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 1826512, "time": 57091.4730989933, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1826704, "time": 57097.42653346062, "episode/length": 266.0, "episode/score": 0.16875000298023224, "episode/reward_rate": 0.003745318352059925, "episode/intrinsic_return": 0.0}
{"step": 1826712, "time": 57097.45489573479, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1826960, "time": 57105.77591109276, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1827080, "time": 57109.24118971825, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1827096, "time": 57109.73584294319, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1827128, "time": 57110.71251320839, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1827192, "time": 57112.6906170845, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1827360, "time": 57118.03766012192, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 1827696, "time": 57128.4499733448, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1827960, "time": 57136.28256583214, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1827992, "time": 57137.26701259613, "episode/length": 238.0, "episode/score": 0.2562499940395355, "episode/reward_rate": 0.0041841004184100415, "episode/intrinsic_return": 0.0}
{"step": 1828000, "time": 57137.74271798134, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1828128, "time": 57141.662501335144, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 1828320, "time": 57147.51261687279, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 1828368, "time": 57148.982234716415, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1828384, "time": 57149.476754426956, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1828496, "time": 57152.91605973244, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1828632, "time": 57156.96611762047, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 1828752, "time": 57160.84379196167, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1829016, "time": 57168.60416889191, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1829040, "time": 57169.55727815628, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1829248, "time": 57175.879731178284, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1829456, "time": 57182.161791324615, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1829600, "time": 57186.60559988022, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1829600, "time": 57186.615012168884, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1829624, "time": 57187.13346862793, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 1829800, "time": 57192.48681473732, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 1829952, "time": 57197.34464788437, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1829960, "time": 57197.37224650383, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1830088, "time": 57202.94536328316, "eval_episode/length": 88.0, "eval_episode/score": 0.7250000238418579, "eval_episode/reward_rate": 0.011235955056179775}
{"step": 1830088, "time": 57202.95246338844, "eval_episode/length": 88.0, "eval_episode/score": 0.7250000238418579, "eval_episode/reward_rate": 0.011235955056179775}
{"step": 1830088, "time": 57203.054564237595, "eval_episode/length": 93.0, "eval_episode/score": 0.7093750238418579, "eval_episode/reward_rate": 0.010638297872340425}
{"step": 1830088, "time": 57203.5651204586, "eval_episode/length": 120.0, "eval_episode/score": 0.625, "eval_episode/reward_rate": 0.008264462809917356}
{"step": 1830088, "time": 57203.77482151985, "eval_episode/length": 131.0, "eval_episode/score": 0.590624988079071, "eval_episode/reward_rate": 0.007575757575757576}
{"step": 1830088, "time": 57203.81786322594, "eval_episode/length": 133.0, "eval_episode/score": 0.5843750238418579, "eval_episode/reward_rate": 0.007462686567164179}
{"step": 1830088, "time": 57204.02436900139, "eval_episode/length": 10.0, "eval_episode/score": 0.96875, "eval_episode/reward_rate": 0.09090909090909091}
{"step": 1830088, "time": 57204.322595357895, "eval_episode/length": 39.0, "eval_episode/score": 0.878125011920929, "eval_episode/reward_rate": 0.025}
{"step": 1830208, "time": 57208.16984653473, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1830272, "time": 57210.11816287041, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1830320, "time": 57211.58850312233, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1830688, "time": 57222.932034254074, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1830696, "time": 57222.9613263607, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1830848, "time": 57227.79051709175, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1830904, "time": 57229.2637386322, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1830984, "time": 57231.6728246212, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1831072, "time": 57234.56948232651, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 1831168, "time": 57237.47390627861, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1831344, "time": 57242.795712947845, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 1831400, "time": 57244.27420783043, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1831584, "time": 57250.19831609726, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1831664, "time": 57252.62459897995, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1831888, "time": 57259.413437366486, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1832064, "time": 57264.75215387344, "episode/length": 262.0, "episode/score": 0.18125000596046448, "episode/reward_rate": 0.0038022813688212928, "episode/intrinsic_return": 0.0}
{"step": 1832144, "time": 57267.19855213165, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 1832200, "time": 57268.67739343643, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1832265, "time": 57271.75853514671, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.440403400081219, "train/action_min": 0.0, "train/action_std": 1.8576491917714033, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.011228288039749507, "train/actor_opt_grad_steps": 113415.0, "train/actor_opt_loss": -35.20633890133093, "train/adv_mag": 0.8231613647819745, "train/adv_max": 0.34889215171927274, "train/adv_mean": 0.0011218917288186563, "train/adv_min": -0.7462210743734152, "train/adv_std": 0.034306098209085444, "train/cont_avg": 0.9926322710396039, "train/cont_loss_mean": 0.029952831068398928, "train/cont_loss_std": 0.3016159392819546, "train/cont_neg_acc": 0.1102702737887307, "train/cont_neg_loss": 3.217716927575593, "train/cont_pos_acc": 0.9999221041060911, "train/cont_pos_loss": 0.006354523713165654, "train/cont_pred": 0.9928614880779002, "train/cont_rate": 0.9926322710396039, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.10181702233592768, "train/extr_critic_critic_opt_grad_steps": 113415.0, "train/extr_critic_critic_opt_loss": 8395.504614499536, "train/extr_critic_mag": 2.064017607433961, "train/extr_critic_max": 2.064017607433961, "train/extr_critic_mean": 1.9351924067676658, "train/extr_critic_min": 1.5774420966016185, "train/extr_critic_std": 0.037662115455190145, "train/extr_return_normed_mag": 0.8375311499775047, "train/extr_return_normed_max": 0.31237922210504515, "train/extr_return_normed_mean": 0.0769538070711464, "train/extr_return_normed_min": -0.7011243010511493, "train/extr_return_normed_std": 0.05174437969332874, "train/extr_return_rate": 0.9997876268802303, "train/extr_return_raw_mag": 2.17173958768939, "train/extr_return_raw_max": 2.17173958768939, "train/extr_return_raw_mean": 1.9363142724084381, "train/extr_return_raw_min": 1.158236064533196, "train/extr_return_raw_std": 0.05174437958267656, "train/extr_reward_mag": 0.2600790781549888, "train/extr_reward_max": 0.2600790781549888, "train/extr_reward_mean": 0.0033137287142326927, "train/extr_reward_min": 9.265276465085474e-08, "train/extr_reward_std": 0.010569677766560032, "train/image_loss_mean": 0.0937454426790228, "train/image_loss_std": 0.10417523080169565, "train/model_loss_mean": 0.7534081177546246, "train/model_loss_std": 0.6272331398017336, "train/model_opt_grad_norm": 13.506385123375619, "train/model_opt_grad_steps": 113311.51485148515, "train/model_opt_loss": 4025.180174572633, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5346.534653465346, "train/policy_entropy_mag": 1.1160410211818053, "train/policy_entropy_max": 1.1160410211818053, "train/policy_entropy_mean": 0.07900435573393756, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.08048741711248265, "train/policy_logprob_mag": 6.551080292994433, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.07924252268996569, "train/policy_logprob_min": -6.551080292994433, "train/policy_logprob_std": 0.6175873551038232, "train/policy_randomness_mag": 0.5735316655718454, "train/policy_randomness_max": 0.5735316655718454, "train/policy_randomness_mean": 0.04060021256751353, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.041362353019637636, "train/post_ent_mag": 29.623764708490654, "train/post_ent_max": 29.623764708490654, "train/post_ent_mean": 28.179980523515457, "train/post_ent_min": 26.907814431898665, "train/post_ent_std": 0.5524169692013523, "train/prior_ent_mag": 29.075792189871912, "train/prior_ent_max": 29.075792189871912, "train/prior_ent_mean": 27.660505672492604, "train/prior_ent_min": 26.129729941339775, "train/prior_ent_std": 0.4775607310014196, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.004081242628473936, "train/reward_loss_mean": 0.02970981580380461, "train/reward_loss_std": 0.32152194684684865, "train/reward_max_data": 0.8230816819290123, "train/reward_max_pred": 0.36143078249279814, "train/reward_neg_acc": 0.9994650311989359, "train/reward_neg_loss": 0.005339230672400998, "train/reward_pos_acc": 0.15174695012150424, "train/reward_pos_loss": 3.9121419622166322, "train/reward_pred": 0.003129009269224019, "train/reward_rate": 0.00623646349009901, "train_stats/mean_log_entropy": 0.073341721430757, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9912109375, "report/cont_loss_mean": 0.03495961055159569, "report/cont_loss_std": 0.33666884899139404, "report/cont_neg_acc": 0.1111111119389534, "report/cont_neg_loss": 3.2629241943359375, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.006337263621389866, "report/cont_pred": 0.9925885200500488, "report/cont_rate": 0.9912109375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.08310718834400177, "report/image_loss_std": 0.09690936654806137, "report/model_loss_mean": 0.7494900822639465, "report/model_loss_std": 0.6761457324028015, "report/post_ent_mag": 29.875234603881836, "report/post_ent_max": 29.875234603881836, "report/post_ent_mean": 28.359882354736328, "report/post_ent_min": 26.81441879272461, "report/post_ent_std": 0.5552700757980347, "report/prior_ent_mag": 28.85505485534668, "report/prior_ent_max": 28.85505485534668, "report/prior_ent_mean": 27.68938636779785, "report/prior_ent_min": 26.266326904296875, "report/prior_ent_std": 0.4452240467071533, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.004528808407485485, "report/reward_loss_mean": 0.03142322599887848, "report/reward_loss_std": 0.34352877736091614, "report/reward_max_data": 0.846875011920929, "report/reward_max_pred": 0.622840404510498, "report/reward_neg_acc": 0.9999999403953552, "report/reward_neg_loss": 0.005317780654877424, "report/reward_pos_acc": 0.1428571492433548, "report/reward_pos_loss": 3.824171543121338, "report/reward_pred": 0.003426710143685341, "report/reward_rate": 0.0068359375, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.01713390462100506, "eval/cont_loss_std": 0.31185704469680786, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.224559307098389, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.004986301064491272, "eval/cont_pred": 0.9951178431510925, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.11219518631696701, "eval/image_loss_std": 0.12095264345407486, "eval/model_loss_mean": 0.7463674545288086, "eval/model_loss_std": 0.6480675935745239, "eval/post_ent_mag": 29.87512969970703, "eval/post_ent_max": 29.87512969970703, "eval/post_ent_mean": 28.160703659057617, "eval/post_ent_min": 26.90015983581543, "eval/post_ent_std": 0.6935669779777527, "eval/prior_ent_mag": 29.014022827148438, "eval/prior_ent_max": 29.014022827148438, "eval/prior_ent_mean": 27.509370803833008, "eval/prior_ent_min": 25.823442459106445, "eval/prior_ent_std": 0.5518608093261719, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0013580322265625, "eval/reward_loss_mean": 0.017038393765687943, "eval/reward_loss_std": 0.31312230229377747, "eval/reward_max_data": 0.7093750238418579, "eval/reward_max_pred": 0.16897475719451904, "eval/reward_neg_acc": 0.9970645904541016, "eval/reward_neg_loss": 0.0043457988649606705, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 6.502954483032227, "eval/reward_pred": 0.002258350607007742, "eval/reward_rate": 0.001953125, "replay/size": 1000000.0, "replay/inserts": 32232.0, "replay/samples": 32240.0, "replay/insert_wait_avg": 1.2147275707389734e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.049732993909207e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4096.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1405791155993938e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.046627044677734e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3301994800568, "timer/env.step_count": 4029.0, "timer/env.step_total": 39.987292528152466, "timer/env.step_frac": 0.03997409310339398, "timer/env.step_avg": 0.00992486784019669, "timer/env.step_min": 0.00766754150390625, "timer/env.step_max": 0.03859829902648926, "timer/replay._sample_count": 32240.0, "timer/replay._sample_total": 16.57131052017212, "timer/replay._sample_frac": 0.016565840488256194, "timer/replay._sample_avg": 0.0005139984652658846, "timer/replay._sample_min": 0.0004246234893798828, "timer/replay._sample_max": 0.023515701293945312, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4541.0, "timer/agent.policy_total": 49.13548421859741, "timer/agent.policy_frac": 0.0491192650628129, "timer/agent.policy_avg": 0.010820410530411233, "timer/agent.policy_min": 0.008697748184204102, "timer/agent.policy_max": 0.09613943099975586, "timer/dataset_train_count": 2015.0, "timer/dataset_train_total": 0.21538162231445312, "timer/dataset_train_frac": 0.00021531052689042316, "timer/dataset_train_avg": 0.00010688914258781792, "timer/dataset_train_min": 9.131431579589844e-05, "timer/dataset_train_max": 0.0010504722595214844, "timer/agent.train_count": 2015.0, "timer/agent.train_total": 899.5843605995178, "timer/agent.train_frac": 0.8992874163622134, "timer/agent.train_avg": 0.44644385141415277, "timer/agent.train_min": 0.4361844062805176, "timer/agent.train_max": 0.728823184967041, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4746673107147217, "timer/agent.report_frac": 0.0004745106275522225, "timer/agent.report_avg": 0.23733365535736084, "timer/agent.report_min": 0.22979211807250977, "timer/agent.report_max": 0.24487519264221191, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.86102294921875e-05, "timer/dataset_eval_frac": 2.8600785527677045e-08, "timer/dataset_eval_avg": 2.86102294921875e-05, "timer/dataset_eval_min": 2.86102294921875e-05, "timer/dataset_eval_max": 2.86102294921875e-05, "fps": 32.22079638738516}
{"step": 1832296, "time": 57272.436625003815, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1832392, "time": 57275.38505792618, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1832416, "time": 57276.334567308426, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1832816, "time": 57288.58325099945, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1832848, "time": 57289.55832695961, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1832872, "time": 57290.0674393177, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1832976, "time": 57293.44523406029, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1833128, "time": 57297.853070020676, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 1833200, "time": 57300.26242852211, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 1833424, "time": 57307.15577673912, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1833544, "time": 57310.59406542778, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1833552, "time": 57311.08050608635, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1833752, "time": 57316.907383441925, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 1833808, "time": 57318.82743382454, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 1833880, "time": 57320.8117454052, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1833928, "time": 57322.259644031525, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1834120, "time": 57328.0987637043, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1834232, "time": 57331.50076842308, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 1834328, "time": 57334.40466737747, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1834600, "time": 57342.76544713974, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1834672, "time": 57345.19306564331, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1834688, "time": 57345.679617643356, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1834824, "time": 57349.56549859047, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1835288, "time": 57364.11381363869, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1835480, "time": 57370.12582015991, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1835536, "time": 57372.0437541008, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1835632, "time": 57374.96554875374, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1835752, "time": 57378.360595703125, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1835856, "time": 57381.748908519745, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1836008, "time": 57386.13773226738, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 1836024, "time": 57386.62453651428, "episode/length": 283.0, "episode/score": 0.11562500149011612, "episode/reward_rate": 0.0035211267605633804, "episode/intrinsic_return": 0.0}
{"step": 1836144, "time": 57390.48438715935, "episode/length": 282.0, "episode/score": 0.11874999850988388, "episode/reward_rate": 0.0035335689045936395, "episode/intrinsic_return": 0.0}
{"step": 1836248, "time": 57393.40395092964, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1836264, "time": 57393.89285778999, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1836280, "time": 57394.39903879166, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1836512, "time": 57401.74217915535, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1836536, "time": 57402.25586628914, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1836592, "time": 57404.199910879135, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 1836632, "time": 57405.19062995911, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1836944, "time": 57414.82093524933, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1837136, "time": 57420.62852811813, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1837192, "time": 57422.0987033844, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1837240, "time": 57423.57487773895, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1837272, "time": 57424.544647455215, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 1837712, "time": 57438.16996216774, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1837976, "time": 57445.952468156815, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1838200, "time": 57452.76819610596, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 1838256, "time": 57454.68664479256, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1838272, "time": 57455.17862701416, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 1838296, "time": 57455.68955659866, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1838392, "time": 57458.750990629196, "episode/length": 234.0, "episode/score": 0.26875001192092896, "episode/reward_rate": 0.00425531914893617, "episode/intrinsic_return": 0.0}
{"step": 1838560, "time": 57464.10018706322, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1838840, "time": 57472.3578004837, "episode/length": 212.0, "episode/score": 0.3375000059604645, "episode/reward_rate": 0.004694835680751174, "episode/intrinsic_return": 0.0}
{"step": 1838936, "time": 57475.28699755669, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1839024, "time": 57478.23984694481, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1839288, "time": 57486.02450919151, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1839312, "time": 57487.06383419037, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1839376, "time": 57489.01461458206, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1839392, "time": 57489.50507116318, "episode/length": 12.0, "episode/score": 0.9624999761581421, "episode/reward_rate": 0.07692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1839400, "time": 57489.532254457474, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 1839800, "time": 57501.70911478996, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1839808, "time": 57502.1776843071, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1839816, "time": 57502.20459270477, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1839840, "time": 57503.1562538147, "episode/length": 204.0, "episode/score": 0.36250001192092896, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.0}
{"step": 1839856, "time": 57503.644132852554, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1840008, "time": 57508.04322719574, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1840072, "time": 57510.351152181625, "eval_episode/length": 19.0, "eval_episode/score": 0.940625011920929, "eval_episode/reward_rate": 0.05}
{"step": 1840072, "time": 57510.95942544937, "eval_episode/length": 52.0, "eval_episode/score": 0.8374999761581421, "eval_episode/reward_rate": 0.018867924528301886}
{"step": 1840072, "time": 57511.302733421326, "eval_episode/length": 71.0, "eval_episode/score": 0.778124988079071, "eval_episode/reward_rate": 0.013888888888888888}
{"step": 1840072, "time": 57511.59836220741, "eval_episode/length": 87.0, "eval_episode/score": 0.7281249761581421, "eval_episode/reward_rate": 0.011363636363636364}
{"step": 1840072, "time": 57511.95817446709, "eval_episode/length": 106.0, "eval_episode/score": 0.668749988079071, "eval_episode/reward_rate": 0.009345794392523364}
{"step": 1840072, "time": 57512.21068906784, "eval_episode/length": 120.0, "eval_episode/score": 0.625, "eval_episode/reward_rate": 0.008264462809917356}
{"step": 1840072, "time": 57513.53003501892, "eval_episode/length": 194.0, "eval_episode/score": 0.39375001192092896, "eval_episode/reward_rate": 0.005128205128205128}
{"step": 1840072, "time": 57514.17815041542, "eval_episode/length": 122.0, "eval_episode/score": 0.6187499761581421, "eval_episode/reward_rate": 0.008130081300813009}
{"step": 1840152, "time": 57516.72982144356, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1840296, "time": 57521.093985795975, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 1840384, "time": 57523.97907447815, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1840480, "time": 57526.89540743828, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1840520, "time": 57527.88933300972, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1840712, "time": 57533.71775722504, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1840808, "time": 57536.637773513794, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1840992, "time": 57542.42476081848, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1841056, "time": 57544.35515975952, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1841520, "time": 57558.44411110878, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 1841528, "time": 57558.47204518318, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1841552, "time": 57559.43536901474, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1841552, "time": 57559.44410300255, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1841768, "time": 57565.732333660126, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1842080, "time": 57575.43837141991, "episode/length": 258.0, "episode/score": 0.19374999403953552, "episode/reward_rate": 0.003861003861003861, "episode/intrinsic_return": 0.0}
{"step": 1842088, "time": 57575.46615147591, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 1842112, "time": 57576.44928073883, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1842168, "time": 57577.99046278, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1842224, "time": 57579.93605566025, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 1842304, "time": 57582.375181913376, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 1842328, "time": 57582.88766336441, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1842512, "time": 57588.686794519424, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 1842752, "time": 57595.94120645523, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1843176, "time": 57608.61259865761, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1843288, "time": 57612.44342088699, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1843312, "time": 57613.42053771019, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1843432, "time": 57616.82158613205, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 1843472, "time": 57618.275114536285, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 1843504, "time": 57619.24719762802, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1843536, "time": 57620.219556331635, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 1843840, "time": 57629.44035792351, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1843864, "time": 57629.95104885101, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1844056, "time": 57635.78362488747, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1844192, "time": 57640.19439840317, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1844208, "time": 57640.675849199295, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1844328, "time": 57644.08210039139, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1844352, "time": 57645.03018283844, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1844368, "time": 57645.51940178871, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1844984, "time": 57663.834720134735, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1845008, "time": 57664.78656768799, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1845048, "time": 57665.782611846924, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1845072, "time": 57666.83715701103, "episode/length": 191.0, "episode/score": 0.40312498807907104, "episode/reward_rate": 0.005208333333333333, "episode/intrinsic_return": 0.0}
{"step": 1845320, "time": 57674.11432290077, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 1845336, "time": 57674.60352921486, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1845432, "time": 57677.53261065483, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1845448, "time": 57678.02302026749, "episode/length": 197.0, "episode/score": 0.3843750059604645, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.0}
{"step": 1845576, "time": 57681.968593120575, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1845992, "time": 57694.571336746216, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1846048, "time": 57696.54515457153, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1846160, "time": 57699.958153009415, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1846312, "time": 57704.35120654106, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 1846336, "time": 57705.30028915405, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1846520, "time": 57710.678730249405, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1846584, "time": 57712.61449480057, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1846736, "time": 57717.45487642288, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1847192, "time": 57731.163925886154, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1847232, "time": 57732.59209942818, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1847280, "time": 57734.03793549538, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1847384, "time": 57736.98558020592, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1847392, "time": 57737.45324754715, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 1847448, "time": 57738.92939376831, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1847496, "time": 57740.40391612053, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 1847616, "time": 57744.2316942215, "episode/length": 20.0, "episode/score": 0.9375, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.0}
{"step": 1847648, "time": 57745.21815633774, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1847944, "time": 57753.921320438385, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1848088, "time": 57758.38146138191, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1848168, "time": 57760.814327955246, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1848272, "time": 57764.19658732414, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1848280, "time": 57764.22369360924, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1848424, "time": 57768.571788311005, "episode/length": 260.0, "episode/score": 0.1875, "episode/reward_rate": 0.0038314176245210726, "episode/intrinsic_return": 0.0}
{"step": 1848504, "time": 57771.01052284241, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1848848, "time": 57781.621762275696, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 1849104, "time": 57789.45220327377, "episode/length": 233.0, "episode/score": 0.2718749940395355, "episode/reward_rate": 0.004273504273504274, "episode/intrinsic_return": 0.0}
{"step": 1849152, "time": 57790.90453886986, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1849168, "time": 57791.39193677902, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1849240, "time": 57793.350549697876, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1849464, "time": 57800.20329093933, "episode/length": 189.0, "episode/score": 0.40937501192092896, "episode/reward_rate": 0.005263157894736842, "episode/intrinsic_return": 0.0}
{"step": 1849536, "time": 57802.6009721756, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 1849768, "time": 57809.39084792137, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1849824, "time": 57811.302568912506, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1849944, "time": 57814.70467734337, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1850056, "time": 57819.167273044586, "eval_episode/length": 49.0, "eval_episode/score": 0.846875011920929, "eval_episode/reward_rate": 0.02}
{"step": 1850056, "time": 57819.70390200615, "eval_episode/length": 75.0, "eval_episode/score": 0.765625, "eval_episode/reward_rate": 0.013157894736842105}
{"step": 1850056, "time": 57819.76865148544, "eval_episode/length": 78.0, "eval_episode/score": 0.7562500238418579, "eval_episode/reward_rate": 0.012658227848101266}
{"step": 1850056, "time": 57819.931013822556, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 1850056, "time": 57819.95579266548, "eval_episode/length": 87.0, "eval_episode/score": 0.7281249761581421, "eval_episode/reward_rate": 0.011363636363636364}
{"step": 1850056, "time": 57820.00027728081, "eval_episode/length": 89.0, "eval_episode/score": 0.721875011920929, "eval_episode/reward_rate": 0.011111111111111112}
{"step": 1850056, "time": 57820.320127010345, "eval_episode/length": 105.0, "eval_episode/score": 0.671875, "eval_episode/reward_rate": 0.009433962264150943}
{"step": 1850056, "time": 57821.195729494095, "eval_episode/length": 152.0, "eval_episode/score": 0.5249999761581421, "eval_episode/reward_rate": 0.006535947712418301}
{"step": 1850064, "time": 57821.66449856758, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1850104, "time": 57822.662952423096, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1850256, "time": 57827.50312590599, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 1850344, "time": 57829.96714067459, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1850344, "time": 57829.975108623505, "episode/length": 229.0, "episode/score": 0.28437501192092896, "episode/reward_rate": 0.004347826086956522, "episode/intrinsic_return": 0.0}
{"step": 1850416, "time": 57832.390991687775, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1850432, "time": 57832.88184785843, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1850496, "time": 57834.82835865021, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1850616, "time": 57838.251369953156, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1850720, "time": 57841.642862319946, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1851112, "time": 57853.43901133537, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1851208, "time": 57856.38067817688, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1851296, "time": 57859.27711558342, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1851408, "time": 57863.171484947205, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1851824, "time": 57875.851951122284, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 1851848, "time": 57876.38654398918, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 1851928, "time": 57878.86610031128, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1852128, "time": 57885.1956114769, "episode/length": 233.0, "episode/score": 0.2718749940395355, "episode/reward_rate": 0.004273504273504274, "episode/intrinsic_return": 0.0}
{"step": 1852240, "time": 57888.575236558914, "episode/length": 189.0, "episode/score": 0.40937501192092896, "episode/reward_rate": 0.005263157894736842, "episode/intrinsic_return": 0.0}
{"step": 1852248, "time": 57888.601999759674, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 1852384, "time": 57892.9406542778, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 1852456, "time": 57894.91028833389, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1852544, "time": 57897.787789583206, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 1852784, "time": 57905.02758049965, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1852880, "time": 57907.979759931564, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 1852928, "time": 57909.450947761536, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1853048, "time": 57912.8601834774, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1853168, "time": 57916.71979999542, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1853168, "time": 57916.72893619537, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 1853280, "time": 57920.15989303589, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1853456, "time": 57925.51310348511, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1853528, "time": 57927.4708814621, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1853968, "time": 57941.13145303726, "episode/length": 229.0, "episode/score": 0.28437501192092896, "episode/reward_rate": 0.004347826086956522, "episode/intrinsic_return": 0.0}
{"step": 1854056, "time": 57943.59175872803, "episode/length": 10.0, "episode/score": 0.96875, "episode/reward_rate": 0.09090909090909091, "episode/intrinsic_return": 0.0}
{"step": 1854288, "time": 57950.8077480793, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1854440, "time": 57955.18146467209, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1854512, "time": 57957.589274168015, "episode/length": 203.0, "episode/score": 0.3656249940395355, "episode/reward_rate": 0.004901960784313725, "episode/intrinsic_return": 0.0}
{"step": 1854600, "time": 57960.027547836304, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 1854696, "time": 57962.94140505791, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1855264, "time": 57980.404034137726, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1855480, "time": 57986.7366566658, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1855496, "time": 57987.22597813606, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 1855832, "time": 57997.54771900177, "episode/length": 221.0, "episode/score": 0.30937498807907104, "episode/reward_rate": 0.0045045045045045045, "episode/intrinsic_return": 0.0}
{"step": 1855840, "time": 57998.02585530281, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1856048, "time": 58004.33770823479, "episode/length": 191.0, "episode/score": 0.40312498807907104, "episode/reward_rate": 0.005208333333333333, "episode/intrinsic_return": 0.0}
{"step": 1856176, "time": 58008.194813489914, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1856208, "time": 58009.159026145935, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1856432, "time": 58015.91843056679, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1856544, "time": 58019.28862977028, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1856744, "time": 58025.08466100693, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1856752, "time": 58025.5696079731, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1856840, "time": 58028.0781993866, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1856880, "time": 58029.50965499878, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 1856976, "time": 58032.42888736725, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1857008, "time": 58033.39984703064, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1857256, "time": 58040.711770534515, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1857304, "time": 58042.159363508224, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1857352, "time": 58043.60264778137, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1857416, "time": 58045.55739736557, "episode/length": 13.0, "episode/score": 0.9593750238418579, "episode/reward_rate": 0.07142857142857142, "episode/intrinsic_return": 0.0}
{"step": 1857536, "time": 58049.4204313755, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1857608, "time": 58051.388461351395, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1858064, "time": 58065.51066446304, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1858104, "time": 58066.5005941391, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1858128, "time": 58067.44782733917, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1858128, "time": 58067.45668435097, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1858472, "time": 58077.5738196373, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1858512, "time": 58079.01182794571, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1858728, "time": 58085.26760482788, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1858840, "time": 58088.76226758957, "episode/length": 197.0, "episode/score": 0.3843750059604645, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.0}
{"step": 1858944, "time": 58092.123384952545, "episode/length": 241.0, "episode/score": 0.24687500298023224, "episode/reward_rate": 0.004132231404958678, "episode/intrinsic_return": 0.0}
{"step": 1858944, "time": 58092.132132291794, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1859152, "time": 58098.58828783035, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1859296, "time": 58102.93689465523, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1859448, "time": 58107.313284397125, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1859456, "time": 58107.78085947037, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 1859536, "time": 58110.20485544205, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1859560, "time": 58110.71197223663, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
