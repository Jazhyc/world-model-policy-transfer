{"step": 1560, "time": 124.32739210128784, "eval_episode/length": 127.0, "eval_episode/score": 0.6031249761581421, "eval_episode/reward_rate": 0.0078125}
{"step": 1560, "time": 127.7208890914917, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 127.72975039482117, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 127.73615050315857, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 127.74241614341736, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 127.74868535995483, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 127.75507473945618, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 127.7666494846344, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1561, "time": 245.00654768943787, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.803955078125, "train/action_min": 0.0, "train/action_std": 2.177912950515747, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0019316435791552067, "train/actor_opt_grad_steps": 1.0, "train/actor_opt_loss": -2.9032270908355713, "train/adv_mag": 0.0, "train/adv_max": 0.0, "train/adv_mean": 0.0, "train/adv_min": 0.0, "train/adv_std": 0.0, "train/cont_avg": 1.0, "train/cont_loss_mean": 0.4768450856208801, "train/cont_loss_std": 0.2237531840801239, "train/cont_neg_acc": NaN, "train/cont_neg_loss": NaN, "train/cont_pos_acc": 0.8505859375, "train/cont_pos_loss": 0.4768450856208801, "train/cont_pred": 0.6352332830429077, "train/cont_rate": 1.0, "train/dyn_loss_mean": 9.997137069702148, "train/dyn_loss_std": 0.41796207427978516, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 16.28055191040039, "train/extr_critic_critic_opt_grad_steps": 1.0, "train/extr_critic_critic_opt_loss": 65141.703125, "train/extr_critic_mag": 0.0, "train/extr_critic_max": 0.0, "train/extr_critic_mean": 0.0, "train/extr_critic_min": 0.0, "train/extr_critic_std": 0.0, "train/extr_return_normed_mag": 0.0, "train/extr_return_normed_max": 0.0, "train/extr_return_normed_mean": 0.0, "train/extr_return_normed_min": 0.0, "train/extr_return_normed_std": 0.0, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.0, "train/extr_return_raw_max": 0.0, "train/extr_return_raw_mean": 0.0, "train/extr_return_raw_min": 0.0, "train/extr_return_raw_std": 0.0, "train/extr_reward_mag": 0.0, "train/extr_reward_max": 0.0, "train/extr_reward_mean": 0.0, "train/extr_reward_min": 0.0, "train/extr_reward_std": 0.0, "train/image_loss_mean": 5035.5771484375, "train/image_loss_std": 38.302181243896484, "train/model_loss_mean": 5047.59326171875, "train/model_loss_std": 38.2575569152832, "train/model_opt_grad_norm": NaN, "train/model_opt_grad_steps": 0.0, "train/model_opt_loss": 50475932.0, "train/model_opt_model_opt_grad_overflow": 1.0, "train/model_opt_model_opt_grad_scale": 5000.0, "train/policy_entropy_mag": 1.9282389879226685, "train/policy_entropy_max": 1.9282389879226685, "train/policy_entropy_mean": 1.6389511823654175, "train/policy_entropy_min": 0.6999279260635376, "train/policy_entropy_std": 0.1762184053659439, "train/policy_logprob_mag": 4.75564432144165, "train/policy_logprob_max": -0.1793755739927292, "train/policy_logprob_mean": -1.6253145933151245, "train/policy_logprob_min": -4.75564432144165, "train/policy_logprob_std": 0.7607080936431885, "train/policy_randomness_mag": 0.9909188747406006, "train/policy_randomness_max": 0.9909188747406006, "train/policy_randomness_mean": 0.8422542810440063, "train/policy_randomness_min": 0.3596918284893036, "train/policy_randomness_std": 0.09055835008621216, "train/post_ent_mag": 106.50057220458984, "train/post_ent_max": 106.50057220458984, "train/post_ent_mean": 106.17095947265625, "train/post_ent_min": 105.80941772460938, "train/post_ent_std": 0.10499053448438644, "train/prior_ent_mag": 106.70928192138672, "train/prior_ent_max": 106.70928192138672, "train/prior_ent_mean": 105.87068176269531, "train/prior_ent_min": 104.58932495117188, "train/prior_ent_std": 0.2762822210788727, "train/rep_loss_mean": 9.997137069702148, "train/rep_loss_std": 0.41796207427978516, "train/reward_avg": 0.0, "train/reward_loss_mean": 5.541262626647949, "train/reward_loss_std": 9.5367431640625e-07, "train/reward_max_data": 0.0, "train/reward_max_pred": 0.0, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 5.541262626647949, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0, "train/reward_rate": 0.0, "train/params_agent/wm/model_opt": 181559683.0, "train/params_agent/task_behavior/critic/critic_opt": 9708799.0, "train/params_agent/task_behavior/ac/actor_opt": 9454599.0, "report/cont_avg": 1.0, "report/cont_loss_mean": 0.4665205776691437, "report/cont_loss_std": 0.2354772686958313, "report/cont_neg_acc": NaN, "report/cont_neg_loss": NaN, "report/cont_pos_acc": 0.85546875, "report/cont_pos_loss": 0.4665205776691437, "report/cont_pred": 0.6430702209472656, "report/cont_rate": 1.0, "report/dyn_loss_mean": 10.04069709777832, "report/dyn_loss_std": 0.3865164816379547, "report/image_loss_mean": 5042.71728515625, "report/image_loss_std": 39.15144348144531, "report/model_loss_mean": 5054.74951171875, "report/model_loss_std": 39.114280700683594, "report/post_ent_mag": 106.43994140625, "report/post_ent_max": 106.43994140625, "report/post_ent_mean": 106.15623474121094, "report/post_ent_min": 105.83194732666016, "report/post_ent_std": 0.10326159745454788, "report/prior_ent_mag": 106.62139892578125, "report/prior_ent_max": 106.62139892578125, "report/prior_ent_mean": 105.83045959472656, "report/prior_ent_min": 104.74142456054688, "report/prior_ent_std": 0.2774673104286194, "report/rep_loss_mean": 10.04069709777832, "report/rep_loss_std": 0.3865164816379547, "report/reward_avg": 0.0, "report/reward_loss_mean": 5.541262626647949, "report/reward_loss_std": 9.5367431640625e-07, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.0, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 5.541262626647949, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.45251792669296265, "eval/cont_loss_std": 0.22264723479747772, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 0.8818359375, "eval/cont_pos_loss": 0.45251792669296265, "eval/cont_pred": 0.6503475904464722, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 10.024712562561035, "eval/dyn_loss_std": 0.40088388323783875, "eval/image_loss_mean": 5043.71484375, "eval/image_loss_std": 34.70967102050781, "eval/model_loss_mean": 5055.72412109375, "eval/model_loss_std": 34.70458984375, "eval/post_ent_mag": 106.46629333496094, "eval/post_ent_max": 106.46629333496094, "eval/post_ent_mean": 106.18009948730469, "eval/post_ent_min": 105.84337615966797, "eval/post_ent_std": 0.1015174463391304, "eval/prior_ent_mag": 106.68507385253906, "eval/prior_ent_max": 106.68507385253906, "eval/prior_ent_mean": 105.85041046142578, "eval/prior_ent_min": 105.04925537109375, "eval/prior_ent_std": 0.28671279549598694, "eval/rep_loss_mean": 10.024712562561035, "eval/rep_loss_std": 0.40088388323783875, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 5.541262626647949, "eval/reward_loss_std": 9.5367431640625e-07, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 5.541262626647949, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0, "eval/reward_rate": 0.0, "replay/size": 1057.0, "replay/inserts": 1057.0, "replay/samples": 112.0, "replay/insert_wait_avg": 1.5417133284382022e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.450580596923828e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 3368.0, "eval_replay/inserts": 3368.0, "eval_replay/samples": 112.0, "eval_replay/insert_wait_avg": 1.2914103736786831e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.727822984967913e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 143.12627267837524, "timer/env.step_count": 196.0, "timer/env.step_total": 1.363201379776001, "timer/env.step_frac": 0.009524466432793267, "timer/env.step_avg": 0.006955109080489801, "timer/env.step_min": 0.0062787532806396484, "timer/env.step_max": 0.01687335968017578, "timer/replay._sample_count": 112.0, "timer/replay._sample_total": 0.076995849609375, "timer/replay._sample_frac": 0.0005379574844542724, "timer/replay._sample_avg": 0.0006874629429408482, "timer/replay._sample_min": 0.00035119056701660156, "timer/replay._sample_max": 0.0011131763458251953, "timer/agent.save_count": 1.0, "timer/agent.save_total": 2.0722815990448, "timer/agent.save_frac": 0.014478694653786634, "timer/agent.save_avg": 2.0722815990448, "timer/agent.save_min": 2.0722815990448, "timer/agent.save_max": 2.0722815990448, "timer/agent.policy_count": 290.0, "timer/agent.policy_total": 22.096840620040894, "timer/agent.policy_frac": 0.15438703325765762, "timer/agent.policy_avg": 0.07619600213807205, "timer/agent.policy_min": 0.009038925170898438, "timer/agent.policy_max": 16.892831087112427, "timer/dataset_train_count": 1.0, "timer/dataset_train_total": 2.9325485229492188e-05, "timer/dataset_train_frac": 2.048923980252784e-07, "timer/dataset_train_avg": 2.9325485229492188e-05, "timer/dataset_train_min": 2.9325485229492188e-05, "timer/dataset_train_max": 2.9325485229492188e-05, "timer/agent.train_count": 1.0, "timer/agent.train_total": 91.00817584991455, "timer/agent.train_frac": 0.6358593299947288, "timer/agent.train_avg": 91.00817584991455, "timer/agent.train_min": 91.00817584991455, "timer/agent.train_max": 91.00817584991455, "timer/agent.report_count": 2.0, "timer/agent.report_total": 24.084302186965942, "timer/agent.report_frac": 0.16827310413572175, "timer/agent.report_avg": 12.042151093482971, "timer/agent.report_min": 0.24429535865783691, "timer/agent.report_max": 23.840006828308105, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.838539123535156e-05, "timer/dataset_eval_frac": 2.6819248847211234e-07, "timer/dataset_eval_avg": 3.838539123535156e-05, "timer/dataset_eval_min": 3.838539123535156e-05, "timer/dataset_eval_max": 3.838539123535156e-05}
{"step": 2312, "time": 267.7923755645752, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 2312, "time": 267.8005783557892, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 2312, "time": 267.8143172264099, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 2312, "time": 267.82178020477295, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 2312, "time": 267.8295443058014, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 2312, "time": 267.8373417854309, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 2312, "time": 267.8444583415985, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 2312, "time": 267.8512682914734, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 4624, "time": 339.17186212539673, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 4624, "time": 339.18012857437134, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 4624, "time": 339.1877453327179, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 4624, "time": 339.1948997974396, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 4624, "time": 339.20188999176025, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 4624, "time": 339.2095081806183, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 4624, "time": 339.2187485694885, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 4624, "time": 339.2262918949127, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 6936, "time": 409.5105564594269, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 6936, "time": 409.51889276504517, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 6936, "time": 409.5310854911804, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 6936, "time": 409.5391080379486, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 6936, "time": 409.54604506492615, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 6936, "time": 409.5550699234009, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 6936, "time": 409.5622832775116, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 6936, "time": 409.57019329071045, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 8760, "time": 465.83796858787537, "episode/length": 227.0, "episode/score": 0.2906250059604645, "episode/reward_rate": 0.0043859649122807015, "episode/intrinsic_return": 0.0}
{"step": 9248, "time": 481.00147914886475, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 9248, "time": 481.0097641944885, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 9248, "time": 481.0195641517639, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 9248, "time": 481.02696228027344, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 9248, "time": 481.0341606140137, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 9248, "time": 481.0428099632263, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 9248, "time": 481.0505690574646, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 10088, "time": 512.0354714393616, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 512.050496339798, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 512.0644044876099, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 512.0791912078857, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 512.0879340171814, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 512.1001505851746, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 512.1104438304901, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 512.1217064857483, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 11072, "time": 542.4754238128662, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 11560, "time": 557.142480134964, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 11560, "time": 557.1507225036621, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 11560, "time": 557.1580986976624, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 11560, "time": 557.1656095981598, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 11560, "time": 557.1728889942169, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 11560, "time": 557.1803021430969, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 11560, "time": 557.1876227855682, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 13384, "time": 612.8621165752411, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 13872, "time": 628.0374281406403, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 13872, "time": 628.0458829402924, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 13872, "time": 628.0538835525513, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 13872, "time": 628.0615031719208, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 13872, "time": 628.0685122013092, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 13872, "time": 628.0756788253784, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 13872, "time": 628.0830361843109, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 15696, "time": 684.0294988155365, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 16184, "time": 698.8272500038147, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 16184, "time": 698.8355777263641, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 16184, "time": 698.8437385559082, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 16184, "time": 698.850919008255, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 16184, "time": 698.858161687851, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 16184, "time": 698.866984128952, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 16184, "time": 698.873872756958, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 17424, "time": 737.7617647647858, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 18008, "time": 755.5094602108002, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 18496, "time": 770.7183589935303, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 18496, "time": 770.7266664505005, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 18496, "time": 770.7340142726898, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 18496, "time": 770.7409865856171, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 18496, "time": 770.7506988048553, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 18496, "time": 770.758309841156, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 19736, "time": 808.7940492630005, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 20072, "time": 825.6415498256683, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 825.649069070816, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 825.6557755470276, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 825.6657409667969, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 825.6740248203278, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 825.6812500953674, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 825.6887009143829, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 825.6952316761017, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20320, "time": 833.4949421882629, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 20808, "time": 848.2154171466827, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 20808, "time": 848.2239592075348, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 20808, "time": 848.2315194606781, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 20808, "time": 848.238783121109, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 20808, "time": 848.2458369731903, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 20808, "time": 848.2530336380005, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 22048, "time": 886.6593887805939, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 22632, "time": 904.5952036380768, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 23120, "time": 919.7647788524628, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 23120, "time": 919.775470495224, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 23120, "time": 919.7833302021027, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 23120, "time": 919.7909457683563, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 23120, "time": 919.7983644008636, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 23120, "time": 919.8067817687988, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 24360, "time": 957.8748073577881, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 24736, "time": 970.199206829071, "episode/length": 201.0, "episode/score": 0.37187498807907104, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.0}
{"step": 24944, "time": 976.5992891788483, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 25432, "time": 991.4516353607178, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 25432, "time": 991.4603269100189, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 25432, "time": 991.4687252044678, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 25432, "time": 991.4873933792114, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 25432, "time": 991.4962153434753, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 26672, "time": 1029.8666348457336, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 26784, "time": 1033.2691197395325, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 27048, "time": 1041.0999238491058, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 27256, "time": 1047.5207698345184, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 27744, "time": 1062.643926858902, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 27744, "time": 1062.652475118637, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 27744, "time": 1062.6614813804626, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 27744, "time": 1062.669742822647, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 27864, "time": 1066.1447007656097, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 28984, "time": 1100.543595790863, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 29360, "time": 1112.3744475841522, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 29568, "time": 1118.805471420288, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 30056, "time": 1133.5916981697083, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 30056, "time": 1133.599837064743, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 30056, "time": 1133.6071209907532, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 30056, "time": 1133.6188309192657, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 30056, "time": 1141.0692028999329, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1141.076975107193, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1141.0834743976593, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1141.0898661613464, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1141.096060037613, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1141.1021666526794, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1141.109356880188, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1141.1157541275024, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30176, "time": 1147.84339761734, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 31296, "time": 1182.1408891677856, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 31672, "time": 1193.406733751297, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 31880, "time": 1199.8420822620392, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 32368, "time": 1214.9443147182465, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 32368, "time": 1214.9573240280151, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 32368, "time": 1214.9691574573517, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 32368, "time": 1214.9819214344025, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 32488, "time": 1218.415676832199, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 32569, "time": 1221.823867559433, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.0012605499109455, "train/action_min": 0.0, "train/action_std": 1.999548896606722, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 7.967333744364184e-05, "train/actor_opt_grad_steps": 970.0, "train/actor_opt_loss": -4.134165716024569, "train/adv_mag": 0.00013499621891328135, "train/adv_max": 0.000134943350616469, "train/adv_mean": 8.071729341484021e-05, "train/adv_min": 1.2326004543266207e-05, "train/adv_std": 3.749666867849066e-05, "train/cont_avg": 0.9970298332253886, "train/cont_loss_mean": 0.022686567086641164, "train/cont_loss_std": 0.29739988137846507, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.784556435756996, "train/cont_pos_acc": 0.9992663020297036, "train/cont_pos_loss": 0.0055332310055108995, "train/cont_pred": 0.9950366146823902, "train/cont_rate": 0.9970298332253886, "train/dyn_loss_mean": 1.0600713497616467, "train/dyn_loss_std": 0.004652667594841353, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 4.486373244017517, "train/extr_critic_critic_opt_grad_steps": 970.0, "train/extr_critic_critic_opt_loss": 5357.389605981698, "train/extr_critic_mag": 0.00013784238093875233, "train/extr_critic_max": 0.00013783188063863647, "train/extr_critic_mean": 0.00013741524482001693, "train/extr_critic_min": 0.0001369955626176429, "train/extr_critic_std": 9.408906963393031e-08, "train/extr_return_normed_mag": 0.00017357046171839925, "train/extr_return_normed_max": 0.0001735597207671413, "train/extr_return_normed_mean": 0.00011950679872528288, "train/extr_return_normed_min": 5.1289267648525525e-05, "train/extr_return_normed_std": 3.7490078197623874e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.00027220361123873687, "train/extr_return_raw_max": 0.00027218519434043685, "train/extr_return_raw_mean": 0.0002181322789822189, "train/extr_return_raw_min": 0.00014991474180536582, "train/extr_return_raw_std": 3.7490078006792434e-05, "train/extr_reward_mag": 1.3230378145998623e-05, "train/extr_reward_max": 1.3229142816573227e-05, "train/extr_reward_mean": 1.3170074190709304e-05, "train/extr_reward_min": 1.3074108973685941e-05, "train/extr_reward_std": 2.1964410246846103e-08, "train/image_loss_mean": 27.17684525591104, "train/image_loss_std": 0.35970585492145213, "train/model_loss_mean": 27.943825315935005, "train/model_loss_std": 0.6048050188879275, "train/model_opt_grad_norm": 100.4391527324915, "train/model_opt_grad_steps": 960.0, "train/model_opt_loss": 532.8875868209285, "train/model_opt_model_opt_grad_overflow": 0.0051813471502590676, "train/model_opt_model_opt_grad_scale": 14.420741580310882, "train/policy_entropy_mag": 1.9457948090498929, "train/policy_entropy_max": 1.9457948090498929, "train/policy_entropy_mean": 1.9409904813519414, "train/policy_entropy_min": 1.8690206948957295, "train/policy_entropy_std": 0.003312423831295859, "train/policy_logprob_mag": 2.4177354679206493, "train/policy_logprob_max": -1.476751269145333, "train/policy_logprob_mean": -1.9409347420529381, "train/policy_logprob_min": -2.4177354679206493, "train/policy_logprob_std": 0.08856986930178855, "train/policy_randomness_mag": 0.9999407844839936, "train/policy_randomness_max": 0.9999407844839936, "train/policy_randomness_mean": 0.9974718464470897, "train/policy_randomness_min": 0.9604866924681195, "train/policy_randomness_std": 0.0017022491831433781, "train/post_ent_mag": 83.71853159375759, "train/post_ent_max": 83.71853159375759, "train/post_ent_mean": 83.63082237441306, "train/post_ent_min": 83.563295117314, "train/post_ent_std": 0.021680675198473616, "train/prior_ent_mag": 89.29252134333002, "train/prior_ent_max": 89.29252134333002, "train/prior_ent_mean": 89.19586351621955, "train/prior_ent_min": 88.85543364687905, "train/prior_ent_std": 0.06457174508566993, "train/rep_loss_mean": 1.0600713497616467, "train/rep_loss_std": 0.004652667594841353, "train/reward_avg": 3.1561184634691e-05, "train/reward_loss_mean": 0.10825032754342791, "train/reward_loss_std": 0.02702164732177087, "train/reward_max_data": 0.03231865306592358, "train/reward_max_pred": 1.3212465869330372e-05, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.10740732018162684, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 10.414261996746063, "train/reward_pred": 1.3141870532435766e-05, "train/reward_rate": 8.095854922279793e-05, "train_stats/mean_log_entropy": 1.9276236179655633, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 1.0, "report/cont_loss_mean": 0.002761473413556814, "report/cont_loss_std": 6.732498718520219e-07, "report/cont_neg_acc": NaN, "report/cont_neg_loss": NaN, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.002761473413556814, "report/cont_pred": 0.9972421526908875, "report/cont_rate": 1.0, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.29293984174728394, "report/image_loss_std": 0.07301513850688934, "report/model_loss_mean": 0.8962639570236206, "report/model_loss_std": 0.07301515340805054, "report/post_ent_mag": 72.13423919677734, "report/post_ent_max": 72.13423919677734, "report/post_ent_mean": 71.89649963378906, "report/post_ent_min": 71.86711120605469, "report/post_ent_std": 0.036774616688489914, "report/prior_ent_mag": 79.6682357788086, "report/prior_ent_max": 79.6682357788086, "report/prior_ent_mean": 79.58016204833984, "report/prior_ent_min": 78.97404479980469, "report/prior_ent_std": 0.08922021090984344, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.0005626194179058075, "report/reward_loss_std": 9.233235687133856e-07, "report/reward_max_data": 0.0, "report/reward_max_pred": 3.9458274841308594e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0005626194179058075, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 3.931298851966858e-05, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.0027614417485892773, "eval/cont_loss_std": 3.37119672622066e-07, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0027614417485892773, "eval/cont_pred": 0.9972422122955322, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.3007887601852417, "eval/image_loss_std": 0.06970331072807312, "eval/model_loss_mean": 0.9041129350662231, "eval/model_loss_std": 0.06970334053039551, "eval/post_ent_mag": 72.13118743896484, "eval/post_ent_max": 72.13118743896484, "eval/post_ent_mean": 71.89669036865234, "eval/post_ent_min": 71.86792755126953, "eval/post_ent_std": 0.03613581880927086, "eval/prior_ent_mag": 79.65119934082031, "eval/prior_ent_max": 79.65119934082031, "eval/prior_ent_mean": 79.57882690429688, "eval/prior_ent_min": 78.97404479980469, "eval/prior_ent_std": 0.09122857451438904, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0005626538768410683, "eval/reward_loss_std": 8.548541359232331e-07, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 3.9458274841308594e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0005626538768410683, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 3.9316131733357906e-05, "eval/reward_rate": 0.0, "replay/size": 32065.0, "replay/inserts": 31008.0, "replay/samples": 31008.0, "replay/insert_wait_avg": 1.3614417475689553e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.245155415175746e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 10304.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2537256106648341e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.385807991027832e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 976.8061542510986, "timer/env.step_count": 3876.0, "timer/env.step_total": 39.17973613739014, "timer/env.step_frac": 0.04011004227080101, "timer/env.step_avg": 0.010108291057118197, "timer/env.step_min": 0.008411169052124023, "timer/env.step_max": 0.03634047508239746, "timer/replay._sample_count": 31008.0, "timer/replay._sample_total": 16.449533462524414, "timer/replay._sample_frac": 0.01684012062263879, "timer/replay._sample_avg": 0.0005304932102207306, "timer/replay._sample_min": 0.0003421306610107422, "timer/replay._sample_max": 0.024861574172973633, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4743.0, "timer/agent.policy_total": 51.71825122833252, "timer/agent.policy_frac": 0.052946279057776886, "timer/agent.policy_avg": 0.010904122122777254, "timer/agent.policy_min": 0.008814573287963867, "timer/agent.policy_max": 0.1060938835144043, "timer/dataset_train_count": 1938.0, "timer/dataset_train_total": 0.21179628372192383, "timer/dataset_train_frac": 0.0002168252961963621, "timer/dataset_train_avg": 0.00010928600811244779, "timer/dataset_train_min": 8.106231689453125e-05, "timer/dataset_train_max": 0.0005733966827392578, "timer/agent.train_count": 1938.0, "timer/agent.train_total": 866.6614866256714, "timer/agent.train_frac": 0.8872399941932456, "timer/agent.train_avg": 0.44719374954885005, "timer/agent.train_min": 0.43451881408691406, "timer/agent.train_max": 0.7001242637634277, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4751911163330078, "timer/agent.report_frac": 0.0004864743268303107, "timer/agent.report_avg": 0.2375955581665039, "timer/agent.report_min": 0.23019003868103027, "timer/agent.report_max": 0.24500107765197754, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.314018249511719e-05, "timer/dataset_eval_frac": 3.392708200177673e-08, "timer/dataset_eval_avg": 3.314018249511719e-05, "timer/dataset_eval_min": 3.314018249511719e-05, "timer/dataset_eval_max": 3.314018249511719e-05, "fps": 31.743821969442084}
{"step": 33608, "time": 1253.9776871204376, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 33984, "time": 1265.7736430168152, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 34192, "time": 1272.247790813446, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 34680, "time": 1287.0700635910034, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 34680, "time": 1287.0784420967102, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 34680, "time": 1287.0855448246002, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 34680, "time": 1287.0926218032837, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 34800, "time": 1290.9551317691803, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 35816, "time": 1321.9287152290344, "episode/length": 228.0, "episode/score": 0.2874999940395355, "episode/reward_rate": 0.004366812227074236, "episode/intrinsic_return": 0.0}
{"step": 35920, "time": 1325.3305642604828, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 36504, "time": 1342.9838869571686, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 36992, "time": 1358.3225951194763, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 36992, "time": 1358.3311784267426, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 36992, "time": 1358.3389489650726, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 36992, "time": 1358.3466322422028, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 37112, "time": 1361.7973244190216, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 37768, "time": 1382.3817529678345, "episode/length": 243.0, "episode/score": 0.24062499403953552, "episode/reward_rate": 0.004098360655737705, "episode/intrinsic_return": 0.0}
{"step": 38232, "time": 1396.4884147644043, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 38816, "time": 1414.627078294754, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 39304, "time": 1429.3111350536346, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 39304, "time": 1429.3203852176666, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 39304, "time": 1429.3285944461823, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 39304, "time": 1429.3359298706055, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 39424, "time": 1433.2347133159637, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 40040, "time": 1457.8298559188843, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1457.8384914398193, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1457.8453686237335, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1457.8546242713928, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1457.8616168498993, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1457.8687734603882, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1457.8752946853638, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1457.882162809372, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40080, "time": 1459.3286237716675, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 40544, "time": 1473.6403133869171, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 41128, "time": 1491.8140070438385, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 41616, "time": 1507.0306150913239, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 41616, "time": 1507.038838148117, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 41616, "time": 1507.0460000038147, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 41616, "time": 1507.0529835224152, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 41736, "time": 1510.5051691532135, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 42392, "time": 1530.7639844417572, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 42856, "time": 1545.0363426208496, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 43440, "time": 1563.195443868637, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 43928, "time": 1577.821734905243, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 43928, "time": 1577.8299820423126, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 43928, "time": 1577.8374512195587, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 43928, "time": 1577.84481549263, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 44048, "time": 1581.7453286647797, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 44704, "time": 1601.9103915691376, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 45168, "time": 1616.1559433937073, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 45752, "time": 1633.719691991806, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 46240, "time": 1648.9608943462372, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 46240, "time": 1648.9693059921265, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 46240, "time": 1648.9767117500305, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 46240, "time": 1648.9839069843292, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 46360, "time": 1652.4640712738037, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 47016, "time": 1672.5808181762695, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 47480, "time": 1686.8443665504456, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 48064, "time": 1704.7869884967804, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 48552, "time": 1719.5397017002106, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 48552, "time": 1719.5479958057404, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 48552, "time": 1719.555073261261, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 48552, "time": 1719.56405544281, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 48672, "time": 1723.4507076740265, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 49328, "time": 1744.141049861908, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 49792, "time": 1758.3669142723083, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 50024, "time": 1770.9739270210266, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1770.981533050537, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1770.9884221553802, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1770.994789838791, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1771.0009367465973, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1771.007072687149, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1771.013284444809, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1771.0201225280762, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50376, "time": 1781.8092057704926, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 50864, "time": 1797.0875585079193, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 50864, "time": 1797.0963125228882, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 50864, "time": 1797.1042709350586, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 50864, "time": 1797.1120522022247, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 50984, "time": 1800.5565524101257, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 51640, "time": 1820.5324354171753, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 52104, "time": 1834.7847981452942, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 52688, "time": 1852.862296819687, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 53176, "time": 1867.7045347690582, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 53176, "time": 1867.7126615047455, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 53176, "time": 1867.7197875976562, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 53176, "time": 1867.730153799057, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 53296, "time": 1871.610241651535, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 53952, "time": 1891.6164934635162, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 54416, "time": 1905.776951789856, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 55000, "time": 1925.3866233825684, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 55488, "time": 1940.5568828582764, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 55488, "time": 1940.565090894699, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 55488, "time": 1940.5724701881409, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 55488, "time": 1940.579519033432, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 55608, "time": 1944.0209078788757, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 56264, "time": 1964.179809331894, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 56728, "time": 1978.487649679184, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 57312, "time": 1996.5211651325226, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 57320, "time": 1996.5510778427124, "episode/length": 228.0, "episode/score": 0.2874999940395355, "episode/reward_rate": 0.004366812227074236, "episode/intrinsic_return": 0.0}
{"step": 57800, "time": 2011.8139760494232, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 57800, "time": 2011.8219017982483, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 57800, "time": 2011.83070063591, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 57920, "time": 2015.7144048213959, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 58576, "time": 2035.7900326251984, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 59040, "time": 2049.9029800891876, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 59624, "time": 2067.511055469513, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 59632, "time": 2068.0016820430756, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 60008, "time": 2085.5080428123474, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2085.5395092964172, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2085.5786662101746, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2085.609516620636, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2085.621340274811, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2085.6284437179565, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2085.6349301338196, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2085.64545750618, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60112, "time": 2089.073741912842, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 60112, "time": 2089.082484960556, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 60112, "time": 2089.091592311859, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 60232, "time": 2092.5812430381775, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 60888, "time": 2112.6772735118866, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 61024, "time": 2117.058696746826, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 61352, "time": 2127.013306617737, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 61936, "time": 2145.03405046463, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 61944, "time": 2145.0640637874603, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 62240, "time": 2154.2987065315247, "episode/length": 265.0, "episode/score": 0.171875, "episode/reward_rate": 0.0037593984962406013, "episode/intrinsic_return": 0.0}
{"step": 62424, "time": 2159.8448872566223, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 62544, "time": 2163.774843454361, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 63200, "time": 2183.7855076789856, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 63336, "time": 2187.7941591739655, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 63664, "time": 2197.9424815177917, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 64248, "time": 2215.57683467865, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 64256, "time": 2216.048154115677, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 64425, "time": 2221.9294044971466, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.0010614013671875, "train/action_min": 0.0, "train/action_std": 1.9997383117675782, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 8.586017631387222e-05, "train/actor_opt_grad_steps": 2935.0, "train/actor_opt_loss": -2.1265678416145963, "train/adv_mag": 0.00033198051445651797, "train/adv_max": 0.00033198051445651797, "train/adv_mean": 0.0001868246823141817, "train/adv_min": 1.502292463555932e-05, "train/adv_std": 8.710967651495593e-05, "train/cont_avg": 0.996494140625, "train/cont_loss_mean": 0.0233507933083456, "train/cont_loss_std": 0.3234048563473527, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.695518778294933, "train/cont_pos_acc": 0.9999999836087227, "train/cont_pos_loss": 0.003437901960569434, "train/cont_pred": 0.9965682458877564, "train/cont_rate": 0.996494140625, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.08528974052518606, "train/extr_critic_critic_opt_grad_steps": 2935.0, "train/extr_critic_critic_opt_loss": 2891.1315252685545, "train/extr_critic_mag": 0.005405624508857727, "train/extr_critic_max": 0.005405624508857727, "train/extr_critic_mean": 0.0053928028850350525, "train/extr_critic_min": 0.005372801423072815, "train/extr_critic_std": 3.957425726923702e-06, "train/extr_return_normed_mag": 0.0006296384433517232, "train/extr_return_normed_max": 0.0006296384433517232, "train/extr_return_normed_mean": 0.0004996624668274308, "train/extr_return_normed_min": 0.00033313827880192547, "train/extr_return_normed_std": 8.684598733452731e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.00570960461627692, "train/extr_return_raw_max": 0.00570960461627692, "train/extr_return_raw_mean": 0.005579628909472376, "train/extr_return_raw_min": 0.005413104451727122, "train/extr_return_raw_std": 8.684598734362225e-05, "train/extr_reward_mag": 4.579126834869385e-05, "train/extr_reward_max": 4.579126834869385e-05, "train/extr_reward_mean": 4.571743004817108e-05, "train/extr_reward_min": 4.5535564422607424e-05, "train/extr_reward_std": 3.707391098672908e-08, "train/image_loss_mean": 0.2651044692844152, "train/image_loss_std": 0.08692600548267365, "train/model_loss_mean": 0.8900985074043274, "train/model_loss_std": 0.36762933142483234, "train/model_opt_grad_norm": 80.73914759635926, "train/model_opt_grad_steps": 2925.0, "train/model_opt_loss": 50.0192502784729, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 56.25, "train/policy_entropy_mag": 1.945885755419731, "train/policy_entropy_max": 1.945885755419731, "train/policy_entropy_mean": 1.9447527527809143, "train/policy_entropy_min": 1.9269943749904632, "train/policy_entropy_std": 0.0007824646693188697, "train/policy_logprob_mag": 2.2003337597846984, "train/policy_logprob_max": -1.6963057172298432, "train/policy_logprob_mean": -1.9447823774814605, "train/policy_logprob_min": -2.2003337597846984, "train/policy_logprob_std": 0.04785607907921076, "train/policy_randomness_mag": 0.9999875235557556, "train/policy_randomness_max": 0.9999875235557556, "train/policy_randomness_mean": 0.999405271410942, "train/policy_randomness_min": 0.9902792742848396, "train/policy_randomness_std": 0.0004021073129842989, "train/post_ent_mag": 63.74146379470825, "train/post_ent_max": 63.74146379470825, "train/post_ent_mean": 63.51030117034912, "train/post_ent_min": 63.4823341178894, "train/post_ent_std": 0.03778650121763349, "train/prior_ent_mag": 70.98426731109619, "train/prior_ent_max": 70.98426731109619, "train/prior_ent_mean": 70.86060268402099, "train/prior_ent_min": 70.64366939544678, "train/prior_ent_std": 0.04857999219559133, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 4.850769037147984e-05, "train/reward_loss_mean": 0.0016432280419394374, "train/reward_loss_std": 0.04179742418053328, "train/reward_max_data": 0.04967187494039536, "train/reward_max_pred": 4.5815110206604e-05, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00033643187081906946, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 9.91262725547508, "train/reward_pred": 4.5710275880992416e-05, "train/reward_rate": 0.0001318359375, "train_stats/mean_log_entropy": 1.9379665381317839, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.020015863701701164, "report/cont_loss_std": 0.31309401988983154, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.796012878417969, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0030442785937339067, "report/cont_pred": 0.996960461139679, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.2881619930267334, "report/image_loss_std": 0.09172721952199936, "report/model_loss_mean": 0.9179665446281433, "report/model_loss_std": 0.5691420435905457, "report/post_ent_mag": 56.00609588623047, "report/post_ent_max": 56.00609588623047, "report/post_ent_mean": 55.82075119018555, "report/post_ent_min": 55.7999267578125, "report/post_ent_std": 0.028550269082188606, "report/prior_ent_mag": 65.40966796875, "report/prior_ent_max": 65.40966796875, "report/prior_ent_mean": 65.25888061523438, "report/prior_ent_min": 65.18133544921875, "report/prior_ent_std": 0.030329430475831032, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0002838134823832661, "report/reward_loss_mean": 0.009788613766431808, "report/reward_loss_std": 0.30576202273368835, "report/reward_max_data": 0.2906250059604645, "report/reward_max_pred": 4.0650367736816406e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0002288823015987873, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 9.78939437866211, "report/reward_pred": 4.0650367736816406e-05, "report/reward_rate": 0.0009765625, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.0030442785937339067, "eval/cont_loss_std": 2.3283064365386963e-10, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0030442785937339067, "eval/cont_pred": 0.996960461139679, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.31885969638824463, "eval/image_loss_std": 0.0984589084982872, "eval/model_loss_mean": 0.9221329689025879, "eval/model_loss_std": 0.09845889359712601, "eval/post_ent_mag": 56.00685119628906, "eval/post_ent_max": 56.00685119628906, "eval/post_ent_mean": 55.820037841796875, "eval/post_ent_min": 55.801151275634766, "eval/post_ent_std": 0.026264898478984833, "eval/prior_ent_mag": 65.42377471923828, "eval/prior_ent_max": 65.42377471923828, "eval/prior_ent_mean": 65.26039123535156, "eval/prior_ent_min": 65.20835876464844, "eval/prior_ent_std": 0.03231058269739151, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00022888323292136192, "eval/reward_loss_std": 2.5771733191959356e-08, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 4.0650367736816406e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00022888323292136192, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 4.0650367736816406e-05, "eval/reward_rate": 0.0, "replay/size": 63921.0, "replay/inserts": 31856.0, "replay/samples": 31856.0, "replay/insert_wait_avg": 1.3643730710583797e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.32429308199152e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 17240.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.224370151242583e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.387731552124023e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0921487808228, "timer/env.step_count": 3982.0, "timer/env.step_total": 40.033223152160645, "timer/env.step_frac": 0.040029534479361466, "timer/env.step_avg": 0.010053546748407997, "timer/env.step_min": 0.008308649063110352, "timer/env.step_max": 0.05071449279785156, "timer/replay._sample_count": 31856.0, "timer/replay._sample_total": 17.182575702667236, "timer/replay._sample_frac": 0.01718099249515548, "timer/replay._sample_avg": 0.0005393827129164752, "timer/replay._sample_min": 0.0003559589385986328, "timer/replay._sample_max": 0.011698484420776367, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4849.0, "timer/agent.policy_total": 52.64576816558838, "timer/agent.policy_frac": 0.05264091736923141, "timer/agent.policy_avg": 0.01085703612406442, "timer/agent.policy_min": 0.009128093719482422, "timer/agent.policy_max": 0.08866381645202637, "timer/dataset_train_count": 1991.0, "timer/dataset_train_total": 0.2143998146057129, "timer/dataset_train_frac": 0.00021438005974457473, "timer/dataset_train_avg": 0.0001076844874965911, "timer/dataset_train_min": 9.298324584960938e-05, "timer/dataset_train_max": 0.0010678768157958984, "timer/agent.train_count": 1991.0, "timer/agent.train_total": 890.6102023124695, "timer/agent.train_frac": 0.8905281412299668, "timer/agent.train_avg": 0.4473180323015919, "timer/agent.train_min": 0.4355502128601074, "timer/agent.train_max": 0.865619421005249, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4755527973175049, "timer/agent.report_frac": 0.0004755089797447511, "timer/agent.report_avg": 0.23777639865875244, "timer/agent.report_min": 0.23063373565673828, "timer/agent.report_max": 0.2449190616607666, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0040740966796875e-05, "timer/dataset_eval_frac": 3.003797300420615e-08, "timer/dataset_eval_avg": 3.0040740966796875e-05, "timer/dataset_eval_min": 3.0040740966796875e-05, "timer/dataset_eval_max": 3.0040740966796875e-05, "fps": 31.852569983539876}
{"step": 64552, "time": 2225.6299979686737, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 64736, "time": 2231.4435057640076, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 64856, "time": 2234.8884439468384, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 65512, "time": 2254.9712092876434, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 65648, "time": 2259.8766646385193, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 65976, "time": 2269.638389110565, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 66560, "time": 2287.7515122890472, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 66568, "time": 2287.780728340149, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 66864, "time": 2296.995733499527, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 67048, "time": 2302.3631253242493, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 67168, "time": 2306.353741645813, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 67824, "time": 2326.2381703853607, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 67960, "time": 2330.1707932949066, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 68288, "time": 2340.452958583832, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 68304, "time": 2340.9439630508423, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 68872, "time": 2357.926427602768, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 68880, "time": 2358.4022195339203, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 69192, "time": 2367.8531506061554, "episode/length": 252.0, "episode/score": 0.21250000596046448, "episode/reward_rate": 0.003952569169960474, "episode/intrinsic_return": 0.0}
{"step": 69360, "time": 2373.2268822193146, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 70096, "time": 2401.81729388237, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2401.825278520584, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2401.832247018814, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2401.83899474144, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2401.845509290695, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2401.8522641658783, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2401.859544992447, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2401.866754770279, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70136, "time": 2402.8657264709473, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 70272, "time": 2407.23748421669, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 70600, "time": 2416.950268507004, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 70616, "time": 2417.440333843231, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 71184, "time": 2435.126593351364, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 71192, "time": 2435.1587402820587, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 71200, "time": 2435.6285316944122, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 71504, "time": 2444.9157395362854, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 71672, "time": 2449.81551194191, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 72448, "time": 2473.714205265045, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 72912, "time": 2487.865693807602, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 72928, "time": 2488.358951807022, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 73496, "time": 2505.2836327552795, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 73504, "time": 2505.754442691803, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 73512, "time": 2505.7836468219757, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 73816, "time": 2515.531185388565, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 73984, "time": 2520.896454334259, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 74760, "time": 2544.2630627155304, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 75224, "time": 2558.4866886138916, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 75240, "time": 2558.981518268585, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 75808, "time": 2576.559844970703, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 75816, "time": 2576.5902483463287, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 75824, "time": 2577.0616459846497, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 76128, "time": 2586.337028980255, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 76296, "time": 2591.2242963314056, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 77072, "time": 2615.2217910289764, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 77536, "time": 2629.312769651413, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 77552, "time": 2629.8247904777527, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 78120, "time": 2646.9449877738953, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 78128, "time": 2647.4127333164215, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 78136, "time": 2647.4424493312836, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 78440, "time": 2656.643310070038, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 78608, "time": 2661.9627647399902, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 79384, "time": 2685.4819350242615, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 79848, "time": 2699.7492661476135, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 79864, "time": 2700.242851257324, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 80080, "time": 2712.938980817795, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2712.9466087818146, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2712.9532248973846, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2712.959630012512, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2712.965977668762, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2712.9721252918243, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2712.9783794879913, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2712.9846818447113, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80432, "time": 2723.703229188919, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 80440, "time": 2723.733809232712, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 80448, "time": 2724.202381372452, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 80752, "time": 2733.56636095047, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 80920, "time": 2738.4589869976044, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 81696, "time": 2762.4241123199463, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 82160, "time": 2776.9503123760223, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 82176, "time": 2777.43701171875, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 82744, "time": 2794.5127370357513, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 82752, "time": 2794.981103181839, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 82760, "time": 2795.0102972984314, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 82800, "time": 2796.44362783432, "episode/length": 234.0, "episode/score": 0.26875001192092896, "episode/reward_rate": 0.00425531914893617, "episode/intrinsic_return": 0.0}
{"step": 82872, "time": 2798.408803462982, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 83064, "time": 2804.2200388908386, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 83136, "time": 2806.611236810684, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 84008, "time": 2832.8438193798065, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 84472, "time": 2846.9783318042755, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 85064, "time": 2865.4970848560333, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 85072, "time": 2865.993700027466, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 85112, "time": 2866.9978914260864, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 85184, "time": 2869.398466348648, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 85376, "time": 2875.3818185329437, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 85448, "time": 2877.3580420017242, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 86320, "time": 2903.8982632160187, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 86784, "time": 2918.0183568000793, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 87376, "time": 2936.015852212906, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 87384, "time": 2936.047719478607, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 87424, "time": 2937.4884445667267, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 87496, "time": 2939.47039103508, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 87688, "time": 2945.2740337848663, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 87760, "time": 2947.666378259659, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 88632, "time": 2973.847902536392, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 89096, "time": 2987.9131004810333, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 89688, "time": 3005.9401304721832, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 89696, "time": 3006.4105594158173, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 89736, "time": 3007.419293165207, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 89808, "time": 3009.8223371505737, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 90000, "time": 3015.674023628235, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 90064, "time": 3019.241634607315, "eval_episode/length": 81.0, "eval_episode/score": 0.746874988079071, "eval_episode/reward_rate": 0.012195121951219513}
{"step": 90064, "time": 3020.8590178489685, "eval_episode/length": 166.0, "eval_episode/score": 0.48124998807907104, "eval_episode/reward_rate": 0.005988023952095809}
{"step": 90064, "time": 3022.925566673279, "eval_episode/length": 274.0, "eval_episode/score": 0.14374999701976776, "eval_episode/reward_rate": 0.0036363636363636364}
{"step": 90064, "time": 3023.8187510967255, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3023.827677488327, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3023.8347251415253, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3023.8408291339874, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3023.846883058548, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90072, "time": 3023.8752319812775, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 90944, "time": 3050.924183368683, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 91408, "time": 3064.96835398674, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 92000, "time": 3082.8479697704315, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 92008, "time": 3082.9058108329773, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 92048, "time": 3084.327041864395, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 92120, "time": 3086.405124425888, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 92312, "time": 3092.178569316864, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 92384, "time": 3094.5624799728394, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 93256, "time": 3120.805826187134, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 93720, "time": 3134.8461022377014, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 94312, "time": 3153.2564420700073, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 94320, "time": 3153.720892906189, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 94360, "time": 3154.7242755889893, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 94432, "time": 3157.104052066803, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 94624, "time": 3162.8566856384277, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 94696, "time": 3164.8163933753967, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 95568, "time": 3191.398977994919, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 96008, "time": 3204.39976978302, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 96032, "time": 3205.4495697021484, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 96569, "time": 3222.3648812770844, "train_stats/mean_log_entropy": 1.9377235691104315, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.998681945800781, "train/action_min": 0.0, "train/action_std": 2.000485023856163, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 6.365406217128111e-05, "train/actor_opt_grad_steps": 4935.0, "train/actor_opt_loss": -2.982947049532086, "train/adv_mag": 0.0002784552099183202, "train/adv_max": 0.0002781222201883793, "train/adv_mean": 0.00014198226786447777, "train/adv_min": -1.0553081519901752e-05, "train/adv_std": 6.796336675733983e-05, "train/cont_avg": 0.9964892578125, "train/cont_loss_mean": 0.023446375102503227, "train/cont_loss_std": 0.31901084494457566, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.674346677958965, "train/cont_pos_acc": 0.9999999839067459, "train/cont_pos_loss": 0.003512522135861218, "train/cont_pred": 0.9964938345551491, "train/cont_rate": 0.9964892578125, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.023198266890831293, "train/extr_critic_critic_opt_grad_steps": 4935.0, "train/extr_critic_critic_opt_loss": 4879.091221923828, "train/extr_critic_mag": 0.010914042592048645, "train/extr_critic_max": 0.010914042592048645, "train/extr_critic_mean": 0.010889368024654686, "train/extr_critic_min": 0.010853009819984437, "train/extr_critic_std": 7.943885684937868e-06, "train/extr_return_normed_mag": 0.0005054518720135092, "train/extr_return_normed_max": 0.0005054518720135092, "train/extr_return_normed_mean": 0.0003992039991862839, "train/extr_return_normed_min": 0.0002616685861721635, "train/extr_return_normed_std": 6.691307642768151e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.011137597244232893, "train/extr_return_raw_max": 0.011137597244232893, "train/extr_return_raw_mean": 0.011031349874101579, "train/extr_return_raw_min": 0.010893813958391547, "train/extr_return_raw_std": 6.691307640039667e-05, "train/extr_reward_mag": 5.519747734069824e-05, "train/extr_reward_max": 5.519747734069824e-05, "train/extr_reward_mean": 5.5139967362265455e-05, "train/extr_reward_min": 5.505084991455078e-05, "train/extr_reward_std": 2.2835575032575938e-08, "train/image_loss_mean": 0.25605396963655946, "train/image_loss_std": 0.0855450788885355, "train/model_loss_mean": 0.8810251492261887, "train/model_loss_std": 0.363128347247839, "train/model_opt_grad_norm": 63.66619626045227, "train/model_opt_grad_steps": 4925.0, "train/model_opt_loss": 198.0507060623169, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 225.0, "train/policy_entropy_mag": 1.9458953523635865, "train/policy_entropy_max": 1.9458953523635865, "train/policy_entropy_mean": 1.945211426615715, "train/policy_entropy_min": 1.9348229295015336, "train/policy_entropy_std": 0.0004750653855444398, "train/policy_logprob_mag": 2.145289282798767, "train/policy_logprob_max": -1.7520051968097687, "train/policy_logprob_mean": -1.9452260494232179, "train/policy_logprob_min": -2.145289282798767, "train/policy_logprob_std": 0.03732675146311522, "train/policy_randomness_mag": 0.999992454946041, "train/policy_randomness_max": 0.999992454946041, "train/policy_randomness_mean": 0.9996409866213799, "train/policy_randomness_min": 0.9943023538589477, "train/policy_randomness_std": 0.00024413533392362297, "train/post_ent_mag": 51.025704307556154, "train/post_ent_max": 51.025704307556154, "train/post_ent_mean": 50.92498847961426, "train/post_ent_min": 50.895746517181394, "train/post_ent_std": 0.016661392957903445, "train/prior_ent_mag": 60.1485590171814, "train/prior_ent_max": 60.1485590171814, "train/prior_ent_mean": 60.025768699645994, "train/prior_ent_min": 59.97355890274048, "train/prior_ent_std": 0.02867289968766272, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 5.003356942324899e-05, "train/reward_loss_mean": 0.0015247817034833133, "train/reward_loss_std": 0.04085690104075515, "train/reward_max_data": 0.05003125011920929, "train/reward_max_pred": 5.5279731750488285e-05, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00021895299658353907, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 9.904251722189096, "train/reward_pred": 5.5174086592160163e-05, "train/reward_rate": 0.0001318359375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.014718379825353622, "report/cont_loss_std": 0.24507251381874084, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.554657936096191, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0038770141545683146, "report/cont_pred": 0.9961305856704712, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.24358318746089935, "report/image_loss_std": 0.08485541492700577, "report/model_loss_mean": 0.8585113286972046, "report/model_loss_std": 0.25948989391326904, "report/post_ent_mag": 46.88972854614258, "report/post_ent_max": 46.88972854614258, "report/post_ent_mean": 46.869686126708984, "report/post_ent_min": 46.80345916748047, "report/post_ent_std": 0.013392840512096882, "report/prior_ent_mag": 57.14640808105469, "report/prior_ent_max": 57.14640808105469, "report/prior_ent_mean": 57.02440643310547, "report/prior_ent_min": 56.977333068847656, "report/prior_ent_std": 0.025624049827456474, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.00020971614867448807, "report/reward_loss_std": 3.0382108207049896e-07, "report/reward_max_data": 0.0, "report/reward_max_pred": 7.271766662597656e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00020971614867448807, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 7.25021818652749e-05, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.003877132199704647, "eval/cont_loss_std": 1.878182047221344e-06, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.003877132199704647, "eval/cont_pred": 0.9961304664611816, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.266910582780838, "eval/image_loss_std": 0.0845082551240921, "eval/model_loss_mean": 0.870997428894043, "eval/model_loss_std": 0.08450828492641449, "eval/post_ent_mag": 46.88793182373047, "eval/post_ent_max": 46.88793182373047, "eval/post_ent_mean": 46.870025634765625, "eval/post_ent_min": 46.805641174316406, "eval/post_ent_std": 0.012054703198373318, "eval/prior_ent_mag": 57.1391487121582, "eval/prior_ent_max": 57.1391487121582, "eval/prior_ent_mean": 57.02531433105469, "eval/prior_ent_min": 56.97643280029297, "eval/prior_ent_std": 0.027099331840872765, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00020971335470676422, "eval/reward_loss_std": 2.962894143365702e-07, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 7.271766662597656e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00020971335470676422, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 7.250020280480385e-05, "eval/reward_rate": 0.0, "replay/size": 96065.0, "replay/inserts": 32144.0, "replay/samples": 32144.0, "replay/insert_wait_avg": 1.3299045306405599e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.395383938323686e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 24176.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2530381291795355e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1473894119262695e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4077200889587, "timer/env.step_count": 4018.0, "timer/env.step_total": 39.87590026855469, "timer/env.step_frac": 0.039859648689045325, "timer/env.step_avg": 0.009924315646728394, "timer/env.step_min": 0.008046150207519531, "timer/env.step_max": 0.06886076927185059, "timer/replay._sample_count": 32144.0, "timer/replay._sample_total": 16.80103063583374, "timer/replay._sample_frac": 0.01679418330992063, "timer/replay._sample_avg": 0.0005226801467096111, "timer/replay._sample_min": 0.00037670135498046875, "timer/replay._sample_max": 0.011179447174072266, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4885.0, "timer/agent.policy_total": 51.869070053100586, "timer/agent.policy_frac": 0.05184793061021986, "timer/agent.policy_avg": 0.010618028670030826, "timer/agent.policy_min": 0.008748531341552734, "timer/agent.policy_max": 0.08762311935424805, "timer/dataset_train_count": 2009.0, "timer/dataset_train_total": 0.2156054973602295, "timer/dataset_train_frac": 0.000215517626494383, "timer/dataset_train_avg": 0.00010731980953719736, "timer/dataset_train_min": 9.322166442871094e-05, "timer/dataset_train_max": 0.0003960132598876953, "timer/agent.train_count": 2009.0, "timer/agent.train_total": 893.341347694397, "timer/agent.train_frac": 0.892977262925319, "timer/agent.train_avg": 0.4446696603755087, "timer/agent.train_min": 0.432628870010376, "timer/agent.train_max": 0.9513781070709229, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47675037384033203, "timer/agent.report_frac": 0.0004765560723561172, "timer/agent.report_avg": 0.23837518692016602, "timer/agent.report_min": 0.22929096221923828, "timer/agent.report_max": 0.24745941162109375, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 0.0003306865692138672, "timer/dataset_eval_frac": 3.3055179660594954e-07, "timer/dataset_eval_avg": 0.0003306865692138672, "timer/dataset_eval_min": 0.0003306865692138672, "timer/dataset_eval_max": 0.0003306865692138672, "fps": 32.130218200237465}
{"step": 96624, "time": 3224.070949792862, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 96632, "time": 3224.1008405685425, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 96672, "time": 3225.52743268013, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 96744, "time": 3227.4689066410065, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 96936, "time": 3233.254134654999, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 97008, "time": 3235.801882982254, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 98280, "time": 3274.0173914432526, "episode/length": 280.0, "episode/score": 0.125, "episode/reward_rate": 0.0035587188612099642, "episode/intrinsic_return": 0.0}
{"step": 98320, "time": 3275.9302790164948, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 98936, "time": 3294.2992017269135, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 98944, "time": 3294.7713956832886, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 98984, "time": 3295.871903896332, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 99056, "time": 3298.317414045334, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 99248, "time": 3304.149566888809, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 99320, "time": 3306.113543987274, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 100048, "time": 3333.6668486595154, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3333.6764810085297, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3333.684102296829, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3333.693221092224, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3333.6999146938324, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3333.705820083618, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3333.713708639145, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3333.7205526828766, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100592, "time": 3350.115923166275, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 100632, "time": 3351.103533267975, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 101248, "time": 3369.984867334366, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 101256, "time": 3370.014291524887, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 101296, "time": 3371.443503856659, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 101368, "time": 3373.3930015563965, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 101560, "time": 3379.212736606598, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 101632, "time": 3381.601419210434, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 102904, "time": 3419.921881914139, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 102944, "time": 3421.351683139801, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 103560, "time": 3439.7103793621063, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 103568, "time": 3440.1788988113403, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 103608, "time": 3441.1648631095886, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 103680, "time": 3443.5719509124756, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 103872, "time": 3449.4491999149323, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 103944, "time": 3451.3976068496704, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 105216, "time": 3490.0617887973785, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 105256, "time": 3491.0732712745667, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 105416, "time": 3495.9026741981506, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 105872, "time": 3509.9427902698517, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 105880, "time": 3509.972907781601, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 105920, "time": 3511.3961374759674, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 105992, "time": 3513.337366104126, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 106256, "time": 3521.5081906318665, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 107528, "time": 3560.3113243579865, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 107568, "time": 3561.736058950424, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 107728, "time": 3566.760656118393, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 108184, "time": 3580.2842094898224, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 108192, "time": 3580.753680706024, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 108232, "time": 3581.7430427074432, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 108304, "time": 3584.158453941345, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 108568, "time": 3591.909547328949, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 109840, "time": 3630.745493888855, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 109880, "time": 3631.7534472942352, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 110032, "time": 3640.876761674881, "eval_episode/length": 244.0, "eval_episode/score": 0.23749999701976776, "eval_episode/reward_rate": 0.004081632653061225}
{"step": 110032, "time": 3641.6679089069366, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3641.675001859665, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3641.6812076568604, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3641.687526702881, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3641.6972844600677, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3641.711087703705, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3641.719648838043, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110040, "time": 3641.7477123737335, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 110496, "time": 3655.80247092247, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 110504, "time": 3655.831912755966, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 110544, "time": 3657.282886981964, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 110616, "time": 3659.228678703308, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 110880, "time": 3667.415214776993, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 112152, "time": 3705.5775368213654, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 112192, "time": 3707.006922006607, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 112352, "time": 3711.8185036182404, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 112808, "time": 3725.4540894031525, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 112816, "time": 3725.9255816936493, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 112856, "time": 3726.9116954803467, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 112928, "time": 3729.3185427188873, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 113192, "time": 3737.075204372406, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 114464, "time": 3775.806714773178, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 114504, "time": 3776.819097518921, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 114664, "time": 3781.70183467865, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 115120, "time": 3796.294143676758, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 115128, "time": 3796.3236150741577, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 115168, "time": 3797.7716069221497, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 115240, "time": 3799.7173902988434, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 115504, "time": 3807.9716329574585, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 116776, "time": 3846.0812232494354, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 116816, "time": 3847.504949569702, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 116976, "time": 3852.3324694633484, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 117432, "time": 3866.008658885956, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 117440, "time": 3866.4760115146637, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 117480, "time": 3867.465268135071, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 117552, "time": 3869.869587659836, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 117816, "time": 3877.6136951446533, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 119088, "time": 3916.252874135971, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 119128, "time": 3917.2398545742035, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 119288, "time": 3922.06272149086, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 119744, "time": 3936.097773551941, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 119752, "time": 3936.1295957565308, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 119792, "time": 3937.5960109233856, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 119864, "time": 3939.5741810798645, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 120016, "time": 3949.558286190033, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 3949.572257041931, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 3949.597372531891, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 3949.6077194213867, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 3949.614465713501, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 3949.6211626529694, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 3949.637660741806, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 3949.6649112701416, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120128, "time": 3953.0511577129364, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 121400, "time": 3991.4116735458374, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 121440, "time": 3992.894295692444, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 121600, "time": 3997.717128753662, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 122056, "time": 4011.2964055538177, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 122064, "time": 4011.764746427536, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 122104, "time": 4012.755217552185, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 122176, "time": 4015.2857546806335, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 122440, "time": 4023.024395942688, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 123712, "time": 4062.2743570804596, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 123752, "time": 4063.2870275974274, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 123912, "time": 4068.2097034454346, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 124368, "time": 4082.3148226737976, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 124376, "time": 4082.3443002700806, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 124416, "time": 4083.765768289566, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 124488, "time": 4085.7428035736084, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 124752, "time": 4093.9312674999237, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 126024, "time": 4132.042449712753, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 126064, "time": 4133.484401226044, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 126224, "time": 4138.400313615799, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 126680, "time": 4151.877830505371, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 126688, "time": 4152.341792583466, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 126728, "time": 4153.323545694351, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 126800, "time": 4155.703036546707, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 127064, "time": 4163.4295489788055, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 127248, "time": 4169.255428314209, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 128336, "time": 4201.960693120956, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 128376, "time": 4202.949445724487, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 128992, "time": 4221.7203941345215, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 129000, "time": 4221.763016939163, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 129001, "time": 4222.767181396484, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.000758579799107, "train/action_min": 0.0, "train/action_std": 1.9993149829028276, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 4.0627646603528495e-05, "train/actor_opt_grad_steps": 6950.0, "train/actor_opt_loss": -4.854398560678137, "train/adv_mag": 0.00019592357790235228, "train/adv_max": 0.00015793148464904043, "train/adv_mean": 4.408262948510719e-05, "train/adv_min": -7.086583032396626e-05, "train/adv_std": 4.547503252869601e-05, "train/cont_avg": 0.9967335668103449, "train/cont_loss_mean": 0.022008973101539344, "train/cont_loss_std": 0.3107314990739352, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.665510465152299, "train/cont_pos_acc": 0.9999999838509583, "train/cont_pos_loss": 0.0035048357986390884, "train/cont_pred": 0.9965014398978849, "train/cont_rate": 0.9967335668103449, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.011533351759586868, "train/extr_critic_critic_opt_grad_steps": 6950.0, "train/extr_critic_critic_opt_loss": 6162.396311191503, "train/extr_critic_mag": 0.015224559553738299, "train/extr_critic_max": 0.015224559553738299, "train/extr_critic_mean": 0.015189829025546024, "train/extr_critic_min": 0.015148727177399133, "train/extr_critic_std": 1.1056550788329817e-05, "train/extr_return_normed_mag": 0.0002900991460372662, "train/extr_return_normed_max": 0.00024062707065948712, "train/extr_return_normed_mean": 0.00015932590911320806, "train/extr_return_normed_min": 7.036565963564248e-05, "train/extr_return_normed_std": 4.260389604473634e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.015315203743945495, "train/extr_return_raw_max": 0.015315203743945495, "train/extr_return_raw_mean": 0.015233903329617578, "train/extr_return_raw_min": 0.01514494233292165, "train/extr_return_raw_std": 4.260389594393027e-05, "train/extr_reward_mag": 5.263941628592355e-05, "train/extr_reward_max": 5.263941628592355e-05, "train/extr_reward_mean": 5.259534241461018e-05, "train/extr_reward_min": 5.2527841088807055e-05, "train/extr_reward_std": 1.5029457637923735e-08, "train/image_loss_mean": 0.2515751211514027, "train/image_loss_std": 0.08554895464422668, "train/model_loss_mean": 0.8753409864280024, "train/model_loss_std": 0.35963504489859927, "train/model_opt_grad_norm": 54.85246191353634, "train/model_opt_grad_steps": 6940.0, "train/model_opt_loss": 792.2305559430804, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 905.1724137931035, "train/policy_entropy_mag": 1.9458991183435976, "train/policy_entropy_max": 1.9458991183435976, "train/policy_entropy_mean": 1.945383179363946, "train/policy_entropy_min": 1.9382407230696654, "train/policy_entropy_std": 0.0003555922251736075, "train/policy_logprob_mag": 2.112195665613184, "train/policy_logprob_max": -1.7815968138831002, "train/policy_logprob_mean": -1.9453625866932234, "train/policy_logprob_min": -2.112195665613184, "train/policy_logprob_std": 0.032450002329102876, "train/policy_randomness_mag": 0.9999943921718691, "train/policy_randomness_max": 0.9999943921718691, "train/policy_randomness_mean": 0.999729252213915, "train/policy_randomness_min": 0.9960587509159972, "train/policy_randomness_std": 0.00018273825926953935, "train/post_ent_mag": 46.15710520626876, "train/post_ent_max": 46.15710520626876, "train/post_ent_mean": 46.13234770826518, "train/post_ent_min": 46.01625540221266, "train/post_ent_std": 0.02708559456680502, "train/prior_ent_mag": 55.34646897715301, "train/prior_ent_max": 55.34646897715301, "train/prior_ent_mean": 55.27983681439179, "train/prior_ent_min": 55.18070775299824, "train/prior_ent_std": 0.018707856223941437, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 6.975446471582016e-05, "train/reward_loss_mean": 0.0017568713347679875, "train/reward_loss_std": 0.048246458231064014, "train/reward_max_data": 0.06567118291197152, "train/reward_max_pred": 5.2761561764872134e-05, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00016225504776660188, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 10.03111907641093, "train/reward_pred": 5.2700156983667114e-05, "train/reward_rate": 0.000158751539408867, "train_stats/mean_log_entropy": 1.9386189201603765, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.020182937383651733, "report/cont_loss_std": 0.2976820766925812, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.51185941696167, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.004046768415719271, "report/cont_pred": 0.9959612488746643, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.22471196949481964, "report/image_loss_std": 0.08240828663110733, "report/model_loss_mean": 0.8450723886489868, "report/model_loss_std": 0.30748870968818665, "report/post_ent_mag": 48.034175872802734, "report/post_ent_max": 48.034175872802734, "report/post_ent_mean": 47.99892807006836, "report/post_ent_min": 47.743995666503906, "report/post_ent_std": 0.05764690041542053, "report/prior_ent_mag": 55.35350799560547, "report/prior_ent_max": 55.35350799560547, "report/prior_ent_mean": 55.309165954589844, "report/prior_ent_min": 55.2071647644043, "report/prior_ent_std": 0.019285617396235466, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.0001773834228515625, "report/reward_loss_std": 0.0, "report/reward_max_data": 0.0, "report/reward_max_pred": 6.306171417236328e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0001773834228515625, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 6.306171417236328e-05, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.004046768415719271, "eval/cont_loss_std": 0.0, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.004046768415719271, "eval/cont_pred": 0.9959612488746643, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2623765468597412, "eval/image_loss_std": 0.08587060123682022, "eval/model_loss_mean": 0.866600751876831, "eval/model_loss_std": 0.08587060868740082, "eval/post_ent_mag": 48.03664779663086, "eval/post_ent_max": 48.03664779663086, "eval/post_ent_mean": 48.00276565551758, "eval/post_ent_min": 47.74391555786133, "eval/post_ent_std": 0.053964097052812576, "eval/prior_ent_mag": 55.36381912231445, "eval/prior_ent_max": 55.36381912231445, "eval/prior_ent_mean": 55.313194274902344, "eval/prior_ent_min": 55.19588851928711, "eval/prior_ent_std": 0.018229547888040543, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0001773834228515625, "eval/reward_loss_std": 0.0, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 6.306171417236328e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0001773834228515625, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 6.306171417236328e-05, "eval/reward_rate": 0.0, "replay/size": 128497.0, "replay/inserts": 32432.0, "replay/samples": 32432.0, "replay/insert_wait_avg": 1.326298913640463e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.335831109090691e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 31112.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1511533730582795e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.685754776000977e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3937640190125, "timer/env.step_count": 4054.0, "timer/env.step_total": 39.12301254272461, "timer/env.step_frac": 0.03910761337170938, "timer/env.step_avg": 0.009650471766828962, "timer/env.step_min": 0.00780177116394043, "timer/env.step_max": 0.041690826416015625, "timer/replay._sample_count": 32432.0, "timer/replay._sample_total": 16.418458938598633, "timer/replay._sample_frac": 0.01641199648490272, "timer/replay._sample_avg": 0.0005062425671743536, "timer/replay._sample_min": 0.00036454200744628906, "timer/replay._sample_max": 0.026329517364501953, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4921.0, "timer/agent.policy_total": 50.443623781204224, "timer/agent.policy_frac": 0.0504237687153811, "timer/agent.policy_avg": 0.010250685588539773, "timer/agent.policy_min": 0.008730173110961914, "timer/agent.policy_max": 0.0805048942565918, "timer/dataset_train_count": 2027.0, "timer/dataset_train_total": 0.20530986785888672, "timer/dataset_train_frac": 0.0002052290560409619, "timer/dataset_train_avg": 0.00010128755197774382, "timer/dataset_train_min": 8.916854858398438e-05, "timer/dataset_train_max": 0.00021028518676757812, "timer/agent.train_count": 2027.0, "timer/agent.train_total": 897.5164220333099, "timer/agent.train_frac": 0.8971631514650792, "timer/agent.train_avg": 0.44278067194539217, "timer/agent.train_min": 0.43220067024230957, "timer/agent.train_max": 0.6652123928070068, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4762747287750244, "timer/agent.report_frac": 0.00047608726274104684, "timer/agent.report_avg": 0.2381373643875122, "timer/agent.report_min": 0.23080801963806152, "timer/agent.report_max": 0.2454667091369629, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.1948089599609375e-05, "timer/dataset_eval_frac": 3.1935514543053674e-08, "timer/dataset_eval_avg": 3.1948089599609375e-05, "timer/dataset_eval_min": 3.1948089599609375e-05, "timer/dataset_eval_max": 3.1948089599609375e-05, "fps": 32.41868852493741}
{"step": 129040, "time": 4223.937670469284, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 129112, "time": 4226.02952504158, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 129376, "time": 4234.183280944824, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 129560, "time": 4239.5260672569275, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 130000, "time": 4258.987886667252, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4258.995482683182, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4259.0021278858185, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4259.008561849594, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4259.014864206314, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4259.021192073822, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4259.027564525604, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4259.03399014473, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130648, "time": 4278.259401082993, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 130688, "time": 4279.697717189789, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 131304, "time": 4298.54341340065, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 131312, "time": 4299.033668518066, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 131352, "time": 4300.020446538925, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 131424, "time": 4302.397381544113, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 131688, "time": 4310.160794496536, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 131872, "time": 4316.009989023209, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 132960, "time": 4348.780519247055, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 133000, "time": 4349.767272472382, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 133616, "time": 4368.558806180954, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 133624, "time": 4368.588541030884, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 133664, "time": 4370.014880180359, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 133736, "time": 4371.970893621445, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 134000, "time": 4380.178812980652, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 134184, "time": 4385.499334096909, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 135272, "time": 4418.3221826553345, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 135312, "time": 4419.768666267395, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 135928, "time": 4438.253408908844, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 135936, "time": 4438.7208688259125, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 135976, "time": 4439.726139545441, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 136048, "time": 4442.112622022629, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 136312, "time": 4449.845509052277, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 136496, "time": 4458.72651219368, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 137584, "time": 4491.6750910282135, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 137624, "time": 4492.664668560028, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 138240, "time": 4511.610074520111, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 138248, "time": 4511.640146493912, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 138288, "time": 4513.071320056915, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 138360, "time": 4515.041544437408, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 138624, "time": 4523.208555936813, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 138808, "time": 4528.706293582916, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 139872, "time": 4562.339729070663, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 139896, "time": 4562.849228382111, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 139936, "time": 4564.284735918045, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 140088, "time": 4573.942344665527, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4573.950080871582, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4573.957624197006, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4573.964368104935, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4573.971041202545, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4573.977467298508, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4573.984035015106, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4573.991035699844, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140224, "time": 4578.322276592255, "episode/length": 247.0, "episode/score": 0.22812500596046448, "episode/reward_rate": 0.004032258064516129, "episode/intrinsic_return": 0.0}
{"step": 140560, "time": 4588.559943437576, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 140600, "time": 4589.576077699661, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 140672, "time": 4591.961728096008, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 140936, "time": 4599.712641954422, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 142184, "time": 4637.435183048248, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 142208, "time": 4638.407684087753, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 142248, "time": 4639.399202108383, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 142536, "time": 4648.216561794281, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 142872, "time": 4658.327675819397, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 142912, "time": 4659.75274181366, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 142984, "time": 4661.6998126506805, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 143248, "time": 4669.9034512043, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 144472, "time": 4706.81046628952, "episode/length": 285.0, "episode/score": 0.109375, "episode/reward_rate": 0.0034965034965034965, "episode/intrinsic_return": 0.0}
{"step": 144520, "time": 4708.254809856415, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 144560, "time": 4709.678589820862, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 144848, "time": 4718.3483810424805, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 145184, "time": 4728.495529651642, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 145224, "time": 4729.479247331619, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 145296, "time": 4731.876297712326, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 145560, "time": 4739.680947780609, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 145680, "time": 4743.4905779361725, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 146832, "time": 4778.30190205574, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 146872, "time": 4779.293353557587, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 147160, "time": 4787.998893737793, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 147496, "time": 4798.704747915268, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 147536, "time": 4800.1321811676025, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 147608, "time": 4802.083013057709, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 147872, "time": 4810.265264749527, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 147992, "time": 4813.674766302109, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 148880, "time": 4840.715429782867, "episode/length": 250.0, "episode/score": 0.21875, "episode/reward_rate": 0.00398406374501992, "episode/intrinsic_return": 0.0}
{"step": 149144, "time": 4848.451891899109, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 149472, "time": 4858.684028148651, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 149808, "time": 4868.807047843933, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 149848, "time": 4869.799249410629, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 149920, "time": 4872.200000524521, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 150072, "time": 4879.015696048737, "eval_episode/length": 135.0, "eval_episode/score": 0.578125, "eval_episode/reward_rate": 0.007352941176470588}
{"step": 150072, "time": 4881.703057765961, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 4881.710412502289, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 4881.717533111572, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 4881.723824262619, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 4881.729983091354, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 4881.735938072205, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 4881.74259185791, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150184, "time": 4885.203664064407, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 150304, "time": 4889.049288034439, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 151192, "time": 4915.630778551102, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 151456, "time": 4923.797186136246, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 151784, "time": 4933.571768522263, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 152120, "time": 4943.749395370483, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 152160, "time": 4945.29571723938, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 152232, "time": 4947.244268894196, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 152496, "time": 4955.420939922333, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 152616, "time": 4958.80899810791, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 153504, "time": 4985.904852628708, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 153768, "time": 4993.666469812393, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 154096, "time": 5003.767329692841, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 154432, "time": 5013.985101699829, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 154472, "time": 5014.974040746689, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 154544, "time": 5017.363713502884, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 154808, "time": 5025.088408946991, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 154928, "time": 5028.929313182831, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 155816, "time": 5055.9515771865845, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 156080, "time": 5064.105209350586, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 156408, "time": 5073.806652069092, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 156744, "time": 5083.930648565292, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 156784, "time": 5085.373204469681, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 156856, "time": 5087.320313453674, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 157120, "time": 5095.576540231705, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 157240, "time": 5098.981265068054, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 157408, "time": 5104.259602308273, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 158128, "time": 5125.982487916946, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 158392, "time": 5133.693678855896, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 158720, "time": 5143.745914936066, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 159056, "time": 5153.827628612518, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 159168, "time": 5157.264360427856, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 159432, "time": 5164.975810050964, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 159552, "time": 5168.819954872131, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 159720, "time": 5173.636924505234, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 160056, "time": 5189.07545208931, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5189.083037853241, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5189.089635372162, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5189.09609246254, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5189.102303743362, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5189.108368873596, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5189.114338159561, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5189.123414993286, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160440, "time": 5200.665910720825, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 160704, "time": 5208.803256511688, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 161032, "time": 5218.521398067474, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 161145, "time": 5222.880302429199, "train_stats/mean_log_entropy": 1.937769408774587, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.999443699471393, "train/action_min": 0.0, "train/action_std": 1.9994130537877628, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 4.953736931125985e-05, "train/actor_opt_grad_steps": 8970.0, "train/actor_opt_loss": -5.0543364832242625, "train/adv_mag": 0.0001878692578542885, "train/adv_max": 0.0001516567116871995, "train/adv_mean": 3.346159346122237e-05, "train/adv_min": -8.402354273926559e-05, "train/adv_std": 4.244507488351135e-05, "train/cont_avg": 0.9964970071517413, "train/cont_loss_mean": 0.02333569051975857, "train/cont_loss_std": 0.3251663571737929, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.67105863801199, "train/cont_pos_acc": 0.9999999822075687, "train/cont_pos_loss": 0.003487422285064017, "train/cont_pred": 0.9965187681848137, "train/cont_rate": 0.9964970071517413, "train/dyn_loss_mean": 1.0031379763759785, "train/dyn_loss_std": 0.0004198176980908237, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.008565066433836015, "train/extr_critic_critic_opt_grad_steps": 8970.0, "train/extr_critic_critic_opt_loss": 6421.84374757074, "train/extr_critic_mag": 0.016204944890529954, "train/extr_critic_max": 0.016204944890529954, "train/extr_critic_mean": 0.01616309225948444, "train/extr_critic_min": 0.016108879995583303, "train/extr_critic_std": 1.4049695449439829e-05, "train/extr_return_normed_mag": 0.0002511301731218153, "train/extr_return_normed_max": 0.0002071970879141964, "train/extr_return_normed_mean": 0.00013070719380924747, "train/extr_return_normed_min": 4.754564377354152e-05, "train/extr_return_normed_std": 3.810299103629427e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.016273036464789316, "train/extr_return_raw_max": 0.016273036464789316, "train/extr_return_raw_mean": 0.016196547381913486, "train/extr_return_raw_min": 0.01611338502064866, "train/extr_return_raw_std": 3.810299093985842e-05, "train/extr_reward_mag": 5.387192341818738e-05, "train/extr_reward_max": 5.387192341818738e-05, "train/extr_reward_mean": 5.383366758236372e-05, "train/extr_reward_min": 5.3799567530997354e-05, "train/extr_reward_std": 2.0441706165254362e-08, "train/image_loss_mean": 0.2510990299543931, "train/image_loss_std": 0.0845713281809394, "train/model_loss_mean": 0.878303705163263, "train/model_loss_std": 0.38024218324849857, "train/model_opt_grad_norm": 49.05166067056988, "train/model_opt_grad_steps": 8959.636815920398, "train/model_opt_loss": 2418.5531072664025, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2754.9751243781093, "train/policy_entropy_mag": 1.9458738547652514, "train/policy_entropy_max": 1.9458738547652514, "train/policy_entropy_mean": 1.944823897893156, "train/policy_entropy_min": 1.9297775842657137, "train/policy_entropy_std": 0.0007014003284310283, "train/policy_logprob_mag": 2.183935758486316, "train/policy_logprob_max": -1.7186733389375222, "train/policy_logprob_mean": -1.944867365988926, "train/policy_logprob_min": -2.183935758486316, "train/policy_logprob_std": 0.04525679264643892, "train/policy_randomness_mag": 0.9999814057231542, "train/policy_randomness_max": 0.9999814057231542, "train/policy_randomness_mean": 0.9994418360107574, "train/policy_randomness_min": 0.9917095608972198, "train/policy_randomness_std": 0.00036044847753028666, "train/post_ent_mag": 56.57829449781731, "train/post_ent_max": 56.57829449781731, "train/post_ent_mean": 56.55519536715835, "train/post_ent_min": 56.33890227891912, "train/post_ent_std": 0.03868701713928832, "train/prior_ent_mag": 54.15678221669363, "train/prior_ent_max": 54.15678221669363, "train/prior_ent_mean": 54.11117472102986, "train/prior_ent_min": 53.89609182177492, "train/prior_ent_std": 0.03951199636308115, "train/rep_loss_mean": 1.0031379763759785, "train/rep_loss_std": 0.0004198176980908237, "train/reward_avg": 7.770595370110736e-05, "train/reward_loss_mean": 0.0019861777354754618, "train/reward_loss_std": 0.05757353327830741, "train/reward_max_data": 0.07772077227113258, "train/reward_max_pred": 5.389327433571887e-05, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00015462692978297272, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 10.164513323042128, "train/reward_pred": 5.385363115396221e-05, "train/reward_rate": 0.00017976523631840796, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.014530924148857594, "report/cont_loss_std": 0.24990151822566986, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.663632392883301, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.003475925885140896, "report/cont_pred": 0.996530294418335, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.2437492161989212, "report/image_loss_std": 0.08043143153190613, "report/model_loss_mean": 0.8584145903587341, "report/model_loss_std": 0.2641177475452423, "report/post_ent_mag": 57.39183807373047, "report/post_ent_max": 57.39183807373047, "report/post_ent_mean": 57.374488830566406, "report/post_ent_min": 57.14775848388672, "report/post_ent_std": 0.03794256970286369, "report/prior_ent_mag": 54.040321350097656, "report/prior_ent_max": 54.040321350097656, "report/prior_ent_mean": 54.00099182128906, "report/prior_ent_min": 53.745426177978516, "report/prior_ent_std": 0.045316170901060104, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.0001344708725810051, "report/reward_loss_std": 5.154346638391871e-08, "report/reward_max_data": 0.0, "report/reward_max_pred": 4.553794860839844e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0001344708725810051, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 4.5300228521227837e-05, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.003475925885140896, "eval/cont_loss_std": 9.313225746154785e-10, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.003475925885140896, "eval/cont_pred": 0.996530294418335, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.25843459367752075, "eval/image_loss_std": 0.08027933537960052, "eval/model_loss_mean": 0.8620449900627136, "eval/model_loss_std": 0.08027933537960052, "eval/post_ent_mag": 57.39124298095703, "eval/post_ent_max": 57.39124298095703, "eval/post_ent_mean": 57.37560272216797, "eval/post_ent_min": 57.149593353271484, "eval/post_ent_std": 0.0359945222735405, "eval/prior_ent_mag": 54.04220962524414, "eval/prior_ent_max": 54.04220962524414, "eval/prior_ent_mean": 54.0020751953125, "eval/prior_ent_min": 53.745426177978516, "eval/prior_ent_std": 0.042273249477148056, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0001344718039035797, "eval/reward_loss_std": 5.948811576672597e-08, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 4.553794860839844e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0001344718039035797, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 4.530046135187149e-05, "eval/reward_rate": 0.0, "replay/size": 160641.0, "replay/inserts": 32144.0, "replay/samples": 32144.0, "replay/insert_wait_avg": 1.3323967109099142e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.2765603433384e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 40360.0, "eval_replay/inserts": 9248.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1459199202514438e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.046627044677734e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0958349704742, "timer/env.step_count": 4018.0, "timer/env.step_total": 37.87281274795532, "timer/env.step_frac": 0.03786918355586736, "timer/env.step_avg": 0.009425787144837064, "timer/env.step_min": 0.007646083831787109, "timer/env.step_max": 0.03871011734008789, "timer/replay._sample_count": 32144.0, "timer/replay._sample_total": 16.356359720230103, "timer/replay._sample_frac": 0.016354792359187246, "timer/replay._sample_avg": 0.0005088464323117877, "timer/replay._sample_min": 0.0003714561462402344, "timer/replay._sample_max": 0.011238813400268555, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5174.0, "timer/agent.policy_total": 53.24565100669861, "timer/agent.policy_frac": 0.053240548700285883, "timer/agent.policy_avg": 0.010291003286953732, "timer/agent.policy_min": 0.008305788040161133, "timer/agent.policy_max": 0.09028863906860352, "timer/dataset_train_count": 2009.0, "timer/dataset_train_total": 0.20847034454345703, "timer/dataset_train_frac": 0.00020845036770862234, "timer/dataset_train_avg": 0.00010376821530286562, "timer/dataset_train_min": 9.036064147949219e-05, "timer/dataset_train_max": 0.0004324913024902344, "timer/agent.train_count": 2009.0, "timer/agent.train_total": 890.0070559978485, "timer/agent.train_frac": 0.8899217703712606, "timer/agent.train_avg": 0.4430099830750864, "timer/agent.train_min": 0.4336249828338623, "timer/agent.train_max": 1.0659921169281006, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47475457191467285, "timer/agent.report_frac": 0.0004747090781841812, "timer/agent.report_avg": 0.23737728595733643, "timer/agent.report_min": 0.23015189170837402, "timer/agent.report_max": 0.24460268020629883, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.600120544433594e-05, "timer/dataset_eval_frac": 3.5997755600490826e-08, "timer/dataset_eval_avg": 3.600120544433594e-05, "timer/dataset_eval_min": 3.600120544433594e-05, "timer/dataset_eval_max": 3.600120544433594e-05, "fps": 32.14036217240431}
{"step": 161368, "time": 5230.043139219284, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 161480, "time": 5233.440065145493, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 161744, "time": 5241.65225315094, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 161864, "time": 5245.106147527695, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 162032, "time": 5250.4364285469055, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 162104, "time": 5252.401448726654, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 162752, "time": 5272.284025430679, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 163016, "time": 5280.1486723423, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 163680, "time": 5300.430548429489, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 163792, "time": 5303.83943104744, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 164056, "time": 5312.177977323532, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 164176, "time": 5316.019825935364, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 164344, "time": 5320.859764814377, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 164416, "time": 5323.25581908226, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 165064, "time": 5342.682049036026, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 165328, "time": 5350.91010761261, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 165992, "time": 5370.886500597, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 166104, "time": 5374.27502989769, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 166368, "time": 5382.487560510635, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 166488, "time": 5385.904212236404, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 166656, "time": 5391.190220594406, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 166728, "time": 5393.157341718674, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 167376, "time": 5412.930183172226, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 167640, "time": 5420.671386003494, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 168304, "time": 5440.956542730331, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 168416, "time": 5444.339480161667, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 168680, "time": 5452.084167957306, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 168800, "time": 5456.009798288345, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 168968, "time": 5460.866592645645, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 169016, "time": 5462.319658994675, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 169040, "time": 5463.274119377136, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 169168, "time": 5467.152763128281, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 169688, "time": 5482.652068853378, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 169952, "time": 5490.9342720508575, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 170040, "time": 5499.268867015839, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5499.276819705963, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5499.283698797226, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5499.290922641754, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5499.298081636429, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5499.304399013519, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5499.3119649887085, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5499.3181138038635, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170728, "time": 5520.262836456299, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 171112, "time": 5531.96454000473, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 171280, "time": 5537.267369031906, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 171328, "time": 5538.73853802681, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 171352, "time": 5539.251126289368, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 171480, "time": 5543.131057262421, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 172000, "time": 5559.096204519272, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 172264, "time": 5567.2990000247955, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 173040, "time": 5591.044657468796, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 173424, "time": 5602.628762960434, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 173592, "time": 5607.538743257523, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 173640, "time": 5608.99524641037, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 173664, "time": 5609.939688205719, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 173792, "time": 5613.7985932827, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 174312, "time": 5629.254001379013, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 174472, "time": 5634.08789730072, "episode/length": 19.0, "episode/score": 0.940625011920929, "episode/reward_rate": 0.05, "episode/intrinsic_return": 0.0}
{"step": 174576, "time": 5637.501640081406, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 175352, "time": 5660.762056112289, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 175736, "time": 5672.449613571167, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 175904, "time": 5677.744638681412, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 175952, "time": 5679.213854551315, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 175976, "time": 5679.721851348877, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 176104, "time": 5683.568730354309, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 176768, "time": 5703.889662265778, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 176784, "time": 5704.376395702362, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 176888, "time": 5707.294148683548, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 178048, "time": 5742.720032453537, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 178216, "time": 5747.580811262131, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 178264, "time": 5749.03804564476, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 178288, "time": 5749.986956357956, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 178416, "time": 5753.860233068466, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 179080, "time": 5773.778224945068, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 179096, "time": 5774.268026828766, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 179200, "time": 5777.652708768845, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 180024, "time": 5807.691226005554, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 5807.699284553528, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 5807.70666885376, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 5807.713959693909, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 5807.720916748047, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 5807.728317975998, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 5807.736330986023, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 5807.747402429581, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180360, "time": 5818.44709610939, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 180528, "time": 5823.73846411705, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 180576, "time": 5825.192422628403, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 180600, "time": 5825.721950292587, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 180728, "time": 5829.571106433868, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 181392, "time": 5849.928985595703, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 181408, "time": 5850.41791343689, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 181512, "time": 5853.339541435242, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 182672, "time": 5888.727773666382, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 182840, "time": 5893.600080251694, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 182888, "time": 5895.052503347397, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 182912, "time": 5896.005440711975, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 183040, "time": 5899.868771314621, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 183704, "time": 5919.7768638134, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 183720, "time": 5920.267189741135, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 183824, "time": 5923.659283399582, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 184984, "time": 5958.576201438904, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 185152, "time": 5963.878155469894, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 185200, "time": 5965.422925233841, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 185224, "time": 5965.9360892772675, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 185352, "time": 5969.815655469894, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 186016, "time": 5990.067865610123, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 186032, "time": 5990.578738689423, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 186136, "time": 5993.486379146576, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 187296, "time": 6028.887021064758, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 187464, "time": 6033.757342576981, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 187512, "time": 6035.225387573242, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 187536, "time": 6036.1779000759125, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 187664, "time": 6040.056677341461, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 188328, "time": 6059.919096231461, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 188344, "time": 6060.4090621471405, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 188448, "time": 6064.290568113327, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 189608, "time": 6099.194419145584, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 189776, "time": 6104.498121976852, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 189824, "time": 6105.946202278137, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 189848, "time": 6106.455107450485, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 189976, "time": 6110.323209524155, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 190008, "time": 6116.549151420593, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6116.556608200073, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6116.566470623016, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6116.5743272304535, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6116.582245826721, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6116.588477611542, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6116.5953373909, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6116.602214574814, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190640, "time": 6135.850082159042, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 190656, "time": 6136.345587015152, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 190760, "time": 6139.296054124832, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 191920, "time": 6174.8046617507935, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 192088, "time": 6179.736998319626, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 192136, "time": 6181.1980676651, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 192160, "time": 6182.14541387558, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 192288, "time": 6186.006574392319, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 192952, "time": 6205.84557390213, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 192968, "time": 6206.339292764664, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 193072, "time": 6209.713233470917, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 193497, "time": 6223.31293296814, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.001700221902073, "train/action_min": 0.0, "train/action_std": 1.9988402033796404, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 6.14471560599515e-05, "train/actor_opt_grad_steps": 10985.0, "train/actor_opt_loss": -4.118212143826012, "train/adv_mag": 0.0002820428626814691, "train/adv_max": 0.0002501673609165862, "train/adv_mean": 8.245569584250736e-05, "train/adv_min": -0.00010350937632345917, "train/adv_std": 6.45273298844829e-05, "train/cont_avg": 0.9963306389232673, "train/cont_loss_mean": 0.024272667541454483, "train/cont_loss_std": 0.3300466373404025, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.645365096101857, "train/cont_pos_acc": 0.9999999837710125, "train/cont_pos_loss": 0.0035677179867069763, "train/cont_pred": 0.99643873106135, "train/cont_rate": 0.9963306389232673, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.010764866559604866, "train/extr_critic_critic_opt_grad_steps": 10985.0, "train/extr_critic_critic_opt_loss": 7042.845898920947, "train/extr_critic_mag": 0.01868897558438896, "train/extr_critic_max": 0.01868897558438896, "train/extr_critic_mean": 0.018615877384891604, "train/extr_critic_min": 0.01854189138601322, "train/extr_critic_std": 2.1545977575658638e-05, "train/extr_return_normed_mag": 0.0004130514928757554, "train/extr_return_normed_max": 0.0003823151645979079, "train/extr_return_normed_mean": 0.00026876666985423646, "train/extr_return_normed_min": 0.00013979413721821097, "train/extr_return_normed_std": 5.7993574524507584e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.018811884963202595, "train/extr_return_raw_max": 0.018811884963202595, "train/extr_return_raw_mean": 0.018698337377224226, "train/extr_return_raw_min": 0.018569363935822897, "train/extr_return_raw_std": 5.7993574636506e-05, "train/extr_reward_mag": 6.897555719507802e-05, "train/extr_reward_max": 6.897555719507802e-05, "train/extr_reward_mean": 6.894008029211372e-05, "train/extr_reward_min": 6.891595255030263e-05, "train/extr_reward_std": 1.245060118480704e-08, "train/image_loss_mean": 0.2456464413369056, "train/image_loss_std": 0.08408186651102387, "train/model_loss_mean": 0.8721270056644289, "train/model_loss_std": 0.3877635342576126, "train/model_opt_grad_norm": 44.08310537999219, "train/model_opt_grad_steps": 10972.920792079209, "train/model_opt_loss": 2364.5998970258356, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2710.3960396039606, "train/policy_entropy_mag": 1.9458895213533156, "train/policy_entropy_max": 1.9458895213533156, "train/policy_entropy_mean": 1.944842502622321, "train/policy_entropy_min": 1.9312374786575242, "train/policy_entropy_std": 0.000759791938264135, "train/policy_logprob_mag": 2.180635952713466, "train/policy_logprob_max": -1.7151590945697066, "train/policy_logprob_mean": -1.9448548767826346, "train/policy_logprob_min": -2.180635952713466, "train/policy_logprob_std": 0.04489255558219877, "train/policy_randomness_mag": 0.9999894603054122, "train/policy_randomness_max": 0.9999894603054122, "train/policy_randomness_mean": 0.9994513917677473, "train/policy_randomness_min": 0.9924597979182064, "train/policy_randomness_std": 0.0003904558458575278, "train/post_ent_mag": 58.584638331196096, "train/post_ent_max": 58.584638331196096, "train/post_ent_mean": 58.56002841609539, "train/post_ent_min": 58.34833985508078, "train/post_ent_std": 0.037408209922216315, "train/prior_ent_mag": 54.6792505849706, "train/prior_ent_max": 54.6792505849706, "train/prior_ent_mean": 54.50358647639209, "train/prior_ent_min": 54.2515927305316, "train/prior_ent_std": 0.07105934586246858, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 9.617569471944566e-05, "train/reward_loss_mean": 0.0022078777691072757, "train/reward_loss_std": 0.06235726900582894, "train/reward_max_data": 0.09381188157171307, "train/reward_max_pred": 6.89318864652426e-05, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00017699624040327727, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 9.78243339061737, "train/reward_pred": 6.887466775825118e-05, "train/reward_rate": 0.00020788211633663366, "train_stats/mean_log_entropy": 1.9368750113865425, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.03138177469372749, "report/cont_loss_std": 0.4057125747203827, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.823274612426758, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0029622865840792656, "report/cont_pred": 0.9970419406890869, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.24970465898513794, "report/image_loss_std": 0.08548271656036377, "report/model_loss_mean": 0.8812886476516724, "report/model_loss_std": 0.4149358868598938, "report/post_ent_mag": 58.83961486816406, "report/post_ent_max": 58.83961486816406, "report/post_ent_mean": 58.78767776489258, "report/post_ent_min": 58.650856018066406, "report/post_ent_std": 0.029600169509649277, "report/prior_ent_mag": 59.28752136230469, "report/prior_ent_max": 59.28752136230469, "report/prior_ent_mean": 58.23949432373047, "report/prior_ent_min": 57.95335388183594, "report/prior_ent_std": 0.24795673787593842, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.000202178955078125, "report/reward_loss_std": 0.0, "report/reward_max_data": 0.0, "report/reward_max_pred": 7.009506225585938e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.000202178955078125, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 7.009506225585938e-05, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.002962286351248622, "eval/cont_loss_std": 4.656612873077393e-10, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.002962286351248622, "eval/cont_pred": 0.9970419406890869, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2727607190608978, "eval/image_loss_std": 0.07742003351449966, "eval/model_loss_mean": 0.8759251832962036, "eval/model_loss_std": 0.07742003351449966, "eval/post_ent_mag": 58.839664459228516, "eval/post_ent_max": 58.839664459228516, "eval/post_ent_mean": 58.7910270690918, "eval/post_ent_min": 58.651832580566406, "eval/post_ent_std": 0.027280662208795547, "eval/prior_ent_mag": 58.89562225341797, "eval/prior_ent_max": 58.89562225341797, "eval/prior_ent_mean": 58.16409683227539, "eval/prior_ent_min": 57.95842742919922, "eval/prior_ent_std": 0.17977842688560486, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.000202178955078125, "eval/reward_loss_std": 0.0, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 7.009506225585938e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.000202178955078125, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 7.009506225585938e-05, "eval/reward_rate": 0.0, "replay/size": 192993.0, "replay/inserts": 32352.0, "replay/samples": 32352.0, "replay/insert_wait_avg": 1.319143349999372e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.286283702454156e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 47296.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.147853461928846e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0281801223754883e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4143924713135, "timer/env.step_count": 4044.0, "timer/env.step_total": 38.01623511314392, "timer/env.step_frac": 0.03800048799701172, "timer/env.step_avg": 0.009400651610569714, "timer/env.step_min": 0.00761723518371582, "timer/env.step_max": 0.03438162803649902, "timer/replay._sample_count": 32352.0, "timer/replay._sample_total": 16.936649322509766, "timer/replay._sample_frac": 0.016929633809716925, "timer/replay._sample_avg": 0.0005235116630350447, "timer/replay._sample_min": 0.00040078163146972656, "timer/replay._sample_max": 0.027727842330932617, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4911.0, "timer/agent.policy_total": 51.2930269241333, "timer/agent.policy_frac": 0.05127178028439261, "timer/agent.policy_avg": 0.010444517801696864, "timer/agent.policy_min": 0.008667230606079102, "timer/agent.policy_max": 0.08448958396911621, "timer/dataset_train_count": 2022.0, "timer/dataset_train_total": 0.21772098541259766, "timer/dataset_train_frac": 0.00021763080084720066, "timer/dataset_train_avg": 0.00010767605608931636, "timer/dataset_train_min": 9.608268737792969e-05, "timer/dataset_train_max": 0.00034332275390625, "timer/agent.train_count": 2022.0, "timer/agent.train_total": 896.9951250553131, "timer/agent.train_frac": 0.8966235709978894, "timer/agent.train_avg": 0.44361776708967016, "timer/agent.train_min": 0.435107946395874, "timer/agent.train_max": 0.6687026023864746, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4805452823638916, "timer/agent.report_frac": 0.0004803462305023476, "timer/agent.report_avg": 0.2402726411819458, "timer/agent.report_min": 0.23316097259521484, "timer/agent.report_max": 0.24738430976867676, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.528594970703125e-05, "timer/dataset_eval_frac": 3.5271333531962415e-08, "timer/dataset_eval_avg": 3.528594970703125e-05, "timer/dataset_eval_min": 3.528594970703125e-05, "timer/dataset_eval_max": 3.528594970703125e-05, "fps": 32.33805098964999}
{"step": 194232, "time": 6245.491562128067, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 194400, "time": 6250.81448340416, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 194448, "time": 6252.266405582428, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 194472, "time": 6252.776796579361, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 194600, "time": 6256.679251194, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 195264, "time": 6277.2422461509705, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 195280, "time": 6277.741953372955, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 195384, "time": 6280.713160037994, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 196544, "time": 6316.356682538986, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 196712, "time": 6321.733143091202, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 196760, "time": 6323.204985618591, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 196784, "time": 6324.1598308086395, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 196912, "time": 6328.19197511673, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 197576, "time": 6348.25742149353, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 197592, "time": 6348.751093626022, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 197696, "time": 6352.13418340683, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 198856, "time": 6387.297714948654, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 199024, "time": 6392.6361310482025, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 199072, "time": 6394.105006694794, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 199096, "time": 6394.6162922382355, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 199224, "time": 6398.521847724915, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 199888, "time": 6418.994680643082, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 199904, "time": 6419.486464738846, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 200008, "time": 6422.432801961899, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 200096, "time": 6426.241255521774, "eval_episode/length": 48.0, "eval_episode/score": 0.8500000238418579, "eval_episode/reward_rate": 0.02040816326530612}
{"step": 200096, "time": 6431.8517327308655, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6431.859122753143, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6431.865923404694, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6431.872344017029, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6431.878772497177, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6431.886728048325, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6431.895086288452, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 201168, "time": 6464.405725240707, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 201336, "time": 6469.279611587524, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 201384, "time": 6470.733471155167, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 201408, "time": 6471.707512378693, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 201536, "time": 6475.683192253113, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 202200, "time": 6495.628366231918, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 202216, "time": 6496.121213436127, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 202320, "time": 6499.492924213409, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 203480, "time": 6534.478041648865, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 203648, "time": 6539.906152009964, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 203696, "time": 6541.36696434021, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 203720, "time": 6541.876580953598, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 203848, "time": 6545.773448705673, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 204512, "time": 6566.2771100997925, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 204528, "time": 6566.764208078384, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 204632, "time": 6569.709398031235, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 205792, "time": 6605.703999996185, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 205960, "time": 6610.605654478073, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 206008, "time": 6612.064023971558, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 206032, "time": 6613.037013053894, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 206160, "time": 6616.913545846939, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 206824, "time": 6637.08763217926, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 206840, "time": 6637.597385406494, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 206944, "time": 6640.955768108368, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 208104, "time": 6675.951509237289, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 208272, "time": 6681.276074409485, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 208320, "time": 6682.730032920837, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 208344, "time": 6683.2401332855225, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 208472, "time": 6687.276473283768, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 209136, "time": 6707.70898103714, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 209152, "time": 6708.20095038414, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 209256, "time": 6711.14106798172, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 209656, "time": 6723.33099770546, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 210080, "time": 6741.597803354263, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 6741.634469747543, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 6741.6724264621735, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 6741.706939697266, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 6741.747786998749, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 6741.7836747169495, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 6741.811604499817, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 6741.8216898441315, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210416, "time": 6752.102307796478, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 210584, "time": 6756.967579841614, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 210656, "time": 6759.38272857666, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 210784, "time": 6763.263653993607, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 211448, "time": 6783.206876993179, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 211464, "time": 6783.705498218536, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 211568, "time": 6787.07453584671, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 211968, "time": 6799.18124127388, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 212728, "time": 6822.110407829285, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 212896, "time": 6827.495343446732, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 212968, "time": 6829.474700212479, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 213096, "time": 6833.817573785782, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 213760, "time": 6854.144145011902, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 213776, "time": 6854.634046077728, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 213880, "time": 6857.594042539597, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 214280, "time": 6869.779340982437, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 215040, "time": 6893.055991888046, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 215208, "time": 6897.992311000824, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 215280, "time": 6900.384320735931, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 215408, "time": 6904.283524274826, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 216072, "time": 6924.110552549362, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 216088, "time": 6924.60825753212, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 216192, "time": 6928.098812580109, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 216592, "time": 6940.2242176532745, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 217352, "time": 6963.125745773315, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 217520, "time": 6968.42947602272, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 217592, "time": 6970.404880285263, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 217720, "time": 6974.283142566681, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 218384, "time": 6994.620672702789, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 218400, "time": 6995.110987186432, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 218504, "time": 6998.024130105972, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 218904, "time": 7010.155919551849, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 219664, "time": 7033.602510690689, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 219832, "time": 7038.489386558533, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 219904, "time": 7040.876004219055, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 220032, "time": 7044.721461057663, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 220064, "time": 7051.072567939758, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7051.080198526382, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7051.086926937103, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7051.093507051468, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7051.1001398563385, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7051.106600284576, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7051.115215539932, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7051.120160341263, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220696, "time": 7070.058646440506, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 220712, "time": 7070.54965877533, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 220816, "time": 7073.9346425533295, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 221216, "time": 7086.648415803909, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 221976, "time": 7109.433158397675, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 222144, "time": 7114.719415664673, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 222216, "time": 7116.710000991821, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 222344, "time": 7120.570079088211, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 223008, "time": 7140.983850240707, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 223024, "time": 7141.473447561264, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 223128, "time": 7144.406977415085, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 223528, "time": 7156.47881269455, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 224288, "time": 7179.839936494827, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 224456, "time": 7184.724363088608, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 224456, "time": 7184.731908321381, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 224528, "time": 7187.134008169174, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 224656, "time": 7191.011463165283, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 225336, "time": 7211.457173585892, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 225440, "time": 7214.822443008423, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 225705, "time": 7223.579338550568, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.005797735535272, "train/action_min": 0.0, "train/action_std": 1.9963927723393582, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0001579808920831794, "train/actor_opt_grad_steps": 13005.0, "train/actor_opt_loss": -5.585722655057907, "train/adv_mag": 0.0005049480235960223, "train/adv_max": 0.0004201468891731583, "train/adv_mean": 3.7284112267170172e-06, "train/adv_min": -0.0004239510007128857, "train/adv_std": 0.00010024516300876316, "train/cont_avg": 0.9964805074257426, "train/cont_loss_mean": 0.02340321091930428, "train/cont_loss_std": 0.32349211423553076, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.666128726460826, "train/cont_pos_acc": 0.999999984066085, "train/cont_pos_loss": 0.0034939848718759004, "train/cont_pred": 0.9965122029332831, "train/cont_rate": 0.9964805074257426, "train/dyn_loss_mean": 1.0000081357389394, "train/dyn_loss_std": 0.00017390792266152208, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.0050154287172977045, "train/extr_critic_critic_opt_grad_steps": 13005.0, "train/extr_critic_critic_opt_loss": 7418.021629409035, "train/extr_critic_mag": 0.020515237114217023, "train/extr_critic_max": 0.020515237114217023, "train/extr_critic_mean": 0.020161308172979567, "train/extr_critic_min": 0.019872557998883843, "train/extr_critic_std": 7.131165726055805e-05, "train/extr_return_normed_mag": 0.0004966910283016687, "train/extr_return_normed_max": 0.00044325290081819683, "train/extr_return_normed_mean": 0.00013995731218627872, "train/extr_return_normed_min": -0.00012590947311998593, "train/extr_return_normed_std": 7.738501778593411e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.020468336068978993, "train/extr_return_raw_max": 0.020468336068978993, "train/extr_return_raw_mean": 0.020165041559329716, "train/extr_return_raw_min": 0.019899173695040812, "train/extr_return_raw_std": 7.738501765086064e-05, "train/extr_reward_mag": 6.119449539939956e-05, "train/extr_reward_max": 6.119449539939956e-05, "train/extr_reward_mean": 6.097164174153107e-05, "train/extr_reward_min": 6.082565477578947e-05, "train/extr_reward_std": 6.148535294269955e-08, "train/image_loss_mean": 0.22068459577489608, "train/image_loss_std": 0.09093210130634874, "train/model_loss_mean": 0.8458432994856693, "train/model_loss_std": 0.3723498469974735, "train/model_opt_grad_norm": 40.033439692884386, "train/model_opt_grad_steps": 12991.20792079208, "train/model_opt_loss": 2463.5934212561883, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2908.4158415841584, "train/policy_entropy_mag": 1.945635489308008, "train/policy_entropy_max": 1.945635489308008, "train/policy_entropy_mean": 1.9298446668256628, "train/policy_entropy_min": 1.8034444651981392, "train/policy_entropy_std": 0.011921338812508021, "train/policy_logprob_mag": 2.752118533200557, "train/policy_logprob_max": -1.2009266886380638, "train/policy_logprob_mean": -1.9298191017443591, "train/policy_logprob_min": -2.752118533200557, "train/policy_logprob_std": 0.16860418879233374, "train/policy_randomness_mag": 0.9998589122649466, "train/policy_randomness_max": 0.9998589122649466, "train/policy_randomness_mean": 0.9917440370167836, "train/policy_randomness_min": 0.9267871751643644, "train/policy_randomness_std": 0.006126356625233288, "train/post_ent_mag": 66.33111559046377, "train/post_ent_max": 66.33111559046377, "train/post_ent_mean": 65.8664393283353, "train/post_ent_min": 65.51369346014344, "train/post_ent_std": 0.1632407661988446, "train/prior_ent_mag": 65.57973672847936, "train/prior_ent_max": 65.57973672847936, "train/prior_ent_mean": 62.89631488535664, "train/prior_ent_min": 61.55841478026739, "train/prior_ent_std": 0.6378796998005692, "train/rep_loss_mean": 1.0000081357389394, "train/rep_loss_std": 0.00017390792266152208, "train/reward_avg": 7.33026183189566e-05, "train/reward_loss_mean": 0.0017505914369358284, "train/reward_loss_std": 0.046346976080052255, "train/reward_max_data": 0.06526918325683859, "train/reward_max_pred": 6.123816612923499e-05, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00015924731193837655, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 9.9465799672263, "train/reward_pred": 6.1001549106054376e-05, "train/reward_rate": 0.0001595374381188119, "train_stats/mean_log_entropy": 1.920670499759061, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.03124063089489937, "report/cont_loss_std": 0.40026673674583435, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.745389938354492, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0032026097178459167, "report/cont_pred": 0.9968023896217346, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.16913263499736786, "report/image_loss_std": 0.09896914660930634, "report/model_loss_mean": 0.8004782199859619, "report/model_loss_std": 0.40783002972602844, "report/post_ent_mag": 71.08427429199219, "report/post_ent_max": 71.08427429199219, "report/post_ent_mean": 70.3355941772461, "report/post_ent_min": 69.63729858398438, "report/post_ent_std": 0.29275014996528625, "report/prior_ent_mag": 71.36014556884766, "report/prior_ent_max": 71.36014556884766, "report/prior_ent_mean": 66.77565002441406, "report/prior_ent_min": 65.39484405517578, "report/prior_ent_std": 0.8443021178245544, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.00010490324348211288, "report/reward_loss_std": 2.9787766919753267e-08, "report/reward_max_data": 0.0, "report/reward_max_pred": 4.279613494873047e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00010490324348211288, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 4.2795902118086815e-05, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.02002542093396187, "eval/cont_loss_std": 0.31034934520721436, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.745389938354492, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0032026097178459167, "eval/cont_pred": 0.9968023896217346, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2118915617465973, "eval/image_loss_std": 0.11457597464323044, "eval/model_loss_mean": 0.8320218920707703, "eval/model_loss_std": 0.336068719625473, "eval/post_ent_mag": 71.11976623535156, "eval/post_ent_max": 71.11976623535156, "eval/post_ent_mean": 70.34102630615234, "eval/post_ent_min": 69.69242095947266, "eval/post_ent_std": 0.2767907977104187, "eval/prior_ent_mag": 71.39314270019531, "eval/prior_ent_max": 71.39314270019531, "eval/prior_ent_mean": 66.76251220703125, "eval/prior_ent_min": 65.2522201538086, "eval/prior_ent_std": 0.8220272064208984, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0001049041748046875, "eval/reward_loss_std": 0.0, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 4.279613494873047e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0001049041748046875, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 4.279613494873047e-05, "eval/reward_rate": 0.0, "replay/size": 225201.0, "replay/inserts": 32208.0, "replay/samples": 32208.0, "replay/insert_wait_avg": 1.3289644655397267e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.371521214969823e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 54232.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1345850692625826e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.98377799987793e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2498948574066, "timer/env.step_count": 4026.0, "timer/env.step_total": 38.086161613464355, "timer/env.step_frac": 0.03807664645532788, "timer/env.step_avg": 0.009460050077859999, "timer/env.step_min": 0.0076367855072021484, "timer/env.step_max": 0.03809070587158203, "timer/replay._sample_count": 32208.0, "timer/replay._sample_total": 16.97887134552002, "timer/replay._sample_frac": 0.016974629472908356, "timer/replay._sample_avg": 0.00052716316894933, "timer/replay._sample_min": 0.00039696693420410156, "timer/replay._sample_max": 0.012459516525268555, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4893.0, "timer/agent.policy_total": 51.83207035064697, "timer/agent.policy_frac": 0.05181912101878905, "timer/agent.policy_avg": 0.010593106550305941, "timer/agent.policy_min": 0.008887529373168945, "timer/agent.policy_max": 0.7837026119232178, "timer/dataset_train_count": 2013.0, "timer/dataset_train_total": 0.21830248832702637, "timer/dataset_train_frac": 0.00021824794928686003, "timer/dataset_train_avg": 0.00010844634293443933, "timer/dataset_train_min": 9.5367431640625e-05, "timer/dataset_train_max": 0.0010559558868408203, "timer/agent.train_count": 2013.0, "timer/agent.train_total": 896.8533923625946, "timer/agent.train_frac": 0.8966293293042016, "timer/agent.train_avg": 0.44553074633015133, "timer/agent.train_min": 0.4350402355194092, "timer/agent.train_max": 0.6705560684204102, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4724113941192627, "timer/agent.report_frac": 0.0004722933704348038, "timer/agent.report_avg": 0.23620569705963135, "timer/agent.report_min": 0.2292156219482422, "timer/agent.report_max": 0.2431957721710205, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.457069396972656e-05, "timer/dataset_eval_frac": 3.456205708939853e-08, "timer/dataset_eval_avg": 3.457069396972656e-05, "timer/dataset_eval_min": 3.457069396972656e-05, "timer/dataset_eval_max": 3.457069396972656e-05, "fps": 32.19942514841256}
{"step": 225840, "time": 7227.738567113876, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 226600, "time": 7250.588753223419, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 226768, "time": 7255.975289821625, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 226768, "time": 7255.983631849289, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 226840, "time": 7257.958847999573, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 226968, "time": 7261.811786651611, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 227648, "time": 7282.608299970627, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 227752, "time": 7285.595604658127, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 228152, "time": 7297.709589242935, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 228912, "time": 7321.100086927414, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 229080, "time": 7325.969518899918, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 229080, "time": 7325.978771209717, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 229152, "time": 7328.398952722549, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 229280, "time": 7332.344646930695, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 229616, "time": 7343.178951263428, "episode/length": 232.0, "episode/score": 0.2750000059604645, "episode/reward_rate": 0.004291845493562232, "episode/intrinsic_return": 0.0}
{"step": 229960, "time": 7353.448235750198, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 230048, "time": 7361.404293060303, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7361.412156820297, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7361.418714046478, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7361.425071954727, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7361.431253194809, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7361.437524318695, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7361.443666219711, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7361.449876070023, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230464, "time": 7373.963660955429, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 231224, "time": 7396.767541408539, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 231392, "time": 7402.082689523697, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 231392, "time": 7402.091034173965, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 231464, "time": 7404.050689935684, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 231592, "time": 7408.034327983856, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 231928, "time": 7418.220386505127, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 232272, "time": 7428.9354774951935, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 232776, "time": 7444.11088180542, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 233304, "time": 7460.148025035858, "episode/length": 238.0, "episode/score": 0.2562499940395355, "episode/reward_rate": 0.0041841004184100415, "episode/intrinsic_return": 0.0}
{"step": 233536, "time": 7467.465668439865, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 233704, "time": 7472.319849491119, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 233776, "time": 7474.73598241806, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 233904, "time": 7478.613213777542, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 234240, "time": 7488.776268005371, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 234584, "time": 7499.061301469803, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 235088, "time": 7514.577423810959, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 235616, "time": 7530.670104265213, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 235848, "time": 7537.496973514557, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 236016, "time": 7542.811085700989, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 236088, "time": 7544.779362678528, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 236216, "time": 7548.663487911224, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 236552, "time": 7558.895956039429, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 236896, "time": 7569.53777885437, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 237400, "time": 7584.595473766327, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 237928, "time": 7601.0804851055145, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 238160, "time": 7608.312538385391, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 238328, "time": 7613.166325569153, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 238400, "time": 7615.65114235878, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 238528, "time": 7619.5349016189575, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 238864, "time": 7629.7103271484375, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 239208, "time": 7639.923716306686, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 239712, "time": 7655.479159116745, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 240032, "time": 7671.032552719116, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7671.040200948715, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7671.046762466431, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7671.05313873291, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7671.059314966202, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7671.065654993057, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7671.071859836578, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7671.078261852264, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240240, "time": 7677.453846216202, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 240472, "time": 7684.28591799736, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 240640, "time": 7689.604358673096, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 240712, "time": 7691.555704593658, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 240840, "time": 7695.426541805267, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 241176, "time": 7705.684267282486, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 241520, "time": 7716.338518381119, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 242024, "time": 7731.345694303513, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 242552, "time": 7747.552139282227, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 242784, "time": 7754.789263725281, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 242952, "time": 7759.656808614731, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 243024, "time": 7762.065894365311, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 243152, "time": 7766.038902521133, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 243488, "time": 7776.205093622208, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 243832, "time": 7786.410277605057, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 244336, "time": 7801.950538396835, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 244864, "time": 7817.921723365784, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 245096, "time": 7824.738658428192, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 245264, "time": 7830.124788284302, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 245336, "time": 7832.077774524689, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 245464, "time": 7835.959521532059, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 245800, "time": 7846.561747074127, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 246144, "time": 7857.291899442673, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 246648, "time": 7872.240530252457, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 247176, "time": 7888.221417427063, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 247408, "time": 7895.444128274918, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 247576, "time": 7900.307978153229, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 247648, "time": 7902.713778495789, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 247776, "time": 7906.567330360413, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 248112, "time": 7916.807908773422, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 248456, "time": 7926.981943130493, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 248880, "time": 7940.017926931381, "episode/length": 212.0, "episode/score": 0.3375000059604645, "episode/reward_rate": 0.004694835680751174, "episode/intrinsic_return": 0.0}
{"step": 248960, "time": 7942.496843576431, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 249720, "time": 7965.350630283356, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 249888, "time": 7970.629635334015, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 249960, "time": 7972.5595915317535, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 250016, "time": 7979.750341653824, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 7979.757279872894, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 7979.764055013657, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 7979.770805120468, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 7979.7768840789795, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 7979.78310918808, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 7979.789451122284, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 7979.798282623291, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250088, "time": 7981.773864030838, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 250424, "time": 7992.038605213165, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 250768, "time": 8002.646863698959, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 251192, "time": 8015.3417937755585, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 251272, "time": 8017.787183761597, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 252032, "time": 8040.984150886536, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 252200, "time": 8045.840614795685, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 252272, "time": 8048.243277311325, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 252400, "time": 8052.090005159378, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 252736, "time": 8062.254461288452, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 253080, "time": 8072.618792057037, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 253504, "time": 8085.6491367816925, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 253584, "time": 8088.090375185013, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 254344, "time": 8111.431230545044, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 254512, "time": 8116.77051615715, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 254584, "time": 8118.7313368320465, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 254712, "time": 8122.631112098694, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 254904, "time": 8128.55145907402, "episode/length": 227.0, "episode/score": 0.2906250059604645, "episode/reward_rate": 0.0043859649122807015, "episode/intrinsic_return": 0.0}
{"step": 255048, "time": 8132.947927713394, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 255816, "time": 8156.352284669876, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 255896, "time": 8158.776670217514, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 256656, "time": 8181.996657371521, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 256824, "time": 8186.999300003052, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 256896, "time": 8189.400328636169, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 257024, "time": 8193.266684770584, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 257216, "time": 8199.039374828339, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 257360, "time": 8203.395154476166, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 258009, "time": 8223.790895938873, "train_stats/mean_log_entropy": 1.921514158802373, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.0032378998561877, "train/action_min": 0.0, "train/action_std": 1.994724165740891, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 9.053394452750391e-05, "train/actor_opt_grad_steps": 15020.0, "train/actor_opt_loss": -5.8777616056266115, "train/adv_mag": 0.0006929127990606413, "train/adv_max": 0.0005412869414879908, "train/adv_mean": -1.1592780820997427e-05, "train/adv_min": -0.0006496582866011568, "train/adv_std": 0.00011872947551234769, "train/cont_avg": 0.9965018656716418, "train/cont_loss_mean": 0.023296505369162605, "train/cont_loss_std": 0.3227319132421784, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.666734818879723, "train/cont_pos_acc": 0.9999999813179472, "train/cont_pos_loss": 0.003483176839524018, "train/cont_pred": 0.9965229559300551, "train/cont_rate": 0.9965018656716418, "train/dyn_loss_mean": 1.000001644613731, "train/dyn_loss_std": 4.718111742829987e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.00208831647212909, "train/extr_critic_critic_opt_grad_steps": 15020.0, "train/extr_critic_critic_opt_loss": 7362.272519239738, "train/extr_critic_mag": 0.020545540164359173, "train/extr_critic_max": 0.020545540164359173, "train/extr_critic_mean": 0.01991936344820172, "train/extr_critic_min": 0.019567052523295086, "train/extr_critic_std": 9.26419768675893e-05, "train/extr_return_normed_mag": 0.0006058490302283966, "train/extr_return_normed_max": 0.0005925004903356827, "train/extr_return_normed_mean": 0.00011723582619930709, "train/extr_return_normed_min": -0.00018075649714588527, "train/extr_return_normed_std": 9.25218454318582e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.020383017183981132, "train/extr_return_raw_max": 0.020383017183981132, "train/extr_return_raw_mean": 0.01990775370145615, "train/extr_return_raw_min": 0.019609760196499564, "train/extr_return_raw_std": 9.252184528706303e-05, "train/extr_reward_mag": 5.719139801329048e-05, "train/extr_reward_max": 5.719139801329048e-05, "train/extr_reward_mean": 5.70477454427749e-05, "train/extr_reward_min": 5.692273230101932e-05, "train/extr_reward_std": 4.720056403937422e-08, "train/image_loss_mean": 0.1937663587764721, "train/image_loss_std": 0.10130759595490213, "train/model_loss_mean": 0.8183785694748608, "train/model_loss_std": 0.3678800165653229, "train/model_opt_grad_norm": 36.56463530051767, "train/model_opt_grad_steps": 15004.492537313432, "train/model_opt_loss": 2321.277055882696, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2848.258706467662, "train/policy_entropy_mag": 1.9457004105866844, "train/policy_entropy_max": 1.9457004105866844, "train/policy_entropy_mean": 1.9321028409312613, "train/policy_entropy_min": 1.8264014151558947, "train/policy_entropy_std": 0.010334806850374634, "train/policy_logprob_mag": 2.738429584313388, "train/policy_logprob_max": -1.2151937716042818, "train/policy_logprob_mean": -1.9320978827737456, "train/policy_logprob_min": -2.738429584313388, "train/policy_logprob_std": 0.16516919730611107, "train/policy_randomness_mag": 0.9998922736490544, "train/policy_randomness_max": 0.9998922736490544, "train/policy_randomness_mean": 0.9929045106641096, "train/policy_randomness_min": 0.9385847137935126, "train/policy_randomness_std": 0.005311040450999541, "train/post_ent_mag": 72.4871197221291, "train/post_ent_max": 72.4871197221291, "train/post_ent_mean": 71.61971647347977, "train/post_ent_min": 70.7243280742892, "train/post_ent_std": 0.35093728278703357, "train/prior_ent_mag": 74.2890373343852, "train/prior_ent_max": 74.2890373343852, "train/prior_ent_mean": 70.33340871630617, "train/prior_ent_min": 67.66743268065191, "train/prior_ent_std": 1.1001569788847396, "train/rep_loss_mean": 1.000001644613731, "train/rep_loss_std": 4.718111742829987e-05, "train/reward_avg": 5.471908032143516e-05, "train/reward_loss_mean": 0.0013146936911996917, "train/reward_loss_std": 0.037258340713061285, "train/reward_max_data": 0.056032338249149605, "train/reward_max_pred": 5.721867974124738e-05, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00014980568472192907, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 9.99023433526357, "train/reward_pred": 5.7082478448155504e-05, "train/reward_rate": 0.0001166044776119403, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.014605877920985222, "report/cont_loss_std": 0.24783195555210114, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.616923809051514, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.003642435185611248, "report/cont_pred": 0.9963643550872803, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.18945607542991638, "report/image_loss_std": 0.11131896078586578, "report/model_loss_mean": 0.8042222261428833, "report/model_loss_std": 0.26732027530670166, "report/post_ent_mag": 77.74555206298828, "report/post_ent_max": 77.74555206298828, "report/post_ent_mean": 76.68650817871094, "report/post_ent_min": 75.38903045654297, "report/post_ent_std": 0.4079403579235077, "report/prior_ent_mag": 78.5667724609375, "report/prior_ent_max": 78.5667724609375, "report/prior_ent_mean": 75.89434814453125, "report/prior_ent_min": 72.93577575683594, "report/prior_ent_std": 0.957353949546814, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.00016021728515625, "report/reward_loss_std": 0.0, "report/reward_max_data": 0.0, "report/reward_max_pred": 6.008148193359375e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00016021728515625, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 6.004492752254009e-05, "report/reward_rate": 0.0, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.014605877920985222, "eval/cont_loss_std": 0.24783195555210114, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.616923809051514, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.003642435185611248, "eval/cont_pred": 0.9963643550872803, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.1743970513343811, "eval/image_loss_std": 0.10160437226295471, "eval/model_loss_mean": 0.7891631722450256, "eval/model_loss_std": 0.27110177278518677, "eval/post_ent_mag": 77.73182678222656, "eval/post_ent_max": 77.73182678222656, "eval/post_ent_mean": 76.69517517089844, "eval/post_ent_min": 75.38887023925781, "eval/post_ent_std": 0.417108416557312, "eval/prior_ent_mag": 78.54867553710938, "eval/prior_ent_max": 78.54867553710938, "eval/prior_ent_mean": 75.99120330810547, "eval/prior_ent_min": 73.0641098022461, "eval/prior_ent_std": 0.9511317610740662, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00016021914780139923, "eval/reward_loss_std": 4.2105668285330466e-08, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 6.031990051269531e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00016021914780139923, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 6.0055055655539036e-05, "eval/reward_rate": 0.0, "replay/size": 257505.0, "replay/inserts": 32304.0, "replay/samples": 32304.0, "replay/insert_wait_avg": 1.3305209189609113e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.375574421799969e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 61168.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1375756137236318e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.238719940185547e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1939392089844, "timer/env.step_count": 4038.0, "timer/env.step_total": 38.0608332157135, "timer/env.step_frac": 0.0380534531591087, "timer/env.step_avg": 0.009425664491261391, "timer/env.step_min": 0.0076258182525634766, "timer/env.step_max": 0.04987978935241699, "timer/replay._sample_count": 32304.0, "timer/replay._sample_total": 16.901578664779663, "timer/replay._sample_frac": 0.016898301421568784, "timer/replay._sample_avg": 0.0005232038962598955, "timer/replay._sample_min": 0.0003790855407714844, "timer/replay._sample_max": 0.012103557586669922, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4905.0, "timer/agent.policy_total": 50.91758489608765, "timer/agent.policy_frac": 0.050907711894711584, "timer/agent.policy_avg": 0.010380751253025004, "timer/agent.policy_min": 0.00885915756225586, "timer/agent.policy_max": 0.0835580825805664, "timer/dataset_train_count": 2019.0, "timer/dataset_train_total": 0.21758580207824707, "timer/dataset_train_frac": 0.0002175436118422468, "timer/dataset_train_avg": 0.00010776909464004312, "timer/dataset_train_min": 9.489059448242188e-05, "timer/dataset_train_max": 0.00033974647521972656, "timer/agent.train_count": 2019.0, "timer/agent.train_total": 898.0342359542847, "timer/agent.train_frac": 0.8978601056756114, "timer/agent.train_avg": 0.44479159779806077, "timer/agent.train_min": 0.4341108798980713, "timer/agent.train_max": 0.6797912120819092, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4795053005218506, "timer/agent.report_frac": 0.0004794123236750197, "timer/agent.report_avg": 0.2397526502609253, "timer/agent.report_min": 0.2322704792022705, "timer/agent.report_max": 0.24723482131958008, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.24249267578125e-05, "timer/dataset_eval_frac": 3.241863951250909e-08, "timer/dataset_eval_avg": 3.24249267578125e-05, "timer/dataset_eval_min": 3.24249267578125e-05, "timer/dataset_eval_max": 3.24249267578125e-05, "fps": 32.29716875067576}
{"step": 258128, "time": 8227.391103982925, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 258208, "time": 8229.815414428711, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 258968, "time": 8252.586401700974, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 259136, "time": 8257.89265704155, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 259208, "time": 8259.859087228775, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 259336, "time": 8263.75586271286, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 259528, "time": 8269.57844376564, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 259672, "time": 8273.936620473862, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 260000, "time": 8289.212825536728, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8289.221735954285, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8289.22808933258, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8289.235044956207, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8289.241150856018, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8289.247547626495, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8289.253671169281, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8289.25993013382, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260440, "time": 8302.400844335556, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 260520, "time": 8304.834532022476, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 261280, "time": 8328.189085960388, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 261448, "time": 8333.061950922012, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 261520, "time": 8335.565264940262, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 261648, "time": 8339.525645971298, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 261840, "time": 8345.448254585266, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 261984, "time": 8349.893645524979, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 262752, "time": 8373.740038633347, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 262832, "time": 8376.175896644592, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 263592, "time": 8399.01323223114, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 263760, "time": 8404.331751585007, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 263832, "time": 8406.316544532776, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 263960, "time": 8410.20135807991, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 264152, "time": 8416.014478445053, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 264296, "time": 8420.414734125137, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 265064, "time": 8443.901996850967, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 265144, "time": 8446.386123895645, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 265904, "time": 8469.838223934174, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 266072, "time": 8474.696384429932, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 266144, "time": 8477.10061120987, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 266272, "time": 8480.981818199158, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 266464, "time": 8486.856425523758, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 266608, "time": 8491.23315525055, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 267376, "time": 8514.483561992645, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 267456, "time": 8517.04019355774, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 268216, "time": 8539.843359231949, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 268384, "time": 8545.284694194794, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 268456, "time": 8547.257892370224, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 268584, "time": 8551.133138179779, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 268776, "time": 8556.968124389648, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 268920, "time": 8561.34448671341, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 269688, "time": 8584.742929935455, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 269768, "time": 8587.194403648376, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 270088, "time": 8599.731738567352, "eval_episode/length": 158.0, "eval_episode/score": 0.5062500238418579, "eval_episode/reward_rate": 0.006289308176100629}
{"step": 270088, "time": 8603.568643808365, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "time": 8603.575942993164, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "time": 8603.582683324814, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "time": 8603.589755296707, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "time": 8603.596871852875, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "time": 8603.603725671768, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "time": 8603.611828804016, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270528, "time": 8617.627391576767, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 270696, "time": 8622.507966279984, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 270768, "time": 8624.919123888016, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 270848, "time": 8627.347285985947, "episode/length": 282.0, "episode/score": 0.11874999850988388, "episode/reward_rate": 0.0035335689045936395, "episode/intrinsic_return": 0.0}
{"step": 271088, "time": 8634.569817304611, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 271232, "time": 8638.989518404007, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 271504, "time": 8647.219733953476, "episode/length": 226.0, "episode/score": 0.29374998807907104, "episode/reward_rate": 0.004405286343612335, "episode/intrinsic_return": 0.0}
{"step": 271568, "time": 8649.152264595032, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 272080, "time": 8664.624925136566, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 272840, "time": 8687.456510543823, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 273008, "time": 8692.769794940948, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 273080, "time": 8694.74407863617, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 273160, "time": 8697.255046606064, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 273400, "time": 8704.53704380989, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 273816, "time": 8717.10135769844, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 273880, "time": 8719.05858874321, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 274392, "time": 8734.560009479523, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 275152, "time": 8757.776295423508, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 275320, "time": 8762.615755319595, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 275392, "time": 8765.011395454407, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 275472, "time": 8767.450243234634, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 275712, "time": 8774.709863424301, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 276128, "time": 8787.2703602314, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 276192, "time": 8789.197029590607, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 276704, "time": 8804.647118806839, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 277464, "time": 8827.538546562195, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 277632, "time": 8832.832986831665, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 277704, "time": 8834.79017996788, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 277784, "time": 8837.218724250793, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 278024, "time": 8844.448774337769, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 278440, "time": 8857.145922660828, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 278504, "time": 8859.058929920197, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 279016, "time": 8875.035962104797, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 279776, "time": 8898.346440792084, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 279944, "time": 8903.203641414642, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 280016, "time": 8905.696885108948, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 280072, "time": 8912.207197904587, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "time": 8912.214438676834, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "time": 8912.220577478409, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "time": 8912.227746486664, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "time": 8912.233975887299, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "time": 8912.240371465683, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "time": 8912.246603488922, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "time": 8912.252828121185, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280096, "time": 8913.201563835144, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 280336, "time": 8920.467740774155, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 280752, "time": 8933.102831840515, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 280816, "time": 8935.093424081802, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 281328, "time": 8950.651370763779, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 282088, "time": 8973.480317354202, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 282256, "time": 8978.8106341362, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 282328, "time": 8980.759556293488, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 282408, "time": 8983.196947336197, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 282648, "time": 8990.436446666718, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 283064, "time": 9003.054094076157, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 283128, "time": 9005.551881313324, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 283640, "time": 9020.925290584564, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 284400, "time": 9043.946580648422, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 284568, "time": 9048.752677202225, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 284640, "time": 9051.154083251953, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 284720, "time": 9053.543637514114, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 284960, "time": 9060.828708410263, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 285376, "time": 9073.392315864563, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 285440, "time": 9075.344054222107, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 285952, "time": 9090.916392326355, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 286632, "time": 9111.190539121628, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 286712, "time": 9113.618742704391, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 286880, "time": 9119.440430641174, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 286952, "time": 9121.391302108765, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 287032, "time": 9123.84228348732, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 287272, "time": 9131.124603748322, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 287448, "time": 9136.451514959335, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 287752, "time": 9145.767756462097, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 288264, "time": 9161.2945997715, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 288944, "time": 9182.189169168472, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 289024, "time": 9184.611165046692, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 289192, "time": 9189.484378099442, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 289344, "time": 9194.330260276794, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 289584, "time": 9201.622048854828, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 289760, "time": 9207.025376319885, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 290056, "time": 9220.961996555328, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "time": 9220.969905853271, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "time": 9220.976811408997, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "time": 9220.983166456223, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "time": 9220.989255428314, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "time": 9220.99526643753, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "time": 9221.001309394836, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "time": 9221.007360935211, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290064, "time": 9221.475630521774, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 290121, "time": 9223.938923597336, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.0261570565143034, "train/action_min": 0.0, "train/action_std": 1.9848442724095055, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00015703468078985436, "train/actor_opt_grad_steps": 17030.0, "train/actor_opt_loss": -5.500837596578162, "train/adv_mag": 0.0017425764481819683, "train/adv_max": 0.001567736490448909, "train/adv_mean": 9.616958350171213e-06, "train/adv_min": -0.0007147574843607139, "train/adv_std": 0.00018178261133068384, "train/cont_avg": 0.9964192708333334, "train/cont_loss_mean": 0.023757044976549364, "train/cont_loss_std": 0.3269429438891102, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.6518364739418026, "train/cont_pos_acc": 0.999999985172974, "train/cont_pos_loss": 0.0035333608321159783, "train/cont_pred": 0.9964729286544952, "train/cont_rate": 0.9964192708333334, "train/dyn_loss_mean": 1.0044546394205804, "train/dyn_loss_std": 0.00240461877561684, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.015223427857889155, "train/extr_critic_critic_opt_grad_steps": 17030.0, "train/extr_critic_critic_opt_loss": 7306.118244228079, "train/extr_critic_mag": 0.020363002274166885, "train/extr_critic_max": 0.020363002274166885, "train/extr_critic_mean": 0.019683385527326694, "train/extr_critic_min": 0.0193345475552687, "train/extr_critic_std": 0.00010097591584057208, "train/extr_return_normed_mag": 0.0017349482398128036, "train/extr_return_normed_max": 0.001713344679024089, "train/extr_return_normed_mean": 0.00019600462423706395, "train/extr_return_normed_min": -0.00017036175105109144, "train/extr_return_normed_std": 0.00016617501524928031, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.021210330367014182, "train/extr_return_raw_max": 0.021210330367014182, "train/extr_return_raw_mean": 0.019692991308830864, "train/extr_return_raw_min": 0.019326623974006567, "train/extr_return_raw_std": 0.00016617501517688271, "train/extr_reward_mag": 0.0003938852851070575, "train/extr_reward_max": 0.0003938852851070575, "train/extr_reward_mean": 5.8638997979326616e-05, "train/extr_reward_min": 4.630539547744675e-05, "train/extr_reward_std": 1.6902541612599942e-05, "train/image_loss_mean": 0.1883493394994024, "train/image_loss_std": 0.10248031919423621, "train/model_loss_mean": 0.8161998907131935, "train/model_loss_std": 0.3737635365617809, "train/model_opt_grad_norm": 35.36786703327995, "train/model_opt_grad_steps": 17012.641791044774, "train/model_opt_loss": 2251.964752045437, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2773.63184079602, "train/policy_entropy_mag": 1.9455794523011392, "train/policy_entropy_max": 1.9455794523011392, "train/policy_entropy_mean": 1.9314891924312458, "train/policy_entropy_min": 1.8413799763911993, "train/policy_entropy_std": 0.009418893169926766, "train/policy_logprob_mag": 2.7209721038590615, "train/policy_logprob_max": -1.2593096628117917, "train/policy_logprob_mean": -1.9314124080079111, "train/policy_logprob_min": -2.7209721038590615, "train/policy_logprob_std": 0.1623239159880586, "train/policy_randomness_mag": 0.9998301137146072, "train/policy_randomness_max": 0.9998301137146072, "train/policy_randomness_mean": 0.9925891460470893, "train/policy_randomness_min": 0.9462821720844478, "train/policy_randomness_std": 0.004840353869865486, "train/post_ent_mag": 82.76082390932301, "train/post_ent_max": 82.76082390932301, "train/post_ent_mean": 81.75406764395794, "train/post_ent_min": 80.55428295230391, "train/post_ent_std": 0.389691939178984, "train/prior_ent_mag": 84.60777316876312, "train/prior_ent_max": 84.60777316876312, "train/prior_ent_mean": 81.3791083720193, "train/prior_ent_min": 78.51263738983306, "train/prior_ent_std": 0.9357325280483683, "train/rep_loss_mean": 1.0044546394205804, "train/rep_loss_std": 0.00240461877561684, "train/reward_avg": 6.300893024916747e-05, "train/reward_loss_mean": 0.0014207018852067082, "train/reward_loss_std": 0.03982791499390732, "train/reward_max_data": 0.06338619414846695, "train/reward_max_pred": 0.0002567394455867027, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00015102555168519232, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 10.093464946746826, "train/reward_pred": 5.478326483764014e-05, "train/reward_rate": 0.00012632151741293532, "train_stats/mean_log_entropy": 1.9218820271284685, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.03101385571062565, "report/cont_loss_std": 0.3891028165817261, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.585789203643799, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0037578411865979433, "report/cont_pred": 0.996249258518219, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.1710236370563507, "report/image_loss_std": 0.09773077070713043, "report/model_loss_mean": 0.8021378517150879, "report/model_loss_std": 0.40116196870803833, "report/post_ent_mag": 95.0516586303711, "report/post_ent_max": 95.0516586303711, "report/post_ent_mean": 94.40241241455078, "report/post_ent_min": 93.71221923828125, "report/post_ent_std": 0.2332489937543869, "report/prior_ent_mag": 97.13484954833984, "report/prior_ent_max": 97.13484954833984, "report/prior_ent_mean": 94.90019989013672, "report/prior_ent_min": 92.11802673339844, "report/prior_ent_std": 0.7028980255126953, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.00010032393038272858, "report/reward_loss_std": 4.908307528239675e-05, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.0001455545425415039, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00010032393038272858, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 3.615301102399826e-05, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.0201114509254694, "eval/cont_loss_std": 0.3016933798789978, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.585789680480957, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0037578409537672997, "eval/cont_pred": 0.996249258518219, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.19358530640602112, "eval/image_loss_std": 0.10139474272727966, "eval/model_loss_mean": 0.8137996792793274, "eval/model_loss_std": 0.3192022740840912, "eval/post_ent_mag": 95.28193664550781, "eval/post_ent_max": 95.28193664550781, "eval/post_ent_mean": 94.39680480957031, "eval/post_ent_min": 93.68522644042969, "eval/post_ent_std": 0.22517593204975128, "eval/prior_ent_mag": 97.76075744628906, "eval/prior_ent_max": 97.76075744628906, "eval/prior_ent_mean": 94.95125579833984, "eval/prior_ent_min": 92.54772186279297, "eval/prior_ent_std": 0.6850408911705017, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0001028766855597496, "eval/reward_loss_std": 4.648001049645245e-05, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.00011527538299560547, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0001028766855597496, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 3.70577909052372e-05, "eval/reward_rate": 0.0, "replay/size": 289617.0, "replay/inserts": 32112.0, "replay/samples": 32112.0, "replay/insert_wait_avg": 1.3089708623805328e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.327796439003101e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 70416.0, "eval_replay/inserts": 9248.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1251665729139914e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.493661880493164e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1321442127228, "timer/env.step_count": 4014.0, "timer/env.step_total": 37.8357298374176, "timer/env.step_frac": 0.03783073072528918, "timer/env.step_avg": 0.009425941663532039, "timer/env.step_min": 0.00757288932800293, "timer/env.step_max": 0.04422640800476074, "timer/replay._sample_count": 32112.0, "timer/replay._sample_total": 16.61644196510315, "timer/replay._sample_frac": 0.016614246488580935, "timer/replay._sample_avg": 0.0005174527268654444, "timer/replay._sample_min": 0.0004036426544189453, "timer/replay._sample_max": 0.03381991386413574, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5170.0, "timer/agent.policy_total": 53.800235986709595, "timer/agent.policy_frac": 0.053793127536221425, "timer/agent.policy_avg": 0.010406235200524099, "timer/agent.policy_min": 0.008237838745117188, "timer/agent.policy_max": 0.9269568920135498, "timer/dataset_train_count": 2007.0, "timer/dataset_train_total": 0.21507716178894043, "timer/dataset_train_frac": 0.00021504874434192235, "timer/dataset_train_avg": 0.0001071635086143201, "timer/dataset_train_min": 9.465217590332031e-05, "timer/dataset_train_max": 0.0010786056518554688, "timer/agent.train_count": 2007.0, "timer/agent.train_total": 892.4709043502808, "timer/agent.train_frac": 0.8923529850675982, "timer/agent.train_avg": 0.44467907541120116, "timer/agent.train_min": 0.43248438835144043, "timer/agent.train_max": 0.6628141403198242, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47672581672668457, "timer/agent.report_frac": 0.0004766628284924792, "timer/agent.report_avg": 0.23836290836334229, "timer/agent.report_min": 0.2328355312347412, "timer/agent.report_max": 0.24389028549194336, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0994415283203125e-05, "timer/dataset_eval_frac": 3.099032009175257e-08, "timer/dataset_eval_avg": 3.0994415283203125e-05, "timer/dataset_eval_min": 3.0994415283203125e-05, "timer/dataset_eval_max": 3.0994415283203125e-05, "fps": 32.107239784541534}
{"step": 290576, "time": 9237.773171663284, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 291152, "time": 9255.258118391037, "episode/length": 265.0, "episode/score": 0.171875, "episode/reward_rate": 0.0037593984962406013, "episode/intrinsic_return": 0.0}
{"step": 291256, "time": 9258.195155382156, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 291504, "time": 9266.05616402626, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 291656, "time": 9270.460640907288, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 291896, "time": 9277.768087387085, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 292072, "time": 9283.117260456085, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 292144, "time": 9285.532779693604, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 292376, "time": 9292.349564552307, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 292888, "time": 9307.991102457047, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 293416, "time": 9323.903377056122, "episode/length": 219.0, "episode/score": 0.31562501192092896, "episode/reward_rate": 0.004545454545454545, "episode/intrinsic_return": 0.0}
{"step": 293568, "time": 9328.812274694443, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 293816, "time": 9336.086838722229, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 294208, "time": 9348.226378917694, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 294384, "time": 9353.579985141754, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 294456, "time": 9355.590147256851, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 294688, "time": 9362.804154157639, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 295200, "time": 9378.733281373978, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 295608, "time": 9390.887524843216, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 295728, "time": 9394.749804258347, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 295880, "time": 9399.130127429962, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 296128, "time": 9406.859741926193, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 296520, "time": 9418.680132627487, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 296696, "time": 9424.123487234116, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 296768, "time": 9426.580832719803, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 297512, "time": 9448.989593029022, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 297920, "time": 9461.58512043953, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 298040, "time": 9465.02614235878, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 298192, "time": 9469.840025901794, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 298440, "time": 9477.2377307415, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 298832, "time": 9489.319342851639, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 298968, "time": 9493.220954179764, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 299008, "time": 9494.677629947662, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 299080, "time": 9496.637060880661, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 299320, "time": 9504.04139328003, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 300040, "time": 9528.392770051956, "eval_episode/length": 136.0, "eval_episode/score": 0.574999988079071, "eval_episode/reward_rate": 0.0072992700729927005}
{"step": 300040, "time": 9531.052428007126, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300040, "time": 9531.06123304367, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300040, "time": 9531.06777715683, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300040, "time": 9531.07417011261, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300040, "time": 9531.080579042435, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300040, "time": 9531.086918354034, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300040, "time": 9531.09321641922, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300352, "time": 9540.907947778702, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 300504, "time": 9545.289008617401, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 300752, "time": 9553.02923297882, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 301144, "time": 9564.67736196518, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 301280, "time": 9569.226613759995, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 301320, "time": 9570.233064889908, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 301392, "time": 9572.656362056732, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 301632, "time": 9579.906005859375, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 302664, "time": 9610.866020202637, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 302816, "time": 9615.65959072113, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 303064, "time": 9622.920048713684, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 303456, "time": 9635.503857851028, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 303592, "time": 9639.398991584778, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 303632, "time": 9640.84767484665, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 303704, "time": 9642.795884370804, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 303944, "time": 9650.057107686996, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 304640, "time": 9671.526078939438, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 304976, "time": 9681.628566265106, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 305128, "time": 9686.057674646378, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 305376, "time": 9693.734498023987, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 305768, "time": 9705.328390359879, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 305944, "time": 9710.624535799026, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 306016, "time": 9713.010685682297, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 306256, "time": 9720.332772493362, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 306952, "time": 9741.17592048645, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 307288, "time": 9751.475692033768, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 307440, "time": 9756.298119068146, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 307688, "time": 9763.585646867752, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 308080, "time": 9775.786873340607, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 308256, "time": 9781.12191748619, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 308328, "time": 9783.103688240051, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 308568, "time": 9790.364310026169, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 309264, "time": 9811.674929141998, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 309552, "time": 9820.402416944504, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 309600, "time": 9821.86155796051, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 309752, "time": 9826.292752027512, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 310000, "time": 9834.078857421875, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 310024, "time": 9835.776480913162, "eval_episode/length": 56.0, "eval_episode/score": 0.824999988079071, "eval_episode/reward_rate": 0.017543859649122806}
{"step": 310024, "time": 9836.754447698593, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 310024, "time": 9840.494820833206, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310024, "time": 9840.502184867859, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310024, "time": 9840.508513450623, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310024, "time": 9840.515340089798, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310024, "time": 9840.522181987762, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310024, "time": 9840.528280496597, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310392, "time": 9851.689197063446, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 310568, "time": 9857.142683506012, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 310640, "time": 9859.589681625366, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 310880, "time": 9866.97996354103, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 311864, "time": 9897.346739768982, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 311912, "time": 9898.833617925644, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 312064, "time": 9903.756543636322, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 312312, "time": 9911.101732492447, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 312704, "time": 9923.221587896347, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 312880, "time": 9928.691556692123, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 312952, "time": 9930.658876895905, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 313192, "time": 9937.902376651764, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 314176, "time": 9968.157540798187, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 314224, "time": 9969.626115083694, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 314376, "time": 9974.028457164764, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 314624, "time": 9981.75970005989, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 315016, "time": 9993.55463051796, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 315192, "time": 9998.904557228088, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 315264, "time": 10001.328958511353, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 315504, "time": 10008.657866239548, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 316240, "time": 10031.070661067963, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 316488, "time": 10038.336563110352, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 316536, "time": 10039.791187524796, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 316688, "time": 10044.600604057312, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 316936, "time": 10051.954344034195, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 317264, "time": 10062.070201396942, "episode/length": 280.0, "episode/score": 0.125, "episode/reward_rate": 0.0035587188612099642, "episode/intrinsic_return": 0.0}
{"step": 317504, "time": 10069.348206281662, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 317816, "time": 10078.722398519516, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 318192, "time": 10090.354548692703, "episode/length": 243.0, "episode/score": 0.24062499403953552, "episode/reward_rate": 0.004098360655737705, "episode/intrinsic_return": 0.0}
{"step": 318312, "time": 10093.764385938644, "episode/length": 221.0, "episode/score": 0.30937498807907104, "episode/reward_rate": 0.0045045045045045045, "episode/intrinsic_return": 0.0}
{"step": 318800, "time": 10108.870428085327, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 319000, "time": 10114.725866317749, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 319232, "time": 10121.960834264755, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 319248, "time": 10122.451236248016, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 319576, "time": 10132.615260124207, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 319816, "time": 10139.949641942978, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 320008, "time": 10151.305978298187, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 320008, "time": 10151.313265323639, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 320008, "time": 10151.319488048553, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 320008, "time": 10151.3256213665, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 320008, "time": 10151.332107543945, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 320008, "time": 10151.338305950165, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 320008, "time": 10151.344553470612, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 320008, "time": 10151.350700378418, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 320128, "time": 10155.24298787117, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 320160, "time": 10156.23094701767, "episode/length": 230.0, "episode/score": 0.28125, "episode/reward_rate": 0.004329004329004329, "episode/intrinsic_return": 0.0}
{"step": 320504, "time": 10166.606036663055, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 321312, "time": 10191.312191963196, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 321544, "time": 10198.25849032402, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 321560, "time": 10198.776056051254, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 321888, "time": 10208.964635848999, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 322128, "time": 10216.245229005814, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 322361, "time": 10224.10088801384, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.1946118043200804, "train/action_min": 0.0, "train/action_std": 1.862863774936978, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0012408533774138806, "train/actor_opt_grad_steps": 19045.0, "train/actor_opt_loss": 6.147820915158002, "train/adv_mag": 0.0071698995675928525, "train/adv_max": 0.007067632713899164, "train/adv_mean": 0.0009268385400549834, "train/adv_min": -0.0023406377099085564, "train/adv_std": 0.0011548995525757137, "train/cont_avg": 0.9964756729579208, "train/cont_loss_mean": 0.023443158170770816, "train/cont_loss_std": 0.32358048842081083, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.6502504157061555, "train/cont_pos_acc": 0.9999999834759401, "train/cont_pos_loss": 0.0035419958553710345, "train/cont_pred": 0.9964643557472984, "train/cont_rate": 0.9964756729579208, "train/dyn_loss_mean": 1.0000100059084374, "train/dyn_loss_std": 0.00030098618536963966, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.07423504888576267, "train/extr_critic_critic_opt_grad_steps": 19045.0, "train/extr_critic_critic_opt_loss": 10166.241184347928, "train/extr_critic_mag": 0.03852997380908173, "train/extr_critic_max": 0.03852997380908173, "train/extr_critic_mean": 0.036307292197379146, "train/extr_critic_min": 0.03363015628097081, "train/extr_critic_std": 0.0007038772422998987, "train/extr_return_normed_mag": 0.010552011817546175, "train/extr_return_normed_max": 0.010552011817546175, "train/extr_return_normed_mean": 0.0037010227079908964, "train/extr_return_normed_min": 0.00028693375389764804, "train/extr_return_normed_std": 0.0014169812919243498, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.04408512630564446, "train/extr_return_raw_max": 0.04408512630564446, "train/extr_return_raw_mean": 0.037234139010900315, "train/extr_return_raw_min": 0.033820048251216955, "train/extr_return_raw_std": 0.0014169812989121506, "train/extr_reward_mag": 0.002881931786489959, "train/extr_reward_max": 0.0028644646748457805, "train/extr_reward_mean": 0.00023467803943150452, "train/extr_reward_min": -3.274360505661162e-05, "train/extr_reward_std": 0.0004064820128891964, "train/image_loss_mean": 0.18093602853541327, "train/image_loss_std": 0.10565176528721752, "train/model_loss_mean": 0.8058306353517098, "train/model_loss_std": 0.37218676249284555, "train/model_opt_grad_norm": 33.322766294573796, "train/model_opt_grad_steps": 19026.29207920792, "train/model_opt_loss": 2820.8641133827737, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3502.4752475247524, "train/policy_entropy_mag": 1.8999980044837046, "train/policy_entropy_max": 1.8999980044837046, "train/policy_entropy_mean": 1.5471480901878658, "train/policy_entropy_min": 0.645625731917006, "train/policy_entropy_std": 0.20783800232030525, "train/policy_logprob_mag": 5.283919755775149, "train/policy_logprob_max": -0.23142258275189612, "train/policy_logprob_mean": -1.5477312372462584, "train/policy_logprob_min": -5.283919755775149, "train/policy_logprob_std": 0.7549990171400627, "train/policy_randomness_mag": 0.9764058825993301, "train/policy_randomness_max": 0.9764058825993301, "train/policy_randomness_mean": 0.7950768879439571, "train/policy_randomness_min": 0.3317860133097609, "train/policy_randomness_std": 0.10680761096980607, "train/post_ent_mag": 95.63280392637347, "train/post_ent_max": 95.63280392637347, "train/post_ent_mean": 94.92923793226186, "train/post_ent_min": 94.27510021700718, "train/post_ent_std": 0.22577060641038535, "train/prior_ent_mag": 98.08307930974676, "train/prior_ent_max": 98.08307930974676, "train/prior_ent_mean": 95.53466789321143, "train/prior_ent_min": 93.10387197815545, "train/prior_ent_std": 0.7311406123756182, "train/rep_loss_mean": 1.0000100059084374, "train/rep_loss_std": 0.00030098618536963966, "train/reward_avg": 7.194292525262895e-05, "train/reward_loss_mean": 0.0014454289062852317, "train/reward_loss_std": 0.039831634119404005, "train/reward_max_data": 0.06984839167925391, "train/reward_max_pred": 0.0018423677671073686, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.0001484166388745687, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 8.196001402537028, "train/reward_pred": 5.7342895053068893e-05, "train/reward_rate": 0.0001595374381188119, "train_stats/mean_log_entropy": 1.5471712566655258, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.031107909977436066, "report/cont_loss_std": 0.39427638053894043, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.6597394943237305, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.003489505499601364, "report/cont_pred": 0.9965164661407471, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.17126436531543732, "report/image_loss_std": 0.11951837688684464, "report/model_loss_mean": 0.802715003490448, "report/model_loss_std": 0.4060605764389038, "report/post_ent_mag": 97.61051177978516, "report/post_ent_max": 97.61051177978516, "report/post_ent_mean": 96.9793930053711, "report/post_ent_min": 96.38661193847656, "report/post_ent_std": 0.22151851654052734, "report/prior_ent_mag": 99.12500762939453, "report/prior_ent_max": 99.12500762939453, "report/prior_ent_mean": 96.06283569335938, "report/prior_ent_min": 93.23013305664062, "report/prior_ent_std": 0.8630759119987488, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.00034267688170075417, "report/reward_loss_std": 0.0017316507874056697, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.007986664772033691, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00034267688170075417, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00013480894267559052, "report/reward_rate": 0.0, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.031107909977436066, "eval/cont_loss_std": 0.39427638053894043, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.6597394943237305, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.003489505499601364, "eval/cont_pred": 0.9965164661407471, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.20285573601722717, "eval/image_loss_std": 0.11232030391693115, "eval/model_loss_mean": 0.8342528343200684, "eval/model_loss_std": 0.41030412912368774, "eval/post_ent_mag": 97.67068481445312, "eval/post_ent_max": 97.67068481445312, "eval/post_ent_mean": 97.00640869140625, "eval/post_ent_min": 96.49068450927734, "eval/post_ent_std": 0.22146670520305634, "eval/prior_ent_mag": 98.6192626953125, "eval/prior_ent_max": 98.6192626953125, "eval/prior_ent_mean": 95.99406433105469, "eval/prior_ent_min": 93.35774230957031, "eval/prior_ent_std": 0.832744836807251, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0002891845069825649, "eval/reward_loss_std": 0.001372870639897883, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0068634748458862305, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0002891845069825649, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00011398515198379755, "eval/reward_rate": 0.0, "replay/size": 321857.0, "replay/inserts": 32240.0, "replay/samples": 32240.0, "replay/insert_wait_avg": 1.3288729835680637e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.419414903626548e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 77352.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1331757322177206e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.98377799987793e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1441206932068, "timer/env.step_count": 4030.0, "timer/env.step_total": 37.87908625602722, "timer/env.step_frac": 0.037873627882522534, "timer/env.step_avg": 0.00939927698660725, "timer/env.step_min": 0.00758814811706543, "timer/env.step_max": 0.03490567207336426, "timer/replay._sample_count": 32240.0, "timer/replay._sample_total": 16.766862154006958, "timer/replay._sample_frac": 0.016764446050420944, "timer/replay._sample_avg": 0.000520063962593268, "timer/replay._sample_min": 0.0003948211669921875, "timer/replay._sample_max": 0.024953365325927734, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4897.0, "timer/agent.policy_total": 50.94768047332764, "timer/agent.policy_frac": 0.05094033891637082, "timer/agent.policy_avg": 0.010403855518343401, "timer/agent.policy_min": 0.008269071578979492, "timer/agent.policy_max": 0.08891081809997559, "timer/dataset_train_count": 2015.0, "timer/dataset_train_total": 0.21794366836547852, "timer/dataset_train_frac": 0.00021791226269912006, "timer/dataset_train_avg": 0.00010816062946177594, "timer/dataset_train_min": 9.441375732421875e-05, "timer/dataset_train_max": 0.0010788440704345703, "timer/agent.train_count": 2015.0, "timer/agent.train_total": 897.9865186214447, "timer/agent.train_frac": 0.8978571188310781, "timer/agent.train_avg": 0.4456508777277641, "timer/agent.train_min": 0.4341104030609131, "timer/agent.train_max": 0.788414716720581, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47603297233581543, "timer/agent.report_frac": 0.0004759643760200017, "timer/agent.report_avg": 0.23801648616790771, "timer/agent.report_min": 0.23132538795471191, "timer/agent.report_max": 0.24470758438110352, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.266334533691406e-05, "timer/dataset_eval_frac": 3.265863855128686e-08, "timer/dataset_eval_avg": 3.266334533691406e-05, "timer/dataset_eval_min": 3.266334533691406e-05, "timer/dataset_eval_max": 3.266334533691406e-05, "fps": 32.23480859682706}
{"step": 322440, "time": 10226.389435529709, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 322472, "time": 10227.365000963211, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 322816, "time": 10238.03048992157, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 323624, "time": 10262.392567157745, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 323856, "time": 10269.641868114471, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 323872, "time": 10270.133617639542, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 324200, "time": 10279.842436552048, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 324392, "time": 10285.756125926971, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 324440, "time": 10287.23790383339, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 324480, "time": 10288.67856001854, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 324752, "time": 10296.936165332794, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 324784, "time": 10297.90793800354, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 325128, "time": 10308.234420537949, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 325936, "time": 10333.16204714775, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 326184, "time": 10340.4751598835, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 326704, "time": 10356.561968564987, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 326752, "time": 10358.022484064102, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 326792, "time": 10359.023016929626, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 327064, "time": 10367.26594877243, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 327096, "time": 10368.238432645798, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 327440, "time": 10378.956530570984, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 327464, "time": 10379.466137647629, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 328496, "time": 10411.617731571198, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 329016, "time": 10427.214167356491, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 329064, "time": 10428.672241687775, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 329104, "time": 10430.137841939926, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 329376, "time": 10438.519223213196, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 329408, "time": 10439.50748038292, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 329752, "time": 10449.719427347183, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 329776, "time": 10450.674006700516, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 330096, "time": 10465.703883171082, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330096, "time": 10465.711330413818, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330096, "time": 10465.717935323715, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330096, "time": 10465.724148750305, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330096, "time": 10465.731673240662, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330096, "time": 10465.73810839653, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330096, "time": 10465.744280338287, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330096, "time": 10465.750586271286, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330808, "time": 10487.070459127426, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 331328, "time": 10503.15365767479, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 331376, "time": 10504.614487171173, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 331416, "time": 10505.604457855225, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 331688, "time": 10513.846088886261, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 331720, "time": 10514.8184735775, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 332064, "time": 10525.56371641159, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 332088, "time": 10526.076994895935, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 332296, "time": 10532.389484167099, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 333120, "time": 10557.656555891037, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 333320, "time": 10563.534287452698, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 333624, "time": 10572.752300739288, "episode/length": 241.0, "episode/score": 0.24687500298023224, "episode/reward_rate": 0.004132231404958678, "episode/intrinsic_return": 0.0}
{"step": 333688, "time": 10574.697609901428, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 333728, "time": 10576.153344869614, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 334032, "time": 10585.424709320068, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 334376, "time": 10595.604336977005, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 334400, "time": 10596.562849760056, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 334608, "time": 10602.853533744812, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 334728, "time": 10606.280776977539, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 335208, "time": 10620.88689160347, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 335632, "time": 10633.957479476929, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 335648, "time": 10634.444518327713, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 335936, "time": 10643.588183164597, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 336040, "time": 10646.611561059952, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 336344, "time": 10655.799533128738, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 336432, "time": 10658.69157576561, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 336688, "time": 10666.439810276031, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 337040, "time": 10677.215144395828, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 337608, "time": 10694.200251579285, "episode/length": 195.0, "episode/score": 0.390625, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.0}
{"step": 337944, "time": 10704.388458490372, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 337960, "time": 10704.916933298111, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 338248, "time": 10713.714327096939, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 338512, "time": 10721.94814491272, "episode/length": 270.0, "episode/score": 0.15625, "episode/reward_rate": 0.0036900369003690036, "episode/intrinsic_return": 0.0}
{"step": 338744, "time": 10728.777968406677, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 339000, "time": 10736.630306720734, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 339352, "time": 10747.303020477295, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 339920, "time": 10764.705883264542, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 340080, "time": 10775.650772333145, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340080, "time": 10775.658658504486, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340080, "time": 10775.665219306946, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340080, "time": 10775.671797990799, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340080, "time": 10775.678452730179, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340080, "time": 10775.685132741928, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340080, "time": 10775.69183588028, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340080, "time": 10775.698595285416, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340256, "time": 10781.028986930847, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 340272, "time": 10781.533619642258, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 340560, "time": 10790.226947069168, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 340824, "time": 10798.07752609253, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 341056, "time": 10805.283071279526, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 341312, "time": 10813.010558605194, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 341664, "time": 10823.620302915573, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 342152, "time": 10838.276076555252, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 342232, "time": 10840.702271223068, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 342568, "time": 10850.85011768341, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 342584, "time": 10851.340365171432, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 342872, "time": 10860.163035392761, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 343136, "time": 10868.338804244995, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 343240, "time": 10871.277266263962, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 343368, "time": 10875.14689874649, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 343624, "time": 10882.885625362396, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 343984, "time": 10894.060163736343, "episode/length": 218.0, "episode/score": 0.3187499940395355, "episode/reward_rate": 0.0045662100456621, "episode/intrinsic_return": 0.0}
{"step": 344464, "time": 10908.985154390335, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 344896, "time": 10922.155678272247, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 345104, "time": 10928.470090389252, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 345184, "time": 10930.88958120346, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 345448, "time": 10938.65518450737, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 345552, "time": 10942.023080587387, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 345648, "time": 10945.3008852005, "episode/length": 284.0, "episode/score": 0.11249999701976776, "episode/reward_rate": 0.0035087719298245615, "episode/intrinsic_return": 0.0}
{"step": 345904, "time": 10953.06772351265, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 345936, "time": 10954.035206079483, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 346088, "time": 10958.428000688553, "episode/length": 202.0, "episode/score": 0.3687500059604645, "episode/reward_rate": 0.0049261083743842365, "episode/intrinsic_return": 0.0}
{"step": 346104, "time": 10958.917010068893, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 346296, "time": 10964.738271474838, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 346936, "time": 10984.21989774704, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 347416, "time": 10998.767894029617, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 347632, "time": 11005.596531152725, "episode/length": 259.0, "episode/score": 0.19062499701976776, "episode/reward_rate": 0.0038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 347960, "time": 11015.284894943237, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 347976, "time": 11015.78038573265, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 348216, "time": 11023.023471355438, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 348248, "time": 11024.000143289566, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 348400, "time": 11028.817001342773, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 348416, "time": 11029.307676315308, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 348544, "time": 11033.18601846695, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 348664, "time": 11036.722709417343, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 348680, "time": 11037.209834814072, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 348992, "time": 11046.881164312363, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 349120, "time": 11050.772081136703, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 349168, "time": 11052.217596769333, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 349368, "time": 11058.056526899338, "episode/length": 243.0, "episode/score": 0.24062499403953552, "episode/reward_rate": 0.004098360655737705, "episode/intrinsic_return": 0.0}
{"step": 349576, "time": 11065.60739517212, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 349984, "time": 11078.1721367836, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 350064, "time": 11081.837691545486, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 350064, "time": 11083.080231428146, "eval_episode/length": 135.0, "eval_episode/score": 0.578125, "eval_episode/reward_rate": 0.007352941176470588}
{"step": 350064, "time": 11083.772532463074, "eval_episode/length": 172.0, "eval_episode/score": 0.4625000059604645, "eval_episode/reward_rate": 0.005780346820809248}
{"step": 350064, "time": 11083.836771965027, "eval_episode/length": 175.0, "eval_episode/score": 0.453125, "eval_episode/reward_rate": 0.005681818181818182}
{"step": 350064, "time": 11085.83809542656, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 350064, "time": 11085.846559047699, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 350064, "time": 11085.85344171524, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 350064, "time": 11085.860074520111, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 350264, "time": 11091.687087535858, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 350856, "time": 11109.620986700058, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 350976, "time": 11113.455368757248, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 350992, "time": 11113.964175701141, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 351304, "time": 11123.170451879501, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 351432, "time": 11127.127198457718, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 351480, "time": 11128.603541851044, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 351888, "time": 11141.134916067123, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 352296, "time": 11153.737583875656, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 352576, "time": 11162.528725385666, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 353168, "time": 11180.391566753387, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 353288, "time": 11183.809151649475, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 353616, "time": 11194.050656557083, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 353720, "time": 11196.979610204697, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 353744, "time": 11197.933072805405, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 353792, "time": 11199.380687236786, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 353896, "time": 11202.341502666473, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 354200, "time": 11211.559136867523, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 354288, "time": 11214.430190324783, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 354368, "time": 11216.956264019012, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 354585, "time": 11224.250453948975, "train_stats/mean_log_entropy": 0.8089679968890859, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.03217919193097, "train/action_min": 0.0, "train/action_std": 1.7794247124325577, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0019336815769100718, "train/actor_opt_grad_steps": 21060.0, "train/actor_opt_loss": 16.937652252382826, "train/adv_mag": 0.0190632195763327, "train/adv_max": 0.019008210327346526, "train/adv_mean": 0.0032521561432374358, "train/adv_min": -0.0051495721424693495, "train/adv_std": 0.003020619264912713, "train/cont_avg": 0.9963998367537313, "train/cont_loss_mean": 0.023868263726914998, "train/cont_loss_std": 0.3272594239034227, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.643894202781446, "train/cont_pos_acc": 0.9999999839868119, "train/cont_pos_loss": 0.003548446528391162, "train/cont_pred": 0.996457876554176, "train/cont_rate": 0.9963998367537313, "train/dyn_loss_mean": 1.0000045394422996, "train/dyn_loss_std": 0.00014240160962075587, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.22463369938609798, "train/extr_critic_critic_opt_grad_steps": 21060.0, "train/extr_critic_critic_opt_loss": 9814.693626593595, "train/extr_critic_mag": 0.1201411734766035, "train/extr_critic_max": 0.1201411734766035, "train/extr_critic_mean": 0.11618606559005543, "train/extr_critic_min": 0.11042491832182776, "train/extr_critic_std": 0.001732911215226319, "train/extr_return_normed_mag": 0.028838148683457826, "train/extr_return_normed_max": 0.028838148683457826, "train/extr_return_normed_mean": 0.011155826306035418, "train/extr_return_normed_min": 0.0025568954943127895, "train/extr_return_normed_std": 0.00364103323179969, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.1371205446138904, "train/extr_return_raw_max": 0.1371205446138904, "train/extr_return_raw_mean": 0.11943822711780297, "train/extr_return_raw_min": 0.11083929135061021, "train/extr_return_raw_std": 0.003641033247727159, "train/extr_reward_mag": 0.012207324825116057, "train/extr_reward_max": 0.012207324825116057, "train/extr_reward_mean": 0.0007977062071481284, "train/extr_reward_min": 1.0236578794261116e-06, "train/extr_reward_std": 0.0018267176344681447, "train/image_loss_mean": 0.1669787893915058, "train/image_loss_std": 0.10528493635541764, "train/model_loss_mean": 0.7925041540345149, "train/model_loss_std": 0.37539550435928565, "train/model_opt_grad_norm": 30.842640511432098, "train/model_opt_grad_steps": 21040.094527363184, "train/model_opt_loss": 2976.664104404734, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3756.218905472637, "train/policy_entropy_mag": 1.835476779226047, "train/policy_entropy_max": 1.835476779226047, "train/policy_entropy_mean": 0.8574924101283894, "train/policy_entropy_min": 0.09220148070682933, "train/policy_entropy_std": 0.42061490398734364, "train/policy_logprob_mag": 6.483890125407508, "train/policy_logprob_max": -0.013808256223686595, "train/policy_logprob_mean": -0.8582715135605181, "train/policy_logprob_min": -6.483890125407508, "train/policy_logprob_std": 1.0064612896881293, "train/policy_randomness_mag": 0.9432485308220138, "train/policy_randomness_max": 0.9432485308220138, "train/policy_randomness_mean": 0.44066395473420916, "train/policy_randomness_min": 0.047382190934757686, "train/policy_randomness_std": 0.216153315050685, "train/post_ent_mag": 99.38129622426199, "train/post_ent_max": 99.38129622426199, "train/post_ent_mean": 98.70619854523768, "train/post_ent_min": 98.16259355687383, "train/post_ent_std": 0.2143660138050715, "train/prior_ent_mag": 100.04381842162479, "train/prior_ent_max": 100.04381842162479, "train/prior_ent_mean": 97.53222959907494, "train/prior_ent_min": 95.09538762486396, "train/prior_ent_std": 0.7405157104060425, "train/rep_loss_mean": 1.0000045394422996, "train/rep_loss_std": 0.00014240160962075587, "train/reward_avg": 8.754445594939315e-05, "train/reward_loss_mean": 0.001654356945102191, "train/reward_loss_std": 0.04269232441746776, "train/reward_max_data": 0.0791977617278028, "train/reward_max_pred": 0.005949353697288095, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00021759219901953055, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 7.164201613834926, "train/reward_pred": 8.781006402192424e-05, "train/reward_rate": 0.000199199315920398, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.02942359261214733, "report/cont_loss_std": 0.3805619180202484, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.36474609375, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.003244386287406087, "report/cont_pred": 0.9967312812805176, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.1767103672027588, "report/image_loss_std": 0.10290694981813431, "report/model_loss_mean": 0.8120359778404236, "report/model_loss_std": 0.4828484058380127, "report/post_ent_mag": 101.60430908203125, "report/post_ent_max": 101.60430908203125, "report/post_ent_mean": 101.01211547851562, "report/post_ent_min": 100.51219177246094, "report/post_ent_std": 0.21008716523647308, "report/prior_ent_mag": 101.12715148925781, "report/prior_ent_max": 101.12715148925781, "report/prior_ent_mean": 99.22268676757812, "report/prior_ent_min": 97.47669982910156, "report/prior_ent_std": 0.628376841545105, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0007049560663290322, "report/reward_loss_mean": 0.005902017932385206, "report/reward_loss_std": 0.1818910837173462, "report/reward_max_data": 0.721875011920929, "report/reward_max_pred": 0.00488126277923584, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0002152115775970742, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 5.82350492477417, "report/reward_pred": 9.090546518564224e-05, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 0.009007947519421577, "eval/cont_loss_std": 0.1816665232181549, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.819380283355713, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0033282102085649967, "eval/cont_pred": 0.996678352355957, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.21574667096138, "eval/image_loss_std": 0.11479569226503372, "eval/model_loss_mean": 0.8248239159584045, "eval/model_loss_std": 0.21586687862873077, "eval/post_ent_mag": 101.7135009765625, "eval/post_ent_max": 101.7135009765625, "eval/post_ent_mean": 100.99879455566406, "eval/post_ent_min": 100.37734985351562, "eval/post_ent_std": 0.21653586626052856, "eval/prior_ent_mag": 101.90159606933594, "eval/prior_ent_max": 101.90159606933594, "eval/prior_ent_mean": 99.1756362915039, "eval/prior_ent_min": 96.9873046875, "eval/prior_ent_std": 0.6904340982437134, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 6.928015500307083e-05, "eval/reward_loss_std": 0.0003432733938097954, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0030211210250854492, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 6.928015500307083e-05, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 2.6935595087707043e-05, "eval/reward_rate": 0.0, "replay/size": 354081.0, "replay/inserts": 32224.0, "replay/samples": 32224.0, "replay/insert_wait_avg": 1.3257520201189633e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.396885719412962e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 84288.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1597812656987772e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1473894119262695e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1321430206299, "timer/env.step_count": 4028.0, "timer/env.step_total": 37.816330671310425, "timer/env.step_frac": 0.0378113341673995, "timer/env.step_avg": 0.009388364118994644, "timer/env.step_min": 0.007634878158569336, "timer/env.step_max": 0.049697160720825195, "timer/replay._sample_count": 32224.0, "timer/replay._sample_total": 16.721227884292603, "timer/replay._sample_frac": 0.016719018582675122, "timer/replay._sample_avg": 0.0005189060291798846, "timer/replay._sample_min": 0.000400543212890625, "timer/replay._sample_max": 0.012056112289428711, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4895.0, "timer/agent.policy_total": 50.83457279205322, "timer/agent.policy_frac": 0.05082785624559679, "timer/agent.policy_avg": 0.01038499954893835, "timer/agent.policy_min": 0.008840560913085938, "timer/agent.policy_max": 0.08689570426940918, "timer/dataset_train_count": 2014.0, "timer/dataset_train_total": 0.2174234390258789, "timer/dataset_train_frac": 0.00021739471183198847, "timer/dataset_train_avg": 0.00010795602732168764, "timer/dataset_train_min": 9.417533874511719e-05, "timer/dataset_train_max": 0.0010743141174316406, "timer/agent.train_count": 2014.0, "timer/agent.train_total": 897.6572046279907, "timer/agent.train_frac": 0.8975386011661007, "timer/agent.train_avg": 0.44570864182124664, "timer/agent.train_min": 0.4346585273742676, "timer/agent.train_max": 1.5864346027374268, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47719287872314453, "timer/agent.report_frac": 0.0004771298293462621, "timer/agent.report_avg": 0.23859643936157227, "timer/agent.report_min": 0.23054242134094238, "timer/agent.report_max": 0.24665045738220215, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.337860107421875e-05, "timer/dataset_eval_frac": 3.337419090782111e-08, "timer/dataset_eval_avg": 3.337860107421875e-05, "timer/dataset_eval_min": 3.337860107421875e-05, "timer/dataset_eval_max": 3.337860107421875e-05, "fps": 32.2192032970357}
{"step": 354608, "time": 11224.908063411713, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 354760, "time": 11229.370782613754, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 355352, "time": 11247.451648712158, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 355480, "time": 11251.348596334457, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 355600, "time": 11255.195373535156, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 355904, "time": 11264.402208328247, "episode/length": 250.0, "episode/score": 0.21875, "episode/reward_rate": 0.00398406374501992, "episode/intrinsic_return": 0.0}
{"step": 356096, "time": 11270.2070581913, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 356104, "time": 11270.236686229706, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 356152, "time": 11271.708199262619, "episode/length": 222.0, "episode/score": 0.3062500059604645, "episode/reward_rate": 0.004484304932735426, "episode/intrinsic_return": 0.0}
{"step": 356256, "time": 11275.16204738617, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 356392, "time": 11279.066682100296, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 356920, "time": 11295.021414995193, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 357104, "time": 11300.822849750519, "episode/length": 218.0, "episode/score": 0.3187499940395355, "episode/reward_rate": 0.0045662100456621, "episode/intrinsic_return": 0.0}
{"step": 357120, "time": 11301.315158367157, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 357200, "time": 11303.732870340347, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 357264, "time": 11305.821080446243, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 357368, "time": 11308.734413146973, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 357728, "time": 11319.843317985535, "episode/length": 227.0, "episode/score": 0.2906250059604645, "episode/reward_rate": 0.0043859649122807015, "episode/intrinsic_return": 0.0}
{"step": 357792, "time": 11321.780097961426, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 357880, "time": 11324.244434595108, "episode/length": 18.0, "episode/score": 0.9437500238418579, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.0}
{"step": 357888, "time": 11324.712492227554, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 358024, "time": 11328.596247911453, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 358224, "time": 11334.890751123428, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 358336, "time": 11338.345186948776, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 358376, "time": 11339.353474378586, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 358408, "time": 11340.337606668472, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 358648, "time": 11347.584542036057, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 358704, "time": 11349.506452560425, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 359432, "time": 11371.399377346039, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 359576, "time": 11375.78141617775, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 359584, "time": 11376.250618934631, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 359704, "time": 11379.684070825577, "episode/length": 209.0, "episode/score": 0.34687501192092896, "episode/reward_rate": 0.004761904761904762, "episode/intrinsic_return": 0.0}
{"step": 359904, "time": 11385.958487987518, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 359968, "time": 11387.90395116806, "episode/length": 271.0, "episode/score": 0.15312500298023224, "episode/reward_rate": 0.003676470588235294, "episode/intrinsic_return": 0.0}
{"step": 360032, "time": 11389.829397201538, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 360048, "time": 11391.105050086975, "eval_episode/length": 42.0, "eval_episode/score": 0.8687499761581421, "eval_episode/reward_rate": 0.023255813953488372}
{"step": 360048, "time": 11391.844680070877, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 360048, "time": 11392.453488826752, "eval_episode/length": 116.0, "eval_episode/score": 0.637499988079071, "eval_episode/reward_rate": 0.008547008547008548}
{"step": 360048, "time": 11393.368464708328, "eval_episode/length": 166.0, "eval_episode/score": 0.48124998807907104, "eval_episode/reward_rate": 0.005988023952095809}
{"step": 360048, "time": 11393.797041654587, "eval_episode/length": 190.0, "eval_episode/score": 0.40625, "eval_episode/reward_rate": 0.005235602094240838}
{"step": 360048, "time": 11393.949257612228, "eval_episode/length": 198.0, "eval_episode/score": 0.3812499940395355, "eval_episode/reward_rate": 0.005025125628140704}
{"step": 360048, "time": 11394.764437675476, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 360048, "time": 11395.064041852951, "eval_episode/length": 254.0, "eval_episode/score": 0.20624999701976776, "eval_episode/reward_rate": 0.00392156862745098}
{"step": 360536, "time": 11410.084821224213, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 360720, "time": 11415.883356809616, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 360736, "time": 11416.374464988708, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 361048, "time": 11425.688163518906, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 361056, "time": 11426.15997171402, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 361232, "time": 11431.492597341537, "episode/length": 205.0, "episode/score": 0.359375, "episode/reward_rate": 0.0048543689320388345, "episode/intrinsic_return": 0.0}
{"step": 361568, "time": 11441.648662805557, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 361608, "time": 11442.636532306671, "episode/length": 204.0, "episode/score": 0.36250001192092896, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.0}
{"step": 361616, "time": 11443.108558893204, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 361752, "time": 11447.010024547577, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 361752, "time": 11447.018228292465, "episode/length": 214.0, "episode/score": 0.33125001192092896, "episode/reward_rate": 0.004651162790697674, "episode/intrinsic_return": 0.0}
{"step": 361976, "time": 11453.786294460297, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 362560, "time": 11471.770567417145, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 362656, "time": 11474.662955522537, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 362800, "time": 11479.01675772667, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 362816, "time": 11479.505250453949, "episode/length": 284.0, "episode/score": 0.11249999701976776, "episode/reward_rate": 0.0035087719298245615, "episode/intrinsic_return": 0.0}
{"step": 362912, "time": 11482.416133880615, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 363032, "time": 11485.920011281967, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 363088, "time": 11487.824199914932, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 363096, "time": 11487.853827476501, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 363568, "time": 11502.335551738739, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 363688, "time": 11508.64849972725, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 363872, "time": 11514.410545349121, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 363880, "time": 11514.439009904861, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 364064, "time": 11520.321314573288, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 364120, "time": 11521.80435872078, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 364200, "time": 11524.210004091263, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 364280, "time": 11526.633594751358, "episode/length": 287.0, "episode/score": 0.10312499850988388, "episode/reward_rate": 0.003472222222222222, "episode/intrinsic_return": 0.0}
{"step": 365040, "time": 11549.857378005981, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 365064, "time": 11550.365518331528, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 365224, "time": 11555.19921541214, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 365320, "time": 11558.101722240448, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 365328, "time": 11558.56945014, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 365400, "time": 11560.554918766022, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 365520, "time": 11564.456116437912, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 365568, "time": 11565.952773094177, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 365880, "time": 11575.35082578659, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 365944, "time": 11577.278288602829, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 366112, "time": 11582.58689570427, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 366432, "time": 11592.279584407806, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 366560, "time": 11596.16366481781, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 366768, "time": 11602.452988624573, "episode/length": 212.0, "episode/score": 0.3375000059604645, "episode/reward_rate": 0.004694835680751174, "episode/intrinsic_return": 0.0}
{"step": 366824, "time": 11603.926688432693, "episode/length": 199.0, "episode/score": 0.37812501192092896, "episode/reward_rate": 0.005, "episode/intrinsic_return": 0.0}
{"step": 367144, "time": 11613.707757472992, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 367208, "time": 11615.663372516632, "episode/length": 204.0, "episode/score": 0.36250001192092896, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.0}
{"step": 367296, "time": 11618.540910959244, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 367576, "time": 11626.803202867508, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 367880, "time": 11636.078518629074, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 368080, "time": 11642.349619150162, "episode/length": 205.0, "episode/score": 0.359375, "episode/reward_rate": 0.0048543689320388345, "episode/intrinsic_return": 0.0}
{"step": 368160, "time": 11644.77695775032, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 368256, "time": 11647.663921356201, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 368504, "time": 11654.931509256363, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 368680, "time": 11660.761419534683, "episode/length": 231.0, "episode/score": 0.27812498807907104, "episode/reward_rate": 0.004310344827586207, "episode/intrinsic_return": 0.0}
{"step": 368872, "time": 11666.718744516373, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 368976, "time": 11670.105684280396, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 369080, "time": 11673.0567445755, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 369088, "time": 11673.526571512222, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 369288, "time": 11679.37120437622, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 369440, "time": 11684.210622310638, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 369976, "time": 11700.390423059464, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 370016, "time": 11701.830960035324, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 370032, "time": 11703.844059705734, "eval_episode/length": 75.0, "eval_episode/score": 0.765625, "eval_episode/reward_rate": 0.013157894736842105}
{"step": 370032, "time": 11703.98426938057, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 370032, "time": 11704.069530963898, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 370032, "time": 11704.80144071579, "eval_episode/length": 41.0, "eval_episode/score": 0.871874988079071, "eval_episode/reward_rate": 0.023809523809523808}
{"step": 370032, "time": 11704.946598052979, "eval_episode/length": 131.0, "eval_episode/score": 0.590624988079071, "eval_episode/reward_rate": 0.007575757575757576}
{"step": 370032, "time": 11705.401128053665, "eval_episode/length": 154.0, "eval_episode/score": 0.518750011920929, "eval_episode/reward_rate": 0.0064516129032258064}
{"step": 370032, "time": 11705.618798971176, "eval_episode/length": 33.0, "eval_episode/score": 0.8968750238418579, "eval_episode/reward_rate": 0.029411764705882353}
{"step": 370032, "time": 11705.778392791748, "eval_episode/length": 97.0, "eval_episode/score": 0.6968749761581421, "eval_episode/reward_rate": 0.01020408163265306}
{"step": 370240, "time": 11712.112716197968, "episode/length": 216.0, "episode/score": 0.32499998807907104, "episode/reward_rate": 0.004608294930875576, "episode/intrinsic_return": 0.0}
{"step": 370272, "time": 11713.090119123459, "episode/length": 263.0, "episode/score": 0.17812499403953552, "episode/reward_rate": 0.003787878787878788, "episode/intrinsic_return": 0.0}
{"step": 370392, "time": 11716.532541513443, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 370480, "time": 11719.437057495117, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 370568, "time": 11721.914551258087, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 371120, "time": 11739.012271881104, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 371168, "time": 11740.484582662582, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 371184, "time": 11740.976064443588, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 371224, "time": 11741.973831653595, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 371264, "time": 11743.412701129913, "episode/length": 17.0, "episode/score": 0.9468749761581421, "episode/reward_rate": 0.05555555555555555, "episode/intrinsic_return": 0.0}
{"step": 371352, "time": 11745.867586374283, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 371360, "time": 11746.339588403702, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 371600, "time": 11753.612576246262, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 371712, "time": 11757.117141008377, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 371904, "time": 11762.92433643341, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 372064, "time": 11767.759095907211, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 372264, "time": 11773.568272829056, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 372312, "time": 11775.03489947319, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 372480, "time": 11780.336773633957, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 372536, "time": 11781.809244632721, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 372584, "time": 11783.256522893906, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 372600, "time": 11783.768384933472, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 372712, "time": 11787.266204357147, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 373128, "time": 11799.906702756882, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 373176, "time": 11801.366909742355, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 373384, "time": 11807.67895936966, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 373400, "time": 11808.190921545029, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 373544, "time": 11812.540751457214, "episode/length": 19.0, "episode/score": 0.940625011920929, "episode/reward_rate": 0.05, "episode/intrinsic_return": 0.0}
{"step": 373640, "time": 11815.54771065712, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 373664, "time": 11816.503288984299, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 373744, "time": 11818.942168951035, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 374064, "time": 11828.663373947144, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 374296, "time": 11835.465005636215, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 374432, "time": 11839.800729990005, "episode/length": 16.0, "episode/score": 0.949999988079071, "episode/reward_rate": 0.058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 374752, "time": 11849.557599544525, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 374864, "time": 11852.970065832138, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 374896, "time": 11853.946180343628, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 374912, "time": 11854.43813586235, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 375208, "time": 11863.168428659439, "episode/length": 207.0, "episode/score": 0.3531250059604645, "episode/reward_rate": 0.004807692307692308, "episode/intrinsic_return": 0.0}
{"step": 375216, "time": 11863.63789486885, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 375232, "time": 11864.128463029861, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 375256, "time": 11864.63647532463, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 375432, "time": 11869.947081565857, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 375592, "time": 11874.782281398773, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 375624, "time": 11875.847697257996, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 375664, "time": 11877.300901889801, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 375712, "time": 11878.755415201187, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 375976, "time": 11886.530152082443, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 375992, "time": 11887.01969218254, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 376360, "time": 11898.128396749496, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 376408, "time": 11899.578308820724, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 376472, "time": 11901.525934696198, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 376776, "time": 11910.865417718887, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 377224, "time": 11924.855308294296, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 377304, "time": 11927.285780191422, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 377392, "time": 11930.176775217056, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 377528, "time": 11934.063484430313, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 377544, "time": 11934.553730010986, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 377696, "time": 11939.442574739456, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 377744, "time": 11940.915919780731, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 377896, "time": 11945.349658489227, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 378336, "time": 11958.886107206345, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 378384, "time": 11960.360049724579, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 379048, "time": 11980.360386610031, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 379088, "time": 11981.791892051697, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 379216, "time": 11985.676624774933, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 379464, "time": 11992.96655368805, "episode/length": 214.0, "episode/score": 0.33125001192092896, "episode/reward_rate": 0.004651162790697674, "episode/intrinsic_return": 0.0}
{"step": 379536, "time": 11995.487673282623, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 379600, "time": 11997.430384874344, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 379616, "time": 11997.918869972229, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 379856, "time": 12005.234018564224, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 379920, "time": 12007.20278596878, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 380008, "time": 12009.673780918121, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 380016, "time": 12013.44959282875, "eval_episode/length": 71.0, "eval_episode/score": 0.778124988079071, "eval_episode/reward_rate": 0.013888888888888888}
{"step": 380016, "time": 12013.850015163422, "eval_episode/length": 93.0, "eval_episode/score": 0.7093750238418579, "eval_episode/reward_rate": 0.010638297872340425}
{"step": 380016, "time": 12014.050746440887, "eval_episode/length": 104.0, "eval_episode/score": 0.675000011920929, "eval_episode/reward_rate": 0.009523809523809525}
{"step": 380016, "time": 12014.324819803238, "eval_episode/length": 119.0, "eval_episode/score": 0.628125011920929, "eval_episode/reward_rate": 0.008333333333333333}
{"step": 380016, "time": 12014.728710889816, "eval_episode/length": 142.0, "eval_episode/score": 0.5562499761581421, "eval_episode/reward_rate": 0.006993006993006993}
{"step": 380016, "time": 12014.916206598282, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 380016, "time": 12014.994790792465, "eval_episode/length": 156.0, "eval_episode/score": 0.512499988079071, "eval_episode/reward_rate": 0.006369426751592357}
{"step": 380016, "time": 12015.08956861496, "eval_episode/length": 67.0, "eval_episode/score": 0.7906249761581421, "eval_episode/reward_rate": 0.014705882352941176}
{"step": 380288, "time": 12023.320838212967, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 380456, "time": 12028.256745100021, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 380520, "time": 12030.187647819519, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 380584, "time": 12032.118997335434, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 380688, "time": 12035.487521409988, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 380784, "time": 12038.404671430588, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 380872, "time": 12040.829776763916, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 381008, "time": 12045.151693105698, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 381184, "time": 12050.445675134659, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 381696, "time": 12065.996632575989, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 381816, "time": 12069.406112670898, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 382072, "time": 12077.168460845947, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 382136, "time": 12079.107107400894, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 382320, "time": 12084.937275886536, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 382496, "time": 12090.344646453857, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 382704, "time": 12096.652341842651, "episode/length": 264.0, "episode/score": 0.17499999701976776, "episode/reward_rate": 0.0037735849056603774, "episode/intrinsic_return": 0.0}
{"step": 382768, "time": 12098.593029022217, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 382944, "time": 12103.911488771439, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 382968, "time": 12104.417294979095, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 383248, "time": 12113.080122470856, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 383296, "time": 12114.540734291077, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 383312, "time": 12115.101886034012, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 383320, "time": 12115.164131641388, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 383392, "time": 12117.57632780075, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 383632, "time": 12124.863157749176, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 383768, "time": 12128.749613285065, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 383920, "time": 12133.566383600235, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 383952, "time": 12134.56025338173, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 384032, "time": 12136.9789686203, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 384120, "time": 12139.44112086296, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 384208, "time": 12142.311756372452, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 384248, "time": 12143.297947645187, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 384248, "time": 12143.305044651031, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 384744, "time": 12158.438099622726, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 384752, "time": 12158.935977935791, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 384912, "time": 12163.798361063004, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 384928, "time": 12164.289411067963, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 385216, "time": 12173.425555706024, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 385312, "time": 12176.476835012436, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 385312, "time": 12176.483983516693, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 385520, "time": 12182.785822153091, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 385584, "time": 12184.729947090149, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 385632, "time": 12186.176767587662, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 385984, "time": 12196.814412593842, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 386016, "time": 12197.77943944931, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 386152, "time": 12201.6666264534, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 386216, "time": 12203.624712705612, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 386264, "time": 12205.160462856293, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 386312, "time": 12206.614649057388, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 386664, "time": 12217.262823104858, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 386873, "time": 12224.595956802368, "train_stats/mean_log_entropy": 0.31090444193719186, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.8901010645498144, "train/action_min": 0.0, "train/action_std": 2.0236846981662335, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.002757470377624072, "train/actor_opt_grad_steps": 23075.0, "train/actor_opt_loss": 15.319072522518068, "train/adv_mag": 0.03265374810388773, "train/adv_max": 0.031122713027024032, "train/adv_mean": 0.007434288569003353, "train/adv_min": -0.013077627756808064, "train/adv_std": 0.005759752224116485, "train/cont_avg": 0.9962001082920792, "train/cont_loss_mean": 0.024465529517833106, "train/cont_loss_std": 0.32861093901752464, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.479752685300153, "train/cont_pos_acc": 0.9999999876069551, "train/cont_pos_loss": 0.003694098000184144, "train/cont_pred": 0.9963083160985814, "train/cont_rate": 0.9962001082920792, "train/dyn_loss_mean": 1.0000169507347711, "train/dyn_loss_std": 0.000491193573727269, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.43478797195193425, "train/extr_critic_critic_opt_grad_steps": 23075.0, "train/extr_critic_critic_opt_loss": 9869.77237754293, "train/extr_critic_mag": 0.2925188582722503, "train/extr_critic_max": 0.2925188582722503, "train/extr_critic_mean": 0.2840403103002227, "train/extr_critic_min": 0.27238467660280735, "train/extr_critic_std": 0.003695076853059933, "train/extr_return_normed_mag": 0.05131285121240238, "train/extr_return_normed_max": 0.05026902516584585, "train/extr_return_normed_mean": 0.022657744256816437, "train/extr_return_normed_min": 0.0029720656647540555, "train/extr_return_normed_std": 0.007117030020609572, "train/extr_return_rate": 1.6114893219535156e-06, "train/extr_return_raw_mag": 0.31908589933473286, "train/extr_return_raw_max": 0.31908589933473286, "train/extr_return_raw_mean": 0.2914746320336172, "train/extr_return_raw_min": 0.27178893983364105, "train/extr_return_raw_std": 0.0071170300505778725, "train/extr_reward_mag": 0.021188227847070976, "train/extr_reward_max": 0.021188227847070976, "train/extr_reward_mean": 0.0018373155733858613, "train/extr_reward_min": 3.6648004361898593e-07, "train/extr_reward_std": 0.0045905160264683754, "train/image_loss_mean": 0.15615592443264356, "train/image_loss_std": 0.10793983855164878, "train/model_loss_mean": 0.7837493180638493, "train/model_loss_std": 0.39668891944064955, "train/model_opt_grad_norm": 29.085712258178408, "train/model_opt_grad_steps": 23053.90099009901, "train/model_opt_loss": 2646.208636897625, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3378.7128712871286, "train/policy_entropy_mag": 1.65928452970958, "train/policy_entropy_max": 1.65928452970958, "train/policy_entropy_mean": 0.3676761159359819, "train/policy_entropy_min": 0.06484126443467518, "train/policy_entropy_std": 0.31795372887708173, "train/policy_logprob_mag": 6.550510949427538, "train/policy_logprob_max": -0.008632243016163017, "train/policy_logprob_mean": -0.36847709561928665, "train/policy_logprob_min": -6.550510949427538, "train/policy_logprob_std": 0.8508181819821349, "train/policy_randomness_mag": 0.8527036188262525, "train/policy_randomness_max": 0.8527036188262525, "train/policy_randomness_mean": 0.18894815917062288, "train/policy_randomness_min": 0.03332182023637366, "train/policy_randomness_std": 0.16339590437341445, "train/post_ent_mag": 103.8497785058352, "train/post_ent_max": 103.8497785058352, "train/post_ent_mean": 103.36725752424486, "train/post_ent_min": 102.94802743137473, "train/post_ent_std": 0.15471815351064844, "train/prior_ent_mag": 103.73796149527672, "train/prior_ent_max": 103.73796149527672, "train/prior_ent_mean": 101.49112251961586, "train/prior_ent_min": 99.68849352090666, "train/prior_ent_std": 0.6230679040793146, "train/rep_loss_mean": 1.0000169507347711, "train/rep_loss_std": 0.000491193573727269, "train/reward_avg": 0.000283284708286986, "train/reward_loss_mean": 0.003117670518309247, "train/reward_loss_std": 0.07748630406112539, "train/reward_max_data": 0.2391707935545704, "train/reward_max_pred": 0.01613039250421052, "train/reward_neg_acc": 0.9999951608110182, "train/reward_neg_loss": 0.0004385198539023237, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 5.824338748857572, "train/reward_pred": 0.00019684314928340293, "train/reward_rate": 0.0004641089108910891, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9990234375, "report/cont_loss_mean": 0.006619946099817753, "report/cont_loss_std": 0.10195426642894745, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 3.2636101245880127, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0034361821599304676, "report/cont_pred": 0.9965481162071228, "report/cont_rate": 0.9990234375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.1472722589969635, "report/image_loss_std": 0.11567261070013046, "report/model_loss_mean": 0.759939968585968, "report/model_loss_std": 0.2905227839946747, "report/post_ent_mag": 106.22621154785156, "report/post_ent_max": 106.22621154785156, "report/post_ent_mean": 105.86170959472656, "report/post_ent_min": 105.58659362792969, "report/post_ent_std": 0.11978068202733994, "report/prior_ent_mag": 106.16146850585938, "report/prior_ent_max": 106.16146850585938, "report/prior_ent_mean": 103.70503997802734, "report/prior_ent_min": 101.92718505859375, "report/prior_ent_std": 0.5536125302314758, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00014953613572288305, "report/reward_loss_mean": 0.006047734059393406, "report/reward_loss_std": 0.1498546004295349, "report/reward_max_data": 0.15312500298023224, "report/reward_max_pred": 0.029374361038208008, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0013681455748155713, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.793266773223877, "report/reward_pred": 0.0006348246242851019, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.01438397541642189, "eval/cont_loss_std": 0.26154372096061707, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.922666549682617, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.002821778180077672, "eval/cont_pred": 0.9971828460693359, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2117023766040802, "eval/image_loss_std": 0.12182674556970596, "eval/model_loss_mean": 0.826350212097168, "eval/model_loss_std": 0.287720650434494, "eval/post_ent_mag": 106.17323303222656, "eval/post_ent_max": 106.17323303222656, "eval/post_ent_mean": 105.84696197509766, "eval/post_ent_min": 105.53628540039062, "eval/post_ent_std": 0.12069886177778244, "eval/prior_ent_mag": 105.29313659667969, "eval/prior_ent_max": 105.29313659667969, "eval/prior_ent_mean": 103.67570495605469, "eval/prior_ent_min": 102.20897674560547, "eval/prior_ent_std": 0.5609424114227295, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0002638653386384249, "eval/reward_loss_std": 0.003089775098487735, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.03985166549682617, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0002638653386384249, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00011642731260508299, "eval/reward_rate": 0.0, "replay/size": 386369.0, "replay/inserts": 32288.0, "replay/samples": 32288.0, "replay/insert_wait_avg": 1.3247339056788163e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.381497044747601e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 89016.0, "eval_replay/inserts": 4728.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.182410922752419e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.08970832824707e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3301074504852, "timer/env.step_count": 4036.0, "timer/env.step_total": 38.274614572525024, "timer/env.step_frac": 0.03826198400653412, "timer/env.step_avg": 0.00948330390795962, "timer/env.step_min": 0.0074138641357421875, "timer/env.step_max": 0.03970456123352051, "timer/replay._sample_count": 32288.0, "timer/replay._sample_total": 16.858204126358032, "timer/replay._sample_frac": 0.016852640944022057, "timer/replay._sample_avg": 0.0005221198007420104, "timer/replay._sample_min": 0.0003991127014160156, "timer/replay._sample_max": 0.011449337005615234, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4627.0, "timer/agent.policy_total": 48.03720259666443, "timer/agent.policy_frac": 0.04802135039111796, "timer/agent.policy_avg": 0.010381932698652351, "timer/agent.policy_min": 0.008939266204833984, "timer/agent.policy_max": 0.07548761367797852, "timer/dataset_train_count": 2018.0, "timer/dataset_train_total": 0.2167508602142334, "timer/dataset_train_frac": 0.00021667933275212574, "timer/dataset_train_avg": 0.0001074087513450116, "timer/dataset_train_min": 9.465217590332031e-05, "timer/dataset_train_max": 0.00047326087951660156, "timer/agent.train_count": 2018.0, "timer/agent.train_total": 897.8742444515228, "timer/agent.train_frac": 0.8975779472837332, "timer/agent.train_avg": 0.44493272767667136, "timer/agent.train_min": 0.4360525608062744, "timer/agent.train_max": 0.6564431190490723, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47537899017333984, "timer/agent.report_frac": 0.00047522211581227483, "timer/agent.report_avg": 0.23768949508666992, "timer/agent.report_min": 0.23488450050354004, "timer/agent.report_max": 0.2404944896697998, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.6464462280273438e-05, "timer/dataset_eval_frac": 2.6455729047007002e-08, "timer/dataset_eval_avg": 2.6464462280273438e-05, "timer/dataset_eval_min": 2.6464462280273438e-05, "timer/dataset_eval_max": 2.6464462280273438e-05, "fps": 32.276791299864236}
{"step": 387120, "time": 12232.055842638016, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 387128, "time": 12232.085109710693, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 387264, "time": 12236.535290718079, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 387408, "time": 12240.908908367157, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 387824, "time": 12253.50278544426, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 387832, "time": 12253.53229689598, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 388008, "time": 12258.8625395298, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 388152, "time": 12266.74274468422, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 388328, "time": 12272.079656600952, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 388464, "time": 12276.433822154999, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 388528, "time": 12278.378590106964, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 388576, "time": 12279.834545135498, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 388624, "time": 12281.319952487946, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 388896, "time": 12289.544016599655, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 388912, "time": 12290.051480531693, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 389040, "time": 12293.916594028473, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 389368, "time": 12303.755822658539, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 389712, "time": 12314.388773441315, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 389744, "time": 12315.357902050018, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 390000, "time": 12323.59470629692, "eval_episode/length": 27.0, "eval_episode/score": 0.9156249761581421, "eval_episode/reward_rate": 0.03571428571428571}
{"step": 390000, "time": 12324.03487253189, "eval_episode/length": 51.0, "eval_episode/score": 0.840624988079071, "eval_episode/reward_rate": 0.019230769230769232}
{"step": 390000, "time": 12324.15199303627, "eval_episode/length": 57.0, "eval_episode/score": 0.8218749761581421, "eval_episode/reward_rate": 0.017241379310344827}
{"step": 390000, "time": 12325.117606163025, "eval_episode/length": 78.0, "eval_episode/score": 0.7562500238418579, "eval_episode/reward_rate": 0.012658227848101266}
{"step": 390000, "time": 12325.526000976562, "eval_episode/length": 91.0, "eval_episode/score": 0.715624988079071, "eval_episode/reward_rate": 0.010869565217391304}
{"step": 390000, "time": 12325.73872923851, "eval_episode/length": 102.0, "eval_episode/score": 0.6812499761581421, "eval_episode/reward_rate": 0.009708737864077669}
{"step": 390000, "time": 12326.677068471909, "eval_episode/length": 102.0, "eval_episode/score": 0.6812499761581421, "eval_episode/reward_rate": 0.009708737864077669}
{"step": 390000, "time": 12327.92933511734, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 390024, "time": 12328.433174610138, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 390184, "time": 12333.279354810715, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 390320, "time": 12337.60926270485, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 390736, "time": 12350.174020051956, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 390776, "time": 12351.176372289658, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 390888, "time": 12354.571468353271, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 390912, "time": 12355.598855018616, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 390936, "time": 12356.107023954391, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 391056, "time": 12359.963889837265, "episode/length": 20.0, "episode/score": 0.9375, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.0}
{"step": 391208, "time": 12364.357154607773, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 391312, "time": 12367.737077713013, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 391360, "time": 12369.19302225113, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 391760, "time": 12381.269413232803, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 392056, "time": 12390.142459154129, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 392120, "time": 12392.09822177887, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 392336, "time": 12398.845037698746, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 392352, "time": 12399.334128141403, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 392376, "time": 12399.841875553131, "episode/length": 199.0, "episode/score": 0.37812501192092896, "episode/reward_rate": 0.005, "episode/intrinsic_return": 0.0}
{"step": 392424, "time": 12401.294887065887, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 392512, "time": 12404.203494787216, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 392568, "time": 12405.667633771896, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 392840, "time": 12413.893218755722, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 392952, "time": 12417.395082712173, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 393048, "time": 12420.301264286041, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 393120, "time": 12422.711139202118, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 393288, "time": 12428.10888504982, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 393672, "time": 12439.834707975388, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 393752, "time": 12442.261791706085, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 393808, "time": 12444.173053741455, "episode/length": 16.0, "episode/score": 0.949999988079071, "episode/reward_rate": 0.058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 393856, "time": 12445.74334359169, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 394024, "time": 12450.622020721436, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 394128, "time": 12453.996992826462, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 394192, "time": 12455.947417020798, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 394216, "time": 12456.457328557968, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 394336, "time": 12460.293148994446, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 394536, "time": 12466.12602519989, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 394632, "time": 12469.019603729248, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 394672, "time": 12470.466740608215, "episode/length": 16.0, "episode/score": 0.949999988079071, "episode/reward_rate": 0.058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 394824, "time": 12474.81075501442, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 394936, "time": 12478.305111169815, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 394960, "time": 12479.258532762527, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 395368, "time": 12491.362888813019, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 395432, "time": 12493.290682792664, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 395536, "time": 12496.66306257248, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 395760, "time": 12503.424026966095, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 395912, "time": 12507.933433532715, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 396504, "time": 12525.808026313782, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 396688, "time": 12531.576882123947, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 396712, "time": 12532.088886499405, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 396896, "time": 12537.96482682228, "episode/length": 182.0, "episode/score": 0.4312500059604645, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.0}
{"step": 396968, "time": 12539.927984714508, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 396984, "time": 12540.416115045547, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 397272, "time": 12549.253808259964, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 397312, "time": 12550.707967042923, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 397352, "time": 12551.705320358276, "episode/length": 9.0, "episode/score": 0.971875011920929, "episode/reward_rate": 0.1, "episode/intrinsic_return": 0.0}
{"step": 397680, "time": 12561.854687929153, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 397760, "time": 12564.277597427368, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 397848, "time": 12566.803218364716, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 397856, "time": 12567.273193359375, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 398120, "time": 12575.026948928833, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 398168, "time": 12576.468077421188, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 398448, "time": 12585.179408073425, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 398688, "time": 12592.4539706707, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 399024, "time": 12602.799119710922, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 399056, "time": 12603.77309346199, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 399280, "time": 12610.548214435577, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 399664, "time": 12622.171459674835, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 399992, "time": 12631.897899389267, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 400024, "time": 12632.866390705109, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 400088, "time": 12636.199617385864, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 400088, "time": 12636.453130960464, "eval_episode/length": 90.0, "eval_episode/score": 0.71875, "eval_episode/reward_rate": 0.01098901098901099}
{"step": 400088, "time": 12636.608402967453, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 400088, "time": 12637.059083461761, "eval_episode/length": 122.0, "eval_episode/score": 0.6187499761581421, "eval_episode/reward_rate": 0.008130081300813009}
{"step": 400088, "time": 12637.506622076035, "eval_episode/length": 48.0, "eval_episode/score": 0.8500000238418579, "eval_episode/reward_rate": 0.02040816326530612}
{"step": 400088, "time": 12637.585215568542, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 400088, "time": 12638.394749879837, "eval_episode/length": 106.0, "eval_episode/score": 0.668749988079071, "eval_episode/reward_rate": 0.009345794392523364}
{"step": 400088, "time": 12639.33671092987, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 400168, "time": 12641.76192688942, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 400480, "time": 12651.425595283508, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 400544, "time": 12653.364661455154, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 400632, "time": 12655.920943021774, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 400760, "time": 12659.804319858551, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 400792, "time": 12660.775821447372, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 400864, "time": 12663.164375305176, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 401000, "time": 12667.053441047668, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 401176, "time": 12672.36294412613, "episode/length": 21.0, "episode/score": 0.934374988079071, "episode/reward_rate": 0.045454545454545456, "episode/intrinsic_return": 0.0}
{"step": 401224, "time": 12674.19782590866, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 401288, "time": 12676.14027929306, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 401368, "time": 12678.564184904099, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 401728, "time": 12690.189898967743, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 401752, "time": 12690.698273420334, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 401840, "time": 12693.573800325394, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 402040, "time": 12699.429870605469, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 402088, "time": 12700.885438203812, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 402184, "time": 12703.778960466385, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 402336, "time": 12708.5853266716, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 402472, "time": 12712.480797052383, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 402504, "time": 12713.458297729492, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 402744, "time": 12720.858733177185, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 402872, "time": 12724.746789932251, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 403064, "time": 12730.565931081772, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 403104, "time": 12731.994207382202, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 403336, "time": 12738.794654607773, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 403528, "time": 12744.577573299408, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 403600, "time": 12747.056933879852, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 403648, "time": 12748.527340888977, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 403816, "time": 12753.393376350403, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 404024, "time": 12759.670086622238, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 404256, "time": 12766.888534069061, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 404400, "time": 12771.248965740204, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 404816, "time": 12783.95727801323, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 405104, "time": 12792.71390748024, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 405112, "time": 12792.74366736412, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 405128, "time": 12793.23493528366, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 405376, "time": 12800.937737464905, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 405536, "time": 12805.85895204544, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 405560, "time": 12806.394067049026, "episode/length": 238.0, "episode/score": 0.2562499940395355, "episode/reward_rate": 0.0041841004184100415, "episode/intrinsic_return": 0.0}
{"step": 405648, "time": 12809.273371458054, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 405896, "time": 12816.558163881302, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 405968, "time": 12818.9543197155, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 405968, "time": 12818.962017297745, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 405992, "time": 12819.469790935516, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 406128, "time": 12823.815031051636, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 406368, "time": 12831.077300548553, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 406480, "time": 12834.44583773613, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 407000, "time": 12850.056790351868, "episode/length": 182.0, "episode/score": 0.4312500059604645, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.0}
{"step": 407072, "time": 12852.443255901337, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 407304, "time": 12859.212032318115, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 407464, "time": 12864.042889118195, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 407752, "time": 12872.845709323883, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 407776, "time": 12873.808860063553, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 407824, "time": 12875.287153720856, "episode/length": 228.0, "episode/score": 0.2874999940395355, "episode/reward_rate": 0.004366812227074236, "episode/intrinsic_return": 0.0}
{"step": 407960, "time": 12879.181164503098, "episode/length": 228.0, "episode/score": 0.2874999940395355, "episode/reward_rate": 0.004366812227074236, "episode/intrinsic_return": 0.0}
{"step": 408208, "time": 12886.89735865593, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 408280, "time": 12888.872056007385, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 408280, "time": 12888.880121469498, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 408520, "time": 12896.276866197586, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 408736, "time": 12903.0109000206, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 408872, "time": 12906.916568279266, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 409728, "time": 12933.51851773262, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 409768, "time": 12934.506179332733, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 410064, "time": 12943.688697099686, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 410072, "time": 12948.082736492157, "eval_episode/length": 242.0, "eval_episode/score": 0.24375000596046448, "eval_episode/reward_rate": 0.00411522633744856}
{"step": 410072, "time": 12948.91847395897, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 410072, "time": 12948.926048994064, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 410072, "time": 12948.932678222656, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 410072, "time": 12948.93907546997, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 410072, "time": 12948.945298671722, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 410072, "time": 12948.951977729797, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 410072, "time": 12948.95989871025, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 410136, "time": 12950.898016929626, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 410272, "time": 12955.36182141304, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 410832, "time": 12972.294512271881, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 411048, "time": 12978.57631111145, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 411184, "time": 12982.903887271881, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 411616, "time": 12996.0300552845, "episode/length": 230.0, "episode/score": 0.28125, "episode/reward_rate": 0.004329004329004329, "episode/intrinsic_return": 0.0}
{"step": 412040, "time": 13008.680814743042, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 412376, "time": 13018.942993164062, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 412448, "time": 13021.365221977234, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 412456, "time": 13021.393245697021, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 412584, "time": 13025.246134996414, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 413144, "time": 13042.143294334412, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 413296, "time": 13047.047828674316, "episode/length": 263.0, "episode/score": 0.17812499403953552, "episode/reward_rate": 0.003787878787878788, "episode/intrinsic_return": 0.0}
{"step": 413360, "time": 13048.996176242828, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 413624, "time": 13056.760136127472, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 413664, "time": 13058.193601369858, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 413928, "time": 13065.959426164627, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 413984, "time": 13067.867270231247, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 413992, "time": 13067.894670009613, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 414096, "time": 13071.26742386818, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 414352, "time": 13079.166785001755, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 414376, "time": 13079.675599098206, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 414480, "time": 13083.019498109818, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 414504, "time": 13083.545914888382, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 414768, "time": 13091.770296573639, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 414816, "time": 13093.224429368973, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 415008, "time": 13099.038080692291, "episode/length": 213.0, "episode/score": 0.3343749940395355, "episode/reward_rate": 0.004672897196261682, "episode/intrinsic_return": 0.0}
{"step": 415072, "time": 13100.961268424988, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 415232, "time": 13105.875525474548, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 415312, "time": 13108.297802448273, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 415656, "time": 13118.423214912415, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 415872, "time": 13125.164250612259, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 415936, "time": 13127.099384307861, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 416136, "time": 13132.929957389832, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 416224, "time": 13135.896726608276, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 416440, "time": 13142.23016834259, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 416512, "time": 13144.638155698776, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 416544, "time": 13145.604437351227, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 416664, "time": 13149.027449131012, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 416792, "time": 13152.94798374176, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 416952, "time": 13157.870014667511, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 416992, "time": 13159.322244882584, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 417104, "time": 13162.729282617569, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 417376, "time": 13171.09338760376, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 417384, "time": 13171.123235940933, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 417520, "time": 13175.465235710144, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 417536, "time": 13175.963220357895, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 417568, "time": 13176.957762002945, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 417656, "time": 13179.39199757576, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 417768, "time": 13182.793591022491, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 417816, "time": 13184.709163188934, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 418200, "time": 13196.442415237427, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 418256, "time": 13198.360687732697, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 418336, "time": 13200.777026176453, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 418496, "time": 13205.61419248581, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 418512, "time": 13206.119906187057, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 418664, "time": 13210.460104942322, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 418696, "time": 13211.44912481308, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 418752, "time": 13213.359121322632, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 419097, "time": 13224.59040236473, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.725265578844061, "train/action_min": 0.0, "train/action_std": 2.020400531849458, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.004718250193081759, "train/actor_opt_grad_steps": 25090.0, "train/actor_opt_loss": 9.13478774840559, "train/adv_mag": 0.12617841881899097, "train/adv_max": 0.12582093373459963, "train/adv_mean": 0.009533371835708414, "train/adv_min": -0.02379644791878278, "train/adv_std": 0.012384948244234964, "train/cont_avg": 0.9957925217661692, "train/cont_loss_mean": 0.025280244093601457, "train/cont_loss_std": 0.3260062447800046, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.084568234405133, "train/cont_pos_acc": 0.9999999810214066, "train/cont_pos_loss": 0.0039337626241369925, "train/cont_pred": 0.9960545523842769, "train/cont_rate": 0.9957925217661692, "train/dyn_loss_mean": 1.0000113438611007, "train/dyn_loss_std": 0.00035196133541459895, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.4393103770652221, "train/extr_critic_critic_opt_grad_steps": 25090.0, "train/extr_critic_critic_opt_loss": 10133.414207040967, "train/extr_critic_mag": 0.6202611852048049, "train/extr_critic_max": 0.6202611852048049, "train/extr_critic_mean": 0.6027972025064686, "train/extr_critic_min": 0.5769557923226807, "train/extr_critic_std": 0.0069641406637435755, "train/extr_return_normed_mag": 0.15953114880851252, "train/extr_return_normed_max": 0.15953114880851252, "train/extr_return_normed_mean": 0.033546860042533176, "train/extr_return_normed_min": 0.0001396262527105227, "train/extr_return_normed_std": 0.014755668484638282, "train/extr_return_rate": 0.8659932798872799, "train/extr_return_raw_mag": 0.7383147980739821, "train/extr_return_raw_max": 0.7383147980739821, "train/extr_return_raw_mean": 0.6123305385682121, "train/extr_return_raw_min": 0.5789232755181801, "train/extr_return_raw_std": 0.014755668574990473, "train/extr_reward_mag": 0.12074202032231574, "train/extr_reward_max": 0.12074202032231574, "train/extr_reward_mean": 0.002984433361926853, "train/extr_reward_min": 6.612853624334383e-07, "train/extr_reward_std": 0.008670686606308492, "train/image_loss_mean": 0.144463526520563, "train/image_loss_std": 0.10913870339073352, "train/model_loss_mean": 0.775416903827914, "train/model_loss_std": 0.4252963803745621, "train/model_opt_grad_norm": 28.8965605693077, "train/model_opt_grad_steps": 25067.427860696516, "train/model_opt_loss": 2246.178458294465, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2898.009950248756, "train/policy_entropy_mag": 1.524663460195361, "train/policy_entropy_max": 1.524663460195361, "train/policy_entropy_mean": 0.18364935853884587, "train/policy_entropy_min": 0.06469491598617971, "train/policy_entropy_std": 0.22392681278103027, "train/policy_logprob_mag": 6.551057495287995, "train/policy_logprob_max": -0.00860962769322431, "train/policy_logprob_mean": -0.1832548337641047, "train/policy_logprob_min": -6.551057495287995, "train/policy_logprob_std": 0.7195833607099542, "train/policy_randomness_mag": 0.7835220706403552, "train/policy_randomness_max": 0.7835220706403552, "train/policy_randomness_mean": 0.09437710613901935, "train/policy_randomness_min": 0.033246612037295724, "train/policy_randomness_std": 0.11507562421892413, "train/post_ent_mag": 106.54862820449753, "train/post_ent_max": 106.54862820449753, "train/post_ent_mean": 106.24544263241896, "train/post_ent_min": 105.98388288507414, "train/post_ent_std": 0.09675728892953835, "train/prior_ent_mag": 106.26701146215942, "train/prior_ent_max": 106.26701146215942, "train/prior_ent_mean": 104.54636994167348, "train/prior_ent_min": 103.20288158056155, "train/prior_ent_std": 0.48717542771083205, "train/rep_loss_mean": 1.0000113438611007, "train/rep_loss_std": 0.00035196133541459895, "train/reward_avg": 0.0005770099725208213, "train/reward_loss_mean": 0.0056663084443918064, "train/reward_loss_std": 0.12121836086984177, "train/reward_max_data": 0.4044465179467083, "train/reward_max_pred": 0.026489518768158717, "train/reward_neg_acc": 0.9999902672435513, "train/reward_neg_loss": 0.0008649560210204669, "train/reward_pos_acc": 0.008, "train/reward_pos_loss": 5.037155069351196, "train/reward_pred": 0.00042348534890464435, "train/reward_rate": 0.0009571284203980099, "train_stats/mean_log_entropy": 0.12967086158130528, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.03340219333767891, "report/cont_loss_std": 0.3923436403274536, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.049598693847656, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0038371854461729527, "report/cont_pred": 0.9961298704147339, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.12996923923492432, "report/image_loss_std": 0.09879867732524872, "report/model_loss_mean": 0.7682381868362427, "report/model_loss_std": 0.46879464387893677, "report/post_ent_mag": 107.73320007324219, "report/post_ent_max": 107.73320007324219, "report/post_ent_mean": 107.57909393310547, "report/post_ent_min": 107.42753601074219, "report/post_ent_std": 0.058982398360967636, "report/prior_ent_mag": 107.23741149902344, "report/prior_ent_max": 107.23741149902344, "report/prior_ent_mean": 105.87933349609375, "report/prior_ent_min": 104.46173858642578, "report/prior_ent_std": 0.458055704832077, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0004394531133584678, "report/reward_loss_mean": 0.0048667388036847115, "report/reward_loss_std": 0.14487144351005554, "report/reward_max_data": 0.44999998807907104, "report/reward_max_pred": 0.022162914276123047, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0003379577537998557, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.637809753417969, "report/reward_pred": 0.00018591189291328192, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.015860002487897873, "eval/cont_loss_std": 0.27118387818336487, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.1447343826293945, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.003866118611767888, "eval/cont_pred": 0.9961522221565247, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.19603192806243896, "eval/image_loss_std": 0.1278478056192398, "eval/model_loss_mean": 0.8119374513626099, "eval/model_loss_std": 0.29934635758399963, "eval/post_ent_mag": 107.728271484375, "eval/post_ent_max": 107.728271484375, "eval/post_ent_mean": 107.57331848144531, "eval/post_ent_min": 107.43504333496094, "eval/post_ent_std": 0.0587814599275589, "eval/prior_ent_mag": 107.39717102050781, "eval/prior_ent_max": 107.39717102050781, "eval/prior_ent_mean": 105.94593048095703, "eval/prior_ent_min": 104.7999038696289, "eval/prior_ent_std": 0.4406798481941223, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 4.5513734221458435e-05, "eval/reward_loss_std": 0.00038587694871239364, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0054416656494140625, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 4.5513734221458435e-05, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 2.0585255697369576e-05, "eval/reward_rate": 0.0, "replay/size": 418593.0, "replay/inserts": 32224.0, "replay/samples": 32224.0, "replay/insert_wait_avg": 1.8871055459076504e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.437653047207451e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 95136.0, "eval_replay/inserts": 6120.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1605764526167726e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.5367431640625e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 999.9760811328888, "timer/env.step_count": 4028.0, "timer/env.step_total": 37.833719968795776, "timer/env.step_frac": 0.03783462493016168, "timer/env.step_avg": 0.00939268122363351, "timer/env.step_min": 0.007593393325805664, "timer/env.step_max": 0.03529810905456543, "timer/replay._sample_count": 32224.0, "timer/replay._sample_total": 16.74984622001648, "timer/replay._sample_frac": 0.01675024686694537, "timer/replay._sample_avg": 0.0005197941354275224, "timer/replay._sample_min": 0.0003743171691894531, "timer/replay._sample_max": 0.020917892456054688, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4793.0, "timer/agent.policy_total": 49.495689868927, "timer/agent.policy_frac": 0.04949687377807332, "timer/agent.policy_avg": 0.010326661771109327, "timer/agent.policy_min": 0.008216619491577148, "timer/agent.policy_max": 0.12353229522705078, "timer/dataset_train_count": 2014.0, "timer/dataset_train_total": 0.27238893508911133, "timer/dataset_train_frac": 0.00027239545047969303, "timer/dataset_train_avg": 0.0001352477334106809, "timer/dataset_train_min": 9.393692016601562e-05, "timer/dataset_train_max": 0.05758380889892578, "timer/agent.train_count": 2014.0, "timer/agent.train_total": 896.0102140903473, "timer/agent.train_frac": 0.8960316461522191, "timer/agent.train_avg": 0.4448908709485339, "timer/agent.train_min": 0.43492960929870605, "timer/agent.train_max": 0.6616702079772949, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4696075916290283, "timer/agent.report_frac": 0.00046961882437928157, "timer/agent.report_avg": 0.23480379581451416, "timer/agent.report_min": 0.22513294219970703, "timer/agent.report_max": 0.2444746494293213, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.147125244140625e-05, "timer/dataset_eval_frac": 3.1472005216116735e-08, "timer/dataset_eval_avg": 3.147125244140625e-05, "timer/dataset_eval_min": 3.147125244140625e-05, "timer/dataset_eval_max": 3.147125244140625e-05, "fps": 32.224246950142316}
{"step": 419176, "time": 13226.88837981224, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 419344, "time": 13232.159624576569, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 419448, "time": 13235.071915626526, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 419520, "time": 13237.479405641556, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 419696, "time": 13242.792716264725, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 419912, "time": 13249.100052595139, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 420056, "time": 13255.068747282028, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 420056, "time": 13255.19675898552, "eval_episode/length": 87.0, "eval_episode/score": 0.7281249761581421, "eval_episode/reward_rate": 0.011363636363636364}
{"step": 420056, "time": 13255.467948675156, "eval_episode/length": 102.0, "eval_episode/score": 0.6812499761581421, "eval_episode/reward_rate": 0.009708737864077669}
{"step": 420056, "time": 13256.384512662888, "eval_episode/length": 49.0, "eval_episode/score": 0.846875011920929, "eval_episode/reward_rate": 0.02}
{"step": 420056, "time": 13256.41124844551, "eval_episode/length": 153.0, "eval_episode/score": 0.5218750238418579, "eval_episode/reward_rate": 0.006493506493506494}
{"step": 420056, "time": 13256.517069101334, "eval_episode/length": 158.0, "eval_episode/score": 0.5062500238418579, "eval_episode/reward_rate": 0.006289308176100629}
{"step": 420056, "time": 13256.704721212387, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 420056, "time": 13257.852422475815, "eval_episode/length": 60.0, "eval_episode/score": 0.8125, "eval_episode/reward_rate": 0.01639344262295082}
{"step": 420136, "time": 13260.334671258926, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 420368, "time": 13267.559985399246, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 420672, "time": 13276.74637746811, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 420808, "time": 13280.640824317932, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 421008, "time": 13286.993008613586, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 421064, "time": 13288.488967895508, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 421064, "time": 13288.498029232025, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 421240, "time": 13293.92182469368, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 421464, "time": 13300.712229728699, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 421680, "time": 13307.452631950378, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 422008, "time": 13317.271901369095, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 422224, "time": 13324.039748191833, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 422296, "time": 13325.999554157257, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 422664, "time": 13337.10965514183, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 422976, "time": 13346.807657718658, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 422984, "time": 13346.837136030197, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 423120, "time": 13351.160418272018, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 423376, "time": 13358.877790689468, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 423496, "time": 13362.29404425621, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 423552, "time": 13364.220626831055, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 423752, "time": 13370.033295631409, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 423800, "time": 13371.497577905655, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 424320, "time": 13387.51151418686, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 424320, "time": 13387.518718004227, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 424976, "time": 13407.475322723389, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 425232, "time": 13415.269975662231, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 425432, "time": 13421.11003613472, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 425536, "time": 13424.469831943512, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 425688, "time": 13428.841540336609, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 425808, "time": 13432.693968296051, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 425864, "time": 13434.176584005356, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 426056, "time": 13440.622746706009, "episode/length": 281.0, "episode/score": 0.12187500298023224, "episode/reward_rate": 0.0035460992907801418, "episode/intrinsic_return": 0.0}
{"step": 426160, "time": 13443.977173089981, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 426400, "time": 13451.27924990654, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 426664, "time": 13459.079878807068, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 426704, "time": 13460.538489818573, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 426752, "time": 13462.001087903976, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 426872, "time": 13465.527967453003, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 426888, "time": 13466.019701480865, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 427472, "time": 13483.99028301239, "episode/length": 222.0, "episode/score": 0.3062500059604645, "episode/reward_rate": 0.004484304932735426, "episode/intrinsic_return": 0.0}
{"step": 427640, "time": 13488.875903844833, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 427656, "time": 13489.368216753006, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 427744, "time": 13492.26346898079, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 427848, "time": 13495.364775657654, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 428640, "time": 13519.780770540237, "episode/length": 246.0, "episode/score": 0.23125000298023224, "episode/reward_rate": 0.004048582995951417, "episode/intrinsic_return": 0.0}
{"step": 428840, "time": 13525.789540052414, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 428960, "time": 13529.671598672867, "episode/length": 258.0, "episode/score": 0.19374999403953552, "episode/reward_rate": 0.003861003861003861, "episode/intrinsic_return": 0.0}
{"step": 429184, "time": 13536.467159748077, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 429328, "time": 13540.90397644043, "episode/length": 210.0, "episode/score": 0.34375, "episode/reward_rate": 0.004739336492890996, "episode/intrinsic_return": 0.0}
{"step": 429784, "time": 13554.665334939957, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 429840, "time": 13556.707255601883, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 429912, "time": 13558.684292554855, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 430032, "time": 13562.548122167587, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 430040, "time": 13562.576092481613, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 430040, "time": 13563.46608710289, "eval_episode/length": 44.0, "eval_episode/score": 0.862500011920929, "eval_episode/reward_rate": 0.022222222222222223}
{"step": 430040, "time": 13563.797671556473, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 430040, "time": 13563.976595640182, "eval_episode/length": 70.0, "eval_episode/score": 0.78125, "eval_episode/reward_rate": 0.014084507042253521}
{"step": 430040, "time": 13564.078429937363, "eval_episode/length": 75.0, "eval_episode/score": 0.765625, "eval_episode/reward_rate": 0.013157894736842105}
{"step": 430040, "time": 13564.163437843323, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 430040, "time": 13564.209517002106, "eval_episode/length": 81.0, "eval_episode/score": 0.746874988079071, "eval_episode/reward_rate": 0.012195121951219513}
{"step": 430040, "time": 13565.601588964462, "eval_episode/length": 41.0, "eval_episode/score": 0.871874988079071, "eval_episode/reward_rate": 0.023809523809523808}
{"step": 430040, "time": 13565.813005447388, "eval_episode/length": 132.0, "eval_episode/score": 0.5874999761581421, "eval_episode/reward_rate": 0.007518796992481203}
{"step": 430048, "time": 13566.282939195633, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 430056, "time": 13566.312594890594, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 430160, "time": 13569.676217556, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 430544, "time": 13581.290682315826, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 430544, "time": 13581.297955989838, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 430680, "time": 13585.330273151398, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 430912, "time": 13592.611967802048, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 430952, "time": 13593.608236789703, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 431120, "time": 13598.931426048279, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 431344, "time": 13605.726469755173, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 431408, "time": 13607.661083221436, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 431488, "time": 13610.095197439194, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 431520, "time": 13611.05737042427, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 431696, "time": 13616.492684364319, "episode/length": 207.0, "episode/score": 0.3531250059604645, "episode/reward_rate": 0.004807692307692308, "episode/intrinsic_return": 0.0}
{"step": 431760, "time": 13618.436267614365, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 431944, "time": 13623.781874418259, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 431984, "time": 13625.233917713165, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 432144, "time": 13630.070315361023, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 432472, "time": 13639.72998046875, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 432552, "time": 13642.164767980576, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 432784, "time": 13649.549100637436, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 432824, "time": 13650.547482967377, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 432856, "time": 13651.527783155441, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 433136, "time": 13660.35356259346, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 433464, "time": 13670.031169176102, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 433928, "time": 13684.173380851746, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 433968, "time": 13685.603472709656, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 434008, "time": 13686.59102845192, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 434072, "time": 13688.539204835892, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 434120, "time": 13690.34166932106, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 434256, "time": 13695.302477359772, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 434432, "time": 13700.731152534485, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 434456, "time": 13701.252336502075, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 434624, "time": 13706.748336315155, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 434648, "time": 13707.259613513947, "episode/length": 232.0, "episode/score": 0.2750000059604645, "episode/reward_rate": 0.004291845493562232, "episode/intrinsic_return": 0.0}
{"step": 434656, "time": 13707.727620601654, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 434984, "time": 13717.430269956589, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 435312, "time": 13727.597648620605, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 436048, "time": 13749.843943119049, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 436280, "time": 13756.614524126053, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 436648, "time": 13767.789499998093, "episode/length": 273.0, "episode/score": 0.14687499403953552, "episode/reward_rate": 0.0036496350364963502, "episode/intrinsic_return": 0.0}
{"step": 436744, "time": 13770.686383247375, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 436800, "time": 13772.611613750458, "episode/length": 226.0, "episode/score": 0.29374998807907104, "episode/reward_rate": 0.004405286343612335, "episode/intrinsic_return": 0.0}
{"step": 436936, "time": 13776.528242349625, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 436960, "time": 13777.482228755951, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 436968, "time": 13777.512068748474, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 437512, "time": 13793.942461967468, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 437680, "time": 13799.374462604523, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 437840, "time": 13804.2301466465, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 437896, "time": 13805.733452558517, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 437960, "time": 13807.667209863663, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 438184, "time": 13814.414098501205, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 438360, "time": 13819.761171579361, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 438488, "time": 13823.632758378983, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 438512, "time": 13824.603658676147, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 438592, "time": 13827.10300540924, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 438608, "time": 13827.592574119568, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 438696, "time": 13830.04018855095, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 438976, "time": 13838.719026088715, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 439320, "time": 13848.909566402435, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 439440, "time": 13852.747307777405, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 439680, "time": 13860.140950679779, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 439824, "time": 13865.836584329605, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 439888, "time": 13867.774712085724, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 439952, "time": 13869.733207702637, "episode/length": 198.0, "episode/score": 0.3812499940395355, "episode/reward_rate": 0.005025125628140704, "episode/intrinsic_return": 0.0}
{"step": 440024, "time": 13872.771008014679, "eval_episode/length": 59.0, "eval_episode/score": 0.815625011920929, "eval_episode/reward_rate": 0.016666666666666666}
{"step": 440024, "time": 13873.50846529007, "eval_episode/length": 100.0, "eval_episode/score": 0.6875, "eval_episode/reward_rate": 0.009900990099009901}
{"step": 440024, "time": 13874.052191972733, "eval_episode/length": 130.0, "eval_episode/score": 0.59375, "eval_episode/reward_rate": 0.007633587786259542}
{"step": 440024, "time": 13874.314110279083, "eval_episode/length": 144.0, "eval_episode/score": 0.550000011920929, "eval_episode/reward_rate": 0.006896551724137931}
{"step": 440024, "time": 13874.606740951538, "eval_episode/length": 160.0, "eval_episode/score": 0.5, "eval_episode/reward_rate": 0.006211180124223602}
{"step": 440024, "time": 13875.073298931122, "eval_episode/length": 185.0, "eval_episode/score": 0.421875, "eval_episode/reward_rate": 0.005376344086021506}
{"step": 440024, "time": 13875.61885213852, "eval_episode/length": 155.0, "eval_episode/score": 0.515625, "eval_episode/reward_rate": 0.00641025641025641}
{"step": 440024, "time": 13876.255880355835, "eval_episode/length": 149.0, "eval_episode/score": 0.534375011920929, "eval_episode/reward_rate": 0.006666666666666667}
{"step": 440744, "time": 13898.22414278984, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 440800, "time": 13900.169365406036, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 440824, "time": 13900.683463096619, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 440904, "time": 13903.11723780632, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 441144, "time": 13910.381847143173, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 441152, "time": 13910.85195350647, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 441568, "time": 13923.608073949814, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 441672, "time": 13926.530328273773, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 441960, "time": 13935.241015195847, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 441992, "time": 13936.214709758759, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 442056, "time": 13938.17564702034, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 442200, "time": 13942.540390729904, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 442528, "time": 13953.353730916977, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 442576, "time": 13954.835184574127, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 443112, "time": 13970.853302955627, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 443216, "time": 13974.233298778534, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 443464, "time": 13981.634887218475, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 443664, "time": 13987.910818815231, "episode/length": 182.0, "episode/score": 0.4312500059604645, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.0}
{"step": 444272, "time": 14006.40876030922, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 444304, "time": 14007.383577346802, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 444648, "time": 14017.555951833725, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 444840, "time": 14023.347214221954, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 444888, "time": 14024.804098129272, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 444936, "time": 14026.270024061203, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 445424, "time": 14041.299888134003, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 445528, "time": 14044.203726530075, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 445776, "time": 14051.920180559158, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 445840, "time": 14053.853520870209, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 445976, "time": 14057.749732971191, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 446048, "time": 14060.15979886055, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 446056, "time": 14060.18827366829, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 446168, "time": 14063.566781282425, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 446960, "time": 14087.746552705765, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 447200, "time": 14095.048510074615, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 447728, "time": 14111.045994997025, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 448088, "time": 14121.69664478302, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 448152, "time": 14123.650574207306, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 448288, "time": 14128.086568593979, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 448360, "time": 14130.040557384491, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 448368, "time": 14130.511148929596, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 448480, "time": 14133.917033195496, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 448904, "time": 14146.499862909317, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 449272, "time": 14157.753888368607, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 449616, "time": 14168.405590772629, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 450008, "time": 14180.669971466064, "eval_episode/length": 28.0, "eval_episode/score": 0.9125000238418579, "eval_episode/reward_rate": 0.034482758620689655}
{"step": 450008, "time": 14181.70762515068, "eval_episode/length": 84.0, "eval_episode/score": 0.737500011920929, "eval_episode/reward_rate": 0.011764705882352941}
{"step": 450008, "time": 14182.718693494797, "eval_episode/length": 138.0, "eval_episode/score": 0.5687500238418579, "eval_episode/reward_rate": 0.007194244604316547}
{"step": 450008, "time": 14185.548564195633, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 450008, "time": 14185.55777668953, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 450008, "time": 14185.564066171646, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 450008, "time": 14185.57045006752, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 450008, "time": 14185.576606988907, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 450040, "time": 14186.567476987839, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 450400, "time": 14197.773716926575, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 450600, "time": 14204.152295827866, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 450672, "time": 14206.562165737152, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 450680, "time": 14206.591368436813, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 450792, "time": 14209.968691587448, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 451257, "time": 14225.04378414154, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.7368874621035446, "train/action_min": 0.0, "train/action_std": 1.87198139660394, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.011699495136862926, "train/actor_opt_grad_steps": 27100.0, "train/actor_opt_loss": 6.319753646266772, "train/adv_mag": 0.4357060701099794, "train/adv_max": 0.2219607533507086, "train/adv_mean": 0.012954519860878503, "train/adv_min": -0.33033972622743296, "train/adv_std": 0.03325627555616608, "train/cont_avg": 0.9957828047263682, "train/cont_loss_mean": 0.022988586854513975, "train/cont_loss_std": 0.2984708029943616, "train/cont_neg_acc": 0.026853175200521946, "train/cont_neg_loss": 4.528455547690392, "train/cont_pos_acc": 0.9999414255369955, "train/cont_pos_loss": 0.004082877658636527, "train/cont_pred": 0.995819252225297, "train/cont_rate": 0.9957828047263682, "train/dyn_loss_mean": 1.0000085480770662, "train/dyn_loss_std": 0.00024390293560940679, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.852866614218894, "train/extr_critic_critic_opt_grad_steps": 27100.0, "train/extr_critic_critic_opt_loss": 9155.339286234841, "train/extr_critic_mag": 0.9245730857944015, "train/extr_critic_max": 0.9245730857944015, "train/extr_critic_mean": 0.8999443347774335, "train/extr_critic_min": 0.8544120723335304, "train/extr_critic_std": 0.012459328101567961, "train/extr_return_normed_mag": 0.4446572824497128, "train/extr_return_normed_max": 0.27666057075434064, "train/extr_return_normed_mean": 0.056527592602304055, "train/extr_return_normed_min": -0.2838879343289048, "train/extr_return_normed_std": 0.03732511017758826, "train/extr_return_rate": 0.9986111281523063, "train/extr_return_raw_mag": 1.1330318166248834, "train/extr_return_raw_max": 1.1330318166248834, "train/extr_return_raw_mean": 0.9128988913042628, "train/extr_return_raw_min": 0.572483311541638, "train/extr_return_raw_std": 0.03732511010345312, "train/extr_reward_mag": 0.23793864250183105, "train/extr_reward_max": 0.23793864250183105, "train/extr_reward_mean": 0.004367509335991857, "train/extr_reward_min": 5.711370439671758e-07, "train/extr_reward_std": 0.0174562917253123, "train/image_loss_mean": 0.13178654915806073, "train/image_loss_std": 0.10847438004479479, "train/model_loss_mean": 0.7618128627686951, "train/model_loss_std": 0.4155462174792195, "train/model_opt_grad_norm": 26.152197880531425, "train/model_opt_grad_steps": 27076.119402985074, "train/model_opt_loss": 3251.089295951881, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 4266.169154228855, "train/policy_entropy_mag": 1.4656503941882308, "train/policy_entropy_max": 1.4656503941882308, "train/policy_entropy_mean": 0.1762371215209439, "train/policy_entropy_min": 0.0646875161510795, "train/policy_entropy_std": 0.21491667672769346, "train/policy_logprob_mag": 6.551077482119129, "train/policy_logprob_max": -0.008608402156118137, "train/policy_logprob_mean": -0.17727751062432331, "train/policy_logprob_min": -6.551077482119129, "train/policy_logprob_std": 0.7136068376735668, "train/policy_randomness_mag": 0.7531953528152769, "train/policy_randomness_max": 0.7531953528152769, "train/policy_randomness_mean": 0.09056796924910736, "train/policy_randomness_min": 0.033242809238718515, "train/policy_randomness_std": 0.11044533098514993, "train/post_ent_mag": 107.44507875964416, "train/post_ent_max": 107.44507875964416, "train/post_ent_mean": 107.27397990819827, "train/post_ent_min": 107.09185783424188, "train/post_ent_std": 0.0604293348814421, "train/prior_ent_mag": 107.55341650360259, "train/prior_ent_max": 107.55341650360259, "train/prior_ent_mean": 106.28739515465884, "train/prior_ent_min": 105.00029477551209, "train/prior_ent_std": 0.40566587047790414, "train/rep_loss_mean": 1.0000085480770662, "train/rep_loss_std": 0.00024390293560940679, "train/reward_avg": 0.0007749946575973238, "train/reward_loss_mean": 0.007032577136058861, "train/reward_loss_std": 0.13763223219499576, "train/reward_max_data": 0.4846703969127503, "train/reward_max_pred": 0.04600876540093873, "train/reward_neg_acc": 0.9999951397008564, "train/reward_neg_loss": 0.001166241214667396, "train/reward_pos_acc": 0.04456264805709217, "train/reward_pos_loss": 4.697021828475574, "train/reward_pred": 0.0005938441206501862, "train/reward_rate": 0.0012437810945273632, "train_stats/mean_log_entropy": 0.137829287477902, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.022579582408070564, "report/cont_loss_std": 0.3004407584667206, "report/cont_neg_acc": 0.20000000298023224, "report/cont_neg_loss": 3.8206288814544678, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.003943421877920628, "report/cont_pred": 0.9953860640525818, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.1240786761045456, "report/image_loss_std": 0.10446062684059143, "report/model_loss_mean": 0.7557330131530762, "report/model_loss_std": 0.4986215829849243, "report/post_ent_mag": 106.66456604003906, "report/post_ent_max": 106.66456604003906, "report/post_ent_mean": 106.52197265625, "report/post_ent_min": 106.36634826660156, "report/post_ent_std": 0.05684014409780502, "report/prior_ent_mag": 107.11308288574219, "report/prior_ent_max": 107.11308288574219, "report/prior_ent_mean": 105.5196533203125, "report/prior_ent_min": 103.80039978027344, "report/prior_ent_std": 0.5883297324180603, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0002807617129292339, "report/reward_loss_mean": 0.009074775502085686, "report/reward_loss_std": 0.2478288859128952, "report/reward_max_data": 0.2874999940395355, "report/reward_max_pred": 0.04076123237609863, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0013298876583576202, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 7.932096004486084, "report/reward_pred": 0.0006545877549797297, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.02947574108839035, "eval/cont_loss_std": 0.4286898076534271, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.866332054138184, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.0026645364705473185, "eval/cont_pred": 0.9973745346069336, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.24446594715118408, "eval/image_loss_std": 0.15191981196403503, "eval/model_loss_mean": 0.8740557432174683, "eval/model_loss_std": 0.45367559790611267, "eval/post_ent_mag": 106.72078704833984, "eval/post_ent_max": 106.72078704833984, "eval/post_ent_mean": 106.51510620117188, "eval/post_ent_min": 106.34489440917969, "eval/post_ent_std": 0.05954936519265175, "eval/prior_ent_mag": 107.22185516357422, "eval/prior_ent_max": 107.22185516357422, "eval/prior_ent_mean": 105.47206115722656, "eval/prior_ent_min": 103.50324249267578, "eval/prior_ent_std": 0.5957111120223999, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00011399993672966957, "eval/reward_loss_std": 0.0016582324169576168, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.024429798126220703, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00011399993672966957, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 5.495257209986448e-05, "eval/reward_rate": 0.0, "replay/size": 450753.0, "replay/inserts": 32160.0, "replay/samples": 32160.0, "replay/insert_wait_avg": 1.334795607856257e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.536956796598671e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 7216.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1691299087456747e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.685754776000977e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4368634223938, "timer/env.step_count": 4020.0, "timer/env.step_total": 37.988998889923096, "timer/env.step_frac": 0.03797241013287591, "timer/env.step_avg": 0.009449999723861466, "timer/env.step_min": 0.007469654083251953, "timer/env.step_max": 0.04165482521057129, "timer/replay._sample_count": 32160.0, "timer/replay._sample_total": 16.72226047515869, "timer/replay._sample_frac": 0.016714958321261294, "timer/replay._sample_avg": 0.0005199707859191136, "timer/replay._sample_min": 0.00041222572326660156, "timer/replay._sample_max": 0.02752971649169922, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4922.0, "timer/agent.policy_total": 51.38705921173096, "timer/agent.policy_frac": 0.05136461988809669, "timer/agent.policy_avg": 0.010440280213679593, "timer/agent.policy_min": 0.008248090744018555, "timer/agent.policy_max": 0.08427548408508301, "timer/dataset_train_count": 2010.0, "timer/dataset_train_total": 0.21824073791503906, "timer/dataset_train_frac": 0.00021814543815234824, "timer/dataset_train_avg": 0.00010857748154977068, "timer/dataset_train_min": 9.226799011230469e-05, "timer/dataset_train_max": 0.00035452842712402344, "timer/agent.train_count": 2010.0, "timer/agent.train_total": 896.6429789066315, "timer/agent.train_frac": 0.8962514394354744, "timer/agent.train_avg": 0.4460910342819062, "timer/agent.train_min": 0.4355332851409912, "timer/agent.train_max": 1.7393684387207031, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4705491065979004, "timer/agent.report_frac": 0.0004703436306697049, "timer/agent.report_avg": 0.2352745532989502, "timer/agent.report_min": 0.22376108169555664, "timer/agent.report_max": 0.24678802490234375, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9802322387695312e-05, "timer/dataset_eval_frac": 2.978930852842084e-08, "timer/dataset_eval_avg": 2.9802322387695312e-05, "timer/dataset_eval_min": 2.9802322387695312e-05, "timer/dataset_eval_max": 2.9802322387695312e-05, "fps": 32.1454368733099}
{"step": 451584, "time": 14234.89728140831, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 451928, "time": 14245.207631587982, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 452352, "time": 14258.349730014801, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 452712, "time": 14269.074000120163, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 452912, "time": 14275.522247552872, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 452984, "time": 14277.493554353714, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 452992, "time": 14277.969275951385, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 453104, "time": 14281.396227121353, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 453896, "time": 14305.330748319626, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 454240, "time": 14315.950600385666, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 454664, "time": 14328.569610357285, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 455024, "time": 14339.70777630806, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 455224, "time": 14345.499005556107, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 455296, "time": 14347.879555225372, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 455304, "time": 14347.908493757248, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 455416, "time": 14351.284685611725, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 456208, "time": 14375.395931959152, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 456552, "time": 14385.496203899384, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 456976, "time": 14398.49067902565, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 457280, "time": 14407.621637105942, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 457336, "time": 14409.087889909744, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 457536, "time": 14415.29796385765, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 457608, "time": 14417.261752843857, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 457616, "time": 14417.7260055542, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 457728, "time": 14421.098293066025, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 458520, "time": 14444.8279337883, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 458864, "time": 14456.039234638214, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 459592, "time": 14477.798248291016, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 459648, "time": 14479.726760864258, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 459848, "time": 14485.621873617172, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 459920, "time": 14490.235838651657, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 459928, "time": 14490.267002105713, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 460040, "time": 14493.720799684525, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 460096, "time": 14501.051034212112, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 460096, "time": 14501.058833122253, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 460096, "time": 14501.066811084747, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 460096, "time": 14501.073597669601, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 460096, "time": 14501.080342769623, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 460096, "time": 14501.087125778198, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 460096, "time": 14501.093691825867, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 460096, "time": 14501.100279808044, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 460832, "time": 14523.45878648758, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 461176, "time": 14533.60615849495, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 461520, "time": 14544.202585220337, "episode/length": 208.0, "episode/score": 0.3499999940395355, "episode/reward_rate": 0.004784688995215311, "episode/intrinsic_return": 0.0}
{"step": 461904, "time": 14555.932836771011, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 461960, "time": 14557.416018486023, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 462224, "time": 14565.593763589859, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 462232, "time": 14565.622042179108, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 462240, "time": 14566.089935064316, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 462352, "time": 14569.47245979309, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 463144, "time": 14593.165266752243, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 463488, "time": 14603.75398015976, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 463832, "time": 14613.996297597885, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 464272, "time": 14627.533961057663, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 464536, "time": 14635.364429712296, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 464544, "time": 14635.830627441406, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 464552, "time": 14635.859838724136, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 464664, "time": 14639.26076078415, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 465456, "time": 14663.349718093872, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 465800, "time": 14673.570473194122, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 466144, "time": 14684.117913007736, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 466584, "time": 14697.303698539734, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 466848, "time": 14705.523773670197, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 466856, "time": 14705.555686712265, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 466864, "time": 14706.029477119446, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 466976, "time": 14709.910720825195, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 467768, "time": 14733.753696918488, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 468112, "time": 14744.372539758682, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 468456, "time": 14754.543287277222, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 468896, "time": 14768.113955497742, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 469160, "time": 14775.881865024567, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 469168, "time": 14776.351961135864, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 469176, "time": 14776.381526708603, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 469288, "time": 14779.778671979904, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 470080, "time": 14803.904482364655, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 470080, "time": 14809.647442817688, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 470080, "time": 14809.661355257034, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 470080, "time": 14809.668236494064, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 470080, "time": 14809.674769639969, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 470080, "time": 14809.681099891663, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 470080, "time": 14809.68739938736, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 470080, "time": 14809.693509340286, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 470080, "time": 14809.700956821442, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 470424, "time": 14819.905067682266, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 470768, "time": 14830.46629166603, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 471208, "time": 14843.500677585602, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 471472, "time": 14851.798085212708, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 471480, "time": 14851.827214717865, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 471488, "time": 14852.29770040512, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 471600, "time": 14855.664486408234, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 472392, "time": 14879.383219718933, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 472736, "time": 14889.965149879456, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 473080, "time": 14900.175245046616, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 473520, "time": 14913.796621799469, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 473784, "time": 14921.539994955063, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 473792, "time": 14922.009746074677, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 473800, "time": 14922.038948059082, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 473912, "time": 14925.43685221672, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 474704, "time": 14949.655182600021, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 475048, "time": 14959.820714473724, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 475392, "time": 14971.075142621994, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 475832, "time": 14984.136763572693, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 476096, "time": 14992.299184799194, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 476104, "time": 14992.33018898964, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 476112, "time": 14992.818660736084, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 476224, "time": 14996.304811954498, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 477016, "time": 15020.030370235443, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 477360, "time": 15030.707091093063, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 477704, "time": 15040.881158828735, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 478144, "time": 15054.440962314606, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 478408, "time": 15062.319882154465, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 478416, "time": 15062.8000395298, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 478424, "time": 15062.8309841156, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 478536, "time": 15066.273524284363, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 479328, "time": 15090.539710998535, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 479672, "time": 15100.675546884537, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 480016, "time": 15111.275454044342, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 480064, "time": 15118.198724269867, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 480064, "time": 15118.231321811676, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 480064, "time": 15118.254895687103, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 480064, "time": 15118.266694784164, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 480064, "time": 15118.28099656105, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 480064, "time": 15118.293341636658, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 480064, "time": 15118.302745819092, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 480064, "time": 15118.316893339157, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 480456, "time": 15129.937911748886, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 480720, "time": 15138.165434837341, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 480728, "time": 15138.195916175842, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 480736, "time": 15138.669383525848, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 480848, "time": 15142.106377840042, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 481640, "time": 15165.928239822388, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 481984, "time": 15176.60125041008, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 482328, "time": 15186.771394491196, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 482768, "time": 15200.297806024551, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 483032, "time": 15208.18173456192, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 483040, "time": 15208.650125980377, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 483048, "time": 15208.678689718246, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 483160, "time": 15212.071701049805, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 483545, "time": 15225.095208883286, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.1529967053101795, "train/action_min": 0.0, "train/action_std": 1.5428443993672285, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.007322784044115924, "train/actor_opt_grad_steps": 29115.0, "train/actor_opt_loss": -18.26338072836694, "train/adv_mag": 0.5907278001898586, "train/adv_max": 0.19748995740814965, "train/adv_mean": -0.007720313115275377, "train/adv_min": -0.5492183034962946, "train/adv_std": 0.02031193960845323, "train/cont_avg": 0.9955667930074258, "train/cont_loss_mean": 0.020245646418182935, "train/cont_loss_std": 0.2768548974527581, "train/cont_neg_acc": 0.15167963541675322, "train/cont_neg_loss": 3.7770957479825116, "train/cont_pos_acc": 0.999873702478881, "train/cont_pos_loss": 0.0035616200766526163, "train/cont_pred": 0.9958569233370299, "train/cont_rate": 0.9955667930074258, "train/dyn_loss_mean": 1.0000095084162042, "train/dyn_loss_std": 0.0002753431605501331, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.22789070347674412, "train/extr_critic_critic_opt_grad_steps": 29115.0, "train/extr_critic_critic_opt_loss": 9898.627449866568, "train/extr_critic_mag": 0.9553377994216314, "train/extr_critic_max": 0.9553377994216314, "train/extr_critic_mean": 0.8994827078710689, "train/extr_critic_min": 0.8607218318646497, "train/extr_critic_std": 0.013087463290845551, "train/extr_return_normed_mag": 0.5912497595395192, "train/extr_return_normed_max": 0.2512233316308201, "train/extr_return_normed_mean": 0.010989676290096619, "train/extr_return_normed_min": -0.5262956377303246, "train/extr_return_normed_std": 0.025565759509359257, "train/extr_return_rate": 0.9993847655777884, "train/extr_return_raw_mag": 1.131996056526014, "train/extr_return_raw_max": 1.131996056526014, "train/extr_return_raw_mean": 0.8917624531405988, "train/extr_return_raw_min": 0.3544770871648694, "train/extr_return_raw_std": 0.02556575944020164, "train/extr_reward_mag": 0.2556668047857757, "train/extr_reward_max": 0.2556668047857757, "train/extr_reward_mean": 0.0005518162456340151, "train/extr_reward_min": 3.5644757865679146e-07, "train/extr_reward_std": 0.006063964418746476, "train/image_loss_mean": 0.12378430137834927, "train/image_loss_std": 0.10828404751892137, "train/model_loss_mean": 0.7506916281020287, "train/model_loss_std": 0.3966422298978461, "train/model_opt_grad_norm": 26.0339298012233, "train/model_opt_grad_steps": 29089.688118811882, "train/model_opt_loss": 3445.0242049717667, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 4591.584158415842, "train/policy_entropy_mag": 1.3133744880704596, "train/policy_entropy_max": 1.3133744880704596, "train/policy_entropy_mean": 0.19262212109152632, "train/policy_entropy_min": 0.06468672375425254, "train/policy_entropy_std": 0.2139694389730397, "train/policy_logprob_mag": 6.551080238701093, "train/policy_logprob_max": -0.00860826208228522, "train/policy_logprob_mean": -0.1919759303183839, "train/policy_logprob_min": -6.551080238701093, "train/policy_logprob_std": 0.7051147293336321, "train/policy_randomness_mag": 0.6749410118797038, "train/policy_randomness_max": 0.6749410118797038, "train/policy_randomness_mean": 0.0989881940923705, "train/policy_randomness_min": 0.03324240239539949, "train/policy_randomness_std": 0.10995854677097631, "train/post_ent_mag": 100.74552709749429, "train/post_ent_max": 100.74552709749429, "train/post_ent_mean": 100.45491435740254, "train/post_ent_min": 100.14602857533067, "train/post_ent_std": 0.09619987160336263, "train/prior_ent_mag": 102.03170062527798, "train/prior_ent_max": 102.03170062527798, "train/prior_ent_mean": 99.5221397097748, "train/prior_ent_min": 97.24227486034431, "train/prior_ent_std": 0.7724682986736298, "train/rep_loss_mean": 1.0000095084162042, "train/rep_loss_std": 0.0002753431605501331, "train/reward_avg": 0.0007500978976131952, "train/reward_loss_mean": 0.006655953115654537, "train/reward_loss_std": 0.13648719837863718, "train/reward_max_data": 0.4922957906481063, "train/reward_max_pred": 0.0662361719820759, "train/reward_neg_acc": 0.9999564552661215, "train/reward_neg_loss": 0.0010392444819084595, "train/reward_pos_acc": 0.07319819846668758, "train/reward_pos_loss": 4.633545604106542, "train/reward_pred": 0.0005368709991833583, "train/reward_rate": 0.0012134514232673267, "train_stats/mean_log_entropy": 0.18629441259984383, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.02416706085205078, "report/cont_loss_std": 0.34412142634391785, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.3081560134887695, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.003445536596700549, "report/cont_pred": 0.9965600967407227, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.11598145961761475, "report/image_loss_std": 0.09234946966171265, "report/model_loss_mean": 0.75177001953125, "report/model_loss_std": 0.5249726176261902, "report/post_ent_mag": 89.2210464477539, "report/post_ent_max": 89.2210464477539, "report/post_ent_mean": 88.66822052001953, "report/post_ent_min": 88.10018920898438, "report/post_ent_std": 0.1744680404663086, "report/prior_ent_mag": 92.32662963867188, "report/prior_ent_max": 92.32662963867188, "report/prior_ent_mean": 88.85368347167969, "report/prior_ent_min": 86.14532470703125, "report/prior_ent_std": 0.9624103307723999, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0013793945545330644, "report/reward_loss_mean": 0.011621452867984772, "report/reward_loss_std": 0.236153244972229, "report/reward_max_data": 0.7406250238418579, "report/reward_max_pred": 0.05908536911010742, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0012911207741126418, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 5.290421485900879, "report/reward_pred": 0.0006361356936395168, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.02635578252375126, "eval/cont_loss_std": 0.42756736278533936, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 7.874196529388428, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.003296507056802511, "eval/cont_pred": 0.9968605041503906, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2606067359447479, "eval/image_loss_std": 0.14512090384960175, "eval/model_loss_mean": 0.8964711427688599, "eval/model_loss_std": 0.6683710813522339, "eval/post_ent_mag": 89.2635269165039, "eval/post_ent_max": 89.2635269165039, "eval/post_ent_mean": 88.64718627929688, "eval/post_ent_min": 88.13727569580078, "eval/post_ent_std": 0.19290021061897278, "eval/prior_ent_mag": 92.58880615234375, "eval/prior_ent_max": 92.58880615234375, "eval/prior_ent_mean": 88.85907745361328, "eval/prior_ent_min": 85.79476928710938, "eval/prior_ent_std": 1.0841439962387085, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.00014038085646461695, "eval/reward_loss_mean": 0.00950860045850277, "eval/reward_loss_std": 0.3009698688983917, "eval/reward_max_data": 0.14374999701976776, "eval/reward_max_pred": 0.006857872009277344, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 9.87281309789978e-05, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 9.635807991027832, "eval/reward_pred": 4.621688276529312e-05, "eval/reward_rate": 0.0009765625, "replay/size": 483041.0, "replay/inserts": 32288.0, "replay/samples": 32288.0, "replay/insert_wait_avg": 1.3499285350115258e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.410442808810972e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1261290469934096e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0132789611816406e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.035894870758, "timer/env.step_count": 4036.0, "timer/env.step_total": 37.89557123184204, "timer/env.step_frac": 0.037894211024034855, "timer/env.step_avg": 0.00938938831314223, "timer/env.step_min": 0.0076160430908203125, "timer/env.step_max": 0.035680294036865234, "timer/replay._sample_count": 32288.0, "timer/replay._sample_total": 16.718074083328247, "timer/replay._sample_frac": 0.016717474011759194, "timer/replay._sample_avg": 0.0005177797969316231, "timer/replay._sample_min": 0.0003819465637207031, "timer/replay._sample_max": 0.022469282150268555, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4903.0, "timer/agent.policy_total": 50.764636278152466, "timer/agent.policy_frac": 0.05076281415349911, "timer/agent.policy_avg": 0.01035379079709412, "timer/agent.policy_min": 0.008866071701049805, "timer/agent.policy_max": 0.08373165130615234, "timer/dataset_train_count": 2018.0, "timer/dataset_train_total": 0.21656012535095215, "timer/dataset_train_frac": 0.00021655235223225642, "timer/dataset_train_avg": 0.00010731423456439651, "timer/dataset_train_min": 9.393692016601562e-05, "timer/dataset_train_max": 0.00040268898010253906, "timer/agent.train_count": 2018.0, "timer/agent.train_total": 895.7032930850983, "timer/agent.train_frac": 0.8956711430851755, "timer/agent.train_avg": 0.44385693413533117, "timer/agent.train_min": 0.43270397186279297, "timer/agent.train_max": 0.6945688724517822, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47629308700561523, "timer/agent.report_frac": 0.0004762759911404681, "timer/agent.report_avg": 0.23814654350280762, "timer/agent.report_min": 0.23189067840576172, "timer/agent.report_max": 0.24440240859985352, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.337860107421875e-05, "timer/dataset_eval_frac": 3.3377402996651945e-08, "timer/dataset_eval_avg": 3.337860107421875e-05, "timer/dataset_eval_min": 3.337860107421875e-05, "timer/dataset_eval_max": 3.337860107421875e-05, "fps": 32.286270869895986}
{"step": 483952, "time": 15237.427942037582, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 484296, "time": 15247.580598592758, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 484640, "time": 15258.189374685287, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 485080, "time": 15271.4280834198, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 485344, "time": 15279.687069416046, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 485352, "time": 15279.717570781708, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 485360, "time": 15280.193544149399, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 485472, "time": 15283.621381282806, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 486264, "time": 15307.631296396255, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 486608, "time": 15318.26852965355, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 486952, "time": 15328.525668621063, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 487128, "time": 15333.866575479507, "episode/length": 21.0, "episode/score": 0.934374988079071, "episode/reward_rate": 0.045454545454545456, "episode/intrinsic_return": 0.0}
{"step": 487392, "time": 15342.12945652008, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 487656, "time": 15349.97957611084, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 487664, "time": 15350.453510046005, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 487672, "time": 15350.484006643295, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 487784, "time": 15353.872835636139, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 488272, "time": 15369.025030851364, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 488576, "time": 15378.18858551979, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 488688, "time": 15381.586877346039, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 488920, "time": 15388.502230405807, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 489272, "time": 15399.157134532928, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 489440, "time": 15404.484272003174, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 489912, "time": 15418.679564476013, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 489944, "time": 15419.646786689758, "episode/length": 285.0, "episode/score": 0.109375, "episode/reward_rate": 0.0034965034965034965, "episode/intrinsic_return": 0.0}
{"step": 489976, "time": 15420.620283126831, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 490048, "time": 15424.781504392624, "eval_episode/length": 89.0, "eval_episode/score": 0.721875011920929, "eval_episode/reward_rate": 0.011111111111111112}
{"step": 490048, "time": 15425.37937951088, "eval_episode/length": 118.0, "eval_episode/score": 0.6312500238418579, "eval_episode/reward_rate": 0.008403361344537815}
{"step": 490048, "time": 15426.363149166107, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 490048, "time": 15426.52901005745, "eval_episode/length": 175.0, "eval_episode/score": 0.453125, "eval_episode/reward_rate": 0.005681818181818182}
{"step": 490048, "time": 15426.536330461502, "eval_episode/length": 175.0, "eval_episode/score": 0.453125, "eval_episode/reward_rate": 0.005681818181818182}
{"step": 490048, "time": 15427.621571302414, "eval_episode/length": 228.0, "eval_episode/score": 0.2874999940395355, "eval_episode/reward_rate": 0.004366812227074236}
{"step": 490048, "time": 15428.837934732437, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 490048, "time": 15428.846733808517, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 490048, "time": 15428.853986501694, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 490584, "time": 15444.784885168076, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 490888, "time": 15454.04215312004, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 491232, "time": 15464.595616817474, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 491528, "time": 15473.468663692474, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 491584, "time": 15475.780038118362, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 491752, "time": 15480.61507678032, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 492032, "time": 15489.254786491394, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 492224, "time": 15495.027290821075, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 492256, "time": 15495.990478277206, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 492288, "time": 15496.979507446289, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 492768, "time": 15511.689820766449, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 493200, "time": 15524.759200811386, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 493544, "time": 15534.9838078022, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 493840, "time": 15544.215375185013, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 493896, "time": 15545.704776525497, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 494344, "time": 15559.322988033295, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 494536, "time": 15565.280513048172, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 494568, "time": 15566.252462863922, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 495080, "time": 15581.678713321686, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 495512, "time": 15594.745945453644, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 495816, "time": 15604.042251348495, "episode/length": 239.0, "episode/score": 0.25312501192092896, "episode/reward_rate": 0.004166666666666667, "episode/intrinsic_return": 0.0}
{"step": 495856, "time": 15605.477068185806, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 495976, "time": 15608.893225431442, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 496152, "time": 15614.205996274948, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 496464, "time": 15623.87147450447, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 496656, "time": 15629.77887558937, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 496880, "time": 15636.554612398148, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 496976, "time": 15639.467130422592, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 497048, "time": 15641.427559614182, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 497392, "time": 15652.068066120148, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 497544, "time": 15656.540082931519, "episode/length": 195.0, "episode/score": 0.390625, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.0}
{"step": 497560, "time": 15657.050194263458, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 497824, "time": 15665.236876487732, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 497888, "time": 15667.183949708939, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 498392, "time": 15682.17344903946, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 498464, "time": 15684.56388258934, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 498760, "time": 15693.334770441055, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 498920, "time": 15698.162402629852, "episode/length": 242.0, "episode/score": 0.24375000596046448, "episode/reward_rate": 0.00411522633744856, "episode/intrinsic_return": 0.0}
{"step": 498960, "time": 15699.58346414566, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 498992, "time": 15700.570669174194, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 499216, "time": 15707.307096004486, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 499360, "time": 15711.640318155289, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 499368, "time": 15711.670545339584, "episode/length": 225.0, "episode/score": 0.296875, "episode/reward_rate": 0.004424778761061947, "episode/intrinsic_return": 0.0}
{"step": 499704, "time": 15721.86699962616, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 499960, "time": 15730.075606107712, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 499984, "time": 15731.033595323563, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 500032, "time": 15733.86838722229, "eval_episode/length": 76.0, "eval_episode/score": 0.762499988079071, "eval_episode/reward_rate": 0.012987012987012988}
{"step": 500032, "time": 15733.933238744736, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 500032, "time": 15733.960058927536, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 500032, "time": 15734.151136636734, "eval_episode/length": 90.0, "eval_episode/score": 0.71875, "eval_episode/reward_rate": 0.01098901098901099}
{"step": 500032, "time": 15734.5802090168, "eval_episode/length": 114.0, "eval_episode/score": 0.643750011920929, "eval_episode/reward_rate": 0.008695652173913044}
{"step": 500032, "time": 15734.769959688187, "eval_episode/length": 124.0, "eval_episode/score": 0.612500011920929, "eval_episode/reward_rate": 0.008}
{"step": 500032, "time": 15735.056843996048, "eval_episode/length": 49.0, "eval_episode/score": 0.846875011920929, "eval_episode/reward_rate": 0.02}
{"step": 500032, "time": 15735.66558766365, "eval_episode/length": 97.0, "eval_episode/score": 0.6968749761581421, "eval_episode/reward_rate": 0.01020408163265306}
{"step": 500088, "time": 15737.135454893112, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 500136, "time": 15738.604121208191, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 500624, "time": 15753.62716293335, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 500632, "time": 15753.655184745789, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 500856, "time": 15760.402512311935, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 501168, "time": 15770.07572722435, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 501272, "time": 15773.000368118286, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 501304, "time": 15773.972277641296, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 501528, "time": 15780.848189353943, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 501656, "time": 15784.712604284286, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 501744, "time": 15787.597886562347, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 501880, "time": 15791.487298965454, "episode/length": 239.0, "episode/score": 0.25312501192092896, "episode/reward_rate": 0.004166666666666667, "episode/intrinsic_return": 0.0}
{"step": 501952, "time": 15793.871141433716, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 502072, "time": 15797.281477689743, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 502448, "time": 15808.922669172287, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 502568, "time": 15812.339433431625, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 502688, "time": 15816.19946193695, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 502864, "time": 15821.508033037186, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 502920, "time": 15822.98590540886, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 502936, "time": 15823.479006052017, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 502944, "time": 15823.95063495636, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 503248, "time": 15833.13638806343, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 503256, "time": 15833.163401603699, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 503456, "time": 15839.478311300278, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 503496, "time": 15840.481992721558, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 503856, "time": 15851.552500724792, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 503968, "time": 15854.941061735153, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 504032, "time": 15856.877725601196, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 504272, "time": 15864.178302526474, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 504296, "time": 15864.697046756744, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 504384, "time": 15867.769830703735, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 504520, "time": 15871.733423948288, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 504672, "time": 15876.56798696518, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 504784, "time": 15879.973784446716, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 504976, "time": 15885.789160728455, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 504984, "time": 15885.816553592682, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 505160, "time": 15891.129677772522, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 505472, "time": 15900.862819433212, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 505568, "time": 15903.770939588547, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 505648, "time": 15906.1635825634, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 505816, "time": 15911.010775566101, "episode/length": 20.0, "episode/score": 0.9375, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.0}
{"step": 505896, "time": 15913.425111055374, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 505912, "time": 15913.911278247833, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 506168, "time": 15921.605365753174, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 506288, "time": 15925.518865346909, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 506520, "time": 15932.28083729744, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 506536, "time": 15932.766860485077, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 506696, "time": 15937.604895591736, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 506912, "time": 15944.322107076645, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 506952, "time": 15945.303900718689, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 506960, "time": 15945.770873785019, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 507016, "time": 15947.250822782516, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 507096, "time": 15949.660871505737, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 507288, "time": 15955.525799512863, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 507408, "time": 15959.354041099548, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 507576, "time": 15964.194650411606, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 507696, "time": 15968.048963785172, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 507720, "time": 15968.563448667526, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 507864, "time": 15972.905788898468, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 507896, "time": 15973.870864868164, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 507928, "time": 15975.308205366135, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 508040, "time": 15979.431457281113, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 508264, "time": 15986.29660487175, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 508304, "time": 15987.752097606659, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 508408, "time": 15990.667479276657, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 508656, "time": 15998.390630722046, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 508848, "time": 16004.187414884567, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 509064, "time": 16010.46818971634, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 509224, "time": 16015.422241687775, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 509288, "time": 16017.380422592163, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 509544, "time": 16025.114157438278, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 509760, "time": 16031.86075592041, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 509792, "time": 16032.82963013649, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 509888, "time": 16035.740983247757, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 510008, "time": 16039.136041641235, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 510016, "time": 16040.69187426567, "eval_episode/length": 59.0, "eval_episode/score": 0.815625011920929, "eval_episode/reward_rate": 0.016666666666666666}
{"step": 510016, "time": 16041.090009450912, "eval_episode/length": 81.0, "eval_episode/score": 0.746874988079071, "eval_episode/reward_rate": 0.012195121951219513}
{"step": 510016, "time": 16041.202691316605, "eval_episode/length": 87.0, "eval_episode/score": 0.7281249761581421, "eval_episode/reward_rate": 0.011363636363636364}
{"step": 510016, "time": 16041.556471824646, "eval_episode/length": 107.0, "eval_episode/score": 0.6656249761581421, "eval_episode/reward_rate": 0.009259259259259259}
{"step": 510016, "time": 16041.93300819397, "eval_episode/length": 40.0, "eval_episode/score": 0.875, "eval_episode/reward_rate": 0.024390243902439025}
{"step": 510016, "time": 16042.115777492523, "eval_episode/length": 138.0, "eval_episode/score": 0.5687500238418579, "eval_episode/reward_rate": 0.007194244604316547}
{"step": 510016, "time": 16043.357712745667, "eval_episode/length": 172.0, "eval_episode/score": 0.4625000059604645, "eval_episode/reward_rate": 0.005780346820809248}
{"step": 510016, "time": 16043.670056819916, "eval_episode/length": 50.0, "eval_episode/score": 0.84375, "eval_episode/reward_rate": 0.0196078431372549}
{"step": 510048, "time": 16044.65356707573, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 510144, "time": 16047.669531106949, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 510192, "time": 16049.146955251694, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 510352, "time": 16054.01253604889, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 510512, "time": 16058.851483345032, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 510616, "time": 16061.765942335129, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 510616, "time": 16061.773041009903, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 511016, "time": 16073.83695268631, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 511032, "time": 16074.324034929276, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 511088, "time": 16076.307711362839, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 511192, "time": 16079.229311466217, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 511248, "time": 16081.127283334732, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 511368, "time": 16084.514585256577, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 511512, "time": 16088.861129522324, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 511752, "time": 16096.073224067688, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 511776, "time": 16097.017283916473, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 511832, "time": 16098.49977684021, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 512072, "time": 16105.835142374039, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 512288, "time": 16112.582503318787, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 512432, "time": 16116.914714813232, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 512448, "time": 16117.399420261383, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 512744, "time": 16126.0683760643, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 512792, "time": 16127.52688407898, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 512824, "time": 16128.491975545883, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 512920, "time": 16131.399502277374, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 512984, "time": 16133.335438489914, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 513280, "time": 16142.582832098007, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 513328, "time": 16144.029593706131, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 513360, "time": 16144.99817609787, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 513504, "time": 16149.354104757309, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 513504, "time": 16149.361427307129, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 513672, "time": 16154.218568325043, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 513760, "time": 16157.108048439026, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 513976, "time": 16163.390040397644, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 514088, "time": 16166.894464731216, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 514280, "time": 16172.706586122513, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 514480, "time": 16178.991902828217, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 514600, "time": 16182.404788017273, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 514760, "time": 16187.25299501419, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 514760, "time": 16187.259952068329, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 514984, "time": 16194.048630952835, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 515040, "time": 16196.041939258575, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 515168, "time": 16199.898981809616, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 515400, "time": 16206.628272771835, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 515472, "time": 16209.019170284271, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 515600, "time": 16212.86482834816, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 515816, "time": 16219.212042808533, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 515848, "time": 16220.179912805557, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 515993, "time": 16225.556276321411, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.796834710783559, "train/action_min": 0.0, "train/action_std": 1.9253918954304285, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.010513618446225897, "train/actor_opt_grad_steps": 31140.0, "train/actor_opt_loss": -4.280559237167845, "train/adv_mag": 0.7882122764446465, "train/adv_max": 0.3119167973255289, "train/adv_mean": 0.005397484783997032, "train/adv_min": -0.7626039262475639, "train/adv_std": 0.03515643763167811, "train/cont_avg": 0.9957762469211823, "train/cont_loss_mean": 0.016176274721854792, "train/cont_loss_std": 0.235830372405867, "train/cont_neg_acc": 0.2926518934700877, "train/cont_neg_loss": 3.0461218201468143, "train/cont_pos_acc": 0.9997970400185421, "train/cont_pos_loss": 0.0032509783250761442, "train/cont_pred": 0.995755467215195, "train/cont_rate": 0.9957762469211823, "train/dyn_loss_mean": 1.000019308968718, "train/dyn_loss_std": 0.0004981231363604919, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.5069514371069341, "train/extr_critic_critic_opt_grad_steps": 31140.0, "train/extr_critic_critic_opt_loss": 8567.690752001232, "train/extr_critic_mag": 0.9494813680648804, "train/extr_critic_max": 0.9494813680648804, "train/extr_critic_mean": 0.8973077708864446, "train/extr_critic_min": 0.8173882990635087, "train/extr_critic_std": 0.014283819133278185, "train/extr_return_normed_mag": 0.7709268701487574, "train/extr_return_normed_max": 0.3559736776821719, "train/extr_return_normed_mean": 0.03992855584643451, "train/extr_return_normed_min": -0.7299415008187882, "train/extr_return_normed_std": 0.03906892162513704, "train/extr_return_rate": 0.9979843840810466, "train/extr_return_raw_mag": 1.2187503529299657, "train/extr_return_raw_max": 1.2187503529299657, "train/extr_return_raw_mean": 0.902705270374937, "train/extr_return_raw_min": 0.13283517442900558, "train/extr_return_raw_std": 0.03906892160678585, "train/extr_reward_mag": 0.33565246001840227, "train/extr_reward_max": 0.33565246001840227, "train/extr_reward_mean": 0.0026033899799594883, "train/extr_reward_min": 2.3548238970376e-07, "train/extr_reward_std": 0.011985898826482334, "train/image_loss_mean": 0.11798481180750091, "train/image_loss_std": 0.10797806895278357, "train/model_loss_mean": 0.7402156929077186, "train/model_loss_std": 0.353094420115936, "train/model_opt_grad_norm": 25.490765364886503, "train/model_opt_grad_steps": 31112.862068965518, "train/model_opt_loss": 3719.538094356142, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5024.630541871921, "train/policy_entropy_mag": 1.461647249207708, "train/policy_entropy_max": 1.461647249207708, "train/policy_entropy_mean": 0.13613799680483166, "train/policy_entropy_min": 0.06468670070171356, "train/policy_entropy_std": 0.1762861589639645, "train/policy_logprob_mag": 6.551080168174406, "train/policy_logprob_max": -0.008608195054450353, "train/policy_logprob_mean": -0.13585699481770322, "train/policy_logprob_min": -6.551080168174406, "train/policy_logprob_std": 0.6711801780855714, "train/policy_randomness_mag": 0.7511381457004641, "train/policy_randomness_max": 0.7511381457004641, "train/policy_randomness_mean": 0.06996109496269907, "train/policy_randomness_min": 0.03324239029379314, "train/policy_randomness_std": 0.09059317009936413, "train/post_ent_mag": 79.47620669961563, "train/post_ent_max": 79.47620669961563, "train/post_ent_mean": 78.46734630415592, "train/post_ent_min": 77.68838733992553, "train/post_ent_std": 0.33134768000377224, "train/prior_ent_mag": 81.85104490383505, "train/prior_ent_max": 81.85104490383505, "train/prior_ent_mean": 77.4534101439227, "train/prior_ent_min": 74.33150448352832, "train/prior_ent_std": 1.204188068512038, "train/rep_loss_mean": 1.000019308968718, "train/rep_loss_std": 0.0004981231363604919, "train/reward_avg": 0.0006966576783910963, "train/reward_loss_mean": 0.006043000713912908, "train/reward_loss_std": 0.12040791108176627, "train/reward_max_data": 0.4499230293804789, "train/reward_max_pred": 0.08733191866005582, "train/reward_neg_acc": 0.9999470094154621, "train/reward_neg_loss": 0.0010870084546238592, "train/reward_pos_acc": 0.1478102194131726, "train/reward_pos_loss": 4.375945399277402, "train/reward_pred": 0.0005931039673409291, "train/reward_rate": 0.0011160714285714285, "train_stats/mean_log_entropy": 0.10295100208276357, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.008178451098501682, "report/cont_loss_std": 0.15888990461826324, "report/cont_neg_acc": 0.6666666865348816, "report/cont_neg_loss": 1.8057146072387695, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0028967580292373896, "report/cont_pred": 0.9954818487167358, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.09912195056676865, "report/image_loss_std": 0.10287369042634964, "report/model_loss_mean": 0.7091044783592224, "report/model_loss_std": 0.19016993045806885, "report/post_ent_mag": 71.00711059570312, "report/post_ent_max": 71.00711059570312, "report/post_ent_mean": 69.7027587890625, "report/post_ent_min": 68.7459716796875, "report/post_ent_std": 0.4178237318992615, "report/prior_ent_mag": 73.40222930908203, "report/prior_ent_max": 73.40222930908203, "report/prior_ent_mean": 68.20256042480469, "report/prior_ent_min": 65.00462341308594, "report/prior_ent_std": 1.2696444988250732, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.0018040870781987906, "report/reward_loss_std": 0.008959905244410038, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.046517014503479004, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0018040870781987906, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.000891532632522285, "report/reward_rate": 0.0, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.045095011591911316, "eval/cont_loss_std": 0.6208265423774719, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 8.671140670776367, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.002768978476524353, "eval/cont_pred": 0.9975039958953857, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.25048932433128357, "eval/image_loss_std": 0.1642185002565384, "eval/model_loss_mean": 0.8957501649856567, "eval/model_loss_std": 0.6368586421012878, "eval/post_ent_mag": 71.012451171875, "eval/post_ent_max": 71.012451171875, "eval/post_ent_mean": 69.64775085449219, "eval/post_ent_min": 68.84581756591797, "eval/post_ent_std": 0.4642266035079956, "eval/prior_ent_mag": 73.40222930908203, "eval/prior_ent_max": 73.40222930908203, "eval/prior_ent_mean": 68.11393737792969, "eval/prior_ent_min": 65.0918960571289, "eval/prior_ent_std": 1.2885316610336304, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00016578799113631248, "eval/reward_loss_std": 0.0012679760111495852, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.011173725128173828, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00016578799113631248, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 8.163554593920708e-05, "eval/reward_rate": 0.0, "replay/size": 515489.0, "replay/inserts": 32448.0, "replay/samples": 32448.0, "replay/insert_wait_avg": 1.3333600183445557e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.505491697811751e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5232.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1399160466792021e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1473894119262695e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4434869289398, "timer/env.step_count": 4056.0, "timer/env.step_total": 38.58628726005554, "timer/env.step_frac": 0.03856918233183148, "timer/env.step_avg": 0.00951338443295255, "timer/env.step_min": 0.007649421691894531, "timer/env.step_max": 0.05309653282165527, "timer/replay._sample_count": 32448.0, "timer/replay._sample_total": 16.853905200958252, "timer/replay._sample_frac": 0.016846434027667733, "timer/replay._sample_avg": 0.0005194127589052715, "timer/replay._sample_min": 0.0004248619079589844, "timer/replay._sample_max": 0.026027917861938477, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4710.0, "timer/agent.policy_total": 49.02412009239197, "timer/agent.policy_frac": 0.04900238817375008, "timer/agent.policy_avg": 0.010408518066325258, "timer/agent.policy_min": 0.008980274200439453, "timer/agent.policy_max": 0.08427715301513672, "timer/dataset_train_count": 2028.0, "timer/dataset_train_total": 0.2180330753326416, "timer/dataset_train_frac": 0.00021793642337753378, "timer/dataset_train_avg": 0.00010751137836915267, "timer/dataset_train_min": 9.250640869140625e-05, "timer/dataset_train_max": 0.0004868507385253906, "timer/agent.train_count": 2028.0, "timer/agent.train_total": 900.1499080657959, "timer/agent.train_frac": 0.8997508803110759, "timer/agent.train_avg": 0.44386090141311435, "timer/agent.train_min": 0.4326894283294678, "timer/agent.train_max": 0.6488568782806396, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4737966060638428, "timer/agent.report_frac": 0.000473586576607396, "timer/agent.report_avg": 0.2368983030319214, "timer/agent.report_min": 0.22860431671142578, "timer/agent.report_max": 0.245192289352417, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.409385681152344e-05, "timer/dataset_eval_frac": 3.407874333429998e-08, "timer/dataset_eval_avg": 3.409385681152344e-05, "timer/dataset_eval_min": 3.409385681152344e-05, "timer/dataset_eval_max": 3.409385681152344e-05, "fps": 32.43304650310912}
{"step": 516008, "time": 16225.607150554657, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 516288, "time": 16235.125714540482, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 516368, "time": 16237.533767700195, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 516392, "time": 16238.0401263237, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 516992, "time": 16256.426243543625, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 517208, "time": 16262.718755245209, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 517216, "time": 16263.185162305832, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 517296, "time": 16265.608788013458, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 517480, "time": 16270.940118551254, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 517488, "time": 16271.407197713852, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 517912, "time": 16284.028267621994, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 518016, "time": 16287.500602960587, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 518064, "time": 16288.986722707748, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 518128, "time": 16290.910737514496, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 518576, "time": 16304.367382764816, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 518584, "time": 16304.395141601562, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 518824, "time": 16311.574501037598, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 518992, "time": 16316.959217071533, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 518992, "time": 16316.966264247894, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 519024, "time": 16317.925515413284, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 519072, "time": 16319.375093698502, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 519304, "time": 16326.120711803436, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 519520, "time": 16332.866389989853, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 519784, "time": 16340.588632583618, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 519792, "time": 16341.07616186142, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 519976, "time": 16346.878789424896, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 520000, "time": 16348.875715255737, "eval_episode/length": 58.0, "eval_episode/score": 0.8187500238418579, "eval_episode/reward_rate": 0.01694915254237288}
{"step": 520000, "time": 16348.968859910965, "eval_episode/length": 63.0, "eval_episode/score": 0.8031250238418579, "eval_episode/reward_rate": 0.015625}
{"step": 520000, "time": 16349.325132369995, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 520000, "time": 16349.895749092102, "eval_episode/length": 114.0, "eval_episode/score": 0.643750011920929, "eval_episode/reward_rate": 0.008695652173913044}
{"step": 520000, "time": 16350.36252951622, "eval_episode/length": 81.0, "eval_episode/score": 0.746874988079071, "eval_episode/reward_rate": 0.012195121951219513}
{"step": 520000, "time": 16350.461874008179, "eval_episode/length": 145.0, "eval_episode/score": 0.546875, "eval_episode/reward_rate": 0.00684931506849315}
{"step": 520000, "time": 16350.486858844757, "eval_episode/length": 146.0, "eval_episode/score": 0.543749988079071, "eval_episode/reward_rate": 0.006802721088435374}
{"step": 520000, "time": 16350.672384500504, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 520024, "time": 16351.181915283203, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 520064, "time": 16353.928938627243, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 520064, "time": 16353.940422296524, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 520408, "time": 16364.084790229797, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 520568, "time": 16368.912603616714, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 520752, "time": 16374.706273078918, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 520936, "time": 16380.179287910461, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 520968, "time": 16381.157554149628, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 521304, "time": 16391.305710077286, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 521336, "time": 16392.28074169159, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 521552, "time": 16399.030913352966, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 521896, "time": 16409.268189668655, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 522136, "time": 16416.502239704132, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 522368, "time": 16423.69682621956, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 522376, "time": 16423.725881814957, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 522392, "time": 16424.213133335114, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 522720, "time": 16434.313926935196, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 522880, "time": 16439.2631149292, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 522888, "time": 16439.292138576508, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 523056, "time": 16444.584144353867, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 523192, "time": 16448.455305337906, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 523216, "time": 16449.39998292923, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 523248, "time": 16450.365099668503, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 523432, "time": 16455.68905568123, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 523448, "time": 16456.177701234818, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 523712, "time": 16464.370708703995, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 523808, "time": 16467.372626304626, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 523880, "time": 16469.321216583252, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 523960, "time": 16471.735026597977, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 524024, "time": 16473.649668693542, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 524032, "time": 16474.11489701271, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 524600, "time": 16491.516785621643, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 525088, "time": 16506.67221403122, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 525352, "time": 16514.456887722015, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 525504, "time": 16519.31783437729, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 525528, "time": 16519.832922935486, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 525560, "time": 16520.829694986343, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 525760, "time": 16527.29270529747, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 526104, "time": 16537.495800733566, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 526120, "time": 16537.98603796959, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 526192, "time": 16540.40717124939, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 526192, "time": 16540.429399251938, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 526528, "time": 16550.6770632267, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 526552, "time": 16551.189148902893, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 526624, "time": 16553.59460926056, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 526696, "time": 16555.737729549408, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 526824, "time": 16559.61766719818, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 527048, "time": 16566.454130649567, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 527296, "time": 16574.217701911926, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 527320, "time": 16574.74990797043, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 527400, "time": 16577.179677248, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 527512, "time": 16580.5887901783, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 527544, "time": 16581.57208132744, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 527720, "time": 16588.275440216064, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 527752, "time": 16589.24645638466, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 527816, "time": 16591.185259103775, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 528008, "time": 16596.98736190796, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 528160, "time": 16601.785468816757, "episode/length": 18.0, "episode/score": 0.9437500238418579, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.0}
{"step": 528280, "time": 16605.19484758377, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 528496, "time": 16611.946269512177, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 528536, "time": 16612.93593287468, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 528648, "time": 16616.444337129593, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 528864, "time": 16623.175003767014, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 529160, "time": 16631.886467933655, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 529392, "time": 16639.106280565262, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 529496, "time": 16642.02163887024, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 529712, "time": 16648.87046766281, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 530032, "time": 16658.605451107025, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 530088, "time": 16660.672159910202, "eval_episode/length": 32.0, "eval_episode/score": 0.8999999761581421, "eval_episode/reward_rate": 0.030303030303030304}
{"step": 530088, "time": 16660.980885505676, "eval_episode/length": 49.0, "eval_episode/score": 0.846875011920929, "eval_episode/reward_rate": 0.02}
{"step": 530088, "time": 16661.423976898193, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 530088, "time": 16662.21750855446, "eval_episode/length": 116.0, "eval_episode/score": 0.637499988079071, "eval_episode/reward_rate": 0.008547008547008548}
{"step": 530088, "time": 16662.322034835815, "eval_episode/length": 121.0, "eval_episode/score": 0.621874988079071, "eval_episode/reward_rate": 0.00819672131147541}
{"step": 530088, "time": 16662.457064151764, "eval_episode/length": 128.0, "eval_episode/score": 0.6000000238418579, "eval_episode/reward_rate": 0.007751937984496124}
{"step": 530088, "time": 16662.714268684387, "eval_episode/length": 109.0, "eval_episode/score": 0.659375011920929, "eval_episode/reward_rate": 0.00909090909090909}
{"step": 530088, "time": 16663.472093582153, "eval_episode/length": 128.0, "eval_episode/score": 0.6000000238418579, "eval_episode/reward_rate": 0.007751937984496124}
{"step": 530320, "time": 16670.7119410038, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 530432, "time": 16674.108473300934, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 530472, "time": 16675.188569784164, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 530848, "time": 16686.786955356598, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 531040, "time": 16692.608809947968, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 531144, "time": 16695.525260925293, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 531384, "time": 16702.821819067, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 531472, "time": 16705.866315603256, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 531648, "time": 16711.18252658844, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 531688, "time": 16712.175704479218, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 531808, "time": 16716.028360128403, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 531848, "time": 16717.02118420601, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 531936, "time": 16719.889713525772, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 532024, "time": 16722.352771520615, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 532240, "time": 16729.1059551239, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 532344, "time": 16732.047229766846, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 532488, "time": 16736.720561265945, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 532504, "time": 16737.49959540367, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 532600, "time": 16740.414601564407, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 532608, "time": 16740.882323265076, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 532800, "time": 16746.717200756073, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 532912, "time": 16750.16811990738, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 533104, "time": 16755.9859790802, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 533288, "time": 16761.326889038086, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 533368, "time": 16763.739331007004, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 533376, "time": 16764.207985639572, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 533472, "time": 16767.240498542786, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 533696, "time": 16773.99898815155, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 534088, "time": 16785.63165307045, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 534128, "time": 16787.067373991013, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 534200, "time": 16789.0367000103, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 534344, "time": 16793.351796388626, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 534552, "time": 16799.76066160202, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 534560, "time": 16800.23800110817, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 534864, "time": 16809.4345164299, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 534872, "time": 16809.46252846718, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 534904, "time": 16810.428963422775, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 534912, "time": 16810.899022340775, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 535304, "time": 16822.485550642014, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 535360, "time": 16824.416186094284, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 535416, "time": 16825.990025520325, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 535432, "time": 16826.478917360306, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 535472, "time": 16827.931119918823, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 535640, "time": 16832.815169095993, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 535944, "time": 16841.97261285782, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 536176, "time": 16849.205488443375, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 536248, "time": 16851.15171265602, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 536296, "time": 16852.624289512634, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 536376, "time": 16855.06699490547, "episode/length": 15.0, "episode/score": 0.953125, "episode/reward_rate": 0.0625, "episode/intrinsic_return": 0.0}
{"step": 536400, "time": 16856.062903881073, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 536408, "time": 16856.090322494507, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 536480, "time": 16858.49569582939, "episode/length": 9.0, "episode/score": 0.971875011920929, "episode/reward_rate": 0.1, "episode/intrinsic_return": 0.0}
{"step": 536632, "time": 16862.86799955368, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 537016, "time": 16874.454276561737, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 537184, "time": 16879.751626968384, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 537200, "time": 16880.239941596985, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 537256, "time": 16881.726667404175, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 537488, "time": 16889.06023454666, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 537600, "time": 16892.44898366928, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 537632, "time": 16893.414219856262, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 537688, "time": 16894.890563249588, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 537744, "time": 16896.81682062149, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 537776, "time": 16897.785124063492, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 537984, "time": 16904.068520784378, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 538696, "time": 16925.486156225204, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 538792, "time": 16928.385051965714, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 538880, "time": 16931.27426290512, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 539040, "time": 16936.124242067337, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 539064, "time": 16936.633833885193, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 539224, "time": 16941.494213819504, "episode/length": 202.0, "episode/score": 0.3687500059604645, "episode/reward_rate": 0.0049261083743842365, "episode/intrinsic_return": 0.0}
{"step": 539328, "time": 16944.863646268845, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 539400, "time": 16947.384906053543, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 539680, "time": 16956.063001394272, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 539704, "time": 16956.572548627853, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 539928, "time": 16963.33849310875, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 539944, "time": 16963.82682657242, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 540000, "time": 16965.754595518112, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 540032, "time": 16966.722952127457, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 540072, "time": 16968.698554754257, "eval_episode/length": 52.0, "eval_episode/score": 0.8374999761581421, "eval_episode/reward_rate": 0.018867924528301886}
{"step": 540072, "time": 16969.565274953842, "eval_episode/length": 100.0, "eval_episode/score": 0.6875, "eval_episode/reward_rate": 0.009900990099009901}
{"step": 540072, "time": 16969.69517683983, "eval_episode/length": 107.0, "eval_episode/score": 0.6656249761581421, "eval_episode/reward_rate": 0.009259259259259259}
{"step": 540072, "time": 16970.10804796219, "eval_episode/length": 129.0, "eval_episode/score": 0.596875011920929, "eval_episode/reward_rate": 0.007692307692307693}
{"step": 540072, "time": 16970.412778377533, "eval_episode/length": 93.0, "eval_episode/score": 0.7093750238418579, "eval_episode/reward_rate": 0.010638297872340425}
{"step": 540072, "time": 16970.558633089066, "eval_episode/length": 154.0, "eval_episode/score": 0.518750011920929, "eval_episode/reward_rate": 0.0064516129032258064}
{"step": 540072, "time": 16971.097499847412, "eval_episode/length": 183.0, "eval_episode/score": 0.4281249940395355, "eval_episode/reward_rate": 0.005434782608695652}
{"step": 540072, "time": 16971.270925283432, "eval_episode/length": 192.0, "eval_episode/score": 0.4000000059604645, "eval_episode/reward_rate": 0.0051813471502590676}
{"step": 540248, "time": 16976.813980340958, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 540288, "time": 16978.29029250145, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 540416, "time": 16982.18191599846, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 540536, "time": 16985.58202290535, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 540984, "time": 16999.584630727768, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 541016, "time": 17000.557397842407, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 541080, "time": 17002.505757331848, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 541144, "time": 17004.436180591583, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 541200, "time": 17006.438485622406, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 541224, "time": 17006.948784589767, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 541688, "time": 17020.94933438301, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 541704, "time": 17021.43714594841, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 541712, "time": 17021.922953128815, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 541992, "time": 17030.180325508118, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 542360, "time": 17041.39183115959, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 542448, "time": 17044.27160549164, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 542552, "time": 17047.19573354721, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 542832, "time": 17055.87569975853, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 542848, "time": 17056.36727643013, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 543168, "time": 17066.155247688293, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 543240, "time": 17068.117846250534, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 543248, "time": 17068.585673332214, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 543328, "time": 17071.018337488174, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 543352, "time": 17071.530789613724, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 543848, "time": 17088.15719485283, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 543960, "time": 17091.56786465645, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 544000, "time": 17093.00810933113, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 544040, "time": 17094.00494980812, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 544088, "time": 17095.571048498154, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 544096, "time": 17096.046332597733, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 544440, "time": 17106.280304431915, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 544552, "time": 17109.673746585846, "episode/length": 212.0, "episode/score": 0.3375000059604645, "episode/reward_rate": 0.004694835680751174, "episode/intrinsic_return": 0.0}
{"step": 544592, "time": 17111.130591392517, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 544912, "time": 17120.842614650726, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 545136, "time": 17127.805245399475, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 545192, "time": 17129.288424015045, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 545304, "time": 17132.68613243103, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 545320, "time": 17133.173443317413, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 545664, "time": 17143.80961227417, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 545720, "time": 17145.309451818466, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 545744, "time": 17146.26019334793, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 545824, "time": 17148.68053150177, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 545976, "time": 17153.084855556488, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 546312, "time": 17163.3887090683, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 546384, "time": 17165.798605442047, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 546496, "time": 17169.185483694077, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 546528, "time": 17170.17618227005, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 546536, "time": 17170.20389008522, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 546792, "time": 17177.944612264633, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 546904, "time": 17181.34553027153, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 546904, "time": 17181.354358911514, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 546920, "time": 17181.84045290947, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 546992, "time": 17184.247871875763, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 547024, "time": 17185.337421894073, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 547096, "time": 17187.28493142128, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 547152, "time": 17189.225259542465, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 547208, "time": 17190.696747541428, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 547216, "time": 17191.164094686508, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 547248, "time": 17192.134034872055, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 547456, "time": 17198.39540886879, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 547880, "time": 17211.01007795334, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 547920, "time": 17212.440407276154, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 548048, "time": 17216.444962978363, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 548112, "time": 17218.40818619728, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 548200, "time": 17220.85158252716, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 548288, "time": 17223.756301879883, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 548329, "time": 17225.737168312073, "train_stats/mean_log_entropy": 0.09382976579065082, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.721547343943379, "train/action_min": 0.0, "train/action_std": 1.9726233641699988, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.010370141733783565, "train/actor_opt_grad_steps": 33165.0, "train/actor_opt_loss": -2.196517592000932, "train/adv_mag": 0.9086481784239854, "train/adv_max": 0.4119762577632866, "train/adv_mean": 0.004457809521704578, "train/adv_min": -0.8736088296564499, "train/adv_std": 0.032230599859434335, "train/cont_avg": 0.9955619585396039, "train/cont_loss_mean": 0.015419913173450322, "train/cont_loss_std": 0.22811269504248655, "train/cont_neg_acc": 0.33530567929443744, "train/cont_neg_loss": 2.8040383430474467, "train/cont_pos_acc": 0.9998058204603667, "train/cont_pos_loss": 0.0030751463278233635, "train/cont_pred": 0.9956677296374103, "train/cont_rate": 0.9955619585396039, "train/dyn_loss_mean": 1.000243349830703, "train/dyn_loss_std": 0.0011271999006062783, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.21692353830958652, "train/extr_critic_critic_opt_grad_steps": 33165.0, "train/extr_critic_critic_opt_loss": 12745.051680461014, "train/extr_critic_mag": 1.0673702978851771, "train/extr_critic_max": 1.0673702978851771, "train/extr_critic_mean": 1.0289235324552743, "train/extr_critic_min": 0.8788301266065919, "train/extr_critic_std": 0.01376171058302026, "train/extr_return_normed_mag": 0.8911284898767377, "train/extr_return_normed_max": 0.36468704266123253, "train/extr_return_normed_mean": 0.032845134904497475, "train/extr_return_normed_min": -0.8618749807966818, "train/extr_return_normed_std": 0.035182929459479775, "train/extr_return_rate": 0.998443344441971, "train/extr_return_raw_mag": 1.365223252537227, "train/extr_return_raw_max": 1.365223252537227, "train/extr_return_raw_mean": 1.0333814027875956, "train/extr_return_raw_min": 0.1386612290793126, "train/extr_return_raw_std": 0.03518292942259571, "train/extr_reward_mag": 0.3829638716017846, "train/extr_reward_max": 0.3829638716017846, "train/extr_reward_mean": 0.0024319756712699956, "train/extr_reward_min": 1.6288001938621598e-07, "train/extr_reward_std": 0.009953309034947122, "train/image_loss_mean": 0.11095599697367979, "train/image_loss_std": 0.10647333590406002, "train/model_loss_mean": 0.7345113350023137, "train/model_loss_std": 0.376535374781873, "train/model_opt_grad_norm": 24.446178686500776, "train/model_opt_grad_steps": 33135.74257425743, "train/model_opt_loss": 2880.180639890161, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3923.267326732673, "train/policy_entropy_mag": 1.4132665212791744, "train/policy_entropy_max": 1.4132665212791744, "train/policy_entropy_mean": 0.12997018095880453, "train/policy_entropy_min": 0.06468668819801641, "train/policy_entropy_std": 0.1740219781894495, "train/policy_logprob_mag": 6.551080184407754, "train/policy_logprob_max": -0.008608206456508671, "train/policy_logprob_mean": -0.12973056497550248, "train/policy_logprob_min": -6.551080184407754, "train/policy_logprob_std": 0.6662866372873287, "train/policy_randomness_mag": 0.726275364951332, "train/policy_randomness_max": 0.726275364951332, "train/policy_randomness_mean": 0.06679146476827635, "train/policy_randomness_min": 0.033242383307897215, "train/policy_randomness_std": 0.08942961194875217, "train/post_ent_mag": 64.82260730479024, "train/post_ent_max": 64.82260730479024, "train/post_ent_mean": 63.19585277066373, "train/post_ent_min": 62.12053776731585, "train/post_ent_std": 0.5280369248720679, "train/prior_ent_mag": 67.70836558200345, "train/prior_ent_max": 67.70836558200345, "train/prior_ent_mean": 62.84321312857146, "train/prior_ent_min": 58.5905975492874, "train/prior_ent_std": 1.7246679825948017, "train/rep_loss_mean": 1.000243349830703, "train/rep_loss_std": 0.0011271999006062783, "train/reward_avg": 0.0010084850974536575, "train/reward_loss_mean": 0.00798939260432847, "train/reward_loss_std": 0.15234830937265317, "train/reward_max_data": 0.5902846534505929, "train/reward_max_pred": 0.10080364257982462, "train/reward_neg_acc": 0.9999176502817928, "train/reward_neg_loss": 0.0013390668058905653, "train/reward_pos_acc": 0.10315040744295935, "train/reward_pos_loss": 4.334105218329081, "train/reward_pred": 0.0007613576852974694, "train/reward_rate": 0.0015373607673267327, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.01029985211789608, "report/cont_loss_std": 0.18366336822509766, "report/cont_neg_acc": 0.5, "report/cont_neg_loss": 2.0005364418029785, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0024950020015239716, "report/cont_pred": 0.9955742359161377, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.09279666841030121, "report/image_loss_std": 0.09439432621002197, "report/model_loss_mean": 0.7084289789199829, "report/model_loss_std": 0.29553741216659546, "report/post_ent_mag": 61.824851989746094, "report/post_ent_max": 61.824851989746094, "report/post_ent_mean": 59.88423156738281, "report/post_ent_min": 58.64533996582031, "report/post_ent_std": 0.6080782413482666, "report/prior_ent_mag": 63.99798583984375, "report/prior_ent_max": 63.99798583984375, "report/prior_ent_mean": 58.99000930786133, "report/prior_ent_min": 54.579017639160156, "report/prior_ent_std": 1.8612735271453857, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0007415771251544356, "report/reward_loss_mean": 0.005332477390766144, "report/reward_loss_std": 0.1258341670036316, "report/reward_max_data": 0.7593749761581421, "report/reward_max_pred": 0.029602408409118652, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0014033984625712037, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.0247802734375, "report/reward_pred": 0.000711334403604269, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.018849048763513565, "eval/cont_loss_std": 0.4031184911727905, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 9.078292846679688, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0011201952584087849, "eval/cont_pred": 0.9989601373672485, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.17486080527305603, "eval/image_loss_std": 0.1422206461429596, "eval/model_loss_mean": 0.7937551736831665, "eval/model_loss_std": 0.4307940900325775, "eval/post_ent_mag": 61.81032943725586, "eval/post_ent_max": 61.81032943725586, "eval/post_ent_mean": 59.64865493774414, "eval/post_ent_min": 58.497833251953125, "eval/post_ent_std": 0.6499647498130798, "eval/prior_ent_mag": 63.99798583984375, "eval/prior_ent_max": 63.99798583984375, "eval/prior_ent_mean": 58.510597229003906, "eval/prior_ent_min": 54.500152587890625, "eval/prior_ent_std": 1.8908225297927856, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 4.529301077127457e-05, "eval/reward_loss_std": 0.0005977867403998971, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.007911443710327148, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 4.529301077127457e-05, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 2.1805521100759506e-05, "eval/reward_rate": 0.0, "replay/size": 547825.0, "replay/inserts": 32336.0, "replay/samples": 32336.0, "replay/insert_wait_avg": 1.3418713163350373e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.592904646286924e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4232.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1110801552554384e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.5367431640625e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1608123779297, "timer/env.step_count": 4042.0, "timer/env.step_total": 38.78945255279541, "timer/env.step_frac": 0.03878321573164984, "timer/env.step_avg": 0.009596598850271008, "timer/env.step_min": 0.007537364959716797, "timer/env.step_max": 0.053106069564819336, "timer/replay._sample_count": 32336.0, "timer/replay._sample_total": 16.91192102432251, "timer/replay._sample_frac": 0.016909201815369687, "timer/replay._sample_avg": 0.0005230059693320915, "timer/replay._sample_min": 0.0003905296325683594, "timer/replay._sample_max": 0.034008026123046875, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4571.0, "timer/agent.policy_total": 47.313594341278076, "timer/agent.policy_frac": 0.04730598695302585, "timer/agent.policy_avg": 0.010350819151450027, "timer/agent.policy_min": 0.008051872253417969, "timer/agent.policy_max": 0.08191657066345215, "timer/dataset_train_count": 2021.0, "timer/dataset_train_total": 0.22041034698486328, "timer/dataset_train_frac": 0.00022037490797187628, "timer/dataset_train_avg": 0.00010906004304050633, "timer/dataset_train_min": 9.465217590332031e-05, "timer/dataset_train_max": 0.0006327629089355469, "timer/agent.train_count": 2021.0, "timer/agent.train_total": 899.5534784793854, "timer/agent.train_frac": 0.8994088424047073, "timer/agent.train_avg": 0.445103156100636, "timer/agent.train_min": 0.4332468509674072, "timer/agent.train_max": 1.9960989952087402, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4736008644104004, "timer/agent.report_frac": 0.00047352471577484815, "timer/agent.report_avg": 0.2368004322052002, "timer/agent.report_min": 0.2308204174041748, "timer/agent.report_max": 0.24278044700622559, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.266334533691406e-05, "timer/dataset_eval_frac": 3.265809351123787e-08, "timer/dataset_eval_avg": 3.266334533691406e-05, "timer/dataset_eval_min": 3.266334533691406e-05, "timer/dataset_eval_max": 3.266334533691406e-05, "fps": 32.330264183560466}
{"step": 548488, "time": 17230.328108549118, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 548680, "time": 17236.13827586174, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 548808, "time": 17240.027208328247, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 548952, "time": 17244.854278326035, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 549056, "time": 17248.307911872864, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 549104, "time": 17249.78109240532, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 549152, "time": 17251.231915473938, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 549440, "time": 17259.928472042084, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 549464, "time": 17260.440435409546, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 549768, "time": 17269.655925750732, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 549768, "time": 17269.67273759842, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 549928, "time": 17274.516102552414, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 550056, "time": 17278.89713907242, "eval_episode/length": 20.0, "eval_episode/score": 0.9375, "eval_episode/reward_rate": 0.047619047619047616}
{"step": 550056, "time": 17279.488222837448, "eval_episode/length": 53.0, "eval_episode/score": 0.8343750238418579, "eval_episode/reward_rate": 0.018518518518518517}
{"step": 550056, "time": 17279.514605760574, "eval_episode/length": 33.0, "eval_episode/score": 0.8968750238418579, "eval_episode/reward_rate": 0.029411764705882353}
{"step": 550056, "time": 17279.59797501564, "eval_episode/length": 58.0, "eval_episode/score": 0.8187500238418579, "eval_episode/reward_rate": 0.01694915254237288}
{"step": 550056, "time": 17279.663534641266, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 550056, "time": 17279.744910001755, "eval_episode/length": 65.0, "eval_episode/score": 0.796875, "eval_episode/reward_rate": 0.015151515151515152}
{"step": 550056, "time": 17280.669404268265, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 550056, "time": 17280.76617217064, "eval_episode/length": 59.0, "eval_episode/score": 0.815625011920929, "eval_episode/reward_rate": 0.016666666666666666}
{"step": 550064, "time": 17281.230741262436, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 550352, "time": 17289.934129714966, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 550448, "time": 17292.841198444366, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 550488, "time": 17293.844427347183, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 550504, "time": 17294.34006214142, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 550864, "time": 17305.541023492813, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 550992, "time": 17309.406120061874, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 550992, "time": 17309.412487983704, "episode/length": 15.0, "episode/score": 0.953125, "episode/reward_rate": 0.0625, "episode/intrinsic_return": 0.0}
{"step": 551096, "time": 17312.322482824326, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 551136, "time": 17313.751559257507, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 551464, "time": 17323.445945501328, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 551504, "time": 17324.895797252655, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 551528, "time": 17325.40491461754, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 552376, "time": 17351.076900482178, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 552440, "time": 17353.02428293228, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 552736, "time": 17362.12997674942, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 552800, "time": 17364.076734781265, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 552840, "time": 17365.15004134178, "episode/length": 230.0, "episode/score": 0.28125, "episode/reward_rate": 0.004329004329004329, "episode/intrinsic_return": 0.0}
{"step": 553408, "time": 17382.54077553749, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 553448, "time": 17383.53648662567, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 553816, "time": 17394.622706651688, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 553976, "time": 17399.546837329865, "episode/length": 191.0, "episode/score": 0.40312498807907104, "episode/reward_rate": 0.005208333333333333, "episode/intrinsic_return": 0.0}
{"step": 554104, "time": 17403.426236867905, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 554136, "time": 17404.401796102524, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 554168, "time": 17405.37845468521, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 554224, "time": 17407.30721640587, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 554240, "time": 17407.79749059677, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 554624, "time": 17419.400869846344, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 554680, "time": 17420.895909547806, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 554688, "time": 17421.364510059357, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 554888, "time": 17427.316877365112, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 555000, "time": 17430.700202703476, "episode/length": 13.0, "episode/score": 0.9593750238418579, "episode/reward_rate": 0.07142857142857142, "episode/intrinsic_return": 0.0}
{"step": 555032, "time": 17431.663851737976, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 555032, "time": 17431.670914888382, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 555112, "time": 17434.086825847626, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 555312, "time": 17441.049329519272, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 555496, "time": 17446.416798591614, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 555528, "time": 17447.381434202194, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 555912, "time": 17459.005108594894, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 556032, "time": 17462.850865602493, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 556072, "time": 17463.839057683945, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 556128, "time": 17465.772080898285, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 556208, "time": 17468.17171239853, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 556288, "time": 17470.59220981598, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 556496, "time": 17476.89319086075, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 556536, "time": 17477.89719414711, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 556728, "time": 17483.709665298462, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 556784, "time": 17485.79140639305, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 556800, "time": 17486.28205394745, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 556872, "time": 17488.236128091812, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 557056, "time": 17494.173124313354, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 557312, "time": 17502.286709308624, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 557520, "time": 17508.552479982376, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 557536, "time": 17509.038578033447, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 557680, "time": 17513.369418621063, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 557704, "time": 17513.881576299667, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 557816, "time": 17517.37811946869, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 558472, "time": 17537.13140821457, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 558600, "time": 17541.011506557465, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 558960, "time": 17552.16886162758, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 559056, "time": 17555.064756393433, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 559088, "time": 17556.030635118484, "episode/length": 15.0, "episode/score": 0.953125, "episode/reward_rate": 0.0625, "episode/intrinsic_return": 0.0}
{"step": 559096, "time": 17556.067707061768, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 559288, "time": 17561.8329205513, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 559512, "time": 17568.56975531578, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 559624, "time": 17571.92621088028, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 559832, "time": 17578.336597681046, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 559848, "time": 17578.827746629715, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 560040, "time": 17585.681127548218, "eval_episode/length": 59.0, "eval_episode/score": 0.815625011920929, "eval_episode/reward_rate": 0.016666666666666666}
{"step": 560040, "time": 17586.360042333603, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 560040, "time": 17586.605167865753, "eval_episode/length": 112.0, "eval_episode/score": 0.6499999761581421, "eval_episode/reward_rate": 0.008849557522123894}
{"step": 560040, "time": 17587.011840343475, "eval_episode/length": 21.0, "eval_episode/score": 0.934374988079071, "eval_episode/reward_rate": 0.045454545454545456}
{"step": 560040, "time": 17587.497151851654, "eval_episode/length": 102.0, "eval_episode/score": 0.6812499761581421, "eval_episode/reward_rate": 0.009708737864077669}
{"step": 560040, "time": 17587.593792676926, "eval_episode/length": 167.0, "eval_episode/score": 0.4781250059604645, "eval_episode/reward_rate": 0.005952380952380952}
{"step": 560040, "time": 17587.695145606995, "eval_episode/length": 172.0, "eval_episode/score": 0.4625000059604645, "eval_episode/reward_rate": 0.005780346820809248}
{"step": 560040, "time": 17588.717691898346, "eval_episode/length": 95.0, "eval_episode/score": 0.703125, "eval_episode/reward_rate": 0.010416666666666666}
{"step": 560072, "time": 17589.691790103912, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 560128, "time": 17591.630629062653, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 560224, "time": 17594.53465819359, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 560280, "time": 17596.026423692703, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 560280, "time": 17596.039254665375, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 560464, "time": 17601.834780216217, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 560912, "time": 17615.556790828705, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 561040, "time": 17619.428816080093, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 561080, "time": 17620.434875011444, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 561200, "time": 17624.27887248993, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 561256, "time": 17625.777287960052, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 561408, "time": 17630.578588485718, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 561648, "time": 17637.967988729477, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 562208, "time": 17654.87017416954, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 562224, "time": 17655.35656762123, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 562264, "time": 17656.348489046097, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 562440, "time": 17661.66085910797, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 562536, "time": 17664.563608646393, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 562568, "time": 17665.6118183136, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 562840, "time": 17673.785162448883, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 563072, "time": 17680.983068227768, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 563224, "time": 17685.34091114998, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 563352, "time": 17689.209329605103, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 563424, "time": 17691.600516319275, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 563568, "time": 17696.059803962708, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 563768, "time": 17701.89299440384, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 563888, "time": 17705.747512340546, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 563960, "time": 17707.723249197006, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 564336, "time": 17719.332359075546, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 564464, "time": 17723.22198319435, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 564576, "time": 17726.769191741943, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 564752, "time": 17732.12227487564, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 564784, "time": 17733.094027996063, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 564824, "time": 17734.082987308502, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 564952, "time": 17737.954763650894, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 564992, "time": 17739.385935783386, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 565496, "time": 17754.98761868477, "episode/length": 258.0, "episode/score": 0.19374999403953552, "episode/reward_rate": 0.003861003861003861, "episode/intrinsic_return": 0.0}
{"step": 565552, "time": 17756.988980531693, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 565584, "time": 17757.965987443924, "episode/length": 251.0, "episode/score": 0.21562500298023224, "episode/reward_rate": 0.003968253968253968, "episode/intrinsic_return": 0.0}
{"step": 565592, "time": 17757.993339300156, "episode/length": 11.0, "episode/score": 0.965624988079071, "episode/reward_rate": 0.08333333333333333, "episode/intrinsic_return": 0.0}
{"step": 565600, "time": 17758.462851047516, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 565632, "time": 17759.437877178192, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 565904, "time": 17767.71825695038, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 566064, "time": 17772.579684734344, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 566120, "time": 17774.048232078552, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 566280, "time": 17778.906314134598, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 566400, "time": 17782.762931108475, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 567128, "time": 17804.727452993393, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 567240, "time": 17808.132835626602, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 567304, "time": 17810.058604240417, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 567616, "time": 17819.79269838333, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 567904, "time": 17828.50127863884, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 567912, "time": 17828.530504465103, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 568376, "time": 17842.5100440979, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 568432, "time": 17844.461277484894, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 568432, "time": 17844.473804950714, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 568712, "time": 17852.8731071949, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 568920, "time": 17859.177191257477, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 569000, "time": 17861.596007585526, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 569080, "time": 17864.028738975525, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 569208, "time": 17867.900416851044, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 569344, "time": 17872.25230026245, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 569440, "time": 17875.317199230194, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 569552, "time": 17878.736105442047, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 569728, "time": 17884.06619310379, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 569760, "time": 17885.03128385544, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 569800, "time": 17886.020283460617, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 569888, "time": 17888.909532785416, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 569928, "time": 17889.897527217865, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 570024, "time": 17894.49153470993, "eval_episode/length": 93.0, "eval_episode/score": 0.7093750238418579, "eval_episode/reward_rate": 0.010638297872340425}
{"step": 570024, "time": 17895.449056386948, "eval_episode/length": 111.0, "eval_episode/score": 0.653124988079071, "eval_episode/reward_rate": 0.008928571428571428}
{"step": 570024, "time": 17895.87365102768, "eval_episode/length": 40.0, "eval_episode/score": 0.875, "eval_episode/reward_rate": 0.024390243902439025}
{"step": 570024, "time": 17897.53245329857, "eval_episode/length": 88.0, "eval_episode/score": 0.7250000238418579, "eval_episode/reward_rate": 0.011235955056179775}
{"step": 570024, "time": 17897.761304855347, "eval_episode/length": 123.0, "eval_episode/score": 0.6156250238418579, "eval_episode/reward_rate": 0.008064516129032258}
{"step": 570024, "time": 17898.713228940964, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 570024, "time": 17898.72211241722, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 570024, "time": 17898.7299888134, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 570024, "time": 17898.736206054688, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 570024, "time": 17898.742364883423, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 570024, "time": 17898.752379179, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 570448, "time": 17911.926263809204, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 570496, "time": 17913.39120221138, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 570560, "time": 17915.352160215378, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 570848, "time": 17924.10157108307, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 570896, "time": 17925.548048496246, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 571008, "time": 17928.94238257408, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 571104, "time": 17931.83364701271, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 571136, "time": 17932.806709766388, "episode/length": 197.0, "episode/score": 0.3843750059604645, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.0}
{"step": 571392, "time": 17940.705963134766, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 571456, "time": 17942.63854575157, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 571480, "time": 17943.16788339615, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 571656, "time": 17948.488352298737, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 571656, "time": 17948.495875120163, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 571800, "time": 17952.858404397964, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 571936, "time": 17957.17834162712, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 572016, "time": 17959.61394095421, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 572136, "time": 17963.01700282097, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 572136, "time": 17963.026093006134, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 572392, "time": 17970.825133562088, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 572456, "time": 17972.78240299225, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 572608, "time": 17977.599050283432, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 572688, "time": 17980.001175165176, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 572728, "time": 17980.98735809326, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 572752, "time": 17981.952008008957, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 572832, "time": 17984.361510276794, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 572864, "time": 17985.32480072975, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 573056, "time": 17991.102154493332, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 573088, "time": 17992.081285715103, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 573320, "time": 17998.93798160553, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 573496, "time": 18004.698839187622, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 573520, "time": 18005.64245414734, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 573536, "time": 18006.130386590958, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 573656, "time": 18009.53229355812, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 573768, "time": 18012.921221971512, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 573928, "time": 18017.76264691353, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 573976, "time": 18019.205089330673, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 574048, "time": 18021.62110233307, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 574104, "time": 18023.09361886978, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 574128, "time": 18024.04329776764, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 574648, "time": 18039.66084933281, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 574696, "time": 18041.12615776062, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 575024, "time": 18051.189160346985, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 575368, "time": 18061.464915513992, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 575496, "time": 18065.36553788185, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 575896, "time": 18077.457654476166, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 576080, "time": 18083.2425031662, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 576240, "time": 18088.21612429619, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 576288, "time": 18089.68003344536, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 576344, "time": 18091.146424770355, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 576376, "time": 18092.113775491714, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 576440, "time": 18094.065012931824, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 577144, "time": 18115.39692926407, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 577248, "time": 18118.777916431427, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 577272, "time": 18119.289823532104, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 577336, "time": 18121.21682190895, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 577496, "time": 18126.038877010345, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 577536, "time": 18127.47612929344, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 577736, "time": 18133.295927524567, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 577872, "time": 18137.619413614273, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 578128, "time": 18145.42107439041, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 578208, "time": 18147.8516933918, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 578472, "time": 18155.583260059357, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 578552, "time": 18158.01253414154, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 578560, "time": 18158.481945753098, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 578920, "time": 18169.125016212463, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 579384, "time": 18183.25266432762, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 579416, "time": 18184.221425771713, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 579648, "time": 18191.46542453766, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 579808, "time": 18196.31460428238, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 579848, "time": 18197.316448926926, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 579960, "time": 18200.692013025284, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 580008, "time": 18202.695245981216, "eval_episode/length": 31.0, "eval_episode/score": 0.903124988079071, "eval_episode/reward_rate": 0.03125}
{"step": 580008, "time": 18203.228548526764, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 580008, "time": 18203.34216237068, "eval_episode/length": 67.0, "eval_episode/score": 0.7906249761581421, "eval_episode/reward_rate": 0.014705882352941176}
{"step": 580008, "time": 18203.503848314285, "eval_episode/length": 76.0, "eval_episode/score": 0.762499988079071, "eval_episode/reward_rate": 0.012987012987012988}
{"step": 580008, "time": 18204.087506771088, "eval_episode/length": 109.0, "eval_episode/score": 0.659375011920929, "eval_episode/reward_rate": 0.00909090909090909}
{"step": 580008, "time": 18204.384109020233, "eval_episode/length": 126.0, "eval_episode/score": 0.606249988079071, "eval_episode/reward_rate": 0.007874015748031496}
{"step": 580008, "time": 18204.613253593445, "eval_episode/length": 139.0, "eval_episode/score": 0.565625011920929, "eval_episode/reward_rate": 0.007142857142857143}
{"step": 580008, "time": 18204.655030965805, "eval_episode/length": 31.0, "eval_episode/score": 0.903124988079071, "eval_episode/reward_rate": 0.03125}
{"step": 580056, "time": 18206.2160923481, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 580128, "time": 18208.62439918518, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 580160, "time": 18209.591499090195, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 580304, "time": 18213.927945375443, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 580440, "time": 18217.802391052246, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 580584, "time": 18222.12111902237, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 580681, "time": 18226.035878419876, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.783084982692605, "train/action_min": 0.0, "train/action_std": 1.9760879785707681, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.010687188386552884, "train/actor_opt_grad_steps": 35185.0, "train/actor_opt_loss": -5.6438111814089345, "train/adv_mag": 1.0101144113162956, "train/adv_max": 0.36264553931680055, "train/adv_mean": 0.0025274145989836296, "train/adv_min": -0.9867908901507312, "train/adv_std": 0.03628044149902935, "train/cont_avg": 0.9956393100247525, "train/cont_loss_mean": 0.014653508139354647, "train/cont_loss_std": 0.21440205922105932, "train/cont_neg_acc": 0.38070289794318746, "train/cont_neg_loss": 2.61988944098547, "train/cont_pos_acc": 0.9998154784783279, "train/cont_pos_loss": 0.0031053061178645653, "train/cont_pred": 0.9955176693378108, "train/cont_rate": 0.9956393100247525, "train/dyn_loss_mean": 1.5641886119795319, "train/dyn_loss_std": 0.033298883762645434, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.2867608531516525, "train/extr_critic_critic_opt_grad_steps": 35185.0, "train/extr_critic_critic_opt_loss": 6163.89064071202, "train/extr_critic_mag": 1.2006111145019531, "train/extr_critic_max": 1.2006111145019531, "train/extr_critic_mean": 1.1637057001047795, "train/extr_critic_min": 0.9401824916943465, "train/extr_critic_std": 0.015084421903005626, "train/extr_return_normed_mag": 0.9992856424633819, "train/extr_return_normed_max": 0.29061270291262337, "train/extr_return_normed_mean": 0.030881499937311332, "train/extr_return_normed_min": -0.9770984443107454, "train/extr_return_normed_std": 0.03997926627940471, "train/extr_return_rate": 0.9983353788899904, "train/extr_return_raw_mag": 1.4259642598652604, "train/extr_return_raw_max": 1.4259642598652604, "train/extr_return_raw_mean": 1.1662331134966104, "train/extr_return_raw_min": 0.15825311264189162, "train/extr_return_raw_std": 0.0399792662194681, "train/extr_reward_mag": 0.33928322437966224, "train/extr_reward_max": 0.33928322437966224, "train/extr_reward_mean": 0.0024466385867787837, "train/extr_reward_min": 1.2097972454410969e-07, "train/extr_reward_std": 0.009685777781282247, "train/image_loss_mean": 0.10658199369612306, "train/image_loss_std": 0.10529742441555061, "train/model_loss_mean": 1.067997852469435, "train/model_loss_std": 0.38469891961995917, "train/model_opt_grad_norm": 24.21027031229503, "train/model_opt_grad_steps": 35153.460396039605, "train/model_opt_loss": 2746.812854577999, "train/model_opt_model_opt_grad_overflow": 0.0049504950495049506, "train/model_opt_model_opt_grad_scale": 2599.009900990099, "train/policy_entropy_mag": 1.413725240395801, "train/policy_entropy_max": 1.413725240395801, "train/policy_entropy_mean": 0.12851235111898715, "train/policy_entropy_min": 0.06468659713126645, "train/policy_entropy_std": 0.1701381444783494, "train/policy_logprob_mag": 6.5510802292587735, "train/policy_logprob_max": -0.008608146146456204, "train/policy_logprob_mean": -0.12868088424795926, "train/policy_logprob_min": -6.5510802292587735, "train/policy_logprob_std": 0.6668260395526886, "train/policy_randomness_mag": 0.7265111007312737, "train/policy_randomness_max": 0.7265111007312737, "train/policy_randomness_mean": 0.06604228825262277, "train/policy_randomness_min": 0.03324233733191349, "train/policy_randomness_std": 0.08743371526793678, "train/post_ent_mag": 62.286707849785834, "train/post_ent_max": 62.286707849785834, "train/post_ent_mean": 59.905438527022255, "train/post_ent_min": 58.506570211731564, "train/post_ent_std": 0.7423209568651596, "train/prior_ent_mag": 65.5365183613088, "train/prior_ent_max": 65.5365183613088, "train/prior_ent_mean": 61.37069469867367, "train/prior_ent_min": 57.077719527896086, "train/prior_ent_std": 1.6060212950895327, "train/rep_loss_mean": 1.5641886119795319, "train/rep_loss_std": 0.033298883762645434, "train/reward_avg": 0.0010417371683282602, "train/reward_loss_mean": 0.008249149902142806, "train/reward_loss_std": 0.1515387344804574, "train/reward_max_data": 0.5761448029096764, "train/reward_max_pred": 0.10573052238709855, "train/reward_neg_acc": 0.9999079689531043, "train/reward_neg_loss": 0.0014864531846193708, "train/reward_pos_acc": 0.13489583414047956, "train/reward_pos_loss": 4.292363754659891, "train/reward_pred": 0.0008319343047188872, "train/reward_rate": 0.0015857054455445546, "train_stats/mean_log_entropy": 0.09245966186961241, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.011336913332343102, "report/cont_loss_std": 0.1985248476266861, "report/cont_neg_acc": 0.6666666865348816, "report/cont_neg_loss": 1.493978500366211, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.00259835715405643, "report/cont_pred": 0.9935904741287231, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.09785866737365723, "report/image_loss_std": 0.10244005173444748, "report/model_loss_mean": 0.7221328020095825, "report/model_loss_std": 0.4870994985103607, "report/post_ent_mag": 63.14744567871094, "report/post_ent_max": 63.14744567871094, "report/post_ent_mean": 60.67253494262695, "report/post_ent_min": 58.9987678527832, "report/post_ent_std": 0.795278012752533, "report/prior_ent_mag": 68.17657470703125, "report/prior_ent_max": 68.17657470703125, "report/prior_ent_mean": 64.77267456054688, "report/prior_ent_min": 61.328330993652344, "report/prior_ent_std": 1.2035138607025146, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0017730712424963713, "report/reward_loss_mean": 0.01293720118701458, "report/reward_loss_std": 0.2542249858379364, "report/reward_max_data": 0.9375, "report/reward_max_pred": 0.030582666397094727, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0017055075149983168, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 5.75233268737793, "report/reward_pred": 0.000850141397677362, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.03485899418592453, "eval/cont_loss_std": 0.5264003276824951, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 8.102696418762207, "eval/cont_pos_acc": 0.9990195631980896, "eval/cont_pos_loss": 0.003220419166609645, "eval/cont_pred": 0.9981460571289062, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.19009801745414734, "eval/image_loss_std": 0.16016776859760284, "eval/model_loss_mean": 0.8252232074737549, "eval/model_loss_std": 0.5447866320610046, "eval/post_ent_mag": 63.14765167236328, "eval/post_ent_max": 63.14765167236328, "eval/post_ent_mean": 60.46324920654297, "eval/post_ent_min": 59.059757232666016, "eval/post_ent_std": 0.7979394793510437, "eval/prior_ent_mag": 68.17657470703125, "eval/prior_ent_max": 68.17657470703125, "eval/prior_ent_mean": 64.53136444091797, "eval/prior_ent_min": 60.688873291015625, "eval/prior_ent_std": 1.2882804870605469, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0002661757171154022, "eval/reward_loss_std": 0.001854429952800274, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.015743136405944824, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0002661757171154022, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0001245646271854639, "eval/reward_rate": 0.0, "replay/size": 580177.0, "replay/inserts": 32352.0, "replay/samples": 32352.0, "replay/insert_wait_avg": 1.3344719431166833e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.353493687660829e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 6272.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1051187709886201e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0728836059570312e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2848861217499, "timer/env.step_count": 4044.0, "timer/env.step_total": 38.23359680175781, "timer/env.step_frac": 0.03822270768280328, "timer/env.step_avg": 0.009454400791730419, "timer/env.step_min": 0.007493019104003906, "timer/env.step_max": 0.037698984146118164, "timer/replay._sample_count": 32352.0, "timer/replay._sample_total": 16.883366346359253, "timer/replay._sample_frac": 0.01687855787946424, "timer/replay._sample_avg": 0.0005218646867692648, "timer/replay._sample_min": 0.00038051605224609375, "timer/replay._sample_max": 0.030396461486816406, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4828.0, "timer/agent.policy_total": 49.99890422821045, "timer/agent.policy_frac": 0.0499846642910536, "timer/agent.policy_avg": 0.010356028216282197, "timer/agent.policy_min": 0.008392333984375, "timer/agent.policy_max": 0.08741021156311035, "timer/dataset_train_count": 2022.0, "timer/dataset_train_total": 0.21611380577087402, "timer/dataset_train_frac": 0.00021605225548171453, "timer/dataset_train_avg": 0.00010688120958005639, "timer/dataset_train_min": 9.322166442871094e-05, "timer/dataset_train_max": 0.00033354759216308594, "timer/agent.train_count": 2022.0, "timer/agent.train_total": 898.4512391090393, "timer/agent.train_frac": 0.8981953557175751, "timer/agent.train_avg": 0.44433790262563766, "timer/agent.train_min": 0.434476375579834, "timer/agent.train_max": 0.675105094909668, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4808809757232666, "timer/agent.report_frac": 0.0004807440184243032, "timer/agent.report_avg": 0.2404404878616333, "timer/agent.report_min": 0.23229122161865234, "timer/agent.report_max": 0.24858975410461426, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.147125244140625e-05, "timer/dataset_eval_frac": 3.1462289271834224e-08, "timer/dataset_eval_avg": 3.147125244140625e-05, "timer/dataset_eval_min": 3.147125244140625e-05, "timer/dataset_eval_max": 3.147125244140625e-05, "fps": 32.342210027064965}
{"step": 580696, "time": 18226.087666749954, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 580704, "time": 18226.93157339096, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 580712, "time": 18226.959414958954, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 580864, "time": 18231.784108161926, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 580864, "time": 18231.793462991714, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 580880, "time": 18232.279991149902, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 581136, "time": 18240.13747525215, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 581136, "time": 18240.14574456215, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 581152, "time": 18240.63380050659, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 581208, "time": 18242.104419708252, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 581376, "time": 18247.389013051987, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 581488, "time": 18250.787932872772, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 581544, "time": 18252.29067182541, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 581544, "time": 18252.29842877388, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 581720, "time": 18258.139680624008, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 581960, "time": 18265.49593758583, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 582064, "time": 18268.87355542183, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 582136, "time": 18270.82313966751, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 582184, "time": 18272.279116630554, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 582192, "time": 18272.766246318817, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 582312, "time": 18276.16618490219, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 582672, "time": 18287.257843017578, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 582720, "time": 18288.711358070374, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 582856, "time": 18292.59841632843, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 582904, "time": 18294.042902231216, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 583016, "time": 18297.51610326767, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 583128, "time": 18300.873846530914, "episode/length": 197.0, "episode/score": 0.3843750059604645, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.0}
{"step": 583448, "time": 18310.52529644966, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 583496, "time": 18311.994324445724, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 583752, "time": 18319.761843442917, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 583888, "time": 18324.10625243187, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 584240, "time": 18334.79272723198, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 584344, "time": 18337.72502565384, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 584504, "time": 18342.550491571426, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 584720, "time": 18349.2755548954, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 584760, "time": 18350.284764289856, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 585016, "time": 18358.061920404434, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 585032, "time": 18358.548854112625, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 585096, "time": 18360.497554063797, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 585168, "time": 18362.883397102356, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 585440, "time": 18371.093955516815, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 585496, "time": 18372.56243443489, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 585584, "time": 18375.452416181564, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 585888, "time": 18384.64332127571, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 586200, "time": 18393.984300374985, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 586248, "time": 18395.434476852417, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 586288, "time": 18396.86169743538, "episode/length": 195.0, "episode/score": 0.390625, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.0}
{"step": 586360, "time": 18398.837198495865, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 586488, "time": 18402.678969860077, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 586568, "time": 18405.10430788994, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 586688, "time": 18408.940490722656, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 586760, "time": 18410.885447978973, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 586840, "time": 18413.314049720764, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 587152, "time": 18423.071039915085, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 587184, "time": 18424.037314891815, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 587320, "time": 18427.929804086685, "episode/length": 16.0, "episode/score": 0.949999988079071, "episode/reward_rate": 0.058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 587344, "time": 18428.87762451172, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 587376, "time": 18429.844376802444, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 587808, "time": 18442.8645966053, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 588048, "time": 18450.18129634857, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 588144, "time": 18453.099970817566, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 588432, "time": 18461.792879104614, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 588672, "time": 18469.04053092003, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 588800, "time": 18472.92073392868, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 588880, "time": 18475.445187091827, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 589016, "time": 18479.337374448776, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 589072, "time": 18481.27389717102, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 589320, "time": 18488.51878452301, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 589632, "time": 18498.247243881226, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 589640, "time": 18498.27794456482, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 589688, "time": 18499.750379800797, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 589712, "time": 18500.742000579834, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 589848, "time": 18505.257665634155, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 589968, "time": 18509.120512008667, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 590096, "time": 18516.496933460236, "eval_episode/length": 41.0, "eval_episode/score": 0.871874988079071, "eval_episode/reward_rate": 0.023809523809523808}
{"step": 590096, "time": 18516.948081970215, "eval_episode/length": 64.0, "eval_episode/score": 0.800000011920929, "eval_episode/reward_rate": 0.015384615384615385}
{"step": 590096, "time": 18517.72597503662, "eval_episode/length": 105.0, "eval_episode/score": 0.671875, "eval_episode/reward_rate": 0.009433962264150943}
{"step": 590096, "time": 18517.73245882988, "eval_episode/length": 105.0, "eval_episode/score": 0.671875, "eval_episode/reward_rate": 0.009433962264150943}
{"step": 590096, "time": 18517.868868350983, "eval_episode/length": 112.0, "eval_episode/score": 0.6499999761581421, "eval_episode/reward_rate": 0.008849557522123894}
{"step": 590096, "time": 18518.35353064537, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 590096, "time": 18518.37940955162, "eval_episode/length": 140.0, "eval_episode/score": 0.5625, "eval_episode/reward_rate": 0.0070921985815602835}
{"step": 590096, "time": 18518.548215150833, "eval_episode/length": 149.0, "eval_episode/score": 0.534375011920929, "eval_episode/reward_rate": 0.006666666666666667}
{"step": 590336, "time": 18525.792728185654, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 590432, "time": 18528.693833589554, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 590456, "time": 18529.19800877571, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 590728, "time": 18537.498830795288, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 590736, "time": 18537.96379995346, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 590816, "time": 18540.367810726166, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 591016, "time": 18546.27924823761, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 591336, "time": 18555.939395666122, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 591384, "time": 18557.39525437355, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 591752, "time": 18568.60085964203, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 592000, "time": 18576.375310897827, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 592512, "time": 18591.83657169342, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 592768, "time": 18599.652312517166, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 593040, "time": 18607.84578180313, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 593048, "time": 18607.874953985214, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 593128, "time": 18610.3093624115, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 593328, "time": 18616.556706428528, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 593536, "time": 18623.02117753029, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 593696, "time": 18627.9745388031, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 594016, "time": 18637.646706819534, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 594256, "time": 18644.920279979706, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 594312, "time": 18646.395326137543, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 594472, "time": 18651.241827964783, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 594824, "time": 18661.937059640884, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 594872, "time": 18663.397934436798, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 595016, "time": 18667.746683597565, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 595120, "time": 18671.09510922432, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 595144, "time": 18671.60175561905, "episode/length": 15.0, "episode/score": 0.953125, "episode/reward_rate": 0.0625, "episode/intrinsic_return": 0.0}
{"step": 595352, "time": 18677.90171098709, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 595440, "time": 18680.764338493347, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 595448, "time": 18680.790919303894, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 595536, "time": 18683.649838209152, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0}
{"step": 595640, "time": 18686.66276025772, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 595672, "time": 18687.626878023148, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 595680, "time": 18688.092403411865, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 595776, "time": 18690.975499868393, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 596088, "time": 18700.172985076904, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 596328, "time": 18707.395451545715, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 596368, "time": 18708.812361240387, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 596384, "time": 18709.30027103424, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 596512, "time": 18713.153292417526, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 596664, "time": 18717.618368148804, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 596944, "time": 18726.31208539009, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 596968, "time": 18726.81739425659, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 596976, "time": 18727.289062023163, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 597136, "time": 18732.1292283535, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 597272, "time": 18736.045325040817, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 597328, "time": 18737.96583867073, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 597832, "time": 18753.09446644783, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 597952, "time": 18756.947323560715, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 597984, "time": 18757.91589164734, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 598160, "time": 18765.192527770996, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 598584, "time": 18777.86604499817, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 598824, "time": 18785.09012579918, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 599088, "time": 18793.24977850914, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 599256, "time": 18798.111018180847, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 599312, "time": 18800.04114151001, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 599448, "time": 18803.9141664505, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 599640, "time": 18809.840507745743, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 599656, "time": 18810.327235221863, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 599832, "time": 18815.643451213837, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 599920, "time": 18818.541313409805, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 599960, "time": 18819.544897794724, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 600080, "time": 18824.595487117767, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 600080, "time": 18824.811759710312, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 600080, "time": 18824.873490571976, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 600080, "time": 18825.04319667816, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 600080, "time": 18825.570577144623, "eval_episode/length": 113.0, "eval_episode/score": 0.6468750238418579, "eval_episode/reward_rate": 0.008771929824561403}
{"step": 600080, "time": 18825.930025339127, "eval_episode/length": 57.0, "eval_episode/score": 0.8218749761581421, "eval_episode/reward_rate": 0.017241379310344827}
{"step": 600080, "time": 18825.99505186081, "eval_episode/length": 135.0, "eval_episode/score": 0.578125, "eval_episode/reward_rate": 0.007352941176470588}
{"step": 600080, "time": 18826.218418121338, "eval_episode/length": 59.0, "eval_episode/score": 0.815625011920929, "eval_episode/reward_rate": 0.016666666666666666}
{"step": 600264, "time": 18831.533043146133, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 600304, "time": 18832.979969263077, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 600320, "time": 18833.466556310654, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 600392, "time": 18835.523760080338, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 600544, "time": 18840.33184814453, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 600808, "time": 18848.058226823807, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 600864, "time": 18849.970650434494, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 600864, "time": 18849.97869515419, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 601136, "time": 18858.243847608566, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 601304, "time": 18863.12240242958, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 601344, "time": 18864.552758693695, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 601384, "time": 18865.660831451416, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 601384, "time": 18865.670939922333, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 601456, "time": 18868.084553718567, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 601800, "time": 18878.36165189743, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 601872, "time": 18880.773880958557, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 602296, "time": 18893.373650312424, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 602312, "time": 18893.864853858948, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 602408, "time": 18896.913907051086, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 602568, "time": 18901.76871418953, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 602656, "time": 18904.66452717781, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 602664, "time": 18904.693889141083, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 602832, "time": 18910.03256392479, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 603088, "time": 18917.765978336334, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 603120, "time": 18918.73625779152, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 603216, "time": 18921.650467395782, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 603448, "time": 18928.57200527191, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 603960, "time": 18944.06730723381, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 603992, "time": 18945.032605409622, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 604120, "time": 18948.908542871475, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 604184, "time": 18950.850821495056, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 604624, "time": 18964.524810552597, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 604688, "time": 18966.45978498459, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 604720, "time": 18967.42859363556, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 604904, "time": 18972.777819156647, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 604976, "time": 18975.193571805954, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 605024, "time": 18976.639343738556, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 605240, "time": 18982.979584932327, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 605400, "time": 18987.963767528534, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 605728, "time": 19001.990127325058, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 605832, "time": 19004.90710902214, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 605840, "time": 19005.37546801567, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 606112, "time": 19013.6088950634, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 606152, "time": 19014.603499412537, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 606272, "time": 19019.05128979683, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 606384, "time": 19022.450928211212, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 606688, "time": 19031.62380552292, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 606800, "time": 19034.99880719185, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 606896, "time": 19037.92004299164, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 607024, "time": 19041.78667616844, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 607072, "time": 19043.237056732178, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 607256, "time": 19048.74028944969, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 607336, "time": 19051.173394441605, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 607568, "time": 19058.392661094666, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 607696, "time": 19062.264254808426, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 607712, "time": 19062.751005887985, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 607944, "time": 19069.56099176407, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 607976, "time": 19070.553108215332, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 608040, "time": 19072.474514245987, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 608376, "time": 19082.70300412178, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 608400, "time": 19083.65399003029, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 608416, "time": 19084.140445947647, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 608968, "time": 19100.554909706116, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 609072, "time": 19103.932680368423, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 609096, "time": 19104.43939447403, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 609568, "time": 19119.024797677994, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 609792, "time": 19125.79312801361, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 610024, "time": 19132.569164037704, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 610064, "time": 19135.985772371292, "eval_episode/length": 99.0, "eval_episode/score": 0.690625011920929, "eval_episode/reward_rate": 0.01}
{"step": 610064, "time": 19136.344381809235, "eval_episode/length": 118.0, "eval_episode/score": 0.6312500238418579, "eval_episode/reward_rate": 0.008403361344537815}
{"step": 610064, "time": 19136.371132850647, "eval_episode/length": 119.0, "eval_episode/score": 0.628125011920929, "eval_episode/reward_rate": 0.008333333333333333}
{"step": 610064, "time": 19136.495168685913, "eval_episode/length": 125.0, "eval_episode/score": 0.609375, "eval_episode/reward_rate": 0.007936507936507936}
{"step": 610064, "time": 19136.967608213425, "eval_episode/length": 149.0, "eval_episode/score": 0.534375011920929, "eval_episode/reward_rate": 0.006666666666666667}
{"step": 610064, "time": 19137.049916744232, "eval_episode/length": 153.0, "eval_episode/score": 0.5218750238418579, "eval_episode/reward_rate": 0.006493506493506494}
{"step": 610064, "time": 19137.274035453796, "eval_episode/length": 46.0, "eval_episode/score": 0.856249988079071, "eval_episode/reward_rate": 0.02127659574468085}
{"step": 610064, "time": 19137.335369825363, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 610256, "time": 19143.118941545486, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 610264, "time": 19143.147969722748, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 610352, "time": 19146.04289674759, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 610648, "time": 19154.781308174133, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 610688, "time": 19156.239161252975, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 610840, "time": 19160.61952996254, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 610872, "time": 19161.5880048275, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 610896, "time": 19162.535060167313, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 611072, "time": 19167.95547890663, "episode/length": 249.0, "episode/score": 0.22187499701976776, "episode/reward_rate": 0.004, "episode/intrinsic_return": 0.0}
{"step": 611144, "time": 19169.912794828415, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 611408, "time": 19178.11651134491, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 611408, "time": 19178.123966932297, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 611432, "time": 19178.63330388069, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 612040, "time": 19197.01362681389, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 612056, "time": 19197.4977080822, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 612096, "time": 19198.927885055542, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 612104, "time": 19198.956273794174, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 612264, "time": 19203.781169891357, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 612760, "time": 19218.793674707413, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 612969, "time": 19226.170647144318, "train_stats/mean_log_entropy": 0.08910163957625628, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.5975251150603342, "train/action_min": 0.0, "train/action_std": 1.9129343274796362, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.010069579196088753, "train/actor_opt_grad_steps": 37205.0, "train/actor_opt_loss": -7.040175534268417, "train/adv_mag": 0.996972378527764, "train/adv_max": 0.3452775608194937, "train/adv_mean": 0.0015727122673155518, "train/adv_min": -0.9469460157474668, "train/adv_std": 0.031143308329017887, "train/cont_avg": 0.9955329517326733, "train/cont_loss_mean": 0.015500588260710903, "train/cont_loss_std": 0.22274329913503463, "train/cont_neg_acc": 0.35244775047101595, "train/cont_neg_loss": 2.7126856718412924, "train/cont_pos_acc": 0.999868916402949, "train/cont_pos_loss": 0.0031209058412996187, "train/cont_pred": 0.9955015203150193, "train/cont_rate": 0.9955329517326733, "train/dyn_loss_mean": 1.000034235491611, "train/dyn_loss_std": 0.00040369505287605654, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.2702053146676557, "train/extr_critic_critic_opt_grad_steps": 37205.0, "train/extr_critic_critic_opt_loss": 3319.3077102510056, "train/extr_critic_mag": 1.2459831662697367, "train/extr_critic_max": 1.2459831662697367, "train/extr_critic_mean": 1.2011760567674543, "train/extr_critic_min": 1.0004010023456988, "train/extr_critic_std": 0.014046730782541603, "train/extr_return_normed_mag": 0.9742591832533921, "train/extr_return_normed_max": 0.29089931037166333, "train/extr_return_normed_mean": 0.028333001770079136, "train/extr_return_normed_min": -0.9400625851484808, "train/extr_return_normed_std": 0.034941513095936266, "train/extr_return_rate": 0.9990995423038407, "train/extr_return_raw_mag": 1.4653150309430492, "train/extr_return_raw_max": 1.4653150309430492, "train/extr_return_raw_mean": 1.2027487908259478, "train/extr_return_raw_min": 0.2343531354229049, "train/extr_return_raw_std": 0.03494151338178775, "train/extr_reward_mag": 0.31758318148036996, "train/extr_reward_max": 0.31758318148036996, "train/extr_reward_mean": 0.0025301848792950487, "train/extr_reward_min": 6.255536976427135e-08, "train/extr_reward_std": 0.009244479229765953, "train/image_loss_mean": 0.10523813900233496, "train/image_loss_std": 0.10694333022036175, "train/model_loss_mean": 0.7305803375669045, "train/model_loss_std": 0.4003161365664241, "train/model_opt_grad_norm": 22.81762710420212, "train/model_opt_grad_steps": 37172.0, "train/model_opt_loss": 1434.2014000014503, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1961.6336633663366, "train/policy_entropy_mag": 1.3969836235046387, "train/policy_entropy_max": 1.3969836235046387, "train/policy_entropy_mean": 0.11685967331032941, "train/policy_entropy_min": 0.06468652487538828, "train/policy_entropy_std": 0.15336783193420656, "train/policy_logprob_mag": 6.551080245782833, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.11720912147424009, "train/policy_logprob_min": -6.551080245782833, "train/policy_logprob_std": 0.6562815698066561, "train/policy_randomness_mag": 0.7179076099159694, "train/policy_randomness_max": 0.7179076099159694, "train/policy_randomness_mean": 0.06005399578278608, "train/policy_randomness_min": 0.033242300023684404, "train/policy_randomness_std": 0.07881547910816009, "train/post_ent_mag": 61.63536628874222, "train/post_ent_max": 61.63536628874222, "train/post_ent_mean": 59.08804749970389, "train/post_ent_min": 57.513174321391794, "train/post_ent_std": 0.8058099569660602, "train/prior_ent_mag": 66.35096298822081, "train/prior_ent_max": 66.35096298822081, "train/prior_ent_mean": 63.035676918407475, "train/prior_ent_min": 59.04441000683473, "train/prior_ent_std": 1.2708987336937745, "train/rep_loss_mean": 1.000034235491611, "train/rep_loss_std": 0.00040369505287605654, "train/reward_avg": 0.001239089207452293, "train/reward_loss_mean": 0.00982104766177991, "train/reward_loss_std": 0.17625534756911346, "train/reward_max_data": 0.6510210380253225, "train/reward_max_pred": 0.10723942341190754, "train/reward_neg_acc": 0.9998740860731294, "train/reward_neg_loss": 0.001725436696661106, "train/reward_pos_acc": 0.09125639009947158, "train/reward_pos_loss": 4.377675528580186, "train/reward_pred": 0.000943360043376094, "train/reward_rate": 0.001846766707920792, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.021516650915145874, "report/cont_loss_std": 0.24055518209934235, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 3.0206379890441895, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0038401037454605103, "report/cont_pred": 0.9957424402236938, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.08895164728164673, "report/image_loss_std": 0.10722783952951431, "report/model_loss_mean": 0.7382631301879883, "report/model_loss_std": 0.5993403196334839, "report/post_ent_mag": 58.8090934753418, "report/post_ent_max": 58.8090934753418, "report/post_ent_mean": 56.241607666015625, "report/post_ent_min": 54.683494567871094, "report/post_ent_std": 0.8241069316864014, "report/prior_ent_mag": 63.29811096191406, "report/prior_ent_max": 63.29811096191406, "report/prior_ent_mean": 59.61924743652344, "report/prior_ent_min": 54.80485916137695, "report/prior_ent_std": 1.2210066318511963, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0041290284134447575, "report/reward_loss_mean": 0.027794841676950455, "report/reward_loss_std": 0.3256697952747345, "report/reward_max_data": 0.8531249761581421, "report/reward_max_pred": 0.2756549119949341, "report/reward_neg_acc": 0.9990177154541016, "report/reward_neg_loss": 0.003381362883374095, "report/reward_pos_acc": 0.1666666716337204, "report/reward_pos_loss": 4.169948577880859, "report/reward_pred": 0.0018608011305332184, "report/reward_rate": 0.005859375, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.04310821741819382, "eval/cont_loss_std": 0.6659963130950928, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 10.338348388671875, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.002734723500907421, "eval/cont_pred": 0.9975159168243408, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.17327968776226044, "eval/image_loss_std": 0.1414562314748764, "eval/model_loss_mean": 0.8170101642608643, "eval/model_loss_std": 0.6763805747032166, "eval/post_ent_mag": 58.808868408203125, "eval/post_ent_max": 58.808868408203125, "eval/post_ent_mean": 56.07258605957031, "eval/post_ent_min": 54.55980682373047, "eval/post_ent_std": 0.8738228678703308, "eval/prior_ent_mag": 62.544036865234375, "eval/prior_ent_max": 62.544036865234375, "eval/prior_ent_mean": 59.13386917114258, "eval/prior_ent_min": 55.129859924316406, "eval/prior_ent_std": 1.2744029760360718, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0006222543306648731, "eval/reward_loss_std": 0.003794840769842267, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.01682913303375244, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0006222543306648731, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00030706007964909077, "eval/reward_rate": 0.0, "replay/size": 612465.0, "replay/inserts": 32288.0, "replay/samples": 32288.0, "replay/insert_wait_avg": 1.3341191266289552e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.503113558554673e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3728.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.130953367175974e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.940696716308594e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1182415485382, "timer/env.step_count": 4036.0, "timer/env.step_total": 38.19598126411438, "timer/env.step_frac": 0.03819146544609909, "timer/env.step_avg": 0.00946382092767948, "timer/env.step_min": 0.007524013519287109, "timer/env.step_max": 0.044048309326171875, "timer/replay._sample_count": 32288.0, "timer/replay._sample_total": 16.917256116867065, "timer/replay._sample_frac": 0.016915256030800064, "timer/replay._sample_avg": 0.0005239487152151593, "timer/replay._sample_min": 0.0004019737243652344, "timer/replay._sample_max": 0.022439002990722656, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4502.0, "timer/agent.policy_total": 46.79550528526306, "timer/agent.policy_frac": 0.0467899727664271, "timer/agent.policy_avg": 0.010394381449414274, "timer/agent.policy_min": 0.008340835571289062, "timer/agent.policy_max": 0.07785892486572266, "timer/dataset_train_count": 2018.0, "timer/dataset_train_total": 0.22333097457885742, "timer/dataset_train_frac": 0.0002233045707006221, "timer/dataset_train_avg": 0.0001106694621302564, "timer/dataset_train_min": 9.34600830078125e-05, "timer/dataset_train_max": 0.005421638488769531, "timer/agent.train_count": 2018.0, "timer/agent.train_total": 896.125039100647, "timer/agent.train_frac": 0.8960190924156399, "timer/agent.train_avg": 0.44406592621439395, "timer/agent.train_min": 0.43396425247192383, "timer/agent.train_max": 0.7529373168945312, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4756615161895752, "timer/agent.report_frac": 0.00047560527988478867, "timer/agent.report_avg": 0.2378307580947876, "timer/agent.report_min": 0.2313213348388672, "timer/agent.report_max": 0.244340181350708, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.3855438232421875e-05, "timer/dataset_eval_frac": 3.385143558625791e-08, "timer/dataset_eval_avg": 3.3855438232421875e-05, "timer/dataset_eval_min": 3.3855438232421875e-05, "timer/dataset_eval_max": 3.3855438232421875e-05, "fps": 32.283653345004716}
{"step": 613152, "time": 19231.686230182648, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 613208, "time": 19233.165626764297, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 613384, "time": 19238.4920501709, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 613712, "time": 19248.684992313385, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 614264, "time": 19265.189286231995, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 614352, "time": 19268.099621534348, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 614368, "time": 19268.592519044876, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 614408, "time": 19269.822412967682, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 614416, "time": 19270.542001485825, "episode/length": 206.0, "episode/score": 0.35624998807907104, "episode/reward_rate": 0.004830917874396135, "episode/intrinsic_return": 0.0}
{"step": 614528, "time": 19273.955693244934, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 614552, "time": 19274.468893289566, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0}
{"step": 614576, "time": 19275.425419569016, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 614840, "time": 19283.202448368073, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 615008, "time": 19288.62041568756, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 615080, "time": 19290.567321777344, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 615144, "time": 19292.498658657074, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 615424, "time": 19301.17951631546, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 615576, "time": 19305.56748533249, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 615800, "time": 19312.357445001602, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 615920, "time": 19316.306651353836, "episode/length": 187.0, "episode/score": 0.4156250059604645, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.0}
{"step": 616056, "time": 19320.21379184723, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 616312, "time": 19327.9765021801, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 616504, "time": 19333.764060020447, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 616552, "time": 19335.21630859375, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 616576, "time": 19336.175149440765, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 616720, "time": 19340.535719156265, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 616864, "time": 19344.902785778046, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 617128, "time": 19352.741924762726, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 617320, "time": 19358.51081776619, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 617456, "time": 19362.83403277397, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 617600, "time": 19367.16800236702, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 617616, "time": 19367.660648822784, "episode/length": 19.0, "episode/score": 0.940625011920929, "episode/reward_rate": 0.05, "episode/intrinsic_return": 0.0}
{"step": 618160, "time": 19384.15708398819, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 618264, "time": 19387.081421613693, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 618384, "time": 19390.918399333954, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 618816, "time": 19403.965527772903, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 618864, "time": 19405.53548026085, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 618984, "time": 19408.92705988884, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 619032, "time": 19410.398663043976, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 619176, "time": 19414.751843690872, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 619440, "time": 19422.929777145386, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 619720, "time": 19431.160264015198, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 619816, "time": 19434.072900533676, "episode/length": 11.0, "episode/score": 0.965624988079071, "episode/reward_rate": 0.08333333333333333, "episode/intrinsic_return": 0.0}
{"step": 619896, "time": 19436.590662956238, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 620048, "time": 19442.593675136566, "eval_episode/length": 65.0, "eval_episode/score": 0.796875, "eval_episode/reward_rate": 0.015151515151515152}
{"step": 620048, "time": 19443.176470518112, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 620048, "time": 19443.22406601906, "eval_episode/length": 100.0, "eval_episode/score": 0.6875, "eval_episode/reward_rate": 0.009900990099009901}
{"step": 620048, "time": 19443.38543152809, "eval_episode/length": 108.0, "eval_episode/score": 0.6625000238418579, "eval_episode/reward_rate": 0.009174311926605505}
{"step": 620048, "time": 19443.66142964363, "eval_episode/length": 123.0, "eval_episode/score": 0.6156250238418579, "eval_episode/reward_rate": 0.008064516129032258}
{"step": 620048, "time": 19444.185368299484, "eval_episode/length": 152.0, "eval_episode/score": 0.5249999761581421, "eval_episode/reward_rate": 0.006535947712418301}
{"step": 620048, "time": 19447.353717803955, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 620048, "time": 19447.36170911789, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 620312, "time": 19455.150723695755, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 620376, "time": 19457.08980369568, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 620480, "time": 19460.457974910736, "episode/length": 207.0, "episode/score": 0.3531250059604645, "episode/reward_rate": 0.004807692307692308, "episode/intrinsic_return": 0.0}
{"step": 620552, "time": 19462.416303634644, "episode/length": 210.0, "episode/score": 0.34375, "episode/reward_rate": 0.004739336492890996, "episode/intrinsic_return": 0.0}
{"step": 620576, "time": 19463.36691045761, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 620888, "time": 19472.74813747406, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 620992, "time": 19476.13179731369, "episode/length": 250.0, "episode/score": 0.21875, "episode/reward_rate": 0.00398406374501992, "episode/intrinsic_return": 0.0}
{"step": 621080, "time": 19478.587076425552, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 621104, "time": 19479.539489507675, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 621272, "time": 19484.38854074478, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 621664, "time": 19496.537284612656, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 621720, "time": 19498.030056238174, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 621752, "time": 19498.998012781143, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 622064, "time": 19508.650792837143, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 622128, "time": 19510.58504009247, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 622272, "time": 19515.211020708084, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 622416, "time": 19519.585586309433, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 622864, "time": 19533.732918024063, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 622936, "time": 19535.68714118004, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 622944, "time": 19536.153290510178, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 623200, "time": 19543.92259812355, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 623320, "time": 19547.348022699356, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 623416, "time": 19550.243153095245, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 623568, "time": 19555.118342876434, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 623584, "time": 19555.619463682175, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 624000, "time": 19568.20613217354, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 624064, "time": 19570.135387659073, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 624312, "time": 19577.44047188759, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 624328, "time": 19577.93180322647, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 624456, "time": 19581.808381080627, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 624528, "time": 19584.212089776993, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 624536, "time": 19584.24077129364, "episode/length": 208.0, "episode/score": 0.3499999940395355, "episode/reward_rate": 0.004784688995215311, "episode/intrinsic_return": 0.0}
{"step": 625104, "time": 19601.79376721382, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 625256, "time": 19606.17551970482, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 625344, "time": 19609.059421539307, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 625352, "time": 19609.08775115013, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 625600, "time": 19616.91395998001, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 625632, "time": 19617.88869857788, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 625648, "time": 19618.377553462982, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 625664, "time": 19618.869059324265, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 625896, "time": 19625.683735370636, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 625976, "time": 19628.105644464493, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 626032, "time": 19630.04385972023, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 626032, "time": 19630.05177140236, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 626064, "time": 19631.026188135147, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 626208, "time": 19635.395308971405, "episode/length": 17.0, "episode/score": 0.9468749761581421, "episode/reward_rate": 0.05555555555555555, "episode/intrinsic_return": 0.0}
{"step": 626368, "time": 19640.250589609146, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 626456, "time": 19642.688075065613, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 626688, "time": 19650.088389396667, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 627088, "time": 19662.21215057373, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 627136, "time": 19663.667392015457, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 627256, "time": 19667.093341350555, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 627488, "time": 19674.33268404007, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 627664, "time": 19679.772789001465, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 627904, "time": 19687.030612945557, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 627960, "time": 19688.526042222977, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 627984, "time": 19689.47861623764, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 628176, "time": 19695.29457592964, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 628208, "time": 19696.266636371613, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 628288, "time": 19698.712786912918, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 628688, "time": 19710.942461252213, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 628768, "time": 19713.37726831436, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 628936, "time": 19718.252084732056, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 628976, "time": 19719.691560268402, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 629008, "time": 19720.66126346588, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 629304, "time": 19729.440366506577, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 629504, "time": 19735.832769870758, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 629616, "time": 19739.240080356598, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 629728, "time": 19742.643166065216, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 629808, "time": 19745.06736946106, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 629816, "time": 19745.095463752747, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 629952, "time": 19749.44307088852, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 629992, "time": 19750.438119649887, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 630032, "time": 19753.03720831871, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 630032, "time": 19753.712839841843, "eval_episode/length": 99.0, "eval_episode/score": 0.690625011920929, "eval_episode/reward_rate": 0.01}
{"step": 630032, "time": 19753.955727100372, "eval_episode/length": 112.0, "eval_episode/score": 0.6499999761581421, "eval_episode/reward_rate": 0.008849557522123894}
{"step": 630032, "time": 19754.59125852585, "eval_episode/length": 33.0, "eval_episode/score": 0.8968750238418579, "eval_episode/reward_rate": 0.029411764705882353}
{"step": 630032, "time": 19754.616220474243, "eval_episode/length": 147.0, "eval_episode/score": 0.5406249761581421, "eval_episode/reward_rate": 0.006756756756756757}
{"step": 630032, "time": 19755.273914575577, "eval_episode/length": 36.0, "eval_episode/score": 0.887499988079071, "eval_episode/reward_rate": 0.02702702702702703}
{"step": 630032, "time": 19755.39643883705, "eval_episode/length": 43.0, "eval_episode/score": 0.8656250238418579, "eval_episode/reward_rate": 0.022727272727272728}
{"step": 630032, "time": 19755.74483013153, "eval_episode/length": 209.0, "eval_episode/score": 0.34687501192092896, "eval_episode/reward_rate": 0.004761904761904762}
{"step": 630272, "time": 19763.00734424591, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 630472, "time": 19768.937759160995, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 630600, "time": 19772.838101625443, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 630624, "time": 19773.78846693039, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 630720, "time": 19776.71816468239, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 630872, "time": 19781.569575309753, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 631008, "time": 19785.924757242203, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 631128, "time": 19789.316156625748, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 631360, "time": 19796.65014910698, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 631488, "time": 19800.527166366577, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 631496, "time": 19800.555033683777, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 631632, "time": 19804.91048002243, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 631728, "time": 19807.811033010483, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 631792, "time": 19809.759246587753, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 632120, "time": 19819.46269416809, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 632128, "time": 19819.93057489395, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 632288, "time": 19824.76493191719, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 632440, "time": 19829.250790834427, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 632528, "time": 19832.14227080345, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 632592, "time": 19834.10778737068, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 632768, "time": 19839.46538257599, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 632808, "time": 19840.458759069443, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 633192, "time": 19852.108164787292, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 633384, "time": 19858.300958156586, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 633520, "time": 19862.63261628151, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 633808, "time": 19871.346304178238, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 633888, "time": 19873.79660511017, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 633944, "time": 19875.286036014557, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 634128, "time": 19881.091751098633, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 634248, "time": 19884.504492282867, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 634376, "time": 19888.486463308334, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 634400, "time": 19889.441035747528, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 634440, "time": 19890.429532766342, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 635080, "time": 19909.735256671906, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 635120, "time": 19911.161513328552, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 635120, "time": 19911.169636964798, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 635136, "time": 19911.654439926147, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 635456, "time": 19921.3849902153, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 635496, "time": 19922.394694328308, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 635944, "time": 19935.976576566696, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 636048, "time": 19939.4033703804, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 636120, "time": 19941.379861354828, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 636304, "time": 19947.289187669754, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 636504, "time": 19953.128923892975, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 636672, "time": 19958.4315905571, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 636712, "time": 19959.43123626709, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 636872, "time": 19964.27285504341, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 636928, "time": 19966.21123933792, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 637408, "time": 19980.84102320671, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 637432, "time": 19981.35855937004, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 637552, "time": 19985.233656406403, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 637664, "time": 19988.615275621414, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 637928, "time": 19996.391203403473, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 638024, "time": 19999.287244796753, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 638176, "time": 20004.121570825577, "episode/length": 18.0, "episode/score": 0.9437500238418579, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.0}
{"step": 638184, "time": 20004.15216755867, "episode/length": 209.0, "episode/score": 0.34687501192092896, "episode/reward_rate": 0.004761904761904762, "episode/intrinsic_return": 0.0}
{"step": 638360, "time": 20009.60998773575, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 638368, "time": 20010.07973742485, "episode/length": 206.0, "episode/score": 0.35624998807907104, "episode/reward_rate": 0.004830917874396135, "episode/intrinsic_return": 0.0}
{"step": 638472, "time": 20013.00771188736, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 638608, "time": 20017.35737156868, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 639112, "time": 20032.876975536346, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 639144, "time": 20033.847945690155, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 639632, "time": 20048.95629310608, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 639720, "time": 20051.400408506393, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 639864, "time": 20055.765213489532, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 640016, "time": 20061.892585277557, "eval_episode/length": 29.0, "eval_episode/score": 0.909375011920929, "eval_episode/reward_rate": 0.03333333333333333}
{"step": 640016, "time": 20062.098553180695, "eval_episode/length": 40.0, "eval_episode/score": 0.875, "eval_episode/reward_rate": 0.024390243902439025}
{"step": 640016, "time": 20062.476136446, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 640016, "time": 20062.571699619293, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 640016, "time": 20062.85481095314, "eval_episode/length": 81.0, "eval_episode/score": 0.746874988079071, "eval_episode/reward_rate": 0.012195121951219513}
{"step": 640016, "time": 20062.969648361206, "eval_episode/length": 87.0, "eval_episode/score": 0.7281249761581421, "eval_episode/reward_rate": 0.011363636363636364}
{"step": 640016, "time": 20063.993061065674, "eval_episode/length": 81.0, "eval_episode/score": 0.746874988079071, "eval_episode/reward_rate": 0.012195121951219513}
{"step": 640016, "time": 20064.29990029335, "eval_episode/length": 130.0, "eval_episode/score": 0.59375, "eval_episode/reward_rate": 0.007633587786259542}
{"step": 640072, "time": 20065.872978448868, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 640144, "time": 20068.29943561554, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 640304, "time": 20073.159925937653, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 640392, "time": 20075.61784029007, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 640488, "time": 20078.548628807068, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 640568, "time": 20080.971709251404, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 640672, "time": 20084.374591827393, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 640680, "time": 20084.40417790413, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 640728, "time": 20085.859305858612, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 641040, "time": 20095.578359365463, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 641576, "time": 20111.559602737427, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 641672, "time": 20114.453877210617, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 641832, "time": 20119.292756319046, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 641976, "time": 20123.637395620346, "episode/length": 197.0, "episode/score": 0.3843750059604645, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.0}
{"step": 642032, "time": 20125.637220859528, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 642384, "time": 20136.297965288162, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 642472, "time": 20138.729606628418, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 642592, "time": 20142.587815523148, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 642632, "time": 20143.583956956863, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 642992, "time": 20154.708750247955, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 643040, "time": 20156.275795459747, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 643088, "time": 20157.730088710785, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 643152, "time": 20159.673756361008, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 643488, "time": 20169.846659898758, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 643912, "time": 20182.44894385338, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 644064, "time": 20187.38787984848, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 644144, "time": 20189.846371889114, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 644152, "time": 20189.87390947342, "episode/length": 10.0, "episode/score": 0.96875, "episode/reward_rate": 0.09090909090909091, "episode/intrinsic_return": 0.0}
{"step": 644696, "time": 20206.351215839386, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 644768, "time": 20208.752383708954, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 644904, "time": 20212.618156194687, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 644976, "time": 20215.064727783203, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 645321, "time": 20226.28644347191, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.5091235472424196, "train/action_min": 0.0, "train/action_std": 1.791711158091479, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.012400916593130862, "train/actor_opt_grad_steps": 39225.0, "train/actor_opt_loss": -9.543077244764508, "train/adv_mag": 1.0109426954595169, "train/adv_max": 0.3937891379441365, "train/adv_mean": 0.0010684610396409799, "train/adv_min": -0.9776857238594848, "train/adv_std": 0.04131809891302987, "train/cont_avg": 0.9951075185643564, "train/cont_loss_mean": 0.015605018680481848, "train/cont_loss_std": 0.22131008851470998, "train/cont_neg_acc": 0.36885314147071085, "train/cont_neg_loss": 2.5442488159616805, "train/cont_pos_acc": 0.9999222050208857, "train/cont_pos_loss": 0.0031336339612463766, "train/cont_pred": 0.995168528639444, "train/cont_rate": 0.9951075185643564, "train/dyn_loss_mean": 1.0000057798801083, "train/dyn_loss_std": 0.00018285976174600292, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.34032991882598046, "train/extr_critic_critic_opt_grad_steps": 39225.0, "train/extr_critic_critic_opt_loss": 4638.79621992961, "train/extr_critic_mag": 1.2787855651118967, "train/extr_critic_max": 1.2787855651118967, "train/extr_critic_mean": 1.2148472294949069, "train/extr_critic_min": 1.0540700271578118, "train/extr_critic_std": 0.015732427644036193, "train/extr_return_normed_mag": 0.9941369684615938, "train/extr_return_normed_max": 0.3818993013684112, "train/extr_return_normed_mean": 0.033717793053463285, "train/extr_return_normed_min": -0.9539903030537142, "train/extr_return_normed_std": 0.04573209684729428, "train/extr_return_rate": 0.9987608082223647, "train/extr_return_raw_mag": 1.5640971259315415, "train/extr_return_raw_max": 1.5640971259315415, "train/extr_return_raw_mean": 1.2159156722597557, "train/extr_return_raw_min": 0.22820752150941603, "train/extr_return_raw_std": 0.045732097008662057, "train/extr_reward_mag": 0.41915720878261153, "train/extr_reward_max": 0.41915720878261153, "train/extr_reward_mean": 0.002586162835820624, "train/extr_reward_min": 5.488348479318147e-08, "train/extr_reward_std": 0.012760535783899745, "train/image_loss_mean": 0.0990568647659061, "train/image_loss_std": 0.1049499231399876, "train/model_loss_mean": 0.7260247805331013, "train/model_loss_std": 0.41672102509453746, "train/model_opt_grad_norm": 21.7767588487312, "train/model_opt_grad_steps": 39191.4702970297, "train/model_opt_loss": 3755.693272354579, "train/model_opt_model_opt_grad_overflow": 0.0049504950495049506, "train/model_opt_model_opt_grad_scale": 5148.514851485149, "train/policy_entropy_mag": 1.2987725622583144, "train/policy_entropy_max": 1.2987725622583144, "train/policy_entropy_mean": 0.11122070459446104, "train/policy_entropy_min": 0.06468650204415369, "train/policy_entropy_std": 0.14263401637868126, "train/policy_logprob_mag": 6.551080250503993, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.11170386036138723, "train/policy_logprob_min": -6.551080250503993, "train/policy_logprob_std": 0.6497332202916098, "train/policy_randomness_mag": 0.6674371051906359, "train/policy_randomness_max": 0.6674371051906359, "train/policy_randomness_mean": 0.057156139136393475, "train/policy_randomness_min": 0.03324228704049446, "train/policy_randomness_std": 0.0732993886317357, "train/post_ent_mag": 53.63815866602529, "train/post_ent_max": 53.63815866602529, "train/post_ent_mean": 51.03128236827284, "train/post_ent_min": 49.51314465362247, "train/post_ent_std": 0.8073772563792692, "train/prior_ent_mag": 58.6419938342406, "train/prior_ent_max": 58.6419938342406, "train/prior_ent_mean": 55.38407253982997, "train/prior_ent_min": 50.59218185726959, "train/prior_ent_std": 1.3788073281250377, "train/rep_loss_mean": 1.0000057798801083, "train/rep_loss_std": 0.00018285976174600292, "train/reward_avg": 0.001461127261593154, "train/reward_loss_mean": 0.011359409925915153, "train/reward_loss_std": 0.1916307554497282, "train/reward_max_data": 0.6621441833748676, "train/reward_max_pred": 0.1405544351823259, "train/reward_neg_acc": 0.9998933903061518, "train/reward_neg_loss": 0.0018661464610607316, "train/reward_pos_acc": 0.1065676843517282, "train/reward_pos_loss": 4.363266854808572, "train/reward_pred": 0.0010797968399388217, "train/reward_rate": 0.002199682858910891, "train_stats/mean_log_entropy": 0.08747458889662663, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.014596129767596722, "report/cont_loss_std": 0.2113485187292099, "report/cont_neg_acc": 0.4000000059604645, "report/cont_neg_loss": 2.389220952987671, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0029443881940096617, "report/cont_pred": 0.9953045845031738, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.0902334526181221, "report/image_loss_std": 0.09351899474859238, "report/model_loss_mean": 0.715935468673706, "report/model_loss_std": 0.41117972135543823, "report/post_ent_mag": 51.07868957519531, "report/post_ent_max": 51.07868957519531, "report/post_ent_mean": 48.626365661621094, "report/post_ent_min": 47.11162567138672, "report/post_ent_std": 0.7927690148353577, "report/prior_ent_mag": 56.3885383605957, "report/prior_ent_max": 56.3885383605957, "report/prior_ent_mean": 53.18275451660156, "report/prior_ent_min": 47.56237030029297, "report/prior_ent_std": 1.4981775283813477, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0015136718284338713, "report/reward_loss_mean": 0.011105882003903389, "report/reward_loss_std": 0.19423924386501312, "report/reward_max_data": 0.824999988079071, "report/reward_max_pred": 0.029526352882385254, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0025368230417370796, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.389894962310791, "report/reward_pred": 0.0013073603622615337, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.9921875, "eval/cont_loss_mean": 0.06973273307085037, "eval/cont_loss_std": 0.7946012020111084, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 8.549869537353516, "eval/cont_pos_acc": 0.999015748500824, "eval/cont_pos_loss": 0.002960003213956952, "eval/cont_pred": 0.9975632429122925, "eval/cont_rate": 0.9921875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.18615257740020752, "eval/image_loss_std": 0.14010214805603027, "eval/model_loss_mean": 0.8693346977233887, "eval/model_loss_std": 0.9407137632369995, "eval/post_ent_mag": 51.07832336425781, "eval/post_ent_max": 51.07832336425781, "eval/post_ent_mean": 48.44866943359375, "eval/post_ent_min": 47.030635833740234, "eval/post_ent_std": 0.8620117902755737, "eval/prior_ent_mag": 55.608184814453125, "eval/prior_ent_max": 55.608184814453125, "eval/prior_ent_mean": 52.47063064575195, "eval/prior_ent_min": 47.99789810180664, "eval/prior_ent_std": 1.5485559701919556, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0014709471724927425, "eval/reward_loss_mean": 0.013449395075440407, "eval/reward_loss_std": 0.29475077986717224, "eval/reward_max_data": 0.7593749761581421, "eval/reward_max_pred": 0.026052117347717285, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0010273484513163567, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 6.361115455627441, "eval/reward_pred": 0.0005278745666146278, "eval/reward_rate": 0.001953125, "replay/size": 644817.0, "replay/inserts": 32352.0, "replay/samples": 32352.0, "replay/insert_wait_avg": 1.323144997144901e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.474795919733397e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5280.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1068853464993563e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.834766387939453e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0993835926056, "timer/env.step_count": 4044.0, "timer/env.step_total": 38.118536710739136, "timer/env.step_frac": 0.038114748730079084, "timer/env.step_avg": 0.009425948741527976, "timer/env.step_min": 0.007502079010009766, "timer/env.step_max": 0.03888535499572754, "timer/replay._sample_count": 32352.0, "timer/replay._sample_total": 16.927523374557495, "timer/replay._sample_frac": 0.01692584122364882, "timer/replay._sample_avg": 0.0005232295800741065, "timer/replay._sample_min": 0.0003867149353027344, "timer/replay._sample_max": 0.033020973205566406, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4704.0, "timer/agent.policy_total": 48.88696336746216, "timer/agent.policy_frac": 0.04888210528822449, "timer/agent.policy_avg": 0.010392636770293825, "timer/agent.policy_min": 0.008988618850708008, "timer/agent.policy_max": 0.08769392967224121, "timer/dataset_train_count": 2022.0, "timer/dataset_train_total": 0.21711111068725586, "timer/dataset_train_frac": 0.0002170895355492959, "timer/dataset_train_avg": 0.00010737443654166956, "timer/dataset_train_min": 9.489059448242188e-05, "timer/dataset_train_max": 0.00044035911560058594, "timer/agent.train_count": 2022.0, "timer/agent.train_total": 899.871753692627, "timer/agent.train_frac": 0.8997823300920994, "timer/agent.train_avg": 0.4450404320932873, "timer/agent.train_min": 0.43474888801574707, "timer/agent.train_max": 0.6629304885864258, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47849321365356445, "timer/agent.report_frac": 0.0004784456640046091, "timer/agent.report_avg": 0.23924660682678223, "timer/agent.report_min": 0.23015499114990234, "timer/agent.report_max": 0.2483382225036621, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.266334533691406e-05, "timer/dataset_eval_frac": 3.266009945889498e-08, "timer/dataset_eval_avg": 3.266334533691406e-05, "timer/dataset_eval_min": 3.266334533691406e-05, "timer/dataset_eval_max": 3.266334533691406e-05, "fps": 32.34824646400766}
{"step": 645352, "time": 20226.969503879547, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 645400, "time": 20228.509619951248, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 645464, "time": 20230.44742012024, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 645680, "time": 20237.21253466606, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 645688, "time": 20237.24194097519, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 645800, "time": 20240.652923345566, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 645904, "time": 20244.037620782852, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 645928, "time": 20244.54897403717, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 646368, "time": 20258.22199845314, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 646464, "time": 20261.115843057632, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 646592, "time": 20264.979405879974, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 646848, "time": 20272.710777282715, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 647304, "time": 20286.875616312027, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 647368, "time": 20288.837364435196, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 647448, "time": 20291.25443124771, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 647712, "time": 20299.46200156212, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 647744, "time": 20300.43429708481, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 647776, "time": 20301.412116527557, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 648216, "time": 20314.60564684868, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 648232, "time": 20315.095806837082, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 648240, "time": 20315.567039728165, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 648304, "time": 20317.527057886124, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 648560, "time": 20326.83948326111, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 648656, "time": 20329.744234085083, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 648872, "time": 20336.117063760757, "episode/length": 195.0, "episode/score": 0.390625, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.0}
{"step": 648872, "time": 20336.124373674393, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 649096, "time": 20342.903913736343, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 649216, "time": 20346.72961831093, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 649312, "time": 20349.64151239395, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 649576, "time": 20357.415151834488, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 650000, "time": 20371.921225070953, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 650000, "time": 20372.819669485092, "eval_episode/length": 125.0, "eval_episode/score": 0.609375, "eval_episode/reward_rate": 0.007936507936507936}
{"step": 650000, "time": 20373.31697535515, "eval_episode/length": 153.0, "eval_episode/score": 0.5218750238418579, "eval_episode/reward_rate": 0.006493506493506494}
{"step": 650000, "time": 20373.323996543884, "eval_episode/length": 153.0, "eval_episode/score": 0.5218750238418579, "eval_episode/reward_rate": 0.006493506493506494}
{"step": 650000, "time": 20373.479046344757, "eval_episode/length": 35.0, "eval_episode/score": 0.890625, "eval_episode/reward_rate": 0.027777777777777776}
{"step": 650000, "time": 20374.643509864807, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 650000, "time": 20375.78794312477, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 650000, "time": 20375.796219587326, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 650000, "time": 20375.80285358429, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 650000, "time": 20375.809475898743, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 650144, "time": 20380.178334474564, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 650256, "time": 20383.580620765686, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 650288, "time": 20384.557475805283, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 650440, "time": 20388.937435388565, "episode/length": 195.0, "episode/score": 0.390625, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.0}
{"step": 650528, "time": 20391.826515197754, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 650544, "time": 20392.318444252014, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 650552, "time": 20392.34751558304, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 650968, "time": 20405.22425889969, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 651040, "time": 20407.67656993866, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 651104, "time": 20409.60574555397, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 651312, "time": 20415.920105218887, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 651504, "time": 20421.771117687225, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 651640, "time": 20425.832766771317, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 651688, "time": 20427.290678024292, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 651912, "time": 20434.06590986252, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 652440, "time": 20450.05888724327, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 652488, "time": 20451.515196084976, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 652608, "time": 20455.51376056671, "episode/length": 187.0, "episode/score": 0.4156250059604645, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.0}
{"step": 652664, "time": 20456.979832172394, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 652840, "time": 20462.306196689606, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 652904, "time": 20464.25104212761, "episode/length": 232.0, "episode/score": 0.2750000059604645, "episode/reward_rate": 0.004291845493562232, "episode/intrinsic_return": 0.0}
{"step": 653008, "time": 20467.635343313217, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 653408, "time": 20479.784765958786, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 653536, "time": 20483.648785352707, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 653600, "time": 20485.71954011917, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 653688, "time": 20488.152721643448, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 654000, "time": 20497.841002464294, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 654016, "time": 20498.33316040039, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 654296, "time": 20506.618523836136, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 654304, "time": 20507.088672876358, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 654352, "time": 20508.570341587067, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 654584, "time": 20515.439513921738, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 654752, "time": 20520.758616924286, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 654784, "time": 20521.726081609726, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 654800, "time": 20522.220518112183, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 654920, "time": 20525.653037071228, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 655168, "time": 20533.387768745422, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 655208, "time": 20534.374789476395, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 655304, "time": 20537.281809091568, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 655320, "time": 20537.792922973633, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 655680, "time": 20549.65530705452, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 655680, "time": 20549.662509441376, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 655744, "time": 20551.59126353264, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 655904, "time": 20556.440141916275, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 656096, "time": 20562.232758760452, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 656296, "time": 20568.077162981033, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 656344, "time": 20569.533063173294, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 656448, "time": 20572.90863633156, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 656528, "time": 20575.4109852314, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0}
{"step": 656616, "time": 20577.866438388824, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 656664, "time": 20579.32391166687, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 656680, "time": 20579.81443977356, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 657008, "time": 20589.985572099686, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 657192, "time": 20595.42946577072, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 657392, "time": 20601.78958964348, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 657544, "time": 20606.298448562622, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 657992, "time": 20619.988141298294, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 658056, "time": 20621.94267630577, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 658152, "time": 20624.87743973732, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 658608, "time": 20638.957981348038, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 658712, "time": 20641.888568401337, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 658840, "time": 20645.773270130157, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 658912, "time": 20648.16193175316, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 658928, "time": 20648.647824525833, "episode/length": 191.0, "episode/score": 0.40312498807907104, "episode/reward_rate": 0.005208333333333333, "episode/intrinsic_return": 0.0}
{"step": 658928, "time": 20648.65605545044, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 658976, "time": 20650.105509519577, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 659384, "time": 20662.280836582184, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 659520, "time": 20666.80536365509, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 659688, "time": 20671.70840525627, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 659784, "time": 20674.630401849747, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 659856, "time": 20677.057228803635, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 659864, "time": 20677.08642601967, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 659888, "time": 20678.04258608818, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 659904, "time": 20678.53418493271, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 660088, "time": 20684.794187307358, "eval_episode/length": 45.0, "eval_episode/score": 0.859375, "eval_episode/reward_rate": 0.021739130434782608}
{"step": 660088, "time": 20685.169686317444, "eval_episode/length": 64.0, "eval_episode/score": 0.800000011920929, "eval_episode/reward_rate": 0.015384615384615385}
{"step": 660088, "time": 20685.855679035187, "eval_episode/length": 99.0, "eval_episode/score": 0.690625011920929, "eval_episode/reward_rate": 0.01}
{"step": 660088, "time": 20686.16640496254, "eval_episode/length": 50.0, "eval_episode/score": 0.84375, "eval_episode/reward_rate": 0.0196078431372549}
{"step": 660088, "time": 20686.327152967453, "eval_episode/length": 123.0, "eval_episode/score": 0.6156250238418579, "eval_episode/reward_rate": 0.008064516129032258}
{"step": 660088, "time": 20686.724051475525, "eval_episode/length": 96.0, "eval_episode/score": 0.699999988079071, "eval_episode/reward_rate": 0.010309278350515464}
{"step": 660088, "time": 20687.409064769745, "eval_episode/length": 52.0, "eval_episode/score": 0.8374999761581421, "eval_episode/reward_rate": 0.018867924528301886}
{"step": 660088, "time": 20687.689039945602, "eval_episode/length": 190.0, "eval_episode/score": 0.40625, "eval_episode/reward_rate": 0.005235602094240838}
{"step": 660520, "time": 20700.94505929947, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 660560, "time": 20702.38022875786, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 660648, "time": 20704.85090827942, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 660704, "time": 20706.7756421566, "episode/length": 215.0, "episode/score": 0.328125, "episode/reward_rate": 0.004629629629629629, "episode/intrinsic_return": 0.0}
{"step": 660744, "time": 20709.545302152634, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 660952, "time": 20715.886412620544, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 661024, "time": 20718.29340481758, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 661160, "time": 20722.21700811386, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 661248, "time": 20725.262110948563, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 661328, "time": 20727.717807769775, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 661648, "time": 20737.502902030945, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 661808, "time": 20742.384109020233, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 661952, "time": 20746.78825712204, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 661952, "time": 20746.795500278473, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 662016, "time": 20748.740562677383, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 662200, "time": 20754.16108608246, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 662768, "time": 20771.739307641983, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 662960, "time": 20777.56643629074, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 663264, "time": 20786.91098332405, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 663368, "time": 20789.875016212463, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 663472, "time": 20793.267657518387, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 663512, "time": 20794.263156414032, "episode/length": 282.0, "episode/score": 0.11874999850988388, "episode/reward_rate": 0.0035335689045936395, "episode/intrinsic_return": 0.0}
{"step": 663640, "time": 20798.653317451477, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 664136, "time": 20813.698392152786, "episode/length": 241.0, "episode/score": 0.24687500298023224, "episode/reward_rate": 0.004132231404958678, "episode/intrinsic_return": 0.0}
{"step": 664240, "time": 20818.408710956573, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 664240, "time": 20818.41681909561, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 664256, "time": 20818.91614985466, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 664280, "time": 20819.454726934433, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 664896, "time": 20838.376111268997, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 664928, "time": 20839.35720038414, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 665080, "time": 20843.726985692978, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 665272, "time": 20849.703413963318, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 665272, "time": 20849.712159872055, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 665376, "time": 20853.082576274872, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 665384, "time": 20853.110956192017, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 665680, "time": 20862.30572271347, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 665896, "time": 20868.6376850605, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 666056, "time": 20873.475692033768, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 666136, "time": 20875.997917175293, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 666352, "time": 20882.763206720352, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 666448, "time": 20885.661687612534, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 666552, "time": 20888.60608267784, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 666592, "time": 20890.043073415756, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 666656, "time": 20891.98163986206, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 666712, "time": 20893.46869969368, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 666928, "time": 20900.233999967575, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 667272, "time": 20910.491943120956, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 667392, "time": 20914.355208158493, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 667688, "time": 20923.10280227661, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 668288, "time": 20941.628459453583, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 668424, "time": 20945.51456260681, "episode/length": 16.0, "episode/score": 0.949999988079071, "episode/reward_rate": 0.058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 668560, "time": 20949.85830450058, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 668664, "time": 20952.801727294922, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 668760, "time": 20955.72895002365, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 668864, "time": 20959.09739255905, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 668888, "time": 20959.61150240898, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 668976, "time": 20962.504842042923, "episode/length": 13.0, "episode/score": 0.9593750238418579, "episode/reward_rate": 0.07142857142857142, "episode/intrinsic_return": 0.0}
{"step": 669024, "time": 20963.96536397934, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 669048, "time": 20964.477119922638, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 669264, "time": 20971.338447332382, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 669584, "time": 20981.041546583176, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 669712, "time": 20984.920178174973, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 669712, "time": 20984.926947832108, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 669736, "time": 20985.435483694077, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 669952, "time": 20992.204238176346, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 670056, "time": 20995.25410914421, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 670072, "time": 20997.03614115715, "eval_episode/length": 67.0, "eval_episode/score": 0.7906249761581421, "eval_episode/reward_rate": 0.014705882352941176}
{"step": 670072, "time": 20997.32456469536, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 670072, "time": 20997.66525578499, "eval_episode/length": 102.0, "eval_episode/score": 0.6812499761581421, "eval_episode/reward_rate": 0.009708737864077669}
{"step": 670072, "time": 20998.981819868088, "eval_episode/length": 139.0, "eval_episode/score": 0.565625011920929, "eval_episode/reward_rate": 0.007142857142857143}
{"step": 670072, "time": 20999.648532629013, "eval_episode/length": 175.0, "eval_episode/score": 0.453125, "eval_episode/reward_rate": 0.005681818181818182}
{"step": 670072, "time": 20999.978273630142, "eval_episode/length": 124.0, "eval_episode/score": 0.612500011920929, "eval_episode/reward_rate": 0.008}
{"step": 670072, "time": 21000.646325588226, "eval_episode/length": 52.0, "eval_episode/score": 0.8374999761581421, "eval_episode/reward_rate": 0.018867924528301886}
{"step": 670072, "time": 21001.404601812363, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 670104, "time": 21002.374954223633, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 670128, "time": 21003.334011554718, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 670472, "time": 21013.539180994034, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 670648, "time": 21018.88792657852, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 670744, "time": 21021.808531284332, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 670872, "time": 21025.845285654068, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 670952, "time": 21028.28469824791, "episode/length": 237.0, "episode/score": 0.2593750059604645, "episode/reward_rate": 0.004201680672268907, "episode/intrinsic_return": 0.0}
{"step": 671104, "time": 21033.11783337593, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 671112, "time": 21033.146113157272, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 671168, "time": 21035.07564687729, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 671392, "time": 21041.899564266205, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 671672, "time": 21050.173097848892, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 671960, "time": 21059.465381622314, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 672152, "time": 21065.28220295906, "episode/length": 209.0, "episode/score": 0.34687501192092896, "episode/reward_rate": 0.004761904761904762, "episode/intrinsic_return": 0.0}
{"step": 672208, "time": 21067.209499835968, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 672504, "time": 21075.96502518654, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 672544, "time": 21077.404828310013, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 672696, "time": 21081.813442468643, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 672920, "time": 21088.750183343887, "episode/length": 226.0, "episode/score": 0.29374998807907104, "episode/reward_rate": 0.004405286343612335, "episode/intrinsic_return": 0.0}
{"step": 673040, "time": 21092.59970331192, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 673056, "time": 21093.089712142944, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 673216, "time": 21097.936050653458, "episode/length": 21.0, "episode/score": 0.934374988079071, "episode/reward_rate": 0.045454545454545456, "episode/intrinsic_return": 0.0}
{"step": 673296, "time": 21100.37073612213, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 673392, "time": 21103.311631917953, "episode/length": 21.0, "episode/score": 0.934374988079071, "episode/reward_rate": 0.045454545454545456, "episode/intrinsic_return": 0.0}
{"step": 673480, "time": 21105.754657268524, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 673704, "time": 21112.52556705475, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 673736, "time": 21113.519028902054, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 673824, "time": 21116.480885505676, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 673848, "time": 21116.99075603485, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 673976, "time": 21120.86128926277, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 674224, "time": 21128.568341732025, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 674368, "time": 21132.918446302414, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 674416, "time": 21134.376381397247, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 674416, "time": 21134.383662223816, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 674464, "time": 21135.840388059616, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 674512, "time": 21137.31500673294, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 674600, "time": 21139.752109527588, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 674888, "time": 21148.559873342514, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 675144, "time": 21156.305810451508, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 675168, "time": 21157.282395124435, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 675280, "time": 21160.66683602333, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 675584, "time": 21169.88396668434, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 675600, "time": 21170.373864889145, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 675776, "time": 21175.823260307312, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 675984, "time": 21182.111829042435, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 676064, "time": 21184.516456842422, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 676160, "time": 21187.43328690529, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 676344, "time": 21192.771648168564, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 676448, "time": 21196.141693115234, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 676536, "time": 21198.58560180664, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 676584, "time": 21200.03547334671, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 676728, "time": 21204.386831760406, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 676760, "time": 21205.46722483635, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 677336, "time": 21222.95809674263, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 677417, "time": 21226.394983530045, "train_stats/mean_log_entropy": 0.09872726929773178, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.692204261893657, "train/action_min": 0.0, "train/action_std": 1.9496070176214721, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.009108195112049765, "train/actor_opt_grad_steps": 41240.0, "train/actor_opt_loss": -7.857603720023264, "train/adv_mag": 0.9590022311874883, "train/adv_max": 0.37842813593831226, "train/adv_mean": 0.0017897492650593616, "train/adv_min": -0.9131490760181674, "train/adv_std": 0.02817014640947776, "train/cont_avg": 0.9947285059079602, "train/cont_loss_mean": 0.016717102013143772, "train/cont_loss_std": 0.23069129614344802, "train/cont_neg_acc": 0.36856931844605734, "train/cont_neg_loss": 2.5175185352343767, "train/cont_pos_acc": 0.9999022979048354, "train/cont_pos_loss": 0.003294543993881723, "train/cont_pred": 0.9948867841146478, "train/cont_rate": 0.9947285059079602, "train/dyn_loss_mean": 1.0000054682072121, "train/dyn_loss_std": 0.00016898552097139222, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.2976445855378215, "train/extr_critic_critic_opt_grad_steps": 41240.0, "train/extr_critic_critic_opt_loss": 4680.493426422575, "train/extr_critic_mag": 1.2805545875682167, "train/extr_critic_max": 1.2805545875682167, "train/extr_critic_mean": 1.2172070196018883, "train/extr_critic_min": 0.9470428946006357, "train/extr_critic_std": 0.017422888798648443, "train/extr_return_normed_mag": 0.948743762958109, "train/extr_return_normed_max": 0.29095975854503575, "train/extr_return_normed_mean": 0.03346029331731559, "train/extr_return_normed_min": -0.9088750422297426, "train/extr_return_normed_std": 0.034200619878386386, "train/extr_return_rate": 0.999291020542828, "train/extr_return_raw_mag": 1.4764962000633353, "train/extr_return_raw_max": 1.4764962000633353, "train/extr_return_raw_mean": 1.2189967970349895, "train/extr_return_raw_min": 0.27666139928855704, "train/extr_return_raw_std": 0.03420061981815159, "train/extr_reward_mag": 0.34416930473859036, "train/extr_reward_max": 0.34416930473859036, "train/extr_reward_mean": 0.0021505466762545577, "train/extr_reward_min": 2.253707961656561e-08, "train/extr_reward_std": 0.008305489759781022, "train/image_loss_mean": 0.09787079832743649, "train/image_loss_std": 0.10489729680676958, "train/model_loss_mean": 0.7261078728372184, "train/model_loss_std": 0.42108970784132754, "train/model_opt_grad_norm": 21.62226908005292, "train/model_opt_grad_steps": 41204.46268656717, "train/model_opt_loss": 2726.35645381491, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3756.218905472637, "train/policy_entropy_mag": 1.3136411727364383, "train/policy_entropy_max": 1.3136411727364383, "train/policy_entropy_mean": 0.11645654826170176, "train/policy_entropy_min": 0.06468649238199736, "train/policy_entropy_std": 0.15195683071121055, "train/policy_logprob_mag": 6.55108026485538, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.11604325584511259, "train/policy_logprob_min": -6.55108026485538, "train/policy_logprob_std": 0.6507960937509489, "train/policy_randomness_mag": 0.6750780616826679, "train/policy_randomness_max": 0.6750780616826679, "train/policy_randomness_mean": 0.059846830271666325, "train/policy_randomness_min": 0.03324228167459739, "train/policy_randomness_std": 0.07809036840402071, "train/post_ent_mag": 50.196862500698415, "train/post_ent_max": 50.196862500698415, "train/post_ent_mean": 47.52246981948169, "train/post_ent_min": 45.963563567963405, "train/post_ent_std": 0.8368143234679948, "train/prior_ent_mag": 54.661602589621474, "train/prior_ent_max": 54.661602589621474, "train/prior_ent_mean": 50.87814042580069, "train/prior_ent_min": 45.86244539479118, "train/prior_ent_std": 1.516164361540951, "train/rep_loss_mean": 1.0000054682072121, "train/rep_loss_std": 0.00016898552097139222, "train/reward_avg": 0.0014800721732696834, "train/reward_loss_mean": 0.011516667330818279, "train/reward_loss_std": 0.192544865140469, "train/reward_max_data": 0.6841262455158565, "train/reward_max_pred": 0.14749892849234206, "train/reward_neg_acc": 0.9999172776492674, "train/reward_neg_loss": 0.0019959180389382686, "train/reward_pos_acc": 0.12234234334649266, "train/reward_pos_loss": 4.199684708182876, "train/reward_pred": 0.001142411126722744, "train/reward_rate": 0.0022446361940298507, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.014862075448036194, "report/cont_loss_std": 0.1927669793367386, "report/cont_neg_acc": 0.5714285969734192, "report/cont_neg_loss": 1.560187816619873, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.004225615411996841, "report/cont_pred": 0.9920759201049805, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.10575832426548004, "report/image_loss_std": 0.10883166640996933, "report/model_loss_mean": 0.7273139953613281, "report/model_loss_std": 0.33162420988082886, "report/post_ent_mag": 48.506561279296875, "report/post_ent_max": 48.506561279296875, "report/post_ent_mean": 45.73723602294922, "report/post_ent_min": 44.14839172363281, "report/post_ent_std": 0.9225682020187378, "report/prior_ent_mag": 53.55357360839844, "report/prior_ent_max": 53.55357360839844, "report/prior_ent_mean": 49.28459167480469, "report/prior_ent_min": 43.2628173828125, "report/prior_ent_std": 1.7479993104934692, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0007751464727334678, "report/reward_loss_mean": 0.006693542003631592, "report/reward_loss_std": 0.14658966660499573, "report/reward_max_data": 0.793749988079071, "report/reward_max_pred": 0.021390795707702637, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0021161092445254326, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.6894073486328125, "report/reward_pred": 0.0010979488724842668, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.030646372586488724, "eval/cont_loss_std": 0.3983237147331238, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.5481133460998535, "eval/cont_pos_acc": 0.999018669128418, "eval/cont_pos_loss": 0.0035734237171709538, "eval/cont_pred": 0.9969258904457092, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.22416327893733978, "eval/image_loss_std": 0.15467599034309387, "eval/model_loss_mean": 0.8661773204803467, "eval/model_loss_std": 0.5858155488967896, "eval/post_ent_mag": 48.50670623779297, "eval/post_ent_max": 48.50670623779297, "eval/post_ent_mean": 45.694984436035156, "eval/post_ent_min": 44.3027458190918, "eval/post_ent_std": 0.8429195284843445, "eval/prior_ent_mag": 53.6073112487793, "eval/prior_ent_max": 53.6073112487793, "eval/prior_ent_mean": 48.991241455078125, "eval/prior_ent_min": 44.32157897949219, "eval/prior_ent_std": 1.6714011430740356, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0014862059615552425, "eval/reward_loss_mean": 0.011367637664079666, "eval/reward_loss_std": 0.24953795969486237, "eval/reward_max_data": 0.824999988079071, "eval/reward_max_pred": 0.01898014545440674, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0004803364572580904, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.5747785568237305, "eval/reward_pred": 0.00025404617190361023, "eval/reward_rate": 0.001953125, "replay/size": 676913.0, "replay/inserts": 32096.0, "replay/samples": 32096.0, "replay/insert_wait_avg": 1.3306677519740278e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.410167836715075e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 6008.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1469727349821008e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.834766387939453e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0890078544617, "timer/env.step_count": 4012.0, "timer/env.step_total": 38.03329634666443, "timer/env.step_frac": 0.038029911385846604, "timer/env.step_avg": 0.009479884433366009, "timer/env.step_min": 0.007600545883178711, "timer/env.step_max": 0.03548073768615723, "timer/replay._sample_count": 32096.0, "timer/replay._sample_total": 16.74883484840393, "timer/replay._sample_frac": 0.01674734420322847, "timer/replay._sample_avg": 0.0005218355822658254, "timer/replay._sample_min": 0.00037360191345214844, "timer/replay._sample_max": 0.025783538818359375, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4763.0, "timer/agent.policy_total": 49.749393939971924, "timer/agent.policy_frac": 0.04974496624725599, "timer/agent.policy_avg": 0.010444970384205736, "timer/agent.policy_min": 0.008378744125366211, "timer/agent.policy_max": 0.0926063060760498, "timer/dataset_train_count": 2006.0, "timer/dataset_train_total": 0.21795010566711426, "timer/dataset_train_frac": 0.00021793070812236296, "timer/dataset_train_avg": 0.00010864910551700611, "timer/dataset_train_min": 9.512901306152344e-05, "timer/dataset_train_max": 0.00029277801513671875, "timer/agent.train_count": 2006.0, "timer/agent.train_total": 896.538896560669, "timer/agent.train_frac": 0.8964591046591506, "timer/agent.train_avg": 0.4469286622934541, "timer/agent.train_min": 0.43642687797546387, "timer/agent.train_max": 2.212737798690796, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47828054428100586, "timer/agent.report_frac": 0.0004782379773447203, "timer/agent.report_avg": 0.23914027214050293, "timer/agent.report_min": 0.23125672340393066, "timer/agent.report_max": 0.2470238208770752, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.147125244140625e-05, "timer/dataset_eval_frac": 3.146845150205482e-08, "timer/dataset_eval_avg": 3.147125244140625e-05, "timer/dataset_eval_min": 3.147125244140625e-05, "timer/dataset_eval_max": 3.147125244140625e-05, "fps": 32.09260835403746}
{"step": 677480, "time": 21228.0625705719, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 677488, "time": 21228.531379938126, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 677840, "time": 21239.272629261017, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 678024, "time": 21244.616801977158, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 678072, "time": 21246.082711696625, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 678264, "time": 21251.890184640884, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 678472, "time": 21258.193967580795, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 678496, "time": 21259.14520382881, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 678760, "time": 21267.037549972534, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 678816, "time": 21268.94879746437, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 678896, "time": 21271.385455846786, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 679056, "time": 21276.223479270935, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 679072, "time": 21276.712279319763, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 679168, "time": 21279.63192343712, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 679472, "time": 21288.809833049774, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 679512, "time": 21294.756901025772, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 679728, "time": 21301.618757009506, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 679744, "time": 21302.109964609146, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 679800, "time": 21303.610516786575, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 679904, "time": 21306.959547281265, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 679944, "time": 21308.14671444893, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 680024, "time": 21310.85923910141, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 680056, "time": 21312.827805280685, "eval_episode/length": 54.0, "eval_episode/score": 0.831250011920929, "eval_episode/reward_rate": 0.01818181818181818}
{"step": 680056, "time": 21313.012693166733, "eval_episode/length": 64.0, "eval_episode/score": 0.800000011920929, "eval_episode/reward_rate": 0.015384615384615385}
{"step": 680056, "time": 21313.90118074417, "eval_episode/length": 114.0, "eval_episode/score": 0.643750011920929, "eval_episode/reward_rate": 0.008695652173913044}
{"step": 680056, "time": 21314.028557300568, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 680056, "time": 21314.086841583252, "eval_episode/length": 124.0, "eval_episode/score": 0.612500011920929, "eval_episode/reward_rate": 0.008}
{"step": 680056, "time": 21314.132046699524, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 680056, "time": 21314.228567123413, "eval_episode/length": 131.0, "eval_episode/score": 0.590624988079071, "eval_episode/reward_rate": 0.007575757575757576}
{"step": 680056, "time": 21314.25360560417, "eval_episode/length": 132.0, "eval_episode/score": 0.5874999761581421, "eval_episode/reward_rate": 0.007518796992481203}
{"step": 680152, "time": 21317.178654909134, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 680336, "time": 21322.945003271103, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 680448, "time": 21326.453101873398, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 680512, "time": 21328.390243530273, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 680536, "time": 21328.900475025177, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 680576, "time": 21330.33182811737, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 680880, "time": 21339.52542901039, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 681000, "time": 21342.945090532303, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 681040, "time": 21344.37901854515, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 681208, "time": 21349.22456741333, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 681328, "time": 21353.05971980095, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 681600, "time": 21361.35941672325, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 681936, "time": 21371.490357637405, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 682136, "time": 21377.32733607292, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 682216, "time": 21379.796771764755, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 682360, "time": 21384.21999692917, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 682464, "time": 21387.7122130394, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 682640, "time": 21393.12560939789, "episode/length": 21.0, "episode/score": 0.934374988079071, "episode/reward_rate": 0.045454545454545456, "episode/intrinsic_return": 0.0}
{"step": 682648, "time": 21393.15529203415, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 682760, "time": 21396.56200504303, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 682832, "time": 21398.97651410103, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 682840, "time": 21399.003576517105, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 682888, "time": 21400.45166707039, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 682888, "time": 21400.46000766754, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 683120, "time": 21407.692506313324, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 683368, "time": 21415.00527071953, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 683464, "time": 21417.965857744217, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 683504, "time": 21419.41233944893, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 683640, "time": 21423.318470478058, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 683648, "time": 21423.78608417511, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 683688, "time": 21424.776328086853, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 683920, "time": 21431.991070985794, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 684104, "time": 21437.335784196854, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 684152, "time": 21438.80554318428, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 684320, "time": 21444.111812353134, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 684696, "time": 21455.37325692177, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 684856, "time": 21460.221761465073, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 684928, "time": 21462.639661550522, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 684984, "time": 21464.11821961403, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 685032, "time": 21465.57047343254, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 685200, "time": 21470.87950515747, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 685296, "time": 21473.789514303207, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 685768, "time": 21487.927850723267, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 685792, "time": 21488.876992702484, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 685960, "time": 21493.74727320671, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 686104, "time": 21498.099739313126, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 686120, "time": 21498.588498830795, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 686232, "time": 21501.967672109604, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 686392, "time": 21506.877558231354, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 686488, "time": 21509.77514886856, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 686808, "time": 21519.446622371674, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 686936, "time": 21523.359898090363, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 687016, "time": 21528.57219529152, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 687072, "time": 21530.487481355667, "episode/length": 267.0, "episode/score": 0.16562500596046448, "episode/reward_rate": 0.0037313432835820895, "episode/intrinsic_return": 0.0}
{"step": 687184, "time": 21533.887209653854, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 687344, "time": 21538.837052345276, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 687344, "time": 21538.84412431717, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 687440, "time": 21541.744502544403, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 687512, "time": 21543.723692178726, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 687552, "time": 21545.15024447441, "episode/length": 13.0, "episode/score": 0.9593750238418579, "episode/reward_rate": 0.07142857142857142, "episode/intrinsic_return": 0.0}
{"step": 687728, "time": 21550.469556331635, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 687968, "time": 21557.747567415237, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 688312, "time": 21568.521852731705, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 688432, "time": 21572.373142004013, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 688928, "time": 21587.348912715912, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 688936, "time": 21587.37765812874, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 688952, "time": 21587.865585803986, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 689120, "time": 21593.160189151764, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 689304, "time": 21598.589749336243, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 689328, "time": 21599.54227900505, "episode/length": 199.0, "episode/score": 0.37812501192092896, "episode/reward_rate": 0.005, "episode/intrinsic_return": 0.0}
{"step": 689424, "time": 21602.456202745438, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 689656, "time": 21609.234570980072, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 690040, "time": 21621.58770298958, "eval_episode/length": 38.0, "eval_episode/score": 0.8812500238418579, "eval_episode/reward_rate": 0.02564102564102564}
{"step": 690040, "time": 21621.74214053154, "eval_episode/length": 46.0, "eval_episode/score": 0.856249988079071, "eval_episode/reward_rate": 0.02127659574468085}
{"step": 690040, "time": 21621.97078204155, "eval_episode/length": 58.0, "eval_episode/score": 0.8187500238418579, "eval_episode/reward_rate": 0.01694915254237288}
{"step": 690040, "time": 21622.71868300438, "eval_episode/length": 96.0, "eval_episode/score": 0.699999988079071, "eval_episode/reward_rate": 0.010309278350515464}
{"step": 690040, "time": 21623.57936835289, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 690040, "time": 21623.83948779106, "eval_episode/length": 153.0, "eval_episode/score": 0.5218750238418579, "eval_episode/reward_rate": 0.006493506493506494}
{"step": 690040, "time": 21623.846222162247, "eval_episode/length": 94.0, "eval_episode/score": 0.706250011920929, "eval_episode/reward_rate": 0.010526315789473684}
{"step": 690040, "time": 21623.923554182053, "eval_episode/length": 157.0, "eval_episode/score": 0.5093749761581421, "eval_episode/reward_rate": 0.006329113924050633}
{"step": 690080, "time": 21625.46191930771, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 690376, "time": 21634.22310590744, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 690592, "time": 21640.97137737274, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 690608, "time": 21641.4623837471, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 690624, "time": 21641.955579042435, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 690656, "time": 21642.930372476578, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 690800, "time": 21647.305288791656, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 691032, "time": 21654.112112760544, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 691152, "time": 21658.056801080704, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 691208, "time": 21659.531367778778, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 691432, "time": 21666.29562854767, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 691504, "time": 21668.698451280594, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 691584, "time": 21671.114409208298, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 691640, "time": 21672.60773897171, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 691856, "time": 21679.378214597702, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 691864, "time": 21679.406141281128, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 691968, "time": 21682.797893047333, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 691976, "time": 21682.8254468441, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 691992, "time": 21683.317623138428, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 692688, "time": 21704.660889148712, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 692704, "time": 21705.15088701248, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 692736, "time": 21706.125184059143, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 692784, "time": 21707.591872930527, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 692816, "time": 21708.55641770363, "episode/length": 13.0, "episode/score": 0.9593750238418579, "episode/reward_rate": 0.07142857142857142, "episode/intrinsic_return": 0.0}
{"step": 693096, "time": 21716.88889336586, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 693304, "time": 21723.171847105026, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 693352, "time": 21724.619120836258, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 693352, "time": 21724.626442432404, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 693520, "time": 21729.972066640854, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 693816, "time": 21738.768265724182, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 693896, "time": 21741.215641736984, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 694176, "time": 21749.97040128708, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 694280, "time": 21752.91971874237, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 694520, "time": 21760.188270807266, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 694920, "time": 21772.250864744186, "episode/length": 201.0, "episode/score": 0.37187498807907104, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.0}
{"step": 694992, "time": 21774.66511821747, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 695224, "time": 21781.60182452202, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 695448, "time": 21788.36551475525, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 695664, "time": 21795.11875271797, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 695664, "time": 21795.12805914879, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 695784, "time": 21798.52710223198, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 695800, "time": 21799.03457403183, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 695832, "time": 21800.00450515747, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 696344, "time": 21815.980599164963, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 696384, "time": 21817.41680788994, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 696488, "time": 21820.343022346497, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 696672, "time": 21826.12897992134, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 696752, "time": 21828.562698602676, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 696856, "time": 21831.47306227684, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 697288, "time": 21844.632765054703, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 697304, "time": 21845.125844478607, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 697392, "time": 21848.008296728134, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 697432, "time": 21848.99397945404, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 697448, "time": 21849.48694896698, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 697768, "time": 21859.132286787033, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 697936, "time": 21864.42448759079, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 698112, "time": 21869.825640916824, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 698144, "time": 21870.79743695259, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 698168, "time": 21871.30784392357, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 698360, "time": 21877.133548498154, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 699192, "time": 21902.367473840714, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 699224, "time": 21903.332223415375, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 699264, "time": 21904.7633728981, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 699592, "time": 21914.503828048706, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 699704, "time": 21917.894829273224, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 699760, "time": 21919.8022005558, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 700024, "time": 21928.236086130142, "eval_episode/length": 32.0, "eval_episode/score": 0.8999999761581421, "eval_episode/reward_rate": 0.030303030303030304}
{"step": 700024, "time": 21928.59216594696, "eval_episode/length": 51.0, "eval_episode/score": 0.840624988079071, "eval_episode/reward_rate": 0.019230769230769232}
{"step": 700024, "time": 21928.855005025864, "eval_episode/length": 65.0, "eval_episode/score": 0.796875, "eval_episode/reward_rate": 0.015151515151515152}
{"step": 700024, "time": 21929.09475660324, "eval_episode/length": 78.0, "eval_episode/score": 0.7562500238418579, "eval_episode/reward_rate": 0.012658227848101266}
{"step": 700024, "time": 21929.33908200264, "eval_episode/length": 58.0, "eval_episode/score": 0.8187500238418579, "eval_episode/reward_rate": 0.01694915254237288}
{"step": 700024, "time": 21929.63231253624, "eval_episode/length": 107.0, "eval_episode/score": 0.6656249761581421, "eval_episode/reward_rate": 0.009259259259259259}
{"step": 700024, "time": 21930.008011579514, "eval_episode/length": 20.0, "eval_episode/score": 0.9375, "eval_episode/reward_rate": 0.047619047619047616}
{"step": 700024, "time": 21930.80805826187, "eval_episode/length": 117.0, "eval_episode/score": 0.6343749761581421, "eval_episode/reward_rate": 0.00847457627118644}
{"step": 700032, "time": 21931.279543876648, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 700080, "time": 21932.74938774109, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 700136, "time": 21934.24246120453, "episode/length": 6.0, "episode/score": 0.981249988079071, "episode/reward_rate": 0.14285714285714285, "episode/intrinsic_return": 0.0}
{"step": 700152, "time": 21934.735253810883, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 700248, "time": 21937.631167650223, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 700280, "time": 21938.62194943428, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 701056, "time": 21962.339025974274, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 701320, "time": 21970.09802031517, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 701488, "time": 21975.390297174454, "episode/length": 215.0, "episode/score": 0.328125, "episode/reward_rate": 0.004629629629629629, "episode/intrinsic_return": 0.0}
{"step": 701576, "time": 21977.84282183647, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 701648, "time": 21980.238010168076, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 701824, "time": 21985.643111228943, "episode/length": 210.0, "episode/score": 0.34375, "episode/reward_rate": 0.004739336492890996, "episode/intrinsic_return": 0.0}
{"step": 701904, "time": 21988.076546907425, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 701992, "time": 21990.508728027344, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 702064, "time": 21992.939788103104, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 702128, "time": 21994.86314058304, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 702240, "time": 21998.248667240143, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 702400, "time": 22003.085703372955, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 702464, "time": 22005.027379989624, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 702696, "time": 22011.818365573883, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 702704, "time": 22012.286643981934, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 702968, "time": 22020.16682624817, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 703120, "time": 22024.969571828842, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 703120, "time": 22024.978886842728, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 703352, "time": 22031.8419816494, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 703368, "time": 22032.342110157013, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 703520, "time": 22037.173139572144, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 703664, "time": 22041.52763748169, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 704152, "time": 22056.14279651642, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 704168, "time": 22056.629503250122, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 704328, "time": 22061.439049959183, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 704360, "time": 22062.402443170547, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 704360, "time": 22062.409151554108, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 704776, "time": 22075.54670023918, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 704976, "time": 22081.801077604294, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 705016, "time": 22082.790078163147, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 705048, "time": 22083.761861801147, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 705072, "time": 22084.731402873993, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 705976, "time": 22111.845512628555, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 706024, "time": 22113.298391342163, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 706080, "time": 22115.22315979004, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 706232, "time": 22119.602804660797, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 706496, "time": 22127.798865556717, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 706640, "time": 22132.147008895874, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 706672, "time": 22133.13743329048, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 707048, "time": 22144.296052455902, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 707088, "time": 22145.72278738022, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 707264, "time": 22151.022296190262, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 707328, "time": 22152.968786239624, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 707520, "time": 22158.74766945839, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 707648, "time": 22162.6047604084, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 707704, "time": 22164.06670331955, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 708200, "time": 22179.116371393204, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 708232, "time": 22180.081806898117, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 708232, "time": 22180.089418888092, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 708288, "time": 22182.018934965134, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 708336, "time": 22183.471319913864, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 708352, "time": 22183.957215070724, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 708688, "time": 22194.10152864456, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 708768, "time": 22196.58730483055, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 708816, "time": 22198.038183689117, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 708824, "time": 22198.066321849823, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 709352, "time": 22214.00661301613, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 709472, "time": 22217.858659029007, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 709536, "time": 22219.788110733032, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 709640, "time": 22222.710625886917, "episode/length": 20.0, "episode/score": 0.9375, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.0}
{"step": 709664, "time": 22223.66006708145, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 709737, "time": 22226.731571674347, "train_stats/mean_log_entropy": 0.08622626415433338, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.728478157874381, "train/action_min": 0.0, "train/action_std": 1.961233134316926, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00936982065028889, "train/actor_opt_grad_steps": 43255.0, "train/actor_opt_loss": -9.459380538746862, "train/adv_mag": 0.9849659676599031, "train/adv_max": 0.3081372527792902, "train/adv_mean": 0.0009947022728180072, "train/adv_min": -0.9446175644303313, "train/adv_std": 0.028453793106969483, "train/cont_avg": 0.9951800355816832, "train/cont_loss_mean": 0.017337880909931616, "train/cont_loss_std": 0.23370890668823874, "train/cont_neg_acc": 0.3153344502690995, "train/cont_neg_loss": 2.803974443594787, "train/cont_pos_acc": 0.9998638827611904, "train/cont_pos_loss": 0.003560487376894839, "train/cont_pred": 0.9951277153916879, "train/cont_rate": 0.9951800355816832, "train/dyn_loss_mean": 1.0000144131112807, "train/dyn_loss_std": 0.0003083350147249749, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.2289681376308424, "train/extr_critic_critic_opt_grad_steps": 43255.0, "train/extr_critic_critic_opt_loss": 8288.606254351022, "train/extr_critic_mag": 1.323107383038738, "train/extr_critic_max": 1.323107383038738, "train/extr_critic_mean": 1.2517265529915838, "train/extr_critic_min": 1.0559113055172533, "train/extr_critic_std": 0.01734357093009028, "train/extr_return_normed_mag": 0.9845148068253357, "train/extr_return_normed_max": 0.28028856468672797, "train/extr_return_normed_mean": 0.033167615196307995, "train/extr_return_normed_min": -0.9435403910603853, "train/extr_return_normed_std": 0.034187019221705965, "train/extr_return_rate": 0.9993132255455055, "train/extr_return_raw_mag": 1.4998421297214999, "train/extr_return_raw_max": 1.4998421297214999, "train/extr_return_raw_mean": 1.2527212417951905, "train/extr_return_raw_min": 0.2760131739743865, "train/extr_return_raw_std": 0.03418701910644327, "train/extr_reward_mag": 0.3176005523983795, "train/extr_reward_max": 0.3176005523983795, "train/extr_reward_mean": 0.002236127887107893, "train/extr_reward_min": 6.019478977316677e-08, "train/extr_reward_std": 0.008360967653259487, "train/image_loss_mean": 0.09473010174708792, "train/image_loss_std": 0.10400801384360484, "train/model_loss_mean": 0.7243907363107889, "train/model_loss_std": 0.42928340322900527, "train/model_opt_grad_norm": 21.419361674370457, "train/model_opt_grad_steps": 43218.425742574254, "train/model_opt_loss": 3676.282737807472, "train/model_opt_model_opt_grad_overflow": 0.0049504950495049506, "train/model_opt_model_opt_grad_scale": 5049.504950495049, "train/policy_entropy_mag": 1.3183864048211882, "train/policy_entropy_max": 1.3183864048211882, "train/policy_entropy_mean": 0.11492454315913786, "train/policy_entropy_min": 0.06468649274936997, "train/policy_entropy_std": 0.14809608050059564, "train/policy_logprob_mag": 6.551080248143413, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.11488403313525833, "train/policy_logprob_min": -6.551080248143413, "train/policy_logprob_std": 0.6507999976672748, "train/policy_randomness_mag": 0.677516628905098, "train/policy_randomness_max": 0.677516628905098, "train/policy_randomness_mean": 0.05905953578946024, "train/policy_randomness_min": 0.03324228185828369, "train/policy_randomness_std": 0.07610633486125729, "train/post_ent_mag": 48.13671040298915, "train/post_ent_max": 48.13671040298915, "train/post_ent_mean": 45.29052388786089, "train/post_ent_min": 43.61211406594456, "train/post_ent_std": 0.8943410315135918, "train/prior_ent_mag": 51.60118690339645, "train/prior_ent_max": 51.60118690339645, "train/prior_ent_mean": 47.711583449108765, "train/prior_ent_min": 42.57901493865665, "train/prior_ent_std": 1.5909664731214541, "train/rep_loss_mean": 1.0000144131112807, "train/rep_loss_std": 0.0003083350147249749, "train/reward_avg": 0.0015448088693434815, "train/reward_loss_mean": 0.012314085320726332, "train/reward_loss_std": 0.196421934642119, "train/reward_max_data": 0.6913830447610062, "train/reward_max_pred": 0.12817131469745446, "train/reward_neg_acc": 0.999849681511964, "train/reward_neg_loss": 0.002240494902460089, "train/reward_pos_acc": 0.09633699673545229, "train/reward_pos_loss": 4.290193211901319, "train/reward_pred": 0.0012394447717585112, "train/reward_rate": 0.0022963722153465345, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.028957519680261612, "report/cont_loss_std": 0.33235684037208557, "report/cont_neg_acc": 0.1428571492433548, "report/cont_neg_loss": 3.629453182220459, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.004175346344709396, "report/cont_pred": 0.9947983026504517, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.08698681741952896, "report/image_loss_std": 0.09467101842164993, "report/model_loss_mean": 0.7385494709014893, "report/model_loss_std": 0.6000915765762329, "report/post_ent_mag": 48.266082763671875, "report/post_ent_max": 48.266082763671875, "report/post_ent_mean": 45.452518463134766, "report/post_ent_min": 43.88320541381836, "report/post_ent_std": 0.9093273282051086, "report/prior_ent_mag": 50.13425064086914, "report/prior_ent_max": 50.13425064086914, "report/prior_ent_mean": 46.72450637817383, "report/prior_ent_min": 42.0944709777832, "report/prior_ent_std": 1.3860371112823486, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0031646727584302425, "report/reward_loss_mean": 0.02260507643222809, "report/reward_loss_std": 0.2994946837425232, "report/reward_max_data": 0.875, "report/reward_max_pred": 0.5462677478790283, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0023857641499489546, "report/reward_pos_acc": 0.20000000298023224, "report/reward_pos_loss": 4.143301010131836, "report/reward_pred": 0.0017618341371417046, "report/reward_rate": 0.0048828125, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.019480222836136818, "eval/cont_loss_std": 0.41055864095687866, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 8.13995361328125, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0035888825077563524, "eval/cont_pred": 0.9965609312057495, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.17534691095352173, "eval/image_loss_std": 0.13891875743865967, "eval/model_loss_mean": 0.8007360100746155, "eval/model_loss_std": 0.49025264382362366, "eval/post_ent_mag": 48.24109649658203, "eval/post_ent_max": 48.24109649658203, "eval/post_ent_mean": 45.085304260253906, "eval/post_ent_min": 43.50507736206055, "eval/post_ent_std": 0.950855553150177, "eval/prior_ent_mag": 49.762550354003906, "eval/prior_ent_max": 49.762550354003906, "eval/prior_ent_mean": 46.22026443481445, "eval/prior_ent_min": 41.67097091674805, "eval/prior_ent_std": 1.5456279516220093, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0007110595470294356, "eval/reward_loss_mean": 0.005908871069550514, "eval/reward_loss_std": 0.14344733953475952, "eval/reward_max_data": 0.7281249761581421, "eval/reward_max_pred": 0.030657649040222168, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.001427394337952137, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 4.590459823608398, "eval/reward_pred": 0.0007094917818903923, "eval/reward_rate": 0.0009765625, "replay/size": 709233.0, "replay/inserts": 32320.0, "replay/samples": 32320.0, "replay/insert_wait_avg": 1.3321195498551473e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.313003743048941e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3688.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1219507701484863e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.791685104370117e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.32120013237, "timer/env.step_count": 4040.0, "timer/env.step_total": 38.188159227371216, "timer/env.step_frac": 0.03817589712416159, "timer/env.step_avg": 0.0094525146602404, "timer/env.step_min": 0.007628679275512695, "timer/env.step_max": 0.0517270565032959, "timer/replay._sample_count": 32320.0, "timer/replay._sample_total": 16.69263792037964, "timer/replay._sample_frac": 0.01668727796448855, "timer/replay._sample_avg": 0.0005164801336751126, "timer/replay._sample_min": 0.00043463706970214844, "timer/replay._sample_max": 0.027661561965942383, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4501.0, "timer/agent.policy_total": 46.619237661361694, "timer/agent.policy_frac": 0.04660426836419411, "timer/agent.policy_avg": 0.010357528918320749, "timer/agent.policy_min": 0.008318662643432617, "timer/agent.policy_max": 0.07599472999572754, "timer/dataset_train_count": 2020.0, "timer/dataset_train_total": 0.21782732009887695, "timer/dataset_train_frac": 0.00021775737640075248, "timer/dataset_train_avg": 0.00010783530697964205, "timer/dataset_train_min": 9.632110595703125e-05, "timer/dataset_train_max": 0.0010738372802734375, "timer/agent.train_count": 2020.0, "timer/agent.train_total": 897.5759510993958, "timer/agent.train_frac": 0.8972877421578407, "timer/agent.train_avg": 0.44434453024722564, "timer/agent.train_min": 0.43265771865844727, "timer/agent.train_max": 0.6692526340484619, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.473325252532959, "timer/agent.report_frac": 0.00047317326921625277, "timer/agent.report_avg": 0.2366626262664795, "timer/agent.report_min": 0.23040485382080078, "timer/agent.report_max": 0.2429203987121582, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.170967102050781e-05, "timer/dataset_eval_frac": 3.169948914039985e-08, "timer/dataset_eval_avg": 3.170967102050781e-05, "timer/dataset_eval_min": 3.170967102050781e-05, "timer/dataset_eval_max": 3.170967102050781e-05, "fps": 32.30906845591934}
{"step": 710008, "time": 22235.512066602707, "eval_episode/length": 46.0, "eval_episode/score": 0.856249988079071, "eval_episode/reward_rate": 0.02127659574468085}
{"step": 710008, "time": 22236.286470413208, "eval_episode/length": 89.0, "eval_episode/score": 0.721875011920929, "eval_episode/reward_rate": 0.011111111111111112}
{"step": 710008, "time": 22237.070303201675, "eval_episode/length": 130.0, "eval_episode/score": 0.59375, "eval_episode/reward_rate": 0.007633587786259542}
{"step": 710008, "time": 22237.096884727478, "eval_episode/length": 131.0, "eval_episode/score": 0.590624988079071, "eval_episode/reward_rate": 0.007575757575757576}
{"step": 710008, "time": 22237.180180311203, "eval_episode/length": 135.0, "eval_episode/score": 0.578125, "eval_episode/reward_rate": 0.007352941176470588}
{"step": 710008, "time": 22237.44608426094, "eval_episode/length": 59.0, "eval_episode/score": 0.815625011920929, "eval_episode/reward_rate": 0.016666666666666666}
{"step": 710008, "time": 22237.492308855057, "eval_episode/length": 151.0, "eval_episode/score": 0.528124988079071, "eval_episode/reward_rate": 0.006578947368421052}
{"step": 710008, "time": 22237.79460287094, "eval_episode/length": 167.0, "eval_episode/score": 0.4781250059604645, "eval_episode/reward_rate": 0.005952380952380952}
{"step": 710080, "time": 22240.20215511322, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 710256, "time": 22245.51999282837, "episode/length": 21.0, "episode/score": 0.934374988079071, "episode/reward_rate": 0.045454545454545456, "episode/intrinsic_return": 0.0}
{"step": 710344, "time": 22247.951636075974, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 710600, "time": 22255.799538850784, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 710664, "time": 22257.728132247925, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 711136, "time": 22272.20410180092, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 711424, "time": 22280.897122383118, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 711664, "time": 22288.241943359375, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 711680, "time": 22288.73078393936, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 711816, "time": 22292.60965871811, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 711840, "time": 22293.554311275482, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 711952, "time": 22296.942819833755, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 711976, "time": 22297.450236082077, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 711984, "time": 22297.91580939293, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 712232, "time": 22305.158659934998, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 712352, "time": 22309.027999162674, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 712656, "time": 22318.287968158722, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 712864, "time": 22325.068040132523, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 712968, "time": 22328.010313272476, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 713016, "time": 22329.457662820816, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 713032, "time": 22329.945214033127, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 713072, "time": 22331.39160346985, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 713368, "time": 22340.093231916428, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 713400, "time": 22341.08102273941, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 713656, "time": 22348.87809062004, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 713728, "time": 22351.290074825287, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 714184, "time": 22364.839210033417, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 714264, "time": 22367.279441595078, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 714344, "time": 22369.689917564392, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 714624, "time": 22378.495492458344, "episode/length": 198.0, "episode/score": 0.3812499940395355, "episode/reward_rate": 0.005025125628140704, "episode/intrinsic_return": 0.0}
{"step": 714704, "time": 22380.920833587646, "episode/length": 229.0, "episode/score": 0.28437501192092896, "episode/reward_rate": 0.004347826086956522, "episode/intrinsic_return": 0.0}
{"step": 714800, "time": 22383.830045461655, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 714920, "time": 22387.257105112076, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 715064, "time": 22391.60427379608, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 715216, "time": 22396.431146621704, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 715256, "time": 22397.426234722137, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 715280, "time": 22398.375728607178, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 715648, "time": 22409.652268648148, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 715680, "time": 22410.62283182144, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 715904, "time": 22417.389226913452, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 716080, "time": 22422.715890169144, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 716256, "time": 22428.09820008278, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 716256, "time": 22428.104969978333, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 716800, "time": 22444.769852161407, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 716864, "time": 22446.715287446976, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 716936, "time": 22448.71990585327, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 716952, "time": 22449.211663722992, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 717112, "time": 22454.063616752625, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 717136, "time": 22455.01629447937, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 717376, "time": 22462.307114362717, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 717520, "time": 22466.7810382843, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 717832, "time": 22476.043907642365, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 717928, "time": 22478.979996204376, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 717976, "time": 22480.431978225708, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 717984, "time": 22480.901333093643, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 718184, "time": 22486.738585948944, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 718816, "time": 22506.218994379044, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 719112, "time": 22514.96081495285, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 719264, "time": 22519.786676883698, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 719264, "time": 22519.795475959778, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 719688, "time": 22532.573994398117, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 719720, "time": 22533.55418944359, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 719872, "time": 22538.39280295372, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 720096, "time": 22545.728364944458, "eval_episode/length": 25.0, "eval_episode/score": 0.921875, "eval_episode/reward_rate": 0.038461538461538464}
{"step": 720096, "time": 22546.323714733124, "eval_episode/length": 56.0, "eval_episode/score": 0.824999988079071, "eval_episode/reward_rate": 0.017543859649122806}
{"step": 720096, "time": 22546.388800144196, "eval_episode/length": 59.0, "eval_episode/score": 0.815625011920929, "eval_episode/reward_rate": 0.016666666666666666}
{"step": 720096, "time": 22546.734949588776, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 720096, "time": 22546.761420965195, "eval_episode/length": 78.0, "eval_episode/score": 0.7562500238418579, "eval_episode/reward_rate": 0.012658227848101266}
{"step": 720096, "time": 22546.842754364014, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 720096, "time": 22547.0006210804, "eval_episode/length": 64.0, "eval_episode/score": 0.800000011920929, "eval_episode/reward_rate": 0.015384615384615385}
{"step": 720096, "time": 22547.538336515427, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 720144, "time": 22549.024304389954, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 720216, "time": 22550.977513313293, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 720240, "time": 22551.933163166046, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 720296, "time": 22553.441910982132, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 720328, "time": 22554.414967536926, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 720384, "time": 22556.4415435791, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 720608, "time": 22563.271210193634, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 720632, "time": 22563.78387570381, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 720816, "time": 22569.59066605568, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 720864, "time": 22571.051793813705, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 720888, "time": 22571.559796333313, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 721576, "time": 22592.980222463608, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 721584, "time": 22593.44870853424, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 721688, "time": 22596.366186618805, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 721704, "time": 22596.85839653015, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 722160, "time": 22610.967143535614, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 722184, "time": 22611.477071523666, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 722264, "time": 22613.91884970665, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 722496, "time": 22621.30881714821, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 722560, "time": 22623.272467136383, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 722608, "time": 22624.7320189476, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 722816, "time": 22631.02941441536, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 723128, "time": 22640.245829820633, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 723128, "time": 22640.253487586975, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 723184, "time": 22642.178626060486, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 723592, "time": 22654.37268781662, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 723824, "time": 22661.642997980118, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 723888, "time": 22663.591356515884, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 723896, "time": 22663.620623588562, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 723904, "time": 22664.09201478958, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 724000, "time": 22667.033264875412, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 724272, "time": 22675.352647542953, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 724384, "time": 22678.72107219696, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 724448, "time": 22680.67973446846, "episode/length": 235.0, "episode/score": 0.265625, "episode/reward_rate": 0.00423728813559322, "episode/intrinsic_return": 0.0}
{"step": 724472, "time": 22681.188898324966, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 724576, "time": 22684.54348874092, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 724632, "time": 22686.02959227562, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 724768, "time": 22690.36514234543, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 724848, "time": 22692.768612861633, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 725032, "time": 22698.122458934784, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 725056, "time": 22699.070949316025, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 725072, "time": 22699.57843708992, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 725256, "time": 22704.970937252045, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 725376, "time": 22708.8673992157, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 725392, "time": 22709.373069763184, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 725464, "time": 22711.32438993454, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 725656, "time": 22717.16327047348, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 726080, "time": 22730.250965595245, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 726088, "time": 22730.27959036827, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 726304, "time": 22737.184795856476, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 726344, "time": 22738.171669960022, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 726696, "time": 22748.90920138359, "episode/length": 202.0, "episode/score": 0.3687500059604645, "episode/reward_rate": 0.0049261083743842365, "episode/intrinsic_return": 0.0}
{"step": 726784, "time": 22751.810732126236, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 726872, "time": 22754.281218767166, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 727280, "time": 22766.968273878098, "episode/length": 202.0, "episode/score": 0.3687500059604645, "episode/reward_rate": 0.0049261083743842365, "episode/intrinsic_return": 0.0}
{"step": 727368, "time": 22769.432545661926, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 727496, "time": 22773.341408252716, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 727520, "time": 22774.29183602333, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 727736, "time": 22780.637440681458, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 727920, "time": 22786.441185951233, "episode/length": 196.0, "episode/score": 0.38749998807907104, "episode/reward_rate": 0.005076142131979695, "episode/intrinsic_return": 0.0}
{"step": 727944, "time": 22786.95264363289, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 728160, "time": 22793.75469470024, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 728384, "time": 22800.642574071884, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 728392, "time": 22800.670958280563, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 728400, "time": 22801.14484524727, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 728424, "time": 22801.65223312378, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 728616, "time": 22807.49307870865, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 728696, "time": 22809.9171295166, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 728752, "time": 22811.85294866562, "episode/length": 16.0, "episode/score": 0.949999988079071, "episode/reward_rate": 0.058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 728784, "time": 22812.821081399918, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 728920, "time": 22816.71612429619, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 729096, "time": 22822.292929649353, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 729280, "time": 22828.45182991028, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 729432, "time": 22832.825626850128, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 729496, "time": 22834.75269675255, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 729568, "time": 22837.178467035294, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 729808, "time": 22844.46614766121, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 729880, "time": 22846.44566345215, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 729896, "time": 22846.935279607773, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 730064, "time": 22852.240710258484, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 730080, "time": 22853.306371450424, "eval_episode/length": 31.0, "eval_episode/score": 0.903124988079071, "eval_episode/reward_rate": 0.03125}
{"step": 730080, "time": 22853.92170238495, "eval_episode/length": 65.0, "eval_episode/score": 0.796875, "eval_episode/reward_rate": 0.015151515151515152}
{"step": 730080, "time": 22854.385481119156, "eval_episode/length": 91.0, "eval_episode/score": 0.715624988079071, "eval_episode/reward_rate": 0.010869565217391304}
{"step": 730080, "time": 22854.77124595642, "eval_episode/length": 112.0, "eval_episode/score": 0.6499999761581421, "eval_episode/reward_rate": 0.008849557522123894}
{"step": 730080, "time": 22854.81726694107, "eval_episode/length": 114.0, "eval_episode/score": 0.643750011920929, "eval_episode/reward_rate": 0.008695652173913044}
{"step": 730080, "time": 22855.834646463394, "eval_episode/length": 128.0, "eval_episode/score": 0.6000000238418579, "eval_episode/reward_rate": 0.007751937984496124}
{"step": 730080, "time": 22855.876194238663, "eval_episode/length": 130.0, "eval_episode/score": 0.59375, "eval_episode/reward_rate": 0.007633587786259542}
{"step": 730080, "time": 22856.938794136047, "eval_episode/length": 122.0, "eval_episode/score": 0.6187499761581421, "eval_episode/reward_rate": 0.008130081300813009}
{"step": 730096, "time": 22857.42686533928, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 730512, "time": 22870.018323659897, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 730640, "time": 22873.880558013916, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 730648, "time": 22873.908754110336, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 730704, "time": 22875.84446668625, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 731264, "time": 22892.768445968628, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 731408, "time": 22897.114214897156, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 731416, "time": 22897.14289879799, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 731440, "time": 22898.085955381393, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 731472, "time": 22899.076035261154, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 731592, "time": 22902.46511864662, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 731600, "time": 22902.935002803802, "episode/length": 253.0, "episode/score": 0.20937499403953552, "episode/reward_rate": 0.003937007874015748, "episode/intrinsic_return": 0.0}
{"step": 732096, "time": 22918.01027750969, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 732192, "time": 22920.917224645615, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 732224, "time": 22921.882541179657, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 732304, "time": 22924.317455768585, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 732328, "time": 22924.82521367073, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 732552, "time": 22931.581057548523, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 732736, "time": 22937.35636162758, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 732808, "time": 22939.358929872513, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 732872, "time": 22941.29783797264, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 732960, "time": 22944.206421375275, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 733080, "time": 22947.789856672287, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 733120, "time": 22949.22852087021, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 733576, "time": 22962.84182715416, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 733616, "time": 22964.275666475296, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 733792, "time": 22969.598534584045, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 733912, "time": 22973.014338493347, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 734536, "time": 22992.011509418488, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 734560, "time": 22992.963421583176, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 734640, "time": 22995.376059532166, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 734768, "time": 22999.259897708893, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 734824, "time": 23000.735088586807, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 734912, "time": 23003.629616498947, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 735024, "time": 23007.137157201767, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 735184, "time": 23011.9867374897, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 735192, "time": 23012.014811992645, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 735376, "time": 23017.7816593647, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 735392, "time": 23018.27015709877, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 735432, "time": 23019.261999607086, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 735608, "time": 23024.586119890213, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 735744, "time": 23028.933583021164, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 735760, "time": 23029.421315670013, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 736064, "time": 23038.69508767128, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 736072, "time": 23038.724053621292, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 736144, "time": 23041.135801792145, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 736144, "time": 23041.142928361893, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 736336, "time": 23046.942864894867, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 736992, "time": 23066.832579135895, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 737136, "time": 23071.273012638092, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 737264, "time": 23075.20921397209, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 737456, "time": 23081.488000154495, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 737456, "time": 23081.494421243668, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 737744, "time": 23090.196425437927, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 737872, "time": 23094.067987442017, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 738072, "time": 23099.975269317627, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 738152, "time": 23102.392698287964, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 738160, "time": 23102.862687587738, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 738168, "time": 23102.89097905159, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 738376, "time": 23109.179857730865, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 738456, "time": 23111.59970498085, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 738592, "time": 23115.944413661957, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 738664, "time": 23117.89720416069, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 738752, "time": 23120.7937207222, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 738952, "time": 23126.743962287903, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 738976, "time": 23127.699880361557, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 739000, "time": 23128.230555534363, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 739448, "time": 23141.76773262024, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 739600, "time": 23146.590177297592, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 739712, "time": 23149.99142885208, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 739848, "time": 23153.876490831375, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 739856, "time": 23154.345509052277, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 740064, "time": 23161.668163776398, "eval_episode/length": 52.0, "eval_episode/score": 0.8374999761581421, "eval_episode/reward_rate": 0.018867924528301886}
{"step": 740064, "time": 23161.710243701935, "eval_episode/length": 54.0, "eval_episode/score": 0.831250011920929, "eval_episode/reward_rate": 0.01818181818181818}
{"step": 740064, "time": 23161.773779153824, "eval_episode/length": 57.0, "eval_episode/score": 0.8218749761581421, "eval_episode/reward_rate": 0.017241379310344827}
{"step": 740064, "time": 23162.357746839523, "eval_episode/length": 35.0, "eval_episode/score": 0.890625, "eval_episode/reward_rate": 0.027777777777777776}
{"step": 740064, "time": 23162.497454166412, "eval_episode/length": 95.0, "eval_episode/score": 0.703125, "eval_episode/reward_rate": 0.010416666666666666}
{"step": 740064, "time": 23162.83366394043, "eval_episode/length": 114.0, "eval_episode/score": 0.643750011920929, "eval_episode/reward_rate": 0.008695652173913044}
{"step": 740064, "time": 23162.9630651474, "eval_episode/length": 121.0, "eval_episode/score": 0.621874988079071, "eval_episode/reward_rate": 0.00819672131147541}
{"step": 740064, "time": 23163.178892850876, "eval_episode/length": 133.0, "eval_episode/score": 0.5843750238418579, "eval_episode/reward_rate": 0.007462686567164179}
{"step": 740232, "time": 23168.040821313858, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 740320, "time": 23170.936305761337, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 740384, "time": 23172.87593317032, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 740472, "time": 23175.330609560013, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 740768, "time": 23184.48133444786, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 740976, "time": 23190.892549991608, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 741088, "time": 23194.28876018524, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 741296, "time": 23200.60276556015, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 741312, "time": 23201.09210920334, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 741416, "time": 23204.032913208008, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 741520, "time": 23207.38875603676, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 741552, "time": 23208.38636302948, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 741632, "time": 23210.799204587936, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 741648, "time": 23211.288009405136, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 741904, "time": 23219.188280820847, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 741952, "time": 23220.634090185165, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 742137, "time": 23226.975127220154, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.6174941865524444, "train/action_min": 0.0, "train/action_std": 1.9183805449174183, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.010459232674266147, "train/actor_opt_grad_steps": 45275.0, "train/actor_opt_loss": -9.88997465903216, "train/adv_mag": 0.9699538866482159, "train/adv_max": 0.3644384440809193, "train/adv_mean": 0.0012002588523658477, "train/adv_min": -0.9246629579822616, "train/adv_std": 0.03307278000629774, "train/cont_avg": 0.9949769879331684, "train/cont_loss_mean": 0.017686679500551656, "train/cont_loss_std": 0.23739488529373365, "train/cont_neg_acc": 0.3015008698226792, "train/cont_neg_loss": 2.779808958417201, "train/cont_pos_acc": 0.9998785207177153, "train/cont_pos_loss": 0.003618162192201408, "train/cont_pred": 0.9950129398615053, "train/cont_rate": 0.9949769879331684, "train/dyn_loss_mean": 1.000003184422408, "train/dyn_loss_std": 0.00010186916209715834, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.23706962620968572, "train/extr_critic_critic_opt_grad_steps": 45275.0, "train/extr_critic_critic_opt_loss": 10285.958747486076, "train/extr_critic_mag": 1.3592348618082482, "train/extr_critic_max": 1.3592348618082482, "train/extr_critic_mean": 1.2766993990038882, "train/extr_critic_min": 1.082441262679525, "train/extr_critic_std": 0.019225602775885916, "train/extr_return_normed_mag": 0.9616394420661548, "train/extr_return_normed_max": 0.3302143446289667, "train/extr_return_normed_mean": 0.03762458545146602, "train/extr_return_normed_min": -0.9110026937900203, "train/extr_return_normed_std": 0.039109193060620884, "train/extr_return_rate": 0.9992310387073177, "train/extr_return_raw_mag": 1.5704893558332236, "train/extr_return_raw_max": 1.5704893558332236, "train/extr_return_raw_mean": 1.2778996465229753, "train/extr_return_raw_min": 0.3292723174142365, "train/extr_return_raw_std": 0.0391091933649144, "train/extr_reward_mag": 0.36946780610792707, "train/extr_reward_max": 0.36946780610792707, "train/extr_reward_mean": 0.0023586772149428725, "train/extr_reward_min": 3.304811987546411e-08, "train/extr_reward_std": 0.00978091611794316, "train/image_loss_mean": 0.0919000249687988, "train/image_loss_std": 0.10295450337009855, "train/model_loss_mean": 0.7227870087222298, "train/model_loss_std": 0.4431641876402468, "train/model_opt_grad_norm": 21.064348069748075, "train/model_opt_grad_steps": 45236.41584158416, "train/model_opt_loss": 3613.935050133431, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5000.0, "train/policy_entropy_mag": 1.2689097098784872, "train/policy_entropy_max": 1.2689097098784872, "train/policy_entropy_mean": 0.10972794923599404, "train/policy_entropy_min": 0.06468649238052934, "train/policy_entropy_std": 0.14129688941163593, "train/policy_logprob_mag": 6.551080250503993, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.1100222759022571, "train/policy_logprob_min": -6.551080250503993, "train/policy_logprob_std": 0.6473435243167499, "train/policy_randomness_mag": 0.6520906356301638, "train/policy_randomness_max": 0.6520906356301638, "train/policy_randomness_mean": 0.05638901396921956, "train/policy_randomness_min": 0.03324228167386338, "train/policy_randomness_std": 0.07261224135313885, "train/post_ent_mag": 45.42297693762449, "train/post_ent_max": 45.42297693762449, "train/post_ent_mean": 42.26990656333395, "train/post_ent_min": 40.4204576888887, "train/post_ent_std": 0.9851424313417756, "train/prior_ent_mag": 47.86885948936538, "train/prior_ent_max": 47.86885948936538, "train/prior_ent_mean": 43.828742829879914, "train/prior_ent_min": 39.092512244045146, "train/prior_ent_std": 1.5553740634776578, "train/rep_loss_mean": 1.000003184422408, "train/rep_loss_std": 0.00010186916209715834, "train/reward_avg": 0.0017109332728086704, "train/reward_loss_mean": 0.01319837169652565, "train/reward_loss_std": 0.2058008265736891, "train/reward_max_data": 0.701392327057253, "train/reward_max_pred": 0.13164680606067772, "train/reward_neg_acc": 0.9998546101079129, "train/reward_neg_loss": 0.0023170438143286375, "train/reward_pos_acc": 0.0769021748362676, "train/reward_pos_loss": 4.2751285074197725, "train/reward_pred": 0.0012915704841956054, "train/reward_rate": 0.002547764542079208, "eval_stats/mean_log_entropy": 0.0, "train_stats/mean_log_entropy": 0.0914888247137978, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.023348836228251457, "report/cont_loss_std": 0.320794016122818, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 4.932638645172119, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.004096718039363623, "report/cont_pred": 0.9959445595741272, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.06802480667829514, "report/image_loss_std": 0.08895410597324371, "report/model_loss_mean": 0.7031065821647644, "report/model_loss_std": 0.4689289629459381, "report/post_ent_mag": 44.57191467285156, "report/post_ent_max": 44.57191467285156, "report/post_ent_mean": 41.17304992675781, "report/post_ent_min": 39.4644660949707, "report/post_ent_std": 0.9954800605773926, "report/prior_ent_mag": 46.56133270263672, "report/prior_ent_max": 46.56133270263672, "report/prior_ent_mean": 42.47001266479492, "report/prior_ent_min": 37.895042419433594, "report/prior_ent_std": 1.4777565002441406, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0014129639603197575, "report/reward_loss_mean": 0.01173288282006979, "report/reward_loss_std": 0.19486258924007416, "report/reward_max_data": 0.7875000238418579, "report/reward_max_pred": 0.10341930389404297, "report/reward_neg_acc": 0.9990215301513672, "report/reward_neg_loss": 0.0031304124277085066, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.407595634460449, "report/reward_pred": 0.001579053932800889, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.02725578099489212, "eval/cont_loss_std": 0.5144203305244446, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 8.784684181213379, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0015238648047670722, "eval/cont_pred": 0.9984710216522217, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.19784235954284668, "eval/image_loss_std": 0.15014158189296722, "eval/model_loss_mean": 0.8306310176849365, "eval/model_loss_std": 0.584768533706665, "eval/post_ent_mag": 44.53786087036133, "eval/post_ent_max": 44.53786087036133, "eval/post_ent_mean": 40.89906692504883, "eval/post_ent_min": 39.06441116333008, "eval/post_ent_std": 1.1050934791564941, "eval/prior_ent_mag": 46.60696029663086, "eval/prior_ent_max": 46.60696029663086, "eval/prior_ent_mean": 42.019386291503906, "eval/prior_ent_min": 38.193092346191406, "eval/prior_ent_std": 1.5828728675842285, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0007659912225790322, "eval/reward_loss_mean": 0.005532817915081978, "eval/reward_loss_std": 0.14555686712265015, "eval/reward_max_data": 0.784375011920929, "eval/reward_max_pred": 0.03554236888885498, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0009849315974861383, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 4.658020496368408, "eval/reward_pred": 0.0005068279569968581, "eval/reward_rate": 0.0009765625, "replay/size": 741633.0, "replay/inserts": 32400.0, "replay/samples": 32400.0, "replay/insert_wait_avg": 1.3293013160611376e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.432511930112485e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4880.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.129459162227443e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.238719940185547e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.226895570755, "timer/env.step_count": 4050.0, "timer/env.step_total": 38.44189929962158, "timer/env.step_frac": 0.03843317898154064, "timer/env.step_avg": 0.009491826987560884, "timer/env.step_min": 0.0074923038482666016, "timer/env.step_max": 0.038410186767578125, "timer/replay._sample_count": 32400.0, "timer/replay._sample_total": 16.84222149848938, "timer/replay._sample_frac": 0.01683840093989752, "timer/replay._sample_avg": 0.0005198216511879438, "timer/replay._sample_min": 0.00040030479431152344, "timer/replay._sample_max": 0.03236961364746094, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4660.0, "timer/agent.policy_total": 48.69401550292969, "timer/agent.policy_frac": 0.048682969552766964, "timer/agent.policy_avg": 0.010449359549984912, "timer/agent.policy_min": 0.008660078048706055, "timer/agent.policy_max": 0.08683228492736816, "timer/dataset_train_count": 2025.0, "timer/dataset_train_total": 0.2210400104522705, "timer/dataset_train_frac": 0.0002209898688298513, "timer/dataset_train_avg": 0.00010915556071717062, "timer/dataset_train_min": 9.608268737792969e-05, "timer/dataset_train_max": 0.0006985664367675781, "timer/agent.train_count": 2025.0, "timer/agent.train_total": 901.2805349826813, "timer/agent.train_frac": 0.9010760848101246, "timer/agent.train_avg": 0.44507680739885497, "timer/agent.train_min": 0.4314277172088623, "timer/agent.train_max": 0.6763553619384766, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48049283027648926, "timer/agent.report_frac": 0.00048038383331244837, "timer/agent.report_avg": 0.24024641513824463, "timer/agent.report_min": 0.23261570930480957, "timer/agent.report_max": 0.2478771209716797, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0040740966796875e-05, "timer/dataset_eval_frac": 3.0033926401923896e-08, "timer/dataset_eval_avg": 3.0040740966796875e-05, "timer/dataset_eval_min": 3.0040740966796875e-05, "timer/dataset_eval_max": 3.0040740966796875e-05, "fps": 32.392087110990936}
{"step": 742312, "time": 23232.041549921036, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 742456, "time": 23236.40708756447, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 742632, "time": 23241.719129562378, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 742640, "time": 23242.18598818779, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 742824, "time": 23247.607839345932, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 742968, "time": 23251.989723920822, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 742992, "time": 23252.958971738815, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 743080, "time": 23255.396785259247, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 743304, "time": 23262.15728187561, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 743336, "time": 23263.15377521515, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 743520, "time": 23268.957381248474, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 743536, "time": 23269.44780898094, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 743712, "time": 23274.76996397972, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 743864, "time": 23279.24337387085, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 744200, "time": 23289.404769182205, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 744336, "time": 23293.759814739227, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 744608, "time": 23302.00623202324, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 744680, "time": 23303.957798719406, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 744904, "time": 23310.795860528946, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 745280, "time": 23322.41176700592, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 745304, "time": 23322.928049087524, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 745568, "time": 23331.606400966644, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 745576, "time": 23331.63467860222, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 745616, "time": 23333.071795463562, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 745624, "time": 23333.100641727448, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 746168, "time": 23349.6812479496, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 746184, "time": 23350.168987989426, "episode/length": 230.0, "episode/score": 0.28125, "episode/reward_rate": 0.004329004329004329, "episode/intrinsic_return": 0.0}
{"step": 746376, "time": 23355.99066567421, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 746472, "time": 23358.87877392769, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 746472, "time": 23358.885627985, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 746512, "time": 23360.334543466568, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 747184, "time": 23380.7946767807, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 747360, "time": 23386.115416765213, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 747472, "time": 23389.499022960663, "episode/length": 13.0, "episode/score": 0.9593750238418579, "episode/reward_rate": 0.07142857142857142, "episode/intrinsic_return": 0.0}
{"step": 747504, "time": 23390.46776366234, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 747592, "time": 23392.8998234272, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 747592, "time": 23392.909312725067, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 747720, "time": 23396.849731445312, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 747840, "time": 23400.70277905464, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 747936, "time": 23403.593394756317, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 747968, "time": 23404.57804608345, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 748136, "time": 23409.43366742134, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 748328, "time": 23415.23623943329, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 748336, "time": 23415.701966047287, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 748632, "time": 23424.43812894821, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 748680, "time": 23426.008461236954, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 748768, "time": 23428.906525850296, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 749024, "time": 23436.61576104164, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 749160, "time": 23440.51801919937, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 749608, "time": 23454.087447166443, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 749816, "time": 23460.461943149567, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 749832, "time": 23460.951675891876, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 749968, "time": 23465.275620937347, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 749992, "time": 23465.785116672516, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 750032, "time": 23467.231913805008, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 750048, "time": 23468.102130889893, "eval_episode/length": 20.0, "eval_episode/score": 0.9375, "eval_episode/reward_rate": 0.047619047619047616}
{"step": 750048, "time": 23468.462811231613, "eval_episode/length": 40.0, "eval_episode/score": 0.875, "eval_episode/reward_rate": 0.024390243902439025}
{"step": 750048, "time": 23468.505897521973, "eval_episode/length": 42.0, "eval_episode/score": 0.8687499761581421, "eval_episode/reward_rate": 0.023255813953488372}
{"step": 750048, "time": 23468.671481132507, "eval_episode/length": 51.0, "eval_episode/score": 0.840624988079071, "eval_episode/reward_rate": 0.019230769230769232}
{"step": 750048, "time": 23468.829199552536, "eval_episode/length": 59.0, "eval_episode/score": 0.815625011920929, "eval_episode/reward_rate": 0.016666666666666666}
{"step": 750048, "time": 23469.2590675354, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 750048, "time": 23469.318819999695, "eval_episode/length": 26.0, "eval_episode/score": 0.918749988079071, "eval_episode/reward_rate": 0.037037037037037035}
{"step": 750048, "time": 23469.46315264702, "eval_episode/length": 94.0, "eval_episode/score": 0.706250011920929, "eval_episode/reward_rate": 0.010526315789473684}
{"step": 750152, "time": 23472.370008707047, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 750176, "time": 23473.322377204895, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 750624, "time": 23486.96805715561, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 750648, "time": 23487.476796388626, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 750664, "time": 23487.967879533768, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 750688, "time": 23488.93348312378, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 750848, "time": 23493.770553827286, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 750928, "time": 23496.184088230133, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 751080, "time": 23500.561995983124, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 751280, "time": 23506.817131519318, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 751312, "time": 23507.79828763008, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 751424, "time": 23511.15623998642, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 751464, "time": 23512.147753238678, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 751472, "time": 23512.633917570114, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 751520, "time": 23514.078671455383, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 752144, "time": 23532.991638183594, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 752176, "time": 23533.95558667183, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 752256, "time": 23536.39371061325, "episode/length": 9.0, "episode/score": 0.971875011920929, "episode/reward_rate": 0.1, "episode/intrinsic_return": 0.0}
{"step": 752304, "time": 23537.88454055786, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 752448, "time": 23542.21862721443, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 752480, "time": 23543.184238433838, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 752744, "time": 23551.045026540756, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 752936, "time": 23556.867789030075, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 753056, "time": 23560.696457862854, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 753304, "time": 23567.970678806305, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 753368, "time": 23569.89419913292, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 753728, "time": 23581.608885765076, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 753832, "time": 23584.535150289536, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 753912, "time": 23586.960367918015, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 754032, "time": 23590.80695605278, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 754288, "time": 23598.524773836136, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 754504, "time": 23604.817959070206, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 754568, "time": 23606.847648620605, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 754616, "time": 23608.300272464752, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 754800, "time": 23614.14183282852, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 754880, "time": 23616.58287024498, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 754976, "time": 23619.4778983593, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 755192, "time": 23625.8035197258, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 755368, "time": 23631.12886619568, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 755512, "time": 23635.57650089264, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 755616, "time": 23638.937072992325, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 755664, "time": 23640.40476155281, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 755768, "time": 23643.31986141205, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 756256, "time": 23658.225433826447, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 756408, "time": 23662.60978579521, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 756640, "time": 23669.91400051117, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 756912, "time": 23678.16229724884, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 757008, "time": 23681.05587553978, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 757080, "time": 23683.02161884308, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 757112, "time": 23683.992052555084, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 757288, "time": 23689.30609369278, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 757328, "time": 23690.73424053192, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 757680, "time": 23701.482052326202, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 757712, "time": 23702.478169441223, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 757928, "time": 23708.806467056274, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 757952, "time": 23709.75682783127, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 758304, "time": 23720.43292450905, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 758512, "time": 23726.83204650879, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 758640, "time": 23730.681334018707, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 758752, "time": 23734.062593460083, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 759288, "time": 23749.9930768013, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 759304, "time": 23750.480566978455, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 759320, "time": 23750.987780570984, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 759360, "time": 23752.423436403275, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 759392, "time": 23753.38423728943, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 759592, "time": 23759.279765367508, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 759640, "time": 23760.75048518181, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 759808, "time": 23766.02893924713, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 759936, "time": 23769.866654872894, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 759992, "time": 23771.34211206436, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 760032, "time": 23773.679095506668, "eval_episode/length": 49.0, "eval_episode/score": 0.846875011920929, "eval_episode/reward_rate": 0.02}
{"step": 760032, "time": 23774.296668052673, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 760032, "time": 23774.5298705101, "eval_episode/length": 96.0, "eval_episode/score": 0.699999988079071, "eval_episode/reward_rate": 0.010309278350515464}
{"step": 760032, "time": 23774.642293214798, "eval_episode/length": 102.0, "eval_episode/score": 0.6812499761581421, "eval_episode/reward_rate": 0.009708737864077669}
{"step": 760032, "time": 23775.002341270447, "eval_episode/length": 122.0, "eval_episode/score": 0.6187499761581421, "eval_episode/reward_rate": 0.008130081300813009}
{"step": 760032, "time": 23775.029012918472, "eval_episode/length": 123.0, "eval_episode/score": 0.6156250238418579, "eval_episode/reward_rate": 0.008064516129032258}
{"step": 760032, "time": 23775.090478897095, "eval_episode/length": 29.0, "eval_episode/score": 0.909375011920929, "eval_episode/reward_rate": 0.03333333333333333}
{"step": 760032, "time": 23775.222813367844, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 760152, "time": 23778.62185716629, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 760168, "time": 23779.107961177826, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 760208, "time": 23780.53359103203, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 760656, "time": 23794.13568711281, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 760664, "time": 23794.165452957153, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 760688, "time": 23795.113686323166, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 760832, "time": 23799.44944190979, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 760872, "time": 23800.435478925705, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 760920, "time": 23801.89204454422, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 760952, "time": 23802.855126857758, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 761032, "time": 23805.25923538208, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 761072, "time": 23806.697003126144, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 761096, "time": 23807.207280874252, "episode/length": 187.0, "episode/score": 0.4156250059604645, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.0}
{"step": 761488, "time": 23819.308694839478, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 761696, "time": 23825.57378554344, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 761864, "time": 23830.621112585068, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 761968, "time": 23834.285024642944, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 762088, "time": 23837.69953083992, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 762144, "time": 23839.596222877502, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 762232, "time": 23842.05088162422, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 762632, "time": 23854.17769908905, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 762664, "time": 23855.14041018486, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 762816, "time": 23859.924174547195, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 762824, "time": 23859.952873706818, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 763040, "time": 23866.707191467285, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 763264, "time": 23873.50164413452, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 763320, "time": 23875.060256004333, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 763344, "time": 23876.065074920654, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 763568, "time": 23882.821652412415, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 763712, "time": 23887.154051303864, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 763736, "time": 23887.66079211235, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 763840, "time": 23891.102199316025, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 763952, "time": 23894.579155683517, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 763960, "time": 23894.60848093033, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 764312, "time": 23905.442771196365, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 764344, "time": 23906.405477762222, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 764392, "time": 23907.853535175323, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 764456, "time": 23909.805394411087, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 764472, "time": 23910.299793481827, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 764568, "time": 23913.197947263718, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 764584, "time": 23913.684614658356, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 764584, "time": 23913.690973997116, "episode/length": 13.0, "episode/score": 0.9593750238418579, "episode/reward_rate": 0.07142857142857142, "episode/intrinsic_return": 0.0}
{"step": 764832, "time": 23921.438891410828, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 765144, "time": 23930.666242837906, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 765232, "time": 23933.552019119263, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 765456, "time": 23940.421490192413, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 765504, "time": 23941.88476371765, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 765528, "time": 23942.399456501007, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 765608, "time": 23944.836003780365, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 765632, "time": 23945.791911125183, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 766024, "time": 23957.406837940216, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 766320, "time": 23966.618795394897, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 766552, "time": 23973.416113615036, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 766560, "time": 23973.884467601776, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 766560, "time": 23973.891510009766, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 766640, "time": 23976.307266950607, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 766672, "time": 23977.305530548096, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 766944, "time": 23985.488573551178, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 767160, "time": 23991.79210305214, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 767296, "time": 23996.21759366989, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 767328, "time": 23997.20273256302, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 767440, "time": 24000.577612161636, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 767544, "time": 24003.504930257797, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 767664, "time": 24007.33458018303, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 767840, "time": 24012.61968588829, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 767976, "time": 24016.517426490784, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 768208, "time": 24023.737387895584, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 768240, "time": 24024.70862030983, "episode/length": 199.0, "episode/score": 0.37812501192092896, "episode/reward_rate": 0.005, "episode/intrinsic_return": 0.0}
{"step": 768408, "time": 24029.666846513748, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 768496, "time": 24032.557720899582, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 768632, "time": 24036.44727730751, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 768664, "time": 24037.42043542862, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 768680, "time": 24037.91047501564, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 768792, "time": 24041.32732605934, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 769072, "time": 24050.014436483383, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 769240, "time": 24054.892191410065, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 769272, "time": 24055.94031238556, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 769488, "time": 24062.69252181053, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 769568, "time": 24065.126163244247, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 769592, "time": 24065.63722205162, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 769640, "time": 24067.098663568497, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 769688, "time": 24068.5511136055, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 770008, "time": 24078.21860551834, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 770016, "time": 24079.33200931549, "eval_episode/length": 34.0, "eval_episode/score": 0.893750011920929, "eval_episode/reward_rate": 0.02857142857142857}
{"step": 770016, "time": 24080.348378181458, "eval_episode/length": 91.0, "eval_episode/score": 0.715624988079071, "eval_episode/reward_rate": 0.010869565217391304}
{"step": 770016, "time": 24080.985335111618, "eval_episode/length": 127.0, "eval_episode/score": 0.6031249761581421, "eval_episode/reward_rate": 0.0078125}
{"step": 770016, "time": 24081.04578757286, "eval_episode/length": 130.0, "eval_episode/score": 0.59375, "eval_episode/reward_rate": 0.007633587786259542}
{"step": 770016, "time": 24081.28539800644, "eval_episode/length": 143.0, "eval_episode/score": 0.5531250238418579, "eval_episode/reward_rate": 0.006944444444444444}
{"step": 770016, "time": 24081.957937002182, "eval_episode/length": 181.0, "eval_episode/score": 0.43437498807907104, "eval_episode/reward_rate": 0.005494505494505495}
{"step": 770016, "time": 24082.341222286224, "eval_episode/length": 71.0, "eval_episode/score": 0.778124988079071, "eval_episode/reward_rate": 0.013888888888888888}
{"step": 770016, "time": 24082.69225335121, "eval_episode/length": 94.0, "eval_episode/score": 0.706250011920929, "eval_episode/reward_rate": 0.010526315789473684}
{"step": 770056, "time": 24083.937340974808, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 770104, "time": 24085.789286375046, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 770584, "time": 24100.274675130844, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 770752, "time": 24105.560940265656, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 770840, "time": 24108.004541873932, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 770848, "time": 24108.47109103203, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 770896, "time": 24109.918762922287, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 770976, "time": 24112.326806783676, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 771144, "time": 24117.275085687637, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 771352, "time": 24123.55960893631, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 771384, "time": 24124.52993965149, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 771480, "time": 24127.45063829422, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 771976, "time": 24142.464978694916, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 772072, "time": 24145.446314811707, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 772296, "time": 24152.21015906334, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 772320, "time": 24153.161903858185, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 772376, "time": 24154.631184577942, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 772440, "time": 24156.577684640884, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 772824, "time": 24168.20371890068, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 772840, "time": 24168.692652463913, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 772896, "time": 24170.6007065773, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 773000, "time": 24173.52391219139, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 773280, "time": 24182.29987001419, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 773296, "time": 24182.7798204422, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 773360, "time": 24184.703191757202, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 773440, "time": 24187.117976665497, "episode/length": 260.0, "episode/score": 0.1875, "episode/reward_rate": 0.0038314176245210726, "episode/intrinsic_return": 0.0}
{"step": 773760, "time": 24196.79006075859, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 773880, "time": 24200.20827817917, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 774232, "time": 24211.060073137283, "episode/length": 281.0, "episode/score": 0.12187500298023224, "episode/reward_rate": 0.0035460992907801418, "episode/intrinsic_return": 0.0}
{"step": 774272, "time": 24212.51221895218, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 774368, "time": 24215.426946163177, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 774480, "time": 24218.80724811554, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 774729, "time": 24227.145670890808, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.562172983206955, "train/action_min": 0.0, "train/action_std": 1.9102885775706346, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.011073225926534803, "train/actor_opt_grad_steps": 47305.0, "train/actor_opt_loss": -9.942560409506163, "train/adv_mag": 0.9707262951369379, "train/adv_max": 0.3462478185401243, "train/adv_mean": 0.002148018921907217, "train/adv_min": -0.920042350303893, "train/adv_std": 0.03257314950529048, "train/cont_avg": 0.9950549555759803, "train/cont_loss_mean": 0.01679403844001867, "train/cont_loss_std": 0.224459600733027, "train/cont_neg_acc": 0.30978562764011985, "train/cont_neg_loss": 2.686288815987582, "train/cont_pos_acc": 0.9998892192162719, "train/cont_pos_loss": 0.0036769743196154924, "train/cont_pred": 0.9948918223381042, "train/cont_rate": 0.9950549555759803, "train/dyn_loss_mean": 1.000001166381088, "train/dyn_loss_std": 3.7294033830346286e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.1743270367219606, "train/extr_critic_critic_opt_grad_steps": 47305.0, "train/extr_critic_critic_opt_loss": 12052.646292892157, "train/extr_critic_mag": 1.4161256738737518, "train/extr_critic_max": 1.4161256738737518, "train/extr_critic_mean": 1.3113975355438157, "train/extr_critic_min": 1.1768886879378675, "train/extr_critic_std": 0.022461655371658066, "train/extr_return_normed_mag": 0.9596056523276311, "train/extr_return_normed_max": 0.3748924656241548, "train/extr_return_normed_mean": 0.04407584966689933, "train/extr_return_normed_min": -0.891929459922454, "train/extr_return_normed_std": 0.04089044752147268, "train/extr_return_rate": 0.9995360134863386, "train/extr_return_raw_mag": 1.6443621562976463, "train/extr_return_raw_max": 1.6443621562976463, "train/extr_return_raw_mean": 1.3135456086373796, "train/extr_return_raw_min": 0.3775402307510376, "train/extr_return_raw_std": 0.04089044765843188, "train/extr_reward_mag": 0.3905993098137425, "train/extr_reward_max": 0.3905993098137425, "train/extr_reward_mean": 0.002430122722894428, "train/extr_reward_min": 1.203780080757889e-07, "train/extr_reward_std": 0.010828447763296757, "train/image_loss_mean": 0.09270285712737664, "train/image_loss_std": 0.10369610220339953, "train/model_loss_mean": 0.7227311011622933, "train/model_loss_std": 0.43725034810018304, "train/model_opt_grad_norm": 20.26773163384082, "train/model_opt_grad_steps": 47264.4068627451, "train/model_opt_loss": 3666.1877142214307, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5098.0392156862745, "train/policy_entropy_mag": 1.2909358061996161, "train/policy_entropy_max": 1.2909358061996161, "train/policy_entropy_mean": 0.10130941192162972, "train/policy_entropy_min": 0.0646864925237263, "train/policy_entropy_std": 0.12824146979141468, "train/policy_logprob_mag": 6.551080247935126, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.10120700968100745, "train/policy_logprob_min": -6.551080247935126, "train/policy_logprob_std": 0.6380992350625057, "train/policy_randomness_mag": 0.6634098078105964, "train/policy_randomness_max": 0.6634098078105964, "train/policy_randomness_mean": 0.05206274204686576, "train/policy_randomness_min": 0.03324228176372308, "train/policy_randomness_std": 0.06590308274562452, "train/post_ent_mag": 43.14270372951732, "train/post_ent_max": 43.14270372951732, "train/post_ent_mean": 39.66363478641884, "train/post_ent_min": 37.62076705109839, "train/post_ent_std": 1.0902840243835075, "train/prior_ent_mag": 43.959424336751304, "train/prior_ent_max": 43.959424336751304, "train/prior_ent_mean": 40.230757844214345, "train/prior_ent_min": 36.12982759288713, "train/prior_ent_std": 1.3980104958309847, "train/rep_loss_mean": 1.000001166381088, "train/rep_loss_std": 3.7294033830346286e-05, "train/reward_avg": 0.0017253052986537416, "train/reward_loss_mean": 0.013233481316288532, "train/reward_loss_std": 0.20886107860589584, "train/reward_max_data": 0.7341911754771775, "train/reward_max_pred": 0.1603443721930186, "train/reward_neg_acc": 0.9998511739221274, "train/reward_neg_loss": 0.002405397207350653, "train/reward_pos_acc": 0.09037133093942633, "train/reward_pos_loss": 4.278358740818933, "train/reward_pred": 0.001361881529994528, "train/reward_rate": 0.0025467218137254903, "train_stats/mean_log_entropy": 0.08280007413898906, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.014975990168750286, "report/cont_loss_std": 0.17370280623435974, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 3.2112014293670654, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.005584534723311663, "report/cont_pred": 0.9943965673446655, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.09724792838096619, "report/image_loss_std": 0.12271596491336823, "report/model_loss_mean": 0.7286598086357117, "report/model_loss_std": 0.4360058009624481, "report/post_ent_mag": 40.116615295410156, "report/post_ent_max": 40.116615295410156, "report/post_ent_mean": 36.721168518066406, "report/post_ent_min": 34.924468994140625, "report/post_ent_std": 0.9728737473487854, "report/prior_ent_mag": 40.936180114746094, "report/prior_ent_max": 40.936180114746094, "report/prior_ent_mean": 37.075286865234375, "report/prior_ent_min": 33.451019287109375, "report/prior_ent_std": 1.1872289180755615, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.002227783203125, "report/reward_loss_mean": 0.016435855999588966, "report/reward_loss_std": 0.22370082139968872, "report/reward_max_data": 0.8374999761581421, "report/reward_max_pred": 0.035839200019836426, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.004327933769673109, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.137165069580078, "report/reward_pred": 0.0022924309596419334, "report/reward_rate": 0.0029296875, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.05304771661758423, "eval/cont_loss_std": 0.7727096676826477, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 10.46013355255127, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.001982525223866105, "eval/cont_pred": 0.9980268478393555, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2127729058265686, "eval/image_loss_std": 0.14437061548233032, "eval/model_loss_mean": 0.8707966804504395, "eval/model_loss_std": 0.8124604225158691, "eval/post_ent_mag": 40.117897033691406, "eval/post_ent_max": 40.117897033691406, "eval/post_ent_mean": 36.38751220703125, "eval/post_ent_min": 34.41447448730469, "eval/post_ent_std": 1.1842550039291382, "eval/prior_ent_mag": 41.065940856933594, "eval/prior_ent_max": 41.065940856933594, "eval/prior_ent_mean": 36.564674377441406, "eval/prior_ent_min": 32.61459732055664, "eval/prior_ent_std": 1.4768109321594238, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0007476806640625, "eval/reward_loss_mean": 0.004976075608283281, "eval/reward_loss_std": 0.13124710321426392, "eval/reward_max_data": 0.765625, "eval/reward_max_pred": 0.020368218421936035, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0008749104454182088, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 4.200468063354492, "eval/reward_pred": 0.0004556190688163042, "eval/reward_rate": 0.0009765625, "replay/size": 774225.0, "replay/inserts": 32592.0, "replay/samples": 32592.0, "replay/insert_wait_avg": 1.3246671440675086e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.373179737703438e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3616.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.084290247047897e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.940696716308594e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1547634601593, "timer/env.step_count": 4074.0, "timer/env.step_total": 38.6484694480896, "timer/env.step_frac": 0.03864248900278236, "timer/env.step_avg": 0.009486614984803535, "timer/env.step_min": 0.007658243179321289, "timer/env.step_max": 0.0534520149230957, "timer/replay._sample_count": 32592.0, "timer/replay._sample_total": 16.725337266921997, "timer/replay._sample_frac": 0.016722749196392987, "timer/replay._sample_avg": 0.0005131730874730608, "timer/replay._sample_min": 0.00041294097900390625, "timer/replay._sample_max": 0.03648233413696289, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4526.0, "timer/agent.policy_total": 46.68307709693909, "timer/agent.policy_frac": 0.046675853380364056, "timer/agent.policy_avg": 0.01031442269044169, "timer/agent.policy_min": 0.008933782577514648, "timer/agent.policy_max": 0.07398748397827148, "timer/dataset_train_count": 2037.0, "timer/dataset_train_total": 0.21857857704162598, "timer/dataset_train_frac": 0.00021854475429925095, "timer/dataset_train_avg": 0.00010730416153246243, "timer/dataset_train_min": 9.512901306152344e-05, "timer/dataset_train_max": 0.0004286766052246094, "timer/agent.train_count": 2037.0, "timer/agent.train_total": 904.8615274429321, "timer/agent.train_frac": 0.9047215096116241, "timer/agent.train_avg": 0.44421282643246546, "timer/agent.train_min": 0.43117475509643555, "timer/agent.train_max": 0.666064977645874, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48479175567626953, "timer/agent.report_frac": 0.00048471673923650816, "timer/agent.report_avg": 0.24239587783813477, "timer/agent.report_min": 0.23323345184326172, "timer/agent.report_max": 0.2515583038330078, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.552436828613281e-05, "timer/dataset_eval_frac": 3.551887126271524e-08, "timer/dataset_eval_avg": 3.552436828613281e-05, "timer/dataset_eval_min": 3.552436828613281e-05, "timer/dataset_eval_max": 3.552436828613281e-05, "fps": 32.58642528938872}
{"step": 774864, "time": 24231.22632598877, "episode/length": 232.0, "episode/score": 0.2750000059604645, "episode/reward_rate": 0.004291845493562232, "episode/intrinsic_return": 0.0}
{"step": 774872, "time": 24231.255637407303, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 774936, "time": 24233.2198138237, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 775144, "time": 24239.708481788635, "episode/length": 230.0, "episode/score": 0.28125, "episode/reward_rate": 0.004329004329004329, "episode/intrinsic_return": 0.0}
{"step": 775184, "time": 24241.151906728745, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 775432, "time": 24248.43918824196, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 775568, "time": 24252.774965047836, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 775824, "time": 24260.563320875168, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 775840, "time": 24261.05272102356, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 775840, "time": 24261.059317350388, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 775864, "time": 24261.56907248497, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 775920, "time": 24263.491502285004, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 775984, "time": 24265.564484119415, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 776304, "time": 24275.287201166153, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 776392, "time": 24277.736629009247, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 776576, "time": 24283.527585983276, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 776576, "time": 24283.5352704525, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 776584, "time": 24283.56393098831, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 776952, "time": 24294.76643180847, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 776968, "time": 24295.372303962708, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 777344, "time": 24306.97681093216, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 777600, "time": 24314.754240512848, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 777600, "time": 24314.76272368431, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 777944, "time": 24324.98392033577, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 778152, "time": 24331.329218387604, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 778176, "time": 24332.289339780807, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 778184, "time": 24332.31882929802, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 778592, "time": 24345.39568090439, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 778616, "time": 24345.908140659332, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 778704, "time": 24348.80682492256, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 778856, "time": 24353.188575983047, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 778856, "time": 24353.196482419968, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 779064, "time": 24359.61226963997, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 779256, "time": 24365.502411842346, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 779264, "time": 24365.975487470627, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 779376, "time": 24369.37508416176, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 779672, "time": 24378.110875606537, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 779864, "time": 24383.903803110123, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 780000, "time": 24389.457213640213, "eval_episode/length": 55.0, "eval_episode/score": 0.828125, "eval_episode/reward_rate": 0.017857142857142856}
{"step": 780000, "time": 24389.525599241257, "eval_episode/length": 58.0, "eval_episode/score": 0.8187500238418579, "eval_episode/reward_rate": 0.01694915254237288}
{"step": 780000, "time": 24390.012089252472, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 780000, "time": 24390.26782464981, "eval_episode/length": 96.0, "eval_episode/score": 0.699999988079071, "eval_episode/reward_rate": 0.010309278350515464}
{"step": 780000, "time": 24390.29484438896, "eval_episode/length": 97.0, "eval_episode/score": 0.6968749761581421, "eval_episode/reward_rate": 0.01020408163265306}
{"step": 780000, "time": 24391.145184516907, "eval_episode/length": 81.0, "eval_episode/score": 0.746874988079071, "eval_episode/reward_rate": 0.012195121951219513}
{"step": 780000, "time": 24391.569791793823, "eval_episode/length": 163.0, "eval_episode/score": 0.4906249940395355, "eval_episode/reward_rate": 0.006097560975609756}
{"step": 780000, "time": 24392.41974210739, "eval_episode/length": 125.0, "eval_episode/score": 0.609375, "eval_episode/reward_rate": 0.007936507936507936}
{"step": 780000, "time": 24392.426790237427, "eval_episode/length": 209.0, "eval_episode/score": 0.34687501192092896, "eval_episode/reward_rate": 0.004761904761904762}
{"step": 780200, "time": 24398.25291776657, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 780200, "time": 24398.264326810837, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 780256, "time": 24400.189312934875, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 780368, "time": 24403.612382888794, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 780472, "time": 24406.555201292038, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 780488, "time": 24407.047429323196, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 780928, "time": 24420.655316352844, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 781192, "time": 24428.43513059616, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 781760, "time": 24445.89276432991, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 781984, "time": 24452.66405248642, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 782120, "time": 24456.542733192444, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 782512, "time": 24468.573279857635, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 782512, "time": 24468.58160662651, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 782568, "time": 24470.050139904022, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 782576, "time": 24470.518441915512, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 782680, "time": 24473.43937778473, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 782800, "time": 24477.39632344246, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 782864, "time": 24479.339923858643, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 782864, "time": 24479.347215414047, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 783184, "time": 24488.96959733963, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 783368, "time": 24494.26302742958, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 783440, "time": 24496.638074159622, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 783464, "time": 24497.149759054184, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 783904, "time": 24510.685631990433, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 783968, "time": 24512.638798713684, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 784024, "time": 24514.12040233612, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 784096, "time": 24516.546981573105, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 784096, "time": 24516.55455684662, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 784136, "time": 24517.56853032112, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 784600, "time": 24531.588485956192, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 784616, "time": 24532.076044797897, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 784680, "time": 24534.01749110222, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 784880, "time": 24540.40074634552, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 784920, "time": 24541.412819862366, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 784992, "time": 24543.797659873962, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 784992, "time": 24543.804109573364, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 785088, "time": 24546.706874370575, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 785168, "time": 24549.10883498192, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 785320, "time": 24553.470388650894, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 785440, "time": 24557.317039489746, "episode/length": 14.0, "episode/score": 0.956250011920929, "episode/reward_rate": 0.06666666666666667, "episode/intrinsic_return": 0.0}
{"step": 785616, "time": 24563.54025912285, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 785632, "time": 24564.026649713516, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 785776, "time": 24568.438561201096, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 785888, "time": 24571.826465129852, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 786032, "time": 24576.199523210526, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 786048, "time": 24576.688175678253, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 786408, "time": 24587.335699796677, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 786424, "time": 24587.82284474373, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 786456, "time": 24589.258259296417, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 786656, "time": 24595.575587511063, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 786656, "time": 24595.58873605728, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 786736, "time": 24598.01375889778, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 786816, "time": 24600.428150892258, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 787088, "time": 24608.64987707138, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 787288, "time": 24614.488983392715, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 787480, "time": 24620.327709913254, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 787552, "time": 24622.724161863327, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 787552, "time": 24622.73210835457, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 787624, "time": 24624.681059598923, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 787840, "time": 24631.585606575012, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 788080, "time": 24638.842667341232, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 788360, "time": 24647.07528781891, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 788400, "time": 24648.501537799835, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 788560, "time": 24653.322540283203, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 788664, "time": 24656.341054439545, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 788720, "time": 24658.247210502625, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 788752, "time": 24659.23421907425, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 788968, "time": 24665.5157725811, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 789136, "time": 24670.8064994812, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 789400, "time": 24678.62025976181, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 789512, "time": 24681.997849464417, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 789536, "time": 24682.94760465622, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 789552, "time": 24683.45778989792, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 789616, "time": 24685.502390146255, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 789864, "time": 24692.85655450821, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 789912, "time": 24694.347158432007, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 789920, "time": 24694.814544439316, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 790016, "time": 24697.72412610054, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 790064, "time": 24699.202743530273, "episode/length": 18.0, "episode/score": 0.9437500238418579, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.0}
{"step": 790088, "time": 24701.2251060009, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 790088, "time": 24701.30465579033, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 790088, "time": 24701.617424964905, "eval_episode/length": 103.0, "eval_episode/score": 0.6781250238418579, "eval_episode/reward_rate": 0.009615384615384616}
{"step": 790088, "time": 24702.107801914215, "eval_episode/length": 131.0, "eval_episode/score": 0.590624988079071, "eval_episode/reward_rate": 0.007575757575757576}
{"step": 790088, "time": 24702.260187149048, "eval_episode/length": 139.0, "eval_episode/score": 0.565625011920929, "eval_episode/reward_rate": 0.007142857142857143}
{"step": 790088, "time": 24703.594435453415, "eval_episode/length": 89.0, "eval_episode/score": 0.721875011920929, "eval_episode/reward_rate": 0.011111111111111112}
{"step": 790088, "time": 24703.83901667595, "eval_episode/length": 106.0, "eval_episode/score": 0.668749988079071, "eval_episode/reward_rate": 0.009345794392523364}
{"step": 790088, "time": 24704.132266759872, "eval_episode/length": 15.0, "eval_episode/score": 0.953125, "eval_episode/reward_rate": 0.0625}
{"step": 790168, "time": 24706.546059131622, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 790296, "time": 24710.424430847168, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 790544, "time": 24718.246510744095, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 790696, "time": 24722.628031492233, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 790744, "time": 24724.084844350815, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 791024, "time": 24732.765361070633, "episode/length": 235.0, "episode/score": 0.265625, "episode/reward_rate": 0.00423728813559322, "episode/intrinsic_return": 0.0}
{"step": 791048, "time": 24733.278010845184, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 791064, "time": 24733.767889261246, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 791160, "time": 24736.68994450569, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 791200, "time": 24738.122438907623, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 791400, "time": 24743.962829113007, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 791408, "time": 24744.42891407013, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 791448, "time": 24745.49777364731, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 791864, "time": 24758.110731124878, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 792144, "time": 24766.83883857727, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 792248, "time": 24769.750176906586, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 792272, "time": 24770.717936515808, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 792352, "time": 24773.132158517838, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 792584, "time": 24781.957266807556, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 792936, "time": 24792.618561029434, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 793080, "time": 24796.972009181976, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 793152, "time": 24799.370583057404, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 793184, "time": 24800.3403339386, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 793376, "time": 24806.266770124435, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 793760, "time": 24817.95404458046, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 794008, "time": 24825.217536211014, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 794408, "time": 24837.41964006424, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 794416, "time": 24837.891860485077, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 794664, "time": 24845.64287519455, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 794776, "time": 24849.043832302094, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 794784, "time": 24849.51018691063, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 794896, "time": 24852.922905921936, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 795096, "time": 24858.748028755188, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 795392, "time": 24868.01755976677, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 795408, "time": 24868.505784273148, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 795440, "time": 24869.472414970398, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 795496, "time": 24870.96421957016, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 795616, "time": 24874.789286613464, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 795952, "time": 24884.94930744171, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 796072, "time": 24888.334705114365, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 796224, "time": 24893.135152339935, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 796424, "time": 24899.05808186531, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 796528, "time": 24902.436177015305, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 796776, "time": 24909.75696349144, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 796824, "time": 24911.19301056862, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 796920, "time": 24914.09268593788, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 796976, "time": 24915.99466443062, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 797120, "time": 24920.351838350296, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 797208, "time": 24922.779232501984, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 797216, "time": 24923.24395108223, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 797456, "time": 24930.614917755127, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 797680, "time": 24937.407076597214, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 797896, "time": 24943.723225593567, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 798024, "time": 24947.556744337082, "episode/length": 199.0, "episode/score": 0.37812501192092896, "episode/reward_rate": 0.005, "episode/intrinsic_return": 0.0}
{"step": 798128, "time": 24950.91473054886, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 798224, "time": 24953.815749168396, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 798616, "time": 24965.50325369835, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 798864, "time": 24973.176517248154, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 798984, "time": 24976.55709052086, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 799088, "time": 24979.919637680054, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 799136, "time": 24981.359694957733, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 799344, "time": 24987.728728294373, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 799528, "time": 24993.04782819748, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 799600, "time": 24995.41387104988, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 799608, "time": 24995.442165851593, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 799616, "time": 24995.908062696457, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 800072, "time": 25009.901411771774, "eval_episode/length": 26.0, "eval_episode/score": 0.918749988079071, "eval_episode/reward_rate": 0.037037037037037035}
{"step": 800072, "time": 25009.907423496246, "eval_episode/length": 26.0, "eval_episode/score": 0.918749988079071, "eval_episode/reward_rate": 0.037037037037037035}
{"step": 800072, "time": 25010.210481405258, "eval_episode/length": 43.0, "eval_episode/score": 0.8656250238418579, "eval_episode/reward_rate": 0.022727272727272728}
{"step": 800072, "time": 25010.649069547653, "eval_episode/length": 67.0, "eval_episode/score": 0.7906249761581421, "eval_episode/reward_rate": 0.014705882352941176}
{"step": 800072, "time": 25010.982149124146, "eval_episode/length": 85.0, "eval_episode/score": 0.734375, "eval_episode/reward_rate": 0.011627906976744186}
{"step": 800072, "time": 25011.530106067657, "eval_episode/length": 89.0, "eval_episode/score": 0.721875011920929, "eval_episode/reward_rate": 0.011111111111111112}
{"step": 800072, "time": 25011.537370204926, "eval_episode/length": 116.0, "eval_episode/score": 0.637499988079071, "eval_episode/reward_rate": 0.008547008547008548}
{"step": 800072, "time": 25011.702328920364, "eval_episode/length": 39.0, "eval_episode/score": 0.878125011920929, "eval_episode/reward_rate": 0.025}
{"step": 800144, "time": 25014.10525226593, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 800176, "time": 25015.163313627243, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 800208, "time": 25016.13067007065, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 800416, "time": 25022.40351986885, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 800544, "time": 25026.277589321136, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 800688, "time": 25030.629434347153, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 801112, "time": 25043.182773590088, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 801408, "time": 25052.480839014053, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 801448, "time": 25053.477339982986, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 801920, "time": 25067.91391992569, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 802160, "time": 25075.26875090599, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 802264, "time": 25078.19019961357, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 802328, "time": 25080.126574277878, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 802456, "time": 25084.00501894951, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 802488, "time": 25084.969945430756, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 802512, "time": 25085.931384801865, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0}
{"step": 802856, "time": 25096.537702560425, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 803096, "time": 25103.749104738235, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 803232, "time": 25108.214072704315, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 803288, "time": 25109.688136339188, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 803672, "time": 25121.3497941494, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 803760, "time": 25124.278660535812, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 803760, "time": 25124.286279916763, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 803800, "time": 25125.304072618484, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 803920, "time": 25129.144562482834, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 804264, "time": 25139.425245523453, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 804336, "time": 25141.856724977493, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 804680, "time": 25152.048968553543, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 804752, "time": 25154.459362268448, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 804768, "time": 25154.947911024094, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 804856, "time": 25157.376568555832, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 805120, "time": 25165.67728114128, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 805248, "time": 25169.560536384583, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 805256, "time": 25169.588655233383, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 805600, "time": 25180.21067762375, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 805872, "time": 25188.451614141464, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 805960, "time": 25190.875333547592, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 805960, "time": 25190.88396024704, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 805984, "time": 25191.83236169815, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 806304, "time": 25201.58719921112, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 806344, "time": 25202.58158159256, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 806536, "time": 25208.395391702652, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 806600, "time": 25210.32901930809, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 806920, "time": 25219.988627672195, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 806952, "time": 25220.951436281204, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 806992, "time": 25222.38923573494, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 807104, "time": 25225.8271818161, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 807120, "time": 25226.31454205513, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 807129, "time": 25227.336746692657, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.5618449296101486, "train/action_min": 0.0, "train/action_std": 1.900079825136921, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.01028778268102704, "train/actor_opt_grad_steps": 49335.0, "train/actor_opt_loss": -11.674656201559719, "train/adv_mag": 1.0658725526663337, "train/adv_max": 0.3291439101247504, "train/adv_mean": 0.0020498060500115274, "train/adv_min": -1.020798121348466, "train/adv_std": 0.032095039129662925, "train/cont_avg": 0.9948464573019802, "train/cont_loss_mean": 0.017898132169900445, "train/cont_loss_std": 0.23074766677011285, "train/cont_neg_acc": 0.31253968834877016, "train/cont_neg_loss": 2.668260677237995, "train/cont_pos_acc": 0.9998833749553945, "train/cont_pos_loss": 0.003906335606756113, "train/cont_pred": 0.9946726663868026, "train/cont_rate": 0.9948464573019802, "train/dyn_loss_mean": 1.0000410699608302, "train/dyn_loss_std": 0.0004167027139257049, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.15339617646935552, "train/extr_critic_critic_opt_grad_steps": 49335.0, "train/extr_critic_critic_opt_loss": 13245.43898901609, "train/extr_critic_mag": 1.4792114885726777, "train/extr_critic_max": 1.4792114885726777, "train/extr_critic_mean": 1.3863267467753722, "train/extr_critic_min": 1.1948211983879014, "train/extr_critic_std": 0.025244486942370928, "train/extr_return_normed_mag": 1.0630549617332987, "train/extr_return_normed_max": 0.32140077399735406, "train/extr_return_normed_mean": 0.0502753593212012, "train/extr_return_normed_min": -1.0060075899161915, "train/extr_return_normed_std": 0.04175094156387714, "train/extr_return_rate": 0.9994099143117962, "train/extr_return_raw_mag": 1.659501832900661, "train/extr_return_raw_max": 1.659501832900661, "train/extr_return_raw_mean": 1.388376490314408, "train/extr_return_raw_min": 0.33209346898711556, "train/extr_return_raw_std": 0.04175094180362354, "train/extr_reward_mag": 0.32640759425588173, "train/extr_reward_max": 0.32640759425588173, "train/extr_reward_mean": 0.002347587807781736, "train/extr_reward_min": 1.0681624459748221e-07, "train/extr_reward_std": 0.008945708471986622, "train/image_loss_mean": 0.09230654625830674, "train/image_loss_std": 0.1038872336618381, "train/model_loss_mean": 0.7239641798014688, "train/model_loss_std": 0.43846982938818413, "train/model_opt_grad_norm": 19.72550731393235, "train/model_opt_grad_steps": 49292.44554455446, "train/model_opt_loss": 3797.148933032952, "train/model_opt_model_opt_grad_overflow": 0.0049504950495049506, "train/model_opt_model_opt_grad_scale": 5222.772277227723, "train/policy_entropy_mag": 1.3191915479036842, "train/policy_entropy_max": 1.3191915479036842, "train/policy_entropy_mean": 0.10457531735301018, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.13369843784240212, "train/policy_logprob_mag": 6.5510802410616735, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.10504816992595645, "train/policy_logprob_min": -6.5510802410616735, "train/policy_logprob_std": 0.6437197306958755, "train/policy_randomness_mag": 0.6779303898905763, "train/policy_randomness_max": 0.6779303898905763, "train/policy_randomness_mean": 0.05374108498344327, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.06870740996950334, "train/post_ent_mag": 41.13527314969809, "train/post_ent_max": 41.13527314969809, "train/post_ent_mean": 37.41165502944795, "train/post_ent_min": 35.20648255678687, "train/post_ent_std": 1.1736883771891642, "train/prior_ent_mag": 41.18510676846646, "train/prior_ent_max": 41.18510676846646, "train/prior_ent_mean": 37.23520777485158, "train/prior_ent_min": 33.20273900740217, "train/prior_ent_std": 1.3915818906066442, "train/rep_loss_mean": 1.0000410699608302, "train/rep_loss_std": 0.0004167027139257049, "train/reward_avg": 0.0018078492436987938, "train/reward_loss_mean": 0.01373483846425125, "train/reward_loss_std": 0.20559995572340886, "train/reward_max_data": 0.6930693056766349, "train/reward_max_pred": 0.17909196992911916, "train/reward_neg_acc": 0.9997672119943222, "train/reward_neg_loss": 0.0026293574097003823, "train/reward_pos_acc": 0.1389832704453855, "train/reward_pos_loss": 4.0977838632222765, "train/reward_pred": 0.0015055943271237435, "train/reward_rate": 0.002721805383663366, "train_stats/mean_log_entropy": 0.0898040346640013, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.02010190114378929, "report/cont_loss_std": 0.21942974627017975, "report/cont_neg_acc": 0.2857142984867096, "report/cont_neg_loss": 2.247413158416748, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.004771342966705561, "report/cont_pred": 0.993227481842041, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 1.000002145767212, "report/dyn_loss_std": 6.631877477047965e-05, "report/image_loss_mean": 0.07866839319467545, "report/image_loss_std": 0.09490413218736649, "report/model_loss_mean": 0.7190940976142883, "report/model_loss_std": 0.5107824206352234, "report/post_ent_mag": 41.719947814941406, "report/post_ent_max": 41.719947814941406, "report/post_ent_mean": 37.64911651611328, "report/post_ent_min": 35.07390594482422, "report/post_ent_std": 1.2618677616119385, "report/prior_ent_mag": 40.504661560058594, "report/prior_ent_max": 40.504661560058594, "report/prior_ent_mean": 36.44117736816406, "report/prior_ent_min": 31.510709762573242, "report/prior_ent_std": 1.439488172531128, "report/rep_loss_mean": 1.000002145767212, "report/rep_loss_std": 6.631877477047965e-05, "report/reward_avg": 0.0023895264603197575, "report/reward_loss_mean": 0.020322570577263832, "report/reward_loss_std": 0.26907268166542053, "report/reward_max_data": 0.699999988079071, "report/reward_max_pred": 0.033644676208496094, "report/reward_neg_acc": 0.9999999403953552, "report/reward_neg_loss": 0.003510280279442668, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.3074564933776855, "report/reward_pred": 0.0019041518680751324, "report/reward_rate": 0.00390625, "eval/cont_avg": 0.9931640625, "eval/cont_loss_mean": 0.058440037071704865, "eval/cont_loss_std": 0.7431367039680481, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 7.937826156616211, "eval/cont_pos_acc": 0.9990166425704956, "eval/cont_pos_loss": 0.004206306301057339, "eval/cont_pred": 0.9960131645202637, "eval/cont_rate": 0.9931640625, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.20081327855587006, "eval/image_loss_std": 0.15356071293354034, "eval/model_loss_mean": 0.8737130165100098, "eval/model_loss_std": 0.8540194630622864, "eval/post_ent_mag": 41.6988525390625, "eval/post_ent_max": 41.6988525390625, "eval/post_ent_mean": 37.589927673339844, "eval/post_ent_min": 35.362205505371094, "eval/post_ent_std": 1.3307878971099854, "eval/prior_ent_mag": 40.632835388183594, "eval/prior_ent_max": 40.632835388183594, "eval/prior_ent_mean": 36.143489837646484, "eval/prior_ent_min": 31.055028915405273, "eval/prior_ent_std": 1.5326660871505737, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.002105712890625, "eval/reward_loss_mean": 0.014459675177931786, "eval/reward_loss_std": 0.22650127112865448, "eval/reward_max_data": 0.796875, "eval/reward_max_pred": 0.08976483345031738, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0021968709770590067, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 4.187901496887207, "eval/reward_pred": 0.0011732352431863546, "eval/reward_rate": 0.0029296875, "replay/size": 806625.0, "replay/inserts": 32400.0, "replay/samples": 32400.0, "replay/insert_wait_avg": 1.3343640315679857e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.359514636757933e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4336.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1162674295066467e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1026859283447266e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1719179153442, "timer/env.step_count": 4050.0, "timer/env.step_total": 38.38711142539978, "timer/env.step_frac": 0.038380513127593045, "timer/env.step_avg": 0.009478299117382662, "timer/env.step_min": 0.007570743560791016, "timer/env.step_max": 0.04927539825439453, "timer/replay._sample_count": 32400.0, "timer/replay._sample_total": 16.561480045318604, "timer/replay._sample_frac": 0.01655863331959735, "timer/replay._sample_avg": 0.0005111567915221791, "timer/replay._sample_min": 0.00039267539978027344, "timer/replay._sample_max": 0.013056278228759766, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4592.0, "timer/agent.policy_total": 47.71986722946167, "timer/agent.policy_frac": 0.04771166473952205, "timer/agent.policy_avg": 0.010391957149273011, "timer/agent.policy_min": 0.008443832397460938, "timer/agent.policy_max": 0.0863497257232666, "timer/dataset_train_count": 2025.0, "timer/dataset_train_total": 0.21988964080810547, "timer/dataset_train_frac": 0.0002198518443373424, "timer/dataset_train_avg": 0.00010858747694227431, "timer/dataset_train_min": 9.417533874511719e-05, "timer/dataset_train_max": 0.001077890396118164, "timer/agent.train_count": 2025.0, "timer/agent.train_total": 902.0699534416199, "timer/agent.train_frac": 0.9019148981125185, "timer/agent.train_avg": 0.445466643674874, "timer/agent.train_min": 0.4335591793060303, "timer/agent.train_max": 2.3643534183502197, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4786205291748047, "timer/agent.report_frac": 0.00047853825987475456, "timer/agent.report_avg": 0.23931026458740234, "timer/agent.report_min": 0.23308467864990234, "timer/agent.report_max": 0.24553585052490234, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.361701965332031e-05, "timer/dataset_eval_frac": 3.361124127878753e-08, "timer/dataset_eval_avg": 3.361701965332031e-05, "timer/dataset_eval_min": 3.361701965332031e-05, "timer/dataset_eval_max": 3.361701965332031e-05, "fps": 32.39389355260726}
{"step": 807360, "time": 25234.329186201096, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 807440, "time": 25236.747553110123, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 807576, "time": 25240.643176794052, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 807632, "time": 25242.58127641678, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 807856, "time": 25249.37433242798, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 807912, "time": 25250.847984075546, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 807944, "time": 25253.552069187164, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 807944, "time": 25253.560183286667, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 808272, "time": 25263.850057840347, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 808360, "time": 25266.286927461624, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 808368, "time": 25266.75612473488, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 808800, "time": 25279.797934532166, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 809192, "time": 25291.556371450424, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 809264, "time": 25293.969232320786, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 809304, "time": 25294.965389728546, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 809400, "time": 25297.885463237762, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 809584, "time": 25303.68226456642, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 809864, "time": 25311.90030312538, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 809864, "time": 25311.907168865204, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 809888, "time": 25312.867044448853, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 809992, "time": 25315.838173627853, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 810056, "time": 25319.62986445427, "eval_episode/length": 103.0, "eval_episode/score": 0.6781250238418579, "eval_episode/reward_rate": 0.009615384615384616}
{"step": 810056, "time": 25319.855577230453, "eval_episode/length": 114.0, "eval_episode/score": 0.643750011920929, "eval_episode/reward_rate": 0.008695652173913044}
{"step": 810056, "time": 25319.959322452545, "eval_episode/length": 119.0, "eval_episode/score": 0.628125011920929, "eval_episode/reward_rate": 0.008333333333333333}
{"step": 810056, "time": 25320.297799110413, "eval_episode/length": 137.0, "eval_episode/score": 0.5718749761581421, "eval_episode/reward_rate": 0.007246376811594203}
{"step": 810056, "time": 25321.724004983902, "eval_episode/length": 215.0, "eval_episode/score": 0.328125, "eval_episode/reward_rate": 0.004629629629629629}
{"step": 810056, "time": 25323.076197862625, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 810056, "time": 25323.084770679474, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 810056, "time": 25323.091552972794, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 810168, "time": 25326.44607949257, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 810288, "time": 25330.273583173752, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 810720, "time": 25343.261431455612, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 810720, "time": 25343.27177453041, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 810800, "time": 25345.785926818848, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 810928, "time": 25349.644705295563, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 811328, "time": 25362.17953157425, "episode/length": 257.0, "episode/score": 0.19687500596046448, "episode/reward_rate": 0.003875968992248062, "episode/intrinsic_return": 0.0}
{"step": 811424, "time": 25365.07214975357, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 811472, "time": 25366.531867027283, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 811480, "time": 25366.55890107155, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 811952, "time": 25381.105975151062, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 812112, "time": 25385.902425050735, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 812200, "time": 25388.31286907196, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 812376, "time": 25393.58426260948, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 812480, "time": 25396.94303870201, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 812536, "time": 25398.404746055603, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 812672, "time": 25402.718370437622, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 813000, "time": 25412.437125205994, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 813000, "time": 25412.444292783737, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 813032, "time": 25413.402405500412, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 813240, "time": 25419.65818619728, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 813272, "time": 25420.61854481697, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 813368, "time": 25423.492023944855, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 813488, "time": 25427.322009801865, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 813736, "time": 25434.56198334694, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 813808, "time": 25437.027764320374, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 813840, "time": 25437.99587392807, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 813896, "time": 25439.479875564575, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 813960, "time": 25441.40461039543, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 814168, "time": 25447.65755200386, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 814216, "time": 25449.12997698784, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 814248, "time": 25450.105694770813, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 814256, "time": 25450.577508211136, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 814424, "time": 25455.456119537354, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 814656, "time": 25462.608712673187, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 814984, "time": 25472.261648893356, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 815072, "time": 25475.146453857422, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 815192, "time": 25478.546208143234, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 815192, "time": 25478.55439066887, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 815584, "time": 25490.563014268875, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 815728, "time": 25494.927953243256, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 815792, "time": 25496.958324193954, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 815800, "time": 25496.987875699997, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 816088, "time": 25505.645200014114, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 816152, "time": 25507.59574532509, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 816224, "time": 25509.969514608383, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 816472, "time": 25517.216247797012, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 816816, "time": 25527.879012584686, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 816968, "time": 25532.2319355011, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 817072, "time": 25535.6034219265, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 817176, "time": 25538.496948480606, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 817272, "time": 25541.387620925903, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 817504, "time": 25548.595950603485, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 817600, "time": 25551.4935901165, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 817608, "time": 25551.521296977997, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 817872, "time": 25559.78911113739, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 817896, "time": 25560.306121349335, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 818272, "time": 25571.809363126755, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 818352, "time": 25574.224929094315, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 818464, "time": 25577.58992290497, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 818632, "time": 25582.432830810547, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 818696, "time": 25584.371161937714, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 818704, "time": 25584.837035894394, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 818848, "time": 25589.261466741562, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 818848, "time": 25589.269422769547, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 819160, "time": 25598.443040132523, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 819232, "time": 25601.289091825485, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 819264, "time": 25602.250326633453, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 819400, "time": 25606.13369512558, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 819480, "time": 25608.549894571304, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 819488, "time": 25609.018597841263, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 819504, "time": 25609.50422143936, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 819568, "time": 25611.42688369751, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 819816, "time": 25618.7404589653, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 820040, "time": 25626.67058491707, "eval_episode/length": 67.0, "eval_episode/score": 0.7906249761581421, "eval_episode/reward_rate": 0.014705882352941176}
{"step": 820040, "time": 25626.75120472908, "eval_episode/length": 71.0, "eval_episode/score": 0.778124988079071, "eval_episode/reward_rate": 0.013888888888888888}
{"step": 820040, "time": 25626.873886823654, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 820040, "time": 25627.342524528503, "eval_episode/length": 103.0, "eval_episode/score": 0.6781250238418579, "eval_episode/reward_rate": 0.009615384615384616}
{"step": 820040, "time": 25627.349057912827, "eval_episode/length": 103.0, "eval_episode/score": 0.6781250238418579, "eval_episode/reward_rate": 0.009615384615384616}
{"step": 820040, "time": 25627.408780813217, "eval_episode/length": 106.0, "eval_episode/score": 0.668749988079071, "eval_episode/reward_rate": 0.009345794392523364}
{"step": 820040, "time": 25627.450176239014, "eval_episode/length": 108.0, "eval_episode/score": 0.6625000238418579, "eval_episode/reward_rate": 0.009174311926605505}
{"step": 820040, "time": 25628.540429592133, "eval_episode/length": 167.0, "eval_episode/score": 0.4781250059604645, "eval_episode/reward_rate": 0.005952380952380952}
{"step": 820048, "time": 25629.008553266525, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 820168, "time": 25632.39569044113, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 820336, "time": 25637.661925792694, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 820448, "time": 25641.02285337448, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 820472, "time": 25641.529215335846, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 821072, "time": 25659.85231566429, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 821216, "time": 25664.15938949585, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 821304, "time": 25666.596037864685, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 821544, "time": 25673.775413751602, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 821576, "time": 25674.76319551468, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 821608, "time": 25675.820713996887, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 821800, "time": 25681.576937913895, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 821840, "time": 25683.0038254261, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 821864, "time": 25683.51212787628, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 822224, "time": 25694.546180725098, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 822648, "time": 25707.124240875244, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 822704, "time": 25709.035954475403, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 822904, "time": 25714.83346414566, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 823056, "time": 25719.623186826706, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 823448, "time": 25731.173505544662, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 823472, "time": 25732.133700847626, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 823616, "time": 25736.512881040573, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 823712, "time": 25739.40148639679, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 823920, "time": 25745.649528741837, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 824016, "time": 25748.551334142685, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 824024, "time": 25748.580203056335, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 824112, "time": 25751.454835176468, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 824176, "time": 25753.37316799164, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 824328, "time": 25757.71702694893, "episode/length": 209.0, "episode/score": 0.34687501192092896, "episode/reward_rate": 0.004761904761904762, "episode/intrinsic_return": 0.0}
{"step": 824592, "time": 25765.976422071457, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 824704, "time": 25769.343716859818, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 824872, "time": 25774.163656949997, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 824912, "time": 25775.60568666458, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 824992, "time": 25777.996285438538, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 825440, "time": 25791.440682411194, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 825656, "time": 25797.858667612076, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 825752, "time": 25800.75323009491, "episode/length": 228.0, "episode/score": 0.2874999940395355, "episode/reward_rate": 0.004366812227074236, "episode/intrinsic_return": 0.0}
{"step": 825760, "time": 25801.217968702316, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 825776, "time": 25801.70166993141, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 825872, "time": 25804.599678993225, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 826488, "time": 25822.878711223602, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 826600, "time": 25826.331270217896, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 826640, "time": 25827.75062584877, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 826664, "time": 25828.261998653412, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 826704, "time": 25829.699935674667, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 826904, "time": 25835.47907590866, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 827000, "time": 25838.376891613007, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 827016, "time": 25838.86419391632, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 827016, "time": 25838.870876550674, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 827128, "time": 25842.223419189453, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 827584, "time": 25856.742577791214, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 827624, "time": 25857.728941679, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 827712, "time": 25860.597959280014, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 827808, "time": 25863.50199365616, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 827848, "time": 25864.49155807495, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 828184, "time": 25874.57546710968, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 828296, "time": 25877.949207782745, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 828416, "time": 25881.74810194969, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 828488, "time": 25883.701370954514, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 828760, "time": 25891.98225569725, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 829328, "time": 25909.242228746414, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 829328, "time": 25909.250902414322, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 829496, "time": 25914.087758779526, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 829608, "time": 25917.55108308792, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 829728, "time": 25921.380657672882, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 829832, "time": 25924.280685186386, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 830024, "time": 25930.03119111061, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 830024, "time": 25930.592919111252, "eval_episode/length": 30.0, "eval_episode/score": 0.90625, "eval_episode/reward_rate": 0.03225806451612903}
{"step": 830024, "time": 25931.06672525406, "eval_episode/length": 56.0, "eval_episode/score": 0.824999988079071, "eval_episode/reward_rate": 0.017543859649122806}
{"step": 830024, "time": 25931.221217870712, "eval_episode/length": 64.0, "eval_episode/score": 0.800000011920929, "eval_episode/reward_rate": 0.015384615384615385}
{"step": 830024, "time": 25932.276580810547, "eval_episode/length": 122.0, "eval_episode/score": 0.6187499761581421, "eval_episode/reward_rate": 0.008130081300813009}
{"step": 830024, "time": 25932.338891267776, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 830024, "time": 25933.165606737137, "eval_episode/length": 168.0, "eval_episode/score": 0.4749999940395355, "eval_episode/reward_rate": 0.005917159763313609}
{"step": 830024, "time": 25933.232431411743, "eval_episode/length": 140.0, "eval_episode/score": 0.5625, "eval_episode/reward_rate": 0.0070921985815602835}
{"step": 830024, "time": 25933.41285467148, "eval_episode/length": 180.0, "eval_episode/score": 0.4375, "eval_episode/reward_rate": 0.0055248618784530384}
{"step": 830184, "time": 25938.22746014595, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 830424, "time": 25945.503777742386, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 830496, "time": 25947.866814136505, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 830536, "time": 25948.86200261116, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 830728, "time": 25954.59732079506, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 830800, "time": 25956.96265745163, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 831072, "time": 25965.115628242493, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 831240, "time": 25969.94372367859, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 831408, "time": 25975.304723262787, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 831680, "time": 25983.50856232643, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 831808, "time": 25987.36656832695, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 831984, "time": 25992.63092803955, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 832040, "time": 25994.086534500122, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 832088, "time": 25995.530585289, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 832616, "time": 26011.475628852844, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 832648, "time": 26012.462588071823, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 832808, "time": 26017.27625131607, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 832864, "time": 26019.167852163315, "episode/length": 202.0, "episode/score": 0.3687500059604645, "episode/reward_rate": 0.0049261083743842365, "episode/intrinsic_return": 0.0}
{"step": 832968, "time": 26022.089815616608, "episode/length": 270.0, "episode/score": 0.15625, "episode/reward_rate": 0.0036900369003690036, "episode/intrinsic_return": 0.0}
{"step": 833056, "time": 26024.965572595596, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 833112, "time": 26026.44622540474, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 833200, "time": 26029.302698373795, "episode/length": 17.0, "episode/score": 0.9468749761581421, "episode/reward_rate": 0.05555555555555555, "episode/intrinsic_return": 0.0}
{"step": 833248, "time": 26030.757817029953, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 833576, "time": 26040.448001861572, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 833616, "time": 26041.876730680466, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 833688, "time": 26043.8162419796, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 833896, "time": 26050.08017683029, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 834000, "time": 26053.401062726974, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 834024, "time": 26053.904313087463, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 834136, "time": 26057.274418115616, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 834248, "time": 26060.647261857986, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 834400, "time": 26065.55412197113, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 834456, "time": 26067.01595544815, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 834480, "time": 26067.964427232742, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 834640, "time": 26072.79606604576, "episode/length": 19.0, "episode/score": 0.940625011920929, "episode/reward_rate": 0.05, "episode/intrinsic_return": 0.0}
{"step": 834672, "time": 26073.782531023026, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 834688, "time": 26074.269419908524, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 835136, "time": 26087.75496697426, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 835280, "time": 26092.083624601364, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 835288, "time": 26092.112100601196, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 835384, "time": 26095.05452632904, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 835480, "time": 26098.016528844833, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 835592, "time": 26101.623044252396, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 835776, "time": 26107.648397922516, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 836072, "time": 26116.340057849884, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 836112, "time": 26117.791373968124, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 836240, "time": 26121.636889457703, "episode/length": 20.0, "episode/score": 0.9375, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.0}
{"step": 836328, "time": 26124.090187311172, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 836336, "time": 26124.554718732834, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 836448, "time": 26128.02942919731, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 836712, "time": 26135.743064403534, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 837256, "time": 26152.153568267822, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 837392, "time": 26156.58505630493, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 837448, "time": 26158.05114388466, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 837520, "time": 26160.428439855576, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 837816, "time": 26169.110360383987, "episode/length": 196.0, "episode/score": 0.38749998807907104, "episode/reward_rate": 0.005076142131979695, "episode/intrinsic_return": 0.0}
{"step": 837872, "time": 26171.030126810074, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 837904, "time": 26171.997237205505, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 838408, "time": 26187.021520853043, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 838496, "time": 26189.88486433029, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 838608, "time": 26193.253418922424, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 838640, "time": 26194.21266055107, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 838648, "time": 26194.24176955223, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 838672, "time": 26195.20094513893, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 838752, "time": 26197.594955682755, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 839072, "time": 26207.243795394897, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 839152, "time": 26209.648125886917, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 839224, "time": 26211.58747458458, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 839336, "time": 26215.001085996628, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 839528, "time": 26220.84233856201, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 839576, "time": 26222.29941534996, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 839721, "time": 26227.638296365738, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.623285929361979, "train/action_min": 0.0, "train/action_std": 1.9297740453598546, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.010495163984231505, "train/actor_opt_grad_steps": 51365.0, "train/actor_opt_loss": -12.73485302852065, "train/adv_mag": 1.0656258060651667, "train/adv_max": 0.31553084067269865, "train/adv_mean": 0.0014583199099102255, "train/adv_min": -1.0185312313192032, "train/adv_std": 0.03093129856621518, "train/cont_avg": 0.994595396752451, "train/cont_loss_mean": 0.018960003303957407, "train/cont_loss_std": 0.24224156848903672, "train/cont_neg_acc": 0.31868952735528056, "train/cont_neg_loss": 2.738353089436286, "train/cont_pos_acc": 0.999860409135912, "train/cont_pos_loss": 0.004018649973623527, "train/cont_pred": 0.9944731867780873, "train/cont_rate": 0.994595396752451, "train/dyn_loss_mean": 1.0000149981648314, "train/dyn_loss_std": 0.00022347772117463333, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.11505371939810906, "train/extr_critic_critic_opt_grad_steps": 51365.0, "train/extr_critic_critic_opt_loss": 11648.633678959864, "train/extr_critic_mag": 1.5467493487339394, "train/extr_critic_max": 1.5467493487339394, "train/extr_critic_mean": 1.4545103977708256, "train/extr_critic_min": 1.2491290908233792, "train/extr_critic_std": 0.02529720067247456, "train/extr_return_normed_mag": 1.0810309046623754, "train/extr_return_normed_max": 0.3290344540979348, "train/extr_return_normed_mean": 0.0486065601911761, "train/extr_return_normed_min": -1.0124994463780348, "train/extr_return_normed_std": 0.040904561559870545, "train/extr_return_rate": 0.9995293123464958, "train/extr_return_raw_mag": 1.736396635279936, "train/extr_return_raw_max": 1.736396635279936, "train/extr_return_raw_mean": 1.4559688229186862, "train/extr_return_raw_min": 0.39486273480396644, "train/extr_return_raw_std": 0.04090456150508687, "train/extr_reward_mag": 0.3239521676418828, "train/extr_reward_max": 0.3239521676418828, "train/extr_reward_mean": 0.002187362869210797, "train/extr_reward_min": 1.3498698963838465e-07, "train/extr_reward_std": 0.008448641126354536, "train/image_loss_mean": 0.09055783186911368, "train/image_loss_std": 0.10334427347954582, "train/model_loss_mean": 0.7243523846069971, "train/model_loss_std": 0.45914951722849817, "train/model_opt_grad_norm": 19.47822326304866, "train/model_opt_grad_steps": 51320.509803921566, "train/model_opt_loss": 3711.4806422813267, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5122.549019607844, "train/policy_entropy_mag": 1.3309847753421933, "train/policy_entropy_max": 1.3309847753421933, "train/policy_entropy_mean": 0.10263084941634945, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.1308461463845828, "train/policy_logprob_mag": 6.551080243260253, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.1024476756871331, "train/policy_logprob_min": -6.551080243260253, "train/policy_logprob_std": 0.6384902079315746, "train/policy_randomness_mag": 0.6839909115258385, "train/policy_randomness_max": 0.6839909115258385, "train/policy_randomness_mean": 0.052741825580596924, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.06724162175155737, "train/post_ent_mag": 39.6037867863973, "train/post_ent_max": 39.6037867863973, "train/post_ent_mean": 35.715093444375434, "train/post_ent_min": 33.455261286567236, "train/post_ent_std": 1.2170122622274886, "train/prior_ent_mag": 38.6122475231395, "train/prior_ent_max": 38.6122475231395, "train/prior_ent_mean": 34.60625731711294, "train/prior_ent_min": 31.209149641149185, "train/prior_ent_std": 1.2949248260142756, "train/rep_loss_mean": 1.0000149981648314, "train/rep_loss_std": 0.00022347772117463333, "train/reward_avg": 0.001917655797881832, "train/reward_loss_mean": 0.014825530036343444, "train/reward_loss_std": 0.21622399502894932, "train/reward_max_data": 0.7001378676470589, "train/reward_max_pred": 0.19724722820169785, "train/reward_neg_acc": 0.999731167274363, "train/reward_neg_loss": 0.0027365031419321895, "train/reward_pos_acc": 0.1295233888036393, "train/reward_pos_loss": 4.181644320805022, "train/reward_pred": 0.0015658892048568483, "train/reward_rate": 0.002900965073529412, "train_stats/mean_log_entropy": 0.08582464228244298, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.01011749729514122, "report/cont_loss_std": 0.1608940213918686, "report/cont_neg_acc": 0.3333333432674408, "report/cont_neg_loss": 2.4179844856262207, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0030424720607697964, "report/cont_pred": 0.9960074424743652, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.08335322141647339, "report/image_loss_std": 0.10037031769752502, "report/model_loss_mean": 0.6991159915924072, "report/model_loss_std": 0.2972770631313324, "report/post_ent_mag": 39.13528060913086, "report/post_ent_max": 39.13528060913086, "report/post_ent_mean": 35.01012420654297, "report/post_ent_min": 32.581932067871094, "report/post_ent_std": 1.2417253255844116, "report/prior_ent_mag": 37.644691467285156, "report/prior_ent_max": 37.644691467285156, "report/prior_ent_mean": 34.05074691772461, "report/prior_ent_min": 30.66419792175293, "report/prior_ent_std": 1.3267582654953003, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0006683349492959678, "report/reward_loss_mean": 0.0056452518329024315, "report/reward_loss_std": 0.13260702788829803, "report/reward_max_data": 0.684374988079071, "report/reward_max_pred": 0.03412806987762451, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0015035426476970315, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.242613792419434, "report/reward_pred": 0.0007898332551121712, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.022278599441051483, "eval/cont_loss_std": 0.4543149471282959, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 9.52910327911377, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0036742459051311016, "eval/cont_pred": 0.9964184165000916, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.18126501142978668, "eval/image_loss_std": 0.13262197375297546, "eval/model_loss_mean": 0.8053022623062134, "eval/model_loss_std": 0.4706730842590332, "eval/post_ent_mag": 39.13849639892578, "eval/post_ent_max": 39.13849639892578, "eval/post_ent_mean": 35.08913803100586, "eval/post_ent_min": 32.79582595825195, "eval/post_ent_std": 1.2805815935134888, "eval/prior_ent_mag": 37.947975158691406, "eval/prior_ent_max": 37.947975158691406, "eval/prior_ent_mean": 34.27045440673828, "eval/prior_ent_min": 30.28692626953125, "eval/prior_ent_std": 1.4174246788024902, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.001758610364049673, "eval/reward_loss_std": 0.006995147559791803, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0388484001159668, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.001758610364049673, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0009067325154319406, "eval/reward_rate": 0.0, "replay/size": 839217.0, "replay/inserts": 32592.0, "replay/samples": 32592.0, "replay/insert_wait_avg": 1.334162336620093e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.213561015440427e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5104.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1033866099055658e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0728836059570312e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2858030796051, "timer/env.step_count": 4074.0, "timer/env.step_total": 38.635170221328735, "timer/env.step_frac": 0.03862413132564879, "timer/env.step_avg": 0.00948335056979105, "timer/env.step_min": 0.007586479187011719, "timer/env.step_max": 0.0391542911529541, "timer/replay._sample_count": 32592.0, "timer/replay._sample_total": 16.300803661346436, "timer/replay._sample_frac": 0.016296146172584618, "timer/replay._sample_avg": 0.0005001473877438155, "timer/replay._sample_min": 0.0003578662872314453, "timer/replay._sample_max": 0.010954618453979492, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4712.0, "timer/agent.policy_total": 48.82863163948059, "timer/agent.policy_frac": 0.04881468025353419, "timer/agent.policy_avg": 0.010362612826714896, "timer/agent.policy_min": 0.008539915084838867, "timer/agent.policy_max": 0.0763847827911377, "timer/dataset_train_count": 2037.0, "timer/dataset_train_total": 0.2205655574798584, "timer/dataset_train_frac": 0.00022050253717567286, "timer/dataset_train_avg": 0.00010827960602840373, "timer/dataset_train_min": 9.274482727050781e-05, "timer/dataset_train_max": 0.0006248950958251953, "timer/agent.train_count": 2037.0, "timer/agent.train_total": 899.3962361812592, "timer/agent.train_frac": 0.8991392594119254, "timer/agent.train_avg": 0.44152981648564515, "timer/agent.train_min": 0.4324660301208496, "timer/agent.train_max": 0.6463868618011475, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48191070556640625, "timer/agent.report_frac": 0.00048177301335551863, "timer/agent.report_avg": 0.24095535278320312, "timer/agent.report_min": 0.23411941528320312, "timer/agent.report_max": 0.24779129028320312, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.5762786865234375e-05, "timer/dataset_eval_frac": 3.575256867100441e-08, "timer/dataset_eval_avg": 3.5762786865234375e-05, "timer/dataset_eval_min": 3.5762786865234375e-05, "timer/dataset_eval_max": 3.5762786865234375e-05, "fps": 32.58215420643116}
{"step": 839752, "time": 26228.317876577377, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 839928, "time": 26233.696356773376, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 840008, "time": 26238.029518842697, "eval_episode/length": 102.0, "eval_episode/score": 0.6812499761581421, "eval_episode/reward_rate": 0.009708737864077669}
{"step": 840008, "time": 26238.089569091797, "eval_episode/length": 105.0, "eval_episode/score": 0.671875, "eval_episode/reward_rate": 0.009433962264150943}
{"step": 840008, "time": 26238.357776641846, "eval_episode/length": 120.0, "eval_episode/score": 0.625, "eval_episode/reward_rate": 0.008264462809917356}
{"step": 840008, "time": 26238.383844852448, "eval_episode/length": 121.0, "eval_episode/score": 0.621874988079071, "eval_episode/reward_rate": 0.00819672131147541}
{"step": 840008, "time": 26238.726645708084, "eval_episode/length": 140.0, "eval_episode/score": 0.5625, "eval_episode/reward_rate": 0.0070921985815602835}
{"step": 840008, "time": 26239.05973815918, "eval_episode/length": 38.0, "eval_episode/score": 0.8812500238418579, "eval_episode/reward_rate": 0.02564102564102564}
{"step": 840008, "time": 26239.29960155487, "eval_episode/length": 172.0, "eval_episode/score": 0.4625000059604645, "eval_episode/reward_rate": 0.005780346820809248}
{"step": 840008, "time": 26241.200121164322, "eval_episode/length": 85.0, "eval_episode/score": 0.734375, "eval_episode/reward_rate": 0.011627906976744186}
{"step": 840136, "time": 26245.088203191757, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 840208, "time": 26247.503252983093, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 840320, "time": 26250.898671627045, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 840536, "time": 26257.174159526825, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 840560, "time": 26258.11822128296, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 840584, "time": 26258.624058008194, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 840632, "time": 26260.083384752274, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 840720, "time": 26262.951545476913, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 840928, "time": 26269.241290330887, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 841152, "time": 26276.10866546631, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 841416, "time": 26283.83713579178, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 841784, "time": 26294.86790037155, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 841840, "time": 26296.76743030548, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 841888, "time": 26298.233780622482, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 842120, "time": 26305.024297952652, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 842168, "time": 26306.50462770462, "episode/length": 203.0, "episode/score": 0.3656249940395355, "episode/reward_rate": 0.004901960784313725, "episode/intrinsic_return": 0.0}
{"step": 842208, "time": 26307.940470695496, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 842216, "time": 26307.968574523926, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 842392, "time": 26313.244225025177, "episode/length": 208.0, "episode/score": 0.3499999940395355, "episode/reward_rate": 0.004784688995215311, "episode/intrinsic_return": 0.0}
{"step": 842432, "time": 26314.65949201584, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 842728, "time": 26323.35330271721, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 842872, "time": 26327.695425510406, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 842872, "time": 26327.702562093735, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 842944, "time": 26330.09254360199, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 842968, "time": 26330.59874677658, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 843016, "time": 26332.063438892365, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 843232, "time": 26338.8882625103, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 843584, "time": 26349.451635599136, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 843640, "time": 26350.944856882095, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 843656, "time": 26351.436225414276, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 843952, "time": 26361.060890197754, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 844040, "time": 26363.475796461105, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 844056, "time": 26363.96225810051, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 844056, "time": 26363.970000982285, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 844720, "time": 26384.218980789185, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 844744, "time": 26384.729249715805, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 844808, "time": 26386.661918401718, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 845064, "time": 26394.347139120102, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 845096, "time": 26395.415877580643, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 845248, "time": 26400.20867729187, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 845256, "time": 26400.237832784653, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 845280, "time": 26401.181908130646, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 845360, "time": 26403.59286260605, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 846016, "time": 26423.285400629044, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 846160, "time": 26427.711063861847, "episode/length": 264.0, "episode/score": 0.17499999701976776, "episode/reward_rate": 0.0037735849056603774, "episode/intrinsic_return": 0.0}
{"step": 846168, "time": 26427.739533424377, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 846264, "time": 26430.6327085495, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 846520, "time": 26438.331509828568, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 846656, "time": 26442.61726999283, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 846832, "time": 26447.922523736954, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 846904, "time": 26449.869295358658, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 847048, "time": 26454.19780755043, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 847120, "time": 26456.698140382767, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 847160, "time": 26457.705294132233, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 847408, "time": 26465.34384059906, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 847448, "time": 26466.336418390274, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 847560, "time": 26469.728406190872, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 847784, "time": 26476.451166152954, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 848016, "time": 26483.659790992737, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 848032, "time": 26484.145789146423, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 848080, "time": 26485.686871767044, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 848488, "time": 26497.726333856583, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 848576, "time": 26500.582767486572, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 848816, "time": 26507.79750442505, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 848864, "time": 26509.243364572525, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 849064, "time": 26515.047117471695, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 849360, "time": 26524.25688433647, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 849384, "time": 26524.774743795395, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 849432, "time": 26526.270948410034, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 849520, "time": 26529.17232465744, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 849760, "time": 26536.382159471512, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 850040, "time": 26544.5655939579, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 850064, "time": 26545.565794467926, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 850096, "time": 26547.021364927292, "eval_episode/length": 26.0, "eval_episode/score": 0.918749988079071, "eval_episode/reward_rate": 0.037037037037037035}
{"step": 850096, "time": 26547.44705748558, "eval_episode/length": 50.0, "eval_episode/score": 0.84375, "eval_episode/reward_rate": 0.0196078431372549}
{"step": 850096, "time": 26547.911627054214, "eval_episode/length": 76.0, "eval_episode/score": 0.762499988079071, "eval_episode/reward_rate": 0.012987012987012988}
{"step": 850096, "time": 26548.097056388855, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 850096, "time": 26548.472423791885, "eval_episode/length": 56.0, "eval_episode/score": 0.824999988079071, "eval_episode/reward_rate": 0.017543859649122806}
{"step": 850096, "time": 26548.49890756607, "eval_episode/length": 108.0, "eval_episode/score": 0.6625000238418579, "eval_episode/reward_rate": 0.009174311926605505}
{"step": 850096, "time": 26548.67671084404, "eval_episode/length": 117.0, "eval_episode/score": 0.6343749761581421, "eval_episode/reward_rate": 0.00847457627118644}
{"step": 850096, "time": 26548.865539312363, "eval_episode/length": 127.0, "eval_episode/score": 0.6031249761581421, "eval_episode/reward_rate": 0.0078125}
{"step": 850320, "time": 26555.641778707504, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 850584, "time": 26563.479228019714, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 850624, "time": 26564.923823595047, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 850800, "time": 26570.209030628204, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 851024, "time": 26577.004284381866, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 851128, "time": 26579.910593509674, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 851280, "time": 26584.705487012863, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 851400, "time": 26588.100066900253, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 851648, "time": 26595.77602982521, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 851744, "time": 26598.65664768219, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 851912, "time": 26603.48987364769, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 851984, "time": 26606.492416143417, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 852176, "time": 26612.24754500389, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 852352, "time": 26617.539249658585, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 852472, "time": 26620.927185058594, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 852632, "time": 26625.727690458298, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 852776, "time": 26630.044896125793, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 852856, "time": 26632.434898376465, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 853096, "time": 26639.715987205505, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 853144, "time": 26641.160249471664, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 853328, "time": 26646.898936986923, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 853368, "time": 26647.88669013977, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 853712, "time": 26658.43738770485, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 853760, "time": 26659.875593423843, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 853968, "time": 26666.254219055176, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 854112, "time": 26670.574407815933, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 854752, "time": 26689.7350461483, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 854848, "time": 26692.613133907318, "episode/length": 212.0, "episode/score": 0.3375000059604645, "episode/reward_rate": 0.004694835680751174, "episode/intrinsic_return": 0.0}
{"step": 854944, "time": 26696.435040712357, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 854992, "time": 26697.910725593567, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 855088, "time": 26700.784320116043, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 855152, "time": 26702.724915981293, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 855192, "time": 26703.705520391464, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 855504, "time": 26713.286581993103, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 855680, "time": 26718.58501458168, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 855960, "time": 26726.870759248734, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 856008, "time": 26728.31281352043, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 856096, "time": 26731.176372289658, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 856104, "time": 26731.20462703705, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 856192, "time": 26734.07371902466, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 856560, "time": 26745.082087993622, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 856752, "time": 26750.85011601448, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 856928, "time": 26756.238338708878, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 857160, "time": 26762.99388885498, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 857160, "time": 26763.001452684402, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 857456, "time": 26772.094136953354, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 857464, "time": 26772.12303709984, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 857536, "time": 26774.492594242096, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 857584, "time": 26775.95537853241, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 858152, "time": 26792.972768068314, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 858264, "time": 26796.34140563011, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 858320, "time": 26798.243644475937, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 858504, "time": 26803.5500164032, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 858552, "time": 26805.012124300003, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 858728, "time": 26810.289308071136, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 858872, "time": 26814.626232624054, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 859152, "time": 26823.418462514877, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 859192, "time": 26824.39902830124, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 859400, "time": 26830.6206240654, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 859576, "time": 26835.895667552948, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 859848, "time": 26844.04882645607, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 860024, "time": 26849.43716454506, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 860080, "time": 26853.03515648842, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 860080, "time": 26853.426607370377, "eval_episode/length": 114.0, "eval_episode/score": 0.643750011920929, "eval_episode/reward_rate": 0.008695652173913044}
{"step": 860080, "time": 26853.620986700058, "eval_episode/length": 124.0, "eval_episode/score": 0.612500011920929, "eval_episode/reward_rate": 0.008}
{"step": 860080, "time": 26853.772002458572, "eval_episode/length": 132.0, "eval_episode/score": 0.5874999761581421, "eval_episode/reward_rate": 0.007518796992481203}
{"step": 860080, "time": 26854.253638744354, "eval_episode/length": 158.0, "eval_episode/score": 0.5062500238418579, "eval_episode/reward_rate": 0.006289308176100629}
{"step": 860080, "time": 26855.154331445694, "eval_episode/length": 114.0, "eval_episode/score": 0.643750011920929, "eval_episode/reward_rate": 0.008695652173913044}
{"step": 860080, "time": 26856.109067201614, "eval_episode/length": 51.0, "eval_episode/score": 0.840624988079071, "eval_episode/reward_rate": 0.019230769230769232}
{"step": 860080, "time": 26856.152651786804, "eval_episode/length": 146.0, "eval_episode/score": 0.543749988079071, "eval_episode/reward_rate": 0.006802721088435374}
{"step": 860216, "time": 26860.49527978897, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 860240, "time": 26861.452517986298, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 860472, "time": 26868.21505856514, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 860576, "time": 26871.552929878235, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 860712, "time": 26875.53828883171, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 860768, "time": 26877.463449954987, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 860864, "time": 26880.342777729034, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 860984, "time": 26883.73386645317, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 861040, "time": 26885.63528060913, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 861160, "time": 26889.023819684982, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 861280, "time": 26892.83688735962, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 861320, "time": 26893.819680452347, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 861584, "time": 26901.9682366848, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 861664, "time": 26904.359793663025, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 861784, "time": 26907.833961486816, "episode/length": 14.0, "episode/score": 0.956250011920929, "episode/reward_rate": 0.06666666666666667, "episode/intrinsic_return": 0.0}
{"step": 862048, "time": 26915.978922128677, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 862080, "time": 26916.94264769554, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 862184, "time": 26919.837530851364, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 862232, "time": 26921.29046201706, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 862264, "time": 26922.249295711517, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 862320, "time": 26924.1736433506, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 862720, "time": 26936.284054756165, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 862800, "time": 26938.683966636658, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 862808, "time": 26938.713010072708, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 863216, "time": 26951.176800251007, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 863216, "time": 26951.18472456932, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 863296, "time": 26953.574197769165, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 863400, "time": 26956.47603201866, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 863496, "time": 26959.36027431488, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 863632, "time": 26963.652224063873, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 863736, "time": 26966.604276180267, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 863832, "time": 26969.492715120316, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 863848, "time": 26969.977610111237, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 864088, "time": 26977.163599729538, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 864144, "time": 26979.085545539856, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 864200, "time": 26980.54328584671, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 864456, "time": 26988.26946902275, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 864512, "time": 26990.175689697266, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 864568, "time": 26991.640050649643, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 864752, "time": 26997.50057053566, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 864872, "time": 27000.887412309647, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 865312, "time": 27014.292715072632, "episode/length": 238.0, "episode/score": 0.2562499940395355, "episode/reward_rate": 0.0041841004184100415, "episode/intrinsic_return": 0.0}
{"step": 865352, "time": 27015.27293419838, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 865368, "time": 27015.75880050659, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 865528, "time": 27020.572444677353, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 865672, "time": 27024.932429790497, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 865760, "time": 27027.846220970154, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 865912, "time": 27032.169180631638, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 866040, "time": 27036.016880512238, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 866072, "time": 27036.980937719345, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 866264, "time": 27042.747444152832, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 866368, "time": 27046.107726573944, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 866400, "time": 27047.07066297531, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 866464, "time": 27048.986480474472, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 866504, "time": 27049.96375465393, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 866768, "time": 27058.19294476509, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 866992, "time": 27064.92232275009, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 867112, "time": 27068.302577972412, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 867360, "time": 27075.99368906021, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 867528, "time": 27080.817095041275, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 868072, "time": 27097.21762251854, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 868224, "time": 27102.01002907753, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 868352, "time": 27106.02039718628, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 868576, "time": 27113.078253746033, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 868640, "time": 27115.06578350067, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 868680, "time": 27116.111721515656, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 868784, "time": 27119.482962608337, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 869080, "time": 27128.14922428131, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 869112, "time": 27129.11676621437, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 869200, "time": 27131.98207092285, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 869304, "time": 27134.912370681763, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 869672, "time": 27146.054414987564, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 869712, "time": 27147.49862074852, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 870016, "time": 27156.611059188843, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 870064, "time": 27158.90107679367, "eval_episode/length": 45.0, "eval_episode/score": 0.859375, "eval_episode/reward_rate": 0.021739130434782608}
{"step": 870064, "time": 27159.13285470009, "eval_episode/length": 57.0, "eval_episode/score": 0.8218749761581421, "eval_episode/reward_rate": 0.017241379310344827}
{"step": 870064, "time": 27159.5211789608, "eval_episode/length": 78.0, "eval_episode/score": 0.7562500238418579, "eval_episode/reward_rate": 0.012658227848101266}
{"step": 870064, "time": 27159.90023446083, "eval_episode/length": 99.0, "eval_episode/score": 0.690625011920929, "eval_episode/reward_rate": 0.01}
{"step": 870064, "time": 27160.124034404755, "eval_episode/length": 111.0, "eval_episode/score": 0.653124988079071, "eval_episode/reward_rate": 0.008928571428571428}
{"step": 870064, "time": 27160.130481243134, "eval_episode/length": 111.0, "eval_episode/score": 0.653124988079071, "eval_episode/reward_rate": 0.008928571428571428}
{"step": 870064, "time": 27160.29159259796, "eval_episode/length": 119.0, "eval_episode/score": 0.628125011920929, "eval_episode/reward_rate": 0.008333333333333333}
{"step": 870064, "time": 27160.653018712997, "eval_episode/length": 139.0, "eval_episode/score": 0.565625011920929, "eval_episode/reward_rate": 0.007142857142857143}
{"step": 870088, "time": 27161.162420988083, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 870296, "time": 27167.389269828796, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 870528, "time": 27174.5617415905, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 870880, "time": 27185.205070734024, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 870888, "time": 27185.23448252678, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 870920, "time": 27186.1924803257, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 870952, "time": 27187.155579805374, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 871096, "time": 27191.47558069229, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 871128, "time": 27192.43739414215, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 871208, "time": 27194.83821296692, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 871424, "time": 27201.545213460922, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 871424, "time": 27201.553816318512, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 871704, "time": 27209.863511562347, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 871800, "time": 27212.75188922882, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 871832, "time": 27213.708834409714, "episode/length": 15.0, "episode/score": 0.953125, "episode/reward_rate": 0.0625, "episode/intrinsic_return": 0.0}
{"step": 871848, "time": 27214.19424843788, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 871896, "time": 27215.63338446617, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 871944, "time": 27217.069046735764, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 872265, "time": 27227.713147878647, "train_stats/mean_log_entropy": 0.08483839580000228, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.6569330552045036, "train/action_min": 0.0, "train/action_std": 1.946679065624873, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.01107598010190379, "train/actor_opt_grad_steps": 53405.0, "train/actor_opt_loss": -14.965055929679497, "train/adv_mag": 1.0592884695997424, "train/adv_max": 0.2748470516765819, "train/adv_mean": 0.0001586678418069217, "train/adv_min": -1.024482630631503, "train/adv_std": 0.03621246005116286, "train/cont_avg": 0.9947916666666666, "train/cont_loss_mean": 0.018583597818517362, "train/cont_loss_std": 0.2399224872089119, "train/cont_neg_acc": 0.279466237069345, "train/cont_neg_loss": 2.8126975006946617, "train/cont_pos_acc": 0.999855568595961, "train/cont_pos_loss": 0.003979370927018132, "train/cont_pred": 0.9946649965702319, "train/cont_rate": 0.9947916666666666, "train/dyn_loss_mean": 1.0000021387549007, "train/dyn_loss_std": 6.271490921932912e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.15158539191892773, "train/extr_critic_critic_opt_grad_steps": 53405.0, "train/extr_critic_critic_opt_loss": 11442.711124195772, "train/extr_critic_mag": 1.5556649624132644, "train/extr_critic_max": 1.5556649624132644, "train/extr_critic_mean": 1.4622919746473724, "train/extr_critic_min": 1.2814899250572802, "train/extr_critic_std": 0.024464259691098156, "train/extr_return_normed_mag": 1.0624387164910634, "train/extr_return_normed_max": 0.29392297887334634, "train/extr_return_normed_mean": 0.04489696226721885, "train/extr_return_normed_min": -1.0048967599868774, "train/extr_return_normed_std": 0.04537119264440501, "train/extr_return_rate": 0.9993783571556503, "train/extr_return_raw_mag": 1.7114765620699115, "train/extr_return_raw_max": 1.7114765620699115, "train/extr_return_raw_mean": 1.4624506182530348, "train/extr_return_raw_min": 0.4126568232096878, "train/extr_return_raw_std": 0.04537119262614379, "train/extr_reward_mag": 0.29205817919151456, "train/extr_reward_max": 0.29205817919151456, "train/extr_reward_mean": 0.0023052877493718567, "train/extr_reward_min": 1.0693774503820083e-07, "train/extr_reward_std": 0.009515390319375358, "train/image_loss_mean": 0.08963320143155608, "train/image_loss_std": 0.10345392794731785, "train/model_loss_mean": 0.723401817913149, "train/model_loss_std": 0.46868288769003225, "train/model_opt_grad_norm": 19.02198274734572, "train/model_opt_grad_steps": 53358.61274509804, "train/model_opt_loss": 3973.6866861979165, "train/model_opt_model_opt_grad_overflow": 0.004901960784313725, "train/model_opt_model_opt_grad_scale": 5465.686274509804, "train/policy_entropy_mag": 1.2842366438285977, "train/policy_entropy_max": 1.2842366438285977, "train/policy_entropy_mean": 0.10141621548317227, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.128591232367006, "train/policy_logprob_mag": 6.551080271309497, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.10134783208224118, "train/policy_logprob_min": -6.551080271309497, "train/policy_logprob_std": 0.6392147318989623, "train/policy_randomness_mag": 0.659967121832511, "train/policy_randomness_max": 0.659967121832511, "train/policy_randomness_mean": 0.052117626858400365, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.06608282493463918, "train/post_ent_mag": 37.9533203349394, "train/post_ent_max": 37.9533203349394, "train/post_ent_mean": 33.863928710713104, "train/post_ent_min": 31.49138504851098, "train/post_ent_std": 1.2858507685801561, "train/prior_ent_mag": 36.63244090360754, "train/prior_ent_max": 36.63244090360754, "train/prior_ent_mean": 32.8727271416608, "train/prior_ent_min": 29.6652650272145, "train/prior_ent_std": 1.2518021855868546, "train/rep_loss_mean": 1.0000021387549007, "train/rep_loss_std": 6.271490921932912e-05, "train/reward_avg": 0.0019405439886802068, "train/reward_loss_mean": 0.015183710846958645, "train/reward_loss_std": 0.22738754137546993, "train/reward_max_data": 0.7506587013748347, "train/reward_max_pred": 0.16872304677963257, "train/reward_neg_acc": 0.9997598151950275, "train/reward_neg_loss": 0.002751273298510533, "train/reward_pos_acc": 0.08845177754230306, "train/reward_pos_loss": 4.290321955826077, "train/reward_pred": 0.001533608441355218, "train/reward_rate": 0.0028961780024509805, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.019333744421601295, "report/cont_loss_std": 0.2349785715341568, "report/cont_neg_acc": 0.2857142984867096, "report/cont_neg_loss": 2.2372937202453613, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.00406755181029439, "report/cont_pred": 0.9935792684555054, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.08376193046569824, "report/image_loss_std": 0.10022346675395966, "report/model_loss_mean": 0.7179630994796753, "report/model_loss_std": 0.46086591482162476, "report/post_ent_mag": 36.92652893066406, "report/post_ent_max": 36.92652893066406, "report/post_ent_mean": 32.96449279785156, "report/post_ent_min": 30.597993850708008, "report/post_ent_std": 1.2561674118041992, "report/prior_ent_mag": 36.33275604248047, "report/prior_ent_max": 36.33275604248047, "report/prior_ent_mean": 32.86543273925781, "report/prior_ent_min": 30.08074188232422, "report/prior_ent_std": 1.251401662826538, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.001934814383275807, "report/reward_loss_mean": 0.014867415651679039, "report/reward_loss_std": 0.22537466883659363, "report/reward_max_data": 0.753125011920929, "report/reward_max_pred": 0.03688383102416992, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00267590768635273, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.164044380187988, "report/reward_pred": 0.0014143474400043488, "report/reward_rate": 0.0029296875, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.021455183625221252, "eval/cont_loss_std": 0.25362661480903625, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 3.3985202312469482, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.004884697496891022, "eval/cont_pred": 0.9947804808616638, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.17105865478515625, "eval/image_loss_std": 0.14564105868339539, "eval/model_loss_mean": 0.808933436870575, "eval/model_loss_std": 0.5058779120445251, "eval/post_ent_mag": 36.92652893066406, "eval/post_ent_max": 36.92652893066406, "eval/post_ent_mean": 33.05237579345703, "eval/post_ent_min": 30.50440216064453, "eval/post_ent_std": 1.3234317302703857, "eval/prior_ent_mag": 36.33275604248047, "eval/prior_ent_max": 36.33275604248047, "eval/prior_ent_mean": 33.0107536315918, "eval/prior_ent_min": 29.620325088500977, "eval/prior_ent_std": 1.2911869287490845, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.001983642578125, "eval/reward_loss_mean": 0.016419542953372, "eval/reward_loss_std": 0.2425667941570282, "eval/reward_max_data": 0.75, "eval/reward_max_pred": 0.11403441429138184, "eval/reward_neg_acc": 0.999020516872406, "eval/reward_neg_loss": 0.0033319962676614523, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 4.470548152923584, "eval/reward_pred": 0.0017247648211196065, "eval/reward_rate": 0.0029296875, "replay/size": 871761.0, "replay/inserts": 32544.0, "replay/samples": 32544.0, "replay/insert_wait_avg": 1.3445257671697536e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.101132767038711e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 6208.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.094659271928453e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.5367431640625e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0539400577545, "timer/env.step_count": 4068.0, "timer/env.step_total": 38.619988679885864, "timer/env.step_frac": 0.03861790562782594, "timer/env.step_avg": 0.009493605870178433, "timer/env.step_min": 0.007482051849365234, "timer/env.step_max": 0.04873251914978027, "timer/replay._sample_count": 32544.0, "timer/replay._sample_total": 16.091457843780518, "timer/replay._sample_frac": 0.01609058991643112, "timer/replay._sample_avg": 0.0004944523673728036, "timer/replay._sample_min": 0.00040221214294433594, "timer/replay._sample_max": 0.024882078170776367, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4844.0, "timer/agent.policy_total": 50.2458713054657, "timer/agent.policy_frac": 0.05024316118644953, "timer/agent.policy_avg": 0.01037280580211926, "timer/agent.policy_min": 0.008640527725219727, "timer/agent.policy_max": 0.08677387237548828, "timer/dataset_train_count": 2034.0, "timer/dataset_train_total": 0.2199864387512207, "timer/dataset_train_frac": 0.00021997457331003183, "timer/dataset_train_avg": 0.00010815459132311735, "timer/dataset_train_min": 9.298324584960938e-05, "timer/dataset_train_max": 0.0010280609130859375, "timer/agent.train_count": 2034.0, "timer/agent.train_total": 897.3634340763092, "timer/agent.train_frac": 0.8973150328516132, "timer/agent.train_avg": 0.44118162933938504, "timer/agent.train_min": 0.43228626251220703, "timer/agent.train_max": 0.680715799331665, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47678184509277344, "timer/agent.report_frac": 0.000476756128839649, "timer/agent.report_avg": 0.23839092254638672, "timer/agent.report_min": 0.23145341873168945, "timer/agent.report_max": 0.24532842636108398, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.504753112792969e-05, "timer/dataset_eval_frac": 3.504564076404283e-08, "timer/dataset_eval_avg": 3.504753112792969e-05, "timer/dataset_eval_min": 3.504753112792969e-05, "timer/dataset_eval_max": 3.504753112792969e-05, "fps": 32.54160857460638}
{"step": 872296, "time": 27228.392186641693, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 872424, "time": 27232.365310430527, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 872544, "time": 27236.33428645134, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 872616, "time": 27238.308990955353, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 872672, "time": 27240.21963119507, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 872984, "time": 27249.435542583466, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 873040, "time": 27251.352466583252, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 873112, "time": 27253.328936576843, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 873120, "time": 27253.79875063896, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 873200, "time": 27256.21927022934, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 873400, "time": 27262.099762678146, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 873536, "time": 27266.501433610916, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 873704, "time": 27271.373928308487, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 873744, "time": 27272.81814146042, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 873856, "time": 27276.18554162979, "episode/length": 18.0, "episode/score": 0.9437500238418579, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.0}
{"step": 873920, "time": 27278.12563586235, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 873928, "time": 27278.154069185257, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 874008, "time": 27280.559251070023, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 874032, "time": 27281.523018598557, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 874104, "time": 27283.46968436241, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 874120, "time": 27283.958570480347, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 874256, "time": 27288.277189970016, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 874296, "time": 27289.260022878647, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 874368, "time": 27291.65571784973, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 874576, "time": 27298.007855176926, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 874728, "time": 27302.384870290756, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 874840, "time": 27305.782428979874, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 875008, "time": 27311.08511519432, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 875064, "time": 27312.554477214813, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 875248, "time": 27318.325578689575, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 875392, "time": 27322.684631347656, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 875464, "time": 27324.627532720566, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 875584, "time": 27328.553203344345, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 875632, "time": 27330.009523630142, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 875680, "time": 27331.462284564972, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 875768, "time": 27333.890554189682, "episode/length": 16.0, "episode/score": 0.949999988079071, "episode/reward_rate": 0.058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 875856, "time": 27336.791516065598, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 875984, "time": 27340.656601190567, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 876240, "time": 27348.349589586258, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 876320, "time": 27350.772448778152, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 876344, "time": 27351.284538269043, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 876496, "time": 27356.209316253662, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 876520, "time": 27356.717930316925, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 876704, "time": 27362.908564805984, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 876824, "time": 27366.320776939392, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 876960, "time": 27370.644109249115, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 877216, "time": 27378.366409540176, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 877472, "time": 27386.217360019684, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 877552, "time": 27388.65532231331, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 877576, "time": 27389.172571897507, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 877608, "time": 27390.162873744965, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 877632, "time": 27391.128183603287, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 877632, "time": 27391.135973215103, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 877752, "time": 27394.601694583893, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 877784, "time": 27395.5872092247, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 877872, "time": 27398.529816627502, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 878184, "time": 27407.74679684639, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 878376, "time": 27413.557678937912, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 878560, "time": 27419.41547226906, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 878704, "time": 27423.780966758728, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 878808, "time": 27426.695345640182, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 879096, "time": 27435.39258003235, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 879208, "time": 27438.7815618515, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 879312, "time": 27442.15762448311, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 879488, "time": 27447.55011034012, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 879744, "time": 27455.285330295563, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 879864, "time": 27458.69133400917, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 879888, "time": 27459.63927912712, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 879944, "time": 27461.10101556778, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 880000, "time": 27463.031062841415, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 880048, "time": 27464.98993253708, "eval_episode/length": 26.0, "eval_episode/score": 0.918749988079071, "eval_episode/reward_rate": 0.037037037037037035}
{"step": 880048, "time": 27465.38468503952, "eval_episode/length": 47.0, "eval_episode/score": 0.8531249761581421, "eval_episode/reward_rate": 0.020833333333333332}
{"step": 880048, "time": 27466.129282474518, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 880048, "time": 27466.191937685013, "eval_episode/length": 89.0, "eval_episode/score": 0.721875011920929, "eval_episode/reward_rate": 0.011111111111111112}
{"step": 880048, "time": 27466.707441329956, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 880048, "time": 27467.9006626606, "eval_episode/length": 89.0, "eval_episode/score": 0.721875011920929, "eval_episode/reward_rate": 0.011111111111111112}
{"step": 880048, "time": 27468.08151936531, "eval_episode/length": 161.0, "eval_episode/score": 0.49687498807907104, "eval_episode/reward_rate": 0.006172839506172839}
{"step": 880048, "time": 27469.910194158554, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 880048, "time": 27469.917571544647, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 880048, "time": 27469.924088954926, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 880048, "time": 27469.930778741837, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 880104, "time": 27471.396219730377, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 880352, "time": 27479.198764562607, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 880512, "time": 27484.021072387695, "episode/length": 225.0, "episode/score": 0.296875, "episode/reward_rate": 0.004424778761061947, "episode/intrinsic_return": 0.0}
{"step": 880696, "time": 27489.345947504044, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 880712, "time": 27489.832183361053, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 880792, "time": 27492.257615327835, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 880824, "time": 27493.228392601013, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 880848, "time": 27494.173181295395, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 881024, "time": 27499.494101047516, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 881152, "time": 27503.368196249008, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 881480, "time": 27513.24569439888, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 881504, "time": 27514.20839214325, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 881504, "time": 27514.216589212418, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 881632, "time": 27518.122572422028, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 882056, "time": 27530.696494817734, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 882144, "time": 27533.575133562088, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 882200, "time": 27535.111160755157, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 882208, "time": 27535.621369600296, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 882576, "time": 27546.772862434387, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 882696, "time": 27550.199185848236, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 882736, "time": 27551.62289762497, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 883016, "time": 27559.90217399597, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 883024, "time": 27560.371898412704, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 883032, "time": 27560.399154424667, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 883104, "time": 27562.795570850372, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 883160, "time": 27564.28639817238, "episode/length": 6.0, "episode/score": 0.981249988079071, "episode/reward_rate": 0.14285714285714285, "episode/intrinsic_return": 0.0}
{"step": 883176, "time": 27564.77682042122, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 883464, "time": 27573.60878586769, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 883616, "time": 27578.441433429718, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 883744, "time": 27582.306365966797, "episode/length": 15.0, "episode/score": 0.953125, "episode/reward_rate": 0.0625, "episode/intrinsic_return": 0.0}
{"step": 883824, "time": 27584.745735645294, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 884032, "time": 27591.065186977386, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 884144, "time": 27594.493903636932, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 884456, "time": 27603.852720975876, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 884800, "time": 27615.03595519066, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 884888, "time": 27617.493873357773, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 885224, "time": 27627.79127407074, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 885328, "time": 27631.205667972565, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 885464, "time": 27635.117960691452, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 885488, "time": 27636.075041770935, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 885776, "time": 27644.812923192978, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 885936, "time": 27649.659739494324, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 886136, "time": 27655.55861234665, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 886456, "time": 27665.228981733322, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 886600, "time": 27669.571602344513, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 886648, "time": 27671.021756649017, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 886760, "time": 27674.424996614456, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 886768, "time": 27674.89353108406, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 886824, "time": 27676.360295772552, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 886936, "time": 27679.75489115715, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 886984, "time": 27681.20200943947, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 887032, "time": 27682.6721739769, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 887048, "time": 27683.16298699379, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 887184, "time": 27687.566434144974, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 887264, "time": 27690.003789186478, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 887264, "time": 27690.011590242386, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 887312, "time": 27691.494628429413, "episode/length": 260.0, "episode/score": 0.1875, "episode/reward_rate": 0.0038314176245210726, "episode/intrinsic_return": 0.0}
{"step": 887648, "time": 27701.68406200409, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 887776, "time": 27705.567096948624, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 887840, "time": 27707.52743244171, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 887848, "time": 27707.556084394455, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 887944, "time": 27710.453261613846, "episode/length": 11.0, "episode/score": 0.965624988079071, "episode/reward_rate": 0.08333333333333333, "episode/intrinsic_return": 0.0}
{"step": 887992, "time": 27711.924601316452, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 888096, "time": 27715.36074900627, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 888112, "time": 27715.867877960205, "episode/length": 20.0, "episode/score": 0.9375, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.0}
{"step": 888600, "time": 27730.355805635452, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 888696, "time": 27733.274133205414, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 888768, "time": 27735.737261533737, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 888904, "time": 27739.668560743332, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 889104, "time": 27746.04228758812, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 889296, "time": 27751.841301441193, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 889496, "time": 27757.666568279266, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 889528, "time": 27758.63238477707, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 889776, "time": 27766.38136935234, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 889856, "time": 27768.800050258636, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 889960, "time": 27771.73787713051, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 890032, "time": 27775.449209928513, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 890032, "time": 27775.489988088608, "eval_episode/length": 64.0, "eval_episode/score": 0.800000011920929, "eval_episode/reward_rate": 0.015384615384615385}
{"step": 890032, "time": 27775.67072892189, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 890032, "time": 27775.763111114502, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 890032, "time": 27775.960238695145, "eval_episode/length": 90.0, "eval_episode/score": 0.71875, "eval_episode/reward_rate": 0.01098901098901099}
{"step": 890032, "time": 27776.469900608063, "eval_episode/length": 43.0, "eval_episode/score": 0.8656250238418579, "eval_episode/reward_rate": 0.022727272727272728}
{"step": 890032, "time": 27776.63026380539, "eval_episode/length": 126.0, "eval_episode/score": 0.606249988079071, "eval_episode/reward_rate": 0.007874015748031496}
{"step": 890032, "time": 27776.79071855545, "eval_episode/length": 54.0, "eval_episode/score": 0.831250011920929, "eval_episode/reward_rate": 0.01818181818181818}
{"step": 890032, "time": 27776.79818367958, "eval_episode/length": 71.0, "eval_episode/score": 0.778124988079071, "eval_episode/reward_rate": 0.013888888888888888}
{"step": 890248, "time": 27783.12464570999, "episode/length": 205.0, "episode/score": 0.359375, "episode/reward_rate": 0.0048543689320388345, "episode/intrinsic_return": 0.0}
{"step": 890304, "time": 27785.035967111588, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 890400, "time": 27787.94427061081, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 890592, "time": 27793.70251107216, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 890616, "time": 27794.210424900055, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 890832, "time": 27800.96240711212, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 890968, "time": 27804.837340831757, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 891216, "time": 27812.61548113823, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 891272, "time": 27814.082360982895, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 891336, "time": 27816.031746149063, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 891456, "time": 27819.867005109787, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 891800, "time": 27830.025537967682, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 891944, "time": 27834.352726221085, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 892112, "time": 27839.749588489532, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 892144, "time": 27840.710850954056, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 892304, "time": 27845.529417276382, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 892336, "time": 27846.49818301201, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 892696, "time": 27857.161516666412, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 892776, "time": 27859.609976768494, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 892896, "time": 27863.44908595085, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 892928, "time": 27864.58474254608, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 893016, "time": 27867.535271167755, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 893144, "time": 27871.42813205719, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 893152, "time": 27871.897064447403, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 893480, "time": 27881.638790130615, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 893496, "time": 27882.131686925888, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 893776, "time": 27890.823800563812, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 893872, "time": 27893.741013765335, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 894256, "time": 27905.495373487473, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 894336, "time": 27907.91730237007, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 894448, "time": 27911.32331752777, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 894576, "time": 27915.21418428421, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 895128, "time": 27931.759790420532, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 895208, "time": 27934.19070649147, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 895328, "time": 27938.0535633564, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 895328, "time": 27938.069422006607, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 895624, "time": 27946.792866945267, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 896024, "time": 27958.97388625145, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 896088, "time": 27960.909570217133, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 896088, "time": 27960.916560173035, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 896240, "time": 27965.732396125793, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 896568, "time": 27975.405069112778, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 896648, "time": 27977.83997654915, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 896760, "time": 27981.22441625595, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 896936, "time": 27986.585675239563, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 896952, "time": 27987.07138133049, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 897104, "time": 27991.91046500206, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 897640, "time": 28008.12523126602, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 897712, "time": 28010.524664402008, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 897744, "time": 28011.484644651413, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 897744, "time": 28011.491219758987, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 898336, "time": 28029.40600013733, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 898368, "time": 28030.38641357422, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 898480, "time": 28033.75585103035, "episode/length": 238.0, "episode/score": 0.2562499940395355, "episode/reward_rate": 0.0041841004184100415, "episode/intrinsic_return": 0.0}
{"step": 898488, "time": 28033.78302192688, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 898848, "time": 28044.896446943283, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 899136, "time": 28053.706218242645, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 899248, "time": 28057.102911949158, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 899344, "time": 28060.017018795013, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 899408, "time": 28061.94541120529, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 899416, "time": 28061.97419500351, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 899768, "time": 28072.589971780777, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 899952, "time": 28078.472996234894, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 900000, "time": 28079.9157910347, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 900016, "time": 28082.02848958969, "eval_episode/length": 54.0, "eval_episode/score": 0.831250011920929, "eval_episode/reward_rate": 0.01818181818181818}
{"step": 900016, "time": 28082.483078718185, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 900016, "time": 28082.97507238388, "eval_episode/length": 107.0, "eval_episode/score": 0.6656249761581421, "eval_episode/reward_rate": 0.009259259259259259}
{"step": 900016, "time": 28083.238938093185, "eval_episode/length": 120.0, "eval_episode/score": 0.625, "eval_episode/reward_rate": 0.008264462809917356}
{"step": 900016, "time": 28083.498681783676, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 900016, "time": 28083.543165683746, "eval_episode/length": 136.0, "eval_episode/score": 0.574999988079071, "eval_episode/reward_rate": 0.0072992700729927005}
{"step": 900016, "time": 28083.777314424515, "eval_episode/length": 28.0, "eval_episode/score": 0.9125000238418579, "eval_episode/reward_rate": 0.034482758620689655}
{"step": 900016, "time": 28084.169617652893, "eval_episode/length": 91.0, "eval_episode/score": 0.715624988079071, "eval_episode/reward_rate": 0.010869565217391304}
{"step": 900360, "time": 28094.321472883224, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 900464, "time": 28097.694625377655, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 900680, "time": 28103.97106075287, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 900688, "time": 28104.44081711769, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 900872, "time": 28109.831022500992, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 900920, "time": 28111.28621697426, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 900952, "time": 28112.245899915695, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 901168, "time": 28119.416702270508, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 901232, "time": 28121.3505153656, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 901336, "time": 28124.234524011612, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 901432, "time": 28127.128277778625, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 901456, "time": 28128.06522154808, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 901536, "time": 28130.453253030777, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 901704, "time": 28135.37731385231, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 901728, "time": 28136.345614671707, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 901824, "time": 28139.22692155838, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 901832, "time": 28139.25395989418, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 901896, "time": 28141.188125371933, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 902080, "time": 28146.939720869064, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 902104, "time": 28147.44787669182, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 902112, "time": 28147.91656446457, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 902512, "time": 28159.99179315567, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 902632, "time": 28163.386612176895, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 902696, "time": 28165.41708302498, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 902696, "time": 28165.423852682114, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 902768, "time": 28167.80441594124, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 902824, "time": 28169.278468370438, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 902904, "time": 28171.72349500656, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 902944, "time": 28173.178033590317, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 903160, "time": 28179.504858016968, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 903336, "time": 28184.830251455307, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 903440, "time": 28188.178273439407, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 903552, "time": 28191.566093683243, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 903600, "time": 28193.016775131226, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 903768, "time": 28197.96873855591, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 903776, "time": 28198.43692088127, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 904200, "time": 28211.03097963333, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 904328, "time": 28214.896290779114, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 904368, "time": 28216.31783723831, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 904392, "time": 28216.82588648796, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 904408, "time": 28217.314217090607, "episode/length": 204.0, "episode/score": 0.36250001192092896, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.0}
{"step": 904424, "time": 28217.803821325302, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 904552, "time": 28221.65718984604, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 904656, "time": 28225.039657115936, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 904672, "time": 28225.581901311874, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 904729, "time": 28228.03962469101, "train_stats/mean_log_entropy": 0.07831015661358834, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.5835190574721536, "train/action_min": 0.0, "train/action_std": 1.9064426988658338, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00902328948665521, "train/actor_opt_grad_steps": 55435.0, "train/actor_opt_loss": -14.596451042902352, "train/adv_mag": 1.0115758127505237, "train/adv_max": 0.26321932702961537, "train/adv_mean": 0.0007715680673961945, "train/adv_min": -0.9746528102619814, "train/adv_std": 0.02946876995910955, "train/cont_avg": 0.994561223700495, "train/cont_loss_mean": 0.019489508054200744, "train/cont_loss_std": 0.24532040612458592, "train/cont_neg_acc": 0.28792940621352314, "train/cont_neg_loss": 2.826141903834853, "train/cont_pos_acc": 0.9998882412910461, "train/cont_pos_loss": 0.0041352296201973265, "train/cont_pred": 0.9944669984944976, "train/cont_rate": 0.994561223700495, "train/dyn_loss_mean": 1.0000025665405954, "train/dyn_loss_std": 8.20847611129745e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.11231611598061748, "train/extr_critic_critic_opt_grad_steps": 55435.0, "train/extr_critic_critic_opt_loss": 9850.782376431003, "train/extr_critic_mag": 1.5792050338027501, "train/extr_critic_max": 1.5792050338027501, "train/extr_critic_mean": 1.4884964145056092, "train/extr_critic_min": 1.2619449549382276, "train/extr_critic_std": 0.025772392685239266, "train/extr_return_normed_mag": 1.0302558317042814, "train/extr_return_normed_max": 0.25899722670564557, "train/extr_return_normed_mean": 0.04829731225819871, "train/extr_return_normed_min": -0.9709950968770698, "train/extr_return_normed_std": 0.040472469477001394, "train/extr_return_rate": 0.9995069217563856, "train/extr_return_raw_mag": 1.6999677897679923, "train/extr_return_raw_max": 1.6999677897679923, "train/extr_return_raw_mean": 1.4892679500107717, "train/extr_return_raw_min": 0.469975466185277, "train/extr_return_raw_std": 0.04047246948622241, "train/extr_reward_mag": 0.252278208732605, "train/extr_reward_max": 0.252278208732605, "train/extr_reward_mean": 0.002290840994331543, "train/extr_reward_min": 9.265276465085474e-08, "train/extr_reward_std": 0.008238110550688488, "train/image_loss_mean": 0.08969521839724909, "train/image_loss_std": 0.10349885208329351, "train/model_loss_mean": 0.7249202238451137, "train/model_loss_std": 0.47359124154295074, "train/model_opt_grad_norm": 18.133057306308558, "train/model_opt_grad_steps": 55386.88118811881, "train/model_opt_loss": 4091.537244740099, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5643.564356435643, "train/policy_entropy_mag": 1.2964995863414046, "train/policy_entropy_max": 1.2964995863414046, "train/policy_entropy_mean": 0.09373495524915137, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.11623825955361423, "train/policy_logprob_mag": 6.551080245782833, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09360764013363583, "train/policy_logprob_min": -6.551080245782833, "train/policy_logprob_std": 0.6311078803374035, "train/policy_randomness_mag": 0.6662690267704501, "train/policy_randomness_max": 0.6662690267704501, "train/policy_randomness_mean": 0.048170239636951155, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.059734652538110715, "train/post_ent_mag": 37.91688275101161, "train/post_ent_max": 37.91688275101161, "train/post_ent_mean": 33.019538020143415, "train/post_ent_min": 30.236265654611117, "train/post_ent_std": 1.5362845370084932, "train/prior_ent_mag": 37.327614850336964, "train/prior_ent_max": 37.327614850336964, "train/prior_ent_mean": 32.86869261524465, "train/prior_ent_min": 29.1557884877271, "train/prior_ent_std": 1.4956722914582432, "train/rep_loss_mean": 1.0000025665405954, "train/rep_loss_std": 8.20847611129745e-05, "train/reward_avg": 0.0020612206803934446, "train/reward_loss_mean": 0.01573393501959151, "train/reward_loss_std": 0.2270219066401593, "train/reward_max_data": 0.7297029695888557, "train/reward_max_pred": 0.18922698910873714, "train/reward_neg_acc": 0.9997769744679479, "train/reward_neg_loss": 0.0028457682744581435, "train/reward_pos_acc": 0.10969122173264623, "train/reward_pos_loss": 4.189348405537506, "train/reward_pred": 0.0016251204582622809, "train/reward_rate": 0.003094059405940594, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.018628640100359917, "report/cont_loss_std": 0.2604410946369171, "report/cont_neg_acc": 0.3333333432674408, "report/cont_neg_loss": 2.591275930404663, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.003465688321739435, "report/cont_pred": 0.9945970773696899, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.0910043716430664, "report/image_loss_std": 0.09452544897794724, "report/model_loss_mean": 0.7256041169166565, "report/model_loss_std": 0.5131762027740479, "report/post_ent_mag": 37.25545120239258, "report/post_ent_max": 37.25545120239258, "report/post_ent_mean": 32.524085998535156, "report/post_ent_min": 29.913633346557617, "report/post_ent_std": 1.548209547996521, "report/prior_ent_mag": 36.23478317260742, "report/prior_ent_max": 36.23478317260742, "report/prior_ent_mean": 31.629396438598633, "report/prior_ent_min": 28.100549697875977, "report/prior_ent_std": 1.4311015605926514, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0027618408203125, "report/reward_loss_mean": 0.015971114858984947, "report/reward_loss_std": 0.26367801427841187, "report/reward_max_data": 0.8218749761581421, "report/reward_max_pred": 0.4172389507293701, "report/reward_neg_acc": 0.9999999403953552, "report/reward_neg_loss": 0.002134196227416396, "report/reward_pos_acc": 0.5, "report/reward_pos_loss": 3.5443854331970215, "report/reward_pred": 0.0017730456311255693, "report/reward_rate": 0.00390625, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.03204887732863426, "eval/cont_loss_std": 0.5640663504600525, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 9.525016784667969, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.004155729431658983, "eval/cont_pred": 0.996043860912323, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.19504694640636444, "eval/image_loss_std": 0.14146308600902557, "eval/model_loss_mean": 0.8345915675163269, "eval/model_loss_std": 0.6413344740867615, "eval/post_ent_mag": 37.255706787109375, "eval/post_ent_max": 37.255706787109375, "eval/post_ent_mean": 32.38798522949219, "eval/post_ent_min": 29.746049880981445, "eval/post_ent_std": 1.5132136344909668, "eval/prior_ent_mag": 36.07548522949219, "eval/prior_ent_max": 36.07548522949219, "eval/prior_ent_mean": 31.4444580078125, "eval/prior_ent_min": 27.913253784179688, "eval/prior_ent_std": 1.4931517839431763, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0005096435779705644, "eval/reward_loss_mean": 0.007495712488889694, "eval/reward_loss_std": 0.16835902631282806, "eval/reward_max_data": 0.5218750238418579, "eval/reward_max_pred": 0.04365730285644531, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0022382137831300497, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.385916709899902, "eval/reward_pred": 0.0011776548344641924, "eval/reward_rate": 0.0009765625, "replay/size": 904225.0, "replay/inserts": 32464.0, "replay/samples": 32464.0, "replay/insert_wait_avg": 1.3459075431391311e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.037740694236849e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4768.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1212373739921006e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.387731552124023e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3136808872223, "timer/env.step_count": 4058.0, "timer/env.step_total": 38.664053201675415, "timer/env.step_frac": 0.03865192883034706, "timer/env.step_avg": 0.009527859339989012, "timer/env.step_min": 0.007579803466796875, "timer/env.step_max": 0.04765820503234863, "timer/replay._sample_count": 32464.0, "timer/replay._sample_total": 16.107348442077637, "timer/replay._sample_frac": 0.01610229745912434, "timer/replay._sample_avg": 0.0004961603142581825, "timer/replay._sample_min": 0.0003790855407714844, "timer/replay._sample_max": 0.01102590560913086, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4654.0, "timer/agent.policy_total": 48.790287256240845, "timer/agent.policy_frac": 0.04877498747489546, "timer/agent.policy_avg": 0.010483516814834733, "timer/agent.policy_min": 0.008128643035888672, "timer/agent.policy_max": 0.08849763870239258, "timer/dataset_train_count": 2029.0, "timer/dataset_train_total": 0.22123408317565918, "timer/dataset_train_frac": 0.00022116470803382088, "timer/dataset_train_avg": 0.00010903601930786555, "timer/dataset_train_min": 9.512901306152344e-05, "timer/dataset_train_max": 0.0010781288146972656, "timer/agent.train_count": 2029.0, "timer/agent.train_total": 901.2069716453552, "timer/agent.train_frac": 0.9009243688900016, "timer/agent.train_avg": 0.44416312057434953, "timer/agent.train_min": 0.4335215091705322, "timer/agent.train_max": 0.7930622100830078, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4785451889038086, "timer/agent.report_frac": 0.00047839512549640006, "timer/agent.report_avg": 0.2392725944519043, "timer/agent.report_min": 0.2321031093597412, "timer/agent.report_max": 0.24644207954406738, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.24249267578125e-05, "timer/dataset_eval_frac": 3.241475886749185e-08, "timer/dataset_eval_avg": 3.24249267578125e-05, "timer/dataset_eval_min": 3.24249267578125e-05, "timer/dataset_eval_max": 3.24249267578125e-05, "fps": 32.453291453117124}
{"step": 904816, "time": 28230.685388565063, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 905144, "time": 28240.377362966537, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 905672, "time": 28256.40267586708, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 905728, "time": 28258.34090256691, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 905744, "time": 28258.832486629486, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 905776, "time": 28259.807458877563, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 905912, "time": 28263.701479434967, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 905944, "time": 28264.668359041214, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 906072, "time": 28268.54513812065, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 906416, "time": 28279.16294145584, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 906640, "time": 28286.007999897003, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 906640, "time": 28286.01660323143, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 906648, "time": 28286.044424533844, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 906680, "time": 28287.033738851547, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 906992, "time": 28296.67323732376, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 907032, "time": 28297.663985729218, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 907272, "time": 28304.88910675049, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 907704, "time": 28318.00373673439, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 907720, "time": 28318.48872089386, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 907840, "time": 28322.317932605743, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 908152, "time": 28331.486394166946, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 908224, "time": 28333.879456996918, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 908304, "time": 28336.296311855316, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 908632, "time": 28346.053632497787, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 908680, "time": 28347.50333404541, "episode/length": 210.0, "episode/score": 0.34375, "episode/reward_rate": 0.004739336492890996, "episode/intrinsic_return": 0.0}
{"step": 908864, "time": 28353.272459745407, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 908952, "time": 28355.736056804657, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 908992, "time": 28357.181627511978, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 909096, "time": 28360.134041070938, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 909232, "time": 28364.489774942398, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 909344, "time": 28368.360416650772, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 909552, "time": 28374.657331943512, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 909624, "time": 28376.713794231415, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 909680, "time": 28378.610283851624, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 909792, "time": 28381.97416830063, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 909832, "time": 28382.963438510895, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 909904, "time": 28385.35555911064, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 909928, "time": 28385.86213707924, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 910000, "time": 28389.236211061478, "eval_episode/length": 53.0, "eval_episode/score": 0.8343750238418579, "eval_episode/reward_rate": 0.018518518518518517}
{"step": 910000, "time": 28389.523720264435, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 910000, "time": 28390.06435251236, "eval_episode/length": 99.0, "eval_episode/score": 0.690625011920929, "eval_episode/reward_rate": 0.01}
{"step": 910000, "time": 28390.410452127457, "eval_episode/length": 118.0, "eval_episode/score": 0.6312500238418579, "eval_episode/reward_rate": 0.008403361344537815}
{"step": 910000, "time": 28390.721664905548, "eval_episode/length": 16.0, "eval_episode/score": 0.949999988079071, "eval_episode/reward_rate": 0.058823529411764705}
{"step": 910000, "time": 28391.2501475811, "eval_episode/length": 163.0, "eval_episode/score": 0.4906249940395355, "eval_episode/reward_rate": 0.006097560975609756}
{"step": 910000, "time": 28391.770579576492, "eval_episode/length": 192.0, "eval_episode/score": 0.4000000059604645, "eval_episode/reward_rate": 0.0051813471502590676}
{"step": 910000, "time": 28391.79447698593, "eval_episode/length": 93.0, "eval_episode/score": 0.7093750238418579, "eval_episode/reward_rate": 0.010638297872340425}
{"step": 910264, "time": 28399.5790848732, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 910288, "time": 28400.534487962723, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 910408, "time": 28403.955411195755, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 910656, "time": 28411.751706838608, "episode/length": 212.0, "episode/score": 0.3375000059604645, "episode/reward_rate": 0.004694835680751174, "episode/intrinsic_return": 0.0}
{"step": 910864, "time": 28418.001274824142, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 910880, "time": 28418.490062475204, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 911144, "time": 28426.227669000626, "episode/length": 182.0, "episode/score": 0.4312500059604645, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.0}
{"step": 911256, "time": 28429.614726305008, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 911448, "time": 28435.517476320267, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 911784, "time": 28445.707364797592, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 911864, "time": 28448.135049819946, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 911976, "time": 28451.551098823547, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 911992, "time": 28452.04224705696, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 912104, "time": 28455.420619010925, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 912384, "time": 28464.138027906418, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 912576, "time": 28470.077175855637, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 912584, "time": 28470.105759859085, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 912816, "time": 28477.35816717148, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 912872, "time": 28478.826097011566, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 913072, "time": 28485.116770744324, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 913080, "time": 28485.144807577133, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 913104, "time": 28486.089272260666, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 913200, "time": 28488.976526260376, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 913232, "time": 28489.963626861572, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 913600, "time": 28501.09308195114, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 913752, "time": 28505.455523729324, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 913880, "time": 28509.321021318436, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 913880, "time": 28509.328502893448, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 914096, "time": 28516.101442575455, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 914408, "time": 28525.407901525497, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 914424, "time": 28525.896637678146, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 914440, "time": 28526.38578557968, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 914560, "time": 28530.234934806824, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 914832, "time": 28538.48929476738, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 914904, "time": 28540.43944978714, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 915248, "time": 28551.04356098175, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 915512, "time": 28558.883168935776, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 915544, "time": 28559.848904132843, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 915672, "time": 28563.68091416359, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 915744, "time": 28566.055282354355, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 916024, "time": 28574.242455482483, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 916096, "time": 28576.63338661194, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 916280, "time": 28581.992956876755, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 916288, "time": 28582.460537433624, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 916592, "time": 28591.799810647964, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 916736, "time": 28596.138941049576, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 916888, "time": 28600.51405262947, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 916936, "time": 28601.975031852722, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 917024, "time": 28604.848120212555, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 917064, "time": 28606.990877866745, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 917064, "time": 28606.999002695084, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 917120, "time": 28608.92008781433, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 917144, "time": 28609.428289413452, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 917608, "time": 28623.965041399002, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 917768, "time": 28628.768488168716, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 917824, "time": 28630.66369700432, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 918032, "time": 28636.914570331573, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 918304, "time": 28645.134283065796, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 918448, "time": 28649.45546722412, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 918592, "time": 28653.784398794174, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 918720, "time": 28657.635030031204, "episode/length": 15.0, "episode/score": 0.953125, "episode/reward_rate": 0.0625, "episode/intrinsic_return": 0.0}
{"step": 918728, "time": 28657.662905931473, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 918920, "time": 28663.434167146683, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 918952, "time": 28664.42249751091, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 919136, "time": 28670.210059404373, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 919200, "time": 28672.1516456604, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 919344, "time": 28676.592210769653, "episode/length": 284.0, "episode/score": 0.11249999701976776, "episode/reward_rate": 0.0035087719298245615, "episode/intrinsic_return": 0.0}
{"step": 919392, "time": 28678.046719312668, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 919432, "time": 28679.03909945488, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 919608, "time": 28684.346103429794, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 919944, "time": 28694.40170264244, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 919976, "time": 28695.384595394135, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 920032, "time": 28697.277985334396, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 920056, "time": 28697.784029483795, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 920088, "time": 28700.07302427292, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 920088, "time": 28700.347125053406, "eval_episode/length": 88.0, "eval_episode/score": 0.7250000238418579, "eval_episode/reward_rate": 0.011235955056179775}
{"step": 920088, "time": 28701.352377414703, "eval_episode/length": 55.0, "eval_episode/score": 0.828125, "eval_episode/reward_rate": 0.017857142857142856}
{"step": 920088, "time": 28703.03875541687, "eval_episode/length": 93.0, "eval_episode/score": 0.7093750238418579, "eval_episode/reward_rate": 0.010638297872340425}
{"step": 920088, "time": 28703.43936395645, "eval_episode/length": 186.0, "eval_episode/score": 0.41874998807907104, "eval_episode/reward_rate": 0.0053475935828877}
{"step": 920088, "time": 28704.919256210327, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 920088, "time": 28704.926748275757, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 920088, "time": 28704.948917627335, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 920088, "time": 28704.96083188057, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 920088, "time": 28704.967072486877, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 920088, "time": 28704.997883558273, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 920208, "time": 28708.88891172409, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 920288, "time": 28711.321147203445, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 920496, "time": 28717.627009868622, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 920536, "time": 28718.61081647873, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 920624, "time": 28721.503761291504, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 920896, "time": 28729.76869726181, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 921168, "time": 28738.18057703972, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 921168, "time": 28738.188040971756, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 921608, "time": 28751.26350092888, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 921640, "time": 28752.232806444168, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 921656, "time": 28752.720925569534, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 921920, "time": 28760.925056934357, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 922256, "time": 28771.141659736633, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 922384, "time": 28775.025852680206, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 922728, "time": 28785.242013931274, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 922840, "time": 28788.647941589355, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 922936, "time": 28791.550417661667, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 923168, "time": 28798.916843175888, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 923208, "time": 28799.909739732742, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 923464, "time": 28807.640130758286, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 923480, "time": 28808.14628648758, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 923560, "time": 28810.543004512787, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 923760, "time": 28816.796180725098, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 923984, "time": 28823.543374061584, "episode/length": 199.0, "episode/score": 0.37812501192092896, "episode/reward_rate": 0.005, "episode/intrinsic_return": 0.0}
{"step": 924024, "time": 28824.538907766342, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 924496, "time": 28839.02605676651, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 924568, "time": 28840.977632761, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 924728, "time": 28845.82093834877, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 925040, "time": 28855.58681535721, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 925216, "time": 28860.923977851868, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 925248, "time": 28861.912151813507, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 925496, "time": 28869.187721967697, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 925520, "time": 28870.148223400116, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 925560, "time": 28871.161238908768, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 925624, "time": 28873.10118842125, "episode/length": 199.0, "episode/score": 0.37812501192092896, "episode/reward_rate": 0.005, "episode/intrinsic_return": 0.0}
{"step": 925664, "time": 28874.532915115356, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 925952, "time": 28883.72620153427, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 926072, "time": 28887.249116659164, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 926104, "time": 28888.207263231277, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 926128, "time": 28889.15028333664, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 926144, "time": 28889.63913846016, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 926880, "time": 28911.755942583084, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 926936, "time": 28913.23732829094, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 926944, "time": 28913.710163116455, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 927040, "time": 28916.79399037361, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 927104, "time": 28918.72171998024, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 927208, "time": 28921.64314031601, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 927560, "time": 28932.225463867188, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 927600, "time": 28933.652849197388, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 927616, "time": 28934.139258384705, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 927984, "time": 28945.354219675064, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 928112, "time": 28949.22187447548, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 928392, "time": 28957.425894737244, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 928416, "time": 28958.374032258987, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 928464, "time": 28959.832693576813, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 928464, "time": 28959.84023809433, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 928872, "time": 28971.85205769539, "episode/length": 220.0, "episode/score": 0.3125, "episode/reward_rate": 0.004524886877828055, "episode/intrinsic_return": 0.0}
{"step": 929120, "time": 28979.64302611351, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 929168, "time": 28981.0926258564, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 929352, "time": 28986.424446821213, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 929352, "time": 28986.433177232742, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 929488, "time": 28990.747594833374, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 929520, "time": 28991.715099334717, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 929608, "time": 28994.153386831284, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 929848, "time": 29001.373012304306, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 929880, "time": 29002.358577013016, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 929904, "time": 29003.308210611343, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 930048, "time": 29007.751076221466, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 930072, "time": 29008.48117876053, "eval_episode/length": 11.0, "eval_episode/score": 0.965624988079071, "eval_episode/reward_rate": 0.08333333333333333}
{"step": 930072, "time": 29008.916021823883, "eval_episode/length": 35.0, "eval_episode/score": 0.890625, "eval_episode/reward_rate": 0.027777777777777776}
{"step": 930072, "time": 29009.23209810257, "eval_episode/length": 52.0, "eval_episode/score": 0.8374999761581421, "eval_episode/reward_rate": 0.018867924528301886}
{"step": 930072, "time": 29009.678698539734, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 930072, "time": 29009.91444993019, "eval_episode/length": 90.0, "eval_episode/score": 0.71875, "eval_episode/reward_rate": 0.01098901098901099}
{"step": 930072, "time": 29010.067116498947, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 930072, "time": 29010.381194353104, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 930072, "time": 29010.473991155624, "eval_episode/length": 108.0, "eval_episode/score": 0.6625000238418579, "eval_episode/reward_rate": 0.009174311926605505}
{"step": 930296, "time": 29017.2374727726, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 930496, "time": 29023.468327999115, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 930664, "time": 29028.324931383133, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 930968, "time": 29037.592826604843, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 931024, "time": 29039.526463508606, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 931056, "time": 29040.50608611107, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 931080, "time": 29041.024822235107, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 931416, "time": 29051.16990017891, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 931432, "time": 29051.655483961105, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 931568, "time": 29055.967965841293, "episode/length": 16.0, "episode/score": 0.949999988079071, "episode/reward_rate": 0.058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 931752, "time": 29061.33906173706, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 931856, "time": 29064.702236890793, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 932072, "time": 29071.117653131485, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 932360, "time": 29079.788360118866, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 932608, "time": 29087.494824886322, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 932760, "time": 29091.875913143158, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 932952, "time": 29097.78666973114, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 932976, "time": 29098.73248076439, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 933200, "time": 29105.474705457687, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 933304, "time": 29108.383593797684, "episode/length": 216.0, "episode/score": 0.32499998807907104, "episode/reward_rate": 0.004608294930875576, "episode/intrinsic_return": 0.0}
{"step": 933392, "time": 29111.282836198807, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 933712, "time": 29120.934031009674, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 933728, "time": 29121.424085378647, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 933832, "time": 29124.321110248566, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 933880, "time": 29125.866591215134, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 933960, "time": 29128.77663707733, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 934056, "time": 29131.677393198013, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 934064, "time": 29132.145638227463, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 934520, "time": 29145.642919063568, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 934728, "time": 29151.897432804108, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 934840, "time": 29155.373683929443, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 934872, "time": 29156.34013581276, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 934928, "time": 29158.252812862396, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 935264, "time": 29168.384509325027, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 935528, "time": 29176.133813619614, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 935664, "time": 29180.467015743256, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 935688, "time": 29180.97783613205, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 936024, "time": 29191.216125249863, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 936256, "time": 29198.393825292587, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 936256, "time": 29198.400936841965, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 936272, "time": 29198.905743837357, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 936416, "time": 29203.222008943558, "episode/length": 17.0, "episode/score": 0.9468749761581421, "episode/reward_rate": 0.05555555555555555, "episode/intrinsic_return": 0.0}
{"step": 936472, "time": 29204.710117816925, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 936824, "time": 29215.50519013405, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 936832, "time": 29215.973326206207, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 936856, "time": 29216.484454393387, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 937160, "time": 29225.66822743416, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 937184, "time": 29226.617789268494, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 937209, "time": 29228.12149310112, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.6217242461707206, "train/action_min": 0.0, "train/action_std": 1.9289162164838443, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.010064015267049812, "train/actor_opt_grad_steps": 57460.0, "train/actor_opt_loss": -14.842837023617598, "train/adv_mag": 1.0245490212158617, "train/adv_max": 0.29820580846570394, "train/adv_mean": -3.571401705324255e-05, "train/adv_min": -0.9830210041530026, "train/adv_std": 0.029583968777264574, "train/cont_avg": 0.9943955895935961, "train/cont_loss_mean": 0.02095536521539606, "train/cont_loss_std": 0.25696788930100173, "train/cont_neg_acc": 0.2556716050640703, "train/cont_neg_loss": 2.9250525955834514, "train/cont_pos_acc": 0.9998693877253039, "train/cont_pos_loss": 0.004365233799071037, "train/cont_pred": 0.9943889811121184, "train/cont_rate": 0.9943955895935961, "train/dyn_loss_mean": 1.0000009836234482, "train/dyn_loss_std": 3.1209133451877924e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.11372651782786024, "train/extr_critic_critic_opt_grad_steps": 57460.0, "train/extr_critic_critic_opt_loss": 8942.194636603293, "train/extr_critic_mag": 1.5921949353711358, "train/extr_critic_max": 1.5921949353711358, "train/extr_critic_mean": 1.5014452059280696, "train/extr_critic_min": 1.2107765175438867, "train/extr_critic_std": 0.025203932572174542, "train/extr_return_normed_mag": 1.0415258783425017, "train/extr_return_normed_max": 0.2617973600115095, "train/extr_return_normed_mean": 0.046816058934028515, "train/extr_return_normed_min": -0.9868154807631018, "train/extr_return_normed_std": 0.039921452433531505, "train/extr_return_rate": 0.9994945972423835, "train/extr_return_raw_mag": 1.7163907224908839, "train/extr_return_raw_max": 1.7163907224908839, "train/extr_return_raw_mean": 1.5014095012777544, "train/extr_return_raw_min": 0.4677778817162725, "train/extr_return_raw_std": 0.039921452461058285, "train/extr_reward_mag": 0.25462417355899153, "train/extr_reward_max": 0.25462417355899153, "train/extr_reward_mean": 0.002295329024455524, "train/extr_reward_min": 1.2273271682814424e-07, "train/extr_reward_std": 0.00788801099435229, "train/image_loss_mean": 0.08861055601333162, "train/image_loss_std": 0.10318504273891449, "train/model_loss_mean": 0.7267441179952011, "train/model_loss_std": 0.4957616209910421, "train/model_opt_grad_norm": 18.161068007276562, "train/model_opt_grad_steps": 57409.93103448276, "train/model_opt_loss": 3738.726204106373, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5147.783251231527, "train/policy_entropy_mag": 1.2970907177243913, "train/policy_entropy_max": 1.2970907177243913, "train/policy_entropy_mean": 0.09444863198719589, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.11648607837595963, "train/policy_logprob_mag": 6.551080240991903, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09418212571020784, "train/policy_logprob_min": -6.551080240991903, "train/policy_logprob_std": 0.6306336580826144, "train/policy_randomness_mag": 0.6665728083385035, "train/policy_randomness_max": 0.6665728083385035, "train/policy_randomness_mean": 0.04853699640760868, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.05986200614368974, "train/post_ent_mag": 37.36630628614003, "train/post_ent_max": 37.36630628614003, "train/post_ent_mean": 32.120246135542544, "train/post_ent_min": 29.16110522641337, "train/post_ent_std": 1.6390428308195668, "train/prior_ent_mag": 37.09607677741591, "train/prior_ent_max": 37.09607677741591, "train/prior_ent_mean": 31.7975172221367, "train/prior_ent_min": 27.919179108342515, "train/prior_ent_std": 1.6470297557379812, "train/rep_loss_mean": 1.0000009836234482, "train/rep_loss_std": 3.1209133451877924e-05, "train/reward_avg": 0.0022416138282307227, "train/reward_loss_mean": 0.017177583290759493, "train/reward_loss_std": 0.23922670182767394, "train/reward_max_data": 0.7596213065931949, "train/reward_max_pred": 0.2114398796570125, "train/reward_neg_acc": 0.9996621890608313, "train/reward_neg_loss": 0.003092855322312362, "train/reward_pos_acc": 0.1162738711927748, "train/reward_pos_loss": 4.155538853655007, "train/reward_pred": 0.0017580568682622586, "train/reward_rate": 0.003357835591133005, "train_stats/mean_log_entropy": 0.08257998365974217, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.016695057973265648, "report/cont_loss_std": 0.19167959690093994, "report/cont_neg_acc": 0.3333333432674408, "report/cont_neg_loss": 2.039503574371338, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0047728074714541435, "report/cont_pred": 0.9932594299316406, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.10996071994304657, "report/image_loss_std": 0.10716130584478378, "report/model_loss_mean": 0.7439261674880981, "report/model_loss_std": 0.4723023474216461, "report/post_ent_mag": 38.4610710144043, "report/post_ent_max": 38.4610710144043, "report/post_ent_mean": 32.33527374267578, "report/post_ent_min": 29.00676727294922, "report/post_ent_std": 1.9673020839691162, "report/prior_ent_mag": 39.229698181152344, "report/prior_ent_max": 39.229698181152344, "report/prior_ent_mean": 32.62539291381836, "report/prior_ent_min": 28.145732879638672, "report/prior_ent_std": 2.0419976711273193, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0014678954612463713, "report/reward_loss_mean": 0.017270375043153763, "report/reward_loss_std": 0.2659272253513336, "report/reward_max_data": 0.6031249761581421, "report/reward_max_pred": 0.06872153282165527, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0031721643172204494, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.815361022949219, "report/reward_pred": 0.0016972820740193129, "report/reward_rate": 0.0029296875, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.034757137298583984, "eval/cont_loss_std": 0.5741508603096008, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 7.842343330383301, "eval/cont_pos_acc": 0.9990195631980896, "eval/cont_pos_loss": 0.004139152821153402, "eval/cont_pred": 0.9960654973983765, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.17691665887832642, "eval/image_loss_std": 0.15977957844734192, "eval/model_loss_mean": 0.8214588761329651, "eval/model_loss_std": 0.6667695045471191, "eval/post_ent_mag": 38.47333526611328, "eval/post_ent_max": 38.47333526611328, "eval/post_ent_mean": 32.06853103637695, "eval/post_ent_min": 28.620906829833984, "eval/post_ent_std": 2.0155820846557617, "eval/prior_ent_mag": 39.229698181152344, "eval/prior_ent_max": 39.229698181152344, "eval/prior_ent_mean": 32.58184814453125, "eval/prior_ent_min": 27.696842193603516, "eval/prior_ent_std": 2.025580644607544, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0015472412342205644, "eval/reward_loss_mean": 0.009785071946680546, "eval/reward_loss_std": 0.17679420113563538, "eval/reward_max_data": 0.815625011920929, "eval/reward_max_pred": 0.06132698059082031, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.001973268575966358, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 4.001616477966309, "eval/reward_pred": 0.001068821526132524, "eval/reward_rate": 0.001953125, "replay/size": 936705.0, "replay/inserts": 32480.0, "replay/samples": 32480.0, "replay/insert_wait_avg": 1.3216449122123531e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.066226108908067e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4832.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.066123807667107e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.08970832824707e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0652368068695, "timer/env.step_count": 4060.0, "timer/env.step_total": 38.19586133956909, "timer/env.step_frac": 0.03819336972608457, "timer/env.step_avg": 0.00940784762058352, "timer/env.step_min": 0.007494688034057617, "timer/env.step_max": 0.04270148277282715, "timer/replay._sample_count": 32480.0, "timer/replay._sample_total": 16.206300258636475, "timer/replay._sample_frac": 0.01620524308032337, "timer/replay._sample_avg": 0.0004989624463865909, "timer/replay._sample_min": 0.0003826618194580078, "timer/replay._sample_max": 0.04657173156738281, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4664.0, "timer/agent.policy_total": 47.815213680267334, "timer/agent.policy_frac": 0.047812094571887724, "timer/agent.policy_avg": 0.010251975488908091, "timer/agent.policy_min": 0.008398056030273438, "timer/agent.policy_max": 0.08281135559082031, "timer/dataset_train_count": 2030.0, "timer/dataset_train_total": 0.21836113929748535, "timer/dataset_train_frac": 0.00021834689504326285, "timer/dataset_train_avg": 0.00010756706369334253, "timer/dataset_train_min": 9.584426879882812e-05, "timer/dataset_train_max": 0.0004868507385253906, "timer/agent.train_count": 2030.0, "timer/agent.train_total": 900.6532905101776, "timer/agent.train_frac": 0.9005945385981954, "timer/agent.train_avg": 0.44367157167989046, "timer/agent.train_min": 0.4318511486053467, "timer/agent.train_max": 0.6694488525390625, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4797389507293701, "timer/agent.report_frac": 0.0004797076561336531, "timer/agent.report_avg": 0.23986947536468506, "timer/agent.report_min": 0.23417091369628906, "timer/agent.report_max": 0.24556803703308105, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.24249267578125e-05, "timer/dataset_eval_frac": 3.242281159711417e-08, "timer/dataset_eval_avg": 3.24249267578125e-05, "timer/dataset_eval_min": 3.24249267578125e-05, "timer/dataset_eval_max": 3.24249267578125e-05, "fps": 32.47735423214669}
{"step": 937256, "time": 29229.317846775055, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 937280, "time": 29230.267602682114, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 937368, "time": 29232.689681768417, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 937640, "time": 29240.895332813263, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 937824, "time": 29246.78160214424, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 937968, "time": 29251.139995336533, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 938344, "time": 29262.262672662735, "episode/length": 189.0, "episode/score": 0.40937501192092896, "episode/reward_rate": 0.005263157894736842, "episode/intrinsic_return": 0.0}
{"step": 938488, "time": 29266.625639677048, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 938784, "time": 29275.890939474106, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 938792, "time": 29275.918440818787, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 939024, "time": 29283.157708883286, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 939144, "time": 29286.54013490677, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 939568, "time": 29301.764036655426, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 939632, "time": 29303.73109769821, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 939680, "time": 29305.311454296112, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 939696, "time": 29305.802539110184, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 939776, "time": 29308.226902008057, "episode/length": 225.0, "episode/score": 0.296875, "episode/reward_rate": 0.004424778761061947, "episode/intrinsic_return": 0.0}
{"step": 940056, "time": 29317.164702177048, "eval_episode/length": 34.0, "eval_episode/score": 0.893750011920929, "eval_episode/reward_rate": 0.02857142857142857}
{"step": 940056, "time": 29317.599249362946, "eval_episode/length": 57.0, "eval_episode/score": 0.8218749761581421, "eval_episode/reward_rate": 0.017241379310344827}
{"step": 940056, "time": 29318.09753060341, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 940056, "time": 29318.122086048126, "eval_episode/length": 87.0, "eval_episode/score": 0.7281249761581421, "eval_episode/reward_rate": 0.011363636363636364}
{"step": 940056, "time": 29318.415620565414, "eval_episode/length": 103.0, "eval_episode/score": 0.6781250238418579, "eval_episode/reward_rate": 0.009615384615384616}
{"step": 940056, "time": 29318.457151174545, "eval_episode/length": 105.0, "eval_episode/score": 0.671875, "eval_episode/reward_rate": 0.009433962264150943}
{"step": 940056, "time": 29319.26087665558, "eval_episode/length": 116.0, "eval_episode/score": 0.637499988079071, "eval_episode/reward_rate": 0.008547008547008548}
{"step": 940056, "time": 29319.621131658554, "eval_episode/length": 84.0, "eval_episode/score": 0.737500011920929, "eval_episode/reward_rate": 0.011764705882352941}
{"step": 940248, "time": 29325.41044473648, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 940296, "time": 29326.879393815994, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 940488, "time": 29332.677942991257, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 940656, "time": 29338.059749126434, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 940800, "time": 29342.411192178726, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 940880, "time": 29344.819093942642, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 940936, "time": 29346.308384895325, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 940952, "time": 29346.79691672325, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 941096, "time": 29351.14630317688, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 941104, "time": 29351.61804294586, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 941176, "time": 29353.582138299942, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 941336, "time": 29358.41958451271, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 941456, "time": 29362.269637584686, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 941504, "time": 29363.720965385437, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 941752, "time": 29371.14827156067, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 941792, "time": 29372.58373785019, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 941808, "time": 29373.074725866318, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 941936, "time": 29376.952530145645, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 941944, "time": 29376.98131418228, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 942064, "time": 29380.82664179802, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 942392, "time": 29390.978541612625, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 942480, "time": 29393.846787691116, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 942872, "time": 29405.598046779633, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 943232, "time": 29416.641345739365, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 943248, "time": 29417.130977630615, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 943768, "time": 29432.659236192703, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 943880, "time": 29436.047293186188, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 944064, "time": 29441.915750026703, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 944104, "time": 29442.927842140198, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 944120, "time": 29443.445653915405, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 944168, "time": 29444.891461372375, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 944256, "time": 29447.757071495056, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 944512, "time": 29455.58180499077, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 944800, "time": 29464.270193576813, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 944888, "time": 29466.704531431198, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 945088, "time": 29472.971652269363, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 945112, "time": 29473.481962442398, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 945208, "time": 29476.372556447983, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 945552, "time": 29487.125447273254, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 946080, "time": 29503.07013773918, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 946376, "time": 29511.789157390594, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 946432, "time": 29513.68921327591, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 946464, "time": 29514.655378818512, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 946520, "time": 29516.273616075516, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 946672, "time": 29521.094779014587, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 946832, "time": 29525.937109470367, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 947024, "time": 29531.74058365822, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 947112, "time": 29534.16270661354, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 947280, "time": 29539.447672128677, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 947328, "time": 29540.907949209213, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 947344, "time": 29541.392666101456, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 947400, "time": 29542.857702970505, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 947456, "time": 29544.768588781357, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 947560, "time": 29547.796725034714, "episode/length": 19.0, "episode/score": 0.940625011920929, "episode/reward_rate": 0.05, "episode/intrinsic_return": 0.0}
{"step": 947672, "time": 29551.17808699608, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 948008, "time": 29561.29647731781, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 948112, "time": 29564.668038606644, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 948344, "time": 29571.45453286171, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 948376, "time": 29572.424284219742, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 948696, "time": 29582.257284402847, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 948744, "time": 29583.72137284279, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 948832, "time": 29586.619959115982, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 948888, "time": 29588.09192609787, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 948928, "time": 29589.545934438705, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 949336, "time": 29601.632630109787, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 949368, "time": 29602.60244512558, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 949472, "time": 29606.053671121597, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 949552, "time": 29608.486525297165, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 949576, "time": 29608.992524385452, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 949768, "time": 29614.78847837448, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 949904, "time": 29619.115283966064, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 950040, "time": 29623.668172597885, "eval_episode/length": 32.0, "eval_episode/score": 0.8999999761581421, "eval_episode/reward_rate": 0.030303030303030304}
{"step": 950040, "time": 29624.540912151337, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 950040, "time": 29624.570898532867, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 950040, "time": 29624.89338350296, "eval_episode/length": 96.0, "eval_episode/score": 0.699999988079071, "eval_episode/reward_rate": 0.010309278350515464}
{"step": 950040, "time": 29626.33230113983, "eval_episode/length": 59.0, "eval_episode/score": 0.815625011920929, "eval_episode/reward_rate": 0.016666666666666666}
{"step": 950040, "time": 29626.394558668137, "eval_episode/length": 143.0, "eval_episode/score": 0.5531250238418579, "eval_episode/reward_rate": 0.006944444444444444}
{"step": 950040, "time": 29626.877326250076, "eval_episode/length": 137.0, "eval_episode/score": 0.5718749761581421, "eval_episode/reward_rate": 0.007246376811594203}
{"step": 950040, "time": 29627.607793331146, "eval_episode/length": 67.0, "eval_episode/score": 0.7906249761581421, "eval_episode/reward_rate": 0.014705882352941176}
{"step": 950136, "time": 29630.506268262863, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 950144, "time": 29630.974201202393, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 950200, "time": 29632.46521115303, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 950328, "time": 29636.93701028824, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 950408, "time": 29639.369357585907, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 950536, "time": 29643.243156194687, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 950592, "time": 29645.154931545258, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 950648, "time": 29646.62493944168, "episode/length": 13.0, "episode/score": 0.9593750238418579, "episode/reward_rate": 0.07142857142857142, "episode/intrinsic_return": 0.0}
{"step": 950720, "time": 29649.034335374832, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 950856, "time": 29652.92325592041, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 950864, "time": 29653.39037823677, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 951144, "time": 29661.625430345535, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 951400, "time": 29669.476999521255, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 951512, "time": 29672.893258810043, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 951576, "time": 29674.834872961044, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 951664, "time": 29677.747658729553, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 951824, "time": 29682.626475334167, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 951840, "time": 29683.123969078064, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 951968, "time": 29687.02755379677, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 952184, "time": 29693.350920915604, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 952288, "time": 29696.83883690834, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 952336, "time": 29698.294367313385, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 952448, "time": 29701.69789123535, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 952520, "time": 29703.65905547142, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 952680, "time": 29708.50105881691, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 952688, "time": 29708.967645168304, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 952768, "time": 29711.403505325317, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 953056, "time": 29720.110043525696, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 953144, "time": 29722.570940971375, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 953144, "time": 29722.58005475998, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 953224, "time": 29725.05447936058, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 953512, "time": 29733.84551715851, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 953512, "time": 29733.85355567932, "episode/length": 208.0, "episode/score": 0.3499999940395355, "episode/reward_rate": 0.004784688995215311, "episode/intrinsic_return": 0.0}
{"step": 953536, "time": 29734.80228114128, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 954000, "time": 29748.846128940582, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 954096, "time": 29751.772451639175, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 954176, "time": 29754.205308675766, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 954336, "time": 29759.221076965332, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 954496, "time": 29764.087164402008, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 954904, "time": 29776.195909261703, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 954976, "time": 29778.60211610794, "episode/length": 8.0, "episode/score": 0.9750000238418579, "episode/reward_rate": 0.1111111111111111, "episode/intrinsic_return": 0.0}
{"step": 955000, "time": 29779.13791537285, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 955056, "time": 29781.09125518799, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 955104, "time": 29782.563685894012, "episode/length": 12.0, "episode/score": 0.9624999761581421, "episode/reward_rate": 0.07692307692307693, "episode/intrinsic_return": 0.0}
{"step": 955248, "time": 29787.025458812714, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 955368, "time": 29790.457189798355, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 955464, "time": 29793.369929790497, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 955536, "time": 29795.7867000103, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 955696, "time": 29800.643189430237, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 955824, "time": 29804.559332847595, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 955856, "time": 29805.544061899185, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 955992, "time": 29809.465663194656, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 956016, "time": 29810.423303604126, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 956128, "time": 29813.82046866417, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 956168, "time": 29814.81417489052, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 956496, "time": 29825.106467723846, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 956824, "time": 29834.777575731277, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 956960, "time": 29839.109035015106, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 957000, "time": 29840.09547829628, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 957032, "time": 29841.06520676613, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 957104, "time": 29843.475463867188, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 957200, "time": 29846.442974805832, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 957248, "time": 29847.90718793869, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 957320, "time": 29849.856566905975, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 957432, "time": 29853.24760198593, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 957680, "time": 29860.955858945847, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 957816, "time": 29864.862144470215, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 957856, "time": 29866.293068408966, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 957912, "time": 29867.779492616653, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 957920, "time": 29868.246520757675, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 957968, "time": 29869.698588371277, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 958064, "time": 29872.60420680046, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 958088, "time": 29873.115444898605, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 958128, "time": 29874.547737836838, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 958352, "time": 29881.36668395996, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 958424, "time": 29883.314581394196, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 958576, "time": 29888.621017694473, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 958688, "time": 29892.0139272213, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 959088, "time": 29904.100483894348, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 959192, "time": 29907.1347219944, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 959560, "time": 29918.221979618073, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 959968, "time": 29930.770151615143, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 960024, "time": 29932.694801330566, "eval_episode/length": 25.0, "eval_episode/score": 0.921875, "eval_episode/reward_rate": 0.038461538461538464}
{"step": 960024, "time": 29933.42909502983, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 960024, "time": 29933.52624320984, "eval_episode/length": 71.0, "eval_episode/score": 0.778124988079071, "eval_episode/reward_rate": 0.013888888888888888}
{"step": 960024, "time": 29934.554215192795, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 960024, "time": 29934.579567193985, "eval_episode/length": 130.0, "eval_episode/score": 0.59375, "eval_episode/reward_rate": 0.007633587786259542}
{"step": 960024, "time": 29934.744191408157, "eval_episode/length": 113.0, "eval_episode/score": 0.6468750238418579, "eval_episode/reward_rate": 0.008771929824561403}
{"step": 960024, "time": 29934.817867279053, "eval_episode/length": 71.0, "eval_episode/score": 0.778124988079071, "eval_episode/reward_rate": 0.013888888888888888}
{"step": 960024, "time": 29936.319527864456, "eval_episode/length": 89.0, "eval_episode/score": 0.721875011920929, "eval_episode/reward_rate": 0.011111111111111112}
{"step": 960128, "time": 29939.689225435257, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 960152, "time": 29940.19682765007, "episode/length": 196.0, "episode/score": 0.38749998807907104, "episode/reward_rate": 0.005076142131979695, "episode/intrinsic_return": 0.0}
{"step": 960200, "time": 29941.64439558983, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 960376, "time": 29946.943658828735, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 960400, "time": 29947.89490699768, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 960664, "time": 29955.688097715378, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 960728, "time": 29957.620268821716, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 960752, "time": 29958.59335398674, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 960856, "time": 29961.513334274292, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 961072, "time": 29968.432453393936, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 961528, "time": 29981.95700287819, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 961672, "time": 29986.32299876213, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 961808, "time": 29990.65377664566, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 961864, "time": 29992.12827849388, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 961872, "time": 29992.618980884552, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 962184, "time": 30001.891632080078, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 962280, "time": 30004.807565689087, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 962384, "time": 30008.18712735176, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 962688, "time": 30017.33830165863, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 962744, "time": 30018.805079460144, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 962832, "time": 30021.686003684998, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 962888, "time": 30023.14754843712, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 963064, "time": 30028.543122053146, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 963064, "time": 30028.551473617554, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 963256, "time": 30034.34377002716, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 963264, "time": 30034.810054779053, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 963336, "time": 30036.772970438004, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 963360, "time": 30037.72275543213, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 963432, "time": 30039.675722122192, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 963544, "time": 30043.06038737297, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 963752, "time": 30049.31574177742, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 963888, "time": 30053.629375219345, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 963936, "time": 30055.159651994705, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 964008, "time": 30057.124554157257, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 964040, "time": 30058.093629837036, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 964088, "time": 30059.5543320179, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 964136, "time": 30061.026161909103, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 964256, "time": 30064.863243579865, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 964768, "time": 30080.36355662346, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 964768, "time": 30080.37195634842, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 964832, "time": 30082.330666065216, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 965056, "time": 30089.163940906525, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 965080, "time": 30089.68736410141, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 965328, "time": 30097.371809244156, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 965480, "time": 30101.74751853943, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 965672, "time": 30107.5503282547, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 965856, "time": 30113.32793354988, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 965888, "time": 30114.32132601738, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 966128, "time": 30121.698356866837, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 966200, "time": 30123.681431293488, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 966320, "time": 30127.513078212738, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 966352, "time": 30128.498517513275, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 966888, "time": 30144.987318754196, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 966968, "time": 30147.47874045372, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 967144, "time": 30152.805417060852, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 967368, "time": 30159.571167707443, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 967392, "time": 30160.522694587708, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 967528, "time": 30164.418637514114, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 967912, "time": 30176.067383527756, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 967960, "time": 30177.537432432175, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 967976, "time": 30178.028630256653, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 968200, "time": 30184.799264907837, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 968424, "time": 30191.554941892624, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 968472, "time": 30193.017618894577, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 968664, "time": 30198.817864894867, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 968664, "time": 30198.824989318848, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 968792, "time": 30202.698723077774, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 968920, "time": 30206.650134325027, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 968936, "time": 30207.13847875595, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 969256, "time": 30216.8026099205, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 969456, "time": 30223.073802232742, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 969456, "time": 30223.082665920258, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 969609, "time": 30228.46156859398, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.569707560421798, "train/action_min": 0.0, "train/action_std": 1.9055760065323026, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.008404346024663431, "train/actor_opt_grad_steps": 59490.0, "train/actor_opt_loss": -12.899916016996787, "train/adv_mag": 0.9011456032691918, "train/adv_max": 0.2855987437252928, "train/adv_mean": 8.880272267345887e-05, "train/adv_min": -0.8402390990938459, "train/adv_std": 0.02618360076686872, "train/cont_avg": 0.9943907789408867, "train/cont_loss_mean": 0.020818513748121305, "train/cont_loss_std": 0.25445742248167547, "train/cont_neg_acc": 0.243381035849085, "train/cont_neg_loss": 2.9476006888403683, "train/cont_pos_acc": 0.9999080549907214, "train/cont_pos_loss": 0.0043155990421698594, "train/cont_pred": 0.9944103057748579, "train/cont_rate": 0.9943907789408867, "train/dyn_loss_mean": 1.0000053996523026, "train/dyn_loss_std": 0.0001169880518771185, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.1045793264673041, "train/extr_critic_critic_opt_grad_steps": 59490.0, "train/extr_critic_critic_opt_loss": 9832.156644473522, "train/extr_critic_mag": 1.5839934255101997, "train/extr_critic_max": 1.5839934255101997, "train/extr_critic_mean": 1.4891229304186817, "train/extr_critic_min": 1.2176689667067504, "train/extr_critic_std": 0.023337666082925396, "train/extr_return_normed_mag": 0.9188282178540536, "train/extr_return_normed_max": 0.2642233688843074, "train/extr_return_normed_mean": 0.04359344537989259, "train/extr_return_normed_min": -0.835977466822845, "train/extr_return_normed_std": 0.03572766143333148, "train/extr_return_rate": 0.9996190276639215, "train/extr_return_raw_mag": 1.7098416389502915, "train/extr_return_raw_max": 1.7098416389502915, "train/extr_return_raw_mean": 1.4892117930163304, "train/extr_return_raw_min": 0.6096408032431391, "train/extr_return_raw_std": 0.0357276614149803, "train/extr_reward_mag": 0.25809471830358643, "train/extr_reward_max": 0.25809471830358643, "train/extr_reward_mean": 0.002350249350084717, "train/extr_reward_min": 6.165997735385237e-08, "train/extr_reward_std": 0.007801812954173593, "train/image_loss_mean": 0.0904438388832097, "train/image_loss_std": 0.1045545984444947, "train/model_loss_mean": 0.7286036225962521, "train/model_loss_std": 0.49785643893069237, "train/model_opt_grad_norm": 17.708439770590495, "train/model_opt_grad_steps": 59437.93103448276, "train/model_opt_loss": 3679.192910781635, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5049.261083743842, "train/policy_entropy_mag": 1.2879352640048625, "train/policy_entropy_max": 1.2879352640048625, "train/policy_entropy_mean": 0.09232335680811277, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.11185973064212376, "train/policy_logprob_mag": 6.5510802386429505, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09237374460755898, "train/policy_logprob_min": -6.5510802386429505, "train/policy_logprob_std": 0.6297125907367086, "train/policy_randomness_mag": 0.6618678352515686, "train/policy_randomness_max": 0.6618678352515686, "train/policy_randomness_mean": 0.0474448211197489, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.057484533766220355, "train/post_ent_mag": 43.25900856732148, "train/post_ent_max": 43.25900856732148, "train/post_ent_mean": 34.55585867783119, "train/post_ent_min": 30.02254909834838, "train/post_ent_std": 2.632280908194669, "train/prior_ent_mag": 44.82775837564703, "train/prior_ent_max": 44.82775837564703, "train/prior_ent_mean": 35.13254795168421, "train/prior_ent_min": 29.705573875915828, "train/prior_ent_std": 2.69501574873337, "train/rep_loss_mean": 1.0000053996523026, "train/rep_loss_std": 0.0001169880518771185, "train/reward_avg": 0.0022979886543459897, "train/reward_loss_mean": 0.017338007396050348, "train/reward_loss_std": 0.241969246889827, "train/reward_max_data": 0.7664870682901936, "train/reward_max_pred": 0.1926411912946278, "train/reward_neg_acc": 0.9997344859715166, "train/reward_neg_loss": 0.003140955469502237, "train/reward_pos_acc": 0.09929498148902419, "train/reward_pos_loss": 4.198091308477566, "train/reward_pred": 0.0017868495675886574, "train/reward_rate": 0.0033866995073891628, "train_stats/mean_log_entropy": 0.07998629508555428, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.02917306125164032, "report/cont_loss_std": 0.31410205364227295, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 3.7261698246002197, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0037266721483319998, "report/cont_pred": 0.996143102645874, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.10458125174045563, "report/image_loss_std": 0.11920490860939026, "report/model_loss_mean": 0.7612341642379761, "report/model_loss_std": 0.6505072712898254, "report/post_ent_mag": 48.60778045654297, "report/post_ent_max": 48.60778045654297, "report/post_ent_mean": 36.174964904785156, "report/post_ent_min": 29.82525634765625, "report/post_ent_std": 3.735995292663574, "report/prior_ent_mag": 50.699974060058594, "report/prior_ent_max": 50.699974060058594, "report/prior_ent_mean": 37.232322692871094, "report/prior_ent_min": 30.818767547607422, "report/prior_ent_std": 3.686047315597534, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0041900635696947575, "report/reward_loss_mean": 0.027479827404022217, "report/reward_loss_std": 0.32202035188674927, "report/reward_max_data": 0.871874988079071, "report/reward_max_pred": 0.05147731304168701, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.002806530799716711, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.21371603012085, "report/reward_pred": 0.001568392850458622, "report/reward_rate": 0.005859375, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.022229867056012154, "eval/cont_loss_std": 0.3056688904762268, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 4.636526584625244, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.004134586546570063, "eval/cont_pred": 0.9958564639091492, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.1519518494606018, "eval/image_loss_std": 0.1380946934223175, "eval/model_loss_mean": 0.7902977466583252, "eval/model_loss_std": 0.5353593826293945, "eval/post_ent_mag": 48.627281188964844, "eval/post_ent_max": 48.627281188964844, "eval/post_ent_mean": 35.88628387451172, "eval/post_ent_min": 29.50609588623047, "eval/post_ent_std": 3.7265758514404297, "eval/prior_ent_mag": 50.699974060058594, "eval/prior_ent_max": 50.699974060058594, "eval/prior_ent_mean": 36.99098587036133, "eval/prior_ent_min": 30.724369049072266, "eval/prior_ent_std": 3.7028284072875977, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0019958496559411287, "eval/reward_loss_mean": 0.016115989536046982, "eval/reward_loss_std": 0.241631418466568, "eval/reward_max_data": 0.7406250238418579, "eval/reward_max_pred": 0.059784531593322754, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.003105936571955681, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 4.443870544433594, "eval/reward_pred": 0.0016739527927711606, "eval/reward_rate": 0.0029296875, "replay/size": 969105.0, "replay/inserts": 32400.0, "replay/samples": 32400.0, "replay/insert_wait_avg": 1.3402288342699592e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.140007654825846e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4832.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.083886781275667e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.046627044677734e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3230996131897, "timer/env.step_count": 4050.0, "timer/env.step_total": 38.45662188529968, "timer/env.step_frac": 0.03844420057896323, "timer/env.step_avg": 0.009495462193901157, "timer/env.step_min": 0.007494688034057617, "timer/env.step_max": 0.04073691368103027, "timer/replay._sample_count": 32400.0, "timer/replay._sample_total": 16.17938542366028, "timer/replay._sample_frac": 0.01617415955896311, "timer/replay._sample_avg": 0.0004993637476438358, "timer/replay._sample_min": 0.00037407875061035156, "timer/replay._sample_max": 0.010487794876098633, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4654.0, "timer/agent.policy_total": 48.47031927108765, "timer/agent.policy_frac": 0.04845466358802512, "timer/agent.policy_avg": 0.010414765636245734, "timer/agent.policy_min": 0.008293867111206055, "timer/agent.policy_max": 0.09335899353027344, "timer/dataset_train_count": 2025.0, "timer/dataset_train_total": 0.21968364715576172, "timer/dataset_train_frac": 0.00021961269038044825, "timer/dataset_train_avg": 0.00010848575168185764, "timer/dataset_train_min": 9.441375732421875e-05, "timer/dataset_train_max": 0.0005924701690673828, "timer/agent.train_count": 2025.0, "timer/agent.train_total": 901.8038566112518, "timer/agent.train_frac": 0.9015125782459349, "timer/agent.train_avg": 0.44533523783271695, "timer/agent.train_min": 0.4346463680267334, "timer/agent.train_max": 2.631009578704834, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4787445068359375, "timer/agent.report_frac": 0.0004785898746325672, "timer/agent.report_avg": 0.23937225341796875, "timer/agent.report_min": 0.23424243927001953, "timer/agent.report_max": 0.24450206756591797, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.24249267578125e-05, "timer/dataset_eval_frac": 3.241445366037308e-08, "timer/dataset_eval_avg": 3.24249267578125e-05, "timer/dataset_eval_min": 3.24249267578125e-05, "timer/dataset_eval_max": 3.24249267578125e-05, "fps": 32.388980791667365}
{"step": 969680, "time": 30230.58748936653, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 969704, "time": 30231.09620642662, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 969808, "time": 30234.459577560425, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 969824, "time": 30234.94987845421, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 970008, "time": 30241.29660820961, "eval_episode/length": 49.0, "eval_episode/score": 0.846875011920929, "eval_episode/reward_rate": 0.02}
{"step": 970008, "time": 30241.68643260002, "eval_episode/length": 70.0, "eval_episode/score": 0.78125, "eval_episode/reward_rate": 0.014084507042253521}
{"step": 970008, "time": 30241.832568883896, "eval_episode/length": 78.0, "eval_episode/score": 0.7562500238418579, "eval_episode/reward_rate": 0.012658227848101266}
{"step": 970008, "time": 30242.093721866608, "eval_episode/length": 91.0, "eval_episode/score": 0.715624988079071, "eval_episode/reward_rate": 0.010869565217391304}
{"step": 970008, "time": 30242.56602859497, "eval_episode/length": 116.0, "eval_episode/score": 0.637499988079071, "eval_episode/reward_rate": 0.008547008547008548}
{"step": 970008, "time": 30243.208644628525, "eval_episode/length": 150.0, "eval_episode/score": 0.53125, "eval_episode/reward_rate": 0.006622516556291391}
{"step": 970008, "time": 30243.368921756744, "eval_episode/length": 158.0, "eval_episode/score": 0.5062500238418579, "eval_episode/reward_rate": 0.006289308176100629}
{"step": 970008, "time": 30243.387390613556, "eval_episode/length": 108.0, "eval_episode/score": 0.6625000238418579, "eval_episode/reward_rate": 0.009174311926605505}
{"step": 970048, "time": 30244.860773563385, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 970072, "time": 30245.380064487457, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 970208, "time": 30249.73927474022, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 970384, "time": 30255.070917367935, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 970552, "time": 30259.968993902206, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 971000, "time": 30273.65255856514, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 971032, "time": 30274.635101556778, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 971104, "time": 30277.044157266617, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 971536, "time": 30290.15246462822, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 971712, "time": 30295.565713882446, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 971768, "time": 30297.04055404663, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 971816, "time": 30298.514875411987, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 971992, "time": 30303.87743616104, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 972016, "time": 30304.833133220673, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 972296, "time": 30313.113258123398, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 972312, "time": 30313.602653741837, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 972368, "time": 30315.509168624878, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 972520, "time": 30319.9386780262, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 972920, "time": 30332.082115888596, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 973256, "time": 30342.20073032379, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 973264, "time": 30342.669649600983, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 973288, "time": 30343.182243585587, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 973312, "time": 30344.13236093521, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 973504, "time": 30349.883913993835, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 973584, "time": 30352.296988487244, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 973936, "time": 30363.032064199448, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 974024, "time": 30365.467305660248, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 974112, "time": 30368.3430724144, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 974152, "time": 30369.330483198166, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 974184, "time": 30370.295957803726, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 974296, "time": 30373.68403530121, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 974328, "time": 30374.646261692047, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 974432, "time": 30378.00564479828, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 974560, "time": 30381.871056079865, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 974728, "time": 30386.805621147156, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 974824, "time": 30389.700125932693, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 974848, "time": 30390.819140911102, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 974888, "time": 30392.13688802719, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 974968, "time": 30394.538939237595, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 975120, "time": 30399.337324380875, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 975160, "time": 30400.34791493416, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 975288, "time": 30404.198194026947, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 975496, "time": 30410.446821451187, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 975592, "time": 30413.318860769272, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 975664, "time": 30415.818527698517, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 975776, "time": 30419.1914229393, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 976000, "time": 30425.985421419144, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 976208, "time": 30432.26498913765, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 976240, "time": 30433.23021531105, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 976416, "time": 30438.554720640182, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 976592, "time": 30443.880340337753, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 977088, "time": 30458.95385146141, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 977136, "time": 30460.40629053116, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 977152, "time": 30460.892656326294, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 977624, "time": 30474.9852643013, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 977808, "time": 30480.82068657875, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 977904, "time": 30483.730770111084, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 977936, "time": 30484.694843530655, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 978088, "time": 30489.059980392456, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 978616, "time": 30505.109762191772, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 978720, "time": 30508.49204158783, "episode/length": 203.0, "episode/score": 0.3656249940395355, "episode/reward_rate": 0.004901960784313725, "episode/intrinsic_return": 0.0}
{"step": 978840, "time": 30511.908334970474, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 978904, "time": 30513.83987545967, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 978976, "time": 30516.229923963547, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 978992, "time": 30516.73642897606, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 979184, "time": 30522.532825231552, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 979184, "time": 30522.54009771347, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 979464, "time": 30530.781434059143, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 979528, "time": 30532.736050605774, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 979616, "time": 30535.73918223381, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 979704, "time": 30538.192561149597, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 979784, "time": 30540.61474609375, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 980096, "time": 30551.288502454758, "eval_episode/length": 50.0, "eval_episode/score": 0.84375, "eval_episode/reward_rate": 0.0196078431372549}
{"step": 980096, "time": 30551.65961408615, "eval_episode/length": 70.0, "eval_episode/score": 0.78125, "eval_episode/reward_rate": 0.014084507042253521}
{"step": 980096, "time": 30551.717445135117, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 980096, "time": 30551.8266146183, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 980096, "time": 30551.850629091263, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 980096, "time": 30551.856944322586, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 980096, "time": 30552.03666472435, "eval_episode/length": 90.0, "eval_episode/score": 0.71875, "eval_episode/reward_rate": 0.01098901098901099}
{"step": 980096, "time": 30552.58675312996, "eval_episode/length": 40.0, "eval_episode/score": 0.875, "eval_episode/reward_rate": 0.024390243902439025}
{"step": 980280, "time": 30557.923558712006, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 980376, "time": 30560.81459379196, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 980488, "time": 30564.21642279625, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 980592, "time": 30567.728063821793, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 981192, "time": 30585.62584733963, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 981288, "time": 30588.528594493866, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 981376, "time": 30591.39239692688, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 981424, "time": 30592.85961484909, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 981496, "time": 30594.80416250229, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 981624, "time": 30598.76389861107, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 981888, "time": 30606.98720049858, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 981928, "time": 30607.983689785004, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 982016, "time": 30610.86411356926, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 982224, "time": 30617.17710351944, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 982272, "time": 30618.632746696472, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 982344, "time": 30620.575772047043, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 982480, "time": 30624.94017481804, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 982936, "time": 30638.584020614624, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 983016, "time": 30641.02064204216, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 983064, "time": 30642.931770563126, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 983216, "time": 30647.760006189346, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 983544, "time": 30657.538123607635, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 983600, "time": 30659.44617176056, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 983608, "time": 30659.474539995193, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 983648, "time": 30660.928375005722, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 983656, "time": 30660.956941127777, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 984088, "time": 30674.001284360886, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 984216, "time": 30677.862851381302, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 984480, "time": 30686.245759248734, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 984584, "time": 30689.170434713364, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 984632, "time": 30690.647536039352, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 985264, "time": 30709.936383247375, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 985440, "time": 30715.341253995895, "episode/length": 21.0, "episode/score": 0.934374988079071, "episode/reward_rate": 0.045454545454545456, "episode/intrinsic_return": 0.0}
{"step": 985528, "time": 30717.778968334198, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 985632, "time": 30721.14679288864, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 985744, "time": 30724.538421154022, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 985856, "time": 30727.89585185051, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 985912, "time": 30729.38524246216, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 986168, "time": 30737.104160308838, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 986328, "time": 30741.94207406044, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 986400, "time": 30744.35765028, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 986752, "time": 30755.04949116707, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 986792, "time": 30756.03724002838, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 986856, "time": 30757.989457130432, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 986896, "time": 30759.4180290699, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 986904, "time": 30759.446095228195, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 986952, "time": 30760.89719605446, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 986968, "time": 30761.385003089905, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 987488, "time": 30777.44512462616, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 987712, "time": 30784.213318109512, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 987792, "time": 30786.640415668488, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 987840, "time": 30788.08553290367, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 987912, "time": 30790.033646583557, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 988056, "time": 30794.37130856514, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 988128, "time": 30796.77113223076, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 988312, "time": 30802.150554180145, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 988384, "time": 30804.55155968666, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 988512, "time": 30808.50475883484, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 988720, "time": 30814.7874212265, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 988896, "time": 30820.119505882263, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 989016, "time": 30823.567445993423, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 989216, "time": 30829.853235006332, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 989296, "time": 30832.28683066368, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 989424, "time": 30836.282595396042, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 989520, "time": 30839.19026350975, "episode/length": 209.0, "episode/score": 0.34687501192092896, "episode/reward_rate": 0.004761904761904762, "episode/intrinsic_return": 0.0}
{"step": 989640, "time": 30842.608568668365, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 989888, "time": 30850.314081668854, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 989968, "time": 30852.944622516632, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 990000, "time": 30853.9326941967, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 990024, "time": 30854.45496916771, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 990040, "time": 30854.973574638367, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 990080, "time": 30857.213249206543, "eval_episode/length": 41.0, "eval_episode/score": 0.871874988079071, "eval_episode/reward_rate": 0.023809523809523808}
{"step": 990080, "time": 30857.278099536896, "eval_episode/length": 44.0, "eval_episode/score": 0.862500011920929, "eval_episode/reward_rate": 0.022222222222222223}
{"step": 990080, "time": 30857.59995508194, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 990080, "time": 30857.7037525177, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 990080, "time": 30858.49548625946, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 990080, "time": 30858.52073788643, "eval_episode/length": 111.0, "eval_episode/score": 0.653124988079071, "eval_episode/reward_rate": 0.008928571428571428}
{"step": 990080, "time": 30859.348011016846, "eval_episode/length": 95.0, "eval_episode/score": 0.703125, "eval_episode/reward_rate": 0.010416666666666666}
{"step": 990080, "time": 30859.442672729492, "eval_episode/length": 162.0, "eval_episode/score": 0.4937500059604645, "eval_episode/reward_rate": 0.006134969325153374}
{"step": 990328, "time": 30866.887751579285, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 990416, "time": 30869.817761421204, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 990472, "time": 30871.286360263824, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 990624, "time": 30876.107815265656, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 990656, "time": 30877.07390475273, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 990832, "time": 30882.414166927338, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 990984, "time": 30886.782268047333, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 991040, "time": 30888.716101646423, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 991336, "time": 30898.059426784515, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 991496, "time": 30902.889602422714, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 991832, "time": 30913.01415991783, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 991904, "time": 30915.401274442673, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 992104, "time": 30921.235620737076, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 992152, "time": 30922.70148730278, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 992312, "time": 30927.676203489304, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 992360, "time": 30929.124095916748, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 992376, "time": 30929.609493732452, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 992424, "time": 30931.057473897934, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 992512, "time": 30933.952325105667, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 992944, "time": 30947.00838160515, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 993040, "time": 30949.88384604454, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 993072, "time": 30950.871883392334, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 993144, "time": 30952.81410098076, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 993160, "time": 30953.301627874374, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 993168, "time": 30953.768496751785, "episode/length": 208.0, "episode/score": 0.3499999940395355, "episode/reward_rate": 0.004784688995215311, "episode/intrinsic_return": 0.0}
{"step": 993360, "time": 30959.670673131943, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 993536, "time": 30964.98481655121, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 993568, "time": 30965.975265979767, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 993688, "time": 30969.373334407806, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 993712, "time": 30970.345683574677, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 993760, "time": 30971.79495024681, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 993936, "time": 30977.110194921494, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 994024, "time": 30979.545843839645, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 994032, "time": 30980.030614852905, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 994128, "time": 30982.91179871559, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 994184, "time": 30984.382231473923, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 994296, "time": 30987.874052524567, "episode/length": 20.0, "episode/score": 0.9375, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.0}
{"step": 994344, "time": 30989.328353643417, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 994440, "time": 30992.248232603073, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 994672, "time": 30999.49216246605, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 994696, "time": 30999.999632120132, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 994760, "time": 31001.922934532166, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 994944, "time": 31007.698340654373, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 995152, "time": 31013.978038072586, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 995272, "time": 31017.47097635269, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 995536, "time": 31025.760895967484, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 995656, "time": 31029.236452817917, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 995768, "time": 31032.62931251526, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 995920, "time": 31037.430584669113, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 996344, "time": 31050.111567258835, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 996584, "time": 31057.354692459106, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 996616, "time": 31058.341103315353, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 996752, "time": 31062.675711393356, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 996888, "time": 31066.561543226242, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 997008, "time": 31070.40852165222, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 997104, "time": 31073.31404185295, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 997464, "time": 31084.044100761414, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 997584, "time": 31087.87401151657, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 997696, "time": 31091.2245721817, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 997848, "time": 31095.590363502502, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 997896, "time": 31097.058571338654, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 998008, "time": 31100.425814151764, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 998200, "time": 31106.333272457123, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 998344, "time": 31110.635390520096, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 998408, "time": 31112.568192005157, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 998864, "time": 31126.469668149948, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 998928, "time": 31128.386705875397, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 999064, "time": 31132.261481285095, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 999088, "time": 31133.209539413452, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 999128, "time": 31134.201899051666, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 999208, "time": 31136.7535238266, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 999272, "time": 31138.710453748703, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 999288, "time": 31139.19678926468, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 999816, "time": 31155.635713100433, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 999832, "time": 31156.128095149994, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 999952, "time": 31159.977834939957, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1000008, "time": 31161.441246509552, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1000040, "time": 31162.408605098724, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1000040, "time": 31162.417461395264, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1000064, "time": 31165.007017850876, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 1000064, "time": 31165.405743598938, "eval_episode/length": 104.0, "eval_episode/score": 0.675000011920929, "eval_episode/reward_rate": 0.009523809523809525}
{"step": 1000064, "time": 31165.575125455856, "eval_episode/length": 113.0, "eval_episode/score": 0.6468750238418579, "eval_episode/reward_rate": 0.008771929824561403}
{"step": 1000064, "time": 31165.617954969406, "eval_episode/length": 115.0, "eval_episode/score": 0.640625, "eval_episode/reward_rate": 0.008620689655172414}
{"step": 1000064, "time": 31166.158507823944, "eval_episode/length": 145.0, "eval_episode/score": 0.546875, "eval_episode/reward_rate": 0.00684931506849315}
{"step": 1000064, "time": 31166.944931983948, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 1000064, "time": 31167.721457719803, "eval_episode/length": 146.0, "eval_episode/score": 0.543749988079071, "eval_episode/reward_rate": 0.006802721088435374}
{"step": 1000064, "time": 31167.904586076736, "eval_episode/length": 53.0, "eval_episode/score": 0.8343750238418579, "eval_episode/reward_rate": 0.018518518518518517}
{"step": 1000128, "time": 31169.85630249977, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1000208, "time": 31172.27278327942, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1000608, "time": 31184.370184659958, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1000656, "time": 31185.82185792923, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1000664, "time": 31185.85040307045, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1000672, "time": 31186.315469264984, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1000808, "time": 31190.195319652557, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1001104, "time": 31199.445075035095, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1001128, "time": 31199.955085277557, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1001224, "time": 31202.852204084396, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1001336, "time": 31206.26066350937, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1001352, "time": 31206.759462356567, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1001752, "time": 31218.83418750763, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1001776, "time": 31219.785408735275, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1001936, "time": 31224.622297763824, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0}
{"step": 1002041, "time": 31228.66072654724, "train_stats/mean_log_entropy": 0.07749345250953282, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.5649543348791566, "train/action_min": 0.0, "train/action_std": 1.9012354794394206, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.008667183863320228, "train/actor_opt_grad_steps": 61520.0, "train/actor_opt_loss": -12.684208036056294, "train/adv_mag": 0.9517352933366897, "train/adv_max": 0.3235229934964861, "train/adv_mean": 0.0013462463398914918, "train/adv_min": -0.8819446598954976, "train/adv_std": 0.024827725465037847, "train/cont_avg": 0.9944292641625616, "train/cont_loss_mean": 0.020417446670870254, "train/cont_loss_std": 0.2500057178939431, "train/cont_neg_acc": 0.2572581959622247, "train/cont_neg_loss": 2.848741985803293, "train/cont_pos_acc": 0.9999031894312703, "train/cont_pos_loss": 0.004267399502674971, "train/cont_pred": 0.994415917126416, "train/cont_rate": 0.9944292641625616, "train/dyn_loss_mean": 1.0000056674327757, "train/dyn_loss_std": 4.898101569375876e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.09357628692859059, "train/extr_critic_critic_opt_grad_steps": 61520.0, "train/extr_critic_critic_opt_loss": 9582.432357412254, "train/extr_critic_mag": 1.5851753051645063, "train/extr_critic_max": 1.5851753051645063, "train/extr_critic_mean": 1.491712685289054, "train/extr_critic_min": 1.1542993830929835, "train/extr_critic_std": 0.024958529908742224, "train/extr_return_normed_mag": 0.975503906827842, "train/extr_return_normed_max": 0.26647825487728777, "train/extr_return_normed_mean": 0.047669743082206235, "train/extr_return_normed_min": -0.9050006901689351, "train/extr_return_normed_std": 0.035835664682640815, "train/extr_return_rate": 0.9996911889226566, "train/extr_return_raw_mag": 1.7118674140845613, "train/extr_return_raw_max": 1.7118674140845613, "train/extr_return_raw_mean": 1.493058969821836, "train/extr_return_raw_min": 0.5403884690383385, "train/extr_return_raw_std": 0.035835664700992004, "train/extr_reward_mag": 0.24353454148240863, "train/extr_reward_max": 0.24353454148240863, "train/extr_reward_mean": 0.0024261054481962336, "train/extr_reward_min": 1.1744757591209976e-08, "train/extr_reward_std": 0.007868474079846529, "train/image_loss_mean": 0.08773114295502014, "train/image_loss_std": 0.10316621453450818, "train/model_loss_mean": 0.7256321769042555, "train/model_loss_std": 0.4964098198146656, "train/model_opt_grad_norm": 17.537827519947673, "train/model_opt_grad_steps": 61466.02463054187, "train/model_opt_loss": 3878.640028479064, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5344.827586206897, "train/policy_entropy_mag": 1.2828030263261843, "train/policy_entropy_max": 1.2828030263261843, "train/policy_entropy_mean": 0.08990840544107512, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.10730858264591893, "train/policy_logprob_mag": 6.5510802386429505, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.08975589268019633, "train/policy_logprob_min": -6.5510802386429505, "train/policy_logprob_std": 0.6267304317704563, "train/policy_randomness_mag": 0.6592303890312834, "train/policy_randomness_max": 0.6592303890312834, "train/policy_randomness_mean": 0.0462037825342176, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.05514570593540304, "train/post_ent_mag": 43.806841469750616, "train/post_ent_max": 43.806841469750616, "train/post_ent_mean": 33.39174899209309, "train/post_ent_min": 28.07426281633048, "train/post_ent_std": 3.1255999339625165, "train/prior_ent_mag": 43.18433479722498, "train/prior_ent_max": 43.18433479722498, "train/prior_ent_mean": 33.78566445035887, "train/prior_ent_min": 28.127061082811778, "train/prior_ent_std": 2.8110762816931816, "train/rep_loss_mean": 1.0000056674327757, "train/rep_loss_std": 4.898101569375876e-05, "train/reward_avg": 0.0023169907425264163, "train/reward_loss_mean": 0.017480159665829515, "train/reward_loss_std": 0.2438348939646898, "train/reward_max_data": 0.7707666252634208, "train/reward_max_pred": 0.19248564431232773, "train/reward_neg_acc": 0.9997779724045928, "train/reward_neg_loss": 0.0031503361045942626, "train/reward_pos_acc": 0.08905240616307186, "train/reward_pos_loss": 4.1650416863024535, "train/reward_pred": 0.00177489539661119, "train/reward_rate": 0.00342037407635468, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.019458185881376266, "report/cont_loss_std": 0.28529882431030273, "report/cont_neg_acc": 0.25, "report/cont_neg_loss": 3.806575298309326, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.004606744274497032, "report/cont_pred": 0.99458909034729, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.07402316480875015, "report/image_loss_std": 0.09316089749336243, "report/model_loss_mean": 0.7046869993209839, "report/model_loss_std": 0.4386570453643799, "report/post_ent_mag": 41.899559020996094, "report/post_ent_max": 41.899559020996094, "report/post_ent_mean": 33.04137420654297, "report/post_ent_min": 27.913774490356445, "report/post_ent_std": 2.8011860847473145, "report/prior_ent_mag": 43.1330680847168, "report/prior_ent_max": 43.1330680847168, "report/prior_ent_mean": 33.611473083496094, "report/prior_ent_min": 28.186321258544922, "report/prior_ent_std": 2.9274158477783203, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0009033202659338713, "report/reward_loss_mean": 0.011205658316612244, "report/reward_loss_std": 0.21420525014400482, "report/reward_max_data": 0.574999988079071, "report/reward_max_pred": 0.6230480670928955, "report/reward_neg_acc": 0.9990215301513672, "report/reward_neg_loss": 0.003966100513935089, "report/reward_pos_acc": 0.5, "report/reward_pos_loss": 3.7106196880340576, "report/reward_pred": 0.0025153968017548323, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.025170328095555305, "eval/cont_loss_std": 0.3711734414100647, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.295733451843262, "eval/cont_pos_acc": 0.999020516872406, "eval/cont_pos_loss": 0.006745559629052877, "eval/cont_pred": 0.9958723783493042, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.12571826577186584, "eval/image_loss_std": 0.14413173496723175, "eval/model_loss_mean": 0.7736577987670898, "eval/model_loss_std": 0.7802680730819702, "eval/post_ent_mag": 41.8673210144043, "eval/post_ent_max": 41.8673210144043, "eval/post_ent_mean": 33.030479431152344, "eval/post_ent_min": 28.399559020996094, "eval/post_ent_std": 2.830564498901367, "eval/prior_ent_mag": 42.92756652832031, "eval/prior_ent_max": 42.92756652832031, "eval/prior_ent_mean": 33.523521423339844, "eval/prior_ent_min": 27.980884552001953, "eval/prior_ent_std": 2.9875168800354004, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0011352539295330644, "eval/reward_loss_mean": 0.022769184783101082, "eval/reward_loss_std": 0.43911030888557434, "eval/reward_max_data": 0.699999988079071, "eval/reward_max_pred": 0.4836341142654419, "eval/reward_neg_acc": 0.9990215301513672, "eval/reward_neg_loss": 0.005825700704008341, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 8.680889129638672, "eval/reward_pred": 0.0015329119050875306, "eval/reward_rate": 0.001953125, "replay/size": 1000000.0, "replay/inserts": 32432.0, "replay/samples": 32432.0, "replay/insert_wait_avg": 1.3310037696661476e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.172923023617203e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5504.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0824134183484454e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.940696716308594e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1754634380341, "timer/env.step_count": 4054.0, "timer/env.step_total": 38.391778230667114, "timer/env.step_frac": 0.03838504305904289, "timer/env.step_avg": 0.009470098231540975, "timer/env.step_min": 0.0075778961181640625, "timer/env.step_max": 0.03910684585571289, "timer/replay._sample_count": 32432.0, "timer/replay._sample_total": 16.222668647766113, "timer/replay._sample_frac": 0.01621982266191755, "timer/replay._sample_avg": 0.0005002056193810469, "timer/replay._sample_min": 0.00040531158447265625, "timer/replay._sample_max": 0.025812149047851562, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4742.0, "timer/agent.policy_total": 48.8927686214447, "timer/agent.policy_frac": 0.048884191233185416, "timer/agent.policy_avg": 0.010310579633370879, "timer/agent.policy_min": 0.008670568466186523, "timer/agent.policy_max": 0.07880187034606934, "timer/dataset_train_count": 2027.0, "timer/dataset_train_total": 0.21904420852661133, "timer/dataset_train_frac": 0.00021900578101932434, "timer/dataset_train_avg": 0.00010806325038313336, "timer/dataset_train_min": 9.417533874511719e-05, "timer/dataset_train_max": 0.00109100341796875, "timer/agent.train_count": 2027.0, "timer/agent.train_total": 900.5418424606323, "timer/agent.train_frac": 0.900383858013355, "timer/agent.train_avg": 0.4442732325903465, "timer/agent.train_min": 0.4335653781890869, "timer/agent.train_max": 0.8112127780914307, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4793226718902588, "timer/agent.report_frac": 0.0004792385830408399, "timer/agent.report_avg": 0.2396613359451294, "timer/agent.report_min": 0.2318732738494873, "timer/agent.report_max": 0.24744939804077148, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.2901763916015625e-05, "timer/dataset_eval_frac": 3.2895991872184194e-08, "timer/dataset_eval_avg": 3.2901763916015625e-05, "timer/dataset_eval_min": 3.2901763916015625e-05, "timer/dataset_eval_max": 3.2901763916015625e-05, "fps": 32.42577108512506}
{"step": 1002184, "time": 31232.730925798416, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1002224, "time": 31234.178780794144, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1002296, "time": 31236.129199504852, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1002816, "time": 31252.046766757965, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1002816, "time": 31252.05425810814, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1002904, "time": 31254.50925731659, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1002920, "time": 31255.05866599083, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1002968, "time": 31256.5434384346, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1003296, "time": 31266.629675388336, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1003536, "time": 31273.884488105774, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1003552, "time": 31274.37237739563, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1003696, "time": 31278.7269551754, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1003744, "time": 31280.179219961166, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1003752, "time": 31280.20784163475, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 1003808, "time": 31282.13080406189, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1003968, "time": 31287.053444862366, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1004192, "time": 31293.821387052536, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1004304, "time": 31297.217257738113, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1004536, "time": 31304.0337100029, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1004752, "time": 31310.78907585144, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1004760, "time": 31310.816252231598, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1005232, "time": 31325.455515623093, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1005424, "time": 31331.261559963226, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1005448, "time": 31331.773814439774, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1005608, "time": 31336.611129045486, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1005640, "time": 31337.58307814598, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1005800, "time": 31342.41987347603, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1006056, "time": 31350.273140192032, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1006256, "time": 31356.576069831848, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1006280, "time": 31357.087913036346, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1006448, "time": 31362.400544404984, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1006504, "time": 31363.88777732849, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1006600, "time": 31366.832255125046, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1006848, "time": 31374.5784368515, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1006848, "time": 31374.585269212723, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1006952, "time": 31377.577322006226, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1006952, "time": 31377.58380818367, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1006960, "time": 31378.05070233345, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1007304, "time": 31388.2426674366, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1007328, "time": 31389.211262464523, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 1007440, "time": 31392.574300527573, "episode/length": 13.0, "episode/score": 0.9593750238418579, "episode/reward_rate": 0.07142857142857142, "episode/intrinsic_return": 0.0}
{"step": 1007688, "time": 31400.31785607338, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1007768, "time": 31402.722909927368, "episode/length": 245.0, "episode/score": 0.234375, "episode/reward_rate": 0.0040650406504065045, "episode/intrinsic_return": 0.0}
{"step": 1007888, "time": 31406.739968776703, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1007976, "time": 31409.205678462982, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1008256, "time": 31417.96035695076, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1008256, "time": 31417.96874690056, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 1008376, "time": 31421.409991025925, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1008432, "time": 31423.370283842087, "episode/length": 197.0, "episode/score": 0.3843750059604645, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.0}
{"step": 1008576, "time": 31427.722824811935, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1008896, "time": 31437.49359178543, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1008920, "time": 31438.02568268776, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1009192, "time": 31446.26221847534, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1009264, "time": 31448.67674803734, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1009272, "time": 31448.70703625679, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1009568, "time": 31457.927359819412, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1009616, "time": 31459.38792657852, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1009616, "time": 31459.396654605865, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1009624, "time": 31459.425285339355, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1009736, "time": 31462.84596133232, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1009784, "time": 31464.3096473217, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1009944, "time": 31469.28547811508, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1010008, "time": 31471.225968122482, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1010016, "time": 31471.69574522972, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 1010048, "time": 31473.787454128265, "eval_episode/length": 22.0, "eval_episode/score": 0.9312499761581421, "eval_episode/reward_rate": 0.043478260869565216}
{"step": 1010048, "time": 31474.621314764023, "eval_episode/length": 63.0, "eval_episode/score": 0.8031250238418579, "eval_episode/reward_rate": 0.015625}
{"step": 1010048, "time": 31475.057639837265, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 1010048, "time": 31475.0846991539, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 1010048, "time": 31475.34954881668, "eval_episode/length": 99.0, "eval_episode/score": 0.690625011920929, "eval_episode/reward_rate": 0.01}
{"step": 1010048, "time": 31475.608250379562, "eval_episode/length": 112.0, "eval_episode/score": 0.6499999761581421, "eval_episode/reward_rate": 0.008849557522123894}
{"step": 1010048, "time": 31476.602239847183, "eval_episode/length": 99.0, "eval_episode/score": 0.690625011920929, "eval_episode/reward_rate": 0.01}
{"step": 1010048, "time": 31476.628696918488, "eval_episode/length": 164.0, "eval_episode/score": 0.48750001192092896, "eval_episode/reward_rate": 0.006060606060606061}
{"step": 1010448, "time": 31488.766853570938, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1010480, "time": 31489.736518383026, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1010576, "time": 31492.64413499832, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1010696, "time": 31496.17970609665, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1010872, "time": 31501.526651382446, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1011032, "time": 31506.374968528748, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1011480, "time": 31519.927783489227, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1011576, "time": 31522.83347415924, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1011832, "time": 31530.744512081146, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1011928, "time": 31533.652921915054, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1011928, "time": 31533.661631584167, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1012056, "time": 31537.567685842514, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1012304, "time": 31545.342221021652, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 1012384, "time": 31547.762412548065, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1012552, "time": 31552.636211395264, "episode/length": 231.0, "episode/score": 0.27812498807907104, "episode/reward_rate": 0.004310344827586207, "episode/intrinsic_return": 0.0}
{"step": 1012760, "time": 31559.039041519165, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1012768, "time": 31559.50763940811, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1012800, "time": 31560.48091363907, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1012912, "time": 31563.875971078873, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 1012920, "time": 31563.90367603302, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1012960, "time": 31565.340691804886, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1013128, "time": 31570.213831424713, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 1013320, "time": 31576.01139640808, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1013576, "time": 31583.77894759178, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1013592, "time": 31584.27064538002, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1013776, "time": 31590.202278614044, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1013832, "time": 31591.688492298126, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1013960, "time": 31595.595449447632, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1014008, "time": 31597.051928520203, "episode/length": 21.0, "episode/score": 0.934374988079071, "episode/reward_rate": 0.045454545454545456, "episode/intrinsic_return": 0.0}
{"step": 1014064, "time": 31598.997064828873, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1014568, "time": 31614.12391614914, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1014696, "time": 31618.13997578621, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1014768, "time": 31620.555554151535, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1014784, "time": 31621.052683353424, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1014968, "time": 31626.448018074036, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1015080, "time": 31629.873157262802, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1015104, "time": 31630.825484275818, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 1015160, "time": 31632.32515192032, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 1015536, "time": 31643.98303246498, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1015608, "time": 31646.024650096893, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 1015632, "time": 31646.994323968887, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1015784, "time": 31651.346922159195, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1015848, "time": 31653.76948595047, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1015984, "time": 31658.10789489746, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1016040, "time": 31659.572329044342, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1016192, "time": 31664.401309251785, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1016216, "time": 31664.91172194481, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1016440, "time": 31671.688465833664, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1016520, "time": 31674.099001407623, "episode/length": 227.0, "episode/score": 0.2906250059604645, "episode/reward_rate": 0.0043859649122807015, "episode/intrinsic_return": 0.0}
{"step": 1016640, "time": 31678.036665439606, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1017032, "time": 31689.665165662766, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1017064, "time": 31690.636308193207, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1017192, "time": 31694.50727081299, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1017248, "time": 31696.438269615173, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1017280, "time": 31697.40461206436, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1017632, "time": 31708.15550994873, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1018008, "time": 31719.33416199684, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1018280, "time": 31727.55970978737, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1018336, "time": 31729.469491243362, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1018352, "time": 31729.976296424866, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1018528, "time": 31735.354259967804, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1018744, "time": 31741.633620738983, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1018952, "time": 31747.921439647675, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1019072, "time": 31751.76415205002, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1019128, "time": 31753.2293343544, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1019344, "time": 31759.98939561844, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1019344, "time": 31759.997742652893, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1019504, "time": 31764.828184366226, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1019600, "time": 31767.802478790283, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1019824, "time": 31774.58518242836, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1019992, "time": 31779.449602365494, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1020032, "time": 31781.035843133926, "eval_episode/length": 7.0, "eval_episode/score": 0.9781249761581421, "eval_episode/reward_rate": 0.125}
{"step": 1020032, "time": 31781.743423461914, "eval_episode/length": 47.0, "eval_episode/score": 0.8531249761581421, "eval_episode/reward_rate": 0.020833333333333332}
{"step": 1020032, "time": 31781.955552339554, "eval_episode/length": 59.0, "eval_episode/score": 0.815625011920929, "eval_episode/reward_rate": 0.016666666666666666}
{"step": 1020032, "time": 31782.13415670395, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 1020032, "time": 31782.139753580093, "eval_episode/length": 21.0, "eval_episode/score": 0.934374988079071, "eval_episode/reward_rate": 0.045454545454545456}
{"step": 1020032, "time": 31782.30608534813, "eval_episode/length": 70.0, "eval_episode/score": 0.78125, "eval_episode/reward_rate": 0.014084507042253521}
{"step": 1020032, "time": 31782.331167936325, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 1020032, "time": 31782.8258831501, "eval_episode/length": 106.0, "eval_episode/score": 0.668749988079071, "eval_episode/reward_rate": 0.009345794392523364}
{"step": 1020096, "time": 31784.75252556801, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 1020192, "time": 31787.66267132759, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1020400, "time": 31793.927614688873, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1020424, "time": 31794.434530973434, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1020592, "time": 31799.866845607758, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1020648, "time": 31801.34934258461, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1021104, "time": 31815.35255074501, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1021136, "time": 31816.323850393295, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1021440, "time": 31825.613531589508, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1021656, "time": 31831.91707611084, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1021784, "time": 31835.79806995392, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 1021784, "time": 31835.805078029633, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1022120, "time": 31845.967853307724, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 1022240, "time": 31849.816828489304, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1022336, "time": 31852.71307349205, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1022408, "time": 31854.67950320244, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1022560, "time": 31859.639936208725, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1022736, "time": 31864.954571723938, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1022736, "time": 31864.96110200882, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1022824, "time": 31867.392263889313, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1023112, "time": 31876.07432126999, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1023136, "time": 31877.020735502243, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1023320, "time": 31882.366386175156, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1023416, "time": 31885.34857583046, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1023448, "time": 31886.316819429398, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1023696, "time": 31894.041472673416, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1023944, "time": 31901.272533416748, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 1024128, "time": 31907.54938197136, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1024216, "time": 31909.99111032486, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 1024376, "time": 31914.831881284714, "episode/length": 204.0, "episode/score": 0.36250001192092896, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.0}
{"step": 1024488, "time": 31918.335104703903, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 1024552, "time": 31920.26576757431, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1024856, "time": 31929.432778596878, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1025264, "time": 31942.0110476017, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1025304, "time": 31943.011479616165, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1025424, "time": 31946.946068048477, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1025424, "time": 31946.957044124603, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1025448, "time": 31947.468648195267, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1025632, "time": 31953.237866401672, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1025800, "time": 31958.092911958694, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1025816, "time": 31958.579191446304, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1026048, "time": 31965.85391640663, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1026136, "time": 31968.286622285843, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1026224, "time": 31971.167899370193, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 1026256, "time": 31972.134581565857, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1026512, "time": 31979.956894397736, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1026528, "time": 31980.44376397133, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1026544, "time": 31980.93040919304, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1026696, "time": 31985.298679351807, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1026992, "time": 31994.469435214996, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1027176, "time": 31999.81554698944, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1027296, "time": 32003.644946813583, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1027432, "time": 32007.645664453506, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 1027472, "time": 32009.091114282608, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1027512, "time": 32010.07772421837, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1027552, "time": 32011.505942106247, "episode/length": 9.0, "episode/score": 0.971875011920929, "episode/reward_rate": 0.1, "episode/intrinsic_return": 0.0}
{"step": 1027552, "time": 32011.51283454895, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1027560, "time": 32011.54007601738, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1027648, "time": 32014.424823760986, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1027712, "time": 32016.35196018219, "episode/length": 19.0, "episode/score": 0.940625011920929, "episode/reward_rate": 0.05, "episode/intrinsic_return": 0.0}
{"step": 1027944, "time": 32023.129754781723, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1028256, "time": 32032.744936704636, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1028392, "time": 32036.796810150146, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1028504, "time": 32040.19767642021, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1028520, "time": 32040.68926715851, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1028568, "time": 32042.143689870834, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1028584, "time": 32042.633322000504, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1028744, "time": 32047.47380757332, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 1028840, "time": 32050.383189439774, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1028872, "time": 32051.35129261017, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1029128, "time": 32059.088376522064, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1029224, "time": 32061.98109316826, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1029288, "time": 32063.930135965347, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1029304, "time": 32064.42239499092, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1029344, "time": 32065.974640846252, "episode/length": 14.0, "episode/score": 0.956250011920929, "episode/reward_rate": 0.06666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1029352, "time": 32066.003234386444, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1029656, "time": 32075.158759117126, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1029680, "time": 32076.10324072838, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1029768, "time": 32078.55067896843, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1029992, "time": 32085.302570581436, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1030000, "time": 32085.771829366684, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1030016, "time": 32086.893179893494, "eval_episode/length": 34.0, "eval_episode/score": 0.893750011920929, "eval_episode/reward_rate": 0.02857142857142857}
{"step": 1030016, "time": 32088.312872171402, "eval_episode/length": 114.0, "eval_episode/score": 0.643750011920929, "eval_episode/reward_rate": 0.008695652173913044}
{"step": 1030016, "time": 32088.53496479988, "eval_episode/length": 126.0, "eval_episode/score": 0.606249988079071, "eval_episode/reward_rate": 0.007874015748031496}
{"step": 1030016, "time": 32088.561180591583, "eval_episode/length": 127.0, "eval_episode/score": 0.6031249761581421, "eval_episode/reward_rate": 0.0078125}
{"step": 1030016, "time": 32088.981029748917, "eval_episode/length": 150.0, "eval_episode/score": 0.53125, "eval_episode/reward_rate": 0.006622516556291391}
{"step": 1030016, "time": 32089.535087108612, "eval_episode/length": 146.0, "eval_episode/score": 0.543749988079071, "eval_episode/reward_rate": 0.006802721088435374}
{"step": 1030016, "time": 32089.719665765762, "eval_episode/length": 63.0, "eval_episode/score": 0.8031250238418579, "eval_episode/reward_rate": 0.015625}
{"step": 1030016, "time": 32091.4068274498, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1030016, "time": 32091.413999795914, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1030016, "time": 32091.42077732086, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1030048, "time": 32092.407958984375, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1030320, "time": 32100.672604084015, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1030672, "time": 32111.314972877502, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1030744, "time": 32113.26804113388, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1030816, "time": 32115.661951303482, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1031016, "time": 32121.4927816391, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1031120, "time": 32124.845497846603, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 1031184, "time": 32126.89939236641, "episode/length": 20.0, "episode/score": 0.9375, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.0}
{"step": 1031656, "time": 32140.91785812378, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1031656, "time": 32140.926215410233, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1031904, "time": 32148.647088766098, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 1031936, "time": 32149.62412571907, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1031960, "time": 32150.152141571045, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 1031968, "time": 32150.623085021973, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1032040, "time": 32152.57242321968, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1032232, "time": 32158.934722185135, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 1032304, "time": 32161.346083402634, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1032400, "time": 32164.238099336624, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1032432, "time": 32165.224746465683, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1032632, "time": 32171.118084669113, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1032728, "time": 32174.0080909729, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 1032792, "time": 32175.962333202362, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1033008, "time": 32182.697414159775, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 1033128, "time": 32186.241213083267, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1033200, "time": 32188.665195465088, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1033216, "time": 32189.165217638016, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1033368, "time": 32193.620596647263, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 1033552, "time": 32199.452467679977, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 1033720, "time": 32204.31600379944, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1033880, "time": 32209.155289173126, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1034136, "time": 32217.027578353882, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1034192, "time": 32218.966383695602, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1034320, "time": 32222.834543704987, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1034489, "time": 32228.74457025528, "train_stats/mean_log_entropy": 0.07675208842538926, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.5569578869508045, "train/action_min": 0.0, "train/action_std": 1.8786438821565987, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.011193388667289573, "train/actor_opt_grad_steps": 63545.0, "train/actor_opt_loss": -14.020881775582192, "train/adv_mag": 1.0364489419625538, "train/adv_max": 0.3388950205085301, "train/adv_mean": 0.0008636174141942644, "train/adv_min": -0.9908592305561104, "train/adv_std": 0.0319584691528194, "train/cont_avg": 0.9940874458539604, "train/cont_loss_mean": 0.020950452967473113, "train/cont_loss_std": 0.25216549448207903, "train/cont_neg_acc": 0.26545655129864665, "train/cont_neg_loss": 2.77765155690872, "train/cont_pos_acc": 0.9999027798081389, "train/cont_pos_loss": 0.00440347358748077, "train/cont_pred": 0.9941427123428571, "train/cont_rate": 0.9940874458539604, "train/dyn_loss_mean": 1.000001059310271, "train/dyn_loss_std": 3.113629674483644e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.12435349836797997, "train/extr_critic_critic_opt_grad_steps": 63545.0, "train/extr_critic_critic_opt_loss": 6589.535569596998, "train/extr_critic_mag": 1.622188939906583, "train/extr_critic_max": 1.622188939906583, "train/extr_critic_mean": 1.5298131303031846, "train/extr_critic_min": 1.1807888280047047, "train/extr_critic_std": 0.025325874530590407, "train/extr_return_normed_mag": 1.060609953533305, "train/extr_return_normed_max": 0.2861611772291731, "train/extr_return_normed_mean": 0.047365497521097116, "train/extr_return_normed_min": -1.0008268182230469, "train/extr_return_normed_std": 0.0420161346619082, "train/extr_return_rate": 0.9994879061042672, "train/extr_return_raw_mag": 1.769472352939077, "train/extr_return_raw_max": 1.769472352939077, "train/extr_return_raw_mean": 1.530676746722495, "train/extr_return_raw_min": 0.48248435748685703, "train/extr_return_raw_std": 0.04201613456047702, "train/extr_reward_mag": 0.26843135191662476, "train/extr_reward_max": 0.26843135191662476, "train/extr_reward_mean": 0.0024814755381499924, "train/extr_reward_min": 4.190029484210628e-08, "train/extr_reward_std": 0.008934539560652753, "train/image_loss_mean": 0.08820074848314323, "train/image_loss_std": 0.10342281595757692, "train/model_loss_mean": 0.7275800961669129, "train/model_loss_std": 0.5060031721276221, "train/model_opt_grad_norm": 17.341305081206972, "train/model_opt_grad_steps": 63489.10396039604, "train/model_opt_loss": 3817.5599075166306, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5247.524752475248, "train/policy_entropy_mag": 1.2621570937704332, "train/policy_entropy_max": 1.2621570937704332, "train/policy_entropy_mean": 0.0885099387257406, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.10405817192674864, "train/policy_logprob_mag": 6.551080262306893, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.08828024802231553, "train/policy_logprob_min": -6.551080262306893, "train/policy_logprob_std": 0.6245980315869397, "train/policy_randomness_mag": 0.6486204762269955, "train/policy_randomness_max": 0.6486204762269955, "train/policy_randomness_mean": 0.04548511285297942, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.0534753252632252, "train/post_ent_mag": 43.54683409586991, "train/post_ent_max": 43.54683409586991, "train/post_ent_mean": 33.61330051233273, "train/post_ent_min": 28.184257497881898, "train/post_ent_std": 3.069157566174422, "train/prior_ent_mag": 43.839733180433214, "train/prior_ent_max": 43.839733180433214, "train/prior_ent_mean": 33.874727891223266, "train/prior_ent_min": 27.677781105041504, "train/prior_ent_std": 3.070348006663936, "train/rep_loss_mean": 1.000001059310271, "train/rep_loss_std": 3.113629674483644e-05, "train/reward_avg": 0.0025545176859751418, "train/reward_loss_mean": 0.018428235065819015, "train/reward_loss_std": 0.25066755876627445, "train/reward_max_data": 0.8002629954330992, "train/reward_max_pred": 0.2552527956443258, "train/reward_neg_acc": 0.9996845731050661, "train/reward_neg_loss": 0.003238221722664219, "train/reward_pos_acc": 0.14213456710179648, "train/reward_pos_loss": 4.029005334151918, "train/reward_pred": 0.001921053053142669, "train/reward_rate": 0.0037660504331683167, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.014457270503044128, "report/cont_loss_std": 0.23763620853424072, "report/cont_neg_acc": 0.25, "report/cont_neg_loss": 2.743501663208008, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0037551349960267544, "report/cont_pred": 0.9948652386665344, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.0880996510386467, "report/image_loss_std": 0.11563608795404434, "report/model_loss_mean": 0.7104614973068237, "report/model_loss_std": 0.34758302569389343, "report/post_ent_mag": 41.82146453857422, "report/post_ent_max": 41.82146453857422, "report/post_ent_mean": 32.802486419677734, "report/post_ent_min": 27.943265914916992, "report/post_ent_std": 2.82572078704834, "report/prior_ent_mag": 43.58863830566406, "report/prior_ent_max": 43.58863830566406, "report/prior_ent_mean": 33.565765380859375, "report/prior_ent_min": 28.15176773071289, "report/prior_ent_std": 2.954948902130127, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0014068603049963713, "report/reward_loss_mean": 0.007904518395662308, "report/reward_loss_std": 0.13404659926891327, "report/reward_max_data": 0.8187500238418579, "report/reward_max_pred": 0.6587411165237427, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0029705630149692297, "report/reward_pos_acc": 0.5, "report/reward_pos_loss": 2.529155731201172, "report/reward_pred": 0.002209003083407879, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.0448283813893795, "eval/cont_loss_std": 0.7226206064224243, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 10.731598854064941, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.002919477876275778, "eval/cont_pred": 0.9970976114273071, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.10147817432880402, "eval/image_loss_std": 0.11546573042869568, "eval/model_loss_mean": 0.7555673718452454, "eval/model_loss_std": 0.7961044311523438, "eval/post_ent_mag": 41.786102294921875, "eval/post_ent_max": 41.786102294921875, "eval/post_ent_mean": 32.18901062011719, "eval/post_ent_min": 27.253612518310547, "eval/post_ent_std": 3.0996828079223633, "eval/prior_ent_mag": 43.550148010253906, "eval/prior_ent_max": 43.550148010253906, "eval/prior_ent_mean": 33.105018615722656, "eval/prior_ent_min": 26.880596160888672, "eval/prior_ent_std": 3.204674005508423, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0005065918085165322, "eval/reward_loss_mean": 0.009260783903300762, "eval/reward_loss_std": 0.22808605432510376, "eval/reward_max_data": 0.518750011920929, "eval/reward_max_pred": 0.03587770462036133, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0021337142679840326, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 7.300252914428711, "eval/reward_pred": 0.001095292391255498, "eval/reward_rate": 0.0009765625, "replay/size": 1000000.0, "replay/inserts": 32448.0, "replay/samples": 32448.0, "replay/insert_wait_avg": 1.2835131359288442e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.985517763292061e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4488.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1212260540368936e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.046627044677734e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0174083709717, "timer/env.step_count": 4056.0, "timer/env.step_total": 39.013434171676636, "timer/env.step_frac": 0.039012755023164564, "timer/env.step_avg": 0.009618696787888717, "timer/env.step_min": 0.007540464401245117, "timer/env.step_max": 0.035157203674316406, "timer/replay._sample_count": 32448.0, "timer/replay._sample_total": 16.24581789970398, "timer/replay._sample_frac": 0.016245535091402474, "timer/replay._sample_avg": 0.0005006723958242104, "timer/replay._sample_min": 0.0004134178161621094, "timer/replay._sample_max": 0.03284764289855957, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4617.0, "timer/agent.policy_total": 48.573848724365234, "timer/agent.policy_frac": 0.04857300314750723, "timer/agent.policy_avg": 0.010520651662197365, "timer/agent.policy_min": 0.009029150009155273, "timer/agent.policy_max": 0.1042945384979248, "timer/dataset_train_count": 2028.0, "timer/dataset_train_total": 0.22867321968078613, "timer/dataset_train_frac": 0.00022866923892184517, "timer/dataset_train_avg": 0.00011275799787021012, "timer/dataset_train_min": 9.918212890625e-05, "timer/dataset_train_max": 0.0010685920715332031, "timer/agent.train_count": 2028.0, "timer/agent.train_total": 900.9295163154602, "timer/agent.train_frac": 0.900913832873244, "timer/agent.train_avg": 0.44424532362695274, "timer/agent.train_min": 0.4332752227783203, "timer/agent.train_max": 0.6569969654083252, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4787454605102539, "timer/agent.report_frac": 0.0004787371264767583, "timer/agent.report_avg": 0.23937273025512695, "timer/agent.report_min": 0.2323760986328125, "timer/agent.report_max": 0.2463693618774414, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.409385681152344e-05, "timer/dataset_eval_frac": 3.4093263303348215e-08, "timer/dataset_eval_avg": 3.409385681152344e-05, "timer/dataset_eval_min": 3.409385681152344e-05, "timer/dataset_eval_max": 3.409385681152344e-05, "fps": 32.446838690047905}
{"step": 1034648, "time": 32233.292599201202, "episode/length": 204.0, "episode/score": 0.36250001192092896, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.0}
{"step": 1034824, "time": 32238.616714954376, "episode/length": 21.0, "episode/score": 0.934374988079071, "episode/reward_rate": 0.045454545454545456, "episode/intrinsic_return": 0.0}
{"step": 1034944, "time": 32242.462648153305, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1035072, "time": 32246.456215381622, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1035496, "time": 32259.083186388016, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 1035680, "time": 32264.885785102844, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1035720, "time": 32265.870614767075, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1035864, "time": 32270.222870111465, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1035896, "time": 32271.190207481384, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1035904, "time": 32271.65633583069, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1035936, "time": 32272.625974178314, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 1036032, "time": 32275.63884830475, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1036144, "time": 32279.082614183426, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1036288, "time": 32283.44586467743, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1036448, "time": 32288.273149967194, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1036480, "time": 32289.2415933609, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1036592, "time": 32292.619738817215, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 1036632, "time": 32293.600853204727, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1036688, "time": 32295.50448870659, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1036712, "time": 32296.013606071472, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1036856, "time": 32300.360103845596, "episode/length": 17.0, "episode/score": 0.9468749761581421, "episode/reward_rate": 0.05555555555555555, "episode/intrinsic_return": 0.0}
{"step": 1037064, "time": 32306.77223777771, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1037288, "time": 32313.555296182632, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1037304, "time": 32314.041746854782, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1037480, "time": 32319.352484226227, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1037576, "time": 32322.264851808548, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1037640, "time": 32324.2144882679, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1038072, "time": 32337.35185289383, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 1038096, "time": 32338.303440093994, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1038456, "time": 32348.965534210205, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1038584, "time": 32352.837000131607, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1038600, "time": 32353.322234630585, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1038720, "time": 32357.166531085968, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1038760, "time": 32358.154764652252, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1039344, "time": 32376.08611059189, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1039616, "time": 32384.30074954033, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1039792, "time": 32389.649279117584, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1039888, "time": 32392.5488615036, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1040000, "time": 32396.465771198273, "eval_episode/length": 22.0, "eval_episode/score": 0.9312499761581421, "eval_episode/reward_rate": 0.043478260869565216}
{"step": 1040000, "time": 32396.52536034584, "eval_episode/length": 25.0, "eval_episode/score": 0.921875, "eval_episode/reward_rate": 0.038461538461538464}
{"step": 1040000, "time": 32397.00016641617, "eval_episode/length": 50.0, "eval_episode/score": 0.84375, "eval_episode/reward_rate": 0.0196078431372549}
{"step": 1040000, "time": 32397.396946668625, "eval_episode/length": 70.0, "eval_episode/score": 0.78125, "eval_episode/reward_rate": 0.014084507042253521}
{"step": 1040000, "time": 32397.624003648758, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 1040000, "time": 32397.683310747147, "eval_episode/length": 85.0, "eval_episode/score": 0.734375, "eval_episode/reward_rate": 0.011627906976744186}
{"step": 1040000, "time": 32397.817364931107, "eval_episode/length": 41.0, "eval_episode/score": 0.871874988079071, "eval_episode/reward_rate": 0.023809523809523808}
{"step": 1040000, "time": 32398.36597752571, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 1040312, "time": 32407.5758934021, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1040728, "time": 32420.602991342545, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1040768, "time": 32422.047766685486, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1040912, "time": 32426.49431538582, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1040968, "time": 32427.96573972702, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1040984, "time": 32428.4557826519, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1041032, "time": 32429.916409015656, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1041072, "time": 32431.370723724365, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1041280, "time": 32437.659236192703, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1041408, "time": 32441.54057407379, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1041520, "time": 32444.906368494034, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1041624, "time": 32447.83347249031, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1041872, "time": 32455.61813235283, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1041928, "time": 32457.091390132904, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1042224, "time": 32466.269803524017, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 1042232, "time": 32466.297892570496, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 1042360, "time": 32470.162962436676, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1042512, "time": 32474.97193980217, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1042576, "time": 32476.899160385132, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1042936, "time": 32487.576524734497, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1042968, "time": 32488.545905828476, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1043040, "time": 32490.941938877106, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1043056, "time": 32491.430368185043, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1043240, "time": 32496.77822327614, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1043344, "time": 32500.143357038498, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1043496, "time": 32504.519396066666, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1043648, "time": 32509.327226161957, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1043720, "time": 32511.279578447342, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1043832, "time": 32514.689519166946, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1043896, "time": 32516.779270410538, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1043912, "time": 32517.27426958084, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1043936, "time": 32518.23742747307, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1044160, "time": 32525.02992773056, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1044232, "time": 32526.978526592255, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1044248, "time": 32527.465899944305, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1044320, "time": 32529.871220350266, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1044368, "time": 32531.31936788559, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1044432, "time": 32533.2686855793, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1044528, "time": 32536.16354036331, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 1044744, "time": 32542.435712575912, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 1045336, "time": 32560.445710897446, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1045344, "time": 32560.920547008514, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1045344, "time": 32560.92782998085, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1045440, "time": 32563.845697402954, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1045512, "time": 32565.806408166885, "episode/length": 196.0, "episode/score": 0.38749998807907104, "episode/reward_rate": 0.005076142131979695, "episode/intrinsic_return": 0.0}
{"step": 1046208, "time": 32587.206180095673, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1046328, "time": 32590.58280467987, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1046416, "time": 32593.482147216797, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1046472, "time": 32594.969857931137, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1046544, "time": 32597.39030098915, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1046560, "time": 32597.87931752205, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1046568, "time": 32597.90788125992, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1047168, "time": 32616.54027557373, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1047240, "time": 32618.499855041504, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1047320, "time": 32620.940427064896, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1047640, "time": 32630.654357671738, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 1047656, "time": 32631.1466588974, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1047672, "time": 32631.636889219284, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1047792, "time": 32635.62823653221, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 1048128, "time": 32645.761100530624, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1048344, "time": 32652.06037259102, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 1048520, "time": 32657.389395475388, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1048664, "time": 32662.2133975029, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1048688, "time": 32663.164416074753, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1048728, "time": 32664.155560970306, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1049080, "time": 32674.87463092804, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1049216, "time": 32679.169924736023, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1049288, "time": 32681.13482451439, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 1049440, "time": 32685.945041656494, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1049664, "time": 32692.74574661255, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1049952, "time": 32701.605153799057, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1049968, "time": 32702.095733642578, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1050088, "time": 32706.420205116272, "eval_episode/length": 49.0, "eval_episode/score": 0.846875011920929, "eval_episode/reward_rate": 0.02}
{"step": 1050088, "time": 32706.779579877853, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 1050088, "time": 32707.048713445663, "eval_episode/length": 84.0, "eval_episode/score": 0.737500011920929, "eval_episode/reward_rate": 0.011764705882352941}
{"step": 1050088, "time": 32707.212146282196, "eval_episode/length": 93.0, "eval_episode/score": 0.7093750238418579, "eval_episode/reward_rate": 0.010638297872340425}
{"step": 1050088, "time": 32707.89459824562, "eval_episode/length": 131.0, "eval_episode/score": 0.590624988079071, "eval_episode/reward_rate": 0.007575757575757576}
{"step": 1050088, "time": 32708.074018001556, "eval_episode/length": 141.0, "eval_episode/score": 0.559374988079071, "eval_episode/reward_rate": 0.007042253521126761}
{"step": 1050088, "time": 32708.186294317245, "eval_episode/length": 147.0, "eval_episode/score": 0.5406249761581421, "eval_episode/reward_rate": 0.006756756756756757}
{"step": 1050088, "time": 32708.862745523453, "eval_episode/length": 91.0, "eval_episode/score": 0.715624988079071, "eval_episode/reward_rate": 0.010869565217391304}
{"step": 1050144, "time": 32710.786290168762, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1050344, "time": 32716.63862681389, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1050440, "time": 32719.56427335739, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1050456, "time": 32720.057907819748, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1050656, "time": 32726.451123952866, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1050824, "time": 32731.34644651413, "episode/length": 191.0, "episode/score": 0.40312498807907104, "episode/reward_rate": 0.005208333333333333, "episode/intrinsic_return": 0.0}
{"step": 1051000, "time": 32736.7136926651, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1051016, "time": 32737.206428050995, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1051328, "time": 32746.902483701706, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1051336, "time": 32746.930802345276, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1051376, "time": 32748.365443468094, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1051392, "time": 32748.853991508484, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1051528, "time": 32753.396250247955, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1051576, "time": 32754.85289120674, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1051744, "time": 32760.29630637169, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1051976, "time": 32767.105864286423, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1052296, "time": 32776.78350806236, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1052464, "time": 32782.097427368164, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1052480, "time": 32782.59051322937, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1052544, "time": 32784.53497338295, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1052648, "time": 32787.559507369995, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 1052704, "time": 32789.481670856476, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1052920, "time": 32795.853407382965, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1052968, "time": 32797.316898822784, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1053176, "time": 32803.61464428902, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1053376, "time": 32809.86788034439, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1053536, "time": 32814.70209789276, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1053640, "time": 32817.76094198227, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 1053704, "time": 32819.693476200104, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1053808, "time": 32823.06359553337, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 1053840, "time": 32824.02973771095, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1053944, "time": 32826.96537542343, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 1054120, "time": 32832.259613752365, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1054128, "time": 32832.724225759506, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 1054512, "time": 32844.313032865524, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1054552, "time": 32845.39304590225, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 1054864, "time": 32855.06498122215, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1055208, "time": 32865.268246650696, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1055232, "time": 32866.214195013046, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1055296, "time": 32868.14571928978, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 1055400, "time": 32872.03182935715, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1055408, "time": 32872.50163078308, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1055952, "time": 32888.98408675194, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1056216, "time": 32896.714572668076, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1056256, "time": 32898.14786672592, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1056632, "time": 32909.357845783234, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1056816, "time": 32915.59218740463, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 1056960, "time": 32919.93912053108, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1057048, "time": 32922.36167263985, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 1057096, "time": 32923.8394548893, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1057176, "time": 32926.253121614456, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1057400, "time": 32933.059121370316, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1057520, "time": 32936.989780664444, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1057544, "time": 32937.50346279144, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1057608, "time": 32939.45996069908, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1057720, "time": 32942.86707639694, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1057800, "time": 32945.32675790787, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1058000, "time": 32951.58941030502, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1058008, "time": 32951.617629528046, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1058384, "time": 32963.21447825432, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1058400, "time": 32963.7036690712, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1058552, "time": 32968.20623135567, "episode/length": 20.0, "episode/score": 0.9375, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.0}
{"step": 1058792, "time": 32975.46459174156, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1058968, "time": 32980.79886221886, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1059176, "time": 32987.10587787628, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 1059192, "time": 32987.597282886505, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 1059360, "time": 32992.905012607574, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1059408, "time": 32994.35328912735, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1059832, "time": 33007.02062249184, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1059840, "time": 33007.48408341408, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1060072, "time": 33015.34453034401, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 1060072, "time": 33015.62390708923, "eval_episode/length": 76.0, "eval_episode/score": 0.762499988079071, "eval_episode/reward_rate": 0.012987012987012988}
{"step": 1060072, "time": 33015.66800761223, "eval_episode/length": 78.0, "eval_episode/score": 0.7562500238418579, "eval_episode/reward_rate": 0.012658227848101266}
{"step": 1060072, "time": 33015.78678703308, "eval_episode/length": 84.0, "eval_episode/score": 0.737500011920929, "eval_episode/reward_rate": 0.011764705882352941}
{"step": 1060072, "time": 33016.20744109154, "eval_episode/length": 107.0, "eval_episode/score": 0.6656249761581421, "eval_episode/reward_rate": 0.009259259259259259}
{"step": 1060072, "time": 33016.267444610596, "eval_episode/length": 31.0, "eval_episode/score": 0.903124988079071, "eval_episode/reward_rate": 0.03125}
{"step": 1060072, "time": 33016.53950428963, "eval_episode/length": 63.0, "eval_episode/score": 0.8031250238418579, "eval_episode/reward_rate": 0.015625}
{"step": 1060072, "time": 33016.65131878853, "eval_episode/length": 131.0, "eval_episode/score": 0.590624988079071, "eval_episode/reward_rate": 0.007575757575757576}
{"step": 1060112, "time": 33018.10379123688, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1060120, "time": 33018.1320772171, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 1060192, "time": 33020.52569818497, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1060296, "time": 33023.456854104996, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0}
{"step": 1060360, "time": 33025.49004364014, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1060784, "time": 33038.53131723404, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1060864, "time": 33040.93805932999, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1060976, "time": 33044.336208343506, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1061104, "time": 33048.216952085495, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1061160, "time": 33049.68270730972, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1061288, "time": 33053.554697752, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1061312, "time": 33054.50602602959, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1061376, "time": 33056.53231072426, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1061504, "time": 33060.40310764313, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1061656, "time": 33064.776935338974, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1061720, "time": 33066.73304629326, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1061880, "time": 33071.55840730667, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1061880, "time": 33071.56552672386, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1061904, "time": 33072.51616740227, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1062296, "time": 33084.17099261284, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1062320, "time": 33085.23080062866, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1062432, "time": 33088.63756418228, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1062584, "time": 33093.02882885933, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1062648, "time": 33094.960800886154, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 1062776, "time": 33098.95382475853, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1062840, "time": 33100.91501331329, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1063040, "time": 33107.197437524796, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1063176, "time": 33111.098638772964, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1063200, "time": 33112.04724884033, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1063200, "time": 33112.05440092087, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1063456, "time": 33119.87982201576, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1063648, "time": 33125.70021009445, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1063776, "time": 33129.53905963898, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1063896, "time": 33132.98673033714, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1064032, "time": 33137.40289592743, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1064352, "time": 33147.23601555824, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1064528, "time": 33152.534658908844, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1064600, "time": 33154.5087954998, "episode/length": 8.0, "episode/score": 0.9750000238418579, "episode/reward_rate": 0.1111111111111111, "episode/intrinsic_return": 0.0}
{"step": 1064640, "time": 33155.92957496643, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1064880, "time": 33163.159055233, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 1064896, "time": 33163.65156698227, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1065088, "time": 33169.94717645645, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1065088, "time": 33169.95413732529, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1065096, "time": 33169.98168230057, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1065256, "time": 33174.78667855263, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 1065312, "time": 33176.77190232277, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1065512, "time": 33182.5708861351, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1065976, "time": 33196.520491838455, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1066080, "time": 33199.89092326164, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1066088, "time": 33199.919870853424, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1066216, "time": 33205.42027378082, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1066248, "time": 33206.406655073166, "episode/length": 19.0, "episode/score": 0.940625011920929, "episode/reward_rate": 0.05, "episode/intrinsic_return": 0.0}
{"step": 1066264, "time": 33206.89956736565, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 1066400, "time": 33211.22014904022, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 1066592, "time": 33216.98925471306, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1066800, "time": 33223.25840616226, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1066953, "time": 33228.82150411606, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.612799282731681, "train/action_min": 0.0, "train/action_std": 1.920950871970266, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.010381574765434992, "train/actor_opt_grad_steps": 65570.0, "train/actor_opt_loss": -14.764623483413546, "train/adv_mag": 0.958748864422878, "train/adv_max": 0.37532347000291194, "train/adv_mean": 0.0003772376074920623, "train/adv_min": -0.8845401667609003, "train/adv_std": 0.03016065447843574, "train/cont_avg": 0.9941021397783252, "train/cont_loss_mean": 0.022985670644459614, "train/cont_loss_std": 0.26684748499282623, "train/cont_neg_acc": 0.19697507390100968, "train/cont_neg_loss": 3.064966919305482, "train/cont_pos_acc": 0.9998887043281142, "train/cont_pos_loss": 0.004755407645197337, "train/cont_pred": 0.994203123259427, "train/cont_rate": 0.9941021397783252, "train/dyn_loss_mean": 1.0000003323766398, "train/dyn_loss_std": 1.0641166720117255e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.13347124022069234, "train/extr_critic_critic_opt_grad_steps": 65570.0, "train/extr_critic_critic_opt_loss": 5306.048016327355, "train/extr_critic_mag": 1.64261816522758, "train/extr_critic_max": 1.64261816522758, "train/extr_critic_mean": 1.5443318864982116, "train/extr_critic_min": 1.2024064181473455, "train/extr_critic_std": 0.026107292035089925, "train/extr_return_normed_mag": 0.9684027597821993, "train/extr_return_normed_max": 0.33536068618003956, "train/extr_return_normed_mean": 0.04916153971124165, "train/extr_return_normed_min": -0.8775599836715924, "train/extr_return_normed_std": 0.040782304086121435, "train/extr_return_rate": 0.9996446849677363, "train/extr_return_raw_mag": 1.830908214517415, "train/extr_return_raw_max": 1.830908214517415, "train/extr_return_raw_mean": 1.5447091404440367, "train/extr_return_raw_min": 0.6179875446657829, "train/extr_return_raw_std": 0.040782304049419064, "train/extr_reward_mag": 0.3310312367425176, "train/extr_reward_max": 0.3310312367425176, "train/extr_reward_mean": 0.002663657644401153, "train/extr_reward_min": 5.637483643780788e-08, "train/extr_reward_std": 0.010298223879298407, "train/image_loss_mean": 0.08722716351521426, "train/image_loss_std": 0.10234481492653269, "train/model_loss_mean": 0.7301094508523425, "train/model_loss_std": 0.5284061662742657, "train/model_opt_grad_norm": 17.39329235189654, "train/model_opt_grad_steps": 65512.226600985225, "train/model_opt_loss": 4062.1456124441966, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5566.5024630541875, "train/policy_entropy_mag": 1.2878150857728103, "train/policy_entropy_max": 1.2878150857728103, "train/policy_entropy_mean": 0.08871039667446624, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.10489782155147327, "train/policy_logprob_mag": 6.551080243340854, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.0883335459041478, "train/policy_logprob_min": -6.551080243340854, "train/policy_logprob_std": 0.6244560738502465, "train/policy_randomness_mag": 0.6618060774991078, "train/policy_randomness_max": 0.6618060774991078, "train/policy_randomness_mean": 0.04558812747961782, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.05390681994372401, "train/post_ent_mag": 43.09561050114373, "train/post_ent_max": 43.09561050114373, "train/post_ent_mean": 33.59312438025263, "train/post_ent_min": 28.165361554751843, "train/post_ent_std": 2.9853129245964762, "train/prior_ent_mag": 43.87181869281336, "train/prior_ent_max": 43.87181869281336, "train/prior_ent_mean": 33.701927476328585, "train/prior_ent_min": 27.38553437106128, "train/prior_ent_std": 3.0884874101930064, "train/rep_loss_mean": 1.0000003323766398, "train/rep_loss_std": 1.0641166720117255e-05, "train/reward_avg": 0.002631893071083334, "train/reward_loss_mean": 0.0198963918812628, "train/reward_loss_std": 0.26114885963205925, "train/reward_max_data": 0.7884082512315271, "train/reward_max_pred": 0.21738570546868988, "train/reward_neg_acc": 0.9997053912707737, "train/reward_neg_loss": 0.0035607826785904726, "train/reward_pos_acc": 0.10220238227397203, "train/reward_pos_loss": 4.182207840681076, "train/reward_pred": 0.0020046552460815004, "train/reward_rate": 0.003877386083743842, "train_stats/mean_log_entropy": 0.07955223017261695, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 0.03042875975370407, "report/cont_loss_std": 0.3361114263534546, "report/cont_neg_acc": 0.125, "report/cont_neg_loss": 3.482283115386963, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0032488005235791206, "report/cont_pred": 0.9960596561431885, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.10032940655946732, "report/image_loss_std": 0.10949684679508209, "report/model_loss_mean": 0.7607567310333252, "report/model_loss_std": 0.6872637271881104, "report/post_ent_mag": 40.98335647583008, "report/post_ent_max": 40.98335647583008, "report/post_ent_mean": 32.012550354003906, "report/post_ent_min": 27.202686309814453, "report/post_ent_std": 2.973536252975464, "report/prior_ent_mag": 43.03002166748047, "report/prior_ent_max": 43.03002166748047, "report/prior_ent_mean": 32.88025665283203, "report/prior_ent_min": 26.96094512939453, "report/prior_ent_std": 2.9176113605499268, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0041656494140625, "report/reward_loss_mean": 0.029998525977134705, "report/reward_loss_std": 0.3515421152114868, "report/reward_max_data": 0.8062499761581421, "report/reward_max_pred": 0.18233859539031982, "report/reward_neg_acc": 0.9999999403953552, "report/reward_neg_loss": 0.0018085850169882178, "report/reward_pos_acc": 0.1428571492433548, "report/reward_pos_loss": 4.125594615936279, "report/reward_pred": 0.001203899853862822, "report/reward_rate": 0.0068359375, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.022831991314888, "eval/cont_loss_std": 0.2703988552093506, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 3.859570264816284, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0040059927850961685, "eval/cont_pred": 0.995975136756897, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.11792582273483276, "eval/image_loss_std": 0.12574784457683563, "eval/model_loss_mean": 0.7705767154693604, "eval/model_loss_std": 0.7006843686103821, "eval/post_ent_mag": 41.133880615234375, "eval/post_ent_max": 41.133880615234375, "eval/post_ent_mean": 31.95744514465332, "eval/post_ent_min": 27.510055541992188, "eval/post_ent_std": 2.9828174114227295, "eval/prior_ent_mag": 42.956295013427734, "eval/prior_ent_max": 42.956295013427734, "eval/prior_ent_mean": 32.905540466308594, "eval/prior_ent_min": 27.199481964111328, "eval/prior_ent_std": 2.886531352996826, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.003253174014389515, "eval/reward_loss_mean": 0.029818911105394363, "eval/reward_loss_std": 0.39894333481788635, "eval/reward_max_data": 0.9375, "eval/reward_max_pred": 0.07256424427032471, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.002701644552871585, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.556317329406738, "eval/reward_pred": 0.0013912941794842482, "eval/reward_rate": 0.0048828125, "replay/size": 1000000.0, "replay/inserts": 32464.0, "replay/samples": 32464.0, "replay/insert_wait_avg": 1.2560966509560048e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.1344623763083e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3520.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0617754676125266e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.685754776000977e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 999.9926416873932, "timer/env.step_count": 4058.0, "timer/env.step_total": 39.03557753562927, "timer/env.step_frac": 0.03903586477372516, "timer/env.step_avg": 0.009619412896902236, "timer/env.step_min": 0.007581472396850586, "timer/env.step_max": 0.03703641891479492, "timer/replay._sample_count": 32464.0, "timer/replay._sample_total": 16.267412900924683, "timer/replay._sample_frac": 0.016267532602514914, "timer/replay._sample_avg": 0.0005010908360314404, "timer/replay._sample_min": 0.0004010200500488281, "timer/replay._sample_max": 0.011046648025512695, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4498.0, "timer/agent.policy_total": 46.67576885223389, "timer/agent.policy_frac": 0.04667611230965953, "timer/agent.policy_avg": 0.010377005080532211, "timer/agent.policy_min": 0.008318662643432617, "timer/agent.policy_max": 0.07675766944885254, "timer/dataset_train_count": 2029.0, "timer/dataset_train_total": 0.2217998504638672, "timer/dataset_train_frac": 0.00022180148254851245, "timer/dataset_train_avg": 0.00010931485976533621, "timer/dataset_train_min": 9.584426879882812e-05, "timer/dataset_train_max": 0.0005946159362792969, "timer/agent.train_count": 2029.0, "timer/agent.train_total": 900.9168784618378, "timer/agent.train_frac": 0.9009235077386425, "timer/agent.train_avg": 0.4440201470979979, "timer/agent.train_min": 0.433516263961792, "timer/agent.train_max": 0.6696481704711914, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47484540939331055, "timer/agent.report_frac": 0.00047484890347998336, "timer/agent.report_avg": 0.23742270469665527, "timer/agent.report_min": 0.23024725914001465, "timer/agent.report_max": 0.2445981502532959, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.337860107421875e-05, "timer/dataset_eval_frac": 3.337884668620712e-08, "timer/dataset_eval_avg": 3.337860107421875e-05, "timer/dataset_eval_min": 3.337860107421875e-05, "timer/dataset_eval_max": 3.337860107421875e-05, "fps": 32.463627128783}
{"step": 1067200, "time": 33236.38171505928, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1067208, "time": 33236.41186547279, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1067240, "time": 33237.38322329521, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1067256, "time": 33237.872776031494, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1067280, "time": 33238.82597541809, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1067408, "time": 33242.71029520035, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1067440, "time": 33243.68135738373, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1067624, "time": 33249.015857219696, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1067784, "time": 33253.85603785515, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1067824, "time": 33255.306616306305, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1068024, "time": 33261.15686130524, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1068160, "time": 33265.629812955856, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1068672, "time": 33281.22288107872, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 1068680, "time": 33281.25180006027, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1068760, "time": 33283.70246005058, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1069720, "time": 33312.937141656876, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1069720, "time": 33312.944662332535, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1069752, "time": 33313.92051959038, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1069872, "time": 33317.8039727211, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1069936, "time": 33319.74776697159, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1069936, "time": 33319.75563430786, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 1070024, "time": 33322.18847513199, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 1070056, "time": 33324.18470835686, "eval_episode/length": 37.0, "eval_episode/score": 0.8843749761581421, "eval_episode/reward_rate": 0.02631578947368421}
{"step": 1070056, "time": 33325.40842628479, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 1070056, "time": 33325.77466058731, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 1070056, "time": 33325.81937813759, "eval_episode/length": 94.0, "eval_episode/score": 0.706250011920929, "eval_episode/reward_rate": 0.010526315789473684}
{"step": 1070056, "time": 33326.15252685547, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 1070056, "time": 33327.292581796646, "eval_episode/length": 169.0, "eval_episode/score": 0.47187501192092896, "eval_episode/reward_rate": 0.0058823529411764705}
{"step": 1070056, "time": 33327.47408223152, "eval_episode/length": 178.0, "eval_episode/score": 0.4437499940395355, "eval_episode/reward_rate": 0.00558659217877095}
{"step": 1070056, "time": 33327.92366814613, "eval_episode/length": 106.0, "eval_episode/score": 0.668749988079071, "eval_episode/reward_rate": 0.009345794392523364}
{"step": 1070096, "time": 33329.35819840431, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1070472, "time": 33340.5326321125, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1070472, "time": 33340.54113817215, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1070568, "time": 33343.464831352234, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1070808, "time": 33350.72958660126, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1071088, "time": 33359.54063749313, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1071216, "time": 33363.42959141731, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1071384, "time": 33368.30813241005, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1071392, "time": 33368.77520060539, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1071416, "time": 33369.28348636627, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1071552, "time": 33373.618628025055, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 1071608, "time": 33375.09298300743, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1071856, "time": 33382.8156349659, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 1072112, "time": 33390.68369483948, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1072184, "time": 33392.64422464371, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1072248, "time": 33394.57271528244, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1072328, "time": 33397.017656087875, "episode/length": 287.0, "episode/score": 0.10312499850988388, "episode/reward_rate": 0.003472222222222222, "episode/intrinsic_return": 0.0}
{"step": 1072360, "time": 33397.991325855255, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1072472, "time": 33401.3829126358, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1072640, "time": 33406.70953583717, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1072712, "time": 33408.668959379196, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1072776, "time": 33410.622584819794, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1072840, "time": 33412.55080366135, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 1073168, "time": 33423.32300591469, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1073320, "time": 33427.69580197334, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1073368, "time": 33429.149896621704, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1073408, "time": 33430.60165429115, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1073672, "time": 33438.36529111862, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1074224, "time": 33455.41512084007, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1074256, "time": 33456.385744571686, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1074424, "time": 33461.31758189201, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1074432, "time": 33461.78702759743, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1074560, "time": 33465.6977763176, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1074672, "time": 33469.09871220589, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1075016, "time": 33479.446805238724, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 1075080, "time": 33481.37906551361, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1075144, "time": 33483.321791648865, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1075400, "time": 33491.04804444313, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1075608, "time": 33497.33053278923, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 1075680, "time": 33499.75170612335, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1075688, "time": 33499.77924442291, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1075720, "time": 33500.74506735802, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 1075952, "time": 33508.04833698273, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1076104, "time": 33512.41291499138, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1076128, "time": 33513.37699794769, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1076384, "time": 33521.135516405106, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1076848, "time": 33535.353813648224, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1076864, "time": 33535.84864115715, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1077080, "time": 33542.19201421738, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 1077208, "time": 33546.06679272652, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 1077288, "time": 33548.52345752716, "episode/length": 195.0, "episode/score": 0.390625, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.0}
{"step": 1077328, "time": 33549.96175408363, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1077456, "time": 33553.85578107834, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1077584, "time": 33557.75224232674, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1077992, "time": 33569.99316358566, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1078000, "time": 33570.46596908569, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1078008, "time": 33570.4953622818, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 1078152, "time": 33574.9003636837, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1078176, "time": 33575.853246212006, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1078416, "time": 33583.14869093895, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1078480, "time": 33585.105458498, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1078568, "time": 33587.56447267532, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1078616, "time": 33589.014441013336, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1078832, "time": 33595.87343168259, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 1078848, "time": 33596.358781814575, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1079384, "time": 33612.38143324852, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1079392, "time": 33612.85104179382, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1079448, "time": 33614.32085418701, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1079656, "time": 33620.68160414696, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 1079896, "time": 33628.14893078804, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1080040, "time": 33633.43291711807, "eval_episode/length": 47.0, "eval_episode/score": 0.8531249761581421, "eval_episode/reward_rate": 0.020833333333333332}
{"step": 1080040, "time": 33633.528079509735, "eval_episode/length": 52.0, "eval_episode/score": 0.8374999761581421, "eval_episode/reward_rate": 0.018867924528301886}
{"step": 1080040, "time": 33634.232372283936, "eval_episode/length": 91.0, "eval_episode/score": 0.715624988079071, "eval_episode/reward_rate": 0.010869565217391304}
{"step": 1080040, "time": 33634.35383152962, "eval_episode/length": 49.0, "eval_episode/score": 0.846875011920929, "eval_episode/reward_rate": 0.02}
{"step": 1080040, "time": 33634.80703020096, "eval_episode/length": 121.0, "eval_episode/score": 0.621874988079071, "eval_episode/reward_rate": 0.00819672131147541}
{"step": 1080040, "time": 33634.92115497589, "eval_episode/length": 127.0, "eval_episode/score": 0.6031249761581421, "eval_episode/reward_rate": 0.0078125}
{"step": 1080040, "time": 33635.0513920784, "eval_episode/length": 134.0, "eval_episode/score": 0.581250011920929, "eval_episode/reward_rate": 0.007407407407407408}
{"step": 1080040, "time": 33635.9823782444, "eval_episode/length": 49.0, "eval_episode/score": 0.846875011920929, "eval_episode/reward_rate": 0.02}
{"step": 1080208, "time": 33641.31561422348, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1080464, "time": 33649.100964307785, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1080488, "time": 33649.61101317406, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1080504, "time": 33650.10171580315, "episode/length": 241.0, "episode/score": 0.24687500298023224, "episode/reward_rate": 0.004132231404958678, "episode/intrinsic_return": 0.0}
{"step": 1080520, "time": 33650.595500946045, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1080584, "time": 33652.53328728676, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1080720, "time": 33656.96405792236, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 1080768, "time": 33658.43428349495, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 1080840, "time": 33660.396441459656, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1081048, "time": 33666.69020819664, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1081176, "time": 33670.57517194748, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1081240, "time": 33672.530182123184, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1081536, "time": 33682.19699430466, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1081632, "time": 33685.23406100273, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1081872, "time": 33692.52810001373, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1082424, "time": 33709.004014253616, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1082520, "time": 33711.91995763779, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1082776, "time": 33719.80625963211, "episode/length": 281.0, "episode/score": 0.12187500298023224, "episode/reward_rate": 0.0035460992907801418, "episode/intrinsic_return": 0.0}
{"step": 1082936, "time": 33724.66209626198, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1083032, "time": 33727.576853990555, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 1083080, "time": 33729.02557301521, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1083176, "time": 33731.93273019791, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1083320, "time": 33736.27547168732, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1083552, "time": 33743.49417614937, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1083848, "time": 33752.32482433319, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1084168, "time": 33761.98472046852, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 1084304, "time": 33766.33813452721, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 1084440, "time": 33770.24616312981, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 1084736, "time": 33779.49784207344, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1084832, "time": 33782.409051179886, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1085080, "time": 33789.69856405258, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1085112, "time": 33790.67112970352, "episode/length": 223.0, "episode/score": 0.3031249940395355, "episode/reward_rate": 0.004464285714285714, "episode/intrinsic_return": 0.0}
{"step": 1085160, "time": 33792.12623119354, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1085384, "time": 33798.90280914307, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1085408, "time": 33799.872181892395, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1085488, "time": 33802.290555000305, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1085784, "time": 33811.147332668304, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 1085824, "time": 33812.582513809204, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1085856, "time": 33813.554109334946, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1085864, "time": 33813.58394598961, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1086080, "time": 33820.3511493206, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1086480, "time": 33832.49786520004, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1086528, "time": 33833.973682165146, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1087016, "time": 33848.657623291016, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 1087048, "time": 33849.63423705101, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1087072, "time": 33850.58240532875, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1087424, "time": 33861.265788793564, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1087440, "time": 33861.75447559357, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1087464, "time": 33862.265280008316, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1087544, "time": 33864.711355924606, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1087560, "time": 33865.33822607994, "episode/length": 211.0, "episode/score": 0.34062498807907104, "episode/reward_rate": 0.0047169811320754715, "episode/intrinsic_return": 0.0}
{"step": 1087576, "time": 33865.830011844635, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1087664, "time": 33868.770413160324, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 1087720, "time": 33870.25677871704, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1088104, "time": 33881.84818291664, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1088168, "time": 33883.79763293266, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1088408, "time": 33891.0680205822, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 1088416, "time": 33891.535898685455, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1088552, "time": 33895.55101966858, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1088712, "time": 33900.40569400787, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 1088752, "time": 33901.855436086655, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 1088848, "time": 33904.76689910889, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 1089088, "time": 33912.10473585129, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1089232, "time": 33916.556300640106, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1089440, "time": 33922.97747373581, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1089736, "time": 33932.52238893509, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1089760, "time": 33933.48687195778, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1089776, "time": 33933.98491406441, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1089856, "time": 33936.45682835579, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1090024, "time": 33942.52053594589, "eval_episode/length": 56.0, "eval_episode/score": 0.824999988079071, "eval_episode/reward_rate": 0.017543859649122806}
{"step": 1090024, "time": 33942.744968891144, "eval_episode/length": 67.0, "eval_episode/score": 0.7906249761581421, "eval_episode/reward_rate": 0.014705882352941176}
{"step": 1090024, "time": 33943.1139626503, "eval_episode/length": 85.0, "eval_episode/score": 0.734375, "eval_episode/reward_rate": 0.011627906976744186}
{"step": 1090024, "time": 33943.14506173134, "eval_episode/length": 85.0, "eval_episode/score": 0.734375, "eval_episode/reward_rate": 0.011627906976744186}
{"step": 1090024, "time": 33943.3224439621, "eval_episode/length": 93.0, "eval_episode/score": 0.7093750238418579, "eval_episode/reward_rate": 0.010638297872340425}
{"step": 1090024, "time": 33943.92619609833, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 1090024, "time": 33944.20010590553, "eval_episode/length": 137.0, "eval_episode/score": 0.5718749761581421, "eval_episode/reward_rate": 0.007246376811594203}
{"step": 1090024, "time": 33944.26450371742, "eval_episode/length": 140.0, "eval_episode/score": 0.5625, "eval_episode/reward_rate": 0.0070921985815602835}
{"step": 1090208, "time": 33950.10086917877, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 1090328, "time": 33953.50824928284, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1090432, "time": 33956.97915124893, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1090456, "time": 33957.49099397659, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 1090688, "time": 33964.73222255707, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 1090912, "time": 33971.515216588974, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 1091072, "time": 33976.366228580475, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1091128, "time": 33977.85265541077, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 1091160, "time": 33978.84506201744, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1091208, "time": 33980.29798865318, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1091360, "time": 33985.25571131706, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1091640, "time": 33993.51969122887, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1091832, "time": 33999.343272447586, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1091848, "time": 33999.83409547806, "episode/length": 248.0, "episode/score": 0.22499999403953552, "episode/reward_rate": 0.004016064257028112, "episode/intrinsic_return": 0.0}
{"step": 1091864, "time": 34000.32305550575, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1092032, "time": 34005.635939121246, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1092072, "time": 34006.63289093971, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1092376, "time": 34015.93505525589, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1092456, "time": 34018.374712228775, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1092520, "time": 34020.31017160416, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1092888, "time": 34031.40800690651, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1092912, "time": 34032.3819770813, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1093056, "time": 34036.70048236847, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1093240, "time": 34042.040701150894, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1093384, "time": 34046.452322244644, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1093392, "time": 34046.937937259674, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1093560, "time": 34051.781643629074, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1093928, "time": 34062.93369793892, "episode/length": 261.0, "episode/score": 0.18437500298023224, "episode/reward_rate": 0.003816793893129771, "episode/intrinsic_return": 0.0}
{"step": 1093952, "time": 34063.89064216614, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1093992, "time": 34064.883628845215, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1094024, "time": 34065.86091756821, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1094112, "time": 34068.764791727066, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1094144, "time": 34069.73765158653, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1094536, "time": 34081.46610045433, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1094560, "time": 34082.41754889488, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1094752, "time": 34088.21142053604, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1094832, "time": 34090.64118051529, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1095144, "time": 34099.820523023605, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1095160, "time": 34100.33141493797, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1095304, "time": 34104.674723386765, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1095360, "time": 34106.740720272064, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 1095384, "time": 34107.24922943115, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1095728, "time": 34117.86774802208, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1095984, "time": 34125.611053705215, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1096064, "time": 34128.02303504944, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 1096208, "time": 34132.38689446449, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1096336, "time": 34136.35444045067, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1096400, "time": 34138.29206800461, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1096424, "time": 34138.80183458328, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1096744, "time": 34148.53991031647, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1097144, "time": 34160.671174287796, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1097200, "time": 34162.58094739914, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1097256, "time": 34164.06627058983, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 1097272, "time": 34164.553886413574, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1097344, "time": 34167.025024175644, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 1097504, "time": 34171.85690975189, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 1097672, "time": 34176.72513318062, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1097704, "time": 34177.69618821144, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1097752, "time": 34179.63347530365, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1097784, "time": 34180.60347390175, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1097888, "time": 34183.98300528526, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1098304, "time": 34196.6947157383, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1098408, "time": 34199.63658761978, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1098536, "time": 34203.512560367584, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1098576, "time": 34204.944885253906, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 1098832, "time": 34212.670811891556, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 1099008, "time": 34218.017186164856, "episode/length": 225.0, "episode/score": 0.296875, "episode/reward_rate": 0.004424778761061947, "episode/intrinsic_return": 0.0}
{"step": 1099096, "time": 34220.451124191284, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 1099128, "time": 34221.422801971436, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 1099224, "time": 34224.336746931076, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 1099304, "time": 34226.84208250046, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1099337, "time": 34228.882058382034, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.6281260222637006, "train/action_min": 0.0, "train/action_std": 1.960448652652684, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.010470207949201095, "train/actor_opt_grad_steps": 67600.0, "train/actor_opt_loss": -16.116039348940543, "train/adv_mag": 1.068402324991273, "train/adv_max": 0.3773988362016349, "train/adv_mean": 0.00015820592295039666, "train/adv_min": -1.02095334224513, "train/adv_std": 0.03483162636827365, "train/cont_avg": 0.9940973291256158, "train/cont_loss_mean": 0.022745800334180298, "train/cont_loss_std": 0.2662604686533436, "train/cont_neg_acc": 0.20392987370637838, "train/cont_neg_loss": 3.0351392883678963, "train/cont_pos_acc": 0.9998549184775705, "train/cont_pos_loss": 0.004938984493922277, "train/cont_pred": 0.9940150107068969, "train/cont_rate": 0.9940973291256158, "train/dyn_loss_mean": 1.0000080034650605, "train/dyn_loss_std": 0.00017620368489050512, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.16050139345742506, "train/extr_critic_critic_opt_grad_steps": 67600.0, "train/extr_critic_critic_opt_loss": 6335.066856046028, "train/extr_critic_mag": 1.654489840192748, "train/extr_critic_max": 1.654489840192748, "train/extr_critic_mean": 1.5355114455293553, "train/extr_critic_min": 1.145079157622577, "train/extr_critic_std": 0.026805061746040002, "train/extr_return_normed_mag": 1.0755318811374346, "train/extr_return_normed_max": 0.3184102620984533, "train/extr_return_normed_mean": 0.04948792134966756, "train/extr_return_normed_min": -1.0233216922858666, "train/extr_return_normed_std": 0.045020543332464004, "train/extr_return_rate": 0.9995802265082674, "train/extr_return_raw_mag": 1.8045919470011895, "train/extr_return_raw_max": 1.8045919470011895, "train/extr_return_raw_mean": 1.5356696791249542, "train/extr_return_raw_min": 0.46285999261686955, "train/extr_return_raw_std": 0.04502054346092229, "train/extr_reward_mag": 0.31779635011268953, "train/extr_reward_max": 0.31779635011268953, "train/extr_reward_mean": 0.0026731909449978415, "train/extr_reward_min": 4.4630078846597905e-08, "train/extr_reward_std": 0.011321494422320808, "train/image_loss_mean": 0.0862801497425939, "train/image_loss_std": 0.10284895675596345, "train/model_loss_mean": 0.7281537616781413, "train/model_loss_std": 0.515975004750226, "train/model_opt_grad_norm": 17.368616578614184, "train/model_opt_grad_steps": 67540.31527093596, "train/model_opt_loss": 3713.624213458282, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5098.522167487685, "train/policy_entropy_mag": 1.2339581309868197, "train/policy_entropy_max": 1.2339581309868197, "train/policy_entropy_mean": 0.08801339860326551, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.10266456327268056, "train/policy_logprob_mag": 6.551080245689805, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.08742368294687694, "train/policy_logprob_min": -6.551080245689805, "train/policy_logprob_std": 0.6227799148982381, "train/policy_randomness_mag": 0.6341290761684549, "train/policy_randomness_max": 0.6341290761684549, "train/policy_randomness_mean": 0.04522994188178936, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.05275915208928691, "train/post_ent_mag": 45.26170230733937, "train/post_ent_max": 45.26170230733937, "train/post_ent_mean": 33.37702980417336, "train/post_ent_min": 27.173597279440592, "train/post_ent_std": 3.6417209409140603, "train/prior_ent_mag": 46.07580838884626, "train/prior_ent_max": 46.07580838884626, "train/prior_ent_mean": 33.834580670436615, "train/prior_ent_min": 27.06868859464899, "train/prior_ent_std": 3.5187697375349223, "train/rep_loss_mean": 1.0000080034650605, "train/rep_loss_std": 0.00017620368489050512, "train/reward_avg": 0.0025507583918871145, "train/reward_loss_mean": 0.019122987157513795, "train/reward_loss_std": 0.2515812657791846, "train/reward_max_data": 0.7752770948879825, "train/reward_max_pred": 0.22480813153271606, "train/reward_neg_acc": 0.999700699533735, "train/reward_neg_loss": 0.003580092264366855, "train/reward_pos_acc": 0.11001540053246626, "train/reward_pos_loss": 4.053402504221124, "train/reward_pred": 0.0020463020635970632, "train/reward_rate": 0.0038052262931034483, "train_stats/mean_log_entropy": 0.07880267353150351, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.990234375, "report/cont_loss_mean": 0.04061579704284668, "report/cont_loss_std": 0.4254014790058136, "report/cont_neg_acc": 0.20000000298023224, "report/cont_neg_loss": 3.630373477935791, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.005213852506130934, "report/cont_pred": 0.992794930934906, "report/cont_rate": 0.990234375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.07383923977613449, "report/image_loss_std": 0.09216134995222092, "report/model_loss_mean": 0.745384931564331, "report/model_loss_std": 0.7366702556610107, "report/post_ent_mag": 42.066680908203125, "report/post_ent_max": 42.066680908203125, "report/post_ent_mean": 31.711551666259766, "report/post_ent_min": 25.21368408203125, "report/post_ent_std": 3.3268706798553467, "report/prior_ent_mag": 46.340484619140625, "report/prior_ent_max": 46.340484619140625, "report/prior_ent_mean": 34.53535461425781, "report/prior_ent_min": 27.665138244628906, "report/prior_ent_std": 3.334277391433716, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.003985595889389515, "report/reward_loss_mean": 0.03092985972762108, "report/reward_loss_std": 0.3488273620605469, "report/reward_max_data": 0.7437499761581421, "report/reward_max_pred": 0.05182933807373047, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.004266445990651846, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.5548224449157715, "report/reward_pred": 0.0022474192082881927, "report/reward_rate": 0.005859375, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.04434236139059067, "eval/cont_loss_std": 0.6414660811424255, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.90820837020874, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0038873543962836266, "eval/cont_pred": 0.9961323738098145, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.10983262956142426, "eval/image_loss_std": 0.12245800346136093, "eval/model_loss_mean": 0.7764104604721069, "eval/model_loss_std": 0.817767858505249, "eval/post_ent_mag": 42.29054260253906, "eval/post_ent_max": 42.29054260253906, "eval/post_ent_mean": 30.69219207763672, "eval/post_ent_min": 25.668678283691406, "eval/post_ent_std": 3.890946626663208, "eval/prior_ent_mag": 46.21015167236328, "eval/prior_ent_max": 46.21015167236328, "eval/prior_ent_mean": 33.746421813964844, "eval/prior_ent_min": 27.247314453125, "eval/prior_ent_std": 3.9245662689208984, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0028839111328125, "eval/reward_loss_mean": 0.022235415875911713, "eval/reward_loss_std": 0.3009674847126007, "eval/reward_max_data": 0.8062499761581421, "eval/reward_max_pred": 0.368422269821167, "eval/reward_neg_acc": 0.9990195631980896, "eval/reward_neg_loss": 0.0035170132759958506, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 4.795428276062012, "eval/reward_pred": 0.001831880654208362, "eval/reward_rate": 0.00390625, "replay/size": 1000000.0, "replay/inserts": 32384.0, "replay/samples": 32384.0, "replay/insert_wait_avg": 1.2629985691530432e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.096837479135265e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4224.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1319802566008135e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.834766387939453e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.111287355423, "timer/env.step_count": 4048.0, "timer/env.step_total": 38.990251541137695, "timer/env.step_frac": 0.03898591290199208, "timer/env.step_avg": 0.009631979135656546, "timer/env.step_min": 0.007566928863525391, "timer/env.step_max": 0.03568696975708008, "timer/replay._sample_count": 32384.0, "timer/replay._sample_total": 16.285354137420654, "timer/replay._sample_frac": 0.016283541985096215, "timer/replay._sample_avg": 0.0005028827241051339, "timer/replay._sample_min": 0.00039196014404296875, "timer/replay._sample_max": 0.026044845581054688, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4576.0, "timer/agent.policy_total": 48.3365273475647, "timer/agent.policy_frac": 0.04833114870184112, "timer/agent.policy_avg": 0.010563052304974802, "timer/agent.policy_min": 0.008603572845458984, "timer/agent.policy_max": 0.08957433700561523, "timer/dataset_train_count": 2024.0, "timer/dataset_train_total": 0.22185325622558594, "timer/dataset_train_frac": 0.00022182856951072783, "timer/dataset_train_avg": 0.00010961129260157408, "timer/dataset_train_min": 9.632110595703125e-05, "timer/dataset_train_max": 0.0005717277526855469, "timer/agent.train_count": 2024.0, "timer/agent.train_total": 901.2560303211212, "timer/agent.train_frac": 0.9011557430816495, "timer/agent.train_avg": 0.44528459996102826, "timer/agent.train_min": 0.43454670906066895, "timer/agent.train_max": 0.7045598030090332, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4787931442260742, "timer/agent.report_frac": 0.0004787398665323923, "timer/agent.report_avg": 0.2393965721130371, "timer/agent.report_min": 0.23273873329162598, "timer/agent.report_max": 0.24605441093444824, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.457069396972656e-05, "timer/dataset_eval_frac": 3.456684711672563e-08, "timer/dataset_eval_avg": 3.457069396972656e-05, "timer/dataset_eval_min": 3.457069396972656e-05, "timer/dataset_eval_max": 3.457069396972656e-05, "fps": 32.379792059236316}
{"step": 1099344, "time": 34228.90384674072, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1099480, "time": 34233.19097280502, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1099832, "time": 34243.82783818245, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1100008, "time": 34249.14749121666, "episode/length": 21.0, "episode/score": 0.934374988079071, "episode/reward_rate": 0.045454545454545456, "episode/intrinsic_return": 0.0}
{"step": 1100008, "time": 34250.866941690445, "eval_episode/length": 93.0, "eval_episode/score": 0.7093750238418579, "eval_episode/reward_rate": 0.010638297872340425}
{"step": 1100008, "time": 34251.09908890724, "eval_episode/length": 105.0, "eval_episode/score": 0.671875, "eval_episode/reward_rate": 0.009433962264150943}
{"step": 1100008, "time": 34251.24944424629, "eval_episode/length": 113.0, "eval_episode/score": 0.6468750238418579, "eval_episode/reward_rate": 0.008771929824561403}
{"step": 1100008, "time": 34251.67019033432, "eval_episode/length": 136.0, "eval_episode/score": 0.574999988079071, "eval_episode/reward_rate": 0.0072992700729927005}
{"step": 1100008, "time": 34251.71565937996, "eval_episode/length": 138.0, "eval_episode/score": 0.5687500238418579, "eval_episode/reward_rate": 0.007194244604316547}
{"step": 1100008, "time": 34252.76226043701, "eval_episode/length": 102.0, "eval_episode/score": 0.6812499761581421, "eval_episode/reward_rate": 0.009708737864077669}
{"step": 1100008, "time": 34252.873057842255, "eval_episode/length": 96.0, "eval_episode/score": 0.699999988079071, "eval_episode/reward_rate": 0.010309278350515464}
{"step": 1100008, "time": 34253.0552175045, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 1100016, "time": 34253.52226662636, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1100064, "time": 34255.016582250595, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1100096, "time": 34256.051443099976, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1100096, "time": 34256.05877137184, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1100296, "time": 34261.88987541199, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1100456, "time": 34266.72685599327, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 1100504, "time": 34268.17213654518, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 1100632, "time": 34272.03602766991, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1100824, "time": 34277.824591875076, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1100960, "time": 34282.16937017441, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1101264, "time": 34291.440091609955, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 1101488, "time": 34298.18733549118, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1101528, "time": 34299.17869210243, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1101672, "time": 34303.55422997475, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0}
{"step": 1102072, "time": 34315.815425395966, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1102112, "time": 34317.25101399422, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1102328, "time": 34323.562467336655, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1102376, "time": 34325.02537512779, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1102464, "time": 34327.89493513107, "episode/length": 250.0, "episode/score": 0.21875, "episode/reward_rate": 0.00398406374501992, "episode/intrinsic_return": 0.0}
{"step": 1102720, "time": 34335.6248190403, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1102792, "time": 34337.58584046364, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1102872, "time": 34340.028945207596, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1102944, "time": 34342.45389461517, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1102984, "time": 34343.44307088852, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1103000, "time": 34343.94776344299, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1103136, "time": 34348.39832568169, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1103424, "time": 34357.17128992081, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1103744, "time": 34366.863097429276, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1103792, "time": 34368.33575344086, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1103816, "time": 34368.842202425, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1103872, "time": 34370.76382923126, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1104312, "time": 34383.96722531319, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1104424, "time": 34387.34525799751, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1104664, "time": 34394.61871981621, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1104872, "time": 34401.006461143494, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1104872, "time": 34401.01423454285, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1104960, "time": 34403.90412259102, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 1104968, "time": 34403.93203353882, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 1105032, "time": 34405.97409439087, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1105104, "time": 34408.39040994644, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1105200, "time": 34411.28031373024, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1105488, "time": 34419.98414373398, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1105688, "time": 34425.81639266014, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1105824, "time": 34430.15010023117, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1105840, "time": 34430.64092063904, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1106128, "time": 34439.90494966507, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1106256, "time": 34443.77936291695, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1106352, "time": 34446.682468652725, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1106648, "time": 34455.41234111786, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1106736, "time": 34458.305016994476, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1106864, "time": 34462.17860555649, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1106896, "time": 34463.14758014679, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1107152, "time": 34470.98675322533, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1107184, "time": 34471.9615213871, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1107184, "time": 34471.97072339058, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1107208, "time": 34472.48444581032, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1107280, "time": 34474.88967347145, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1107512, "time": 34481.72648239136, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1107600, "time": 34484.61074542999, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1107984, "time": 34496.33643770218, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1108336, "time": 34506.98817753792, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 1108536, "time": 34512.79911208153, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1108568, "time": 34513.765399456024, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1108640, "time": 34516.17178058624, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 1109008, "time": 34527.394484996796, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1109248, "time": 34534.684519052505, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1109320, "time": 34536.64379501343, "episode/length": 214.0, "episode/score": 0.33125001192092896, "episode/reward_rate": 0.004651162790697674, "episode/intrinsic_return": 0.0}
{"step": 1109432, "time": 34540.03226470947, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 1109464, "time": 34541.00669050217, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1109496, "time": 34541.97915697098, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1109592, "time": 34544.89583110809, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1109600, "time": 34545.36438560486, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1110056, "time": 34559.037611961365, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1110096, "time": 34561.23027968407, "eval_episode/length": 39.0, "eval_episode/score": 0.878125011920929, "eval_episode/reward_rate": 0.025}
{"step": 1110096, "time": 34561.59170174599, "eval_episode/length": 59.0, "eval_episode/score": 0.815625011920929, "eval_episode/reward_rate": 0.016666666666666666}
{"step": 1110096, "time": 34561.76314496994, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 1110096, "time": 34561.82686090469, "eval_episode/length": 71.0, "eval_episode/score": 0.778124988079071, "eval_episode/reward_rate": 0.013888888888888888}
{"step": 1110096, "time": 34562.53926539421, "eval_episode/length": 49.0, "eval_episode/score": 0.846875011920929, "eval_episode/reward_rate": 0.02}
{"step": 1110096, "time": 34563.32179069519, "eval_episode/length": 152.0, "eval_episode/score": 0.5249999761581421, "eval_episode/reward_rate": 0.006535947712418301}
{"step": 1110096, "time": 34563.57772564888, "eval_episode/length": 166.0, "eval_episode/score": 0.48124998807907104, "eval_episode/reward_rate": 0.005988023952095809}
{"step": 1110096, "time": 34563.67760825157, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 1110216, "time": 34567.10645508766, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1110232, "time": 34567.596529483795, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1110320, "time": 34570.487374305725, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1110472, "time": 34574.870809316635, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1110648, "time": 34580.20958447456, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1110696, "time": 34581.681131362915, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1110720, "time": 34582.636112213135, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1110760, "time": 34583.63188672066, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 1111080, "time": 34593.41808509827, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1111344, "time": 34601.6163084507, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1111496, "time": 34606.00510811806, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1111584, "time": 34608.88905000687, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1111624, "time": 34609.87818622589, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1111744, "time": 34613.75357079506, "episode/length": 19.0, "episode/score": 0.940625011920929, "episode/reward_rate": 0.05, "episode/intrinsic_return": 0.0}
{"step": 1111904, "time": 34618.72013711929, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1112368, "time": 34632.72360706329, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1112400, "time": 34633.69147896767, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 1112432, "time": 34634.68099093437, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1112456, "time": 34635.19196653366, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1112736, "time": 34643.87425994873, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1113008, "time": 34652.21086215973, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1113432, "time": 34664.85904502869, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1113480, "time": 34666.30913066864, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1113576, "time": 34669.2205889225, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1113648, "time": 34671.603607177734, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1113656, "time": 34671.6319770813, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1113848, "time": 34677.5453710556, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1113880, "time": 34678.5379281044, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 1113936, "time": 34680.450884103775, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 1113960, "time": 34680.96445274353, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1113968, "time": 34681.43239212036, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1114056, "time": 34683.88592004776, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1114448, "time": 34696.39682006836, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1114504, "time": 34697.88001728058, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1114624, "time": 34701.74244117737, "episode/length": 14.0, "episode/score": 0.956250011920929, "episode/reward_rate": 0.06666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1114704, "time": 34704.17466402054, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1114912, "time": 34710.63555622101, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1115048, "time": 34714.53486609459, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 1115072, "time": 34715.48051929474, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 1115176, "time": 34718.42014360428, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1115240, "time": 34720.34903550148, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1115304, "time": 34722.286428928375, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1115320, "time": 34722.79248023033, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1115520, "time": 34729.08276772499, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1115680, "time": 34733.95872235298, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1115888, "time": 34740.34860229492, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1115976, "time": 34742.81189227104, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1115976, "time": 34742.81906747818, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1116072, "time": 34745.716120004654, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1116160, "time": 34748.61193728447, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1116280, "time": 34752.03650689125, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1116280, "time": 34752.044719696045, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1116456, "time": 34757.42128396034, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1116592, "time": 34761.75638246536, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 1116600, "time": 34761.78364562988, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1116848, "time": 34769.600610256195, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1117288, "time": 34782.683035612106, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1117552, "time": 34790.908621788025, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1117600, "time": 34792.36152839661, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1117992, "time": 34804.07527804375, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1118032, "time": 34805.52377462387, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1118288, "time": 34813.218693971634, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1118288, "time": 34813.227625370026, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1118304, "time": 34813.71504044533, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1118488, "time": 34819.030903339386, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1118568, "time": 34821.462466716766, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 1118592, "time": 34822.408200502396, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1118752, "time": 34827.36505484581, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1118912, "time": 34832.22086548805, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1119024, "time": 34835.61175918579, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1119024, "time": 34835.61944055557, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1119144, "time": 34839.0230383873, "episode/length": 14.0, "episode/score": 0.956250011920929, "episode/reward_rate": 0.06666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1119200, "time": 34840.95997285843, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 1119200, "time": 34840.967767715454, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1119464, "time": 34848.73124742508, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1119680, "time": 34855.57717347145, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1119872, "time": 34861.36587738991, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1120080, "time": 34868.92670798302, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 1120080, "time": 34869.012305259705, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 1120080, "time": 34869.07799935341, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 1120080, "time": 34869.384174346924, "eval_episode/length": 84.0, "eval_episode/score": 0.737500011920929, "eval_episode/reward_rate": 0.011764705882352941}
{"step": 1120080, "time": 34870.09796500206, "eval_episode/length": 50.0, "eval_episode/score": 0.84375, "eval_episode/reward_rate": 0.0196078431372549}
{"step": 1120080, "time": 34870.27972531319, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 1120080, "time": 34870.48558950424, "eval_episode/length": 140.0, "eval_episode/score": 0.5625, "eval_episode/reward_rate": 0.0070921985815602835}
{"step": 1120080, "time": 34870.75614905357, "eval_episode/length": 146.0, "eval_episode/score": 0.543749988079071, "eval_episode/reward_rate": 0.006802721088435374}
{"step": 1120192, "time": 34874.52869129181, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1120216, "time": 34875.051574230194, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1120376, "time": 34880.4524269104, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 1120600, "time": 34887.37452554703, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1120880, "time": 34896.083256959915, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1120904, "time": 34896.60091853142, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1121104, "time": 34902.923471450806, "episode/length": 237.0, "episode/score": 0.2593750059604645, "episode/reward_rate": 0.004201680672268907, "episode/intrinsic_return": 0.0}
{"step": 1121216, "time": 34906.310386657715, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1121416, "time": 34912.14338541031, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1121648, "time": 34919.452659368515, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1121800, "time": 34923.85136628151, "episode/length": 240.0, "episode/score": 0.25, "episode/reward_rate": 0.004149377593360996, "episode/intrinsic_return": 0.0}
{"step": 1121984, "time": 34929.63821434975, "episode/length": 223.0, "episode/score": 0.3031249940395355, "episode/reward_rate": 0.004464285714285714, "episode/intrinsic_return": 0.0}
{"step": 1122136, "time": 34934.05718946457, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 1122136, "time": 34934.06521844864, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1122528, "time": 34946.80110788345, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1122800, "time": 34955.00612568855, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1122808, "time": 34955.03478527069, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 1123016, "time": 34961.3576772213, "episode/length": 199.0, "episode/score": 0.37812501192092896, "episode/reward_rate": 0.005, "episode/intrinsic_return": 0.0}
{"step": 1123104, "time": 34964.234192848206, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1123416, "time": 34973.47685265541, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1123504, "time": 34976.52718710899, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 1123672, "time": 34981.38844823837, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 1123720, "time": 34982.83754467964, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1123848, "time": 34986.70778083801, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1123896, "time": 34988.163182497025, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1124272, "time": 34999.75153207779, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1124336, "time": 35001.6773788929, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1124384, "time": 35003.13007688522, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1124448, "time": 35005.244990587234, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1124544, "time": 35008.16550922394, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1124560, "time": 35008.6552195549, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 1125088, "time": 35024.67095422745, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1125120, "time": 35025.65314412117, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1125176, "time": 35027.137078523636, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1125376, "time": 35033.43384861946, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1125464, "time": 35036.00116562843, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1125512, "time": 35037.462147951126, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1125672, "time": 35042.30801177025, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1125816, "time": 35046.67464160919, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1125920, "time": 35050.05282783508, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1126032, "time": 35053.45450925827, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1126168, "time": 35057.34531521797, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1126248, "time": 35059.786115169525, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1126560, "time": 35069.60245370865, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1126664, "time": 35072.53393745422, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1126792, "time": 35076.43616938591, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1126912, "time": 35080.30655121803, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1127032, "time": 35083.742136478424, "episode/length": 238.0, "episode/score": 0.2562499940395355, "episode/reward_rate": 0.0041841004184100415, "episode/intrinsic_return": 0.0}
{"step": 1127296, "time": 35091.97086048126, "episode/length": 228.0, "episode/score": 0.2874999940395355, "episode/reward_rate": 0.004366812227074236, "episode/intrinsic_return": 0.0}
{"step": 1127464, "time": 35096.96058821678, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1127592, "time": 35100.85228228569, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 1127640, "time": 35102.33076643944, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1127688, "time": 35103.79305386543, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1127864, "time": 35109.13432574272, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1128216, "time": 35119.814591646194, "episode/length": 206.0, "episode/score": 0.35624998807907104, "episode/reward_rate": 0.004830917874396135, "episode/intrinsic_return": 0.0}
{"step": 1128256, "time": 35121.25435781479, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 1128376, "time": 35124.695259809494, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1128584, "time": 35131.15953159332, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1128648, "time": 35133.12286901474, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1128752, "time": 35136.50810098648, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1128760, "time": 35136.53646206856, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1129096, "time": 35146.82102870941, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1129112, "time": 35147.32368016243, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1129176, "time": 35149.307208776474, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1129264, "time": 35152.267584085464, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1129544, "time": 35160.71846318245, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1129584, "time": 35162.17576098442, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 1129608, "time": 35162.68780422211, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1129616, "time": 35163.157940626144, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1129664, "time": 35164.61768865585, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1129856, "time": 35170.44000291824, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 1129888, "time": 35171.424832344055, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1130000, "time": 35174.80769729614, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1130064, "time": 35177.60790371895, "eval_episode/length": 42.0, "eval_episode/score": 0.8687499761581421, "eval_episode/reward_rate": 0.023255813953488372}
{"step": 1130064, "time": 35177.9506919384, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 1130064, "time": 35178.32962560654, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 1130064, "time": 35178.389743328094, "eval_episode/length": 85.0, "eval_episode/score": 0.734375, "eval_episode/reward_rate": 0.011627906976744186}
{"step": 1130064, "time": 35178.666467666626, "eval_episode/length": 57.0, "eval_episode/score": 0.8218749761581421, "eval_episode/reward_rate": 0.017241379310344827}
{"step": 1130064, "time": 35179.276856422424, "eval_episode/length": 51.0, "eval_episode/score": 0.840624988079071, "eval_episode/reward_rate": 0.019230769230769232}
{"step": 1130064, "time": 35179.442496061325, "eval_episode/length": 143.0, "eval_episode/score": 0.5531250238418579, "eval_episode/reward_rate": 0.006944444444444444}
{"step": 1130064, "time": 35179.501675605774, "eval_episode/length": 146.0, "eval_episode/score": 0.543749988079071, "eval_episode/reward_rate": 0.006802721088435374}
{"step": 1130384, "time": 35189.29292321205, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1130424, "time": 35190.29225683212, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1130504, "time": 35192.90898156166, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1130520, "time": 35193.70392870903, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1130712, "time": 35199.52660727501, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 1130776, "time": 35201.472514390945, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1130968, "time": 35207.32508945465, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1131016, "time": 35208.801176548004, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 1131072, "time": 35210.70575547218, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1131216, "time": 35215.19187140465, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1131440, "time": 35222.003385066986, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1131641, "time": 35228.99258565903, "train_stats/mean_log_entropy": 0.07769847033592332, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.6305330484220297, "train/action_min": 0.0, "train/action_std": 1.9496848937308435, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00906085726657495, "train/actor_opt_grad_steps": 69625.0, "train/actor_opt_loss": -16.043800894576723, "train/adv_mag": 0.916772195608309, "train/adv_max": 0.3385148815589376, "train/adv_mean": 0.0007878263779482697, "train/adv_min": -0.8276476747918837, "train/adv_std": 0.02800144404541738, "train/cont_avg": 0.9939472462871287, "train/cont_loss_mean": 0.023987258602357883, "train/cont_loss_std": 0.2735180520996599, "train/cont_neg_acc": 0.18774252849640233, "train/cont_neg_loss": 3.083898047261899, "train/cont_pos_acc": 0.9998393896782752, "train/cont_pos_loss": 0.005220423473303418, "train/cont_pred": 0.9937609454782883, "train/cont_rate": 0.9939472462871287, "train/dyn_loss_mean": 1.0000076648032312, "train/dyn_loss_std": 0.00018928456523612436, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.1343548858612038, "train/extr_critic_critic_opt_grad_steps": 69625.0, "train/extr_critic_critic_opt_loss": 5486.831031723777, "train/extr_critic_mag": 1.6305515235013301, "train/extr_critic_max": 1.6305515235013301, "train/extr_critic_mean": 1.5444664311881113, "train/extr_critic_min": 1.1758455244621429, "train/extr_critic_std": 0.026514556609315447, "train/extr_return_normed_mag": 0.89835521372238, "train/extr_return_normed_max": 0.2479166518343557, "train/extr_return_normed_mean": 0.051537603333518645, "train/extr_return_normed_min": -0.8227550818188356, "train/extr_return_normed_std": 0.03959817075087588, "train/extr_return_rate": 0.9995997353355484, "train/extr_return_raw_mag": 1.7416332216546087, "train/extr_return_raw_max": 1.7416332216546087, "train/extr_return_raw_mean": 1.5452542417120225, "train/extr_return_raw_min": 0.6709614880014174, "train/extr_return_raw_std": 0.039598170852307046, "train/extr_reward_mag": 0.2224474785351517, "train/extr_reward_max": 0.2224474785351517, "train/extr_reward_mean": 0.0028155163779974646, "train/extr_reward_min": 1.616997293906637e-07, "train/extr_reward_std": 0.009187331344784782, "train/image_loss_mean": 0.0864057038901466, "train/image_loss_std": 0.10280052399133692, "train/model_loss_mean": 0.7310942243231405, "train/model_loss_std": 0.5378369573909457, "train/model_opt_grad_norm": 16.1137690355282, "train/model_opt_grad_steps": 69563.42574257425, "train/model_opt_loss": 3963.0992165744897, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5420.792079207921, "train/policy_entropy_mag": 1.23987612393823, "train/policy_entropy_max": 1.23987612393823, "train/policy_entropy_mean": 0.08621692753369266, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.09949684519283843, "train/policy_logprob_mag": 6.551080236340513, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.08605628176638395, "train/policy_logprob_min": -6.551080236340513, "train/policy_logprob_std": 0.6228870312766274, "train/policy_randomness_mag": 0.6371703242311383, "train/policy_randomness_max": 0.6371703242311383, "train/policy_randomness_mean": 0.04430673867095225, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.05113126735876102, "train/post_ent_mag": 47.21602539968963, "train/post_ent_max": 47.21602539968963, "train/post_ent_mean": 33.45651237563332, "train/post_ent_min": 26.25067674051417, "train/post_ent_std": 4.302131528901581, "train/prior_ent_mag": 48.07170125753573, "train/prior_ent_max": 48.07170125753573, "train/prior_ent_mean": 33.752683762276526, "train/prior_ent_min": 25.956588679020946, "train/prior_ent_std": 4.113480016736701, "train/rep_loss_mean": 1.0000076648032312, "train/rep_loss_std": 0.00018928456523612436, "train/reward_avg": 0.002780952089752006, "train/reward_loss_mean": 0.0206966390164735, "train/reward_loss_std": 0.26500063529238105, "train/reward_max_data": 0.7909808158874512, "train/reward_max_pred": 0.2427686824656949, "train/reward_neg_acc": 0.9996261499305763, "train/reward_neg_loss": 0.003913750248444774, "train/reward_pos_acc": 0.10884581802029107, "train/reward_pos_loss": 4.083390857706118, "train/reward_pred": 0.002247262536893866, "train/reward_rate": 0.004114132116336633, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.011508939787745476, "report/cont_loss_std": 0.14856715500354767, "report/cont_neg_acc": 0.5, "report/cont_neg_loss": 1.8261127471923828, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.004392846953123808, "report/cont_pred": 0.9941490888595581, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.05442722886800766, "report/image_loss_std": 0.07883301377296448, "report/model_loss_mean": 0.6774013042449951, "report/model_loss_std": 0.356343537569046, "report/post_ent_mag": 46.68840026855469, "report/post_ent_max": 46.68840026855469, "report/post_ent_mean": 32.26459884643555, "report/post_ent_min": 25.517913818359375, "report/post_ent_std": 4.556927680969238, "report/prior_ent_mag": 50.6849365234375, "report/prior_ent_max": 50.6849365234375, "report/prior_ent_mean": 34.055450439453125, "report/prior_ent_min": 25.50843048095703, "report/prior_ent_std": 4.886890411376953, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0014190673828125, "report/reward_loss_mean": 0.011465085670351982, "report/reward_loss_std": 0.1841931939125061, "report/reward_max_data": 0.8031250238418579, "report/reward_max_pred": 0.04574871063232422, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0033408531453460455, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.162948131561279, "report/reward_pred": 0.001735071069560945, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.9921875, "eval/cont_loss_mean": 0.042290423065423965, "eval/cont_loss_std": 0.4384176731109619, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 4.56212043762207, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.006701208185404539, "eval/cont_pred": 0.993299663066864, "eval/cont_rate": 0.9921875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.09859459847211838, "eval/image_loss_std": 0.11146476119756699, "eval/model_loss_mean": 0.7833861112594604, "eval/model_loss_std": 0.9174314737319946, "eval/post_ent_mag": 46.3818244934082, "eval/post_ent_max": 46.3818244934082, "eval/post_ent_mean": 34.44364929199219, "eval/post_ent_min": 25.543560028076172, "eval/post_ent_std": 4.231101036071777, "eval/prior_ent_mag": 50.46675109863281, "eval/prior_ent_max": 50.46675109863281, "eval/prior_ent_mean": 36.17951965332031, "eval/prior_ent_min": 27.767375946044922, "eval/prior_ent_std": 4.55054235458374, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.004330444149672985, "eval/reward_loss_mean": 0.042501069605350494, "eval/reward_loss_std": 0.4805137813091278, "eval/reward_max_data": 0.809374988079071, "eval/reward_max_pred": 0.09748899936676025, "eval/reward_neg_acc": 0.9999999403953552, "eval/reward_neg_loss": 0.005347812082618475, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.440338611602783, "eval/reward_pred": 0.0028199031949043274, "eval/reward_rate": 0.0068359375, "replay/size": 1000000.0, "replay/inserts": 32304.0, "replay/samples": 32304.0, "replay/insert_wait_avg": 1.2385012667742385e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.085153078076389e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5432.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.140388719112076e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.4007091522216797e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0271284580231, "timer/env.step_count": 4038.0, "timer/env.step_total": 38.98596453666687, "timer/env.step_frac": 0.03898490693625552, "timer/env.step_avg": 0.009654770811457868, "timer/env.step_min": 0.0075359344482421875, "timer/env.step_max": 0.042206525802612305, "timer/replay._sample_count": 32304.0, "timer/replay._sample_total": 16.20264506340027, "timer/replay._sample_frac": 0.01620220552254787, "timer/replay._sample_avg": 0.0005015677644688047, "timer/replay._sample_min": 0.0004119873046875, "timer/replay._sample_max": 0.010607481002807617, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4717.0, "timer/agent.policy_total": 48.9327929019928, "timer/agent.policy_frac": 0.048931465466785874, "timer/agent.policy_avg": 0.010373710600380072, "timer/agent.policy_min": 0.0084228515625, "timer/agent.policy_max": 0.09522390365600586, "timer/dataset_train_count": 2019.0, "timer/dataset_train_total": 0.21606707572937012, "timer/dataset_train_frac": 0.00021606121432178697, "timer/dataset_train_avg": 0.00010701687752816746, "timer/dataset_train_min": 9.322166442871094e-05, "timer/dataset_train_max": 0.0007395744323730469, "timer/agent.train_count": 2019.0, "timer/agent.train_total": 898.5187857151031, "timer/agent.train_frac": 0.8984944109471918, "timer/agent.train_avg": 0.44503159272664844, "timer/agent.train_min": 0.434309720993042, "timer/agent.train_max": 0.6858060359954834, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47724390029907227, "timer/agent.report_frac": 0.0004772309537591759, "timer/agent.report_avg": 0.23862195014953613, "timer/agent.report_min": 0.23096656799316406, "timer/agent.report_max": 0.2462773323059082, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 4.38690185546875e-05, "timer/dataset_eval_frac": 4.3867828488143795e-08, "timer/dataset_eval_avg": 4.38690185546875e-05, "timer/dataset_eval_min": 4.38690185546875e-05, "timer/dataset_eval_max": 4.38690185546875e-05, "fps": 32.30252599023478}
{"step": 1131848, "time": 35235.11929559708, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1131920, "time": 35237.51613211632, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 1132104, "time": 35242.84552693367, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1132200, "time": 35245.871158123016, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1132656, "time": 35259.914027929306, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1132696, "time": 35260.9093773365, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1132912, "time": 35267.695833683014, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1133024, "time": 35271.085902929306, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1133328, "time": 35280.393590688705, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1133392, "time": 35282.336415052414, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1133680, "time": 35291.02807927132, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1133752, "time": 35293.02778983116, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1133872, "time": 35296.88625741005, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1133888, "time": 35297.376190662384, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1134160, "time": 35305.717124700546, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1134376, "time": 35312.04173374176, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1134512, "time": 35316.38788032532, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1134752, "time": 35323.63224411011, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1134856, "time": 35326.56656265259, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 1134904, "time": 35328.01544547081, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1134936, "time": 35328.99084877968, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 1135104, "time": 35334.280677080154, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1135312, "time": 35340.695479393005, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1135368, "time": 35342.17396378517, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1135704, "time": 35352.34065532684, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1135720, "time": 35352.8313395977, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1135744, "time": 35353.78637456894, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1135888, "time": 35358.170129776, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1135992, "time": 35361.12481665611, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1136016, "time": 35362.07367801666, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 1136064, "time": 35363.535514354706, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1136152, "time": 35366.09843111038, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1136288, "time": 35370.50818681717, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1136584, "time": 35379.330183029175, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1136608, "time": 35380.30339336395, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1136672, "time": 35382.23964595795, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1136840, "time": 35387.12394070625, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1137024, "time": 35392.92037272453, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1137352, "time": 35402.75916862488, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 1137368, "time": 35403.25062394142, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1137416, "time": 35404.721963882446, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1137472, "time": 35406.652772665024, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1137696, "time": 35413.420585393906, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1137872, "time": 35418.76253461838, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1137944, "time": 35420.72021651268, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1138056, "time": 35424.11429262161, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1138224, "time": 35429.49530529976, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1138280, "time": 35430.964555978775, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1138488, "time": 35437.26747560501, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1138600, "time": 35440.67549943924, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1138632, "time": 35441.64722943306, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1138728, "time": 35445.053678274155, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1138792, "time": 35446.986958026886, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1138832, "time": 35448.44184708595, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1139304, "time": 35462.60881495476, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1139336, "time": 35463.5977435112, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1139336, "time": 35463.6120994091, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1139336, "time": 35463.62029051781, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1139384, "time": 35465.06673884392, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1139416, "time": 35466.03466105461, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1139456, "time": 35467.46464371681, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1139768, "time": 35476.71579623222, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1139784, "time": 35477.20770597458, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1139840, "time": 35479.13961458206, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1140040, "time": 35485.01442241669, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 1140048, "time": 35485.927929878235, "eval_episode/length": 21.0, "eval_episode/score": 0.934374988079071, "eval_episode/reward_rate": 0.045454545454545456}
{"step": 1140048, "time": 35486.73221492767, "eval_episode/length": 65.0, "eval_episode/score": 0.796875, "eval_episode/reward_rate": 0.015151515151515152}
{"step": 1140048, "time": 35487.347282886505, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 1140048, "time": 35487.56661748886, "eval_episode/length": 110.0, "eval_episode/score": 0.65625, "eval_episode/reward_rate": 0.009009009009009009}
{"step": 1140048, "time": 35487.684715270996, "eval_episode/length": 94.0, "eval_episode/score": 0.706250011920929, "eval_episode/reward_rate": 0.010526315789473684}
{"step": 1140048, "time": 35488.15572500229, "eval_episode/length": 140.0, "eval_episode/score": 0.5625, "eval_episode/reward_rate": 0.0070921985815602835}
{"step": 1140048, "time": 35488.507575035095, "eval_episode/length": 158.0, "eval_episode/score": 0.5062500238418579, "eval_episode/reward_rate": 0.006289308176100629}
{"step": 1140048, "time": 35488.65562725067, "eval_episode/length": 55.0, "eval_episode/score": 0.828125, "eval_episode/reward_rate": 0.017857142857142856}
{"step": 1140120, "time": 35490.62201619148, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1140328, "time": 35496.94390010834, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1140592, "time": 35505.16910982132, "episode/length": 219.0, "episode/score": 0.31562501192092896, "episode/reward_rate": 0.004545454545454545, "episode/intrinsic_return": 0.0}
{"step": 1140704, "time": 35508.54265975952, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 1140896, "time": 35514.341648340225, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1141096, "time": 35520.29720664024, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 1141120, "time": 35521.25092673302, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1141320, "time": 35527.08520388603, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1141648, "time": 35537.25666928291, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1141656, "time": 35537.2859711647, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1141672, "time": 35537.7741727829, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1141736, "time": 35539.727645397186, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1142096, "time": 35550.9082596302, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1142160, "time": 35552.84433412552, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1142232, "time": 35554.81947636604, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1142376, "time": 35559.19460749626, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1142432, "time": 35561.10923528671, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1142608, "time": 35566.424983501434, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1142992, "time": 35578.232325553894, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1143248, "time": 35585.96658158302, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1143272, "time": 35586.47567820549, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1143632, "time": 35597.57376408577, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1143728, "time": 35600.45759344101, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1143840, "time": 35603.844193696976, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1143944, "time": 35606.82775950432, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 1143960, "time": 35607.33833050728, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1143992, "time": 35608.307421684265, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1144048, "time": 35610.21679735184, "episode/length": 226.0, "episode/score": 0.29374998807907104, "episode/reward_rate": 0.004405286343612335, "episode/intrinsic_return": 0.0}
{"step": 1144232, "time": 35615.56039881706, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1144504, "time": 35623.759637355804, "episode/length": 258.0, "episode/score": 0.19374999403953552, "episode/reward_rate": 0.003861003861003861, "episode/intrinsic_return": 0.0}
{"step": 1144688, "time": 35629.54278707504, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1144720, "time": 35630.505538225174, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1144832, "time": 35633.88791465759, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1145040, "time": 35640.269525527954, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1145256, "time": 35646.604828834534, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1145304, "time": 35648.059435367584, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 1145504, "time": 35654.30853509903, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1145576, "time": 35656.28855347633, "episode/length": 203.0, "episode/score": 0.3656249940395355, "episode/reward_rate": 0.004901960784313725, "episode/intrinsic_return": 0.0}
{"step": 1145648, "time": 35658.69949173927, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 1145904, "time": 35666.53856730461, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1146000, "time": 35669.43198251724, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1146040, "time": 35670.449969530106, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1146048, "time": 35670.91789317131, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1146160, "time": 35674.29615974426, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 1146264, "time": 35677.236342191696, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 1146552, "time": 35685.934046030045, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1146568, "time": 35686.421001672745, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1146576, "time": 35686.88823723793, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1146928, "time": 35698.13452172279, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1147104, "time": 35703.48724317551, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1147136, "time": 35704.45987153053, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1147144, "time": 35704.48892354965, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1147328, "time": 35710.30164575577, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1147432, "time": 35713.20942926407, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1147576, "time": 35717.56610369682, "episode/length": 196.0, "episode/score": 0.38749998807907104, "episode/reward_rate": 0.005076142131979695, "episode/intrinsic_return": 0.0}
{"step": 1147728, "time": 35722.384367227554, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 1147928, "time": 35728.307973861694, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1147928, "time": 35728.31565952301, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1147968, "time": 35729.767973423004, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1148080, "time": 35733.150389671326, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1148176, "time": 35736.064643383026, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1148208, "time": 35737.03066635132, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1148216, "time": 35737.05973315239, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1148808, "time": 35754.995980501175, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1148984, "time": 35760.38996720314, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1148984, "time": 35760.39696645737, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1149072, "time": 35763.290578365326, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1149352, "time": 35771.527369737625, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1149624, "time": 35779.76917934418, "episode/length": 211.0, "episode/score": 0.34062498807907104, "episode/reward_rate": 0.0047169811320754715, "episode/intrinsic_return": 0.0}
{"step": 1149872, "time": 35787.569199323654, "episode/length": 237.0, "episode/score": 0.2593750059604645, "episode/reward_rate": 0.004201680672268907, "episode/intrinsic_return": 0.0}
{"step": 1149896, "time": 35788.07829260826, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1149904, "time": 35788.54775738716, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1150032, "time": 35793.29925560951, "eval_episode/length": 48.0, "eval_episode/score": 0.8500000238418579, "eval_episode/reward_rate": 0.02040816326530612}
{"step": 1150032, "time": 35793.34149312973, "eval_episode/length": 50.0, "eval_episode/score": 0.84375, "eval_episode/reward_rate": 0.0196078431372549}
{"step": 1150032, "time": 35793.528215646744, "eval_episode/length": 60.0, "eval_episode/score": 0.8125, "eval_episode/reward_rate": 0.01639344262295082}
{"step": 1150032, "time": 35793.83970570564, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 1150032, "time": 35794.01116704941, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 1150032, "time": 35794.77576994896, "eval_episode/length": 78.0, "eval_episode/score": 0.7562500238418579, "eval_episode/reward_rate": 0.012658227848101266}
{"step": 1150032, "time": 35795.27362704277, "eval_episode/length": 157.0, "eval_episode/score": 0.5093749761581421, "eval_episode/reward_rate": 0.006329113924050633}
{"step": 1150032, "time": 35795.38559103012, "eval_episode/length": 163.0, "eval_episode/score": 0.4906249940395355, "eval_episode/reward_rate": 0.006097560975609756}
{"step": 1150040, "time": 35795.412469387054, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1150192, "time": 35800.23734164238, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1150320, "time": 35804.11069560051, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 1150488, "time": 35809.01657128334, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1150584, "time": 35811.96933221817, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1150624, "time": 35813.41276097298, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1150752, "time": 35817.435421705246, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1151040, "time": 35826.16104888916, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1151080, "time": 35827.14855694771, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1151088, "time": 35827.61656165123, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1151248, "time": 35832.45165848732, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1151552, "time": 35841.65326523781, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1151864, "time": 35850.968943595886, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1151904, "time": 35852.40951514244, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1152176, "time": 35860.64605283737, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 1152232, "time": 35862.1242518425, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1152352, "time": 35866.006266355515, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1152416, "time": 35867.94307780266, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 1152504, "time": 35870.395829916, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1152936, "time": 35883.541043519974, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1153240, "time": 35892.6983127594, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1153616, "time": 35904.374839544296, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1153808, "time": 35910.284859895706, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1153864, "time": 35911.75765752792, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1154176, "time": 35921.40811634064, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1154288, "time": 35924.816334962845, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1154488, "time": 35930.64485669136, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1154544, "time": 35932.57848572731, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1154560, "time": 35933.06602931023, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1154584, "time": 35933.57883310318, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1154816, "time": 35940.920038700104, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1154888, "time": 35942.888785123825, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 1154912, "time": 35943.83940887451, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 1155136, "time": 35951.02282500267, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 1155224, "time": 35953.47325372696, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1155400, "time": 35958.79269385338, "episode/length": 222.0, "episode/score": 0.3062500059604645, "episode/reward_rate": 0.004484304932735426, "episode/intrinsic_return": 0.0}
{"step": 1155544, "time": 35963.16167974472, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1155792, "time": 35970.96523952484, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1156016, "time": 35977.73922085762, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1156056, "time": 35978.72811841965, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1156200, "time": 35983.09911417961, "episode/length": 238.0, "episode/score": 0.2562499940395355, "episode/reward_rate": 0.0041841004184100415, "episode/intrinsic_return": 0.0}
{"step": 1156312, "time": 35986.5089507103, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1156488, "time": 35991.84204554558, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1156792, "time": 36001.183658361435, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1156936, "time": 36005.55726337433, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1157200, "time": 36013.75018072128, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1157232, "time": 36014.7478055954, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 1157360, "time": 36018.597960710526, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1157392, "time": 36019.58769392967, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 1157712, "time": 36029.45252275467, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1157856, "time": 36033.82072043419, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1157896, "time": 36034.83417081833, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1158056, "time": 36039.67666220665, "episode/length": 19.0, "episode/score": 0.940625011920929, "episode/reward_rate": 0.05, "episode/intrinsic_return": 0.0}
{"step": 1158240, "time": 36045.453431367874, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1158272, "time": 36046.424636125565, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1158328, "time": 36047.898307561874, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1158408, "time": 36050.32845687866, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1158440, "time": 36051.30185627937, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 1158792, "time": 36062.13856673241, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1158904, "time": 36065.53379678726, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1159008, "time": 36068.906490564346, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1159064, "time": 36070.376547813416, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1159096, "time": 36071.353452920914, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1159104, "time": 36071.8232216835, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1159200, "time": 36074.729576826096, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 1159512, "time": 36083.9436275959, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1159624, "time": 36087.423422813416, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1159704, "time": 36089.85544538498, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1159752, "time": 36091.32557463646, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 1159792, "time": 36092.78523564339, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1159840, "time": 36094.23710536957, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 1159912, "time": 36096.20853948593, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1160016, "time": 36100.12028050423, "eval_episode/length": 26.0, "eval_episode/score": 0.918749988079071, "eval_episode/reward_rate": 0.037037037037037035}
{"step": 1160016, "time": 36100.572437763214, "eval_episode/length": 50.0, "eval_episode/score": 0.84375, "eval_episode/reward_rate": 0.0196078431372549}
{"step": 1160016, "time": 36101.05318593979, "eval_episode/length": 76.0, "eval_episode/score": 0.762499988079071, "eval_episode/reward_rate": 0.012987012987012988}
{"step": 1160016, "time": 36101.0787217617, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 1160016, "time": 36101.45405912399, "eval_episode/length": 97.0, "eval_episode/score": 0.6968749761581421, "eval_episode/reward_rate": 0.01020408163265306}
{"step": 1160016, "time": 36101.94352173805, "eval_episode/length": 45.0, "eval_episode/score": 0.859375, "eval_episode/reward_rate": 0.021739130434782608}
{"step": 1160016, "time": 36102.26081323624, "eval_episode/length": 139.0, "eval_episode/score": 0.565625011920929, "eval_episode/reward_rate": 0.007142857142857143}
{"step": 1160016, "time": 36102.565190792084, "eval_episode/length": 156.0, "eval_episode/score": 0.512499988079071, "eval_episode/reward_rate": 0.006369426751592357}
{"step": 1160144, "time": 36106.45929026604, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1160392, "time": 36113.755883693695, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 1160408, "time": 36114.245127916336, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1160448, "time": 36115.85175251961, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1160552, "time": 36118.76453566551, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1160688, "time": 36123.10065960884, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1160824, "time": 36126.99575424194, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1160968, "time": 36131.35705971718, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 1161056, "time": 36134.23640704155, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1161080, "time": 36134.76608300209, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1161136, "time": 36136.678698301315, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1161360, "time": 36143.43854141235, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1161360, "time": 36143.44589424133, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1161376, "time": 36143.93356657028, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1161408, "time": 36144.944465875626, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1161536, "time": 36148.87048101425, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1161720, "time": 36154.240226984024, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 1161864, "time": 36158.58766555786, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 1161872, "time": 36159.07355904579, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1161928, "time": 36160.54565501213, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1161976, "time": 36162.00215244293, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1162040, "time": 36163.96887564659, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1162168, "time": 36167.841086387634, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1162368, "time": 36174.1389234066, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1162392, "time": 36174.65104866028, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1162680, "time": 36183.533674001694, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1162768, "time": 36186.41074681282, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1162912, "time": 36190.78587055206, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1162976, "time": 36192.72115802765, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 1163000, "time": 36193.2605805397, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1163008, "time": 36193.72926926613, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1163048, "time": 36194.72538328171, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1163336, "time": 36203.97805595398, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 1163440, "time": 36207.46722316742, "episode/length": 196.0, "episode/score": 0.38749998807907104, "episode/reward_rate": 0.005076142131979695, "episode/intrinsic_return": 0.0}
{"step": 1163448, "time": 36207.49747943878, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1163608, "time": 36212.39458489418, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1163616, "time": 36212.8617503643, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1163648, "time": 36213.84851503372, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1164121, "time": 36229.00653839111, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.611791150323276, "train/action_min": 0.0, "train/action_std": 1.9411673481241236, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.009724473150612171, "train/actor_opt_grad_steps": 71650.0, "train/actor_opt_loss": -17.321327303430717, "train/adv_mag": 0.9041666265191703, "train/adv_max": 0.35317085470472065, "train/adv_mean": 0.0004712682694024372, "train/adv_min": -0.8168359469310403, "train/adv_std": 0.02936887192847253, "train/cont_avg": 0.9937846366995073, "train/cont_loss_mean": 0.024697590935883557, "train/cont_loss_std": 0.277294744631927, "train/cont_neg_acc": 0.1754265718235828, "train/cont_neg_loss": 3.137866193705266, "train/cont_pos_acc": 0.999840332663118, "train/cont_pos_loss": 0.005262106358821463, "train/cont_pred": 0.9937494085927315, "train/cont_rate": 0.9937846366995073, "train/dyn_loss_mean": 1.0000032392041436, "train/dyn_loss_std": 4.8885392621526576e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.15372890982721826, "train/extr_critic_critic_opt_grad_steps": 71650.0, "train/extr_critic_critic_opt_loss": 4714.862394887238, "train/extr_critic_mag": 1.642693476136682, "train/extr_critic_max": 1.642693476136682, "train/extr_critic_mean": 1.5524936685421196, "train/extr_critic_min": 1.199348557758801, "train/extr_critic_std": 0.028209081259120274, "train/extr_return_normed_mag": 0.901546894623141, "train/extr_return_normed_max": 0.30037505109909135, "train/extr_return_normed_mean": 0.05515974318709573, "train/extr_return_normed_min": -0.7991608569187484, "train/extr_return_normed_std": 0.04184596234097563, "train/extr_return_rate": 0.9996527007647923, "train/extr_return_raw_mag": 1.7981801778812128, "train/extr_return_raw_max": 1.7981801778812128, "train/extr_return_raw_mean": 1.552964941621414, "train/extr_return_raw_min": 0.6986442698633729, "train/extr_return_raw_std": 0.041845962451082734, "train/extr_reward_mag": 0.28135095147663736, "train/extr_reward_max": 0.28135095147663736, "train/extr_reward_mean": 0.002860421330892834, "train/extr_reward_min": 1.0511558044132928e-07, "train/extr_reward_std": 0.009857844664563834, "train/image_loss_mean": 0.0871860665897724, "train/image_loss_std": 0.10344919936703931, "train/model_loss_mean": 0.7333116284732161, "train/model_loss_std": 0.5468050039974339, "train/model_opt_grad_norm": 16.329132769367483, "train/model_opt_grad_steps": 71586.52216748768, "train/model_opt_loss": 3830.336540034252, "train/model_opt_model_opt_grad_overflow": 0.0049261083743842365, "train/model_opt_model_opt_grad_scale": 5221.674876847291, "train/policy_entropy_mag": 1.2545628353879956, "train/policy_entropy_max": 1.2545628353879956, "train/policy_entropy_mean": 0.08706353380909107, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.10209997324961159, "train/policy_logprob_mag": 6.551080240991903, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.08676526475275678, "train/policy_logprob_min": -6.551080240991903, "train/policy_logprob_std": 0.6232018438466077, "train/policy_randomness_mag": 0.6447178013806273, "train/policy_randomness_max": 0.6447178013806273, "train/policy_randomness_mean": 0.04474180762477109, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.05246901036850337, "train/post_ent_mag": 44.856865229865015, "train/post_ent_max": 44.856865229865015, "train/post_ent_mean": 34.05254658102402, "train/post_ent_min": 27.772250283527843, "train/post_ent_std": 3.5717595105100735, "train/prior_ent_mag": 44.334636594274365, "train/prior_ent_max": 44.334636594274365, "train/prior_ent_mean": 34.36852403462227, "train/prior_ent_min": 27.96476137696816, "train/prior_ent_std": 3.222761111893677, "train/rep_loss_mean": 1.0000032392041436, "train/rep_loss_std": 4.8885392621526576e-05, "train/reward_avg": 0.002953109360246098, "train/reward_loss_mean": 0.021426005516054447, "train/reward_loss_std": 0.26962399501995793, "train/reward_max_data": 0.8011699511206208, "train/reward_max_pred": 0.27836338052608695, "train/reward_neg_acc": 0.999555469440122, "train/reward_neg_loss": 0.004003501896347318, "train/reward_pos_acc": 0.12721397399459736, "train/reward_pos_loss": 4.049662012865047, "train/reward_pred": 0.0023248699497147073, "train/reward_rate": 0.004324776785714286, "train_stats/mean_log_entropy": 0.07684415554710727, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 0.034136150032281876, "report/cont_loss_std": 0.36362722516059875, "report/cont_neg_acc": 0.125, "report/cont_neg_loss": 3.702968120574951, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.005247706547379494, "report/cont_pred": 0.9939099550247192, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.08951351791620255, "report/image_loss_std": 0.10750678926706314, "report/model_loss_mean": 0.7501797676086426, "report/model_loss_std": 0.6530020236968994, "report/post_ent_mag": 45.78700256347656, "report/post_ent_max": 45.78700256347656, "report/post_ent_mean": 34.82000732421875, "report/post_ent_min": 28.798355102539062, "report/post_ent_std": 3.533043384552002, "report/prior_ent_mag": 41.86140823364258, "report/prior_ent_max": 41.86140823364258, "report/prior_ent_mean": 35.09855651855469, "report/prior_ent_min": 29.44460105895996, "report/prior_ent_std": 2.3906023502349854, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.002767944475635886, "report/reward_loss_mean": 0.02653007209300995, "report/reward_loss_std": 0.3235434591770172, "report/reward_max_data": 0.7250000238418579, "report/reward_max_pred": 0.04422962665557861, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.004130219109356403, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.591620445251465, "report/reward_pred": 0.0022127763368189335, "report/reward_rate": 0.0048828125, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.032947883009910583, "eval/cont_loss_std": 0.3858089745044708, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 4.819915771484375, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.004733931738883257, "eval/cont_pred": 0.9952595233917236, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.11436501890420914, "eval/image_loss_std": 0.11591210216283798, "eval/model_loss_mean": 0.7689801454544067, "eval/model_loss_std": 0.6504232883453369, "eval/post_ent_mag": 45.85554504394531, "eval/post_ent_max": 45.85554504394531, "eval/post_ent_mean": 34.8797721862793, "eval/post_ent_min": 28.71065330505371, "eval/post_ent_std": 3.7286744117736816, "eval/prior_ent_mag": 41.838584899902344, "eval/prior_ent_max": 41.838584899902344, "eval/prior_ent_mean": 35.20073699951172, "eval/prior_ent_min": 29.938047409057617, "eval/prior_ent_std": 2.40972638130188, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0030975341796875, "eval/reward_loss_mean": 0.0216672345995903, "eval/reward_loss_std": 0.29369959235191345, "eval/reward_max_data": 0.8999999761581421, "eval/reward_max_pred": 0.06414508819580078, "eval/reward_neg_acc": 0.9999999403953552, "eval/reward_neg_loss": 0.003396193729713559, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 4.680782794952393, "eval/reward_pred": 0.0017471181927248836, "eval/reward_rate": 0.00390625, "replay/size": 1000000.0, "replay/inserts": 32480.0, "replay/samples": 32480.0, "replay/insert_wait_avg": 1.2590013114102368e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.977920212769156e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3904.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0830823515282302e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0132789611816406e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0607233047485, "timer/env.step_count": 4060.0, "timer/env.step_total": 39.13762331008911, "timer/env.step_frac": 0.039135246888565886, "timer/env.step_avg": 0.009639808697066283, "timer/env.step_min": 0.007607936859130859, "timer/env.step_max": 0.03620409965515137, "timer/replay._sample_count": 32480.0, "timer/replay._sample_total": 16.257859468460083, "timer/replay._sample_frac": 0.016256872297449307, "timer/replay._sample_avg": 0.0005005498604821454, "timer/replay._sample_min": 0.0004112720489501953, "timer/replay._sample_max": 0.011086702346801758, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4548.0, "timer/agent.policy_total": 47.494688749313354, "timer/agent.policy_frac": 0.04749180488997196, "timer/agent.policy_avg": 0.010442983454114634, "timer/agent.policy_min": 0.009070634841918945, "timer/agent.policy_max": 0.08166742324829102, "timer/dataset_train_count": 2030.0, "timer/dataset_train_total": 0.22043991088867188, "timer/dataset_train_frac": 0.0002204265258615673, "timer/dataset_train_avg": 0.00010859108910772014, "timer/dataset_train_min": 9.489059448242188e-05, "timer/dataset_train_max": 0.00040984153747558594, "timer/agent.train_count": 2030.0, "timer/agent.train_total": 902.8467586040497, "timer/agent.train_frac": 0.9027919380940683, "timer/agent.train_avg": 0.44475209783450725, "timer/agent.train_min": 0.43524622917175293, "timer/agent.train_max": 0.6659843921661377, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4823904037475586, "timer/agent.report_frac": 0.0004823611131866837, "timer/agent.report_avg": 0.2411952018737793, "timer/agent.report_min": 0.23535799980163574, "timer/agent.report_max": 0.24703240394592285, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.337860107421875e-05, "timer/dataset_eval_frac": 3.3376574338323744e-08, "timer/dataset_eval_avg": 3.337860107421875e-05, "timer/dataset_eval_min": 3.337860107421875e-05, "timer/dataset_eval_max": 3.337860107421875e-05, "fps": 32.47744940414396}
{"step": 1164280, "time": 36233.55613589287, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1164384, "time": 36236.995426893234, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1164392, "time": 36237.02359414101, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1164392, "time": 36237.03065276146, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1164496, "time": 36240.42020726204, "episode/length": 215.0, "episode/score": 0.328125, "episode/reward_rate": 0.004629629629629629, "episode/intrinsic_return": 0.0}
{"step": 1164512, "time": 36240.906572818756, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1164640, "time": 36244.81541109085, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1164792, "time": 36249.27719926834, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1164976, "time": 36255.07531404495, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1165016, "time": 36256.06842947006, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1165232, "time": 36262.863985061646, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1165312, "time": 36265.36172914505, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1165360, "time": 36266.81414270401, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1165568, "time": 36273.11400747299, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1165608, "time": 36274.10492324829, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1165904, "time": 36283.273983478546, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1166024, "time": 36286.686717033386, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1166128, "time": 36290.05997133255, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 1166304, "time": 36295.502933979034, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1166496, "time": 36301.322508096695, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1166696, "time": 36307.170372486115, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1166704, "time": 36307.641765356064, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1166792, "time": 36310.07020306587, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1166984, "time": 36315.857915878296, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1167120, "time": 36320.20709371567, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1167128, "time": 36320.23491978645, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 1167368, "time": 36327.593220710754, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1167672, "time": 36336.84452223778, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1168040, "time": 36347.992795705795, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1168072, "time": 36348.95900225639, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1168200, "time": 36352.83320689201, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1168440, "time": 36360.24054288864, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1168808, "time": 36371.39979171753, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1168824, "time": 36371.89274430275, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1168904, "time": 36374.31726884842, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1168912, "time": 36374.809941768646, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1169000, "time": 36377.27184844017, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1169008, "time": 36377.7446949482, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1169368, "time": 36388.58708548546, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 1169432, "time": 36390.58233189583, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1169600, "time": 36395.97670316696, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1169760, "time": 36400.91782426834, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1169864, "time": 36403.88824701309, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1169984, "time": 36407.821184396744, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1169992, "time": 36407.84924554825, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1170000, "time": 36409.346632003784, "eval_episode/length": 56.0, "eval_episode/score": 0.824999988079071, "eval_episode/reward_rate": 0.017543859649122806}
{"step": 1170000, "time": 36410.225420713425, "eval_episode/length": 105.0, "eval_episode/score": 0.671875, "eval_episode/reward_rate": 0.009433962264150943}
{"step": 1170000, "time": 36410.32153511047, "eval_episode/length": 110.0, "eval_episode/score": 0.65625, "eval_episode/reward_rate": 0.009009009009009009}
{"step": 1170000, "time": 36410.47631430626, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 1170000, "time": 36410.776094675064, "eval_episode/length": 134.0, "eval_episode/score": 0.581250011920929, "eval_episode/reward_rate": 0.007407407407407408}
{"step": 1170000, "time": 36411.076421022415, "eval_episode/length": 151.0, "eval_episode/score": 0.528124988079071, "eval_episode/reward_rate": 0.006578947368421052}
{"step": 1170000, "time": 36411.27180147171, "eval_episode/length": 51.0, "eval_episode/score": 0.840624988079071, "eval_episode/reward_rate": 0.019230769230769232}
{"step": 1170000, "time": 36412.43737959862, "eval_episode/length": 93.0, "eval_episode/score": 0.7093750238418579, "eval_episode/reward_rate": 0.010638297872340425}
{"step": 1170112, "time": 36415.93500185013, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 1170368, "time": 36423.70790243149, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 1170648, "time": 36431.9517455101, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1170656, "time": 36432.421250104904, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1171072, "time": 36445.11108541489, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1171248, "time": 36450.477986097336, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1171416, "time": 36455.352628707886, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 1171744, "time": 36465.976392030716, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1172000, "time": 36473.745633125305, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1172040, "time": 36474.737481594086, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1172176, "time": 36479.20172834396, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1172208, "time": 36480.17330121994, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1172296, "time": 36482.61977100372, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1172384, "time": 36485.497042655945, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1172560, "time": 36490.80684995651, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1172680, "time": 36494.21091723442, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1172752, "time": 36496.61751866341, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1172760, "time": 36496.644535303116, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1172960, "time": 36502.88853383064, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1173184, "time": 36509.69511270523, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1173312, "time": 36513.56181907654, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1174200, "time": 36540.372250556946, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 1174312, "time": 36543.75976419449, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1174336, "time": 36544.71507740021, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1174448, "time": 36548.116948604584, "episode/length": 16.0, "episode/score": 0.949999988079071, "episode/reward_rate": 0.058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 1174608, "time": 36552.95758509636, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1174760, "time": 36557.34778738022, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1174872, "time": 36560.753571510315, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1174896, "time": 36561.69943809509, "episode/length": 213.0, "episode/score": 0.3343749940395355, "episode/reward_rate": 0.004672897196261682, "episode/intrinsic_return": 0.0}
{"step": 1174992, "time": 36564.624695301056, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1175064, "time": 36566.689984083176, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1175120, "time": 36568.59821105003, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1175336, "time": 36574.94468188286, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1175392, "time": 36576.85179591179, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1175520, "time": 36580.73630809784, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1175600, "time": 36583.15089511871, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1175616, "time": 36583.64143252373, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1175864, "time": 36590.92551255226, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1176048, "time": 36596.81331729889, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1176080, "time": 36597.78544640541, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1176104, "time": 36598.29463624954, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1176552, "time": 36611.8206474781, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 1176584, "time": 36612.784393548965, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1176608, "time": 36613.74890732765, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 1176720, "time": 36617.13932132721, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1176760, "time": 36618.15450000763, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1177128, "time": 36629.376098155975, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1177128, "time": 36629.38342213631, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1177184, "time": 36631.29562997818, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1177240, "time": 36632.78551244736, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1177432, "time": 36638.612122774124, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1177704, "time": 36646.85390329361, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1177912, "time": 36653.146238565445, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1178384, "time": 36667.69213628769, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 1178408, "time": 36668.203674316406, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1178576, "time": 36673.5064766407, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 1178920, "time": 36683.699021101, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1179032, "time": 36687.22105097771, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1179176, "time": 36691.59331512451, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1179440, "time": 36699.807472229004, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1179728, "time": 36709.00712680817, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1180016, "time": 36717.81356167793, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1180088, "time": 36720.600237846375, "eval_episode/length": 42.0, "eval_episode/score": 0.8687499761581421, "eval_episode/reward_rate": 0.023255813953488372}
{"step": 1180088, "time": 36721.08371424675, "eval_episode/length": 67.0, "eval_episode/score": 0.7906249761581421, "eval_episode/reward_rate": 0.014705882352941176}
{"step": 1180088, "time": 36721.837334394455, "eval_episode/length": 108.0, "eval_episode/score": 0.6625000238418579, "eval_episode/reward_rate": 0.009174311926605505}
{"step": 1180088, "time": 36721.965811014175, "eval_episode/length": 114.0, "eval_episode/score": 0.643750011920929, "eval_episode/reward_rate": 0.008695652173913044}
{"step": 1180088, "time": 36722.218052864075, "eval_episode/length": 126.0, "eval_episode/score": 0.606249988079071, "eval_episode/reward_rate": 0.007874015748031496}
{"step": 1180088, "time": 36723.583755254745, "eval_episode/length": 166.0, "eval_episode/score": 0.48124998807907104, "eval_episode/reward_rate": 0.005988023952095809}
{"step": 1180088, "time": 36723.66624927521, "eval_episode/length": 60.0, "eval_episode/score": 0.8125, "eval_episode/reward_rate": 0.01639344262295082}
{"step": 1180088, "time": 36724.11882686615, "eval_episode/length": 125.0, "eval_episode/score": 0.609375, "eval_episode/reward_rate": 0.007936507936507936}
{"step": 1180192, "time": 36727.502212285995, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1180224, "time": 36728.475385427475, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1180328, "time": 36731.41531872749, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1180696, "time": 36742.587584257126, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1180720, "time": 36743.543476104736, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1181168, "time": 36757.19557642937, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1181184, "time": 36757.68767738342, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1181344, "time": 36762.53838682175, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1181488, "time": 36766.89882683754, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1181528, "time": 36767.888499736786, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 1181552, "time": 36768.85302066803, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 1181656, "time": 36771.76544427872, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 1181720, "time": 36773.70986175537, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1182280, "time": 36790.780040979385, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1182456, "time": 36796.109389066696, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 1182496, "time": 36797.54793548584, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1182648, "time": 36801.938433885574, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1182648, "time": 36801.94655299187, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1182776, "time": 36805.927077531815, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1182992, "time": 36812.709741830826, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1183008, "time": 36813.198046922684, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1183096, "time": 36815.6388938427, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1183496, "time": 36827.757132291794, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1183568, "time": 36830.15526986122, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1183640, "time": 36832.14396882057, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1183832, "time": 36838.0615978241, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1184000, "time": 36843.40155315399, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 1184248, "time": 36850.68444609642, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1184464, "time": 36857.45505142212, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 1184488, "time": 36857.96746134758, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1184600, "time": 36861.38712453842, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1184616, "time": 36861.87697792053, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1184696, "time": 36864.3139462471, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1184736, "time": 36865.849774837494, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1184808, "time": 36867.85025596619, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1184864, "time": 36869.766170978546, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1185000, "time": 36873.68764543533, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1185328, "time": 36883.89117240906, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1185384, "time": 36885.36861562729, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1185576, "time": 36891.21247315407, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1185880, "time": 36900.56225657463, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1185984, "time": 36903.96391296387, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1186040, "time": 36905.48066353798, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 1186216, "time": 36910.83465886116, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1186312, "time": 36913.74800181389, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1186328, "time": 36914.23759508133, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1186696, "time": 36925.56219339371, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1186832, "time": 36929.92400288582, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1186848, "time": 36930.412848711014, "episode/length": 182.0, "episode/score": 0.4312500059604645, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.0}
{"step": 1186960, "time": 36933.80662369728, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1187176, "time": 36940.14874839783, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1187376, "time": 36946.416625738144, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 1187432, "time": 36947.89790844917, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1187856, "time": 36961.661422252655, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1187896, "time": 36962.665215969086, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1188192, "time": 36971.89354586601, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1188424, "time": 36978.69538760185, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1188440, "time": 36979.20447397232, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1188568, "time": 36983.07410621643, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 1188624, "time": 36985.047582149506, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1188904, "time": 36993.344579935074, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1189032, "time": 36997.22498559952, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1189072, "time": 36998.68905425072, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1189160, "time": 37001.14544939995, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1189168, "time": 37001.614594221115, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 1189488, "time": 37011.34248971939, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1189664, "time": 37016.803800821304, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1189696, "time": 37017.78145956993, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1189744, "time": 37019.27214026451, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1189848, "time": 37022.205948114395, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1189912, "time": 37024.16139149666, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 1190072, "time": 37029.81678724289, "eval_episode/length": 39.0, "eval_episode/score": 0.878125011920929, "eval_episode/reward_rate": 0.025}
{"step": 1190072, "time": 37030.18160414696, "eval_episode/length": 57.0, "eval_episode/score": 0.8218749761581421, "eval_episode/reward_rate": 0.017241379310344827}
{"step": 1190072, "time": 37030.696413517, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 1190072, "time": 37030.72429895401, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 1190072, "time": 37031.02712917328, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 1190072, "time": 37031.83761715889, "eval_episode/length": 81.0, "eval_episode/score": 0.746874988079071, "eval_episode/reward_rate": 0.012195121951219513}
{"step": 1190072, "time": 37031.961339235306, "eval_episode/length": 145.0, "eval_episode/score": 0.546875, "eval_episode/reward_rate": 0.00684931506849315}
{"step": 1190072, "time": 37032.56816267967, "eval_episode/length": 135.0, "eval_episode/score": 0.578125, "eval_episode/reward_rate": 0.007352941176470588}
{"step": 1190232, "time": 37037.428008556366, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1190344, "time": 37040.809408187866, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 1190448, "time": 37044.1928191185, "episode/length": 234.0, "episode/score": 0.26875001192092896, "episode/reward_rate": 0.00425531914893617, "episode/intrinsic_return": 0.0}
{"step": 1190784, "time": 37054.52347993851, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1190808, "time": 37055.03362369537, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1190920, "time": 37058.450077056885, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1190920, "time": 37058.45690584183, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1190936, "time": 37058.94842171669, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 1191256, "time": 37068.65480685234, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 1191504, "time": 37076.482980012894, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1191600, "time": 37079.38606238365, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1191856, "time": 37087.13170194626, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1192008, "time": 37091.498701334, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1192008, "time": 37091.50681734085, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1192080, "time": 37093.89301228523, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 1192160, "time": 37096.31989979744, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1192192, "time": 37097.2877600193, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1192200, "time": 37097.315393447876, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1192504, "time": 37106.53383398056, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1192664, "time": 37111.375776052475, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1193072, "time": 37123.94804263115, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1193096, "time": 37124.46329665184, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1193096, "time": 37124.469905376434, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1193168, "time": 37126.86695432663, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1193328, "time": 37131.70913720131, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1193368, "time": 37132.70188641548, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1193568, "time": 37139.1026802063, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1193672, "time": 37142.02676343918, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1193792, "time": 37145.89549946785, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 1193824, "time": 37146.87031793594, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1194168, "time": 37157.09100174904, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1194200, "time": 37158.08369588852, "episode/length": 264.0, "episode/score": 0.17499999701976776, "episode/reward_rate": 0.0037735849056603774, "episode/intrinsic_return": 0.0}
{"step": 1194288, "time": 37160.97226023674, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1194480, "time": 37166.82963371277, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1194648, "time": 37171.68170881271, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 1194648, "time": 37171.68963646889, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 1195024, "time": 37183.26805448532, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1195064, "time": 37184.25696396828, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1195216, "time": 37189.07294297218, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1195384, "time": 37193.92382121086, "episode/length": 226.0, "episode/score": 0.29374998807907104, "episode/reward_rate": 0.004405286343612335, "episode/intrinsic_return": 0.0}
{"step": 1195504, "time": 37197.85265302658, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 1195648, "time": 37202.20584106445, "episode/length": 227.0, "episode/score": 0.2906250059604645, "episode/reward_rate": 0.0043859649122807015, "episode/intrinsic_return": 0.0}
{"step": 1195888, "time": 37209.451961278915, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1195928, "time": 37210.44137263298, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 1195976, "time": 37211.912261009216, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1196264, "time": 37221.06869959831, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1196280, "time": 37221.578688144684, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1196505, "time": 37231.78711891174, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.609473502281869, "train/action_min": 0.0, "train/action_std": 1.93906173552617, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.010176373807031035, "train/actor_opt_grad_steps": 73675.0, "train/actor_opt_loss": -17.483028010566635, "train/adv_mag": 0.910435664771807, "train/adv_max": 0.3341928266062595, "train/adv_mean": 0.00010234627958684226, "train/adv_min": -0.8299140192494534, "train/adv_std": 0.027952455039514174, "train/cont_avg": 0.9934347926980198, "train/cont_loss_mean": 0.025981102917933523, "train/cont_loss_std": 0.28410816815967604, "train/cont_neg_acc": 0.17428645661266723, "train/cont_neg_loss": 3.10484573304063, "train/cont_pos_acc": 0.9998589960655363, "train/cont_pos_loss": 0.005502435218515151, "train/cont_pred": 0.9935014894103059, "train/cont_rate": 0.9934347926980198, "train/dyn_loss_mean": 1.0000006704047175, "train/dyn_loss_std": 2.1441383411217997e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.11621702089905739, "train/extr_critic_critic_opt_grad_steps": 73675.0, "train/extr_critic_critic_opt_loss": 4818.471202283803, "train/extr_critic_mag": 1.637284254083539, "train/extr_critic_max": 1.637284254083539, "train/extr_critic_mean": 1.5479127935843893, "train/extr_critic_min": 1.1753810343175832, "train/extr_critic_std": 0.025414712579533604, "train/extr_return_normed_mag": 0.9121234145494971, "train/extr_return_normed_max": 0.2738366988625857, "train/extr_return_normed_mean": 0.05100031964259573, "train/extr_return_normed_min": -0.8304128965528885, "train/extr_return_normed_std": 0.03854906657655345, "train/extr_return_rate": 0.9996384122584125, "train/extr_return_raw_mag": 1.770851443309595, "train/extr_return_raw_max": 1.770851443309595, "train/extr_return_raw_mean": 1.5480151571849785, "train/extr_return_raw_min": 0.6666018478941209, "train/extr_return_raw_std": 0.03854906641057517, "train/extr_reward_mag": 0.24096543954150512, "train/extr_reward_max": 0.24096543954150512, "train/extr_reward_mean": 0.002904410553533621, "train/extr_reward_min": 4.3670729835434714e-08, "train/extr_reward_std": 0.008996544569491012, "train/image_loss_mean": 0.08987858627766075, "train/image_loss_std": 0.10546792368635093, "train/model_loss_mean": 0.7385785479356747, "train/model_loss_std": 0.5601956772405913, "train/model_opt_grad_norm": 16.312392189951225, "train/model_opt_grad_steps": 73609.68316831683, "train/model_opt_loss": 4073.5902909382735, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5519.80198019802, "train/policy_entropy_mag": 1.2826246583815848, "train/policy_entropy_max": 1.2826246583815848, "train/policy_entropy_mean": 0.08783443021302176, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.10410847264056158, "train/policy_logprob_mag": 6.551080257585733, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.08876161679330438, "train/policy_logprob_min": -6.551080257585733, "train/policy_logprob_std": 0.6303559532850096, "train/policy_randomness_mag": 0.6591387243554143, "train/policy_randomness_max": 0.6591387243554143, "train/policy_randomness_mean": 0.04513797056999537, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.05350117510793233, "train/post_ent_mag": 46.536354253787806, "train/post_ent_max": 46.536354253787806, "train/post_ent_mean": 35.42578920043341, "train/post_ent_min": 28.37709145498748, "train/post_ent_std": 3.832804583086826, "train/prior_ent_mag": 42.75573333891312, "train/prior_ent_max": 42.75573333891312, "train/prior_ent_mean": 34.567004987508945, "train/prior_ent_min": 28.178396055013827, "train/prior_ent_std": 2.9249208717062922, "train/rep_loss_mean": 1.0000006704047175, "train/rep_loss_std": 2.1441383411217997e-05, "train/reward_avg": 0.0031342912476283896, "train/reward_loss_mean": 0.022718437103609934, "train/reward_loss_std": 0.27729275792671165, "train/reward_max_data": 0.8060179441282065, "train/reward_max_pred": 0.265351934008079, "train/reward_neg_acc": 0.999679581658675, "train/reward_neg_loss": 0.00413242883007457, "train/reward_pos_acc": 0.12054917624398093, "train/reward_pos_loss": 4.017398199244361, "train/reward_pred": 0.002404847079749671, "train/reward_rate": 0.004583075495049505, "train_stats/mean_log_entropy": 0.0796006327867508, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9912109375, "report/cont_loss_mean": 0.035794880241155624, "report/cont_loss_std": 0.3614439070224762, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 3.492550849914551, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.005143840331584215, "report/cont_pred": 0.9944702982902527, "report/cont_rate": 0.9912109375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.09071707725524902, "report/image_loss_std": 0.10890620201826096, "report/model_loss_mean": 0.7642583250999451, "report/model_loss_std": 0.761722981929779, "report/post_ent_mag": 47.21422576904297, "report/post_ent_max": 47.21422576904297, "report/post_ent_mean": 37.173179626464844, "report/post_ent_min": 29.950807571411133, "report/post_ent_std": 3.9047489166259766, "report/prior_ent_mag": 42.68279266357422, "report/prior_ent_max": 42.68279266357422, "report/prior_ent_mean": 34.01498031616211, "report/prior_ent_min": 27.582805633544922, "report/prior_ent_std": 3.0465188026428223, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00427856482565403, "report/reward_loss_mean": 0.037746332585811615, "report/reward_loss_std": 0.40733009576797485, "report/reward_max_data": 0.793749988079071, "report/reward_max_pred": 0.23687970638275146, "report/reward_neg_acc": 0.999015748500824, "report/reward_neg_loss": 0.003970178309828043, "report/reward_pos_acc": 0.125, "report/reward_pos_loss": 4.32731819152832, "report/reward_pred": 0.002331059891730547, "report/reward_rate": 0.0078125, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.019182290881872177, "eval/cont_loss_std": 0.25722354650497437, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 4.6312665939331055, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.005630623083561659, "eval/cont_pred": 0.9944866895675659, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.09505575150251389, "eval/image_loss_std": 0.11831353604793549, "eval/model_loss_mean": 0.734649658203125, "eval/model_loss_std": 0.5848478674888611, "eval/post_ent_mag": 48.24481201171875, "eval/post_ent_max": 48.24481201171875, "eval/post_ent_mean": 36.68310546875, "eval/post_ent_min": 29.89163589477539, "eval/post_ent_std": 3.889779567718506, "eval/prior_ent_mag": 43.31232452392578, "eval/prior_ent_max": 43.31232452392578, "eval/prior_ent_mean": 33.77747344970703, "eval/prior_ent_min": 27.934537887573242, "eval/prior_ent_std": 2.9666590690612793, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0020935058128088713, "eval/reward_loss_mean": 0.02041163109242916, "eval/reward_loss_std": 0.2966979444026947, "eval/reward_max_data": 0.7593749761581421, "eval/reward_max_pred": 0.12221908569335938, "eval/reward_neg_acc": 0.999020516872406, "eval/reward_neg_loss": 0.004595565609633923, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.403146266937256, "eval/reward_pred": 0.0022300679702311754, "eval/reward_rate": 0.0029296875, "replay/size": 1000000.0, "replay/inserts": 32384.0, "replay/samples": 32384.0, "replay/insert_wait_avg": 1.2845183785253833e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.021227338097312e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4792.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.138657679740893e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.98377799987793e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4336152076721, "timer/env.step_count": 4048.0, "timer/env.step_total": 38.78338694572449, "timer/env.step_frac": 0.038766577168314914, "timer/env.step_avg": 0.009580876221769884, "timer/env.step_min": 0.0076198577880859375, "timer/env.step_max": 0.03422403335571289, "timer/replay._sample_count": 32384.0, "timer/replay._sample_total": 16.05261754989624, "timer/replay._sample_frac": 0.016045659907743107, "timer/replay._sample_avg": 0.0004956959470694244, "timer/replay._sample_min": 0.00040984153747558594, "timer/replay._sample_max": 0.011919736862182617, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4647.0, "timer/agent.policy_total": 48.904305934906006, "timer/agent.policy_frac": 0.04888310947523924, "timer/agent.policy_avg": 0.01052384461693695, "timer/agent.policy_min": 0.0087127685546875, "timer/agent.policy_max": 0.08609771728515625, "timer/dataset_train_count": 2024.0, "timer/dataset_train_total": 0.2242112159729004, "timer/dataset_train_frac": 0.00022411403671832654, "timer/dataset_train_avg": 0.00011077629247672944, "timer/dataset_train_min": 9.846687316894531e-05, "timer/dataset_train_max": 0.0004971027374267578, "timer/agent.train_count": 2024.0, "timer/agent.train_total": 900.8682503700256, "timer/agent.train_frac": 0.9004777895063247, "timer/agent.train_avg": 0.4450930090760996, "timer/agent.train_min": 0.4350712299346924, "timer/agent.train_max": 0.6735637187957764, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47853827476501465, "timer/agent.report_frac": 0.00047833086322841985, "timer/agent.report_avg": 0.23926913738250732, "timer/agent.report_min": 0.23188376426696777, "timer/agent.report_max": 0.24665451049804688, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.218650817871094e-05, "timer/dataset_eval_frac": 3.2172557668436197e-08, "timer/dataset_eval_avg": 3.218650817871094e-05, "timer/dataset_eval_min": 3.218650817871094e-05, "timer/dataset_eval_max": 3.218650817871094e-05, "fps": 32.36940432437246}
{"step": 1196816, "time": 37241.11724281311, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1196824, "time": 37241.14567613602, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1196960, "time": 37245.48037958145, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1196960, "time": 37245.49406337738, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1197040, "time": 37247.90074586868, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 1197512, "time": 37262.0867190361, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1197616, "time": 37265.45145010948, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1197696, "time": 37267.85644865036, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1197816, "time": 37271.25513005257, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1197944, "time": 37275.10150027275, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1198192, "time": 37282.78363251686, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1198232, "time": 37283.77177476883, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1198288, "time": 37285.79179430008, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1198392, "time": 37288.721031188965, "episode/length": 263.0, "episode/score": 0.17812499403953552, "episode/reward_rate": 0.003787878787878788, "episode/intrinsic_return": 0.0}
{"step": 1198528, "time": 37293.06001281738, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 1198680, "time": 37297.43586349487, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1198864, "time": 37303.22910284996, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1198952, "time": 37305.68186545372, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 1198992, "time": 37307.13843393326, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1199200, "time": 37313.41808581352, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1199280, "time": 37315.940626621246, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1199384, "time": 37318.86138868332, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1199456, "time": 37321.25749063492, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 1199544, "time": 37323.711163282394, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1199768, "time": 37330.46800994873, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1199856, "time": 37333.353753089905, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1199872, "time": 37333.839361429214, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1199928, "time": 37335.30638241768, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1200056, "time": 37340.21813869476, "eval_episode/length": 58.0, "eval_episode/score": 0.8187500238418579, "eval_episode/reward_rate": 0.01694915254237288}
{"step": 1200056, "time": 37340.45313215256, "eval_episode/length": 71.0, "eval_episode/score": 0.778124988079071, "eval_episode/reward_rate": 0.013888888888888888}
{"step": 1200056, "time": 37340.458794116974, "eval_episode/length": 71.0, "eval_episode/score": 0.778124988079071, "eval_episode/reward_rate": 0.013888888888888888}
{"step": 1200056, "time": 37340.866718530655, "eval_episode/length": 94.0, "eval_episode/score": 0.706250011920929, "eval_episode/reward_rate": 0.010526315789473684}
{"step": 1200056, "time": 37341.19207882881, "eval_episode/length": 40.0, "eval_episode/score": 0.875, "eval_episode/reward_rate": 0.024390243902439025}
{"step": 1200056, "time": 37341.51847577095, "eval_episode/length": 58.0, "eval_episode/score": 0.8187500238418579, "eval_episode/reward_rate": 0.01694915254237288}
{"step": 1200056, "time": 37341.56044101715, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 1200056, "time": 37341.92339038849, "eval_episode/length": 152.0, "eval_episode/score": 0.5249999761581421, "eval_episode/reward_rate": 0.006535947712418301}
{"step": 1200528, "time": 37356.486184597015, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1200672, "time": 37360.8477127552, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 1200872, "time": 37366.6885638237, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1200928, "time": 37368.62851905823, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 1201072, "time": 37372.97630786896, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1201408, "time": 37383.25625562668, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 1201504, "time": 37386.149327754974, "episode/length": 216.0, "episode/score": 0.32499998807907104, "episode/reward_rate": 0.004608294930875576, "episode/intrinsic_return": 0.0}
{"step": 1201512, "time": 37386.17627811432, "episode/length": 12.0, "episode/score": 0.9624999761581421, "episode/reward_rate": 0.07692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1201592, "time": 37388.60260605812, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1201608, "time": 37389.090314626694, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1201648, "time": 37390.524768829346, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1201720, "time": 37392.485610723495, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1201848, "time": 37396.33368253708, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1201856, "time": 37396.80219101906, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1202080, "time": 37403.57268619537, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 1202168, "time": 37406.070714235306, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1202240, "time": 37408.48661899567, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1202328, "time": 37410.92728614807, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1202472, "time": 37415.295961141586, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1202584, "time": 37418.6994035244, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1202624, "time": 37420.13330030441, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1202760, "time": 37424.03033900261, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1202760, "time": 37424.039139032364, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1202800, "time": 37425.47094464302, "episode/length": 21.0, "episode/score": 0.934374988079071, "episode/reward_rate": 0.045454545454545456, "episode/intrinsic_return": 0.0}
{"step": 1202856, "time": 37426.958726882935, "episode/length": 11.0, "episode/score": 0.965624988079071, "episode/reward_rate": 0.08333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1203032, "time": 37432.27754354477, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1203088, "time": 37434.18798947334, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 1203272, "time": 37439.66529774666, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1203544, "time": 37447.898788928986, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1203776, "time": 37455.11326098442, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1203840, "time": 37457.06314659119, "episode/length": 219.0, "episode/score": 0.31562501192092896, "episode/reward_rate": 0.004545454545454545, "episode/intrinsic_return": 0.0}
{"step": 1204032, "time": 37462.87204289436, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 1204072, "time": 37463.86292910576, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1204112, "time": 37465.39038991928, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1204112, "time": 37465.397780656815, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
