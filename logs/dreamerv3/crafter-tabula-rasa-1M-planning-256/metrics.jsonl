{"step": 408, "time": 125.31258177757263, "episode/length": 50.0, "episode/score": 1.1611887559556635, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.061188724197563715}
{"step": 1136, "time": 132.9986538887024, "episode/length": 141.0, "episode/score": 3.2114523516011104, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.11145225948166626}
{"step": 1168, "time": 134.9731891155243, "episode/length": 145.0, "episode/score": 0.24521418588483357, "episode/reward_rate": 0.9657534246575342, "episode/intrinsic_return": 0.14521417764262878}
{"step": 1184, "time": 136.82523655891418, "episode/length": 147.0, "episode/score": 2.2181660368460143, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.11816591451679415}
{"step": 1264, "time": 139.33146166801453, "episode/length": 157.0, "episode/score": 1.2227953981928295, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.12279533430410083}
{"step": 1344, "time": 141.84485578536987, "episode/length": 167.0, "episode/score": 2.2647221513470868, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.16472208582854364}
{"step": 1464, "time": 144.5858302116394, "episode/length": 182.0, "episode/score": 2.2698152081229637, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.16981514260442054}
{"step": 1560, "time": 161.66957473754883, "eval_episode/length": 138.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9928057553956835}
{"step": 1560, "time": 161.67633032798767, "eval_episode/length": 138.0, "eval_episode/score": 1.1000000014901161, "eval_episode/reward_rate": 0.9784172661870504}
{"step": 1560, "time": 164.62206602096558, "eval_episode/length": 143.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9652777777777778}
{"step": 1560, "time": 166.0284926891327, "eval_episode/length": 145.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.958904109589041}
{"step": 1560, "time": 167.8916482925415, "eval_episode/length": 164.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9939393939393939}
{"step": 1560, "time": 169.34177255630493, "eval_episode/length": 168.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9704142011834319}
{"step": 1560, "time": 171.14289450645447, "eval_episode/length": 188.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9735449735449735}
{"step": 1560, "time": 172.71868562698364, "train_stats/sum_log_reward": 1.6714285441807337, "train_stats/max_log_achievement_collect_sapling": 1.0, "train_stats/max_log_achievement_place_plant": 0.8571428571428571, "train_stats/max_log_achievement_collect_wood": 0.16666666666666666, "train_stats/max_log_achievement_wake_up": 2.1666666666666665, "eval_stats/sum_log_reward": 0.8142856987459319, "eval_stats/max_log_achievement_collect_sapling": 0.42857142857142855, "eval_stats/max_log_achievement_collect_wood": 0.14285714285714285, "eval_stats/max_log_achievement_place_plant": 0.2857142857142857, "eval_stats/max_log_achievement_wake_up": 1.2857142857142858}
{"step": 1560, "time": 215.9049952030182, "eval_episode/length": 79.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.925}
{"step": 1560, "time": 220.6608645915985, "eval_episode/length": 140.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9645390070921985}
{"step": 1560, "time": 222.74198126792908, "eval_episode/length": 142.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.965034965034965}
{"step": 1560, "time": 225.20180678367615, "eval_episode/length": 148.0, "eval_episode/score": 2.0999999940395355, "eval_episode/reward_rate": 0.9932885906040269}
{"step": 1560, "time": 227.81348514556885, "eval_episode/length": 159.0, "eval_episode/score": 2.0999999716877937, "eval_episode/reward_rate": 0.99375}
{"step": 1560, "time": 231.394047498703, "eval_episode/length": 190.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9738219895287958}
{"step": 1560, "time": 233.74827194213867, "eval_episode/length": 192.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.9740932642487047}
{"step": 1560, "time": 236.06398010253906, "eval_episode/length": 199.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.975}
{"step": 1561, "time": 366.5767846107483, "eval_stats/sum_log_reward": 2.7249999344348907, "eval_stats/max_log_achievement_collect_sapling": 1.625, "eval_stats/max_log_achievement_collect_wood": 0.875, "eval_stats/max_log_achievement_place_plant": 1.0, "eval_stats/max_log_achievement_wake_up": 1.625, "eval_stats/max_log_achievement_collect_drink": 0.8333333333333334, "eval_stats/max_log_achievement_make_wood_sword": 0.3333333333333333, "eval_stats/max_log_achievement_place_table": 0.3333333333333333, "eval_stats/max_log_achievement_defeat_zombie": 0.5, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 7.36859130859375, "train/action_min": 0.0, "train/action_std": 4.857132911682129, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00028188852593302727, "train/actor_opt_grad_steps": 1.0, "train/actor_opt_loss": -1.7614980936050415, "train/adv_mag": 0.0, "train/adv_max": 0.0, "train/adv_mean": 0.0, "train/adv_min": 0.0, "train/adv_std": 0.0, "train/cont_avg": 0.9970703125, "train/cont_loss_mean": 0.702106773853302, "train/cont_loss_std": 0.28410103917121887, "train/cont_neg_acc": 0.3333333432674408, "train/cont_neg_loss": 0.7210807800292969, "train/cont_pos_acc": 0.5367286801338196, "train/cont_pos_loss": 0.702051043510437, "train/cont_pred": 0.5147566199302673, "train/cont_rate": 0.9970703125, "train/dyn_loss_mean": 10.83079719543457, "train/dyn_loss_std": 0.5299736857414246, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 6.1410956382751465, "train/extr_critic_critic_opt_grad_steps": 1.0, "train/extr_critic_critic_opt_loss": 25274.396484375, "train/extr_critic_mag": 0.0, "train/extr_critic_max": 0.0, "train/extr_critic_mean": 0.0, "train/extr_critic_min": 0.0, "train/extr_critic_std": 0.0, "train/extr_return_normed_mag": 0.0, "train/extr_return_normed_max": 0.0, "train/extr_return_normed_mean": 0.0, "train/extr_return_normed_min": 0.0, "train/extr_return_normed_std": 0.0, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.0, "train/extr_return_raw_max": 0.0, "train/extr_return_raw_mean": 0.0, "train/extr_return_raw_min": 0.0, "train/extr_return_raw_std": 0.0, "train/extr_reward_mag": 0.0, "train/extr_reward_max": 0.0, "train/extr_reward_mean": 0.0, "train/extr_reward_min": 0.0, "train/extr_reward_std": 0.0, "train/image_loss_mean": 3716.13720703125, "train/image_loss_std": 150.8556671142578, "train/model_loss_mean": 3728.87890625, "train/model_loss_std": 150.7454376220703, "train/model_opt_grad_norm": NaN, "train/model_opt_grad_steps": 0.0, "train/model_opt_loss": 37288788.0, "train/model_opt_model_opt_grad_overflow": 1.0, "train/model_opt_model_opt_grad_scale": 5000.0, "train/policy_entropy_mag": 2.7777159214019775, "train/policy_entropy_max": 2.7777159214019775, "train/policy_entropy_mean": 2.573035717010498, "train/policy_entropy_min": 2.0127758979797363, "train/policy_entropy_std": 0.08285285532474518, "train/policy_logprob_mag": 5.726454734802246, "train/policy_logprob_max": -0.7189464569091797, "train/policy_logprob_mean": -2.575230836868286, "train/policy_logprob_min": -5.726454734802246, "train/policy_logprob_std": 0.6814849376678467, "train/policy_randomness_mag": 0.9804118275642395, "train/policy_randomness_max": 0.9804118275642395, "train/policy_randomness_mean": 0.9081687331199646, "train/policy_randomness_min": 0.7104215621948242, "train/policy_randomness_std": 0.02924342267215252, "train/post_ent_mag": 106.10896301269531, "train/post_ent_max": 106.10896301269531, "train/post_ent_mean": 105.62904357910156, "train/post_ent_min": 104.96456146240234, "train/post_ent_std": 0.23996759951114655, "train/prior_ent_mag": 106.51577758789062, "train/prior_ent_max": 106.51577758789062, "train/prior_ent_mean": 105.55552673339844, "train/prior_ent_min": 104.60159301757812, "train/prior_ent_std": 0.2956623136997223, "train/rep_loss_mean": 10.83079719543457, "train/rep_loss_std": 0.5299736857414246, "train/reward_avg": 0.011679762974381447, "train/reward_loss_mean": 5.541262626647949, "train/reward_loss_std": 9.871948805084685e-07, "train/reward_max_data": 1.0012500286102295, "train/reward_max_pred": 0.0, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 5.541263103485107, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 5.541263580322266, "train/reward_pred": 0.0, "train/reward_rate": 0.015625, "train/params_agent/wm/model_opt": 181569923.0, "train/params_agent/task_behavior/critic/critic_opt": 9708799.0, "train/params_agent/task_behavior/ac/actor_opt": 9464849.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.6821092367172241, "report/cont_loss_std": 0.30258551239967346, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 1.0908851623535156, "report/cont_pos_acc": 0.5572967529296875, "report/cont_pos_loss": 0.6809080839157104, "report/cont_pred": 0.5284146070480347, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 10.848758697509766, "report/dyn_loss_std": 0.5291303396224976, "report/image_loss_mean": 3715.799560546875, "report/image_loss_std": 148.57781982421875, "report/model_loss_mean": 3728.5322265625, "report/model_loss_std": 148.4263458251953, "report/post_ent_mag": 106.22525024414062, "report/post_ent_max": 106.22525024414062, "report/post_ent_mean": 105.64317321777344, "report/post_ent_min": 105.02348327636719, "report/post_ent_std": 0.2376735508441925, "report/prior_ent_mag": 106.58393859863281, "report/prior_ent_max": 106.58393859863281, "report/prior_ent_mean": 105.51238250732422, "report/prior_ent_min": 104.41809844970703, "report/prior_ent_std": 0.3031453788280487, "report/rep_loss_mean": 10.848758697509766, "report/rep_loss_std": 0.5291303396224976, "report/reward_avg": 0.011679762974381447, "report/reward_loss_mean": 5.541262626647949, "report/reward_loss_std": 9.871948805084685e-07, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 0.0, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 5.541263103485107, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 5.541263580322266, "report/reward_pred": 0.0, "report/reward_rate": 0.015625, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.6985165476799011, "eval/cont_loss_std": 0.3029423654079437, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 1.02396559715271, "eval/cont_pos_acc": 0.5190989375114441, "eval/cont_pos_loss": 0.6975602507591248, "eval/cont_pred": 0.5202251672744751, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 10.933248519897461, "eval/dyn_loss_std": 0.4904335141181946, "eval/image_loss_mean": 3655.747802734375, "eval/image_loss_std": 177.1214141845703, "eval/model_loss_mean": 3668.547607421875, "eval/model_loss_std": 176.9927520751953, "eval/post_ent_mag": 106.15978240966797, "eval/post_ent_max": 106.15978240966797, "eval/post_ent_mean": 105.58242797851562, "eval/post_ent_min": 104.92839050292969, "eval/post_ent_std": 0.2437141090631485, "eval/prior_ent_mag": 106.48072814941406, "eval/prior_ent_max": 106.48072814941406, "eval/prior_ent_mean": 105.57212829589844, "eval/prior_ent_min": 104.62378692626953, "eval/prior_ent_std": 0.29360079765319824, "eval/rep_loss_mean": 10.933248519897461, "eval/rep_loss_std": 0.4904335141181946, "eval/reward_avg": 0.01171875, "eval/reward_loss_mean": 5.541262626647949, "eval/reward_loss_std": 9.542561656417092e-07, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 5.541262626647949, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.541264057159424, "eval/reward_pred": 0.0, "eval/reward_rate": 0.0146484375, "replay/size": 1057.0, "replay/inserts": 1057.0, "replay/samples": 112.0, "replay/insert_wait_avg": 2.361178510913109e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.642673492431641e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 2656.0, "eval_replay/inserts": 2656.0, "eval_replay/samples": 112.0, "eval_replay/insert_wait_avg": 1.5771891697343573e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.281294686453683e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 255.60040998458862, "timer/env.step_count": 196.0, "timer/env.step_total": 29.457417249679565, "timer/env.step_frac": 0.11524792644681475, "timer/env.step_avg": 0.15029294515142635, "timer/env.step_min": 0.023288965225219727, "timer/env.step_max": 11.293669939041138, "timer/replay._sample_count": 112.0, "timer/replay._sample_total": 0.12086701393127441, "timer/replay._sample_frac": 0.0004728748828633024, "timer/replay._sample_avg": 0.0010791697672435216, "timer/replay._sample_min": 0.00041937828063964844, "timer/replay._sample_max": 0.009716033935546875, "timer/agent.save_count": 1.0, "timer/agent.save_total": 10.739818572998047, "timer/agent.save_frac": 0.04201800213718594, "timer/agent.save_avg": 10.739818572998047, "timer/agent.save_min": 10.739818572998047, "timer/agent.save_max": 10.739818572998047, "timer/agent.policy_count": 201.0, "timer/agent.policy_total": 29.772788524627686, "timer/agent.policy_frac": 0.11648177139630891, "timer/agent.policy_avg": 0.14812332599317257, "timer/agent.policy_min": 0.011074542999267578, "timer/agent.policy_max": 23.32450008392334, "timer/dataset_train_count": 1.0, "timer/dataset_train_total": 3.3855438232421875e-05, "timer/dataset_train_frac": 1.3245455370929641e-07, "timer/dataset_train_avg": 3.3855438232421875e-05, "timer/dataset_train_min": 3.3855438232421875e-05, "timer/dataset_train_max": 3.3855438232421875e-05, "timer/agent.train_count": 1.0, "timer/agent.train_total": 94.66149139404297, "timer/agent.train_frac": 0.3703495287810789, "timer/agent.train_avg": 94.66149139404297, "timer/agent.train_min": 94.66149139404297, "timer/agent.train_max": 94.66149139404297, "timer/agent.report_count": 2.0, "timer/agent.report_total": 33.06814360618591, "timer/agent.report_frac": 0.1293743762311639, "timer/agent.report_avg": 16.534071803092957, "timer/agent.report_min": 8.451089143753052, "timer/agent.report_max": 24.61705446243286, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 5.555152893066406e-05, "timer/dataset_eval_frac": 2.1733740150891593e-07, "timer/dataset_eval_avg": 5.555152893066406e-05, "timer/dataset_eval_min": 5.555152893066406e-05, "timer/dataset_eval_max": 5.555152893066406e-05}
{"step": 1760, "time": 391.171493768692, "episode/length": 219.0, "episode/score": 2.3411507159380562, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.2411506492553599}
{"step": 1792, "time": 396.71518421173096, "episode/length": 172.0, "episode/score": 3.2499389882596006, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.1499388941028883}
{"step": 1864, "time": 407.1791527271271, "episode/length": 49.0, "episode/score": -0.8543270052459775, "episode/reward_rate": 0.92, "episode/intrinsic_return": 0.04567301398583368}
{"step": 2208, "time": 451.528902053833, "episode/length": 129.0, "episode/score": 1.2296419324811723, "episode/reward_rate": 0.9692307692307692, "episode/intrinsic_return": 0.1296418944366451}
{"step": 2472, "time": 485.8531322479248, "episode/length": 166.0, "episode/score": 0.2392917122460858, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.13929170400388102}
{"step": 2496, "time": 490.43424940109253, "episode/length": 153.0, "episode/score": 0.22186788593262463, "episode/reward_rate": 0.961038961038961, "episode/intrinsic_return": 0.1218678811828795}
{"step": 2880, "time": 539.7866997718811, "episode/length": 191.0, "episode/score": 0.2835066656862182, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.1835066574440134}
{"step": 2936, "time": 548.3244135379791, "episode/length": 133.0, "episode/score": 0.21981462642270344, "episode/reward_rate": 0.9925373134328358, "episode/intrinsic_return": 0.1198145613698216}
{"step": 2960, "time": 552.9359347820282, "episode/length": 149.0, "episode/score": 0.23538651968465274, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.1353864546317709}
{"step": 3192, "time": 583.243331193924, "episode/length": 250.0, "episode/score": 3.341178465519988, "episode/reward_rate": 0.9960159362549801, "episode/intrinsic_return": 0.24117837648554996}
{"step": 3248, "time": 591.7034687995911, "episode/length": 181.0, "episode/score": 3.2621335522953814, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.16213345813866908}
{"step": 3424, "time": 615.052346944809, "episode/length": 151.0, "episode/score": 1.241636839675266, "episode/reward_rate": 0.9605263157894737, "episode/intrinsic_return": 0.14163680628735165}
{"step": 3512, "time": 627.332010269165, "episode/length": 32.0, "episode/score": -0.863833354334929, "episode/reward_rate": 0.8484848484848485, "episode/intrinsic_return": 0.03616666606103536}
{"step": 3800, "time": 664.667576789856, "episode/length": 165.0, "episode/score": 1.2190250968310465, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.11902505744774317}
{"step": 4080, "time": 700.7349753379822, "episode/length": 197.0, "episode/score": 2.2740959976208615, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.1740959909502635}
{"step": 4352, "time": 735.8557541370392, "episode/length": 176.0, "episode/score": 2.235562955277601, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.13556288975905773}
{"step": 4688, "time": 778.8363437652588, "episode/length": 215.0, "episode/score": 3.277115033492919, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.17711494282866624}
{"step": 4728, "time": 785.2475364208221, "episode/length": 230.0, "episode/score": 1.2933245222034202, "episode/reward_rate": 0.9783549783549783, "episode/intrinsic_return": 0.19332448532304625}
{"step": 4936, "time": 812.5338864326477, "episode/length": 217.0, "episode/score": 1.2556547554145254, "episode/reward_rate": 0.981651376146789, "episode/intrinsic_return": 0.1556546872184299}
{"step": 4944, "time": 814.9905078411102, "episode/length": 189.0, "episode/score": 1.237603820269669, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.13760378338929513}
{"step": 5320, "time": 862.8880929946899, "episode/length": 154.0, "episode/score": 0.2146347747566324, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.11463476651442761}
{"step": 5344, "time": 867.4141869544983, "episode/length": 192.0, "episode/score": 0.2671233424430284, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.1671233342008236}
{"step": 5360, "time": 871.461332321167, "episode/length": 230.0, "episode/score": 1.280929800532249, "episode/reward_rate": 0.987012987012987, "episode/intrinsic_return": 0.18092976365187496}
{"step": 5648, "time": 908.7118289470673, "episode/length": 161.0, "episode/score": 0.23035456870002236, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.13035455987574096}
{"step": 6008, "time": 955.2223155498505, "episode/length": 82.0, "episode/score": 0.17675809465345083, "episode/reward_rate": 0.9397590361445783, "episode/intrinsic_return": 0.07675807354735298}
{"step": 6232, "time": 984.4549305438995, "episode/length": 192.0, "episode/score": 1.287464767091933, "episode/reward_rate": 0.9637305699481865, "episode/intrinsic_return": 0.18746473719647838}
{"step": 6328, "time": 997.8074598312378, "episode/length": 172.0, "episode/score": 0.26972450591438246, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.16972449650802446}
{"step": 6392, "time": 1007.1626725196838, "episode/length": 207.0, "episode/score": 1.2704715955551364, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.1704715598389157}
{"step": 6648, "time": 1040.2550206184387, "episode/length": 213.0, "episode/score": 1.2691266237552554, "episode/reward_rate": 0.9813084112149533, "episode/intrinsic_return": 0.16912658571072825}
{"step": 6680, "time": 1045.796192407608, "episode/length": 164.0, "episode/score": 0.22808112494249144, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.12808111670028666}
{"step": 6800, "time": 1062.3213305473328, "episode/length": 70.0, "episode/score": 0.16335888662433717, "episode/reward_rate": 0.9295774647887324, "episode/intrinsic_return": 0.06335887838213239}
{"step": 7368, "time": 1133.923418521881, "episode/length": 255.0, "episode/score": 0.3490277135610995, "episode/reward_rate": 0.98046875, "episode/intrinsic_return": 0.24902772895120506}
{"step": 7408, "time": 1140.6004757881165, "episode/length": 219.0, "episode/score": 0.3006443472547744, "episode/reward_rate": 0.9681818181818181, "episode/intrinsic_return": 0.20064431782498104}
{"step": 7472, "time": 1150.0781507492065, "episode/length": 102.0, "episode/score": 1.1637867167937657, "episode/reward_rate": 0.9611650485436893, "episode/intrinsic_return": 0.06378674365078041}
{"step": 7640, "time": 1172.5445938110352, "episode/length": 119.0, "episode/score": 0.17174304042055155, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.07174308986213873}
{"step": 7904, "time": 1206.6289715766907, "episode/length": 196.0, "episode/score": 2.248155730922008, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.1481556797225494}
{"step": 7920, "time": 1210.2062323093414, "episode/length": 139.0, "episode/score": 0.24561778798306477, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.14561777974086}
{"step": 8248, "time": 1253.0395159721375, "episode/length": 231.0, "episode/score": 1.3198265369901492, "episode/reward_rate": 0.978448275862069, "episode/intrinsic_return": 0.2198265047663881}
{"step": 8336, "time": 1265.5259881019592, "episode/length": 290.0, "episode/score": 1.3272670999431284, "episode/reward_rate": 0.9896907216494846, "episode/intrinsic_return": 0.2272670360543998}
{"step": 8616, "time": 1301.3498179912567, "episode/length": 155.0, "episode/score": 0.21322769137896103, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.1132276882590304}
{"step": 8656, "time": 1307.7819402217865, "episode/length": 91.0, "episode/score": 0.18114568500459427, "episode/reward_rate": 0.9565217391304348, "episode/intrinsic_return": 0.0811456773444661}
{"step": 8752, "time": 1321.2217435836792, "episode/length": 159.0, "episode/score": 1.2213382000491038, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.12133816223740723}
{"step": 8816, "time": 1330.6159946918488, "episode/length": 175.0, "episode/score": 1.2409351427941147, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.14093510474958748}
{"step": 8825, "time": 1334.2066073417664, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.3114843210462706, "train/action_min": 0.0, "train/action_std": 1.6756333470015237, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.005551930994236937, "train/actor_opt_grad_steps": 910.0, "train/actor_opt_loss": 205.13954557980622, "train/adv_mag": 2.4501832035365028, "train/adv_max": 2.449073848803399, "train/adv_mean": 0.04347732567861248, "train/adv_min": -0.5123451480432606, "train/adv_std": 0.20938748248725034, "train/cont_avg": 0.9945560687154696, "train/cont_loss_mean": 0.017541491765080623, "train/cont_loss_std": 0.16563722137548287, "train/cont_neg_acc": 0.39291534881565454, "train/cont_neg_loss": 1.8563744886958384, "train/cont_pos_acc": 0.9973245266392745, "train/cont_pos_loss": 0.007483061973816903, "train/cont_pred": 0.9918560388997115, "train/cont_rate": 0.9945560687154696, "train/dyn_loss_mean": 4.670277233281847, "train/dyn_loss_std": 7.120059421378604, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 4.801396134808577, "train/extr_critic_critic_opt_grad_steps": 910.0, "train/extr_critic_critic_opt_loss": 21955.21023610152, "train/extr_critic_mag": 0.7857738417156493, "train/extr_critic_max": 0.7857738403984196, "train/extr_critic_mean": 0.1058204822337611, "train/extr_critic_min": -0.20627134807860653, "train/extr_critic_std": 0.22173092123825927, "train/extr_return_normed_mag": 3.0528237175351944, "train/extr_return_normed_max": 3.0521772261061084, "train/extr_return_normed_mean": 0.2919894711829469, "train/extr_return_normed_min": -0.34873399843025904, "train/extr_return_normed_std": 0.30381973030380166, "train/extr_return_rate": 0.17991087782307327, "train/extr_return_raw_mag": 4.244974386292922, "train/extr_return_raw_max": 4.244945427824779, "train/extr_return_raw_mean": 0.15706955426512784, "train/extr_return_raw_min": -0.7793801177371851, "train/extr_return_raw_std": 0.44406180084230285, "train/extr_reward_mag": 0.7566095873795821, "train/extr_reward_max": 0.7565720213052317, "train/extr_reward_mean": 0.014723961835398109, "train/extr_reward_min": -0.2128213835026019, "train/extr_reward_std": 0.07193268634612209, "train/image_loss_mean": 60.190182670045296, "train/image_loss_std": 29.82878759025869, "train/model_loss_mean": 63.28641048452472, "train/model_loss_std": 31.630831007140777, "train/model_opt_grad_norm": 215.15239306555853, "train/model_opt_grad_steps": 900.0, "train/model_opt_loss": 892.4179550086595, "train/model_opt_model_opt_grad_overflow": 0.0055248618784530384, "train/model_opt_model_opt_grad_scale": 14.081923342541437, "train/policy_entropy_mag": 0.7649657360756594, "train/policy_entropy_max": 0.7649657360756594, "train/policy_entropy_mean": 0.584544940218741, "train/policy_entropy_min": 0.43636330036003945, "train/policy_entropy_std": 0.0609308065994815, "train/policy_logprob_mag": 7.0992432615375, "train/policy_logprob_max": -0.17832013654898213, "train/policy_logprob_mean": -0.5840591264693118, "train/policy_logprob_min": -7.0992432615375, "train/policy_logprob_std": 0.7936177006742572, "train/policy_randomness_mag": 0.26999933366246975, "train/policy_randomness_max": 0.26999933366246975, "train/policy_randomness_mean": 0.2063187104521206, "train/policy_randomness_min": 0.15401709638535976, "train/policy_randomness_std": 0.021505901145070883, "train/post_ent_mag": 45.682003253072665, "train/post_ent_max": 45.682003253072665, "train/post_ent_mean": 27.64063904693772, "train/post_ent_min": 13.70118161459654, "train/post_ent_std": 6.122558805741658, "train/prior_ent_mag": 57.29915827545672, "train/prior_ent_max": 57.29915827545672, "train/prior_ent_mean": 33.226684960212495, "train/prior_ent_min": 16.767364027750425, "train/prior_ent_std": 7.069069522396965, "train/rep_loss_mean": 4.670277233281847, "train/rep_loss_std": 7.120059421378604, "train/reward_avg": 0.00923409582905533, "train/reward_loss_mean": 0.27652083234398406, "train/reward_loss_std": 0.5306947414968144, "train/reward_max_data": 1.0012500286102295, "train/reward_max_pred": 0.800195672894051, "train/reward_neg_acc": 0.9963674028275421, "train/reward_neg_loss": 0.23829078816330235, "train/reward_pos_acc": 0.4710652814426804, "train/reward_pos_loss": 2.2535390211732347, "train/reward_pred": 0.007638201322689529, "train/reward_rate": 0.01873813017955801, "train_stats/sum_log_reward": 0.8674418383906054, "train_stats/max_log_achievement_collect_drink": 6.8604651162790695, "train_stats/max_log_achievement_collect_sapling": 9.674418604651162, "train_stats/max_log_achievement_collect_wood": 0.13953488372093023, "train_stats/max_log_achievement_defeat_zombie": 0.27906976744186046, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 0.09302325581395349, "train_stats/max_log_achievement_place_table": 0.0, "train_stats/max_log_achievement_wake_up": 0.7906976744186046, "train_stats/mean_log_entropy": 0.7509481750948485, "train_stats/max_log_achievement_eat_cow": 0.2777777777777778, "report/cont_avg": 0.9912109375, "report/cont_loss_mean": 0.0004000380577053875, "report/cont_loss_std": 0.006912794895470142, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.028249340131878853, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.00015309844457078725, "report/cont_pred": 0.9912862777709961, "report/cont_rate": 0.9912109375, "report/dyn_loss_mean": 4.492036819458008, "report/dyn_loss_std": 6.284358024597168, "report/image_loss_mean": 9.90083122253418, "report/image_loss_std": 9.963422775268555, "report/model_loss_mean": 12.697237968444824, "report/model_loss_std": 12.238826751708984, "report/post_ent_mag": 47.44106674194336, "report/post_ent_max": 47.44106674194336, "report/post_ent_mean": 23.616615295410156, "report/post_ent_min": 10.970807075500488, "report/post_ent_std": 4.316986083984375, "report/prior_ent_mag": 57.107032775878906, "report/prior_ent_max": 57.107032775878906, "report/prior_ent_mean": 28.40549087524414, "report/prior_ent_min": 12.69820785522461, "report/prior_ent_std": 6.5610761642456055, "report/rep_loss_mean": 4.492036819458008, "report/rep_loss_std": 6.284358024597168, "report/reward_avg": 0.005215140990912914, "report/reward_loss_mean": 0.10078530013561249, "report/reward_loss_std": 0.2787307798862457, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0031874179840088, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.08896157145500183, "report/reward_pos_acc": 0.75, "report/reward_pos_loss": 0.8456803560256958, "report/reward_pred": 0.004247698932886124, "report/reward_rate": 0.015625, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.028491094708442688, "eval/cont_loss_std": 0.3887457251548767, "eval/cont_neg_acc": 0.5, "eval/cont_neg_loss": 3.4784111976623535, "eval/cont_pos_acc": 0.9970530867576599, "eval/cont_pos_loss": 0.0081575782969594, "eval/cont_pred": 0.993849515914917, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 12.772588729858398, "eval/dyn_loss_std": 9.158685684204102, "eval/image_loss_mean": 48.92806625366211, "eval/image_loss_std": 38.800254821777344, "eval/model_loss_mean": 56.84522247314453, "eval/model_loss_std": 42.30109786987305, "eval/post_ent_mag": 48.9085578918457, "eval/post_ent_max": 48.9085578918457, "eval/post_ent_mean": 26.908119201660156, "eval/post_ent_min": 12.24036979675293, "eval/post_ent_std": 6.259706020355225, "eval/prior_ent_mag": 51.658653259277344, "eval/prior_ent_max": 51.658653259277344, "eval/prior_ent_mean": 31.38163185119629, "eval/prior_ent_min": 13.664020538330078, "eval/prior_ent_std": 7.019769191741943, "eval/rep_loss_mean": 12.772588729858398, "eval/rep_loss_std": 9.158685684204102, "eval/reward_avg": 0.0048828125, "eval/reward_loss_mean": 0.22510966658592224, "eval/reward_loss_std": 0.9587600827217102, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9981217384338379, "eval/reward_neg_acc": 0.9990128874778748, "eval/reward_neg_loss": 0.17906679213047028, "eval/reward_pos_acc": 0.4545454680919647, "eval/reward_pos_loss": 4.465241432189941, "eval/reward_pred": -0.0034876223653554916, "eval/reward_rate": 0.0107421875, "replay/size": 8321.0, "replay/inserts": 7264.0, "replay/samples": 29056.0, "replay/insert_wait_avg": 1.7224954613504956e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.742782898411351e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 2656.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 9.387731552124023e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 967.6196444034576, "timer/env.step_count": 908.0, "timer/env.step_total": 92.96800994873047, "timer/env.step_frac": 0.09607908488262008, "timer/env.step_avg": 0.1023876761549895, "timer/env.step_min": 0.023772001266479492, "timer/env.step_max": 2.0927646160125732, "timer/replay._sample_count": 29056.0, "timer/replay._sample_total": 15.138028621673584, "timer/replay._sample_frac": 0.015644606544760936, "timer/replay._sample_avg": 0.0005209949277833695, "timer/replay._sample_min": 0.0003516674041748047, "timer/replay._sample_max": 0.01138615608215332, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 908.0, "timer/agent.policy_total": 15.662652492523193, "timer/agent.policy_frac": 0.016186786391856788, "timer/agent.policy_avg": 0.01724961728251453, "timer/agent.policy_min": 0.015311002731323242, "timer/agent.policy_max": 0.05729103088378906, "timer/dataset_train_count": 1816.0, "timer/dataset_train_total": 0.3170313835144043, "timer/dataset_train_frac": 0.0003276404993925642, "timer/dataset_train_avg": 0.00017457675303656625, "timer/dataset_train_min": 0.00010061264038085938, "timer/dataset_train_max": 0.005560874938964844, "timer/agent.train_count": 1816.0, "timer/agent.train_total": 823.7375745773315, "timer/agent.train_frac": 0.8513030707279304, "timer/agent.train_avg": 0.4535999860007332, "timer/agent.train_min": 0.4398193359375, "timer/agent.train_max": 0.9416964054107666, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48752284049987793, "timer/agent.report_frac": 0.0005038372704808388, "timer/agent.report_avg": 0.24376142024993896, "timer/agent.report_min": 0.2405085563659668, "timer/agent.report_max": 0.24701428413391113, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 4.744529724121094e-05, "timer/dataset_eval_frac": 4.903300332483556e-08, "timer/dataset_eval_avg": 4.744529724121094e-05, "timer/dataset_eval_min": 4.744529724121094e-05, "timer/dataset_eval_max": 4.744529724121094e-05, "fps": 7.506988803675162}
{"step": 9016, "time": 1357.5826170444489, "episode/length": 171.0, "episode/score": 0.21026340671869548, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.11026339847649069}
{"step": 9168, "time": 1377.9511020183563, "episode/length": 157.0, "episode/score": 0.18317898067743954, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.08317897243523475}
{"step": 9656, "time": 1440.0323278903961, "episode/length": 175.0, "episode/score": 0.22675704784796835, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.126757008290042}
{"step": 9888, "time": 1470.9630727767944, "episode/length": 141.0, "episode/score": 1.1937645475159115, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.09376443263727197}
{"step": 9968, "time": 1482.2772765159607, "episode/length": 163.0, "episode/score": 1.1896835109364474, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0896834723680513}
{"step": 10016, "time": 1489.6793365478516, "episode/length": 174.0, "episode/score": 0.20870474673984063, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.10870468168695879}
{"step": 10080, "time": 1499.1531732082367, "episode/length": 217.0, "episode/score": 2.233462965761646, "episode/reward_rate": 0.9862385321100917, "episode/intrinsic_return": 0.13346296409690694}
{"step": 10088, "time": 1516.7942836284637, "eval_episode/length": 40.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.8780487804878049}
{"step": 10088, "time": 1523.1851923465729, "eval_episode/length": 145.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.952054794520548}
{"step": 10088, "time": 1525.547085762024, "eval_episode/length": 149.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9666666666666667}
{"step": 10088, "time": 1527.941213130951, "eval_episode/length": 155.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.967948717948718}
{"step": 10088, "time": 1531.4450578689575, "eval_episode/length": 148.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9664429530201343}
{"step": 10088, "time": 1533.238535642624, "eval_episode/length": 194.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 10088, "time": 1534.9232580661774, "eval_episode/length": 195.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9795918367346939}
{"step": 10088, "time": 1536.7567908763885, "eval_episode/length": 200.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9800995024875622}
{"step": 10112, "time": 1539.6692972183228, "episode/length": 161.0, "episode/score": 0.19792557426990243, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.09792556602769764}
{"step": 10328, "time": 1567.5619795322418, "episode/length": 163.0, "episode/score": 1.2137257236336154, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.11372568675324146}
{"step": 10856, "time": 1634.049709558487, "episode/length": 65.0, "episode/score": 0.16590373436338268, "episode/reward_rate": 0.9242424242424242, "episode/intrinsic_return": 0.0659037261211779}
{"step": 11128, "time": 1668.9568750858307, "episode/length": 130.0, "episode/score": 1.2228526785479517, "episode/reward_rate": 0.9694656488549618, "episode/intrinsic_return": 0.12285264050342448}
{"step": 11200, "time": 1679.3280079364777, "episode/length": 163.0, "episode/score": 1.195298300858667, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.09529831085001206}
{"step": 11224, "time": 1683.7511141300201, "episode/length": 45.0, "episode/score": 0.1413285352737148, "episode/reward_rate": 0.8913043478260869, "episode/intrinsic_return": 0.04132852703151002}
{"step": 11240, "time": 1687.241975069046, "episode/length": 197.0, "episode/score": 1.2130059585874733, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.11300598893694769}
{"step": 11312, "time": 1697.608294725418, "episode/length": 267.0, "episode/score": 2.408090758837261, "episode/reward_rate": 0.9850746268656716, "episode/intrinsic_return": 0.3080907014677905}
{"step": 11400, "time": 1709.974312543869, "episode/length": 178.0, "episode/score": 0.20800579228261995, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.10800578404041516}
{"step": 11480, "time": 1721.3355181217194, "episode/length": 170.0, "episode/score": 0.21328405277927232, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.11328404337291431}
{"step": 11488, "time": 1724.1934881210327, "episode/length": 183.0, "episode/score": 1.271027691001109, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.17102765528488817}
{"step": 12152, "time": 1807.5040102005005, "episode/length": 113.0, "episode/score": 0.21886590630447245, "episode/reward_rate": 0.956140350877193, "episode/intrinsic_return": 0.11886589806226766}
{"step": 12376, "time": 1836.407939195633, "episode/length": 132.0, "episode/score": 1.25242574292497, "episode/reward_rate": 0.9548872180451128, "episode/intrinsic_return": 0.1524257089549792}
{"step": 12560, "time": 1860.5931389331818, "episode/length": 178.0, "episode/score": 0.261682674581607, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.1616826663394022}
{"step": 12792, "time": 1890.648564338684, "episode/length": 162.0, "episode/score": 1.2358355201879476, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.1358354829583277}
{"step": 12816, "time": 1895.153195142746, "episode/length": 176.0, "episode/score": 0.25924031708882467, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.15924030884661988}
{"step": 12936, "time": 1911.3918104171753, "episode/length": 181.0, "episode/score": 2.2419388850487394, "episode/reward_rate": 0.9835164835164835, "episode/intrinsic_return": 0.14193880230072864}
{"step": 13256, "time": 1952.8054196834564, "episode/length": 253.0, "episode/score": 0.3173113670713974, "episode/reward_rate": 0.9881889763779528, "episode/intrinsic_return": 0.21731132867762426}
{"step": 13480, "time": 1981.864951133728, "episode/length": 165.0, "episode/score": 0.21371665052879507, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.11371664228659029}
{"step": 13720, "time": 2012.718656539917, "episode/length": 167.0, "episode/score": 0.19767339277836982, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.09767338395408842}
{"step": 13784, "time": 2022.1132822036743, "episode/length": 322.0, "episode/score": 2.4230651326683983, "episode/reward_rate": 0.9938080495356038, "episode/intrinsic_return": 0.32306507297062126}
{"step": 14120, "time": 2064.927530527115, "episode/length": 162.0, "episode/score": 0.24987215394276063, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.14987214686470907}
{"step": 14208, "time": 2077.259589910507, "episode/length": 158.0, "episode/score": -0.8013115144344738, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.09868850596149059}
{"step": 14288, "time": 2088.675318956375, "episode/length": 186.0, "episode/score": 0.24730446761577696, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.14730440256289512}
{"step": 14360, "time": 2099.043436050415, "episode/length": 137.0, "episode/score": 0.2517144251492027, "episode/reward_rate": 0.9637681159420289, "episode/intrinsic_return": 0.15171439339110293}
{"step": 14728, "time": 2145.8596868515015, "episode/length": 270.0, "episode/score": 0.3774389842358232, "episode/reward_rate": 0.992619926199262, "episode/intrinsic_return": 0.27743897715777166}
{"step": 15032, "time": 2184.5726821422577, "episode/length": 163.0, "episode/score": -0.7080149210805757, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.19198509780198947}
{"step": 15160, "time": 2202.1860961914062, "episode/length": 129.0, "episode/score": -0.766169142016679, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.13383088070759186}
{"step": 15408, "time": 2234.011796474457, "episode/length": 202.0, "episode/score": -0.7445001192299969, "episode/reward_rate": 0.9605911330049262, "episode/intrinsic_return": 0.15549991164334642}
{"step": 15424, "time": 2237.5657556056976, "episode/length": 242.0, "episode/score": -0.7204492547473365, "episode/reward_rate": 0.9958847736625515, "episode/intrinsic_return": 0.1795507719350553}
{"step": 15680, "time": 2270.4831907749176, "episode/length": 183.0, "episode/score": -0.7555017241056703, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.1444982962902941}
{"step": 15848, "time": 2292.777973651886, "episode/length": 185.0, "episode/score": -0.7253990011656697, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.17460101806614148}
{"step": 16024, "time": 2316.033059358597, "episode/length": 216.0, "episode/score": -0.7536656957306604, "episode/reward_rate": 0.9815668202764977, "episode/intrinsic_return": 0.14633432350115072}
{"step": 16152, "time": 2333.2149443626404, "episode/length": 92.0, "episode/score": -0.788333359407261, "episode/reward_rate": 0.9354838709677419, "episode/intrinsic_return": 0.11166666448116302}
{"step": 16153, "time": 2335.904615163803, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 3.766075592874829, "train/action_min": 0.0, "train/action_std": 0.6646002413796597, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.001274521202792075, "train/actor_opt_grad_steps": 2730.0, "train/actor_opt_loss": 13.007918845691663, "train/adv_mag": 2.3019069087961332, "train/adv_max": 2.25693541879211, "train/adv_mean": 0.017838173162716454, "train/adv_min": -1.0283982664183842, "train/adv_std": 0.17660095247496022, "train/cont_avg": 0.9941032701502732, "train/cont_loss_mean": 0.0007431195227741103, "train/cont_loss_std": 0.01930212962573326, "train/cont_neg_acc": 0.9763379331494941, "train/cont_neg_loss": 0.08016566532632531, "train/cont_pos_acc": 0.9999247958751324, "train/cont_pos_loss": 0.00026610971880984693, "train/cont_pred": 0.994122476199937, "train/cont_rate": 0.9941032701502732, "train/dyn_loss_mean": 4.445773906395083, "train/dyn_loss_std": 5.535011380096602, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.285576243869594, "train/extr_critic_critic_opt_grad_steps": 2730.0, "train/extr_critic_critic_opt_loss": 15204.612016521516, "train/extr_critic_mag": 1.982535118613738, "train/extr_critic_max": 1.9792431234661998, "train/extr_critic_mean": -0.050905786167138097, "train/extr_critic_min": -0.5929216589432597, "train/extr_critic_std": 0.41692346244887574, "train/extr_return_normed_mag": 3.6481844655802993, "train/extr_return_normed_max": 3.6480174331717152, "train/extr_return_normed_mean": 0.37636138612781067, "train/extr_return_normed_min": -0.4589098715350602, "train/extr_return_normed_std": 0.4003643544156695, "train/extr_return_rate": 0.23030190984082352, "train/extr_return_raw_mag": 3.865797837900985, "train/extr_return_raw_max": 3.84944585047133, "train/extr_return_raw_mean": -0.025666996951805316, "train/extr_return_raw_min": -1.0758042319224832, "train/extr_return_raw_std": 0.511061976027619, "train/extr_reward_mag": 0.9593359121207983, "train/extr_reward_max": 0.9543714451659573, "train/extr_reward_mean": 0.004776494402024389, "train/extr_reward_min": -0.3766007729566814, "train/extr_reward_std": 0.06375649178024036, "train/image_loss_mean": 9.35376451575691, "train/image_loss_std": 9.391389680039035, "train/model_loss_mean": 12.097103499323945, "train/model_loss_std": 11.345587678294365, "train/model_opt_grad_norm": 112.09156976501798, "train/model_opt_grad_steps": 2720.0, "train/model_opt_loss": 616.1753344092864, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 50.37568306010929, "train/policy_entropy_mag": 0.1261593737726003, "train/policy_entropy_max": 0.1261593737726003, "train/policy_entropy_mean": 0.0818996056507194, "train/policy_entropy_min": 0.07943433808172987, "train/policy_entropy_std": 0.004104390607638186, "train/policy_logprob_mag": 7.438229764094118, "train/policy_logprob_max": -0.009464301112937471, "train/policy_logprob_mean": -0.08181276530678806, "train/policy_logprob_min": -7.438229764094118, "train/policy_logprob_std": 0.7220864282931135, "train/policy_randomness_mag": 0.044528722590028914, "train/policy_randomness_max": 0.044528722590028914, "train/policy_randomness_mean": 0.0289069669311001, "train/policy_randomness_min": 0.02803683552707805, "train/policy_randomness_std": 0.0014486697746824923, "train/post_ent_mag": 36.32842569403309, "train/post_ent_max": 36.32842569403309, "train/post_ent_mean": 25.084169471198745, "train/post_ent_min": 11.906674994797003, "train/post_ent_std": 3.9747721640790097, "train/prior_ent_mag": 52.87440895122257, "train/prior_ent_max": 52.87440895122257, "train/prior_ent_mean": 29.74022284752684, "train/prior_ent_min": 14.109225174116958, "train/prior_ent_std": 5.79874637218121, "train/rep_loss_mean": 4.445773906395083, "train/rep_loss_std": 5.535011380096602, "train/reward_avg": 0.006026216879801295, "train/reward_loss_mean": 0.07513143250443896, "train/reward_loss_std": 0.23593639350328288, "train/reward_max_data": 1.0083538554405254, "train/reward_max_pred": 1.0037382880195242, "train/reward_neg_acc": 0.9977833071693045, "train/reward_neg_loss": 0.05876321915557476, "train/reward_pos_acc": 0.6950354380685775, "train/reward_pos_loss": 1.0260536693484406, "train/reward_pred": 0.005591435097107063, "train/reward_rate": 0.016969774590163935, "train_stats/sum_log_reward": 0.2951219423515041, "train_stats/max_log_achievement_collect_drink": 0.024390243902439025, "train_stats/max_log_achievement_collect_sapling": 10.634146341463415, "train_stats/max_log_achievement_collect_wood": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.17073170731707318, "train_stats/max_log_achievement_eat_cow": 0.21951219512195122, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 0.024390243902439025, "train_stats/max_log_achievement_place_table": 0.0, "train_stats/max_log_achievement_wake_up": 0.04878048780487805, "train_stats/mean_log_entropy": 0.08114778686587404, "eval_stats/sum_log_reward": 0.7249999959021807, "eval_stats/max_log_achievement_collect_drink": 0.0, "eval_stats/max_log_achievement_collect_sapling": 15.75, "eval_stats/max_log_achievement_collect_wood": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.25, "eval_stats/max_log_achievement_eat_cow": 0.25, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 0.125, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 0.0, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 3.66202630175394e-06, "report/cont_loss_std": 1.4368943084264174e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00016438685997854918, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.8733863928209757e-06, "report/cont_pred": 0.9951151609420776, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 3.8191518783569336, "report/dyn_loss_std": 5.640690803527832, "report/image_loss_mean": 7.582489013671875, "report/image_loss_std": 7.26923131942749, "report/model_loss_mean": 9.943565368652344, "report/model_loss_std": 9.443452835083008, "report/post_ent_mag": 36.937522888183594, "report/post_ent_max": 36.937522888183594, "report/post_ent_mean": 24.20917510986328, "report/post_ent_min": 10.154550552368164, "report/post_ent_std": 4.63728666305542, "report/prior_ent_mag": 55.665191650390625, "report/prior_ent_max": 55.665191650390625, "report/prior_ent_mean": 28.354225158691406, "report/prior_ent_min": 13.607935905456543, "report/prior_ent_std": 6.395388603210449, "report/rep_loss_mean": 3.8191518783569336, "report/rep_loss_std": 5.640690803527832, "report/reward_avg": 0.007134794723242521, "report/reward_loss_mean": 0.06958247721195221, "report/reward_loss_std": 0.19648897647857666, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0011379718780518, "report/reward_neg_acc": 0.996023952960968, "report/reward_neg_loss": 0.052327580749988556, "report/reward_pos_acc": 0.7222222089767456, "report/reward_pos_loss": 1.0339393615722656, "report/reward_pred": 0.00600790698081255, "report/reward_rate": 0.017578125, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.006156688556075096, "eval/cont_loss_std": 0.1376250684261322, "eval/cont_neg_acc": 0.6000000238418579, "eval/cont_neg_loss": 1.1500086784362793, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0005440685199573636, "eval/cont_pred": 0.996468186378479, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 14.082897186279297, "eval/dyn_loss_std": 9.51001262664795, "eval/image_loss_mean": 48.780006408691406, "eval/image_loss_std": 65.11449432373047, "eval/model_loss_mean": 57.385292053222656, "eval/model_loss_std": 67.98768615722656, "eval/post_ent_mag": 44.36296844482422, "eval/post_ent_max": 44.36296844482422, "eval/post_ent_mean": 25.39160919189453, "eval/post_ent_min": 10.920127868652344, "eval/post_ent_std": 5.685412883758545, "eval/prior_ent_mag": 58.091705322265625, "eval/prior_ent_max": 58.091705322265625, "eval/prior_ent_mean": 31.134307861328125, "eval/prior_ent_min": 13.843938827514648, "eval/prior_ent_std": 7.455697536468506, "eval/rep_loss_mean": 14.082897186279297, "eval/rep_loss_std": 9.51001262664795, "eval/reward_avg": 0.005078124813735485, "eval/reward_loss_mean": 0.14939174056053162, "eval/reward_loss_std": 0.9672605395317078, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9979835748672485, "eval/reward_neg_acc": 0.9990138411521912, "eval/reward_neg_loss": 0.10707661509513855, "eval/reward_pos_acc": 0.5, "eval/reward_pos_loss": 4.440145969390869, "eval/reward_pred": 0.0011382685042917728, "eval/reward_rate": 0.009765625, "replay/size": 15649.0, "replay/inserts": 7328.0, "replay/samples": 29312.0, "replay/insert_wait_avg": 1.73491161463042e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.709289491436887e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 4264.0, "eval_replay/inserts": 1608.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2616316477457683e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.238719940185547e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1001.68359208107, "timer/env.step_count": 916.0, "timer/env.step_total": 90.6082775592804, "timer/env.step_frac": 0.09045598657659468, "timer/env.step_avg": 0.09891733358000043, "timer/env.step_min": 0.023365020751953125, "timer/env.step_max": 2.210897207260132, "timer/replay._sample_count": 29312.0, "timer/replay._sample_total": 15.037791728973389, "timer/replay._sample_frac": 0.015012516774614718, "timer/replay._sample_avg": 0.0005130250999240375, "timer/replay._sample_min": 0.00032830238342285156, "timer/replay._sample_max": 0.025874853134155273, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1117.0, "timer/agent.policy_total": 18.58622694015503, "timer/agent.policy_frac": 0.018554987909446336, "timer/agent.policy_avg": 0.016639415344812024, "timer/agent.policy_min": 0.009789228439331055, "timer/agent.policy_max": 0.04662442207336426, "timer/dataset_train_count": 1832.0, "timer/dataset_train_total": 0.2987642288208008, "timer/dataset_train_frac": 0.0002982620771496282, "timer/dataset_train_avg": 0.00016308091092838472, "timer/dataset_train_min": 9.632110595703125e-05, "timer/dataset_train_max": 0.000659942626953125, "timer/agent.train_count": 1832.0, "timer/agent.train_total": 827.2718827724457, "timer/agent.train_frac": 0.8258814353280247, "timer/agent.train_avg": 0.45156762160068, "timer/agent.train_min": 0.43849778175354004, "timer/agent.train_max": 0.602555513381958, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.475754976272583, "timer/agent.report_frac": 0.000474955345214518, "timer/agent.report_avg": 0.2378774881362915, "timer/agent.report_min": 0.23151111602783203, "timer/agent.report_max": 0.24424386024475098, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0994415283203125e-05, "timer/dataset_eval_frac": 3.094232103653609e-08, "timer/dataset_eval_avg": 3.0994415283203125e-05, "timer/dataset_eval_min": 3.0994415283203125e-05, "timer/dataset_eval_max": 3.0994415283203125e-05, "fps": 7.315586374138745}
{"step": 16704, "time": 2404.5002863407135, "episode/length": 246.0, "episode/score": -0.6850214152891567, "episode/reward_rate": 0.9878542510121457, "episode/intrinsic_return": 0.21497860510680766}
{"step": 16720, "time": 2408.0694546699524, "episode/length": 210.0, "episode/score": -0.7006324329170184, "episode/reward_rate": 0.981042654028436, "episode/intrinsic_return": 0.1993675863147928}
{"step": 16760, "time": 2414.4856140613556, "episode/length": 166.0, "episode/score": -0.8052367135662735, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.09476325001901387}
{"step": 16984, "time": 2443.584200143814, "episode/length": 227.0, "episode/score": 0.26718671228059065, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.16718670287423265}
{"step": 17208, "time": 2472.6741275787354, "episode/length": 190.0, "episode/score": -0.7534477648644042, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.14655225553156015}
{"step": 17360, "time": 2492.7661967277527, "episode/length": 188.0, "episode/score": -0.789218051070975, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.1107819693249894}
{"step": 17480, "time": 2509.017811536789, "episode/length": 181.0, "episode/score": 0.2730480621642073, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.1730480539220025}
{"step": 17832, "time": 2553.522770881653, "episode/length": 43.0, "episode/score": -0.8593721920115058, "episode/reward_rate": 0.8863636363636364, "episode/intrinsic_return": 0.04062782768596662}
{"step": 17888, "time": 2561.9025287628174, "episode/length": 112.0, "episode/score": -0.8292112852345781, "episode/reward_rate": 0.9557522123893806, "episode/intrinsic_return": 0.07078872683769077}
{"step": 17920, "time": 2567.4711825847626, "episode/length": 220.0, "episode/score": 0.28462427806607593, "episode/reward_rate": 0.9819004524886877, "episode/intrinsic_return": 0.18462426865971793}
{"step": 18032, "time": 2582.7162024974823, "episode/length": 165.0, "episode/score": -0.7978679260088484, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.10213209438711601}
{"step": 18168, "time": 2600.9550971984863, "episode/length": 41.0, "episode/score": -0.8560833524097688, "episode/reward_rate": 0.9047619047619048, "episode/intrinsic_return": 0.043916666123550385}
{"step": 18184, "time": 2604.511358976364, "episode/length": 182.0, "episode/score": 1.25453241268292, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.15453237463839287}
{"step": 18280, "time": 2617.855259656906, "episode/length": 189.0, "episode/score": 0.22629151800538239, "episode/reward_rate": 0.968421052631579, "episode/intrinsic_return": 0.12629148543237534}
{"step": 18488, "time": 2644.7367825508118, "episode/length": 159.0, "episode/score": -0.7361718047332033, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.16382821566276107}
{"step": 18944, "time": 2701.950623035431, "episode/length": 197.0, "episode/score": -0.7152957077576048, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.1847043114742064}
{"step": 19160, "time": 2729.8509001731873, "episode/length": 158.0, "episode/score": -0.7597338377047436, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.14026618269122082}
{"step": 19336, "time": 2752.7395617961884, "episode/length": 143.0, "episode/score": -0.7683703646007416, "episode/reward_rate": 0.9652777777777778, "episode/intrinsic_return": 0.13162965777428326}
{"step": 19536, "time": 2778.9260427951813, "episode/length": 170.0, "episode/score": -0.7882401941310491, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.1117598251007621}
{"step": 19608, "time": 2789.292936563492, "episode/length": 210.0, "episode/score": -0.6944261390864312, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.20557388130953314}
{"step": 19952, "time": 2832.7766518592834, "episode/length": 239.0, "episode/score": -0.7207035996289051, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.1792964270534867}
{"step": 19968, "time": 2836.320436000824, "episode/length": 210.0, "episode/score": -0.7284966027042401, "episode/reward_rate": 0.981042654028436, "episode/intrinsic_return": 0.17150341652757106}
{"step": 20016, "time": 2843.758246898651, "episode/length": 190.0, "episode/score": 0.26041551728451395, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.16041550787815595}
{"step": 20072, "time": 2866.2666022777557, "eval_episode/length": 25.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.8461538461538461}
{"step": 20072, "time": 2869.079028367996, "eval_episode/length": 26.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9629629629629629}
{"step": 20072, "time": 2874.9551904201508, "eval_episode/length": 151.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 20072, "time": 2877.8595588207245, "eval_episode/length": 182.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.994535519125683}
{"step": 20072, "time": 2880.558406352997, "eval_episode/length": 203.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9803921568627451}
{"step": 20072, "time": 2882.5769958496094, "eval_episode/length": 210.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.981042654028436}
{"step": 20072, "time": 2882.5918040275574, "eval_episode/length": 157.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9683544303797469}
{"step": 20072, "time": 2886.0527329444885, "eval_episode/length": 216.0, "eval_episode/score": -0.9000000208616257, "eval_episode/reward_rate": 0.9953917050691244}
{"step": 20192, "time": 2900.5291125774384, "episode/length": 155.0, "episode/score": -0.8058255569121684, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.09417446348379599}
{"step": 20400, "time": 2927.506776332855, "episode/length": 107.0, "episode/score": -0.8051130006260792, "episode/reward_rate": 0.9444444444444444, "episode/intrinsic_return": 0.09488702326234488}
{"step": 20592, "time": 2952.7708208560944, "episode/length": 178.0, "episode/score": -0.7948650463040394, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.10513497292777174}
{"step": 20992, "time": 3003.0195422172546, "episode/length": 206.0, "episode/score": -0.7197111479617888, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.18028887243417557}
{"step": 21184, "time": 3027.8787927627563, "episode/length": 151.0, "episode/score": 0.19565724718904676, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.09565723894684197}
{"step": 21224, "time": 3034.4924812316895, "episode/length": 128.0, "episode/score": -0.7753609377932662, "episode/reward_rate": 0.9689922480620154, "episode/intrinsic_return": 0.12463908143854496}
{"step": 21424, "time": 3060.556067943573, "episode/length": 175.0, "episode/score": 1.2157105830665387, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.11571054618616472}
{"step": 21496, "time": 3070.9267349243164, "episode/length": 192.0, "episode/score": -0.7403576599708686, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.15964236042509583}
{"step": 21656, "time": 3092.551457643509, "episode/length": 156.0, "episode/score": -0.8059308367182894, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.09406918251352181}
{"step": 21792, "time": 3110.517664194107, "episode/length": 272.0, "episode/score": -0.6063355039968883, "episode/reward_rate": 0.9816849816849816, "episode/intrinsic_return": 0.2936645280406083}
{"step": 22496, "time": 3197.8185391426086, "episode/length": 237.0, "episode/score": 0.29955133322710026, "episode/reward_rate": 0.9747899159663865, "episode/intrinsic_return": 0.19955133546227444}
{"step": 22728, "time": 3228.29172372818, "episode/length": 162.0, "episode/score": -0.7746252977976837, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.12537472143412742}
{"step": 22728, "time": 3228.300234079361, "episode/length": 187.0, "episode/score": -0.7226755361225514, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.17732448427341296}
{"step": 22920, "time": 3255.047080516815, "episode/length": 177.0, "episode/score": -0.7746406181140628, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.12535940036104876}
{"step": 22960, "time": 3261.5816946029663, "episode/length": 245.0, "episode/score": -0.6195639685101924, "episode/reward_rate": 0.9878048780487805, "episode/intrinsic_return": 0.28043605188577203}
{"step": 23088, "time": 3278.7933061122894, "episode/length": 237.0, "episode/score": -0.691753329931089, "episode/reward_rate": 0.9873949579831933, "episode/intrinsic_return": 0.20824669046487543}
{"step": 23224, "time": 3297.0987799167633, "episode/length": 195.0, "episode/score": -0.7586332367445721, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.1413667824872391}
{"step": 23288, "time": 3306.6016023159027, "episode/length": 40.0, "episode/score": -0.859872044675285, "episode/reward_rate": 0.8780487804878049, "episode/intrinsic_return": 0.04012797572067939}
{"step": 23480, "time": 3331.83314704895, "episode/length": 48.0, "episode/score": -0.8458070369470079, "episode/reward_rate": 0.9183673469387755, "episode/intrinsic_return": 0.05419298228480329}
{"step": 23493, "time": 3335.959584712982, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 2.0606188566788384, "train/action_min": 0.0, "train/action_std": 0.773976105062858, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 4.60081595638653e-05, "train/actor_opt_grad_steps": 4565.0, "train/actor_opt_loss": -3.1140495787739106, "train/adv_mag": 1.0484222361575002, "train/adv_max": 0.9874463917120643, "train/adv_mean": -0.007168165203319918, "train/adv_min": -0.6963137295906958, "train/adv_std": 0.06709562357434112, "train/cont_avg": 0.9944378396739131, "train/cont_loss_mean": 0.0007906481605396372, "train/cont_loss_std": 0.017607879171447148, "train/cont_neg_acc": 0.9734040745736464, "train/cont_neg_loss": 0.06792527421654758, "train/cont_pos_acc": 0.9998609831799632, "train/cont_pos_loss": 0.00039617369678514915, "train/cont_pred": 0.9944189275088517, "train/cont_rate": 0.9944378396739131, "train/dyn_loss_mean": 4.4808923679849375, "train/dyn_loss_std": 6.132340182428774, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8082124381123678, "train/extr_critic_critic_opt_grad_steps": 4565.0, "train/extr_critic_critic_opt_loss": 11224.69068975034, "train/extr_critic_mag": 1.0020368617513906, "train/extr_critic_max": 0.9573390082172726, "train/extr_critic_mean": -0.193194601491205, "train/extr_critic_min": -0.5805764962797579, "train/extr_critic_std": 0.19311821185376332, "train/extr_return_normed_mag": 1.934257930063683, "train/extr_return_normed_max": 1.9319977065467315, "train/extr_return_normed_mean": 0.25071527363489504, "train/extr_return_normed_min": -0.4354494604403558, "train/extr_return_normed_std": 0.20200603572732728, "train/extr_return_rate": 0.060563507990952094, "train/extr_return_raw_mag": 1.5564444541283275, "train/extr_return_raw_max": 1.488088833451595, "train/extr_return_raw_mean": -0.2004571116481795, "train/extr_return_raw_min": -0.8901641893645992, "train/extr_return_raw_std": 0.20350520794644303, "train/extr_reward_mag": 0.9404567590226298, "train/extr_reward_max": 0.9292109135700308, "train/extr_reward_mean": -0.0011745994824215577, "train/extr_reward_min": -0.368655317503473, "train/extr_reward_std": 0.038368607552357666, "train/image_loss_mean": 9.52447217443715, "train/image_loss_std": 12.364371882832568, "train/model_loss_mean": 12.278349301089412, "train/model_loss_std": 14.480475371298583, "train/model_opt_grad_norm": 111.17083329739778, "train/model_opt_grad_steps": 4555.0, "train/model_opt_loss": 2159.6166915893555, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 180.4517663043478, "train/policy_entropy_mag": 0.08888373742608921, "train/policy_entropy_max": 0.08888373742608921, "train/policy_entropy_mean": 0.07965749894957179, "train/policy_entropy_min": 0.07941304625052473, "train/policy_entropy_std": 0.00041573881571821403, "train/policy_logprob_mag": 7.438380601613418, "train/policy_logprob_max": -0.009461366196932353, "train/policy_logprob_mean": -0.08000632849238488, "train/policy_logprob_min": -7.438380601613418, "train/policy_logprob_std": 0.7195297693428786, "train/policy_randomness_mag": 0.031372058681090886, "train/policy_randomness_max": 0.031372058681090886, "train/policy_randomness_mean": 0.028115601471179853, "train/policy_randomness_min": 0.028029320316146248, "train/policy_randomness_std": 0.0001467375588973759, "train/post_ent_mag": 37.620833790820576, "train/post_ent_max": 37.620833790820576, "train/post_ent_mean": 25.505140252735305, "train/post_ent_min": 12.192658937495688, "train/post_ent_std": 3.8573909764704495, "train/prior_ent_mag": 56.77631133535634, "train/prior_ent_max": 56.77631133535634, "train/prior_ent_mean": 30.216215351353522, "train/prior_ent_min": 14.231775656990383, "train/prior_ent_std": 6.174834992574609, "train/rep_loss_mean": 4.4808923679849375, "train/rep_loss_std": 6.132340182428774, "train/reward_avg": 0.00300816483507768, "train/reward_loss_mean": 0.06455101329914253, "train/reward_loss_std": 0.19502218565701143, "train/reward_max_data": 1.0072282909051231, "train/reward_max_pred": 1.00522253241228, "train/reward_neg_acc": 0.9990208382191865, "train/reward_neg_loss": 0.05370015596323039, "train/reward_pos_acc": 0.705505997914335, "train/reward_pos_loss": 0.8847724860129149, "train/reward_pred": 0.0028120501690706155, "train/reward_rate": 0.013034986413043478, "train_stats/sum_log_reward": -0.6380952522158623, "train_stats/max_log_achievement_collect_drink": 0.047619047619047616, "train_stats/max_log_achievement_collect_sapling": 0.0, "train_stats/max_log_achievement_collect_wood": 0.14285714285714285, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 0.0, "train_stats/max_log_achievement_place_table": 0.0, "train_stats/max_log_achievement_wake_up": 0.07142857142857142, "train_stats/mean_log_entropy": 0.07913714665032569, "eval_stats/sum_log_reward": -0.7750000208616257, "eval_stats/max_log_achievement_collect_drink": 0.125, "eval_stats/max_log_achievement_collect_sapling": 0.0, "eval_stats/max_log_achievement_collect_wood": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 0.0, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 0.0, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 4.615030320564983e-06, "report/cont_loss_std": 6.706851854687557e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0005768077098764479, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.2425782642822014e-06, "report/cont_pred": 0.9941427707672119, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 4.334074020385742, "report/dyn_loss_std": 6.211587905883789, "report/image_loss_mean": 7.664484024047852, "report/image_loss_std": 16.41839027404785, "report/model_loss_mean": 10.32753849029541, "report/model_loss_std": 18.427711486816406, "report/post_ent_mag": 42.54983901977539, "report/post_ent_max": 42.54983901977539, "report/post_ent_mean": 26.259538650512695, "report/post_ent_min": 14.860092163085938, "report/post_ent_std": 3.430690050125122, "report/prior_ent_mag": 57.159217834472656, "report/prior_ent_max": 57.159217834472656, "report/prior_ent_mean": 30.737503051757812, "report/prior_ent_min": 18.256458282470703, "report/prior_ent_std": 5.500423908233643, "report/rep_loss_mean": 4.334074020385742, "report/rep_loss_std": 6.211587905883789, "report/reward_avg": 0.004576428327709436, "report/reward_loss_mean": 0.06260578334331512, "report/reward_loss_std": 0.14347787201404572, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0087666511535645, "report/reward_neg_acc": 0.9980120062828064, "report/reward_neg_loss": 0.0515323132276535, "report/reward_pos_acc": 0.8333333134651184, "report/reward_pos_loss": 0.6814900636672974, "report/reward_pred": 0.005589995998889208, "report/reward_rate": 0.017578125, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.00019833739497698843, "eval/cont_loss_std": 0.004863519221544266, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.007853399030864239, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.0001683175505604595, "eval/cont_pred": 0.9959677457809448, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 16.935951232910156, "eval/dyn_loss_std": 10.399928092956543, "eval/image_loss_mean": 53.79423904418945, "eval/image_loss_std": 73.31514739990234, "eval/model_loss_mean": 64.12257385253906, "eval/model_loss_std": 76.43403625488281, "eval/post_ent_mag": 41.74825668334961, "eval/post_ent_max": 41.74825668334961, "eval/post_ent_mean": 25.253793716430664, "eval/post_ent_min": 10.284666061401367, "eval/post_ent_std": 6.007253646850586, "eval/prior_ent_mag": 57.159217834472656, "eval/prior_ent_max": 57.159217834472656, "eval/prior_ent_mean": 30.634395599365234, "eval/prior_ent_min": 13.070682525634766, "eval/prior_ent_std": 8.076613426208496, "eval/rep_loss_mean": 16.935951232910156, "eval/rep_loss_std": 10.399928092956543, "eval/reward_avg": 0.008886718191206455, "eval/reward_loss_mean": 0.16656766831874847, "eval/reward_loss_std": 1.0502245426177979, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.004758358001709, "eval/reward_neg_acc": 0.997029721736908, "eval/reward_neg_loss": 0.11935869604349136, "eval/reward_pos_acc": 0.6428571939468384, "eval/reward_pos_loss": 3.572357416152954, "eval/reward_pred": 0.007550086826086044, "eval/reward_rate": 0.013671875, "replay/size": 22989.0, "replay/inserts": 7340.0, "replay/samples": 29360.0, "replay/insert_wait_avg": 1.784501348594229e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.346680399507528e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 6000.0, "eval_replay/inserts": 1736.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.272160886070146e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.238719940185547e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0410070419312, "timer/env.step_count": 917.0, "timer/env.step_total": 91.44262647628784, "timer/env.step_frac": 0.09143887683843119, "timer/env.step_avg": 0.09971933094469776, "timer/env.step_min": 0.023145437240600586, "timer/env.step_max": 3.355862617492676, "timer/replay._sample_count": 29360.0, "timer/replay._sample_total": 14.510767459869385, "timer/replay._sample_frac": 0.014510172440619685, "timer/replay._sample_avg": 0.000494235948905633, "timer/replay._sample_min": 0.0003457069396972656, "timer/replay._sample_max": 0.01083993911743164, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1134.0, "timer/agent.policy_total": 18.64270544052124, "timer/agent.policy_frac": 0.018641940989665397, "timer/agent.policy_avg": 0.016439775520741835, "timer/agent.policy_min": 0.009908676147460938, "timer/agent.policy_max": 0.05031538009643555, "timer/dataset_train_count": 1835.0, "timer/dataset_train_total": 0.295703649520874, "timer/dataset_train_frac": 0.00029569152408614715, "timer/dataset_train_avg": 0.00016114640300865068, "timer/dataset_train_min": 9.202957153320312e-05, "timer/dataset_train_max": 0.0019299983978271484, "timer/agent.train_count": 1835.0, "timer/agent.train_total": 826.0681045055389, "timer/agent.train_frac": 0.82603423128518, "timer/agent.train_avg": 0.4501733539539722, "timer/agent.train_min": 0.43823695182800293, "timer/agent.train_max": 0.9407775402069092, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4813661575317383, "timer/agent.report_frac": 0.0004813464189389534, "timer/agent.report_avg": 0.24068307876586914, "timer/agent.report_min": 0.23379015922546387, "timer/agent.report_max": 0.24757599830627441, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.62396240234375e-05, "timer/dataset_eval_frac": 3.623813800459284e-08, "timer/dataset_eval_avg": 3.62396240234375e-05, "timer/dataset_eval_min": 3.62396240234375e-05, "timer/dataset_eval_max": 3.62396240234375e-05, "fps": 7.339595964753175}
{"step": 23784, "time": 3371.565017938614, "episode/length": 131.0, "episode/score": -0.7673781002413307, "episode/reward_rate": 0.9545454545454546, "episode/intrinsic_return": 0.13262192364709335}
{"step": 23944, "time": 3392.709619283676, "episode/length": 268.0, "episode/score": -0.6208580584516312, "episode/reward_rate": 0.9925650557620818, "episode/intrinsic_return": 0.2791419631084864}
{"step": 24192, "time": 3424.3807899951935, "episode/length": 182.0, "episode/score": -0.7695346353393688, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.13046538389244233}
{"step": 24336, "time": 3443.5478563308716, "episode/length": 176.0, "episode/score": 0.2908330280715745, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.19083301982936973}
{"step": 24784, "time": 3501.05539894104, "episode/length": 194.0, "episode/score": -0.7281257933846064, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.17187422933966445}
{"step": 24800, "time": 3504.6081142425537, "episode/length": 188.0, "episode/score": -0.7572237438771481, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.14277627535466308}
{"step": 24840, "time": 3511.3008546829224, "episode/length": 169.0, "episode/score": 0.23137001971463178, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.131370011472427}
{"step": 25000, "time": 3532.783255815506, "episode/length": 131.0, "episode/score": -0.7594188809871412, "episode/reward_rate": 0.9621212121212122, "episode/intrinsic_return": 0.14058113940882322}
{"step": 25112, "time": 3548.0895488262177, "episode/length": 165.0, "episode/score": 0.25170517505284806, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.1517051664613973}
{"step": 25208, "time": 3561.3069248199463, "episode/length": 338.0, "episode/score": -0.5990241442686965, "episode/reward_rate": 0.46607669616519176, "episode/intrinsic_return": 0.3009758796197275}
{"step": 25440, "time": 3591.1700937747955, "episode/length": 28.0, "episode/score": -0.86500002106186, "episode/reward_rate": 0.8275862068965517, "episode/intrinsic_return": 0.03499999933410436}
{"step": 25784, "time": 3634.4908645153046, "episode/length": 198.0, "episode/score": -0.7797547746995406, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.12024524569642381}
{"step": 25816, "time": 3639.8899426460266, "episode/length": 184.0, "episode/score": -0.7327459453854317, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.1672540750105327}
{"step": 26336, "time": 3704.5731570720673, "episode/length": 193.0, "episode/score": -0.7780375481793271, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.12196247221663725}
{"step": 26552, "time": 3732.4137349128723, "episode/length": 179.0, "episode/score": -0.7895265567703973, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.11047346362556709}
{"step": 26616, "time": 3741.724091053009, "episode/length": 226.0, "episode/score": -0.709978471818431, "episode/reward_rate": 0.9823788546255506, "episode/intrinsic_return": 0.19002154741338018}
{"step": 26840, "time": 3770.380812883377, "episode/length": 249.0, "episode/score": 0.32677190268441336, "episode/reward_rate": 0.968, "episode/intrinsic_return": 0.226771906898648}
{"step": 27072, "time": 3800.2225267887115, "episode/length": 160.0, "episode/score": -0.7593254400007936, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.14067458039517078}
{"step": 27128, "time": 3808.511215686798, "episode/length": 265.0, "episode/score": 0.34315690626954165, "episode/reward_rate": 0.9887218045112782, "episode/intrinsic_return": 0.24315697876136255}
{"step": 27432, "time": 3846.8619458675385, "episode/length": 248.0, "episode/score": 0.3358296886963217, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.23582968860318942}
{"step": 27608, "time": 3869.8472809791565, "episode/length": 158.0, "episode/score": -0.8064606373513925, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.09353938304457188}
{"step": 27776, "time": 3891.5998890399933, "episode/length": 42.0, "episode/score": -0.8508750213077292, "episode/reward_rate": 0.8837209302325582, "episode/intrinsic_return": 0.0491249990882352}
{"step": 27912, "time": 3909.6741983890533, "episode/length": 261.0, "episode/score": -0.6871061581437061, "episode/reward_rate": 0.9885496183206107, "episode/intrinsic_return": 0.21289386283433487}
{"step": 28040, "time": 3927.1415894031525, "episode/length": 149.0, "episode/score": -0.7938325729314784, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.10616744746448603}
{"step": 28112, "time": 3937.450827360153, "episode/length": 194.0, "episode/score": -0.7470367218297724, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.15296329856619195}
{"step": 28184, "time": 3947.7327303886414, "episode/length": 71.0, "episode/score": -0.8170722001693775, "episode/reward_rate": 0.9305555555555556, "episode/intrinsic_return": 0.08292782022658685}
{"step": 28208, "time": 3952.11802983284, "episode/length": 198.0, "episode/score": -0.7298663257824956, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.17013369461346883}
{"step": 29120, "time": 4064.3265783786774, "episode/length": 255.0, "episode/score": -0.7016080923528989, "episode/reward_rate": 0.98828125, "episode/intrinsic_return": 0.1983919280430655}
{"step": 29160, "time": 4070.6499457359314, "episode/length": 172.0, "episode/score": -0.7797812881656228, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.12021873223034163}
{"step": 29160, "time": 4070.658673286438, "episode/length": 253.0, "episode/score": -0.6810189193843144, "episode/reward_rate": 0.984251968503937, "episode/intrinsic_return": 0.21898110450410968}
{"step": 29456, "time": 4110.0013382434845, "episode/length": 192.0, "episode/score": -0.7888038306334693, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.11119618976249512}
{"step": 29456, "time": 4110.009517431259, "episode/length": 167.0, "episode/score": -0.770850781556419, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.12914923883954543}
{"step": 29504, "time": 4120.161396741867, "episode/length": 164.0, "episode/score": -0.7651801146698745, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.1348199045619367}
{"step": 29648, "time": 4139.149394035339, "episode/length": 60.0, "episode/score": -0.8498543705284192, "episode/reward_rate": 0.9180327868852459, "episode/intrinsic_return": 0.05014565219585165}
{"step": 29648, "time": 4139.160990953445, "episode/length": 179.0, "episode/score": 0.2641842585519498, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.16418425030974504}
{"step": 29856, "time": 4167.580679655075, "episode/length": 226.0, "episode/score": -0.7171111811185256, "episode/reward_rate": 0.9823788546255506, "episode/intrinsic_return": 0.1828888381132856}
{"step": 30056, "time": 4207.332329273224, "eval_episode/length": 7.0, "eval_episode/score": -0.8999999761581421, "eval_episode/reward_rate": 0.875}
{"step": 30056, "time": 4211.304049730301, "eval_episode/length": 61.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9193548387096774}
{"step": 30056, "time": 4216.958709001541, "eval_episode/length": 156.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9745222929936306}
{"step": 30056, "time": 4218.8742299079895, "eval_episode/length": 164.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9696969696969697}
{"step": 30056, "time": 4220.798778295517, "eval_episode/length": 172.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9710982658959537}
{"step": 30056, "time": 4222.449485063553, "eval_episode/length": 174.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.96}
{"step": 30056, "time": 4224.861908912659, "eval_episode/length": 185.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9946236559139785}
{"step": 30056, "time": 4229.573739767075, "eval_episode/length": 232.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9828326180257511}
{"step": 30464, "time": 4278.873625278473, "episode/length": 162.0, "episode/score": -0.8050349767399894, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.09496504482012824}
{"step": 30728, "time": 4312.278529644012, "episode/length": 158.0, "episode/score": -0.8091549003954697, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.09084512000049472}
{"step": 30800, "time": 4322.654447793961, "episode/length": 167.0, "episode/score": -0.7633169629734766, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.13668305742248776}
{"step": 30880, "time": 4333.928929805756, "episode/length": 171.0, "episode/score": -0.7538514898942594, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.14614852933755174}
{"step": 30881, "time": 4336.522096395493, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 2.060307353251689, "train/action_min": 0.0, "train/action_std": 0.7725782030337566, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00011198735448144017, "train/actor_opt_grad_steps": 6410.0, "train/actor_opt_loss": 2.6085292742059036, "train/adv_mag": 0.9928137004375458, "train/adv_max": 0.9473827084979496, "train/adv_mean": -0.0014391709384260654, "train/adv_min": -0.6495613188356967, "train/adv_std": 0.06100288117052736, "train/cont_avg": 0.994288429054054, "train/cont_loss_mean": 0.0005151246443028406, "train/cont_loss_std": 0.014087105496450071, "train/cont_neg_acc": 0.9841398564544884, "train/cont_neg_loss": 0.06268106787601199, "train/cont_pos_acc": 0.9999362478385101, "train/cont_pos_loss": 0.00019567972560969032, "train/cont_pred": 0.9942877850017032, "train/cont_rate": 0.994288429054054, "train/dyn_loss_mean": 4.616664297516282, "train/dyn_loss_std": 6.456677467758591, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.6415487787208042, "train/extr_critic_critic_opt_grad_steps": 6410.0, "train/extr_critic_critic_opt_loss": 10647.252465160473, "train/extr_critic_mag": 0.8603455549961811, "train/extr_critic_max": 0.7667238493223448, "train/extr_critic_mean": -0.3014736231114413, "train/extr_critic_min": -0.6450109533361487, "train/extr_critic_std": 0.14978778704598145, "train/extr_return_normed_mag": 1.734308294670002, "train/extr_return_normed_max": 1.732341595275982, "train/extr_return_normed_mean": 0.23120275598925513, "train/extr_return_normed_min": -0.3980755809191111, "train/extr_return_normed_std": 0.16486514891321594, "train/extr_return_rate": 0.10572494906247468, "train/extr_return_raw_mag": 1.3195727216230857, "train/extr_return_raw_max": 1.1982260646852287, "train/extr_return_raw_mean": -0.30291280537038234, "train/extr_return_raw_min": -0.9321911132013475, "train/extr_return_raw_std": 0.16486514931595003, "train/extr_reward_mag": 0.9412148952484131, "train/extr_reward_max": 0.9298961710285496, "train/extr_reward_mean": -0.0019707068765136364, "train/extr_reward_min": -0.37681796937375456, "train/extr_reward_std": 0.03995732802998375, "train/image_loss_mean": 7.389458685952264, "train/image_loss_std": 9.724670219421387, "train/model_loss_mean": 10.222259364256988, "train/model_loss_std": 12.174113443735484, "train/model_opt_grad_norm": 81.5325804942363, "train/model_opt_grad_steps": 6399.972972972973, "train/model_opt_loss": 6204.596068676098, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 626.6891891891892, "train/policy_entropy_mag": 0.11038828222332774, "train/policy_entropy_max": 0.11038828222332774, "train/policy_entropy_mean": 0.07994953627521928, "train/policy_entropy_min": 0.07942288433377807, "train/policy_entropy_std": 0.0013261309212130319, "train/policy_logprob_mag": 7.438379357312177, "train/policy_logprob_max": -0.0094627281197825, "train/policy_logprob_mean": -0.07991490734590066, "train/policy_logprob_min": -7.438379357312177, "train/policy_logprob_std": 0.7186067062455255, "train/policy_randomness_mag": 0.0389622193735999, "train/policy_randomness_max": 0.0389622193735999, "train/policy_randomness_mean": 0.028218677831259933, "train/policy_randomness_min": 0.02803279273211956, "train/policy_randomness_std": 0.0004680660209340056, "train/post_ent_mag": 38.25482134432406, "train/post_ent_max": 38.25482134432406, "train/post_ent_mean": 26.357271452207822, "train/post_ent_min": 12.64524295394485, "train/post_ent_std": 3.973530898223052, "train/prior_ent_mag": 59.40358826920793, "train/prior_ent_max": 59.40358826920793, "train/prior_ent_mean": 31.147320154550915, "train/prior_ent_min": 14.574496996080553, "train/prior_ent_std": 6.4526148641431655, "train/rep_loss_mean": 4.616664297516282, "train/rep_loss_std": 6.456677467758591, "train/reward_avg": 0.0016228385025798973, "train/reward_loss_mean": 0.06228695489667557, "train/reward_loss_std": 0.17939119757832708, "train/reward_max_data": 1.0088175979820457, "train/reward_max_pred": 1.0048001334473893, "train/reward_neg_acc": 0.9992085302198256, "train/reward_neg_loss": 0.05288730950371639, "train/reward_pos_acc": 0.7013927294595822, "train/reward_pos_loss": 0.8385655683440131, "train/reward_pred": 0.0014662620441585376, "train/reward_rate": 0.011803209459459459, "train_stats/sum_log_reward": -0.7250000186264515, "train_stats/max_log_achievement_collect_drink": 0.05, "train_stats/max_log_achievement_collect_sapling": 0.0, "train_stats/max_log_achievement_collect_wood": 0.025, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 0.0, "train_stats/max_log_achievement_place_table": 0.0, "train_stats/max_log_achievement_wake_up": 0.1, "train_stats/mean_log_entropy": 0.0795346723869443, "eval_stats/sum_log_reward": -0.7750000031664968, "eval_stats/max_log_achievement_collect_drink": 0.0, "eval_stats/max_log_achievement_collect_sapling": 0.0, "eval_stats/max_log_achievement_collect_wood": 0.125, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 0.0, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 0.0, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.00021428012405522168, "report/cont_loss_std": 0.006455558352172375, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.034539658576250076, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.1969473234785255e-05, "report/cont_pred": 0.9943116307258606, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 4.599057197570801, "report/dyn_loss_std": 6.158176422119141, "report/image_loss_mean": 7.173083782196045, "report/image_loss_std": 9.541996955871582, "report/model_loss_mean": 9.989335060119629, "report/model_loss_std": 11.639421463012695, "report/post_ent_mag": 41.1423454284668, "report/post_ent_max": 41.1423454284668, "report/post_ent_mean": 27.012557983398438, "report/post_ent_min": 16.63482666015625, "report/post_ent_std": 3.4560434818267822, "report/prior_ent_mag": 60.330238342285156, "report/prior_ent_max": 60.330238342285156, "report/prior_ent_mean": 31.936927795410156, "report/prior_ent_min": 20.477420806884766, "report/prior_ent_std": 5.76658821105957, "report/rep_loss_mean": 4.599057197570801, "report/rep_loss_std": 6.158176422119141, "report/reward_avg": -0.0028196959756314754, "report/reward_loss_mean": 0.056602369993925095, "report/reward_loss_std": 0.12098905444145203, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 0.9981275796890259, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.05174075439572334, "report/reward_pos_acc": 0.875, "report/reward_pos_loss": 0.6740273833274841, "report/reward_pred": -0.0029690987430512905, "report/reward_rate": 0.0078125, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.0005067455931566656, "eval/cont_loss_std": 0.015873197466135025, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.1288221776485443, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 3.5478526569932e-06, "eval/cont_pred": 0.996486246585846, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 18.97709846496582, "eval/dyn_loss_std": 10.901999473571777, "eval/image_loss_mean": 47.48789978027344, "eval/image_loss_std": 65.12505340576172, "eval/model_loss_mean": 59.03211975097656, "eval/model_loss_std": 67.70277404785156, "eval/post_ent_mag": 38.78045654296875, "eval/post_ent_max": 38.78045654296875, "eval/post_ent_mean": 24.608076095581055, "eval/post_ent_min": 10.62309455871582, "eval/post_ent_std": 6.0555524826049805, "eval/prior_ent_mag": 60.330238342285156, "eval/prior_ent_max": 60.330238342285156, "eval/prior_ent_mean": 31.421707153320312, "eval/prior_ent_min": 11.492116928100586, "eval/prior_ent_std": 8.82718563079834, "eval/rep_loss_mean": 18.97709846496582, "eval/rep_loss_std": 10.901999473571777, "eval/reward_avg": 0.01162109337747097, "eval/reward_loss_mean": 0.15745441615581512, "eval/reward_loss_std": 0.9836319088935852, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9940065145492554, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.07850180566310883, "eval/reward_pos_acc": 0.4375, "eval/reward_pos_loss": 5.131468772888184, "eval/reward_pred": 0.0018878390546888113, "eval/reward_rate": 0.015625, "replay/size": 30377.0, "replay/inserts": 7388.0, "replay/samples": 29552.0, "replay/insert_wait_avg": 1.6647670871835822e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.505683429059172e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 7864.0, "eval_replay/inserts": 1864.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.4586510064775852e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.046627044677734e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.5480535030365, "timer/env.step_count": 924.0, "timer/env.step_total": 88.5514726638794, "timer/env.step_frac": 0.08850296830207231, "timer/env.step_avg": 0.0958349271254106, "timer/env.step_min": 0.022423505783081055, "timer/env.step_max": 4.283930540084839, "timer/replay._sample_count": 29552.0, "timer/replay._sample_total": 14.46430253982544, "timer/replay._sample_frac": 0.014456379670305903, "timer/replay._sample_avg": 0.0004894525764694586, "timer/replay._sample_min": 0.00034618377685546875, "timer/replay._sample_max": 0.02595996856689453, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1157.0, "timer/agent.policy_total": 19.5791118144989, "timer/agent.policy_frac": 0.019568387291295133, "timer/agent.policy_avg": 0.016922309260586778, "timer/agent.policy_min": 0.009625911712646484, "timer/agent.policy_max": 0.20295310020446777, "timer/dataset_train_count": 1847.0, "timer/dataset_train_total": 0.27921414375305176, "timer/dataset_train_frac": 0.0002790612032830309, "timer/dataset_train_avg": 0.00015117170750029874, "timer/dataset_train_min": 8.630752563476562e-05, "timer/dataset_train_max": 0.0007922649383544922, "timer/agent.train_count": 1847.0, "timer/agent.train_total": 828.5764782428741, "timer/agent.train_frac": 0.8281226227385385, "timer/agent.train_avg": 0.4486066476680423, "timer/agent.train_min": 0.43610692024230957, "timer/agent.train_max": 1.0336482524871826, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47269320487976074, "timer/agent.report_frac": 0.0004724342856145751, "timer/agent.report_avg": 0.23634660243988037, "timer/agent.report_min": 0.22933387756347656, "timer/agent.report_max": 0.24335932731628418, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.86102294921875e-05, "timer/dataset_eval_frac": 2.8594558144428664e-08, "timer/dataset_eval_avg": 2.86102294921875e-05, "timer/dataset_eval_min": 2.86102294921875e-05, "timer/dataset_eval_max": 2.86102294921875e-05, "fps": 7.383858809259867}
{"step": 31056, "time": 4357.774471998215, "episode/length": 241.0, "episode/score": 0.2805493865118933, "episode/reward_rate": 0.987603305785124, "episode/intrinsic_return": 0.18054934811812018}
{"step": 31224, "time": 4379.885592460632, "episode/length": 196.0, "episode/score": -0.7192964735259011, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.18070354884912376}
{"step": 31576, "time": 4424.532447099686, "episode/length": 214.0, "episode/score": -0.7341796410657935, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.16582038445244507}
{"step": 31704, "time": 4441.779934883118, "episode/length": 154.0, "episode/score": -0.8163206042070215, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.0836794150247897}
{"step": 32088, "time": 4490.309206485748, "episode/length": 160.0, "episode/score": 0.21599391394170198, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.11599390569949719}
{"step": 32240, "time": 4510.502018451691, "episode/length": 169.0, "episode/score": -0.8032243181494323, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.09677570224653209}
{"step": 32280, "time": 4516.911487340927, "episode/length": 152.0, "episode/score": -0.7610666469902299, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.13893337340573453}
{"step": 32360, "time": 4528.143685340881, "episode/length": 338.0, "episode/score": -0.6333510036376993, "episode/reward_rate": 0.9941002949852508, "episode/intrinsic_return": 0.26664902688639813}
{"step": 32392, "time": 4533.700171947479, "episode/length": 207.0, "episode/score": -0.7226237085912999, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.1773763106405113}
{"step": 32440, "time": 4541.354949951172, "episode/length": 151.0, "episode/score": -0.7842445736484933, "episode/reward_rate": 0.9605263157894737, "episode/intrinsic_return": 0.1157554490757775}
{"step": 32568, "time": 4558.459104061127, "episode/length": 107.0, "episode/score": 0.20324454304886785, "episode/reward_rate": 0.9537037037037037, "episode/intrinsic_return": 0.10324453480666307}
{"step": 32824, "time": 4592.43568778038, "episode/length": 57.0, "episode/score": -0.8603469631543703, "episode/reward_rate": 0.9137931034482759, "episode/intrinsic_return": 0.039653056310271495}
{"step": 33112, "time": 4629.326995372772, "episode/length": 191.0, "episode/score": -0.7159352730936916, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.18406474730227274}
{"step": 33504, "time": 4678.855568408966, "episode/length": 152.0, "episode/score": -0.7740561522307416, "episode/reward_rate": 0.9738562091503268, "episode/intrinsic_return": 0.12594386700106952}
{"step": 33712, "time": 4705.8475823402405, "episode/length": 202.0, "episode/score": 0.27178567221039884, "episode/reward_rate": 0.9802955665024631, "episode/intrinsic_return": 0.17178566280404084}
{"step": 33720, "time": 4708.334890127182, "episode/length": 184.0, "episode/score": -0.7707386506822331, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.12926136854957804}
{"step": 33792, "time": 4718.764632940292, "episode/length": 168.0, "episode/score": -0.730423918702968, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.1695761005288432}
{"step": 34000, "time": 4745.62002158165, "episode/length": 178.0, "episode/score": -0.7828376258901244, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.11716239334168677}
{"step": 34224, "time": 4774.683084011078, "episode/length": 138.0, "episode/score": -0.7823268825613923, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.11767306495858065}
{"step": 34400, "time": 4797.736563682556, "episode/length": 250.0, "episode/score": -0.7081380118951301, "episode/reward_rate": 0.9960159362549801, "episode/intrinsic_return": 0.19186200733668102}
{"step": 34728, "time": 4839.559884309769, "episode/length": 237.0, "episode/score": -0.7347110173667488, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.16528894738269173}
{"step": 34856, "time": 4856.548570632935, "episode/length": 142.0, "episode/score": 0.19522551385216502, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.09522544879928319}
{"step": 34872, "time": 4860.196479558945, "episode/length": 134.0, "episode/score": 0.17055494737610388, "episode/reward_rate": 0.9925925925925926, "episode/intrinsic_return": 0.07055489093795586}
{"step": 34968, "time": 4873.948586702347, "episode/length": 155.0, "episode/score": 0.26353878328518476, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.16353877818619367}
{"step": 35128, "time": 4894.84902215004, "episode/length": 140.0, "episode/score": 0.2614197026414331, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.1614196399168577}
{"step": 35512, "time": 4943.205266237259, "episode/length": 160.0, "episode/score": 0.2713511387364633, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.17135113049425854}
{"step": 36120, "time": 5018.866967916489, "episode/length": 214.0, "episode/score": 0.3048393715000657, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.20483931506191766}
{"step": 36224, "time": 5033.13494849205, "episode/length": 168.0, "episode/score": 0.27018269611983214, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.17018270833762017}
{"step": 36504, "time": 5068.97852230072, "episode/length": 123.0, "episode/score": 0.18493159318256858, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.08493166485948223}
{"step": 36552, "time": 5076.291922569275, "episode/length": 211.0, "episode/score": 0.29598421418040743, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.19598420593820265}
{"step": 36656, "time": 5090.522898197174, "episode/length": 210.0, "episode/score": 0.27348189001361334, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.17348188177140855}
{"step": 36744, "time": 5103.000363588333, "episode/length": 404.0, "episode/score": 0.40236539476165945, "episode/reward_rate": 0.9975308641975309, "episode/intrinsic_return": 0.3023653913506905}
{"step": 36784, "time": 5109.962033033371, "episode/length": 256.0, "episode/score": 0.36710783311343675, "episode/reward_rate": 0.9844357976653697, "episode/intrinsic_return": 0.26710782370707875}
{"step": 37384, "time": 5185.223994731903, "episode/length": 281.0, "episode/score": 0.3525314802760704, "episode/reward_rate": 0.9964539007092199, "episode/intrinsic_return": 0.2525314163873418}
{"step": 37520, "time": 5203.389485836029, "episode/length": 174.0, "episode/score": 0.24657442285092657, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.14657439621510093}
{"step": 37520, "time": 5203.3983108997345, "episode/length": 161.0, "episode/score": 0.22776259057957304, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.1277625398457758}
{"step": 37680, "time": 5226.4186198711395, "episode/length": 146.0, "episode/score": 0.2644270380433227, "episode/reward_rate": 0.9727891156462585, "episode/intrinsic_return": 0.16442703096527111}
{"step": 38000, "time": 5267.070492744446, "episode/length": 76.0, "episode/score": 0.16979442676029066, "episode/reward_rate": 0.935064935064935, "episode/intrinsic_return": 0.06979441851808588}
{"step": 38064, "time": 5276.36247587204, "episode/length": 188.0, "episode/score": 0.3074518288588024, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.2074518194524444}
{"step": 38312, "time": 5308.146415710449, "episode/length": 206.0, "episode/score": 0.2731218996515281, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.17312183459864627}
{"step": 38344, "time": 5313.736214876175, "episode/length": 34.0, "episode/score": -0.8660595434193965, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.03394047581241466}
{"step": 38480, "time": 5331.9401948452, "episode/length": 216.0, "episode/score": 0.2527153949060903, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.15271535031320127}
{"step": 38497, "time": 5336.553009033203, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 3.5419992547286183, "train/action_min": 0.0, "train/action_std": 1.1883469318088733, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.011842082311513399, "train/actor_opt_grad_steps": 8285.0, "train/actor_opt_loss": 10.760789626032897, "train/adv_mag": 1.010636414822779, "train/adv_max": 0.9607819252892544, "train/adv_mean": 0.004053661794439808, "train/adv_min": -0.6863247327114407, "train/adv_std": 0.07795630136602803, "train/cont_avg": 0.9943256578947368, "train/cont_loss_mean": 0.00039217248049022886, "train/cont_loss_std": 0.011124816527147854, "train/cont_neg_acc": 0.9846094429492951, "train/cont_neg_loss": 0.04346027676634238, "train/cont_pos_acc": 0.9999483102246335, "train/cont_pos_loss": 0.0001590553691152919, "train/cont_pred": 0.9943386993910137, "train/cont_rate": 0.9943256578947368, "train/dyn_loss_mean": 4.826521416714317, "train/dyn_loss_std": 6.792683772036904, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8020148823135778, "train/extr_critic_critic_opt_grad_steps": 8285.0, "train/extr_critic_critic_opt_loss": 12402.847856702303, "train/extr_critic_mag": 1.0448040855558296, "train/extr_critic_max": 1.014665320672487, "train/extr_critic_mean": -0.08957832039726016, "train/extr_critic_min": -0.6015195652058251, "train/extr_critic_std": 0.2987861171364784, "train/extr_return_normed_mag": 1.855936912172719, "train/extr_return_normed_max": 1.8550403667123694, "train/extr_return_normed_mean": 0.31357355658945285, "train/extr_return_normed_min": -0.41561578292595713, "train/extr_return_normed_std": 0.267740268221027, "train/extr_return_rate": 0.16793723474991948, "train/extr_return_raw_mag": 1.7211313922154277, "train/extr_return_raw_max": 1.6567970209215817, "train/extr_return_raw_mean": -0.0855861778567104, "train/extr_return_raw_min": -0.9281540858118158, "train/extr_return_raw_std": 0.3186471560283711, "train/extr_reward_mag": 0.9672465405966106, "train/extr_reward_max": 0.9636217807468616, "train/extr_reward_mean": -0.0008081260963129017, "train/extr_reward_min": -0.4422898455670005, "train/extr_reward_std": 0.04669474744679112, "train/image_loss_mean": 6.595899098797848, "train/image_loss_std": 10.141010678441901, "train/model_loss_mean": 9.55094777910333, "train/model_loss_std": 12.798640835912604, "train/model_opt_grad_norm": 88.90176597474114, "train/model_opt_grad_steps": 8273.505263157895, "train/model_opt_loss": 6038.78119217722, "train/model_opt_model_opt_grad_overflow": 0.005263157894736842, "train/model_opt_model_opt_grad_scale": 628.2894736842105, "train/policy_entropy_mag": 0.6048441517509913, "train/policy_entropy_max": 0.6048441517509913, "train/policy_entropy_mean": 0.15530943094115507, "train/policy_entropy_min": 0.0795526829597197, "train/policy_entropy_std": 0.12036704408298982, "train/policy_logprob_mag": 7.438331716939023, "train/policy_logprob_max": -0.009480630361327999, "train/policy_logprob_mean": -0.1550320311988655, "train/policy_logprob_min": -7.438331716939023, "train/policy_logprob_std": 0.7774033684479563, "train/policy_randomness_mag": 0.21348344362095784, "train/policy_randomness_max": 0.21348344362095784, "train/policy_randomness_mean": 0.054817414244538856, "train/policy_randomness_min": 0.028078605999287805, "train/policy_randomness_std": 0.04248428403707773, "train/post_ent_mag": 38.70667031940661, "train/post_ent_max": 38.70667031940661, "train/post_ent_mean": 26.83233221957558, "train/post_ent_min": 13.089432365015933, "train/post_ent_std": 4.08606616070396, "train/prior_ent_mag": 61.256135699623506, "train/prior_ent_max": 61.256135699623506, "train/prior_ent_mean": 31.82689144736842, "train/prior_ent_min": 15.335937203859029, "train/prior_ent_std": 6.681227759311073, "train/rep_loss_mean": 4.826521416714317, "train/rep_loss_std": 6.792683772036904, "train/reward_avg": 0.0007896998556373689, "train/reward_loss_mean": 0.05874369132675623, "train/reward_loss_std": 0.16127778279938196, "train/reward_max_data": 1.000176344655062, "train/reward_max_pred": 0.9994290489899484, "train/reward_neg_acc": 0.9995114712338699, "train/reward_neg_loss": 0.050372038173832394, "train/reward_pos_acc": 0.6986279811121916, "train/reward_pos_loss": 0.8185861004026312, "train/reward_pred": 0.0006262098242969889, "train/reward_rate": 0.010896381578947368, "train_stats/sum_log_reward": -0.32857144056331544, "train_stats/max_log_achievement_collect_drink": 0.0, "train_stats/max_log_achievement_collect_sapling": 0.0, "train_stats/max_log_achievement_collect_wood": 0.047619047619047616, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 0.0, "train_stats/max_log_achievement_place_table": 0.0, "train_stats/max_log_achievement_wake_up": 1.5952380952380953, "train_stats/mean_log_entropy": 0.16222709399603663, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.00010002966155298054, "report/cont_loss_std": 0.0019610144663602114, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.014140279032289982, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 3.390786787349498e-06, "report/cont_pred": 0.9932554960250854, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 4.383090496063232, "report/dyn_loss_std": 6.454682350158691, "report/image_loss_mean": 6.02764892578125, "report/image_loss_std": 9.958044052124023, "report/model_loss_mean": 8.711798667907715, "report/model_loss_std": 12.198920249938965, "report/post_ent_mag": 39.2779655456543, "report/post_ent_max": 39.2779655456543, "report/post_ent_mean": 26.335742950439453, "report/post_ent_min": 12.336219787597656, "report/post_ent_std": 4.454584121704102, "report/prior_ent_mag": 62.64932632446289, "report/prior_ent_max": 62.64932632446289, "report/prior_ent_mean": 31.253856658935547, "report/prior_ent_min": 15.551152229309082, "report/prior_ent_std": 7.338001251220703, "report/rep_loss_mean": 4.383090496063232, "report/rep_loss_std": 6.454682350158691, "report/reward_avg": 0.0024012329522520304, "report/reward_loss_mean": 0.05419545620679855, "report/reward_loss_std": 0.11623063683509827, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0028259754180908, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.04738937318325043, "report/reward_pos_acc": 0.8181818723678589, "report/reward_pos_loss": 0.6809737682342529, "report/reward_pred": 0.00260740565136075, "report/reward_rate": 0.0107421875, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.0004837347660213709, "eval/cont_loss_std": 0.012007542885839939, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0006337192025966942, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.00048344125389121473, "eval/cont_pred": 0.9976303577423096, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 19.76607894897461, "eval/dyn_loss_std": 12.561979293823242, "eval/image_loss_mean": 59.075843811035156, "eval/image_loss_std": 80.61172485351562, "eval/model_loss_mean": 71.0439682006836, "eval/model_loss_std": 84.94203186035156, "eval/post_ent_mag": 42.84014129638672, "eval/post_ent_max": 42.84014129638672, "eval/post_ent_mean": 26.102035522460938, "eval/post_ent_min": 14.856842041015625, "eval/post_ent_std": 4.972870826721191, "eval/prior_ent_mag": 62.64932632446289, "eval/prior_ent_max": 62.64932632446289, "eval/prior_ent_mean": 32.46002960205078, "eval/prior_ent_min": 13.737371444702148, "eval/prior_ent_std": 8.450464248657227, "eval/rep_loss_mean": 19.76607894897461, "eval/rep_loss_std": 12.561979293823242, "eval/reward_avg": 0.010351561941206455, "eval/reward_loss_mean": 0.10798928141593933, "eval/reward_loss_std": 0.788203239440918, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0018105506896973, "eval/reward_neg_acc": 0.9950495362281799, "eval/reward_neg_loss": 0.06542374193668365, "eval/reward_pos_acc": 0.6428571939468384, "eval/reward_pos_loss": 3.178788423538208, "eval/reward_pred": 0.0066815586760640144, "eval/reward_rate": 0.013671875, "replay/size": 37993.0, "replay/inserts": 7616.0, "replay/samples": 30464.0, "replay/insert_wait_avg": 1.6666760965555655e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.900432879183473e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 7864.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 1.4454126358032227e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0196897983551, "timer/env.step_count": 952.0, "timer/env.step_total": 90.20048546791077, "timer/env.step_frac": 0.09019870947350934, "timer/env.step_avg": 0.09474840910494828, "timer/env.step_min": 0.022388935089111328, "timer/env.step_max": 3.3133816719055176, "timer/replay._sample_count": 30464.0, "timer/replay._sample_total": 15.697121143341064, "timer/replay._sample_frac": 0.015696812076276465, "timer/replay._sample_avg": 0.0005152678946737482, "timer/replay._sample_min": 0.0003552436828613281, "timer/replay._sample_max": 0.01051020622253418, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 952.0, "timer/agent.policy_total": 15.689253091812134, "timer/agent.policy_frac": 0.01568894417966483, "timer/agent.policy_avg": 0.01648030786955056, "timer/agent.policy_min": 0.01487421989440918, "timer/agent.policy_max": 0.05168008804321289, "timer/dataset_train_count": 1904.0, "timer/dataset_train_total": 0.31904149055480957, "timer/dataset_train_frac": 0.0003190352088158798, "timer/dataset_train_avg": 0.00016756380806450083, "timer/dataset_train_min": 9.942054748535156e-05, "timer/dataset_train_max": 0.004698038101196289, "timer/agent.train_count": 1904.0, "timer/agent.train_total": 859.5546033382416, "timer/agent.train_frac": 0.8595376792146592, "timer/agent.train_avg": 0.45144674545075714, "timer/agent.train_min": 0.43909525871276855, "timer/agent.train_max": 0.986628532409668, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48699522018432617, "timer/agent.report_frac": 0.0004869856315354394, "timer/agent.report_avg": 0.24349761009216309, "timer/agent.report_min": 0.23355793952941895, "timer/agent.report_max": 0.2534372806549072, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 4.076957702636719e-05, "timer/dataset_eval_frac": 4.076877429742209e-08, "timer/dataset_eval_avg": 4.076957702636719e-05, "timer/dataset_eval_min": 4.076957702636719e-05, "timer/dataset_eval_max": 4.076957702636719e-05, "fps": 7.61574305720704}
{"step": 38520, "time": 5339.393971920013, "episode/length": 216.0, "episode/score": 0.28485437992787865, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.18485437680794803}
{"step": 38864, "time": 5383.492975234985, "episode/length": 167.0, "episode/score": 0.22068409753092055, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.12068408928871577}
{"step": 39248, "time": 5432.229127883911, "episode/length": 90.0, "episode/score": 0.19466795289906713, "episode/reward_rate": 0.945054945054945, "episode/intrinsic_return": 0.09466794663592282}
{"step": 39272, "time": 5436.663198232651, "episode/length": 218.0, "episode/score": 0.2549464904142269, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.15494642536134506}
{"step": 39712, "time": 5492.201092720032, "episode/length": 213.0, "episode/score": 0.27887131233649143, "episode/reward_rate": 0.9813084112149533, "episode/intrinsic_return": 0.17887132339012624}
{"step": 39792, "time": 5503.405230522156, "episode/length": 163.0, "episode/score": 0.22015388991121654, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.12015383917741929}
{"step": 39952, "time": 5524.666505813599, "episode/length": 29.0, "episode/score": -0.8654166876804084, "episode/reward_rate": 0.8333333333333334, "episode/intrinsic_return": 0.034583332715556026}
{"step": 40040, "time": 5551.358811616898, "eval_episode/length": 38.0, "eval_episode/score": -0.8999999910593033, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 40040, "time": 5553.981424331665, "eval_episode/length": 61.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9193548387096774}
{"step": 40040, "time": 5555.967084407806, "eval_episode/length": 11.0, "eval_episode/score": -0.8999999761581421, "eval_episode/reward_rate": 0.9166666666666666}
{"step": 40040, "time": 5561.935759544373, "eval_episode/length": 102.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.941747572815534}
{"step": 40040, "time": 5561.944694042206, "eval_episode/length": 176.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9717514124293786}
{"step": 40040, "time": 5565.268054962158, "eval_episode/length": 182.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9726775956284153}
{"step": 40040, "time": 5567.086959838867, "eval_episode/length": 189.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 40040, "time": 5568.804533004761, "eval_episode/length": 194.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 40160, "time": 5583.533136129379, "episode/length": 230.0, "episode/score": 0.3118858698467193, "episode/reward_rate": 0.9826839826839827, "episode/intrinsic_return": 0.21188591928830647}
{"step": 40176, "time": 5586.936061382294, "episode/length": 163.0, "episode/score": 0.22558722591963942, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.12558723199651922}
{"step": 40184, "time": 5589.412179231644, "episode/length": 312.0, "episode/score": 0.3828594340525342, "episode/reward_rate": 0.9904153354632588, "episode/intrinsic_return": 0.2828594495008474}
{"step": 40336, "time": 5609.60391330719, "episode/length": 135.0, "episode/score": 0.2039911038984883, "episode/reward_rate": 0.9926470588235294, "episode/intrinsic_return": 0.10399103884560645}
{"step": 40344, "time": 5612.129626274109, "episode/length": 249.0, "episode/score": 0.3137222539672848, "episode/reward_rate": 0.984, "episode/intrinsic_return": 0.21372221440935846}
{"step": 40904, "time": 5682.216810703278, "episode/length": 138.0, "episode/score": 0.21254671935355418, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.11254665662897878}
{"step": 41072, "time": 5705.58816242218, "episode/length": 139.0, "episode/score": 0.17891438490664768, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.07891438079718682}
{"step": 41472, "time": 5755.860111951828, "episode/length": 163.0, "episode/score": 0.26852659570283777, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.16852658746063298}
{"step": 41528, "time": 5764.266503334045, "episode/length": 147.0, "episode/score": 0.2199414562894617, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.11994144688310371}
{"step": 41576, "time": 5771.620072126389, "episode/length": 173.0, "episode/score": 0.2235253983876646, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.12352539014545982}
{"step": 41600, "time": 5775.952006340027, "episode/length": 290.0, "episode/score": 0.35399129232246196, "episode/reward_rate": 0.9896907216494846, "episode/intrinsic_return": 0.2539912840802572}
{"step": 41656, "time": 5784.419895410538, "episode/length": 184.0, "episode/score": 0.2542755894012316, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.1542755448083426}
{"step": 41920, "time": 5818.046628713608, "episode/length": 197.0, "episode/score": 0.27093579777806553, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.1709357946581349}
{"step": 42024, "time": 5832.316339492798, "episode/length": 52.0, "episode/score": 0.16215064574498683, "episode/reward_rate": 0.9056603773584906, "episode/intrinsic_return": 0.06215063983108848}
{"step": 42456, "time": 5886.375354528427, "episode/length": 193.0, "episode/score": 0.25104362561444304, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.15104361737223826}
{"step": 42824, "time": 5932.7563371658325, "episode/length": 145.0, "episode/score": 0.24190357611951185, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.1419035253857146}
{"step": 42848, "time": 5937.185462713242, "episode/length": 171.0, "episode/score": 0.22474245532987425, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.12474239970663348}
{"step": 43040, "time": 5962.134280920029, "episode/length": 188.0, "episode/score": 0.24783182508281243, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.14783180062977408}
{"step": 43168, "time": 5979.315837860107, "episode/length": 261.0, "episode/score": 0.3755628787965861, "episode/reward_rate": 0.9847328244274809, "episode/intrinsic_return": 0.2755628693902281}
{"step": 43320, "time": 5999.312566518784, "episode/length": 217.0, "episode/score": 0.3133027995498878, "episode/reward_rate": 0.981651376146789, "episode/intrinsic_return": 0.21330279014352982}
{"step": 43448, "time": 6016.441734790802, "episode/length": 34.0, "episode/score": -0.8599999642465264, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.03999999933876097}
{"step": 43568, "time": 6032.467263221741, "episode/length": 205.0, "episode/score": 0.2818244749414589, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.18182445575621387}
{"step": 43736, "time": 6054.123813152313, "episode/length": 159.0, "episode/score": 0.24349829879793106, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.14349829055572627}
{"step": 44136, "time": 6104.35600399971, "episode/length": 163.0, "episode/score": 0.2547001826005726, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.15470016341532755}
{"step": 44160, "time": 6108.741544723511, "episode/length": 163.0, "episode/score": 0.2540892621855164, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.15408922379174328}
{"step": 44320, "time": 6129.613990306854, "episode/length": 93.0, "episode/score": 0.20073838436110236, "episode/reward_rate": 0.9468085106382979, "episode/intrinsic_return": 0.10073837611889758}
{"step": 44624, "time": 6168.040952682495, "episode/length": 162.0, "episode/score": 0.2660858761491909, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.16608585696394584}
{"step": 44704, "time": 6179.328638792038, "episode/length": 207.0, "episode/score": 0.29844237661473016, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.19844231156184833}
{"step": 44776, "time": 6189.533269643784, "episode/length": 165.0, "episode/score": 1.2354124983939982, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.1354124615136243}
{"step": 44800, "time": 6193.854289531708, "episode/length": 346.0, "episode/score": 1.443484165541122, "episode/reward_rate": 0.9971181556195965, "episode/intrinsic_return": 0.3434841309890544}
{"step": 45040, "time": 6224.554154396057, "episode/length": 162.0, "episode/score": 0.25117795069945714, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.15117794012894592}
{"step": 45640, "time": 6299.285249471664, "episode/length": 187.0, "episode/score": 1.2648441687815648, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.1648440750905138}
{"step": 45720, "time": 6310.555230855942, "episode/length": 194.0, "episode/score": 2.2800630447518415, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.18006306031657004}
{"step": 45917, "time": 6336.865509986877, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.416600381174395, "train/action_min": 0.0, "train/action_std": 2.332374007471146, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.027896174835541878, "train/actor_opt_grad_steps": 10165.0, "train/actor_opt_loss": 16.35507789132015, "train/adv_mag": 0.9050977454390577, "train/adv_max": 0.8615894968150765, "train/adv_mean": 0.004924280979070983, "train/adv_min": -0.6716263057083212, "train/adv_std": 0.07869458853477432, "train/cont_avg": 0.9943086357526881, "train/cont_loss_mean": 0.0002993177434941315, "train/cont_loss_std": 0.007261825331792173, "train/cont_neg_acc": 0.9916325326888792, "train/cont_neg_loss": 0.02569656909234973, "train/cont_pos_acc": 0.9999419210418579, "train/cont_pos_loss": 0.00015732417257216793, "train/cont_pred": 0.9942974384113025, "train/cont_rate": 0.9943086357526881, "train/dyn_loss_mean": 5.010471359375985, "train/dyn_loss_std": 7.184933562432566, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.959291999378512, "train/extr_critic_critic_opt_grad_steps": 10165.0, "train/extr_critic_critic_opt_loss": 12802.811612693213, "train/extr_critic_mag": 1.3249868846708728, "train/extr_critic_max": 1.3249868846708728, "train/extr_critic_mean": 0.1377736494090328, "train/extr_critic_min": -0.6270055181236678, "train/extr_critic_std": 0.5115481810544127, "train/extr_return_normed_mag": 1.751925899136451, "train/extr_return_normed_max": 1.751925899136451, "train/extr_return_normed_mean": 0.3785425664115978, "train/extr_return_normed_min": -0.4235385856641236, "train/extr_return_normed_std": 0.34923964538561403, "train/extr_return_rate": 0.28969885529048983, "train/extr_return_raw_mag": 2.277559140036183, "train/extr_return_raw_max": 2.2718395616418574, "train/extr_return_raw_mean": 0.145996163903688, "train/extr_return_raw_min": -1.0808777632892772, "train/extr_return_raw_std": 0.5383452386945806, "train/extr_reward_mag": 1.0049918633635326, "train/extr_reward_max": 1.0049918633635326, "train/extr_reward_mean": 0.0019342791859525209, "train/extr_reward_min": -0.5715572308468563, "train/extr_reward_std": 0.07367647054695314, "train/image_loss_mean": 6.298865427253067, "train/image_loss_std": 10.480524834766182, "train/model_loss_mean": 9.362621333009454, "train/model_loss_std": 13.34000160104485, "train/model_opt_grad_norm": 72.02294048186272, "train/model_opt_grad_steps": 10151.913978494624, "train/model_opt_loss": 6898.790008873068, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 735.8870967741935, "train/policy_entropy_mag": 1.7052018728948408, "train/policy_entropy_max": 1.7052018728948408, "train/policy_entropy_mean": 0.39267996946970624, "train/policy_entropy_min": 0.07986696765467685, "train/policy_entropy_std": 0.3248562844049546, "train/policy_logprob_mag": 7.437718878510178, "train/policy_logprob_max": -0.009523891012675019, "train/policy_logprob_mean": -0.39230994039004846, "train/policy_logprob_min": -7.437718878510178, "train/policy_logprob_std": 0.9816659906859039, "train/policy_randomness_mag": 0.6018614296310691, "train/policy_randomness_max": 0.6018614296310691, "train/policy_randomness_mean": 0.13859879608035727, "train/policy_randomness_min": 0.028189534671925087, "train/policy_randomness_std": 0.11466001214519624, "train/post_ent_mag": 39.676392052763255, "train/post_ent_max": 39.676392052763255, "train/post_ent_mean": 27.304328200637652, "train/post_ent_min": 13.223151899153187, "train/post_ent_std": 4.308753931394187, "train/prior_ent_mag": 63.03134916161978, "train/prior_ent_max": 63.03134916161978, "train/prior_ent_mean": 32.45517626116353, "train/prior_ent_min": 15.029040152026761, "train/prior_ent_std": 7.23049517344403, "train/rep_loss_mean": 5.010471359375985, "train/rep_loss_std": 7.184933562432566, "train/reward_avg": 0.0007336428770745394, "train/reward_loss_mean": 0.057173833591482974, "train/reward_loss_std": 0.15772151490372996, "train/reward_max_data": 1.00284133146527, "train/reward_max_pred": 1.000610629717509, "train/reward_neg_acc": 0.9996387772662665, "train/reward_neg_loss": 0.049535329493704025, "train/reward_pos_acc": 0.7337248427092388, "train/reward_pos_loss": 0.8171668703197151, "train/reward_pred": 0.0006260899313655432, "train/reward_rate": 0.009944136424731184, "train_stats/sum_log_reward": 0.17499999217689038, "train_stats/max_log_achievement_collect_drink": 0.125, "train_stats/max_log_achievement_collect_sapling": 0.0, "train_stats/max_log_achievement_collect_wood": 0.125, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 0.0, "train_stats/max_log_achievement_place_table": 0.0, "train_stats/max_log_achievement_wake_up": 3.225, "train_stats/mean_log_entropy": 0.36594257727265356, "eval_stats/sum_log_reward": -0.14999999199062586, "eval_stats/max_log_achievement_collect_drink": 0.0, "eval_stats/max_log_achievement_collect_sapling": 0.0, "eval_stats/max_log_achievement_collect_wood": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 0.0, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 1.875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9892578125, "report/cont_loss_mean": 0.00018210714915767312, "report/cont_loss_std": 0.00516599602997303, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.001434635603800416, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.00016850615793373436, "report/cont_pred": 0.9891191124916077, "report/cont_rate": 0.9892578125, "report/dyn_loss_mean": 6.021313190460205, "report/dyn_loss_std": 7.625411033630371, "report/image_loss_mean": 9.588083267211914, "report/image_loss_std": 20.26468849182129, "report/model_loss_mean": 13.261159896850586, "report/model_loss_std": 23.1694393157959, "report/post_ent_mag": 39.572731018066406, "report/post_ent_max": 39.572731018066406, "report/post_ent_mean": 26.75189971923828, "report/post_ent_min": 13.178878784179688, "report/post_ent_std": 4.753899097442627, "report/prior_ent_mag": 64.19377136230469, "report/prior_ent_max": 64.19377136230469, "report/prior_ent_mean": 32.98870849609375, "report/prior_ent_min": 16.819190979003906, "report/prior_ent_std": 8.66391658782959, "report/rep_loss_mean": 6.021313190460205, "report/rep_loss_std": 7.625411033630371, "report/reward_avg": -0.0017367457039654255, "report/reward_loss_mean": 0.06010720878839493, "report/reward_loss_std": 0.11851517856121063, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0010502338409424, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.05439773574471474, "report/reward_pos_acc": 0.625, "report/reward_pos_loss": 0.7852104902267456, "report/reward_pred": -0.0016868290258571506, "report/reward_rate": 0.0078125, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.00033457213430665433, "eval/cont_loss_std": 0.009728544391691685, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0007912613218650222, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0003332302439957857, "eval/cont_pred": 0.9967833161354065, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 25.58209800720215, "eval/dyn_loss_std": 11.653105735778809, "eval/image_loss_mean": 64.16777801513672, "eval/image_loss_std": 58.1161994934082, "eval/model_loss_mean": 79.66281127929688, "eval/model_loss_std": 62.23735046386719, "eval/post_ent_mag": 42.02946472167969, "eval/post_ent_max": 42.02946472167969, "eval/post_ent_mean": 28.247920989990234, "eval/post_ent_min": 12.782082557678223, "eval/post_ent_std": 5.261877059936523, "eval/prior_ent_mag": 64.19377136230469, "eval/prior_ent_max": 64.19377136230469, "eval/prior_ent_mean": 36.91803741455078, "eval/prior_ent_min": 16.771381378173828, "eval/prior_ent_std": 7.815787315368652, "eval/rep_loss_mean": 25.58209800720215, "eval/rep_loss_std": 11.653105735778809, "eval/reward_avg": 0.01230468787252903, "eval/reward_loss_mean": 0.1454389989376068, "eval/reward_loss_std": 1.0075793266296387, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0033259391784668, "eval/reward_neg_acc": 0.9990069270133972, "eval/reward_neg_loss": 0.05627082288265228, "eval/reward_pos_acc": 0.47058823704719543, "eval/reward_pos_loss": 5.427342414855957, "eval/reward_pred": 0.003039929084479809, "eval/reward_rate": 0.0166015625, "replay/size": 45413.0, "replay/inserts": 7420.0, "replay/samples": 29680.0, "replay/insert_wait_avg": 1.6568805972199556e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.039477700493085e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 9424.0, "eval_replay/inserts": 1560.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1986646896753557e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.748603820800781e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3011059761047, "timer/env.step_count": 927.0, "timer/env.step_total": 83.90196895599365, "timer/env.step_frac": 0.08387671317640022, "timer/env.step_avg": 0.09050913587485832, "timer/env.step_min": 0.022426605224609375, "timer/env.step_max": 2.0023412704467773, "timer/replay._sample_count": 29680.0, "timer/replay._sample_total": 15.365102291107178, "timer/replay._sample_frac": 0.01536047715963859, "timer/replay._sample_avg": 0.0005176921257111583, "timer/replay._sample_min": 0.0003559589385986328, "timer/replay._sample_max": 0.012147903442382812, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1122.0, "timer/agent.policy_total": 18.35424041748047, "timer/agent.policy_frac": 0.018348715509586687, "timer/agent.policy_avg": 0.01635850304588277, "timer/agent.policy_min": 0.009960412979125977, "timer/agent.policy_max": 0.05280017852783203, "timer/dataset_train_count": 1855.0, "timer/dataset_train_total": 0.34967684745788574, "timer/dataset_train_frac": 0.000349571589363252, "timer/dataset_train_avg": 0.00018850503906085484, "timer/dataset_train_min": 9.322166442871094e-05, "timer/dataset_train_max": 0.050357818603515625, "timer/agent.train_count": 1855.0, "timer/agent.train_total": 835.7151989936829, "timer/agent.train_frac": 0.8354636359000952, "timer/agent.train_avg": 0.45052032290764576, "timer/agent.train_min": 0.4313375949859619, "timer/agent.train_max": 1.0363006591796875, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4724266529083252, "timer/agent.report_frac": 0.00047228444523944227, "timer/agent.report_avg": 0.2362133264541626, "timer/agent.report_min": 0.2291419506072998, "timer/agent.report_max": 0.2432847023010254, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.956390380859375e-05, "timer/dataset_eval_frac": 2.955500462007884e-08, "timer/dataset_eval_avg": 2.956390380859375e-05, "timer/dataset_eval_min": 2.956390380859375e-05, "timer/dataset_eval_max": 2.956390380859375e-05, "fps": 7.417669991164679}
{"step": 45920, "time": 6336.8936150074005, "episode/length": 161.0, "episode/score": 1.239610474811343, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.13961042186565464}
{"step": 46048, "time": 6354.341007232666, "episode/length": 40.0, "episode/score": 0.14958334062248468, "episode/reward_rate": 0.8780487804878049, "episode/intrinsic_return": 0.0495833323802799}
{"step": 46056, "time": 6356.765304327011, "episode/length": 156.0, "episode/score": 1.2105963218637044, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.11059634383127559}
{"step": 46064, "time": 6359.383582830429, "episode/length": 169.0, "episode/score": 0.26378364615447936, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.1637836390764278}
{"step": 46256, "time": 6384.101898908615, "episode/length": 184.0, "episode/score": 1.269676300649735, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.16967621906587738}
{"step": 46344, "time": 6396.35990691185, "episode/length": 162.0, "episode/score": 4.233708826381189, "episode/reward_rate": 0.9877300613496932, "episode/intrinsic_return": 0.13370869147911435}
{"step": 46352, "time": 6398.830599069595, "episode/length": 35.0, "episode/score": 0.13962502477806993, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.03962499930639751}
{"step": 46648, "time": 6436.393714666367, "episode/length": 37.0, "episode/score": 0.1448958418914117, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.04489583248505369}
{"step": 46688, "time": 6442.8354597091675, "episode/length": 295.0, "episode/score": 1.3978709932225684, "episode/reward_rate": 0.9966216216216216, "episode/intrinsic_return": 0.2978709477274606}
{"step": 46952, "time": 6476.397896051407, "episode/length": 74.0, "episode/score": 1.1812112640318446, "episode/reward_rate": 0.9866666666666667, "episode/intrinsic_return": 0.08121120875784982}
{"step": 47400, "time": 6532.472482442856, "episode/length": 184.0, "episode/score": 2.263062948048173, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.1630628400380374}
{"step": 47552, "time": 6552.529834985733, "episode/length": 161.0, "episode/score": 3.2514867252821205, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.15148663112540817}
{"step": 47576, "time": 6557.027218103409, "episode/length": 189.0, "episode/score": 5.293776706284916, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.1937765003694949}
{"step": 47704, "time": 6574.335328102112, "episode/length": 37.0, "episode/score": 0.14625002455431968, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.046249999082647264}
{"step": 48008, "time": 6612.878916025162, "episode/length": 244.0, "episode/score": 2.307010971369891, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.20701084554821136}
{"step": 48040, "time": 6618.200432300568, "episode/length": 168.0, "episode/score": 3.2565763888678703, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.15657620774891257}
{"step": 48040, "time": 6618.210510730743, "episode/length": 299.0, "episode/score": 4.377396070844043, "episode/reward_rate": 0.9966666666666667, "episode/intrinsic_return": 0.27739590648889134}
{"step": 48384, "time": 6663.189804792404, "episode/length": 178.0, "episode/score": 2.279971656006637, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.1799715058541551}
{"step": 48408, "time": 6667.641477823257, "episode/length": 219.0, "episode/score": 3.3100838293021297, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.21008366459773242}
{"step": 48752, "time": 6710.827442407608, "episode/length": 92.0, "episode/score": 0.19126944743766217, "episode/reward_rate": 0.946236559139785, "episode/intrinsic_return": 0.09126944385207025}
{"step": 48840, "time": 6723.213616132736, "episode/length": 160.0, "episode/score": 3.267501101086964, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.16750098970078398}
{"step": 49008, "time": 6744.994113922119, "episode/length": 178.0, "episode/score": 1.287681173126657, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.18768112250927516}
{"step": 49032, "time": 6749.555270910263, "episode/length": 165.0, "episode/score": 1.2430444501815145, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.14304438767521788}
{"step": 49200, "time": 6772.669072151184, "episode/length": 144.0, "episode/score": 1.2589082547019643, "episode/reward_rate": 0.9586206896551724, "episode/intrinsic_return": 0.1589081934907881}
{"step": 49352, "time": 6792.605289936066, "episode/length": 120.0, "episode/score": 3.2221464637659665, "episode/reward_rate": 0.9586776859504132, "episode/intrinsic_return": 0.1221463835790928}
{"step": 49696, "time": 6836.321946144104, "episode/length": 160.0, "episode/score": 2.2642146457255876, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.16421453771545202}
{"step": 49968, "time": 6870.883283853531, "episode/length": 240.0, "episode/score": 3.363805629264789, "episode/reward_rate": 0.983402489626556, "episode/intrinsic_return": 0.2638055362722298}
{"step": 50024, "time": 6893.514348268509, "eval_episode/length": 42.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9767441860465116}
{"step": 50024, "time": 6899.308987379074, "eval_episode/length": 102.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9514563106796117}
{"step": 50024, "time": 6901.055989027023, "eval_episode/length": 151.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.993421052631579}
{"step": 50024, "time": 6902.897066831589, "eval_episode/length": 161.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9938271604938271}
{"step": 50024, "time": 6904.3930077552795, "eval_episode/length": 162.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9938650306748467}
{"step": 50024, "time": 6906.147098779678, "eval_episode/length": 167.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9761904761904762}
{"step": 50024, "time": 6907.821195840836, "eval_episode/length": 168.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9940828402366864}
{"step": 50024, "time": 6914.2890820503235, "eval_episode/length": 134.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9925925925925926}
{"step": 50128, "time": 6926.814822912216, "episode/length": 160.0, "episode/score": 2.2475993491107147, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.14759928359217156}
{"step": 50168, "time": 6933.145140647888, "episode/length": 120.0, "episode/score": 2.2353138353551003, "episode/reward_rate": 0.9586776859504132, "episode/intrinsic_return": 0.13531373968498883}
{"step": 50320, "time": 6952.871321439743, "episode/length": 160.0, "episode/score": 3.2366482404931958, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.13664814517233026}
{"step": 50392, "time": 6963.164797306061, "episode/length": 204.0, "episode/score": 3.264306456199847, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.16430633998243138}
{"step": 50664, "time": 6997.539033412933, "episode/length": 206.0, "episode/score": 4.2801041258644545, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.18010394625889603}
{"step": 50784, "time": 7013.702231884003, "episode/length": 178.0, "episode/score": 4.255340776092908, "episode/reward_rate": 0.9664804469273743, "episode/intrinsic_return": 0.15534070356034135}
{"step": 51320, "time": 7080.283851623535, "episode/length": 202.0, "episode/score": 4.249718952402873, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.14971887006231555}
{"step": 51344, "time": 7084.716812372208, "episode/length": 171.0, "episode/score": 2.228252102708211, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.12825207435525954}
{"step": 51432, "time": 7096.844489097595, "episode/length": 162.0, "episode/score": 3.2300300945680647, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.13003004202982993}
{"step": 51584, "time": 7116.92685508728, "episode/length": 176.0, "episode/score": 3.240282431750529, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.14028230124313268}
{"step": 51696, "time": 7131.95644569397, "episode/length": 171.0, "episode/score": 1.2653821833155234, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.165382158018474}
{"step": 51888, "time": 7156.796282291412, "episode/length": 37.0, "episode/score": -0.8559583545429632, "episode/reward_rate": 0.868421052631579, "episode/intrinsic_return": 0.04404166585300118}
{"step": 52264, "time": 7204.131069421768, "episode/length": 199.0, "episode/score": 3.2939544850505627, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.19395439089385036}
{"step": 52456, "time": 7228.932757854462, "episode/length": 257.0, "episode/score": 3.382106668661436, "episode/reward_rate": 0.9689922480620154, "episode/intrinsic_return": 0.28210654190843343}
{"step": 52456, "time": 7228.941869258881, "episode/length": 208.0, "episode/score": 3.2826458089930384, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.18264568672202586}
{"step": 52648, "time": 7255.144578695297, "episode/length": 162.0, "episode/score": 2.247927160753534, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.14792709407083748}
{"step": 52744, "time": 7268.411237716675, "episode/length": 163.0, "episode/score": 1.239636150714432, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.1396360895032558}
{"step": 52960, "time": 7296.241629600525, "episode/length": 204.0, "episode/score": 3.2760380331747, "episode/reward_rate": 0.9707317073170731, "episode/intrinsic_return": 0.1760379123588791}
{"step": 53232, "time": 7330.607140541077, "episode/length": 167.0, "episode/score": 1.205798520690223, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.10579846174914564}
{"step": 53265, "time": 7336.971519470215, "train_stats/sum_log_reward": 2.121739088355199, "train_stats/max_log_achievement_collect_drink": 9.58695652173913, "train_stats/max_log_achievement_collect_sapling": 1.3695652173913044, "train_stats/max_log_achievement_collect_wood": 0.8695652173913043, "train_stats/max_log_achievement_defeat_zombie": 0.06521739130434782, "train_stats/max_log_achievement_eat_cow": 0.10869565217391304, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 0.21739130434782608, "train_stats/max_log_achievement_place_table": 0.0, "train_stats/max_log_achievement_wake_up": 3.0, "train_stats/mean_log_entropy": 0.535894900560379, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.052306795380806, "train/action_min": 0.0, "train/action_std": 2.514260291401806, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04509695739449699, "train/actor_opt_grad_steps": 12010.0, "train/actor_opt_loss": 46.496466598956964, "train/adv_mag": 0.962232207665678, "train/adv_max": 0.9430136043843025, "train/adv_mean": 0.013930511285386766, "train/adv_min": -0.5682047473602607, "train/adv_std": 0.0881682634964341, "train/cont_avg": 0.9944074453551912, "train/cont_loss_mean": 0.00037368134230261795, "train/cont_loss_std": 0.010638349899009072, "train/cont_neg_acc": 0.9844891152095273, "train/cont_neg_loss": 0.054180658499952364, "train/cont_pos_acc": 0.9999784683920646, "train/cont_pos_loss": 0.00012171264091394395, "train/cont_pred": 0.994432184865566, "train/cont_rate": 0.9944074453551912, "train/dyn_loss_mean": 5.489424140075517, "train/dyn_loss_std": 7.570459707187173, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.5236486131376257, "train/extr_critic_critic_opt_grad_steps": 12010.0, "train/extr_critic_critic_opt_loss": 16187.121878201844, "train/extr_critic_mag": 3.4964258775033588, "train/extr_critic_max": 3.4964258775033588, "train/extr_critic_mean": 0.7767986654828155, "train/extr_critic_min": -0.650631113781955, "train/extr_critic_std": 1.0992690360611255, "train/extr_return_normed_mag": 1.886563416387214, "train/extr_return_normed_max": 1.886563416387214, "train/extr_return_normed_mean": 0.368600435025705, "train/extr_return_normed_min": -0.18494469733511815, "train/extr_return_normed_std": 0.35384102002844786, "train/extr_return_rate": 0.49309115787672864, "train/extr_return_raw_mag": 5.793275384955067, "train/extr_return_raw_max": 5.793275384955067, "train/extr_return_raw_mean": 0.820445565537351, "train/extr_return_raw_min": -1.020054563472831, "train/extr_return_raw_std": 1.1828294894734368, "train/extr_reward_mag": 1.0069237191820406, "train/extr_reward_max": 1.0069237191820406, "train/extr_reward_mean": 0.014332927504867376, "train/extr_reward_min": -0.5920885267153464, "train/extr_reward_std": 0.11424723112843727, "train/image_loss_mean": 6.620460885470031, "train/image_loss_std": 11.929820574046484, "train/model_loss_mean": 9.973188105828124, "train/model_loss_std": 15.056893270523823, "train/model_opt_grad_norm": 68.81408818562825, "train/model_opt_grad_steps": 11995.590163934427, "train/model_opt_loss": 8109.877769595287, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 809.4262295081967, "train/policy_entropy_mag": 2.156429026947647, "train/policy_entropy_max": 2.156429026947647, "train/policy_entropy_mean": 0.5664221914739557, "train/policy_entropy_min": 0.07943542073658906, "train/policy_entropy_std": 0.41631669310924135, "train/policy_logprob_mag": 7.437904592420234, "train/policy_logprob_max": -0.00946449471098152, "train/policy_logprob_mean": -0.565366548592927, "train/policy_logprob_min": -7.437904592420234, "train/policy_logprob_std": 1.0730776894287986, "train/policy_randomness_mag": 0.7611248125144041, "train/policy_randomness_max": 0.7611248125144041, "train/policy_randomness_mean": 0.19992217633242165, "train/policy_randomness_min": 0.02803721755254464, "train/policy_randomness_std": 0.14694152300149366, "train/post_ent_mag": 41.51674925173567, "train/post_ent_max": 41.51674925173567, "train/post_ent_mean": 27.86528710328816, "train/post_ent_min": 13.51582656401754, "train/post_ent_std": 4.571316174470661, "train/prior_ent_mag": 64.52432403147546, "train/prior_ent_max": 64.52432403147546, "train/prior_ent_mean": 33.48198248649555, "train/prior_ent_min": 15.720836154750137, "train/prior_ent_std": 7.915764519425689, "train/rep_loss_mean": 5.489424140075517, "train/rep_loss_std": 7.570459707187173, "train/reward_avg": 0.0019928756689390707, "train/reward_loss_mean": 0.05869904612420035, "train/reward_loss_std": 0.17267410241352404, "train/reward_max_data": 1.00562161435195, "train/reward_max_pred": 1.0046058893203735, "train/reward_neg_acc": 0.9991080181194785, "train/reward_neg_loss": 0.0489944729526512, "train/reward_pos_acc": 0.7241327440966674, "train/reward_pos_loss": 0.8990877427038599, "train/reward_pred": 0.0017615878226774964, "train/reward_rate": 0.011243809767759563, "eval_stats/sum_log_reward": 1.3499999400228262, "eval_stats/max_log_achievement_collect_drink": 9.125, "eval_stats/max_log_achievement_collect_sapling": 0.25, "eval_stats/max_log_achievement_collect_wood": 1.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 0.0, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 2.5, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 7.492624717997387e-06, "report/cont_loss_std": 0.00011153361992910504, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0015175758162513375, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 8.299253551058428e-08, "report/cont_pred": 0.9951245784759521, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 4.1645188331604, "report/dyn_loss_std": 7.044107913970947, "report/image_loss_mean": 3.6309280395507812, "report/image_loss_std": 4.8206467628479, "report/model_loss_mean": 6.177811622619629, "report/model_loss_std": 8.221944808959961, "report/post_ent_mag": 39.270572662353516, "report/post_ent_max": 39.270572662353516, "report/post_ent_mean": 27.885234832763672, "report/post_ent_min": 14.98988151550293, "report/post_ent_std": 3.978658676147461, "report/prior_ent_mag": 66.14570617675781, "report/prior_ent_max": 66.14570617675781, "report/prior_ent_mean": 32.229591369628906, "report/prior_ent_min": 17.58152961730957, "report/prior_ent_std": 7.5556182861328125, "report/rep_loss_mean": 4.1645188331604, "report/rep_loss_std": 7.044107913970947, "report/reward_avg": -0.0024638595059514046, "report/reward_loss_mean": 0.04816476255655289, "report/reward_loss_std": 0.10326503962278366, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 0.997123122215271, "report/reward_neg_acc": 0.9999999403953552, "report/reward_neg_loss": 0.043860919773578644, "report/reward_pos_acc": 0.2857142984867096, "report/reward_pos_loss": 0.6734510660171509, "report/reward_pred": -0.002501321490854025, "report/reward_rate": 0.0068359375, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 4.4494161556940526e-05, "eval/cont_loss_std": 0.0008209964144043624, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.008799271658062935, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.877003705885727e-05, "eval/cont_pred": 0.9970772862434387, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 22.822044372558594, "eval/dyn_loss_std": 12.611039161682129, "eval/image_loss_mean": 38.37257385253906, "eval/image_loss_std": 40.31087112426758, "eval/model_loss_mean": 52.23489761352539, "eval/model_loss_std": 45.21808624267578, "eval/post_ent_mag": 45.77307891845703, "eval/post_ent_max": 45.77307891845703, "eval/post_ent_mean": 26.458974838256836, "eval/post_ent_min": 14.65859603881836, "eval/post_ent_std": 5.165714263916016, "eval/prior_ent_mag": 66.14570617675781, "eval/prior_ent_max": 66.14570617675781, "eval/prior_ent_mean": 35.09710693359375, "eval/prior_ent_min": 14.34037971496582, "eval/prior_ent_std": 9.109037399291992, "eval/rep_loss_mean": 22.822044372558594, "eval/rep_loss_std": 12.611039161682129, "eval/reward_avg": 0.02089843899011612, "eval/reward_loss_mean": 0.169051393866539, "eval/reward_loss_std": 1.0494545698165894, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0030882358551025, "eval/reward_neg_acc": 0.9979979991912842, "eval/reward_neg_loss": 0.05582268163561821, "eval/reward_pos_acc": 0.4399999976158142, "eval/reward_pos_loss": 4.693670749664307, "eval/reward_pred": 0.008386616595089436, "eval/reward_rate": 0.0244140625, "replay/size": 52761.0, "replay/inserts": 7348.0, "replay/samples": 29392.0, "replay/insert_wait_avg": 1.6547183855500114e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.64055620670059e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 11720.0, "eval_replay/inserts": 2296.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1694555913945108e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 6.854534149169922e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0873737335205, "timer/env.step_count": 919.0, "timer/env.step_total": 93.74231934547424, "timer/env.step_frac": 0.09373412944462638, "timer/env.step_avg": 0.10200470004948231, "timer/env.step_min": 0.022921323776245117, "timer/env.step_max": 3.2433245182037354, "timer/replay._sample_count": 29392.0, "timer/replay._sample_total": 14.604360580444336, "timer/replay._sample_frac": 0.014603084654417163, "timer/replay._sample_avg": 0.0004968821645496848, "timer/replay._sample_min": 0.000354766845703125, "timer/replay._sample_max": 0.011603116989135742, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1206.0, "timer/agent.policy_total": 18.96277642250061, "timer/agent.policy_frac": 0.01896111971867906, "timer/agent.policy_avg": 0.015723695209370323, "timer/agent.policy_min": 0.009354829788208008, "timer/agent.policy_max": 0.0543973445892334, "timer/dataset_train_count": 1837.0, "timer/dataset_train_total": 0.2934885025024414, "timer/dataset_train_frac": 0.0002934628615565776, "timer/dataset_train_avg": 0.00015976510751357725, "timer/dataset_train_min": 9.655952453613281e-05, "timer/dataset_train_max": 0.0005276203155517578, "timer/agent.train_count": 1837.0, "timer/agent.train_total": 823.5660870075226, "timer/agent.train_frac": 0.8234941352503935, "timer/agent.train_avg": 0.4483212231940787, "timer/agent.train_min": 0.43263912200927734, "timer/agent.train_max": 0.9796619415283203, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47159433364868164, "timer/agent.report_frac": 0.0004715531322909601, "timer/agent.report_avg": 0.23579716682434082, "timer/agent.report_min": 0.22858977317810059, "timer/agent.report_max": 0.24300456047058105, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 7.05718994140625e-05, "timer/dataset_eval_frac": 7.056573382243982e-08, "timer/dataset_eval_avg": 7.05718994140625e-05, "timer/dataset_eval_min": 7.05718994140625e-05, "timer/dataset_eval_max": 7.05718994140625e-05, "fps": 7.34725387335597}
{"step": 53600, "time": 7377.23996090889, "episode/length": 237.0, "episode/score": 3.3465819788134468, "episode/reward_rate": 0.9747899159663865, "episode/intrinsic_return": 0.24658193491904967}
{"step": 53720, "time": 7393.354059934616, "episode/length": 157.0, "episode/score": 4.22705368822335, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.12705355480557046}
{"step": 53808, "time": 7405.507068872452, "episode/length": 168.0, "episode/score": 2.250141412961966, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.1501412604811776}
{"step": 53880, "time": 7415.800254583359, "episode/length": 201.0, "episode/score": 1.2466773474325237, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.14667739474953123}
{"step": 53952, "time": 7426.106489658356, "episode/length": 162.0, "episode/score": 3.2524315223627127, "episode/reward_rate": 0.9877300613496932, "episode/intrinsic_return": 0.15243142587769398}
{"step": 54008, "time": 7434.314687252045, "episode/length": 157.0, "episode/score": 4.244044695839875, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.14404463189293892}
{"step": 54552, "time": 7501.73729133606, "episode/length": 164.0, "episode/score": 3.2597785988491523, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.1597784874629724}
{"step": 54656, "time": 7515.790434360504, "episode/length": 211.0, "episode/score": 2.3067535633317675, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.20675346335428912}
{"step": 54920, "time": 7549.19989824295, "episode/length": 164.0, "episode/score": 3.2493318164160883, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.1493317257227318}
{"step": 55088, "time": 7571.16136431694, "episode/length": 159.0, "episode/score": 4.286508225568468, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.18650816651097557}
{"step": 55176, "time": 7583.252868413925, "episode/length": 181.0, "episode/score": 3.322583412344102, "episode/reward_rate": 0.9560439560439561, "episode/intrinsic_return": 0.2225833286647685}
{"step": 55256, "time": 7594.469865560532, "episode/length": 162.0, "episode/score": 4.228463977379761, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.128463992653451}
{"step": 55336, "time": 7605.688472747803, "episode/length": 165.0, "episode/score": 4.266144857605468, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.16614464784834126}
{"step": 55520, "time": 7629.4789843559265, "episode/length": 204.0, "episode/score": 2.269511018506819, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.16951092283670732}
{"step": 55592, "time": 7639.595573186874, "episode/length": 41.0, "episode/score": -0.8475000215694308, "episode/reward_rate": 0.8809523809523809, "episode/intrinsic_return": 0.052499998826533556}
{"step": 55968, "time": 7686.732420921326, "episode/length": 163.0, "episode/score": 4.222448726472521, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.122448592821911}
{"step": 56240, "time": 7721.365395069122, "episode/length": 143.0, "episode/score": 3.239110038497529, "episode/reward_rate": 0.9652777777777778, "episode/intrinsic_return": 0.13910991384000226}
{"step": 56264, "time": 7725.715856075287, "episode/length": 213.0, "episode/score": 3.3343766496459466, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.23437652533766595}
{"step": 56376, "time": 7740.886252880096, "episode/length": 181.0, "episode/score": 4.287348711078721, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.1873485397386503}
{"step": 56544, "time": 7762.737151384354, "episode/length": 37.0, "episode/score": -0.8595754006819334, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.040424602484563366}
{"step": 56688, "time": 7781.6337876319885, "episode/length": 136.0, "episode/score": 2.24753680939466, "episode/reward_rate": 0.9635036496350365, "episode/intrinsic_return": 0.14753674620442325}
{"step": 56712, "time": 7786.050560712814, "episode/length": 191.0, "episode/score": 3.3097551819632827, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.20975503332419976}
{"step": 56792, "time": 7797.163766145706, "episode/length": 181.0, "episode/score": 3.294007670969677, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.1940075595834969}
{"step": 57232, "time": 7852.020812749863, "episode/length": 213.0, "episode/score": 5.345483236177188, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.2454830647207018}
{"step": 57552, "time": 7893.469685316086, "episode/length": 160.0, "episode/score": 3.2491138971258806, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.14911377165344675}
{"step": 57624, "time": 7903.671571969986, "episode/length": 206.0, "episode/score": 6.320646275378294, "episode/reward_rate": 0.9710144927536232, "episode/intrinsic_return": 0.22064603849639752}
{"step": 57792, "time": 7925.595180273056, "episode/length": 176.0, "episode/score": 2.2900960411902815, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.1900959776507989}
{"step": 57872, "time": 7936.65624666214, "episode/length": 30.0, "episode/score": 2.1358333993703127, "episode/reward_rate": 0.8709677419354839, "episode/intrinsic_return": 0.03583333268761635}
{"step": 58008, "time": 7955.162888050079, "episode/length": 182.0, "episode/score": 2.2914515803317954, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.19145145800257524}
{"step": 58232, "time": 7983.719007253647, "episode/length": 192.0, "episode/score": 4.285237630056599, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.18523743438572637}
{"step": 58656, "time": 8036.356092453003, "episode/length": 242.0, "episode/score": 3.3469431319158502, "episode/reward_rate": 0.9958847736625515, "episode/intrinsic_return": 0.24694299654811402}
{"step": 58720, "time": 8046.227919340134, "episode/length": 185.0, "episode/score": 4.2836820800312125, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.18368196072879073}
{"step": 58728, "time": 8048.700162410736, "episode/length": 146.0, "episode/score": 3.2503029285012417, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.15030284633530755}
{"step": 59048, "time": 8088.868010759354, "episode/length": 146.0, "episode/score": 2.2224660487313486, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.12246594072121297}
{"step": 59176, "time": 8105.825338125229, "episode/length": 172.0, "episode/score": 4.277201518787479, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.17720151694811648}
{"step": 59232, "time": 8114.449388027191, "episode/length": 152.0, "episode/score": 3.2815417809179053, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.18154166324529797}
{"step": 59336, "time": 8128.447874307632, "episode/length": 137.0, "episode/score": 4.25822063860187, "episode/reward_rate": 0.9927536231884058, "episode/intrinsic_return": 0.15822051464283504}
{"step": 59632, "time": 8165.791153430939, "episode/length": 36.0, "episode/score": 1.1407983307726681, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.04079823708161712}
{"step": 59808, "time": 8188.622030496597, "episode/length": 143.0, "episode/score": 2.2202356299249004, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.1202354774441119}
{"step": 59888, "time": 8199.836657524109, "episode/length": 144.0, "episode/score": 3.2667034581754706, "episode/reward_rate": 0.9586206896551724, "episode/intrinsic_return": 0.16670336983952438}
{"step": 60008, "time": 8229.522373437881, "eval_episode/length": 28.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.8275862068965517}
{"step": 60008, "time": 8236.830690145493, "eval_episode/length": 159.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.975}
{"step": 60008, "time": 8238.596226453781, "eval_episode/length": 164.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9939393939393939}
{"step": 60008, "time": 8240.800455093384, "eval_episode/length": 152.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9607843137254902}
{"step": 60008, "time": 8243.603340148926, "eval_episode/length": 210.0, "eval_episode/score": 3.0999999940395355, "eval_episode/reward_rate": 0.995260663507109}
{"step": 60008, "time": 8245.348880052567, "eval_episode/length": 217.0, "eval_episode/score": 3.0999999716877937, "eval_episode/reward_rate": 0.9954128440366973}
{"step": 60008, "time": 8248.112084627151, "eval_episode/length": 247.0, "eval_episode/score": 3.0999999716877937, "eval_episode/reward_rate": 0.9959677419354839}
{"step": 60008, "time": 8249.936740159988, "eval_episode/length": 251.0, "eval_episode/score": 3.100000001490116, "eval_episode/reward_rate": 0.9761904761904762}
{"step": 60056, "time": 8255.712187051773, "episode/length": 407.0, "episode/score": 4.447675385029015, "episode/reward_rate": 0.9901960784313726, "episode/intrinsic_return": 0.3476752830433725}
{"step": 60056, "time": 8255.721793413162, "episode/length": 166.0, "episode/score": 4.254366137677607, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.15436595807204867}
{"step": 60192, "time": 8275.420429229736, "episode/length": 37.0, "episode/score": 0.14362500741844997, "episode/reward_rate": 0.868421052631579, "episode/intrinsic_return": 0.04362499917624518}
{"step": 60256, "time": 8284.724704504013, "episode/length": 134.0, "episode/score": 4.237216812090537, "episode/reward_rate": 0.9703703703703703, "episode/intrinsic_return": 0.1372167553613508}
{"step": 60320, "time": 8293.90515780449, "episode/length": 158.0, "episode/score": 3.242895645443241, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.14289555128652864}
{"step": 60661, "time": 8337.397220611572, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.085073770059122, "train/action_min": 0.0, "train/action_std": 2.7398010988493224, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03882499759060305, "train/actor_opt_grad_steps": 13850.0, "train/actor_opt_loss": -0.5787876573768822, "train/adv_mag": 0.732710441222062, "train/adv_max": 0.7104533849535761, "train/adv_mean": 0.003506769897205379, "train/adv_min": -0.5015628162268045, "train/adv_std": 0.0654962863672424, "train/cont_avg": 0.9943148226351352, "train/cont_loss_mean": 0.0003278879089170791, "train/cont_loss_std": 0.00976688911728806, "train/cont_neg_acc": 0.9856306317690257, "train/cont_neg_loss": 0.047671256376829535, "train/cont_pos_acc": 0.9999627596623188, "train/cont_pos_loss": 7.987758996385131e-05, "train/cont_pred": 0.9943401491319811, "train/cont_rate": 0.9943148226351352, "train/dyn_loss_mean": 5.7530135154724125, "train/dyn_loss_std": 7.915158856881631, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.5106759300103059, "train/extr_critic_critic_opt_grad_steps": 13850.0, "train/extr_critic_critic_opt_loss": 15410.176858108109, "train/extr_critic_mag": 5.047708305152687, "train/extr_critic_max": 5.047708305152687, "train/extr_critic_mean": 1.0927462384507463, "train/extr_critic_min": -0.6454540336454236, "train/extr_critic_std": 1.3848233854448473, "train/extr_return_normed_mag": 1.6902086921640345, "train/extr_return_normed_max": 1.6902086921640345, "train/extr_return_normed_mean": 0.3504860529223004, "train/extr_return_normed_min": -0.14308696534182574, "train/extr_return_normed_std": 0.3343937818263028, "train/extr_return_rate": 0.5504751118453773, "train/extr_return_raw_mag": 6.840585324570939, "train/extr_return_raw_max": 6.840585324570939, "train/extr_return_raw_mean": 1.1077583783381695, "train/extr_return_raw_min": -1.0060643112337266, "train/extr_return_raw_std": 1.4324677209596377, "train/extr_reward_mag": 1.0085062735789532, "train/extr_reward_max": 1.0085062735789532, "train/extr_reward_mean": 0.013970613271954495, "train/extr_reward_min": -0.6119441470584354, "train/extr_reward_std": 0.11806055895380071, "train/image_loss_mean": 6.2615494740975866, "train/image_loss_std": 10.678354234953185, "train/model_loss_mean": 9.774871032302444, "train/model_loss_std": 14.096652296427134, "train/model_opt_grad_norm": 60.63678113273952, "train/model_opt_grad_steps": 13834.54054054054, "train/model_opt_loss": 10670.445315139357, "train/model_opt_model_opt_grad_overflow": 0.005405405405405406, "train/model_opt_model_opt_grad_scale": 1087.837837837838, "train/policy_entropy_mag": 2.193862875732216, "train/policy_entropy_max": 2.193862875732216, "train/policy_entropy_mean": 0.5817553293060612, "train/policy_entropy_min": 0.07939553796439558, "train/policy_entropy_std": 0.42444415140796354, "train/policy_logprob_mag": 7.4382065154410695, "train/policy_logprob_max": -0.009459072522617675, "train/policy_logprob_mean": -0.5819142554257367, "train/policy_logprob_min": -7.4382065154410695, "train/policy_logprob_std": 1.0681492038675258, "train/policy_randomness_mag": 0.7743373213587581, "train/policy_randomness_max": 0.7743373213587581, "train/policy_randomness_mean": 0.20533410189925014, "train/policy_randomness_min": 0.02802314070632329, "train/policy_randomness_std": 0.14981015751490723, "train/post_ent_mag": 43.364322105613915, "train/post_ent_max": 43.364322105613915, "train/post_ent_mean": 28.334507040075355, "train/post_ent_min": 14.369736078623179, "train/post_ent_std": 4.846386703285011, "train/prior_ent_mag": 66.03907932590793, "train/prior_ent_max": 66.03907932590793, "train/prior_ent_mean": 34.27635703215728, "train/prior_ent_min": 16.40388469180545, "train/prior_ent_std": 8.68720274744807, "train/rep_loss_mean": 5.7530135154724125, "train/rep_loss_std": 7.915158856881631, "train/reward_avg": 0.004346143151633441, "train/reward_loss_mean": 0.0611855643625195, "train/reward_loss_std": 0.17142545411715637, "train/reward_max_data": 1.0050338132961376, "train/reward_max_pred": 1.0053642788448849, "train/reward_neg_acc": 0.998965707340756, "train/reward_neg_loss": 0.04976821122942744, "train/reward_pos_acc": 0.7637385429562749, "train/reward_pos_loss": 0.8574011316170563, "train/reward_pred": 0.0041322922472514815, "train/reward_rate": 0.014036106418918918, "train_stats/sum_log_reward": 2.9888888130585354, "train_stats/max_log_achievement_collect_drink": 5.955555555555556, "train_stats/max_log_achievement_collect_sapling": 1.9333333333333333, "train_stats/max_log_achievement_collect_wood": 1.2444444444444445, "train_stats/max_log_achievement_defeat_skeleton": 0.022222222222222223, "train_stats/max_log_achievement_defeat_zombie": 0.06666666666666667, "train_stats/max_log_achievement_eat_cow": 0.08888888888888889, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.6666666666666667, "train_stats/max_log_achievement_place_table": 0.022222222222222223, "train_stats/max_log_achievement_wake_up": 2.8444444444444446, "train_stats/mean_log_entropy": 0.5384315676159329, "eval_stats/sum_log_reward": 3.0999999344348907, "eval_stats/max_log_achievement_collect_drink": 5.75, "eval_stats/max_log_achievement_collect_sapling": 2.625, "eval_stats/max_log_achievement_collect_wood": 0.625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.125, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 3.25, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 1.2588787967615644e-06, "report/cont_loss_std": 1.9214156054658815e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00022770320356357843, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 3.7086192605784163e-07, "report/cont_pred": 0.9960943460464478, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 5.6151909828186035, "report/dyn_loss_std": 7.440025806427002, "report/image_loss_mean": 6.453269958496094, "report/image_loss_std": 8.553940773010254, "report/model_loss_mean": 9.880395889282227, "report/model_loss_std": 11.912050247192383, "report/post_ent_mag": 41.9342041015625, "report/post_ent_max": 41.9342041015625, "report/post_ent_mean": 28.295576095581055, "report/post_ent_min": 13.214033126831055, "report/post_ent_std": 5.109725475311279, "report/prior_ent_mag": 65.49136352539062, "report/prior_ent_max": 65.49136352539062, "report/prior_ent_mean": 34.40691375732422, "report/prior_ent_min": 15.78325080871582, "report/prior_ent_std": 8.542245864868164, "report/rep_loss_mean": 5.6151909828186035, "report/rep_loss_std": 7.440025806427002, "report/reward_avg": 0.008103172294795513, "report/reward_loss_mean": 0.058009907603263855, "report/reward_loss_std": 0.17741256952285767, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0046567916870117, "report/reward_neg_acc": 0.9990089535713196, "report/reward_neg_loss": 0.04864323139190674, "report/reward_pos_acc": 0.8000000715255737, "report/reward_pos_loss": 0.6880751848220825, "report/reward_pred": 0.009043384343385696, "report/reward_rate": 0.0146484375, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.018920335918664932, "eval/cont_loss_std": 0.4281591773033142, "eval/cont_neg_acc": 0.5, "eval/cont_neg_loss": 4.843524932861328, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 3.214840944565367e-07, "eval/cont_pred": 0.9980531334877014, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 19.666648864746094, "eval/dyn_loss_std": 11.297404289245605, "eval/image_loss_mean": 28.811450958251953, "eval/image_loss_std": 38.84434509277344, "eval/model_loss_mean": 40.749610900878906, "eval/model_loss_std": 43.185577392578125, "eval/post_ent_mag": 46.95237731933594, "eval/post_ent_max": 46.95237731933594, "eval/post_ent_mean": 27.72565460205078, "eval/post_ent_min": 15.593877792358398, "eval/post_ent_std": 4.962803840637207, "eval/prior_ent_mag": 65.49136352539062, "eval/prior_ent_max": 65.49136352539062, "eval/prior_ent_mean": 34.23506164550781, "eval/prior_ent_min": 16.21283531188965, "eval/prior_ent_std": 8.705521583557129, "eval/rep_loss_mean": 19.666648864746094, "eval/rep_loss_std": 11.297404289245605, "eval/reward_avg": 0.007617187220603228, "eval/reward_loss_mean": 0.11924823373556137, "eval/reward_loss_std": 0.7923809289932251, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0029244422912598, "eval/reward_neg_acc": 0.9950593113899231, "eval/reward_neg_loss": 0.0619124211370945, "eval/reward_pos_acc": 0.5, "eval/reward_pos_loss": 4.954568862915039, "eval/reward_pred": 0.0024680953938513994, "eval/reward_rate": 0.01171875, "replay/size": 60157.0, "replay/inserts": 7396.0, "replay/samples": 29584.0, "replay/insert_wait_avg": 1.6564546629439954e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.715884126670428e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 13736.0, "eval_replay/inserts": 2016.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.154485202970959e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.599592208862305e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4147508144379, "timer/env.step_count": 924.0, "timer/env.step_total": 92.9786217212677, "timer/env.step_frac": 0.0929400747495714, "timer/env.step_avg": 0.10062621398405595, "timer/env.step_min": 0.023363351821899414, "timer/env.step_max": 3.315155506134033, "timer/replay._sample_count": 29584.0, "timer/replay._sample_total": 14.444166421890259, "timer/replay._sample_frac": 0.014438178175732874, "timer/replay._sample_avg": 0.0004882425102045112, "timer/replay._sample_min": 0.0003414154052734375, "timer/replay._sample_max": 0.02564096450805664, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1176.0, "timer/agent.policy_total": 18.836161375045776, "timer/agent.policy_frac": 0.01882835230059458, "timer/agent.policy_avg": 0.01601714402639947, "timer/agent.policy_min": 0.009175300598144531, "timer/agent.policy_max": 0.429396390914917, "timer/dataset_train_count": 1849.0, "timer/dataset_train_total": 0.29441094398498535, "timer/dataset_train_frac": 0.00029428888742924405, "timer/dataset_train_avg": 0.00015922711951594666, "timer/dataset_train_min": 9.322166442871094e-05, "timer/dataset_train_max": 0.0007321834564208984, "timer/agent.train_count": 1849.0, "timer/agent.train_total": 826.3766937255859, "timer/agent.train_frac": 0.8260340954117604, "timer/agent.train_avg": 0.4469316894135132, "timer/agent.train_min": 0.43607187271118164, "timer/agent.train_max": 0.9265568256378174, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.475848913192749, "timer/agent.report_frac": 0.00047565163628920937, "timer/agent.report_avg": 0.2379244565963745, "timer/agent.report_min": 0.2307751178741455, "timer/agent.report_max": 0.24507379531860352, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 5.53131103515625e-05, "timer/dataset_eval_frac": 5.5290178704914224e-08, "timer/dataset_eval_avg": 5.53131103515625e-05, "timer/dataset_eval_min": 5.53131103515625e-05, "timer/dataset_eval_max": 5.53131103515625e-05, "fps": 7.392830834648215}
{"step": 61184, "time": 8401.094106435776, "episode/length": 243.0, "episode/score": 5.370038415705494, "episode/reward_rate": 0.9795081967213115, "episode/intrinsic_return": 0.27003831337060547}
{"step": 61280, "time": 8414.281400442123, "episode/length": 183.0, "episode/score": 3.295777079866184, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.19577691303720712}
{"step": 61408, "time": 8431.475804567337, "episode/length": 168.0, "episode/score": 4.273116053794638, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.17311595480668984}
{"step": 61616, "time": 8458.212456464767, "episode/length": 177.0, "episode/score": 4.243145955632599, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.14314582518341012}
{"step": 61664, "time": 8465.77337551117, "episode/length": 200.0, "episode/score": 3.3055889115873924, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.20558878727911178}
{"step": 61768, "time": 8479.9563934803, "episode/length": 180.0, "episode/score": 4.273521713870423, "episode/reward_rate": 0.9613259668508287, "episode/intrinsic_return": 0.1735217287366595}
{"step": 62288, "time": 8545.03051996231, "episode/length": 253.0, "episode/score": 4.367212193069236, "episode/reward_rate": 0.9803149606299213, "episode/intrinsic_return": 0.26721201229952385}
{"step": 62656, "time": 8591.514179229736, "episode/length": 183.0, "episode/score": 3.293037830828098, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.19303773434307914}
{"step": 62832, "time": 8614.522817373276, "episode/length": 193.0, "episode/score": 3.320703071389744, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.22070297327491062}
{"step": 63000, "time": 8636.624494075775, "episode/length": 42.0, "episode/score": 1.1461489025095943, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.04614880881854333}
{"step": 63048, "time": 8644.099934101105, "episode/length": 426.0, "episode/score": 4.537707098916144, "episode/reward_rate": 0.7892271662763466, "episode/intrinsic_return": 0.4377069183647109}
{"step": 63232, "time": 8668.179164886475, "episode/length": 182.0, "episode/score": 2.2768036995548755, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.17680363287217915}
{"step": 63408, "time": 8691.280725717545, "episode/length": 223.0, "episode/score": 4.301051755766821, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.20105161574247177}
{"step": 63440, "time": 8696.801196098328, "episode/length": 221.0, "episode/score": 4.353797342715552, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.25379722224897705}
{"step": 63512, "time": 8707.109469890594, "episode/length": 34.0, "episode/score": 1.1429167198948562, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.04291666578501463}
{"step": 63624, "time": 8722.36092877388, "episode/length": 276.0, "episode/score": 4.402108732857641, "episode/reward_rate": 0.9963898916967509, "episode/intrinsic_return": 0.30210865168123746}
{"step": 63904, "time": 8758.198594808578, "episode/length": 201.0, "episode/score": 4.3046062522771535, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.20460607616405468}
{"step": 64008, "time": 8772.559463500977, "episode/length": 119.0, "episode/score": 3.243208435655106, "episode/reward_rate": 0.9583333333333334, "episode/intrinsic_return": 0.14320833049714565}
{"step": 64248, "time": 8803.437564373016, "episode/length": 77.0, "episode/score": 3.1794183851779962, "episode/reward_rate": 0.9358974358974359, "episode/intrinsic_return": 0.07941826616661274}
{"step": 64280, "time": 8808.818792104721, "episode/length": 159.0, "episode/score": 3.2673567331949016, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.16735655440425035}
{"step": 64296, "time": 8812.248371839523, "episode/length": 182.0, "episode/score": 3.2864490807332913, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.18644893209420843}
{"step": 64664, "time": 8858.581505537033, "episode/length": 152.0, "episode/score": 3.2514147952460917, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.1514146697736578}
{"step": 64752, "time": 8870.81691980362, "episode/length": 167.0, "episode/score": 4.293294759845594, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.19329463937901892}
{"step": 65264, "time": 8934.891237974167, "episode/length": 218.0, "episode/score": 4.329941512132791, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.2299413421897043}
{"step": 65456, "time": 8959.904156684875, "episode/length": 180.0, "episode/score": 4.303335906337452, "episode/reward_rate": 0.9668508287292817, "episode/intrinsic_return": 0.20333577353085275}
{"step": 65536, "time": 8972.027045488358, "episode/length": 160.0, "episode/score": 4.254001280287412, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.15400112734096183}
{"step": 65576, "time": 8979.097868680954, "episode/length": 38.0, "episode/score": 1.1419766097824322, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.04197658099292312}
{"step": 65584, "time": 8981.647783041, "episode/length": 162.0, "episode/score": 4.2455394531298225, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.14553940839141433}
{"step": 65664, "time": 8992.839081048965, "episode/length": 170.0, "episode/score": 3.297072780165763, "episode/reward_rate": 0.9649122807017544, "episode/intrinsic_return": 0.1970726683139219}
{"step": 65720, "time": 9001.238914728165, "episode/length": 226.0, "episode/score": 4.332535326771904, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.23253517813282087}
{"step": 66072, "time": 9045.594867944717, "episode/length": 164.0, "episode/score": 4.246674246320254, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.146674131616237}
{"step": 66160, "time": 9057.744904279709, "episode/length": 186.0, "episode/score": 3.2779153980718547, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.17791526142354996}
{"step": 66368, "time": 9084.52942276001, "episode/length": 36.0, "episode/score": 2.1447500904032495, "episode/reward_rate": 0.9459459459459459, "episode/intrinsic_return": 0.04474999904050492}
{"step": 66768, "time": 9134.568596601486, "episode/length": 163.0, "episode/score": 2.2459422059773715, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.14594211030726}
{"step": 66880, "time": 9149.68408370018, "episode/length": 167.0, "episode/score": 4.226050547894374, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.1260504443953323}
{"step": 66992, "time": 9164.823554992676, "episode/length": 165.0, "episode/score": 2.224414365220582, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.12441431931802072}
{"step": 66992, "time": 9164.83094239235, "episode/length": 158.0, "episode/score": 4.249091430345288, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.14909130987871322}
{"step": 67112, "time": 9182.704556941986, "episode/length": 190.0, "episode/score": 3.245519758372211, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.14551967853458336}
{"step": 67312, "time": 9208.603054523468, "episode/length": 143.0, "episode/score": 4.237459856413807, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.13745967680824833}
{"step": 67328, "time": 9212.046328306198, "episode/length": 218.0, "episode/score": 3.2822921536635477, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.182292029355267}
{"step": 68136, "time": 9311.92936205864, "episode/length": 220.0, "episode/score": 2.310468642401247, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.2104685666381556}
{"step": 68328, "time": 9336.720213651657, "episode/length": 180.0, "episode/score": 2.299342386148055, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.19934226614714134}
{"step": 68329, "time": 9339.359475851059, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.071420351664226, "train/action_min": 0.0, "train/action_std": 2.7303472893933454, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04126206297466221, "train/actor_opt_grad_steps": 15735.0, "train/actor_opt_loss": -5.236620771077772, "train/adv_mag": 0.7609208947978914, "train/adv_max": 0.7400428542556862, "train/adv_mean": 0.002514031064263141, "train/adv_min": -0.523080303799361, "train/adv_std": 0.06651833397336304, "train/cont_avg": 0.9943186442057291, "train/cont_loss_mean": 0.0001252310268637924, "train/cont_loss_std": 0.0034180798529755605, "train/cont_neg_acc": 0.9967053349440297, "train/cont_neg_loss": 0.00886120527841546, "train/cont_pos_acc": 0.9999846192076802, "train/cont_pos_loss": 6.915238586432022e-05, "train/cont_pred": 0.994302541638414, "train/cont_rate": 0.9943186442057291, "train/dyn_loss_mean": 5.988477552930514, "train/dyn_loss_std": 8.096290973325571, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.457550462645789, "train/extr_critic_critic_opt_grad_steps": 15735.0, "train/extr_critic_critic_opt_loss": 15224.672627766928, "train/extr_critic_mag": 5.744777835905552, "train/extr_critic_max": 5.744777835905552, "train/extr_critic_mean": 0.978675463081648, "train/extr_critic_min": -0.6738568736861149, "train/extr_critic_std": 1.3005336473385494, "train/extr_return_normed_mag": 1.8024112253139417, "train/extr_return_normed_max": 1.8024112253139417, "train/extr_return_normed_mean": 0.33729727667135495, "train/extr_return_normed_min": -0.15730247924026722, "train/extr_return_normed_std": 0.3293405775912106, "train/extr_return_rate": 0.5176361356861889, "train/extr_return_raw_mag": 6.955189538498719, "train/extr_return_raw_max": 6.955189538498719, "train/extr_return_raw_mean": 0.9889956197390953, "train/extr_return_raw_min": -1.0288502645368378, "train/extr_return_raw_std": 1.3432130391399066, "train/extr_reward_mag": 1.0100172944366932, "train/extr_reward_max": 1.0100172944366932, "train/extr_reward_mean": 0.01457889696393977, "train/extr_reward_min": -0.6220927697916826, "train/extr_reward_std": 0.12321854875578235, "train/image_loss_mean": 6.155901315311591, "train/image_loss_std": 10.545153565704823, "train/model_loss_mean": 9.811018156508604, "train/model_loss_std": 14.115302500625452, "train/model_opt_grad_norm": 57.408969700336456, "train/model_opt_grad_steps": 15717.526041666666, "train/model_opt_loss": 6990.561023712158, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 712.890625, "train/policy_entropy_mag": 2.2105931832144656, "train/policy_entropy_max": 2.2105931832144656, "train/policy_entropy_mean": 0.5498138897431394, "train/policy_entropy_min": 0.07937671224741887, "train/policy_entropy_std": 0.42260500726600486, "train/policy_logprob_mag": 7.438322941462199, "train/policy_logprob_max": -0.009456115323700942, "train/policy_logprob_mean": -0.5501112098184725, "train/policy_logprob_min": -7.438322941462199, "train/policy_logprob_std": 1.0558137226228912, "train/policy_randomness_mag": 0.780242383480072, "train/policy_randomness_max": 0.780242383480072, "train/policy_randomness_mean": 0.1940601758348445, "train/policy_randomness_min": 0.02801649611016425, "train/policy_randomness_std": 0.14916102153559527, "train/post_ent_mag": 43.91106182336807, "train/post_ent_max": 43.91106182336807, "train/post_ent_mean": 28.70431720217069, "train/post_ent_min": 14.897384410103163, "train/post_ent_std": 4.837624388436477, "train/prior_ent_mag": 66.96030032634735, "train/prior_ent_max": 66.96030032634735, "train/prior_ent_mean": 34.81443217396736, "train/prior_ent_min": 17.03538915514946, "train/prior_ent_std": 8.864965803921223, "train/rep_loss_mean": 5.988477552930514, "train/rep_loss_std": 8.096290973325571, "train/reward_avg": 0.005802324187698105, "train/reward_loss_mean": 0.061905106995254755, "train/reward_loss_std": 0.16774330233844617, "train/reward_max_data": 1.0059375297278166, "train/reward_max_pred": 1.005545375868678, "train/reward_neg_acc": 0.9988310588523746, "train/reward_neg_loss": 0.049482119599512465, "train/reward_pos_acc": 0.7721750414930284, "train/reward_pos_loss": 0.8416116467366616, "train/reward_pred": 0.005662711762245938, "train/reward_rate": 0.01593017578125, "train_stats/sum_log_reward": 3.3142856444631303, "train_stats/max_log_achievement_collect_drink": 4.5476190476190474, "train_stats/max_log_achievement_collect_sapling": 1.9523809523809523, "train_stats/max_log_achievement_collect_wood": 1.7142857142857142, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.07142857142857142, "train_stats/max_log_achievement_eat_cow": 0.07142857142857142, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.7619047619047619, "train_stats/max_log_achievement_place_table": 0.023809523809523808, "train_stats/max_log_achievement_wake_up": 2.9523809523809526, "train_stats/mean_log_entropy": 0.541605131257148, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 3.079527959926054e-05, "report/cont_loss_std": 0.000954608665779233, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 7.215757796075195e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 3.0551495001418516e-05, "report/cont_pred": 0.9941112399101257, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 6.436144828796387, "report/dyn_loss_std": 7.857521057128906, "report/image_loss_mean": 5.67697286605835, "report/image_loss_std": 7.4466753005981445, "report/model_loss_mean": 9.602874755859375, "report/model_loss_std": 11.03458023071289, "report/post_ent_mag": 46.36724853515625, "report/post_ent_max": 46.36724853515625, "report/post_ent_mean": 29.959726333618164, "report/post_ent_min": 16.37300682067871, "report/post_ent_std": 4.966183185577393, "report/prior_ent_mag": 67.11094665527344, "report/prior_ent_max": 67.11094665527344, "report/prior_ent_mean": 37.3519401550293, "report/prior_ent_min": 18.785991668701172, "report/prior_ent_std": 8.854804039001465, "report/rep_loss_mean": 6.436144828796387, "report/rep_loss_std": 7.857521057128906, "report/reward_avg": 0.0035336315631866455, "report/reward_loss_mean": 0.06418323516845703, "report/reward_loss_std": 0.11686630547046661, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0040743350982666, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.05541430413722992, "report/reward_pos_acc": 0.9285714626312256, "report/reward_pos_loss": 0.6967993974685669, "report/reward_pred": 0.00369845237582922, "report/reward_rate": 0.013671875, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 7.423864190059248e-06, "eval/cont_loss_std": 0.00013395104906521738, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.001120470929890871, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 8.636659458716167e-07, "eval/cont_pred": 0.994146466255188, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 20.570804595947266, "eval/dyn_loss_std": 12.23401927947998, "eval/image_loss_mean": 33.52770233154297, "eval/image_loss_std": 39.7030029296875, "eval/model_loss_mean": 46.034507751464844, "eval/model_loss_std": 44.43424606323242, "eval/post_ent_mag": 43.40619659423828, "eval/post_ent_max": 43.40619659423828, "eval/post_ent_mean": 29.993499755859375, "eval/post_ent_min": 16.25547981262207, "eval/post_ent_std": 5.354468822479248, "eval/prior_ent_mag": 67.11094665527344, "eval/prior_ent_max": 67.11094665527344, "eval/prior_ent_mean": 37.42174530029297, "eval/prior_ent_min": 16.078659057617188, "eval/prior_ent_std": 8.413056373596191, "eval/rep_loss_mean": 20.570804595947266, "eval/rep_loss_std": 12.23401927947998, "eval/reward_avg": 0.009082031436264515, "eval/reward_loss_mean": 0.16431847214698792, "eval/reward_loss_std": 1.0792759656906128, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9992104768753052, "eval/reward_neg_acc": 0.997029721736908, "eval/reward_neg_loss": 0.08202904462814331, "eval/reward_pos_acc": 0.4285714626312256, "eval/reward_pos_loss": 6.10091495513916, "eval/reward_pred": 0.0034445454366505146, "eval/reward_rate": 0.013671875, "replay/size": 67825.0, "replay/inserts": 7668.0, "replay/samples": 30672.0, "replay/insert_wait_avg": 1.6841654610870153e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.824081272648596e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 13736.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 9.08970832824707e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1001.9449722766876, "timer/env.step_count": 959.0, "timer/env.step_total": 90.30520510673523, "timer/env.step_frac": 0.0901299049403258, "timer/env.step_avg": 0.09416601158158001, "timer/env.step_min": 0.02329111099243164, "timer/env.step_max": 3.1668481826782227, "timer/replay._sample_count": 30672.0, "timer/replay._sample_total": 15.470044612884521, "timer/replay._sample_frac": 0.015440014213288014, "timer/replay._sample_avg": 0.0005043702599401578, "timer/replay._sample_min": 0.0003552436828613281, "timer/replay._sample_max": 0.03139996528625488, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 959.0, "timer/agent.policy_total": 15.585147142410278, "timer/agent.policy_frac": 0.015554893306162958, "timer/agent.policy_avg": 0.01625145687425472, "timer/agent.policy_min": 0.014823675155639648, "timer/agent.policy_max": 0.046849966049194336, "timer/dataset_train_count": 1917.0, "timer/dataset_train_total": 0.3234412670135498, "timer/dataset_train_frac": 0.00032281340389243585, "timer/dataset_train_avg": 0.00016872262233362013, "timer/dataset_train_min": 0.00010156631469726562, "timer/dataset_train_max": 0.008592367172241211, "timer/agent.train_count": 1917.0, "timer/agent.train_total": 861.7374610900879, "timer/agent.train_frac": 0.8600646591718398, "timer/agent.train_avg": 0.449523975529519, "timer/agent.train_min": 0.4395914077758789, "timer/agent.train_max": 0.9741604328155518, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48225903511047363, "timer/agent.report_frac": 0.00048132287546156534, "timer/agent.report_avg": 0.24112951755523682, "timer/agent.report_min": 0.2331397533416748, "timer/agent.report_max": 0.24911928176879883, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9802322387695312e-05, "timer/dataset_eval_frac": 2.9744470217737054e-08, "timer/dataset_eval_avg": 2.9802322387695312e-05, "timer/dataset_eval_min": 2.9802322387695312e-05, "timer/dataset_eval_max": 2.9802322387695312e-05, "fps": 7.653004959822963}
{"step": 68344, "time": 9341.081816911697, "episode/length": 168.0, "episode/score": 4.266074375735116, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.16607426725931873}
{"step": 68496, "time": 9361.256537675858, "episode/length": 172.0, "episode/score": 3.278093411079226, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.17809331692251362}
{"step": 68616, "time": 9377.401510715485, "episode/length": 33.0, "episode/score": -0.8587500200374052, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.04124999919440597}
{"step": 68664, "time": 9384.646172046661, "episode/length": 236.0, "episode/score": 5.329914770702089, "episode/reward_rate": 0.9662447257383966, "episode/intrinsic_return": 0.22991461717356287}
{"step": 68712, "time": 9392.111458301544, "episode/length": 174.0, "episode/score": 5.28556431878269, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.18556416967794576}
{"step": 68712, "time": 9392.119628190994, "episode/length": 214.0, "episode/score": 3.34577737226482, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.24577723119273287}
{"step": 69248, "time": 9460.657717943192, "episode/length": 239.0, "episode/score": 4.371951717876527, "episode/reward_rate": 0.9708333333333333, "episode/intrinsic_return": 0.27195160439487154}
{"step": 69864, "time": 9537.278480291367, "episode/length": 215.0, "episode/score": 4.328372008389579, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.2283718907169714}
{"step": 69888, "time": 9541.822036504745, "episode/length": 152.0, "episode/score": 3.2605847336490115, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.16058465381138376}
{"step": 69984, "time": 9555.01775598526, "episode/length": 158.0, "episode/score": 3.243330049815995, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.14332998429745203}
{"step": 70040, "time": 9563.41157245636, "episode/length": 165.0, "episode/score": 4.2839974599846755, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.18399728270742344}
{"step": 70048, "time": 9565.974820613861, "episode/length": 193.0, "episode/score": 2.307957506207458, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.20795741053734673}
{"step": 70096, "time": 9573.424664735794, "episode/length": 184.0, "episode/score": 4.290764662404399, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.19076453960951767}
{"step": 70096, "time": 9588.398196458817, "eval_episode/length": 50.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9215686274509803}
{"step": 70096, "time": 9591.330667257309, "eval_episode/length": 87.0, "eval_episode/score": 3.0999999940395355, "eval_episode/reward_rate": 0.9886363636363636}
{"step": 70096, "time": 9596.001183986664, "eval_episode/length": 161.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9691358024691358}
{"step": 70096, "time": 9597.882105112076, "eval_episode/length": 171.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9709302325581395}
{"step": 70096, "time": 9599.744926691055, "eval_episode/length": 175.0, "eval_episode/score": 5.099999971687794, "eval_episode/reward_rate": 0.9943181818181818}
{"step": 70096, "time": 9601.664647340775, "eval_episode/length": 13.0, "eval_episode/score": -0.8999999761581421, "eval_episode/reward_rate": 0.9285714285714286}
{"step": 70096, "time": 9603.547481298447, "eval_episode/length": 193.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.9845360824742269}
{"step": 70096, "time": 9603.555159807205, "eval_episode/length": 193.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9742268041237113}
{"step": 70280, "time": 9627.448267936707, "episode/length": 28.0, "episode/score": 0.13479167537298054, "episode/reward_rate": 0.8620689655172413, "episode/intrinsic_return": 0.03479166596662253}
{"step": 70632, "time": 9671.94250202179, "episode/length": 287.0, "episode/score": 4.4214004149107495, "episode/reward_rate": 0.9895833333333334, "episode/intrinsic_return": 0.32140029211586807}
{"step": 70736, "time": 9685.911487340927, "episode/length": 185.0, "episode/score": 3.2712929412227822, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.17129287436546292}
{"step": 71232, "time": 9748.022180557251, "episode/length": 170.0, "episode/score": 3.2572437759172317, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.15724365044479782}
{"step": 71328, "time": 9761.316535234451, "episode/length": 160.0, "episode/score": 4.256378406400472, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.15637829169645556}
{"step": 71328, "time": 9761.324384450912, "episode/length": 167.0, "episode/score": 3.289929673564984, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.18992959035131207}
{"step": 71400, "time": 9773.289870262146, "episode/length": 188.0, "episode/score": 4.287790246118675, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.18779015202017035}
{"step": 71424, "time": 9777.682663440704, "episode/length": 142.0, "episode/score": 3.227128370937862, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.12712822692628833}
{"step": 71552, "time": 9794.827633142471, "episode/length": 39.0, "episode/score": 1.1429004556057407, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.042900417561213544}
{"step": 71840, "time": 9831.444637060165, "episode/length": 217.0, "episode/score": 3.3068224952603487, "episode/reward_rate": 0.981651376146789, "episode/intrinsic_return": 0.20682246484102507}
{"step": 72112, "time": 9866.4144551754, "episode/length": 171.0, "episode/score": 3.26546230384065, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.1654622192008901}
{"step": 72272, "time": 9887.472168684006, "episode/length": 53.0, "episode/score": 2.154963992613375, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.05496385654714686}
{"step": 72360, "time": 9899.791831970215, "episode/length": 215.0, "episode/score": 4.3309692613138395, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.23096916279155266}
{"step": 72728, "time": 9946.018567085266, "episode/length": 165.0, "episode/score": 4.231729871266907, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.13172967908849387}
{"step": 72816, "time": 9958.186853647232, "episode/length": 173.0, "episode/score": 2.2644969650273197, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.1644968997416072}
{"step": 72920, "time": 9972.40565443039, "episode/length": 198.0, "episode/score": 4.307953406985689, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.2079532841908076}
{"step": 72944, "time": 9976.84177350998, "episode/length": 173.0, "episode/score": 3.2726885059582855, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.17268837361734768}
{"step": 73088, "time": 9995.81699347496, "episode/length": 219.0, "episode/score": 1.2984243819882977, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.1984242906255531}
{"step": 73352, "time": 10029.465361356735, "episode/length": 32.0, "episode/score": 0.13875000865664333, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.03874999925028533}
{"step": 73424, "time": 10039.667431592941, "episode/length": 163.0, "episode/score": 3.261714439984644, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.1617143805779051}
{"step": 73560, "time": 10058.025851726532, "episode/length": 160.0, "episode/score": 4.25587170021754, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.15587154968670802}
{"step": 73856, "time": 10097.001061201096, "episode/length": 186.0, "episode/score": 3.286140959945442, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.18614088624872238}
{"step": 74080, "time": 10125.935715436935, "episode/length": 141.0, "episode/score": 3.211016164859302, "episode/reward_rate": 0.971830985915493, "episode/intrinsic_return": 0.11101606799593355}
{"step": 74184, "time": 10140.23191523552, "episode/length": 170.0, "episode/score": 3.2824582257453585, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.18245817250863183}
{"step": 74296, "time": 10155.354699373245, "episode/length": 195.0, "episode/score": 4.27500700635801, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.17500689671805958}
{"step": 74360, "time": 10164.793424844742, "episode/length": 179.0, "episode/score": 3.28608661469616, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.18608649038787917}
{"step": 74968, "time": 10240.57129240036, "episode/length": 201.0, "episode/score": 4.2910175475713, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.19101737658047568}
{"step": 74984, "time": 10244.625174999237, "episode/length": 177.0, "episode/score": 3.255572620854764, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.15557252669805166}
{"step": 75008, "time": 10249.48551774025, "episode/length": 115.0, "episode/score": 3.2296660391371006, "episode/reward_rate": 0.9568965517241379, "episode/intrinsic_return": 0.1296659449803883}
{"step": 75216, "time": 10276.414422988892, "episode/length": 223.0, "episode/score": 3.336738958615115, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.2367388376828785}
{"step": 75232, "time": 10279.921335935593, "episode/length": 130.0, "episode/score": 4.217836475118929, "episode/reward_rate": 0.9923664122137404, "episode/intrinsic_return": 0.11783640372141235}
{"step": 75536, "time": 10318.745090961456, "episode/length": 39.0, "episode/score": 0.14333841782763557, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.04333835277475373}
{"step": 75680, "time": 10337.888071775436, "episode/length": 164.0, "episode/score": 4.254060932656557, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.15406072639189006}
{"step": 75681, "time": 10340.529539346695, "train_stats/sum_log_reward": 3.0999999422094096, "train_stats/max_log_achievement_collect_drink": 4.173913043478261, "train_stats/max_log_achievement_collect_sapling": 2.130434782608696, "train_stats/max_log_achievement_collect_wood": 1.6521739130434783, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.043478260869565216, "train_stats/max_log_achievement_eat_cow": 0.021739130434782608, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.6956521739130435, "train_stats/max_log_achievement_place_table": 0.021739130434782608, "train_stats/max_log_achievement_wake_up": 2.4347826086956523, "train_stats/mean_log_entropy": 0.46380962010311044, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 3.8247614321501358, "train/action_min": 0.0, "train/action_std": 2.5579396369664567, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0454691090600808, "train/actor_opt_grad_steps": 17615.0, "train/actor_opt_loss": -4.244409273661997, "train/adv_mag": 0.7725262400572714, "train/adv_max": 0.7490815168813519, "train/adv_mean": 0.0028488665410132735, "train/adv_min": -0.5470994080862274, "train/adv_std": 0.0695678504264873, "train/cont_avg": 0.9941618546195652, "train/cont_loss_mean": 0.00025928534674458996, "train/cont_loss_std": 0.006237281220938198, "train/cont_neg_acc": 0.9983178059691968, "train/cont_neg_loss": 0.005418857793927145, "train/cont_pos_acc": 0.9999306049683819, "train/cont_pos_loss": 0.00022537808323325916, "train/cont_pred": 0.9941058213944021, "train/cont_rate": 0.9941618546195652, "train/dyn_loss_mean": 6.127121663611868, "train/dyn_loss_std": 8.123026803783748, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.4780143447544263, "train/extr_critic_critic_opt_grad_steps": 17615.0, "train/extr_critic_critic_opt_loss": 15421.605903957201, "train/extr_critic_mag": 5.739728461141172, "train/extr_critic_max": 5.739728461141172, "train/extr_critic_mean": 0.9138592535062976, "train/extr_critic_min": -0.7009570650432421, "train/extr_critic_std": 1.2424357786126758, "train/extr_return_normed_mag": 1.8274822552566943, "train/extr_return_normed_max": 1.8274822552566943, "train/extr_return_normed_mean": 0.3439336100836163, "train/extr_return_normed_min": -0.1654809965428127, "train/extr_return_normed_std": 0.3334354661890994, "train/extr_return_rate": 0.5076487043305583, "train/extr_return_raw_mag": 6.631587562353714, "train/extr_return_raw_max": 6.631587562353714, "train/extr_return_raw_mean": 0.9248931399830009, "train/extr_return_raw_min": -1.033950519302617, "train/extr_return_raw_std": 1.2826939338575238, "train/extr_reward_mag": 1.0099636601365132, "train/extr_reward_max": 1.0099636601365132, "train/extr_reward_mean": 0.015568898669500966, "train/extr_reward_min": -0.6339922748182131, "train/extr_reward_std": 0.1288122761508693, "train/image_loss_mean": 5.81749497289243, "train/image_loss_std": 10.347675554130388, "train/model_loss_mean": 9.557450628798941, "train/model_loss_std": 13.93344173224076, "train/model_opt_grad_norm": 55.55770389930062, "train/model_opt_grad_steps": 17596.233695652172, "train/model_opt_loss": 8276.578719429348, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 879.7554347826087, "train/policy_entropy_mag": 2.1638699420120404, "train/policy_entropy_max": 2.1638699420120404, "train/policy_entropy_mean": 0.4648192265759344, "train/policy_entropy_min": 0.07937558570309826, "train/policy_entropy_std": 0.38198120940638625, "train/policy_logprob_mag": 7.438365710818249, "train/policy_logprob_max": -0.009455906287969454, "train/policy_logprob_mean": -0.46503543918547424, "train/policy_logprob_min": -7.438365710818249, "train/policy_logprob_std": 1.0042578315605288, "train/policy_randomness_mag": 0.763751129741254, "train/policy_randomness_max": 0.763751129741254, "train/policy_randomness_mean": 0.16406078960584558, "train/policy_randomness_min": 0.02801609846115436, "train/policy_randomness_std": 0.1348226035175764, "train/post_ent_mag": 44.66332665733669, "train/post_ent_max": 44.66332665733669, "train/post_ent_mean": 28.95654337302498, "train/post_ent_min": 15.457871908726899, "train/post_ent_std": 4.949806578781294, "train/prior_ent_mag": 67.76346331057341, "train/prior_ent_max": 67.76346331057341, "train/prior_ent_mean": 35.23514337125032, "train/prior_ent_min": 17.548396950182706, "train/prior_ent_std": 8.983145190321881, "train/rep_loss_mean": 6.127121663611868, "train/rep_loss_std": 8.123026803783748, "train/reward_avg": 0.007393615278883574, "train/reward_loss_mean": 0.0634234126292817, "train/reward_loss_std": 0.16296882781645525, "train/reward_max_data": 1.0050543773433436, "train/reward_max_pred": 1.0055998550808949, "train/reward_neg_acc": 0.9991347942015399, "train/reward_neg_loss": 0.05030309886712095, "train/reward_pos_acc": 0.8111488130753455, "train/reward_pos_loss": 0.7865737534087637, "train/reward_pred": 0.007259192050222065, "train/reward_rate": 0.017864724864130436, "eval_stats/sum_log_reward": 2.7249999940395355, "eval_stats/max_log_achievement_collect_drink": 6.25, "eval_stats/max_log_achievement_collect_sapling": 1.375, "eval_stats/max_log_achievement_collect_wood": 1.5, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.125, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 1.25, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 1.5, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9892578125, "report/cont_loss_mean": 5.9593230616883375e-06, "report/cont_loss_std": 9.253194730263203e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00039112530066631734, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.7768693396646995e-06, "report/cont_pred": 0.9892602562904358, "report/cont_rate": 0.9892578125, "report/dyn_loss_mean": 6.000668525695801, "report/dyn_loss_std": 8.052938461303711, "report/image_loss_mean": 3.574239730834961, "report/image_loss_std": 6.780213832855225, "report/model_loss_mean": 7.25023889541626, "report/model_loss_std": 10.535433769226074, "report/post_ent_mag": 43.03504943847656, "report/post_ent_max": 43.03504943847656, "report/post_ent_mean": 29.611391067504883, "report/post_ent_min": 16.33307647705078, "report/post_ent_std": 4.667840957641602, "report/prior_ent_mag": 67.5169677734375, "report/prior_ent_max": 67.5169677734375, "report/prior_ent_mean": 35.90479278564453, "report/prior_ent_min": 15.825149536132812, "report/prior_ent_std": 8.733353614807129, "report/rep_loss_mean": 6.000668525695801, "report/rep_loss_std": 8.052938461303711, "report/reward_avg": 0.002869347110390663, "report/reward_loss_mean": 0.07559201121330261, "report/reward_loss_std": 0.2329425811767578, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0005075931549072, "report/reward_neg_acc": 0.9980120062828064, "report/reward_neg_loss": 0.06181633472442627, "report/reward_pos_acc": 0.7777777910232544, "report/reward_pos_loss": 0.8454991579055786, "report/reward_pred": 0.0034252535551786423, "report/reward_rate": 0.017578125, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 6.4491896409890614e-06, "eval/cont_loss_std": 0.00010577509237919003, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.001304152305237949, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 1.3601577393274056e-06, "eval/cont_pred": 0.9960975050926208, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 21.314125061035156, "eval/dyn_loss_std": 11.42056941986084, "eval/image_loss_mean": 37.70705032348633, "eval/image_loss_std": 35.55025863647461, "eval/model_loss_mean": 50.595802307128906, "eval/model_loss_std": 39.63786315917969, "eval/post_ent_mag": 44.584434509277344, "eval/post_ent_max": 44.584434509277344, "eval/post_ent_mean": 31.23879623413086, "eval/post_ent_min": 19.665752410888672, "eval/post_ent_std": 5.21768045425415, "eval/prior_ent_mag": 67.5169677734375, "eval/prior_ent_max": 67.5169677734375, "eval/prior_ent_mean": 36.98875427246094, "eval/prior_ent_min": 21.08379554748535, "eval/prior_ent_std": 7.491493225097656, "eval/rep_loss_mean": 21.314125061035156, "eval/rep_loss_std": 11.42056941986084, "eval/reward_avg": 0.002636718563735485, "eval/reward_loss_mean": 0.1002710834145546, "eval/reward_loss_std": 0.7859240174293518, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9999216794967651, "eval/reward_neg_acc": 0.998031497001648, "eval/reward_neg_loss": 0.05510322377085686, "eval/reward_pos_acc": 0.375, "eval/reward_pos_loss": 5.8365888595581055, "eval/reward_pred": -0.0004737443523481488, "eval/reward_rate": 0.0078125, "replay/size": 75177.0, "replay/inserts": 7352.0, "replay/samples": 29408.0, "replay/insert_wait_avg": 1.6435056568100091e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.043059846132961e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 15288.0, "eval_replay/inserts": 1552.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.184565504801642e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.195638656616211e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1001.1560401916504, "timer/env.step_count": 919.0, "timer/env.step_total": 95.71287631988525, "timer/env.step_frac": 0.09560235615375504, "timer/env.step_avg": 0.10414894050041922, "timer/env.step_min": 0.022825241088867188, "timer/env.step_max": 3.2666590213775635, "timer/replay._sample_count": 29408.0, "timer/replay._sample_total": 14.902181386947632, "timer/replay._sample_frac": 0.01488497375903053, "timer/replay._sample_avg": 0.0005067390297520277, "timer/replay._sample_min": 0.00035858154296875, "timer/replay._sample_max": 0.025656700134277344, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1113.0, "timer/agent.policy_total": 18.006637573242188, "timer/agent.policy_frac": 0.017985845213294816, "timer/agent.policy_avg": 0.01617847041621041, "timer/agent.policy_min": 0.010286092758178711, "timer/agent.policy_max": 0.04550981521606445, "timer/dataset_train_count": 1838.0, "timer/dataset_train_total": 0.3141751289367676, "timer/dataset_train_frac": 0.0003138123492484002, "timer/dataset_train_avg": 0.0001709331495847484, "timer/dataset_train_min": 9.894371032714844e-05, "timer/dataset_train_max": 0.012269020080566406, "timer/agent.train_count": 1838.0, "timer/agent.train_total": 827.8416810035706, "timer/agent.train_frac": 0.8268857678220646, "timer/agent.train_avg": 0.4504035261172854, "timer/agent.train_min": 0.43841052055358887, "timer/agent.train_max": 0.9479753971099854, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4785473346710205, "timer/agent.report_frac": 0.00047799475352454813, "timer/agent.report_avg": 0.23927366733551025, "timer/agent.report_min": 0.2306685447692871, "timer/agent.report_max": 0.2478787899017334, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0040740966796875e-05, "timer/dataset_eval_frac": 3.000605276380913e-08, "timer/dataset_eval_avg": 3.0040740966796875e-05, "timer/dataset_eval_min": 3.0040740966796875e-05, "timer/dataset_eval_max": 3.0040740966796875e-05, "fps": 7.34341081223731}
{"step": 75848, "time": 10360.870080709457, "episode/length": 193.0, "episode/score": 4.282251686412565, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.18225160316978872}
{"step": 75928, "time": 10372.10593509674, "episode/length": 258.0, "episode/score": 5.372775938808445, "episode/reward_rate": 0.9845559845559846, "episode/intrinsic_return": 0.2727758696082674}
{"step": 76112, "time": 10396.019753932953, "episode/length": 142.0, "episode/score": 3.253126388671717, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.15312623770432765}
{"step": 76472, "time": 10441.5889377594, "episode/length": 154.0, "episode/score": 3.2447082026792486, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.14470808349324216}
{"step": 76496, "time": 10446.024588108063, "episode/length": 185.0, "episode/score": 2.278625175439629, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.17862507976951747}
{"step": 76680, "time": 10470.079916477203, "episode/length": 211.0, "episode/score": 5.32125701699897, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.22125681457600876}
{"step": 76992, "time": 10509.615128993988, "episode/length": 181.0, "episode/score": 4.290582818659914, "episode/reward_rate": 0.967032967032967, "episode/intrinsic_return": 0.19058270110372177}
{"step": 77256, "time": 10543.400127887726, "episode/length": 175.0, "episode/score": 3.2683462420186515, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.16834610187788712}
{"step": 77600, "time": 10587.045198917389, "episode/length": 185.0, "episode/score": 3.2847401235853795, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.18474011051193884}
{"step": 77648, "time": 10594.548884630203, "episode/length": 214.0, "episode/score": 3.300830314166433, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.20083022513199467}
{"step": 77656, "time": 10597.177073955536, "episode/length": 144.0, "episode/score": 4.236970008611934, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.13696986275226664}
{"step": 77848, "time": 10622.217209815979, "episode/length": 106.0, "episode/score": 3.226041756104678, "episode/reward_rate": 0.9532710280373832, "episode/intrinsic_return": 0.12604166427627206}
{"step": 77864, "time": 10625.772718906403, "episode/length": 272.0, "episode/score": 4.393847627871764, "episode/reward_rate": 0.9963369963369964, "episode/intrinsic_return": 0.2938474625852905}
{"step": 78176, "time": 10665.240213394165, "episode/length": 212.0, "episode/score": 3.3434277567112076, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.24342766255449533}
{"step": 78232, "time": 10673.549085855484, "episode/length": 193.0, "episode/score": 4.305650180668181, "episode/reward_rate": 0.9639175257731959, "episode/intrinsic_return": 0.2056500815056097}
{"step": 78312, "time": 10684.788438558578, "episode/length": 131.0, "episode/score": 3.204159485796481, "episode/reward_rate": 0.9924242424242424, "episode/intrinsic_return": 0.10415938055120932}
{"step": 78784, "time": 10743.669705152512, "episode/length": 147.0, "episode/score": 4.201057995741394, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.10105783659582812}
{"step": 78888, "time": 10757.796097755432, "episode/length": 154.0, "episode/score": 3.238701017967742, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.13870101031488957}
{"step": 79184, "time": 10795.50346660614, "episode/length": 36.0, "episode/score": 3.145416777115315, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.045416665729135275}
{"step": 79248, "time": 10805.09438943863, "episode/length": 172.0, "episode/score": 3.2757221582564853, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.17572196107221316}
{"step": 79456, "time": 10832.018653392792, "episode/length": 200.0, "episode/score": 4.31134803612963, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.2113478588523776}
{"step": 79512, "time": 10840.389089107513, "episode/length": 166.0, "episode/score": 2.2866704921252676, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.18667041403386975}
{"step": 79576, "time": 10849.690436124802, "episode/length": 239.0, "episode/score": 3.342039736438437, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.2420396411175716}
{"step": 79768, "time": 10874.572505235672, "episode/length": 181.0, "episode/score": 4.294997468452493, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.19499731317773694}
{"step": 79824, "time": 10882.782298088074, "episode/length": 198.0, "episode/score": 3.320343066305213, "episode/reward_rate": 0.9698492462311558, "episode/intrinsic_return": 0.22034299228835152}
{"step": 80080, "time": 10930.282060623169, "eval_episode/length": 41.0, "eval_episode/score": -0.8999999910593033, "eval_episode/reward_rate": 0.9761904761904762}
{"step": 80080, "time": 10936.983957529068, "eval_episode/length": 131.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9621212121212122}
{"step": 80080, "time": 10938.570861816406, "eval_episode/length": 133.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9925373134328358}
{"step": 80080, "time": 10941.245948553085, "eval_episode/length": 159.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.96875}
{"step": 80080, "time": 10943.765610218048, "eval_episode/length": 139.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9928571428571429}
{"step": 80080, "time": 10945.281472682953, "eval_episode/length": 50.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9803921568627451}
{"step": 80080, "time": 10947.107069253922, "eval_episode/length": 187.0, "eval_episode/score": 3.0999999716877937, "eval_episode/reward_rate": 0.9946808510638298}
{"step": 80080, "time": 10949.533027172089, "eval_episode/length": 205.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9951456310679612}
{"step": 80120, "time": 10954.376110076904, "episode/length": 36.0, "episode/score": -0.8565922263805987, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0434077372046886}
{"step": 80632, "time": 11018.265496492386, "episode/length": 230.0, "episode/score": 3.3397887220417033, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.23978859656926943}
{"step": 80720, "time": 11030.501468420029, "episode/length": 191.0, "episode/score": 4.296090661249764, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.19609054188913433}
{"step": 80960, "time": 11061.3110871315, "episode/length": 104.0, "episode/score": 3.200771146604893, "episode/reward_rate": 0.9523809523809523, "episode/intrinsic_return": 0.10077099156296754}
{"step": 81032, "time": 11071.769166231155, "episode/length": 196.0, "episode/score": 2.3380373745967518, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.23803730861254735}
{"step": 81040, "time": 11074.396762132645, "episode/length": 182.0, "episode/score": 3.3049359969281795, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.20493585294570948}
{"step": 81048, "time": 11076.85195016861, "episode/length": 191.0, "episode/score": 2.299678131681503, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.1996780863028107}
{"step": 81088, "time": 11083.183688640594, "episode/length": 229.0, "episode/score": 4.366095249162754, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.2660950943536591}
{"step": 81312, "time": 11112.063972473145, "episode/length": 33.0, "episode/score": 1.133232196647441, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.03323214253759943}
{"step": 81664, "time": 11156.240162849426, "episode/length": 236.0, "episode/score": 5.3284878617632785, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.22848774251906434}
{"step": 81744, "time": 11167.632463216782, "episode/length": 138.0, "episode/score": 3.2459089277981548, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.14590884173230734}
{"step": 81936, "time": 11193.724792957306, "episode/length": 151.0, "episode/score": 4.268968949916598, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.16896874877420487}
{"step": 82088, "time": 11213.713998794556, "episode/length": 96.0, "episode/score": 3.2200000857701525, "episode/reward_rate": 0.9381443298969072, "episode/intrinsic_return": 0.1199999974342063}
{"step": 82248, "time": 11234.55331659317, "episode/length": 160.0, "episode/score": 3.2621235785845784, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.16212351920694346}
{"step": 82464, "time": 11262.380237579346, "episode/length": 178.0, "episode/score": 4.296872844188329, "episode/reward_rate": 0.9664804469273743, "episode/intrinsic_return": 0.1968727933963237}
{"step": 82800, "time": 11304.82201385498, "episode/length": 68.0, "episode/score": 3.1763244448357, "episode/reward_rate": 0.9130434782608695, "episode/intrinsic_return": 0.07632432401987899}
{"step": 82864, "time": 11314.371839761734, "episode/length": 221.0, "episode/score": 3.329727033137715, "episode/reward_rate": 0.9819819819819819, "episode/intrinsic_return": 0.22972695213593397}
{"step": 82992, "time": 11331.426634311676, "episode/length": 165.0, "episode/score": 4.239523608640411, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.1395234456531398}
{"step": 83049, "time": 11340.84948849678, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 3.9936327726944634, "train/action_min": 0.0, "train/action_std": 2.546079598043276, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04419798466741391, "train/actor_opt_grad_steps": 19455.0, "train/actor_opt_loss": -1.8429788680261243, "train/adv_mag": 0.7557335810168929, "train/adv_max": 0.7386103980243206, "train/adv_mean": 0.003537778314004616, "train/adv_min": -0.5349157862365246, "train/adv_std": 0.06801483804441016, "train/cont_avg": 0.9943210767663043, "train/cont_loss_mean": 0.00025103522635576593, "train/cont_loss_std": 0.007611557377618075, "train/cont_neg_acc": 0.9938341103818106, "train/cont_neg_loss": 0.02445647896110645, "train/cont_pos_acc": 0.9999786223406377, "train/cont_pos_loss": 0.00011137380110140658, "train/cont_pred": 0.9943227631890256, "train/cont_rate": 0.9943210767663043, "train/dyn_loss_mean": 6.090913433095683, "train/dyn_loss_std": 8.200659127339073, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.3688780425683311, "train/extr_critic_critic_opt_grad_steps": 19455.0, "train/extr_critic_critic_opt_loss": 15008.170277471128, "train/extr_critic_mag": 5.531273564566737, "train/extr_critic_max": 5.531273564566737, "train/extr_critic_mean": 0.8988985618495423, "train/extr_critic_min": -0.6796765871669935, "train/extr_critic_std": 1.2163370549678802, "train/extr_return_normed_mag": 1.7898295314415642, "train/extr_return_normed_max": 1.7898295314415642, "train/extr_return_normed_mean": 0.3401826169017864, "train/extr_return_normed_min": -0.1758630144531312, "train/extr_return_normed_std": 0.3328791569270518, "train/extr_return_rate": 0.4921390514658845, "train/extr_return_raw_mag": 6.387269188528475, "train/extr_return_raw_max": 6.387269188528475, "train/extr_return_raw_mean": 0.912227204312449, "train/extr_return_raw_min": -1.0354521064006763, "train/extr_return_raw_std": 1.2570158090928327, "train/extr_reward_mag": 1.0113720680060594, "train/extr_reward_max": 1.0113720680060594, "train/extr_reward_mean": 0.015985673999555573, "train/extr_reward_min": -0.638272274447524, "train/extr_reward_std": 0.12898853737051072, "train/image_loss_mean": 5.380375630181769, "train/image_loss_std": 9.114482268043187, "train/model_loss_mean": 9.099708020687103, "train/model_loss_std": 12.809897321721781, "train/model_opt_grad_norm": 55.93768223472264, "train/model_opt_grad_steps": 19434.744565217392, "train/model_opt_loss": 8254.775468909222, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 910.3260869565217, "train/policy_entropy_mag": 2.1519408498121346, "train/policy_entropy_max": 2.1519408498121346, "train/policy_entropy_mean": 0.4404049225799415, "train/policy_entropy_min": 0.07937545280741609, "train/policy_entropy_std": 0.37842947843929997, "train/policy_logprob_mag": 7.4383766417918, "train/policy_logprob_max": -0.009455885110503954, "train/policy_logprob_mean": -0.4399416681541049, "train/policy_logprob_min": -7.4383766417918, "train/policy_logprob_std": 0.9901334808572478, "train/policy_randomness_mag": 0.75954068419726, "train/policy_randomness_max": 0.75954068419726, "train/policy_randomness_mean": 0.15544361021855604, "train/policy_randomness_min": 0.028016051571087344, "train/policy_randomness_std": 0.13356899785930695, "train/post_ent_mag": 45.54109861539758, "train/post_ent_max": 45.54109861539758, "train/post_ent_mean": 29.36434116570846, "train/post_ent_min": 15.483506047207376, "train/post_ent_std": 5.095716617677523, "train/prior_ent_mag": 68.5529721716176, "train/prior_ent_max": 68.5529721716176, "train/prior_ent_mean": 35.61136695613032, "train/prior_ent_min": 17.713745910188425, "train/prior_ent_std": 9.159185588359833, "train/rep_loss_mean": 6.090913433095683, "train/rep_loss_std": 8.200659127339073, "train/reward_avg": 0.008440944742608775, "train/reward_loss_mean": 0.06453334837747009, "train/reward_loss_std": 0.1764209169651503, "train/reward_max_data": 1.0072282909051231, "train/reward_max_pred": 1.0053611987310906, "train/reward_neg_acc": 0.999063332443652, "train/reward_neg_loss": 0.05043614837948395, "train/reward_pos_acc": 0.8098599256380744, "train/reward_pos_loss": 0.8095056657557902, "train/reward_pred": 0.008277057301830095, "train/reward_rate": 0.01877229110054348, "train_stats/sum_log_reward": 3.3093022690262903, "train_stats/max_log_achievement_collect_drink": 3.6511627906976742, "train_stats/max_log_achievement_collect_sapling": 2.86046511627907, "train_stats/max_log_achievement_collect_wood": 1.9069767441860466, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.11627906976744186, "train_stats/max_log_achievement_eat_cow": 0.06976744186046512, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 2.0232558139534884, "train_stats/max_log_achievement_place_table": 0.0, "train_stats/max_log_achievement_wake_up": 2.4186046511627906, "train_stats/mean_log_entropy": 0.43312860574833184, "eval_stats/sum_log_reward": 2.599999967031181, "eval_stats/max_log_achievement_collect_drink": 4.25, "eval_stats/max_log_achievement_collect_sapling": 2.0, "eval_stats/max_log_achievement_collect_wood": 1.0, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 1.125, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 1.75, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 5.213328222453129e-07, "report/cont_loss_std": 1.0576345630397554e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00014558274415321648, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 9.509947318520062e-08, "report/cont_pred": 0.9970706701278687, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 6.718283653259277, "report/dyn_loss_std": 8.106866836547852, "report/image_loss_mean": 5.560873985290527, "report/image_loss_std": 9.337907791137695, "report/model_loss_mean": 9.647174835205078, "report/model_loss_std": 13.282625198364258, "report/post_ent_mag": 47.5430793762207, "report/post_ent_max": 47.5430793762207, "report/post_ent_mean": 30.243572235107422, "report/post_ent_min": 17.9951171875, "report/post_ent_std": 5.533331871032715, "report/prior_ent_mag": 69.6181640625, "report/prior_ent_max": 69.6181640625, "report/prior_ent_mean": 37.24286651611328, "report/prior_ent_min": 17.506574630737305, "report/prior_ent_std": 9.852479934692383, "report/rep_loss_mean": 6.718283653259277, "report/rep_loss_std": 8.106866836547852, "report/reward_avg": 0.017475847154855728, "report/reward_loss_mean": 0.05533089488744736, "report/reward_loss_std": 0.13196536898612976, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.002586841583252, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0388297438621521, "report/reward_pos_acc": 0.9090909361839294, "report/reward_pos_loss": 0.8068832159042358, "report/reward_pred": 0.016064349561929703, "report/reward_rate": 0.021484375, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.0010782425524666905, "eval/cont_loss_std": 0.034471988677978516, "eval/cont_neg_acc": 0.800000011920929, "eval/cont_neg_loss": 0.2208034098148346, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.0125680205419485e-07, "eval/cont_pred": 0.9957701563835144, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 23.89957046508789, "eval/dyn_loss_std": 9.817649841308594, "eval/image_loss_mean": 53.88145065307617, "eval/image_loss_std": 47.25284194946289, "eval/model_loss_mean": 68.26194763183594, "eval/model_loss_std": 50.30281448364258, "eval/post_ent_mag": 44.98396301269531, "eval/post_ent_max": 44.98396301269531, "eval/post_ent_mean": 32.26470184326172, "eval/post_ent_min": 17.920555114746094, "eval/post_ent_std": 5.457388401031494, "eval/prior_ent_mag": 69.6181640625, "eval/prior_ent_max": 69.6181640625, "eval/prior_ent_mean": 40.316650390625, "eval/prior_ent_min": 18.074413299560547, "eval/prior_ent_std": 7.084560394287109, "eval/rep_loss_mean": 23.89957046508789, "eval/rep_loss_std": 9.817649841308594, "eval/reward_avg": -0.0012695312034338713, "eval/reward_loss_mean": 0.039676543325185776, "eval/reward_loss_std": 0.4167446494102478, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9991463422775269, "eval/reward_neg_acc": 0.9970616698265076, "eval/reward_neg_loss": 0.026810886338353157, "eval/reward_pos_acc": 0.6666666865348816, "eval/reward_pos_loss": 4.4182891845703125, "eval/reward_pred": -0.0015631039859727025, "eval/reward_rate": 0.0029296875, "replay/size": 82545.0, "replay/inserts": 7368.0, "replay/samples": 29472.0, "replay/insert_wait_avg": 1.6234014243955333e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.984983804559863e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 16936.0, "eval_replay/inserts": 1648.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2875760643227587e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.046627044677734e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3059818744659, "timer/env.step_count": 921.0, "timer/env.step_total": 89.36679148674011, "timer/env.step_frac": 0.08933945523276422, "timer/env.step_avg": 0.09703234689114018, "timer/env.step_min": 0.022986650466918945, "timer/env.step_max": 1.6976344585418701, "timer/replay._sample_count": 29472.0, "timer/replay._sample_total": 14.975986003875732, "timer/replay._sample_frac": 0.014971405025302701, "timer/replay._sample_avg": 0.0005081428475799312, "timer/replay._sample_min": 0.00033855438232421875, "timer/replay._sample_max": 0.011272907257080078, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1127.0, "timer/agent.policy_total": 19.524173259735107, "timer/agent.policy_frac": 0.019518201043993464, "timer/agent.policy_avg": 0.01732402241325209, "timer/agent.policy_min": 0.009925127029418945, "timer/agent.policy_max": 0.11977958679199219, "timer/dataset_train_count": 1842.0, "timer/dataset_train_total": 0.3029744625091553, "timer/dataset_train_frac": 0.00030288178617248065, "timer/dataset_train_avg": 0.0001644812500049703, "timer/dataset_train_min": 0.0001010894775390625, "timer/dataset_train_max": 0.0012209415435791016, "timer/agent.train_count": 1842.0, "timer/agent.train_total": 829.1227614879608, "timer/agent.train_frac": 0.8288691425540351, "timer/agent.train_avg": 0.45012093457544017, "timer/agent.train_min": 0.4396500587463379, "timer/agent.train_max": 1.001805067062378, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4767744541168213, "timer/agent.report_frac": 0.0004766286143999631, "timer/agent.report_avg": 0.23838722705841064, "timer/agent.report_min": 0.2315225601196289, "timer/agent.report_max": 0.24525189399719238, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8371810913085938e-05, "timer/dataset_eval_frac": 2.8363132308696396e-08, "timer/dataset_eval_avg": 2.8371810913085938e-05, "timer/dataset_eval_min": 2.8371810913085938e-05, "timer/dataset_eval_max": 2.8371810913085938e-05, "fps": 7.365646616423197}
{"step": 83256, "time": 11365.858732938766, "episode/length": 164.0, "episode/score": 4.245149803037748, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.1451496234321894}
{"step": 83576, "time": 11406.379609584808, "episode/length": 185.0, "episode/score": 4.2896340166144, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.18963389265536534}
{"step": 83584, "time": 11408.876731395721, "episode/length": 229.0, "episode/score": 4.338634656925933, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.2386345318027452}
{"step": 83616, "time": 11414.266455888748, "episode/length": 143.0, "episode/score": 3.2376085765490643, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.13760848442962015}
{"step": 83856, "time": 11445.148911476135, "episode/length": 350.0, "episode/score": 3.5144397985941396, "episode/reward_rate": 0.9886039886039886, "episode/intrinsic_return": 0.4144397125864998}
{"step": 84168, "time": 11484.680565595627, "episode/length": 162.0, "episode/score": 3.2219843013845093, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.12198419998094323}
{"step": 84336, "time": 11506.674974918365, "episode/length": 191.0, "episode/score": 3.312033124595473, "episode/reward_rate": 0.9635416666666666, "episode/intrinsic_return": 0.21203300727211172}
{"step": 84752, "time": 11559.078799724579, "episode/length": 219.0, "episode/score": 5.342079651007225, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.2420794995741744}
{"step": 84936, "time": 11583.162703990936, "episode/length": 164.0, "episode/score": 4.2144359018125215, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.11443577901764002}
{"step": 85032, "time": 11596.46148777008, "episode/length": 221.0, "episode/score": 4.309571874613539, "episode/reward_rate": 0.963963963963964, "episode/intrinsic_return": 0.20957176229603647}
{"step": 85080, "time": 11603.896225690842, "episode/length": 186.0, "episode/score": 3.2521523086375055, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.15215216724527636}
{"step": 85112, "time": 11609.410559892654, "episode/length": 191.0, "episode/score": 4.2799941418916205, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.17999402861369163}
{"step": 85176, "time": 11618.797264575958, "episode/length": 164.0, "episode/score": 5.261598812050124, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.16159861952246501}
{"step": 85432, "time": 11651.475606679916, "episode/length": 157.0, "episode/score": 4.237782084539958, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.1377820289749252}
{"step": 85864, "time": 11705.728073120117, "episode/length": 190.0, "episode/score": 4.253706168762619, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.15370610436457355}
{"step": 86144, "time": 11741.426918506622, "episode/length": 138.0, "episode/score": 4.2249892542463385, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.12498912050841682}
{"step": 86488, "time": 11784.807554006577, "episode/length": 175.0, "episode/score": 3.2818743096818253, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.18187427373277387}
{"step": 86520, "time": 11790.285290241241, "episode/length": 197.0, "episode/score": 3.2990892501629787, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.1990891548421132}
{"step": 86544, "time": 11794.706022977829, "episode/length": 223.0, "episode/score": 4.308366242486954, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.20836611852791975}
{"step": 86656, "time": 11809.733971595764, "episode/length": 192.0, "episode/score": 4.291523568917455, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.19152351102411558}
{"step": 86976, "time": 11850.243935585022, "episode/length": 192.0, "episode/score": 4.300196586635593, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.2001963627922123}
{"step": 86984, "time": 11852.731076955795, "episode/length": 225.0, "episode/score": 3.322454130879123, "episode/reward_rate": 0.9823008849557522, "episode/intrinsic_return": 0.2224539752551209}
{"step": 87312, "time": 11893.999005794525, "episode/length": 145.0, "episode/score": 3.215061553049509, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.1150614781886361}
{"step": 87488, "time": 11917.040439128876, "episode/length": 202.0, "episode/score": 4.304543437331176, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.2045433887510626}
{"step": 87712, "time": 11945.7660009861, "episode/length": 131.0, "episode/score": 3.2530597613231294, "episode/reward_rate": 0.946969696969697, "episode/intrinsic_return": 0.1530596738020904}
{"step": 87760, "time": 11953.0383040905, "episode/length": 154.0, "episode/score": 3.2641373896144614, "episode/reward_rate": 0.9612903225806452, "episode/intrinsic_return": 0.1641373155975998}
{"step": 87880, "time": 11969.385511398315, "episode/length": 166.0, "episode/score": 4.276850268281578, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.1768500910043258}
{"step": 88304, "time": 12022.176531553268, "episode/length": 164.0, "episode/score": 4.222522316026243, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.12252216971546659}
{"step": 88448, "time": 12041.140572786331, "episode/length": 183.0, "episode/score": 4.292050941303387, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.19205080127903784}
{"step": 88456, "time": 12043.567282915115, "episode/length": 142.0, "episode/score": 3.220563623738144, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.12056343112317336}
{"step": 88656, "time": 12069.44085097313, "episode/length": 145.0, "episode/score": 4.263019618380895, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.16301940862376796}
{"step": 88752, "time": 12082.41059923172, "episode/length": 282.0, "episode/score": 3.387281536339742, "episode/reward_rate": 0.9858657243816255, "episode/intrinsic_return": 0.2872814251863929}
{"step": 88912, "time": 12103.376945734024, "episode/length": 149.0, "episode/score": 1.2479054032323802, "episode/reward_rate": 0.9733333333333334, "episode/intrinsic_return": 0.14790536518785302}
{"step": 89368, "time": 12159.934698104858, "episode/length": 200.0, "episode/score": 3.277425090840552, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.17742490777891362}
{"step": 89888, "time": 12224.46415424347, "episode/length": 250.0, "episode/score": 5.390910890793748, "episode/reward_rate": 0.9920318725099602, "episode/intrinsic_return": 0.29091074052485055}
{"step": 89896, "time": 12226.959430932999, "episode/length": 154.0, "episode/score": 3.2224212540400003, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.12242114795071757}
{"step": 89896, "time": 12226.967337608337, "episode/length": 179.0, "episode/score": 4.282321833404012, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.18232167425844636}
{"step": 90064, "time": 12266.355365514755, "eval_episode/length": 78.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.9620253164556962}
{"step": 90064, "time": 12270.180972576141, "eval_episode/length": 132.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9548872180451128}
{"step": 90064, "time": 12272.020093679428, "eval_episode/length": 139.0, "eval_episode/score": 3.0999999716877937, "eval_episode/reward_rate": 0.9928571428571429}
{"step": 90064, "time": 12275.281590223312, "eval_episode/length": 180.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9723756906077348}
{"step": 90064, "time": 12277.342869758606, "eval_episode/length": 193.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9742268041237113}
{"step": 90064, "time": 12278.905257940292, "eval_episode/length": 195.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9744897959183674}
{"step": 90064, "time": 12281.638478040695, "eval_episode/length": 224.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9822222222222222}
{"step": 90064, "time": 12283.305138111115, "eval_episode/length": 34.0, "eval_episode/score": 0.09999997168779373, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 90248, "time": 12306.64747595787, "episode/length": 186.0, "episode/score": 4.275873092480651, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.17587295179419016}
{"step": 90312, "time": 12315.939985990524, "episode/length": 232.0, "episode/score": 4.352827940127781, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.25282782594763376}
{"step": 90368, "time": 12324.305078029633, "episode/length": 257.0, "episode/score": 3.36663326087978, "episode/reward_rate": 0.9806201550387597, "episode/intrinsic_return": 0.26663313147832923}
{"step": 90485, "time": 12340.906682729721, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 3.814562725764449, "train/action_min": 0.0, "train/action_std": 2.7181360157587195, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.044068623314140944, "train/actor_opt_grad_steps": 21305.0, "train/actor_opt_loss": -2.410583160897737, "train/adv_mag": 0.829993450192995, "train/adv_max": 0.7963942629034801, "train/adv_mean": 0.004208370403116581, "train/adv_min": -0.5754932429521314, "train/adv_std": 0.07114246996339932, "train/cont_avg": 0.9940041162634409, "train/cont_loss_mean": 0.0002705798654112739, "train/cont_loss_std": 0.00834742039792884, "train/cont_neg_acc": 0.9918202786676346, "train/cont_neg_loss": 0.03916649459882416, "train/cont_pos_acc": 0.9999894128050856, "train/cont_pos_loss": 2.9917613136246647e-05, "train/cont_pred": 0.9940356961501542, "train/cont_rate": 0.9940041162634409, "train/dyn_loss_mean": 6.309930514263851, "train/dyn_loss_std": 8.279239962177892, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.370997614757989, "train/extr_critic_critic_opt_grad_steps": 21305.0, "train/extr_critic_critic_opt_loss": 15330.903099798386, "train/extr_critic_mag": 6.42162154054129, "train/extr_critic_max": 6.42162154054129, "train/extr_critic_mean": 1.0105403152204329, "train/extr_critic_min": -0.6951733680181605, "train/extr_critic_std": 1.3692066842509854, "train/extr_return_normed_mag": 1.8913226954398616, "train/extr_return_normed_max": 1.8913226954398616, "train/extr_return_normed_mean": 0.3385112949757166, "train/extr_return_normed_min": -0.16558481258169938, "train/extr_return_normed_std": 0.3465552924461262, "train/extr_return_rate": 0.5062794271976717, "train/extr_return_raw_mag": 7.418599682469522, "train/extr_return_raw_max": 7.418599682469522, "train/extr_return_raw_mean": 1.0278216251122054, "train/extr_return_raw_min": -1.0462283309428924, "train/extr_return_raw_std": 1.426356610111011, "train/extr_reward_mag": 1.0098547845758417, "train/extr_reward_max": 1.0098547845758417, "train/extr_reward_mean": 0.017683438584959556, "train/extr_reward_min": -0.6407467325528463, "train/extr_reward_std": 0.13577888261086196, "train/image_loss_mean": 5.3380720153931644, "train/image_loss_std": 9.326984446535828, "train/model_loss_mean": 9.190561973920433, "train/model_loss_std": 13.04121506598688, "train/model_opt_grad_norm": 52.97191040490263, "train/model_opt_grad_steps": 21283.1935483871, "train/model_opt_loss": 9842.863139490928, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1071.9086021505377, "train/policy_entropy_mag": 2.228851547805212, "train/policy_entropy_max": 2.228851547805212, "train/policy_entropy_mean": 0.4824601767524596, "train/policy_entropy_min": 0.07937538731963403, "train/policy_entropy_std": 0.420569414573331, "train/policy_logprob_mag": 7.438377631607876, "train/policy_logprob_max": -0.009455854058145516, "train/policy_logprob_mean": -0.48228233636066475, "train/policy_logprob_min": -7.438377631607876, "train/policy_logprob_std": 1.0323450510860772, "train/policy_randomness_mag": 0.7866867864003746, "train/policy_randomness_max": 0.7866867864003746, "train/policy_randomness_mean": 0.17028727118046053, "train/policy_randomness_min": 0.02801602842506542, "train/policy_randomness_std": 0.1484425462061359, "train/post_ent_mag": 46.15183405722341, "train/post_ent_max": 46.15183405722341, "train/post_ent_mean": 29.763502387590307, "train/post_ent_min": 15.828046044995707, "train/post_ent_std": 5.082340604515486, "train/prior_ent_mag": 69.16380568473569, "train/prior_ent_max": 69.16380568473569, "train/prior_ent_mean": 36.12374537478211, "train/prior_ent_min": 18.1296999121225, "train/prior_ent_std": 9.089670914475636, "train/rep_loss_mean": 6.309930514263851, "train/rep_loss_std": 8.279239962177892, "train/reward_avg": 0.009534865482560089, "train/reward_loss_mean": 0.06626104695662376, "train/reward_loss_std": 0.17152719608237665, "train/reward_max_data": 1.005551104904503, "train/reward_max_pred": 1.0047171801649115, "train/reward_neg_acc": 0.9989156267976248, "train/reward_neg_loss": 0.05080996533875824, "train/reward_pos_acc": 0.8258483813654992, "train/reward_pos_loss": 0.7931121783230894, "train/reward_pred": 0.009352384627075685, "train/reward_rate": 0.02072307627688172, "train_stats/sum_log_reward": 3.699999898672104, "train_stats/max_log_achievement_collect_drink": 4.85, "train_stats/max_log_achievement_collect_sapling": 2.325, "train_stats/max_log_achievement_collect_wood": 2.275, "train_stats/max_log_achievement_defeat_skeleton": 0.025, "train_stats/max_log_achievement_defeat_zombie": 0.075, "train_stats/max_log_achievement_eat_cow": 0.125, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.85, "train_stats/max_log_achievement_place_table": 0.0, "train_stats/max_log_achievement_wake_up": 3.125, "train_stats/mean_log_entropy": 0.4735035732388496, "eval_stats/sum_log_reward": 2.850000001490116, "eval_stats/max_log_achievement_collect_drink": 14.375, "eval_stats/max_log_achievement_collect_sapling": 2.125, "eval_stats/max_log_achievement_collect_wood": 1.875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 1.625, "eval_stats/max_log_achievement_place_table": 0.125, "eval_stats/max_log_achievement_wake_up": 1.875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 2.9723138140980154e-05, "report/cont_loss_std": 0.0002077948156511411, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0005274893483147025, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.5803718017414212e-05, "report/cont_pred": 0.9921660423278809, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 7.349987983703613, "report/dyn_loss_std": 8.823078155517578, "report/image_loss_mean": 5.521540641784668, "report/image_loss_std": 11.58409309387207, "report/model_loss_mean": 10.006962776184082, "report/model_loss_std": 15.315149307250977, "report/post_ent_mag": 43.87456512451172, "report/post_ent_max": 43.87456512451172, "report/post_ent_mean": 30.240764617919922, "report/post_ent_min": 18.289012908935547, "report/post_ent_std": 4.791747093200684, "report/prior_ent_mag": 70.09722137451172, "report/prior_ent_max": 70.09722137451172, "report/prior_ent_mean": 37.36036682128906, "report/prior_ent_min": 22.521236419677734, "report/prior_ent_std": 9.005613327026367, "report/rep_loss_mean": 7.349987983703613, "report/rep_loss_std": 8.823078155517578, "report/reward_avg": 0.008341509848833084, "report/reward_loss_mean": 0.0753994733095169, "report/reward_loss_std": 0.18565979599952698, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0003581047058105, "report/reward_neg_acc": 0.9989949464797974, "report/reward_neg_loss": 0.05245549976825714, "report/reward_pos_acc": 0.6551724076271057, "report/reward_pos_loss": 0.8626151084899902, "report/reward_pred": 0.007722613867372274, "report/reward_rate": 0.0283203125, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.0016980011714622378, "eval/cont_loss_std": 0.05356797203421593, "eval/cont_neg_acc": 0.800000011920929, "eval/cont_neg_loss": 0.34325703978538513, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.2049236577004194e-05, "eval/cont_pred": 0.9958973526954651, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 24.343849182128906, "eval/dyn_loss_std": 13.55350399017334, "eval/image_loss_mean": 46.312923431396484, "eval/image_loss_std": 48.544254302978516, "eval/model_loss_mean": 61.00733947753906, "eval/model_loss_std": 53.94222640991211, "eval/post_ent_mag": 42.5920524597168, "eval/post_ent_max": 42.5920524597168, "eval/post_ent_mean": 30.06014633178711, "eval/post_ent_min": 15.321185111999512, "eval/post_ent_std": 5.09499454498291, "eval/prior_ent_mag": 70.09722137451172, "eval/prior_ent_max": 70.09722137451172, "eval/prior_ent_mean": 39.55377197265625, "eval/prior_ent_min": 15.781401634216309, "eval/prior_ent_std": 10.25346851348877, "eval/rep_loss_mean": 24.343849182128906, "eval/rep_loss_std": 13.55350399017334, "eval/reward_avg": 0.00498046912252903, "eval/reward_loss_mean": 0.08640685677528381, "eval/reward_loss_std": 0.8052964210510254, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0014936923980713, "eval/reward_neg_acc": 0.9980295896530151, "eval/reward_neg_loss": 0.06246080994606018, "eval/reward_pos_acc": 0.7777777910232544, "eval/reward_pos_loss": 2.7869887351989746, "eval/reward_pred": 0.004991048946976662, "eval/reward_rate": 0.0087890625, "replay/size": 89981.0, "replay/inserts": 7436.0, "replay/samples": 29744.0, "replay/insert_wait_avg": 1.641259903930861e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.728805075158606e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 18784.0, "eval_replay/inserts": 1848.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1671931196600845e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.238719940185547e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0447521209717, "timer/env.step_count": 929.0, "timer/env.step_total": 85.26632189750671, "timer/env.step_frac": 0.08526250621951403, "timer/env.step_avg": 0.09178290839344103, "timer/env.step_min": 0.02291417121887207, "timer/env.step_max": 3.3007240295410156, "timer/replay._sample_count": 29744.0, "timer/replay._sample_total": 14.957599639892578, "timer/replay._sample_frac": 0.014956930285539075, "timer/replay._sample_avg": 0.0005028778792325369, "timer/replay._sample_min": 0.00038933753967285156, "timer/replay._sample_max": 0.025869131088256836, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1160.0, "timer/agent.policy_total": 18.37253475189209, "timer/agent.policy_frac": 0.018371712578788307, "timer/agent.policy_avg": 0.01583839202749318, "timer/agent.policy_min": 0.009316444396972656, "timer/agent.policy_max": 0.05063891410827637, "timer/dataset_train_count": 1859.0, "timer/dataset_train_total": 0.33064913749694824, "timer/dataset_train_frac": 0.0003306343409089265, "timer/dataset_train_avg": 0.00017786397928829922, "timer/dataset_train_min": 9.679794311523438e-05, "timer/dataset_train_max": 0.02493453025817871, "timer/agent.train_count": 1859.0, "timer/agent.train_total": 834.1823554039001, "timer/agent.train_frac": 0.8341450256448045, "timer/agent.train_avg": 0.4487263880601937, "timer/agent.train_min": 0.43622612953186035, "timer/agent.train_max": 0.9262499809265137, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47918009757995605, "timer/agent.report_frac": 0.00047915865421389804, "timer/agent.report_avg": 0.23959004878997803, "timer/agent.report_min": 0.23167157173156738, "timer/agent.report_max": 0.24750852584838867, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9325485229492188e-05, "timer/dataset_eval_frac": 2.93241729105587e-08, "timer/dataset_eval_avg": 2.9325485229492188e-05, "timer/dataset_eval_min": 2.9325485229492188e-05, "timer/dataset_eval_max": 2.9325485229492188e-05, "fps": 7.435560234621724}
{"step": 90936, "time": 12395.706143140793, "episode/length": 252.0, "episode/score": 3.312713893604723, "episode/reward_rate": 0.9802371541501976, "episode/intrinsic_return": 0.2127137979928193}
{"step": 90968, "time": 12401.143902301788, "episode/length": 199.0, "episode/score": 3.314616840899589, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.21461681141158806}
{"step": 91248, "time": 12436.683590173721, "episode/length": 168.0, "episode/score": 4.272468308607358, "episode/reward_rate": 0.9881656804733728, "episode/intrinsic_return": 0.17246820408968233}
{"step": 91464, "time": 12464.490283727646, "episode/length": 195.0, "episode/score": 1.248083875762859, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.14808387211905938}
{"step": 91528, "time": 12474.207076787949, "episode/length": 151.0, "episode/score": 4.251597081700538, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.15159686225183577}
{"step": 91656, "time": 12491.251084566116, "episode/length": 175.0, "episode/score": 4.261053190911298, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.1610531426513262}
{"step": 91944, "time": 12527.588015317917, "episode/length": 256.0, "episode/score": 5.361490457497439, "episode/reward_rate": 0.980544747081712, "episode/intrinsic_return": 0.2614903083926947}
{"step": 92056, "time": 12542.675065040588, "episode/length": 139.0, "episode/score": 3.229964798291576, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.12996466164327103}
{"step": 92152, "time": 12555.737292766571, "episode/length": 222.0, "episode/score": 3.3162982105116043, "episode/reward_rate": 0.9730941704035875, "episode/intrinsic_return": 0.21629812217565814}
{"step": 92528, "time": 12602.895504713058, "episode/length": 159.0, "episode/score": 2.2285828553610827, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.12858286530877194}
{"step": 92616, "time": 12615.156934976578, "episode/length": 135.0, "episode/score": 3.25239849527361, "episode/reward_rate": 0.9632352941176471, "episode/intrinsic_return": 0.15239846601843965}
{"step": 92824, "time": 12642.277204036713, "episode/length": 169.0, "episode/score": 4.264101448598922, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.16410134168745572}
{"step": 93088, "time": 12675.737008571625, "episode/length": 142.0, "episode/score": 5.214543279536201, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.11454307129247354}
{"step": 93096, "time": 12678.325381040573, "episode/length": 265.0, "episode/score": 4.384575304755344, "episode/reward_rate": 0.981203007518797, "episode/intrinsic_return": 0.2845751842887694}
{"step": 93120, "time": 12682.910172224045, "episode/length": 182.0, "episode/score": 4.262479217542477, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.16247917248392696}
{"step": 93288, "time": 12705.483065843582, "episode/length": 141.0, "episode/score": 2.233675608871181, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.1336755008610453}
{"step": 93376, "time": 12717.768805503845, "episode/length": 164.0, "episode/score": 4.260903107960985, "episode/reward_rate": 0.9636363636363636, "episode/intrinsic_return": 0.1609030602103303}
{"step": 94024, "time": 12798.35048699379, "episode/length": 175.0, "episode/score": 2.2398983243990642, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.13989820206984405}
{"step": 94152, "time": 12816.110271692276, "episode/length": 165.0, "episode/score": 3.269500545800838, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.1695003948334488}
{"step": 94288, "time": 12834.249314785004, "episode/length": 219.0, "episode/score": 3.3133220845556934, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.21332191628607688}
{"step": 94368, "time": 12845.88038778305, "episode/length": 134.0, "episode/score": 3.217198419246415, "episode/reward_rate": 0.9925925925925926, "episode/intrinsic_return": 0.11719833061943064}
{"step": 94392, "time": 12850.392429590225, "episode/length": 162.0, "episode/score": 2.2567259495590406, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.15672587053632014}
{"step": 94592, "time": 12876.552084445953, "episode/length": 183.0, "episode/score": 1.216003975705462, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.1160039075093664}
{"step": 95216, "time": 12954.686645746231, "episode/length": 264.0, "episode/score": 4.373395641025127, "episode/reward_rate": 0.9962264150943396, "episode/intrinsic_return": 0.2733954637478746}
{"step": 95232, "time": 12958.119262933731, "episode/length": 231.0, "episode/score": 2.3602738996032713, "episode/reward_rate": 0.978448275862069, "episode/intrinsic_return": 0.26027383408472815}
{"step": 95512, "time": 12994.039138555527, "episode/length": 169.0, "episode/score": 3.255809583730297, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.15580948957358487}
{"step": 95592, "time": 13005.309080123901, "episode/length": 152.0, "episode/score": 3.2486679275125425, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.14866778597479424}
{"step": 95816, "time": 13034.425854444504, "episode/length": 190.0, "episode/score": 3.3022960867438087, "episode/reward_rate": 0.9633507853403142, "episode/intrinsic_return": 0.20229600190032215}
{"step": 95864, "time": 13041.857669830322, "episode/length": 183.0, "episode/score": 4.262297940725148, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.16229781793026632}
{"step": 96112, "time": 13074.226018428802, "episode/length": 189.0, "episode/score": 4.286193859737978, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.18619379579104134}
{"step": 96264, "time": 13094.341707706451, "episode/length": 279.0, "episode/score": 4.401472137406017, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.30147198445956747}
{"step": 96408, "time": 13113.492962121964, "episode/length": 148.0, "episode/score": 4.253790921066866, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.1537907535685008}
{"step": 96472, "time": 13123.425810575485, "episode/length": 109.0, "episode/score": 5.225178510120713, "episode/reward_rate": 0.9545454545454546, "episode/intrinsic_return": 0.12517829244734457}
{"step": 96664, "time": 13148.595190763474, "episode/length": 178.0, "episode/score": 5.261770733472076, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.161770586433704}
{"step": 96824, "time": 13169.586512327194, "episode/length": 119.0, "episode/score": 4.232073158321327, "episode/reward_rate": 0.95, "episode/intrinsic_return": 0.13207304134721198}
{"step": 97120, "time": 13207.139738082886, "episode/length": 200.0, "episode/score": 4.297770518187463, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.1977704493510828}
{"step": 97376, "time": 13240.064066648483, "episode/length": 157.0, "episode/score": 0.19340956228370487, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.09340952388993173}
{"step": 97456, "time": 13251.237769842148, "episode/length": 148.0, "episode/score": 3.244338067663193, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.14433791669580387}
{"step": 97792, "time": 13293.877735853195, "episode/length": 246.0, "episode/score": 4.376973203876332, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.2769730265990802}
{"step": 97856, "time": 13303.257963180542, "episode/length": 172.0, "episode/score": 5.261770348212849, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.16177030324161024}
{"step": 98145, "time": 13341.119836091995, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.296273595999673, "train/action_min": 0.0, "train/action_std": 3.188014934200267, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04296712622202504, "train/actor_opt_grad_steps": 23190.0, "train/actor_opt_loss": -1.5250077224799787, "train/adv_mag": 0.7924848111512149, "train/adv_max": 0.7561040001077802, "train/adv_mean": 0.0032784875126484554, "train/adv_min": -0.5698490219278486, "train/adv_std": 0.06540662397420843, "train/cont_avg": 0.9944167212041884, "train/cont_loss_mean": 0.00015835187541209027, "train/cont_loss_std": 0.00469910710935842, "train/cont_neg_acc": 0.9976190485452351, "train/cont_neg_loss": 0.008584564369927026, "train/cont_pos_acc": 0.999979426411434, "train/cont_pos_loss": 0.00010263983783796312, "train/cont_pred": 0.9944079022132913, "train/cont_rate": 0.9944167212041884, "train/dyn_loss_mean": 6.248141128979428, "train/dyn_loss_std": 8.224942484451214, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.410330960887889, "train/extr_critic_critic_opt_grad_steps": 23190.0, "train/extr_critic_critic_opt_loss": 15311.903289635144, "train/extr_critic_mag": 7.187341008510889, "train/extr_critic_max": 7.187341008510889, "train/extr_critic_mean": 1.0193102063308837, "train/extr_critic_min": -0.6878126653701223, "train/extr_critic_std": 1.445984994865837, "train/extr_return_normed_mag": 1.8961392647308828, "train/extr_return_normed_max": 1.8961392647308828, "train/extr_return_normed_mean": 0.31717321768169005, "train/extr_return_normed_min": -0.15262733483735805, "train/extr_return_normed_std": 0.340480073740345, "train/extr_return_rate": 0.49364811010385684, "train/extr_return_raw_mag": 7.943315658269753, "train/extr_return_raw_max": 7.943315658269753, "train/extr_return_raw_mean": 1.0336867380516692, "train/extr_return_raw_min": -1.021539767063101, "train/extr_return_raw_std": 1.4906260599016519, "train/extr_reward_mag": 1.014079674376243, "train/extr_reward_max": 1.014079674376243, "train/extr_reward_mean": 0.017167248729011774, "train/extr_reward_min": -0.6347805767159187, "train/extr_reward_std": 0.13362885949187253, "train/image_loss_mean": 5.1050093286324545, "train/image_loss_std": 9.164746863679737, "train/model_loss_mean": 8.919214253650285, "train/model_loss_std": 12.855073541870915, "train/model_opt_grad_norm": 49.542030983570356, "train/model_opt_grad_steps": 23166.769633507854, "train/model_opt_loss": 10314.61270477135, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1174.738219895288, "train/policy_entropy_mag": 2.3003695597823377, "train/policy_entropy_max": 2.3003695597823377, "train/policy_entropy_mean": 0.5573042319083089, "train/policy_entropy_min": 0.07937533334287673, "train/policy_entropy_std": 0.46795630704670055, "train/policy_logprob_mag": 7.438377842229074, "train/policy_logprob_max": -0.009455860060937118, "train/policy_logprob_mean": -0.5568048598254538, "train/policy_logprob_min": -7.438377842229074, "train/policy_logprob_std": 1.0805554346264346, "train/policy_randomness_mag": 0.8119295064691474, "train/policy_randomness_max": 0.8119295064691474, "train/policy_randomness_mean": 0.19670393696318123, "train/policy_randomness_min": 0.028016009411886724, "train/policy_randomness_std": 0.1651680392276554, "train/post_ent_mag": 47.731333368111656, "train/post_ent_max": 47.731333368111656, "train/post_ent_mean": 30.39430256788643, "train/post_ent_min": 16.41895725090466, "train/post_ent_std": 5.304126769460309, "train/prior_ent_mag": 69.68569990227984, "train/prior_ent_max": 69.68569990227984, "train/prior_ent_mean": 36.78951265424958, "train/prior_ent_min": 19.194706497392104, "train/prior_ent_std": 9.052349177954708, "train/rep_loss_mean": 6.248141128979428, "train/rep_loss_std": 8.224942484451214, "train/reward_avg": 0.009773616188971317, "train/reward_loss_mean": 0.06516192516029193, "train/reward_loss_std": 0.16542647162657134, "train/reward_max_data": 1.0101505542924891, "train/reward_max_pred": 1.0088149421502157, "train/reward_neg_acc": 0.9991744675561396, "train/reward_neg_loss": 0.05014907003073168, "train/reward_pos_acc": 0.8229633781922425, "train/reward_pos_loss": 0.779051172483654, "train/reward_pred": 0.009595434754935742, "train/reward_rate": 0.020512925392670158, "train_stats/sum_log_reward": 3.424999913573265, "train_stats/max_log_achievement_collect_drink": 4.5, "train_stats/max_log_achievement_collect_sapling": 2.8, "train_stats/max_log_achievement_collect_wood": 1.825, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.1, "train_stats/max_log_achievement_eat_cow": 0.15, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 2.15, "train_stats/max_log_achievement_place_table": 0.025, "train_stats/max_log_achievement_wake_up": 2.95, "train_stats/mean_log_entropy": 0.5411187030375004, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 2.082044375129044e-05, "report/cont_loss_std": 0.0004903661319985986, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00292322039604187, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 3.7139632240723586e-06, "report/cont_pred": 0.9941539764404297, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 6.070985794067383, "report/dyn_loss_std": 8.341328620910645, "report/image_loss_mean": 4.639344215393066, "report/image_loss_std": 9.306787490844727, "report/model_loss_mean": 8.360258102416992, "report/model_loss_std": 13.010656356811523, "report/post_ent_mag": 46.20850372314453, "report/post_ent_max": 46.20850372314453, "report/post_ent_mean": 29.560710906982422, "report/post_ent_min": 15.781978607177734, "report/post_ent_std": 4.886836528778076, "report/prior_ent_mag": 70.68486022949219, "report/prior_ent_max": 70.68486022949219, "report/prior_ent_mean": 36.390525817871094, "report/prior_ent_min": 20.547454833984375, "report/prior_ent_std": 9.161114692687988, "report/rep_loss_mean": 6.070985794067383, "report/rep_loss_std": 8.341328620910645, "report/reward_avg": 0.011013677343726158, "report/reward_loss_mean": 0.07830076664686203, "report/reward_loss_std": 0.20001037418842316, "report/reward_max_data": 1.1012500524520874, "report/reward_max_pred": 1.004133701324463, "report/reward_neg_acc": 0.99698805809021, "report/reward_neg_loss": 0.058852631598711014, "report/reward_pos_acc": 0.8928571939468384, "report/reward_pos_loss": 0.7700987458229065, "report/reward_pred": 0.012404550798237324, "report/reward_rate": 0.02734375, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.015105736441910267, "eval/cont_loss_std": 0.37900999188423157, "eval/cont_neg_acc": 0.6666666865348816, "eval/cont_neg_loss": 2.576873302459717, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 6.911589935043594e-06, "eval/cont_pred": 0.9960720539093018, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 25.189224243164062, "eval/dyn_loss_std": 13.833945274353027, "eval/image_loss_mean": 43.708011627197266, "eval/image_loss_std": 46.096561431884766, "eval/model_loss_mean": 58.933162689208984, "eval/model_loss_std": 51.62260055541992, "eval/post_ent_mag": 45.873809814453125, "eval/post_ent_max": 45.873809814453125, "eval/post_ent_mean": 31.99036979675293, "eval/post_ent_min": 18.072721481323242, "eval/post_ent_std": 4.986684799194336, "eval/prior_ent_mag": 70.68486022949219, "eval/prior_ent_max": 70.68486022949219, "eval/prior_ent_mean": 41.34434509277344, "eval/prior_ent_min": 20.771068572998047, "eval/prior_ent_std": 8.923368453979492, "eval/rep_loss_mean": 25.189224243164062, "eval/rep_loss_std": 13.833945274353027, "eval/reward_avg": 0.0044921874068677425, "eval/reward_loss_mean": 0.09651264548301697, "eval/reward_loss_std": 0.6500484347343445, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 1.0034739971160889, "eval/reward_neg_acc": 0.9980257153511047, "eval/reward_neg_loss": 0.0714372992515564, "eval/reward_pos_acc": 0.9090909361839294, "eval/reward_pos_loss": 2.405724287033081, "eval/reward_pred": 0.003267242107540369, "eval/reward_rate": 0.0107421875, "replay/size": 97641.0, "replay/inserts": 7660.0, "replay/samples": 30640.0, "replay/insert_wait_avg": 1.6360619049470667e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.911855184689515e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 18784.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 9.685754776000977e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.202398777008, "timer/env.step_count": 958.0, "timer/env.step_total": 89.78041434288025, "timer/env.step_frac": 0.08976224657395218, "timer/env.step_avg": 0.09371650766480193, "timer/env.step_min": 0.02326798439025879, "timer/env.step_max": 2.1450414657592773, "timer/replay._sample_count": 30640.0, "timer/replay._sample_total": 15.51333737373352, "timer/replay._sample_frac": 0.01551019812860114, "timer/replay._sample_avg": 0.0005063099665056632, "timer/replay._sample_min": 0.0003523826599121094, "timer/replay._sample_max": 0.011164426803588867, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 958.0, "timer/agent.policy_total": 15.374782085418701, "timer/agent.policy_frac": 0.015371670878032416, "timer/agent.policy_avg": 0.016048833074549792, "timer/agent.policy_min": 0.014464616775512695, "timer/agent.policy_max": 0.04745221138000488, "timer/dataset_train_count": 1915.0, "timer/dataset_train_total": 0.3176758289337158, "timer/dataset_train_frac": 0.0003176115447454957, "timer/dataset_train_avg": 0.0001658881613230892, "timer/dataset_train_min": 9.918212890625e-05, "timer/dataset_train_max": 0.0007736682891845703, "timer/agent.train_count": 1915.0, "timer/agent.train_total": 861.4553270339966, "timer/agent.train_frac": 0.8612810048119623, "timer/agent.train_avg": 0.4498461237775439, "timer/agent.train_min": 0.43602705001831055, "timer/agent.train_max": 0.5858283042907715, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4794638156890869, "timer/agent.report_frac": 0.00047936679243655946, "timer/agent.report_avg": 0.23973190784454346, "timer/agent.report_min": 0.23212313652038574, "timer/agent.report_max": 0.24734067916870117, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9087066650390625e-05, "timer/dataset_eval_frac": 2.9081180654992104e-08, "timer/dataset_eval_avg": 2.9087066650390625e-05, "timer/dataset_eval_min": 2.9087066650390625e-05, "timer/dataset_eval_max": 2.9087066650390625e-05, "fps": 7.658336997806017}
{"step": 98152, "time": 13341.710596323013, "episode/length": 185.0, "episode/score": 4.299386818061976, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.19938669526709418}
{"step": 98272, "time": 13358.304597139359, "episode/length": 180.0, "episode/score": 3.2628016012822627, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.1628015771493665}
{"step": 98400, "time": 13376.65556883812, "episode/length": 159.0, "episode/score": 4.2329207081579625, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.13292047310960697}
{"step": 98720, "time": 13417.55040717125, "episode/length": 157.0, "episode/score": 2.2580813250842766, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.15808120508336287}
{"step": 98784, "time": 13426.767090797424, "episode/length": 115.0, "episode/score": 5.240208478528075, "episode/reward_rate": 0.9482758620689655, "episode/intrinsic_return": 0.14020833058748394}
{"step": 99272, "time": 13487.959477424622, "episode/length": 184.0, "episode/score": 2.2771368257594986, "episode/reward_rate": 0.9675675675675676, "episode/intrinsic_return": 0.17713676373341514}
{"step": 99320, "time": 13495.330602169037, "episode/length": 242.0, "episode/score": 3.305324764341094, "episode/reward_rate": 0.9794238683127572, "episode/intrinsic_return": 0.20532467018438183}
{"step": 99568, "time": 13527.174197673798, "episode/length": 176.0, "episode/score": 1.26715677320135, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.16715673515682283}
{"step": 99656, "time": 13539.490372896194, "episode/length": 172.0, "episode/score": 3.245338184591674, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.14533805911923992}
{"step": 99760, "time": 13553.754814624786, "episode/length": 169.0, "episode/score": 5.2786603262416065, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.17866017713686233}
{"step": 99792, "time": 13559.285707712173, "episode/length": 422.0, "episode/score": 6.4936010826640995, "episode/reward_rate": 0.7044917257683215, "episode/intrinsic_return": 0.39360098681936506}
{"step": 99896, "time": 13573.629929065704, "episode/length": 138.0, "episode/score": 4.2269955310339355, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.12699532127680868}
{"step": 99952, "time": 13581.922937631607, "episode/length": 153.0, "episode/score": 3.265031407041988, "episode/reward_rate": 0.9545454545454546, "episode/intrinsic_return": 0.1650313635841485}
{"step": 100048, "time": 13611.098378419876, "eval_episode/length": 79.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.925}
{"step": 100048, "time": 13614.096360445023, "eval_episode/length": 103.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9519230769230769}
{"step": 100048, "time": 13618.01369524002, "eval_episode/length": 157.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9936708860759493}
{"step": 100048, "time": 13620.80023765564, "eval_episode/length": 184.0, "eval_episode/score": 1.0999999716877937, "eval_episode/reward_rate": 0.9945945945945946}
{"step": 100048, "time": 13623.656732082367, "eval_episode/length": 58.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9152542372881356}
{"step": 100048, "time": 13625.77740764618, "eval_episode/length": 151.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9671052631578947}
{"step": 100048, "time": 13628.081158399582, "eval_episode/length": 250.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9960159362549801}
{"step": 100048, "time": 13630.302452087402, "eval_episode/length": 264.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9811320754716981}
{"step": 100072, "time": 13633.207501411438, "episode/length": 34.0, "episode/score": 1.1394584107329138, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0394583327579312}
{"step": 100776, "time": 13721.133091688156, "episode/length": 187.0, "episode/score": 3.2558670380435615, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.15586690139525672}
{"step": 101016, "time": 13751.961057186127, "episode/length": 211.0, "episode/score": 4.314124203083338, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.21412408890319057}
{"step": 101136, "time": 13768.024302005768, "episode/length": 195.0, "episode/score": 5.291397587457141, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.1913974921217232}
{"step": 101184, "time": 13775.49558186531, "episode/length": 190.0, "episode/score": 2.266239824476088, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.16623980662961912}
{"step": 101280, "time": 13788.620847463608, "episode/length": 189.0, "episode/score": 4.2952654120208535, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.19526530238090345}
{"step": 101384, "time": 13802.827687263489, "episode/length": 178.0, "episode/score": 4.281269797566438, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.18126964461998796}
{"step": 101512, "time": 13819.96540236473, "episode/length": 201.0, "episode/score": 4.316503391533388, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.21650326873850645}
{"step": 101688, "time": 13842.976003408432, "episode/length": 201.0, "episode/score": 4.306588043262309, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.20658785900013754}
{"step": 102192, "time": 13906.207059383392, "episode/length": 176.0, "episode/score": 4.311431213490323, "episode/reward_rate": 0.96045197740113, "episode/intrinsic_return": 0.21143109768036084}
{"step": 102336, "time": 13925.471102714539, "episode/length": 164.0, "episode/score": 3.2505652668692164, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.15056518703158872}
{"step": 102352, "time": 13928.819887638092, "episode/length": 145.0, "episode/score": 1.1984806942145951, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.09848063687422837}
{"step": 102560, "time": 13955.778359651566, "episode/length": 177.0, "episode/score": 2.2750660090573547, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.17506594353881155}
{"step": 102760, "time": 13981.825346946716, "episode/length": 184.0, "episode/score": 2.3079905429217433, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.20799047085483835}
{"step": 102800, "time": 13988.31891989708, "episode/length": 160.0, "episode/score": 2.281243708537204, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.1812436430186608}
{"step": 102816, "time": 13991.81591629982, "episode/length": 178.0, "episode/score": 5.282678581456821, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.1826784384347775}
{"step": 102832, "time": 13995.701039791107, "episode/length": 142.0, "episode/score": 4.233179872549044, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.13317970726257045}
{"step": 103520, "time": 14081.923974514008, "episode/length": 145.0, "episode/score": 4.24611190497194, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.14611169521481315}
{"step": 103632, "time": 14097.06247830391, "episode/length": 179.0, "episode/score": 5.307421463186984, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.20742127962330414}
{"step": 103632, "time": 14097.070713758469, "episode/length": 161.0, "episode/score": 5.250516232666087, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.15051610480713862}
{"step": 103912, "time": 14134.706484794617, "episode/length": 138.0, "episode/score": 1.2488572300399028, "episode/reward_rate": 0.9568345323741008, "episode/intrinsic_return": 0.14885719898029492}
{"step": 104032, "time": 14150.880689620972, "episode/length": 149.0, "episode/score": 3.27089478886046, "episode/reward_rate": 0.96, "episode/intrinsic_return": 0.17089468562335242}
{"step": 104216, "time": 14175.609847784042, "episode/length": 181.0, "episode/score": 5.271771951260689, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.1717717725282455}
{"step": 104296, "time": 14186.946588039398, "episode/length": 184.0, "episode/score": 2.222611438271997, "episode/reward_rate": 0.9891891891891892, "episode/intrinsic_return": 0.12261137584573589}
{"step": 104360, "time": 14196.33110499382, "episode/length": 224.0, "episode/score": 4.334230623436497, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.23423047951223452}
{"step": 104848, "time": 14257.343253135681, "episode/length": 151.0, "episode/score": 1.1930930805472144, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.09309305175770533}
{"step": 104880, "time": 14262.856734275818, "episode/length": 155.0, "episode/score": 3.2413331415014, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.1413330667860464}
{"step": 105016, "time": 14280.98164653778, "episode/length": 186.0, "episode/score": 3.276406924294861, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.1764068301381485}
{"step": 105072, "time": 14289.2702896595, "episode/length": 129.0, "episode/score": 4.222038011715767, "episode/reward_rate": 0.9923076923076923, "episode/intrinsic_return": 0.12203787762859974}
{"step": 105192, "time": 14305.425370693207, "episode/length": 38.0, "episode/score": 0.13853794315946288, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.03853787810658105}
{"step": 105192, "time": 14305.432735919952, "episode/length": 159.0, "episode/score": 4.276955956024494, "episode/reward_rate": 0.9625, "episode/intrinsic_return": 0.1769558367220725}
{"step": 105449, "time": 14341.185237407684, "train_stats/sum_log_reward": 3.349999934096228, "train_stats/max_log_achievement_collect_drink": 7.2272727272727275, "train_stats/max_log_achievement_collect_sapling": 2.090909090909091, "train_stats/max_log_achievement_collect_wood": 1.5454545454545454, "train_stats/max_log_achievement_defeat_skeleton": 0.022727272727272728, "train_stats/max_log_achievement_defeat_zombie": 0.11363636363636363, "train_stats/max_log_achievement_eat_cow": 0.09090909090909091, "train_stats/max_log_achievement_make_wood_sword": 0.045454545454545456, "train_stats/max_log_achievement_place_plant": 1.7045454545454546, "train_stats/max_log_achievement_place_table": 0.09090909090909091, "train_stats/max_log_achievement_wake_up": 2.5681818181818183, "train_stats/mean_log_entropy": 0.5421233001080427, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.420955470350922, "train/action_min": 0.0, "train/action_std": 3.4188129328639127, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.046303831356389276, "train/actor_opt_grad_steps": 25060.0, "train/actor_opt_loss": -4.9688969919753205, "train/adv_mag": 0.8088642831057147, "train/adv_max": 0.7781889739909459, "train/adv_mean": 0.003466036135176212, "train/adv_min": -0.5840466548510588, "train/adv_std": 0.06833236173935275, "train/cont_avg": 0.9943327356557377, "train/cont_loss_mean": 0.00012794231369872385, "train/cont_loss_std": 0.0037461033079774202, "train/cont_neg_acc": 0.9975800162456074, "train/cont_neg_loss": 0.006173821631272319, "train/cont_pos_acc": 0.999978474580525, "train/cont_pos_loss": 8.517013815180018e-05, "train/cont_pred": 0.9943126052455172, "train/cont_rate": 0.9943327356557377, "train/dyn_loss_mean": 6.468047983659421, "train/dyn_loss_std": 8.412519434110715, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.354575339887963, "train/extr_critic_critic_opt_grad_steps": 25060.0, "train/extr_critic_critic_opt_loss": 15490.370047814207, "train/extr_critic_mag": 7.476215802906641, "train/extr_critic_max": 7.476215802906641, "train/extr_critic_mean": 1.0718081653769551, "train/extr_critic_min": -0.662540917188092, "train/extr_critic_std": 1.4002837379122042, "train/extr_return_normed_mag": 1.9391915641847204, "train/extr_return_normed_max": 1.9391915641847204, "train/extr_return_normed_mean": 0.3308575742883109, "train/extr_return_normed_min": -0.15743272725105936, "train/extr_return_normed_std": 0.3378972446983629, "train/extr_return_rate": 0.5203232012811254, "train/extr_return_raw_mag": 7.975303576943653, "train/extr_return_raw_max": 7.975303576943653, "train/extr_return_raw_mean": 1.0866438941877397, "train/extr_return_raw_min": -1.0024712903252064, "train/extr_return_raw_std": 1.4469717441360808, "train/extr_reward_mag": 1.016371516582093, "train/extr_reward_max": 1.016371516582093, "train/extr_reward_mean": 0.01862708759835102, "train/extr_reward_min": -0.6416366725671486, "train/extr_reward_std": 0.13860101228366134, "train/image_loss_mean": 5.25751489107726, "train/image_loss_std": 9.988659843069609, "train/model_loss_mean": 9.206120006373672, "train/model_loss_std": 13.747880862710254, "train/model_opt_grad_norm": 52.81207680832493, "train/model_opt_grad_steps": 25035.30601092896, "train/model_opt_loss": 12703.229745666837, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1379.7814207650274, "train/policy_entropy_mag": 2.321805315590947, "train/policy_entropy_max": 2.321805315590947, "train/policy_entropy_mean": 0.5389741032175679, "train/policy_entropy_min": 0.0793752685759237, "train/policy_entropy_std": 0.4750972624684944, "train/policy_logprob_mag": 7.438380629638505, "train/policy_logprob_max": -0.009455804280488868, "train/policy_logprob_mean": -0.539489052497624, "train/policy_logprob_min": -7.438380629638505, "train/policy_logprob_std": 1.0749402808361366, "train/policy_randomness_mag": 0.8194953857875261, "train/policy_randomness_max": 0.8194953857875261, "train/policy_randomness_mean": 0.1902342060876023, "train/policy_randomness_min": 0.028015986420824878, "train/policy_randomness_std": 0.16768848399321237, "train/post_ent_mag": 48.0212652487833, "train/post_ent_max": 48.0212652487833, "train/post_ent_mean": 30.786136283249153, "train/post_ent_min": 16.568763769389502, "train/post_ent_std": 5.286292482594975, "train/prior_ent_mag": 70.06910409562575, "train/prior_ent_max": 70.06910409562575, "train/prior_ent_mean": 37.27807223210569, "train/prior_ent_min": 19.579824385095815, "train/prior_ent_std": 9.073788324991861, "train/rep_loss_mean": 6.468047983659421, "train/rep_loss_std": 8.412519434110715, "train/reward_avg": 0.011208262749695693, "train/reward_loss_mean": 0.0676483611469386, "train/reward_loss_std": 0.17690616182453645, "train/reward_max_data": 1.0121789929645308, "train/reward_max_pred": 1.0093173348838513, "train/reward_neg_acc": 0.9989842599858352, "train/reward_neg_loss": 0.05086701711426016, "train/reward_pos_acc": 0.8234565117971493, "train/reward_pos_loss": 0.7981828239446129, "train/reward_pred": 0.010933901502654119, "train/reward_rate": 0.022402237021857924, "eval_stats/sum_log_reward": 3.224999964237213, "eval_stats/max_log_achievement_collect_drink": 8.625, "eval_stats/max_log_achievement_collect_sapling": 1.375, "eval_stats/max_log_achievement_collect_wood": 2.125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.125, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 1.125, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 2.125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9892578125, "report/cont_loss_mean": 5.0357259169686586e-05, "report/cont_loss_std": 0.0008828751742839813, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.003985905088484287, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 7.62179706725874e-06, "report/cont_pred": 0.9892928004264832, "report/cont_rate": 0.9892578125, "report/dyn_loss_mean": 6.69969367980957, "report/dyn_loss_std": 8.42282485961914, "report/image_loss_mean": 5.137293815612793, "report/image_loss_std": 7.913151741027832, "report/model_loss_mean": 9.23690414428711, "report/model_loss_std": 11.58498477935791, "report/post_ent_mag": 49.16994094848633, "report/post_ent_max": 49.16994094848633, "report/post_ent_mean": 31.261201858520508, "report/post_ent_min": 17.736547470092773, "report/post_ent_std": 6.333375453948975, "report/prior_ent_mag": 69.19610595703125, "report/prior_ent_max": 69.19610595703125, "report/prior_ent_mean": 38.220035552978516, "report/prior_ent_min": 17.82645034790039, "report/prior_ent_std": 10.499529838562012, "report/rep_loss_mean": 6.69969367980957, "report/rep_loss_std": 8.42282485961914, "report/reward_avg": 0.014988165348768234, "report/reward_loss_mean": 0.07974499464035034, "report/reward_loss_std": 0.1513684242963791, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0029635429382324, "report/reward_neg_acc": 0.9989888072013855, "report/reward_neg_loss": 0.057354263961315155, "report/reward_pos_acc": 0.6571428775787354, "report/reward_pos_loss": 0.7124427556991577, "report/reward_pred": 0.014811478555202484, "report/reward_rate": 0.0341796875, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 2.436021895846352e-05, "eval/cont_loss_std": 0.00041545089334249496, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.004765337333083153, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 5.76815364183858e-06, "eval/cont_pred": 0.9961066246032715, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 21.45557403564453, "eval/dyn_loss_std": 12.977879524230957, "eval/image_loss_mean": 35.13592529296875, "eval/image_loss_std": 29.558395385742188, "eval/model_loss_mean": 48.07246398925781, "eval/model_loss_std": 35.141719818115234, "eval/post_ent_mag": 46.11522674560547, "eval/post_ent_max": 46.11522674560547, "eval/post_ent_mean": 32.01895523071289, "eval/post_ent_min": 17.0230712890625, "eval/post_ent_std": 5.075109004974365, "eval/prior_ent_mag": 69.19610595703125, "eval/prior_ent_max": 69.19610595703125, "eval/prior_ent_mean": 41.58582305908203, "eval/prior_ent_min": 16.483386993408203, "eval/prior_ent_std": 9.01367473602295, "eval/rep_loss_mean": 21.45557403564453, "eval/rep_loss_std": 12.977879524230957, "eval/reward_avg": 0.008496093563735485, "eval/reward_loss_mean": 0.06316900253295898, "eval/reward_loss_std": 0.5624988079071045, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0023775100708008, "eval/reward_neg_acc": 0.9990118741989136, "eval/reward_neg_loss": 0.03313707932829857, "eval/reward_pos_acc": 0.75, "eval/reward_pos_loss": 2.5958619117736816, "eval/reward_pred": 0.008107196539640427, "eval/reward_rate": 0.01171875, "replay/size": 104945.0, "replay/inserts": 7304.0, "replay/samples": 29216.0, "replay/insert_wait_avg": 1.6501934348165923e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.942008815485441e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 20904.0, "eval_replay/inserts": 2120.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1749987332326062e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.685754776000977e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0489282608032, "timer/env.step_count": 913.0, "timer/env.step_total": 92.80618000030518, "timer/env.step_frac": 0.09280163937749075, "timer/env.step_avg": 0.10164970427196623, "timer/env.step_min": 0.0230100154876709, "timer/env.step_max": 3.4707624912261963, "timer/replay._sample_count": 29216.0, "timer/replay._sample_total": 15.130244970321655, "timer/replay._sample_frac": 0.015129504709969382, "timer/replay._sample_avg": 0.0005178753070345583, "timer/replay._sample_min": 0.0003440380096435547, "timer/replay._sample_max": 0.03268909454345703, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1178.0, "timer/agent.policy_total": 19.73635959625244, "timer/agent.policy_frac": 0.019735393977748844, "timer/agent.policy_avg": 0.016754125293932463, "timer/agent.policy_min": 0.009666681289672852, "timer/agent.policy_max": 0.567072868347168, "timer/dataset_train_count": 1826.0, "timer/dataset_train_total": 0.3052654266357422, "timer/dataset_train_frac": 0.0003052504912600955, "timer/dataset_train_avg": 0.00016717712302066932, "timer/dataset_train_min": 9.942054748535156e-05, "timer/dataset_train_max": 0.0023202896118164062, "timer/agent.train_count": 1826.0, "timer/agent.train_total": 824.7822725772858, "timer/agent.train_frac": 0.8247419193895585, "timer/agent.train_avg": 0.4516879915538257, "timer/agent.train_min": 0.4416182041168213, "timer/agent.train_max": 0.9918978214263916, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4764375686645508, "timer/agent.report_frac": 0.0004764142585434584, "timer/agent.report_avg": 0.2382187843322754, "timer/agent.report_min": 0.231689453125, "timer/agent.report_max": 0.24474811553955078, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.147125244140625e-05, "timer/dataset_eval_frac": 3.1469712683096686e-08, "timer/dataset_eval_avg": 3.147125244140625e-05, "timer/dataset_eval_min": 3.147125244140625e-05, "timer/dataset_eval_max": 3.147125244140625e-05, "fps": 7.303536032707124}
{"step": 105584, "time": 14357.51546740532, "episode/length": 170.0, "episode/score": 3.2708176919552443, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.17081758281005932}
{"step": 105920, "time": 14400.31002497673, "episode/length": 194.0, "episode/score": 4.290880964233338, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.1908808012751706}
{"step": 106240, "time": 14441.118794679642, "episode/length": 145.0, "episode/score": 3.239700617085873, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.13970046611848375}
{"step": 106336, "time": 14454.43991947174, "episode/length": 142.0, "episode/score": 5.23469665942298, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.1346964511792521}
{"step": 106464, "time": 14471.686932086945, "episode/length": 270.0, "episode/score": 5.392342871543178, "episode/reward_rate": 0.977859778597786, "episode/intrinsic_return": 0.2923427393768634}
{"step": 106480, "time": 14475.225049972534, "episode/length": 182.0, "episode/score": 4.293330076737902, "episode/reward_rate": 0.9672131147540983, "episode/intrinsic_return": 0.19332995976378697}
{"step": 106944, "time": 14534.551528453827, "episode/length": 261.0, "episode/score": 4.39139074026275, "episode/reward_rate": 0.9961832061068703, "episode/intrinsic_return": 0.29139059942349377}
{"step": 106992, "time": 14541.956389188766, "episode/length": 175.0, "episode/score": 5.271603975319522, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.17160382668043894}
{"step": 107096, "time": 14556.338382720947, "episode/length": 237.0, "episode/score": 5.338354758309833, "episode/reward_rate": 0.9789915966386554, "episode/intrinsic_return": 0.23835459337260545}
{"step": 107168, "time": 14566.614976882935, "episode/length": 155.0, "episode/score": 4.282716454246611, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.18271628046181831}
{"step": 107640, "time": 14625.994436740875, "episode/length": 174.0, "episode/score": 4.2563307634245575, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.15633073054596025}
{"step": 107920, "time": 14661.770028352737, "episode/length": 197.0, "episode/score": 4.285762228957992, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.18576208432796193}
{"step": 108160, "time": 14692.697405338287, "episode/length": 145.0, "episode/score": 3.2450531630722708, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.14505305168609084}
{"step": 108320, "time": 14713.878902196884, "episode/length": 171.0, "episode/score": 3.289555892119779, "episode/reward_rate": 0.9651162790697675, "episode/intrinsic_return": 0.18955585320213686}
{"step": 108480, "time": 14734.967458724976, "episode/length": 251.0, "episode/score": 4.361901374377339, "episode/reward_rate": 0.9841269841269841, "episode/intrinsic_return": 0.2619013092662499}
{"step": 108520, "time": 14741.410270690918, "episode/length": 177.0, "episode/score": 4.277956131075371, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.17795605647643242}
{"step": 108960, "time": 14796.726999521255, "episode/length": 223.0, "episode/score": 4.339142938750456, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.23914278463985283}
{"step": 108984, "time": 14801.229137897491, "episode/length": 312.0, "episode/score": 3.4566171339081393, "episode/reward_rate": 0.9840255591054313, "episode/intrinsic_return": 0.3566170467363463}
{"step": 109224, "time": 14832.132041454315, "episode/length": 162.0, "episode/score": 3.2676533469700644, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.1676532632325234}
{"step": 109432, "time": 14859.12570810318, "episode/length": 158.0, "episode/score": 2.248317542795803, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.14831749389554716}
{"step": 109672, "time": 14890.053077220917, "episode/length": 253.0, "episode/score": 3.3619344703397473, "episode/reward_rate": 0.984251968503937, "episode/intrinsic_return": 0.26193437501888184}
{"step": 109808, "time": 14908.210533618927, "episode/length": 185.0, "episode/score": 3.276338605318415, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.17633849509638821}
{"step": 110032, "time": 14956.142127990723, "eval_episode/length": 152.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9934640522875817}
{"step": 110032, "time": 14958.184591054916, "eval_episode/length": 160.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.968944099378882}
{"step": 110032, "time": 14960.319805145264, "eval_episode/length": 173.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9712643678160919}
{"step": 110032, "time": 14962.100038766861, "eval_episode/length": 178.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9720670391061452}
{"step": 110032, "time": 14964.844977140427, "eval_episode/length": 205.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9951456310679612}
{"step": 110032, "time": 14967.073425769806, "eval_episode/length": 217.0, "eval_episode/score": 6.0999999940395355, "eval_episode/reward_rate": 0.9954128440366973}
{"step": 110032, "time": 14967.081089496613, "eval_episode/length": 217.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.981651376146789}
{"step": 110032, "time": 14974.82072877884, "eval_episode/length": 168.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9704142011834319}
{"step": 110048, "time": 14976.786526203156, "episode/length": 195.0, "episode/score": 3.2957373656072377, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.19573741663498367}
{"step": 110112, "time": 14986.131910324097, "episode/length": 143.0, "episode/score": 2.269881923844423, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.1698818606541863}
{"step": 110192, "time": 14997.233072042465, "episode/length": 208.0, "episode/score": 4.322448063579031, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.22244788630177936}
{"step": 110336, "time": 15016.397774457932, "episode/length": 138.0, "episode/score": 2.240462577361086, "episode/reward_rate": 0.9640287769784173, "episode/intrinsic_return": 0.14046251417084932}
{"step": 110488, "time": 15036.37082362175, "episode/length": 187.0, "episode/score": 4.273690847977377, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.17369072518249595}
{"step": 111096, "time": 15111.95998120308, "episode/length": 207.0, "episode/score": 4.295919389687242, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.19591936727147186}
{"step": 111120, "time": 15116.48047542572, "episode/length": 180.0, "episode/score": 4.225052199653419, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.12505198989629207}
{"step": 111368, "time": 15148.263222932816, "episode/length": 194.0, "episode/score": 3.251365762613659, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.15136561746703592}
{"step": 111416, "time": 15155.713441610336, "episode/length": 162.0, "episode/score": 1.228535111220026, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.12853501985728144}
{"step": 111424, "time": 15158.19262623787, "episode/length": 135.0, "episode/score": 4.220199655844226, "episode/reward_rate": 0.9926470588235294, "episode/intrinsic_return": 0.12019949211480707}
{"step": 111824, "time": 15208.654814243317, "episode/length": 221.0, "episode/score": 4.33374483128955, "episode/reward_rate": 0.9819819819819819, "episode/intrinsic_return": 0.2337448472617325}
{"step": 112064, "time": 15239.51103425026, "episode/length": 196.0, "episode/score": 1.2985376310405172, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.19853753269285335}
{"step": 112088, "time": 15244.032608509064, "episode/length": 236.0, "episode/score": 5.324251629790751, "episode/reward_rate": 0.9789029535864979, "episode/intrinsic_return": 0.22425148892239122}
{"step": 112865, "time": 15341.347651720047, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.229894359691723, "train/action_min": 0.0, "train/action_std": 3.1886019719613565, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0451050956909721, "train/actor_opt_grad_steps": 26900.0, "train/actor_opt_loss": -11.157260488859706, "train/adv_mag": 0.7437034797024082, "train/adv_max": 0.7074543286014248, "train/adv_mean": 0.0018406840030267533, "train/adv_min": -0.5552488428515356, "train/adv_std": 0.06632690651191248, "train/cont_avg": 0.9942198057432432, "train/cont_loss_mean": 0.0002529342867380881, "train/cont_loss_std": 0.007779966246134545, "train/cont_neg_acc": 0.99034320244918, "train/cont_neg_loss": 0.034533813582854504, "train/cont_pos_acc": 0.9999946716669443, "train/cont_pos_loss": 2.607951343367023e-05, "train/cont_pred": 0.9942722449431548, "train/cont_rate": 0.9942198057432432, "train/dyn_loss_mean": 6.264355110477757, "train/dyn_loss_std": 8.391598801999478, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.3580258662636215, "train/extr_critic_critic_opt_grad_steps": 26900.0, "train/extr_critic_critic_opt_loss": 15119.141886613175, "train/extr_critic_mag": 6.2272821168641785, "train/extr_critic_max": 6.2272821168641785, "train/extr_critic_mean": 0.9613774090199857, "train/extr_critic_min": -0.6975965731852763, "train/extr_critic_std": 1.3124133081049532, "train/extr_return_normed_mag": 1.812272944965878, "train/extr_return_normed_max": 1.812272944965878, "train/extr_return_normed_mean": 0.3376969827188028, "train/extr_return_normed_min": -0.17253523291768255, "train/extr_return_normed_std": 0.33964613200844945, "train/extr_return_rate": 0.5016705638653524, "train/extr_return_raw_mag": 6.802548176533467, "train/extr_return_raw_max": 6.802548176533467, "train/extr_return_raw_mean": 0.9686102237250354, "train/extr_return_raw_min": -1.0501242164018991, "train/extr_return_raw_std": 1.3444819076641186, "train/extr_reward_mag": 1.0179008986498859, "train/extr_reward_max": 1.0179008986498859, "train/extr_reward_mean": 0.018051093577633837, "train/extr_reward_min": -0.632888910577104, "train/extr_reward_std": 0.13816494986012176, "train/image_loss_mean": 4.7164527042492015, "train/image_loss_std": 9.17407794385343, "train/model_loss_mean": 8.54200433782629, "train/model_loss_std": 12.967998195338893, "train/model_opt_grad_norm": 49.469277527021326, "train/model_opt_grad_steps": 26873.545945945945, "train/model_opt_loss": 11277.307506334459, "train/model_opt_model_opt_grad_overflow": 0.005405405405405406, "train/model_opt_model_opt_grad_scale": 1310.8108108108108, "train/policy_entropy_mag": 2.3347231452529495, "train/policy_entropy_max": 2.3347231452529495, "train/policy_entropy_mean": 0.5220893515122903, "train/policy_entropy_min": 0.079375224097355, "train/policy_entropy_std": 0.47352529248675784, "train/policy_logprob_mag": 7.438381939965326, "train/policy_logprob_max": -0.009455723416160893, "train/policy_logprob_mean": -0.5222980157749073, "train/policy_logprob_min": -7.438381939965326, "train/policy_logprob_std": 1.0673329495094919, "train/policy_randomness_mag": 0.8240548153181334, "train/policy_randomness_max": 0.8240548153181334, "train/policy_randomness_mean": 0.18427462948335183, "train/policy_randomness_min": 0.028015970670290897, "train/policy_randomness_std": 0.16713364776727316, "train/post_ent_mag": 49.41087341308594, "train/post_ent_max": 49.41087341308594, "train/post_ent_mean": 31.37402616964804, "train/post_ent_min": 16.73480502463676, "train/post_ent_std": 5.386209745664854, "train/prior_ent_mag": 70.48407947437184, "train/prior_ent_max": 70.48407947437184, "train/prior_ent_mean": 37.68176764410895, "train/prior_ent_min": 20.268070293117216, "train/prior_ent_std": 9.048518961829108, "train/rep_loss_mean": 6.264355110477757, "train/rep_loss_std": 8.391598801999478, "train/reward_avg": 0.011244691650358003, "train/reward_loss_mean": 0.06668567005041483, "train/reward_loss_std": 0.17227550169100633, "train/reward_max_data": 1.0126013826679539, "train/reward_max_pred": 1.0101724940377312, "train/reward_neg_acc": 0.9991787517392957, "train/reward_neg_loss": 0.05045640855222135, "train/reward_pos_acc": 0.8404137292423763, "train/reward_pos_loss": 0.7804324001879306, "train/reward_pred": 0.011091045170040751, "train/reward_rate": 0.022328969594594593, "train_stats/sum_log_reward": 3.614285635948181, "train_stats/max_log_achievement_collect_drink": 4.9714285714285715, "train_stats/max_log_achievement_collect_sapling": 2.8, "train_stats/max_log_achievement_collect_wood": 2.914285714285714, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.08571428571428572, "train_stats/max_log_achievement_eat_cow": 0.05714285714285714, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 2.3714285714285714, "train_stats/max_log_achievement_place_table": 0.08571428571428572, "train_stats/max_log_achievement_wake_up": 3.0, "train_stats/mean_log_entropy": 0.5424615068095071, "eval_stats/sum_log_reward": 3.974999949336052, "eval_stats/max_log_achievement_collect_drink": 4.75, "eval_stats/max_log_achievement_collect_sapling": 2.0, "eval_stats/max_log_achievement_collect_wood": 2.375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.5, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 1.625, "eval_stats/max_log_achievement_place_table": 0.25, "eval_stats/max_log_achievement_wake_up": 3.0, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 7.949871360324323e-06, "report/cont_loss_std": 0.00018143343913834542, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0011329813860356808, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 2.0629367725177872e-07, "report/cont_pred": 0.9931716918945312, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 5.688731670379639, "report/dyn_loss_std": 8.290809631347656, "report/image_loss_mean": 4.7720746994018555, "report/image_loss_std": 9.313505172729492, "report/model_loss_mean": 8.246882438659668, "report/model_loss_std": 13.050018310546875, "report/post_ent_mag": 50.023033142089844, "report/post_ent_max": 50.023033142089844, "report/post_ent_mean": 31.16857147216797, "report/post_ent_min": 16.828405380249023, "report/post_ent_std": 5.2484259605407715, "report/prior_ent_mag": 70.1923828125, "report/prior_ent_max": 70.1923828125, "report/prior_ent_mean": 37.07740020751953, "report/prior_ent_min": 21.353008270263672, "report/prior_ent_std": 8.963356971740723, "report/rep_loss_mean": 5.688731670379639, "report/rep_loss_std": 8.290809631347656, "report/reward_avg": 0.005667783319950104, "report/reward_loss_mean": 0.06156092882156372, "report/reward_loss_std": 0.1642770916223526, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0035879611968994, "report/reward_neg_acc": 0.998019814491272, "report/reward_neg_loss": 0.05009452626109123, "report/reward_pos_acc": 0.7142857313156128, "report/reward_pos_loss": 0.8887801170349121, "report/reward_pred": 0.005467335693538189, "report/reward_rate": 0.013671875, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 2.1007836039643735e-05, "eval/cont_loss_std": 0.0004425584338605404, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0032114216592162848, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.2038243514543865e-06, "eval/cont_pred": 0.9941571950912476, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 22.038097381591797, "eval/dyn_loss_std": 13.474149703979492, "eval/image_loss_mean": 32.54451370239258, "eval/image_loss_std": 31.87140655517578, "eval/model_loss_mean": 45.88835906982422, "eval/model_loss_std": 37.42974853515625, "eval/post_ent_mag": 45.73676300048828, "eval/post_ent_max": 45.73676300048828, "eval/post_ent_mean": 31.2654972076416, "eval/post_ent_min": 19.523971557617188, "eval/post_ent_std": 4.652370929718018, "eval/prior_ent_mag": 70.1923828125, "eval/prior_ent_max": 70.1923828125, "eval/prior_ent_mean": 39.8001708984375, "eval/prior_ent_min": 21.66140365600586, "eval/prior_ent_std": 9.027180671691895, "eval/rep_loss_mean": 22.038097381591797, "eval/rep_loss_std": 13.474149703979492, "eval/reward_avg": 0.011914062313735485, "eval/reward_loss_mean": 0.12096475064754486, "eval/reward_loss_std": 0.7491564154624939, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0042040348052979, "eval/reward_neg_acc": 0.9960278272628784, "eval/reward_neg_loss": 0.07447429746389389, "eval/reward_pos_acc": 0.6470588445663452, "eval/reward_pos_loss": 2.874840259552002, "eval/reward_pred": 0.008965989574790001, "eval/reward_rate": 0.0166015625, "replay/size": 112361.0, "replay/inserts": 7416.0, "replay/samples": 29664.0, "replay/insert_wait_avg": 1.6652007447605895e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.965771768728377e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 23480.0, "eval_replay/inserts": 2576.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.185614129771357e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.897615432739258e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1463775634766, "timer/env.step_count": 927.0, "timer/env.step_total": 77.58218050003052, "timer/env.step_frac": 0.07757082587154257, "timer/env.step_avg": 0.08369167259981718, "timer/env.step_min": 0.02263498306274414, "timer/env.step_max": 1.737356424331665, "timer/replay._sample_count": 29664.0, "timer/replay._sample_total": 15.383875131607056, "timer/replay._sample_frac": 0.015381623607021146, "timer/replay._sample_avg": 0.0005186042048141537, "timer/replay._sample_min": 0.0003886222839355469, "timer/replay._sample_max": 0.010408163070678711, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1249.0, "timer/agent.policy_total": 20.2945396900177, "timer/agent.policy_frac": 0.0202915694595211, "timer/agent.policy_avg": 0.016248630656539392, "timer/agent.policy_min": 0.00965571403503418, "timer/agent.policy_max": 0.049445152282714844, "timer/dataset_train_count": 1854.0, "timer/dataset_train_total": 0.32222414016723633, "timer/dataset_train_frac": 0.0003221769806857953, "timer/dataset_train_avg": 0.00017379942835341766, "timer/dataset_train_min": 0.00010275840759277344, "timer/dataset_train_max": 0.010895967483520508, "timer/agent.train_count": 1854.0, "timer/agent.train_total": 837.0330901145935, "timer/agent.train_frac": 0.8369105851822868, "timer/agent.train_avg": 0.45147415863786056, "timer/agent.train_min": 0.4412269592285156, "timer/agent.train_max": 0.9042181968688965, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47907495498657227, "timer/agent.report_frac": 0.00047900483942528373, "timer/agent.report_avg": 0.23953747749328613, "timer/agent.report_min": 0.23317575454711914, "timer/agent.report_max": 0.24589920043945312, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8371810913085938e-05, "timer/dataset_eval_frac": 2.8367658524349608e-08, "timer/dataset_eval_avg": 2.8371810913085938e-05, "timer/dataset_eval_min": 2.8371810913085938e-05, "timer/dataset_eval_max": 2.8371810913085938e-05, "fps": 7.41480761599452}
{"step": 112920, "time": 15347.921521663666, "episode/length": 186.0, "episode/score": 4.302495173228863, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.20249502028241295}
{"step": 112944, "time": 15352.32898902893, "episode/length": 230.0, "episode/score": 4.338751233242647, "episode/reward_rate": 0.9783549783549783, "episode/intrinsic_return": 0.2387511104477653}
{"step": 112976, "time": 15357.796308040619, "episode/length": 231.0, "episode/score": 4.318126966721593, "episode/reward_rate": 0.978448275862069, "episode/intrinsic_return": 0.21812693932906768}
{"step": 113072, "time": 15371.200675725937, "episode/length": 212.0, "episode/score": 4.2998514271114345, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.19985131089401875}
{"step": 113072, "time": 15371.207195997238, "episode/length": 122.0, "episode/score": 4.24635727648274, "episode/reward_rate": 0.967479674796748, "episode/intrinsic_return": 0.14635713995085098}
{"step": 113264, "time": 15397.854005336761, "episode/length": 179.0, "episode/score": 3.2842143098508814, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.18421419962885466}
{"step": 113664, "time": 15448.110679149628, "episode/length": 199.0, "episode/score": 4.289856226787151, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.18985604718159266}
{"step": 113808, "time": 15467.289048433304, "episode/length": 298.0, "episode/score": 4.42807383627769, "episode/reward_rate": 0.9866220735785953, "episode/intrinsic_return": 0.3280736821670871}
{"step": 114024, "time": 15495.193562746048, "episode/length": 137.0, "episode/score": 3.2073389207060927, "episode/reward_rate": 0.9637681159420289, "episode/intrinsic_return": 0.10733884700937324}
{"step": 114240, "time": 15523.258611917496, "episode/length": 145.0, "episode/score": 4.226886014566503, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.12688583496094452}
{"step": 114304, "time": 15532.579133987427, "episode/length": 165.0, "episode/score": 4.278225071260977, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.1782250151138669}
{"step": 114440, "time": 15550.804616212845, "episode/length": 186.0, "episode/score": 4.3007943938342805, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.20079421073626236}
{"step": 114728, "time": 15588.81451535225, "episode/length": 182.0, "episode/score": 4.304315525247603, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.2043153918589269}
{"step": 114792, "time": 15598.0924949646, "episode/length": 214.0, "episode/score": 4.296671072234403, "episode/reward_rate": 0.9813953488372092, "episode/intrinsic_return": 0.19667103063920877}
{"step": 115136, "time": 15641.81615805626, "episode/length": 183.0, "episode/score": 4.274690266295124, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.17469014524647264}
{"step": 115224, "time": 15654.112024068832, "episode/length": 114.0, "episode/score": 2.21263911195922, "episode/reward_rate": 0.9565217391304348, "episode/intrinsic_return": 0.1126390464406768}
{"step": 115336, "time": 15669.419458150864, "episode/length": 136.0, "episode/score": 3.2360262815516307, "episode/reward_rate": 0.9927007299270073, "episode/intrinsic_return": 0.13602612592762853}
{"step": 115408, "time": 15679.656495809555, "episode/length": 172.0, "episode/score": 4.272644815730928, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.17264470725513092}
{"step": 115592, "time": 15703.580038070679, "episode/length": 143.0, "episode/score": 2.216457912695546, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.11645774414944299}
{"step": 115648, "time": 15711.996041536331, "episode/length": 229.0, "episode/score": 6.327219600050626, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.22721941602128481}
{"step": 116096, "time": 15768.833135843277, "episode/length": 170.0, "episode/score": 3.253233093621816, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.1532329994651036}
{"step": 116168, "time": 15779.108703613281, "episode/length": 171.0, "episode/score": 5.266844399802608, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.16684423253707337}
{"step": 116400, "time": 15808.871780633926, "episode/length": 123.0, "episode/score": 3.214257939395111, "episode/reward_rate": 0.9516129032258065, "episode/intrinsic_return": 0.11425786319546205}
{"step": 116440, "time": 15815.32268500328, "episode/length": 162.0, "episode/score": 2.2402740429654386, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.14027397744689551}
{"step": 117032, "time": 15889.718516111374, "episode/length": 211.0, "episode/score": 4.310108572067065, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.21010849371373297}
{"step": 117440, "time": 15941.021327733994, "episode/length": 276.0, "episode/score": 5.370224602172357, "episode/reward_rate": 0.9963898916967509, "episode/intrinsic_return": 0.2702244400290965}
{"step": 117448, "time": 15943.47662949562, "episode/length": 224.0, "episode/score": 5.344734786317531, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.24473457458134362}
{"step": 117624, "time": 15966.540335893631, "episode/length": 147.0, "episode/score": 4.238903000191499, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.138902930685731}
{"step": 117728, "time": 15980.694634914398, "episode/length": 203.0, "episode/score": 3.286966315526456, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.18696624182973665}
{"step": 117760, "time": 15986.162662029266, "episode/length": 198.0, "episode/score": 3.2692996390608187, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.16929949042173575}
{"step": 117760, "time": 15986.169464826584, "episode/length": 169.0, "episode/score": 3.277334049671481, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.17733393968228484}
{"step": 117824, "time": 15997.277042150497, "episode/length": 278.0, "episode/score": 4.382723375983687, "episode/reward_rate": 0.996415770609319, "episode/intrinsic_return": 0.2827231963781287}
{"step": 118208, "time": 16045.578186511993, "episode/length": 146.0, "episode/score": 3.2102325524911066, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.11023251427195646}
{"step": 118888, "time": 16130.508707761765, "episode/length": 180.0, "episode/score": 5.277809914046884, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.1778098226768634}
{"step": 118984, "time": 16144.380499839783, "episode/length": 152.0, "episode/score": 4.226160239046635, "episode/reward_rate": 0.9607843137254902, "episode/intrinsic_return": 0.12616020542589013}
{"step": 119016, "time": 16149.686137676239, "episode/length": 160.0, "episode/score": 4.258595878133519, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.15859574753881134}
{"step": 119072, "time": 16158.051102876663, "episode/length": 180.0, "episode/score": 5.283989140022527, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.18398894749486772}
{"step": 119088, "time": 16161.662569999695, "episode/length": 157.0, "episode/score": 3.2399692160034874, "episode/reward_rate": 0.9873417721518988, "episode/intrinsic_return": 0.13996912580489607}
{"step": 119200, "time": 16176.832148313522, "episode/length": 218.0, "episode/score": 3.2999427530106686, "episode/reward_rate": 0.9817351598173516, "episode/intrinsic_return": 0.19994267814979594}
{"step": 119584, "time": 16225.15331196785, "episode/length": 227.0, "episode/score": 3.3609627467583323, "episode/reward_rate": 0.9692982456140351, "episode/intrinsic_return": 0.26096276731436774}
{"step": 120016, "time": 16299.548128604889, "eval_episode/length": 140.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9929078014184397}
{"step": 120016, "time": 16301.362627744675, "eval_episode/length": 148.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9932885906040269}
{"step": 120016, "time": 16303.059998750687, "eval_episode/length": 153.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.9935064935064936}
{"step": 120016, "time": 16305.166971206665, "eval_episode/length": 166.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9700598802395209}
{"step": 120016, "time": 16307.483424425125, "eval_episode/length": 183.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9945652173913043}
{"step": 120016, "time": 16307.494440793991, "eval_episode/length": 183.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9836956521739131}
{"step": 120016, "time": 16311.822093009949, "eval_episode/length": 209.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9809523809523809}
{"step": 120016, "time": 16314.993944644928, "eval_episode/length": 100.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9900990099009901}
{"step": 120096, "time": 16324.79716539383, "episode/length": 235.0, "episode/score": 3.3679034925153246, "episode/reward_rate": 0.9661016949152542, "episode/intrinsic_return": 0.26790343977336306}
{"step": 120213, "time": 16341.447949886322, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.319877956224524, "train/action_min": 0.0, "train/action_std": 3.1893471583076147, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04623398320425464, "train/actor_opt_grad_steps": 28745.0, "train/actor_opt_loss": -6.532947539068434, "train/adv_mag": 0.7507292189351891, "train/adv_max": 0.7266095897749715, "train/adv_mean": 0.0032083164038963136, "train/adv_min": -0.515377089381218, "train/adv_std": 0.06789787605647808, "train/cont_avg": 0.9944378396739131, "train/cont_loss_mean": 0.00013730506401450927, "train/cont_loss_std": 0.0039349796718193665, "train/cont_neg_acc": 0.9987789988517761, "train/cont_neg_loss": 0.006902753986496164, "train/cont_pos_acc": 0.9999839563084685, "train/cont_pos_loss": 8.763255052916989e-05, "train/cont_pred": 0.9944233295062314, "train/cont_rate": 0.9944378396739131, "train/dyn_loss_mean": 6.275080115898795, "train/dyn_loss_std": 8.368244554685509, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.26103555864614, "train/extr_critic_critic_opt_grad_steps": 28745.0, "train/extr_critic_critic_opt_loss": 15145.058705205503, "train/extr_critic_mag": 5.494994679222936, "train/extr_critic_max": 5.494994679222936, "train/extr_critic_mean": 0.8564188141861687, "train/extr_critic_min": -0.6770629869854968, "train/extr_critic_std": 1.2277945565140767, "train/extr_return_normed_mag": 1.8185989889113798, "train/extr_return_normed_max": 1.8185989889113798, "train/extr_return_normed_mean": 0.32696737551494787, "train/extr_return_normed_min": -0.1804639322521246, "train/extr_return_normed_std": 0.34157943385450734, "train/extr_return_rate": 0.463822982719411, "train/extr_return_raw_mag": 6.380852473818737, "train/extr_return_raw_max": 6.380852473818737, "train/extr_return_raw_mean": 0.8683031525300897, "train/extr_return_raw_min": -1.0076301259839016, "train/extr_return_raw_std": 1.2628022325427637, "train/extr_reward_mag": 1.0161730996940448, "train/extr_reward_max": 1.0161730996940448, "train/extr_reward_mean": 0.018946701885990635, "train/extr_reward_min": -0.6508238341497339, "train/extr_reward_std": 0.1391328780952355, "train/image_loss_mean": 4.676830417436102, "train/image_loss_std": 9.088394457879273, "train/model_loss_mean": 8.508964214635933, "train/model_loss_std": 12.893194177876348, "train/model_opt_grad_norm": 49.028849777968034, "train/model_opt_grad_steps": 28716.755434782608, "train/model_opt_loss": 10794.077772057575, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1270.3804347826087, "train/policy_entropy_mag": 2.3458164658235465, "train/policy_entropy_max": 2.3458164658235465, "train/policy_entropy_mean": 0.5562683151144049, "train/policy_entropy_min": 0.07937517098110655, "train/policy_entropy_std": 0.4997895862097326, "train/policy_logprob_mag": 7.438382291275522, "train/policy_logprob_max": -0.009455694204560765, "train/policy_logprob_mean": -0.5573167577385902, "train/policy_logprob_min": -7.438382291275522, "train/policy_logprob_std": 1.0979654963897623, "train/policy_randomness_mag": 0.8279702702294225, "train/policy_randomness_max": 0.8279702702294225, "train/policy_randomness_mean": 0.19633830338716507, "train/policy_randomness_min": 0.028015951949941074, "train/policy_randomness_std": 0.1764037914412177, "train/post_ent_mag": 50.440104360165805, "train/post_ent_max": 50.440104360165805, "train/post_ent_mean": 32.10976468998453, "train/post_ent_min": 17.06400017116381, "train/post_ent_std": 5.50022362107816, "train/prior_ent_mag": 70.9380289160687, "train/prior_ent_max": 70.9380289160687, "train/prior_ent_mean": 38.4121907275656, "train/prior_ent_min": 21.07530949426734, "train/prior_ent_std": 8.91613980739013, "train/rep_loss_mean": 6.275080115898795, "train/rep_loss_std": 8.368244554685509, "train/reward_avg": 0.011453904517111368, "train/reward_loss_mean": 0.06694847219826086, "train/reward_loss_std": 0.16956493157245542, "train/reward_max_data": 1.0088587260764579, "train/reward_max_pred": 1.0082427664943363, "train/reward_neg_acc": 0.999130120743876, "train/reward_neg_loss": 0.05030210642144084, "train/reward_pos_acc": 0.8296212034057016, "train/reward_pos_loss": 0.786779657330202, "train/reward_pred": 0.01114292368267501, "train/reward_rate": 0.022625467051630436, "train_stats/sum_log_reward": 3.8073169836183873, "train_stats/max_log_achievement_collect_drink": 4.536585365853658, "train_stats/max_log_achievement_collect_sapling": 2.1219512195121952, "train_stats/max_log_achievement_collect_wood": 1.975609756097561, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0975609756097561, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.024390243902439025, "train_stats/max_log_achievement_place_plant": 1.7317073170731707, "train_stats/max_log_achievement_place_table": 0.4634146341463415, "train_stats/max_log_achievement_wake_up": 2.975609756097561, "train_stats/mean_log_entropy": 0.5344122248451885, "eval_stats/sum_log_reward": 3.7249999046325684, "eval_stats/max_log_achievement_collect_drink": 3.0, "eval_stats/max_log_achievement_collect_sapling": 3.125, "eval_stats/max_log_achievement_collect_wood": 1.75, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.125, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 3.0, "eval_stats/max_log_achievement_place_table": 0.5, "eval_stats/max_log_achievement_wake_up": 2.625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9912109375, "report/cont_loss_mean": 1.2889868230558932e-06, "report/cont_loss_std": 4.325103418523213e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 2.0242347090970725e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.1209276635781862e-06, "report/cont_pred": 0.9912099838256836, "report/cont_rate": 0.9912109375, "report/dyn_loss_mean": 4.831699371337891, "report/dyn_loss_std": 7.835860729217529, "report/image_loss_mean": 4.380064964294434, "report/image_loss_std": 5.408698081970215, "report/model_loss_mean": 7.350926876068115, "report/model_loss_std": 8.800865173339844, "report/post_ent_mag": 54.050987243652344, "report/post_ent_max": 54.050987243652344, "report/post_ent_mean": 31.661930084228516, "report/post_ent_min": 17.312341690063477, "report/post_ent_std": 5.465885162353516, "report/prior_ent_mag": 70.28498840332031, "report/prior_ent_max": 70.28498840332031, "report/prior_ent_mean": 37.18033218383789, "report/prior_ent_min": 20.794309616088867, "report/prior_ent_std": 8.510466575622559, "report/rep_loss_mean": 4.831699371337891, "report/rep_loss_std": 7.835860729217529, "report/reward_avg": 0.012519811280071735, "report/reward_loss_mean": 0.07184047996997833, "report/reward_loss_std": 0.18419332802295685, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0035812854766846, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.05296734720468521, "report/reward_pos_acc": 0.9599999785423279, "report/reward_pos_loss": 0.8260108828544617, "report/reward_pred": 0.011769047938287258, "report/reward_rate": 0.0244140625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 5.489281193149509e-06, "eval/cont_loss_std": 6.70415029162541e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00028012131224386394, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 4.4122925828560255e-06, "eval/cont_pred": 0.9960905313491821, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 21.9202880859375, "eval/dyn_loss_std": 13.648913383483887, "eval/image_loss_mean": 39.37090301513672, "eval/image_loss_std": 36.38774490356445, "eval/model_loss_mean": 52.59246063232422, "eval/model_loss_std": 42.15148162841797, "eval/post_ent_mag": 53.531219482421875, "eval/post_ent_max": 53.531219482421875, "eval/post_ent_mean": 32.47617721557617, "eval/post_ent_min": 20.317399978637695, "eval/post_ent_std": 5.5445170402526855, "eval/prior_ent_mag": 70.28498840332031, "eval/prior_ent_max": 70.28498840332031, "eval/prior_ent_mean": 41.99393081665039, "eval/prior_ent_min": 22.307586669921875, "eval/prior_ent_std": 9.523931503295898, "eval/rep_loss_mean": 21.9202880859375, "eval/rep_loss_std": 13.648913383483887, "eval/reward_avg": 0.011425781063735485, "eval/reward_loss_mean": 0.06937345117330551, "eval/reward_loss_std": 0.49385470151901245, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0018210411071777, "eval/reward_neg_acc": 0.997029721736908, "eval/reward_neg_loss": 0.038149960339069366, "eval/reward_pos_acc": 0.7142857313156128, "eval/reward_pos_loss": 2.321925163269043, "eval/reward_pred": 0.007494349963963032, "eval/reward_rate": 0.013671875, "replay/size": 119709.0, "replay/inserts": 7348.0, "replay/samples": 29392.0, "replay/insert_wait_avg": 1.6243157986395374e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.053278624524743e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 25480.0, "eval_replay/inserts": 2000.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2295246124267578e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0579824447631836e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0863876342773, "timer/env.step_count": 918.0, "timer/env.step_total": 87.84757566452026, "timer/env.step_frac": 0.08783998737581591, "timer/env.step_avg": 0.09569452686766913, "timer/env.step_min": 0.02292799949645996, "timer/env.step_max": 3.3700990676879883, "timer/replay._sample_count": 29392.0, "timer/replay._sample_total": 15.328968286514282, "timer/replay._sample_frac": 0.015327644167595599, "timer/replay._sample_avg": 0.000521535393525935, "timer/replay._sample_min": 0.0003731250762939453, "timer/replay._sample_max": 0.011775970458984375, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1168.0, "timer/agent.policy_total": 20.269222736358643, "timer/agent.policy_frac": 0.020267471877410372, "timer/agent.policy_avg": 0.017353786589348153, "timer/agent.policy_min": 0.009949207305908203, "timer/agent.policy_max": 0.13477015495300293, "timer/dataset_train_count": 1837.0, "timer/dataset_train_total": 0.30606770515441895, "timer/dataset_train_frac": 0.00030604126697337386, "timer/dataset_train_avg": 0.0001666127954025144, "timer/dataset_train_min": 0.000102996826171875, "timer/dataset_train_max": 0.0010800361633300781, "timer/agent.train_count": 1837.0, "timer/agent.train_total": 829.1989281177521, "timer/agent.train_frac": 0.8291273017716373, "timer/agent.train_avg": 0.45138754932920633, "timer/agent.train_min": 0.43961501121520996, "timer/agent.train_max": 0.9462704658508301, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4701673984527588, "timer/agent.report_frac": 0.00047012678531196527, "timer/agent.report_avg": 0.2350836992263794, "timer/agent.report_min": 0.2243204116821289, "timer/agent.report_max": 0.24584698677062988, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.956390380859375e-05, "timer/dataset_eval_frac": 2.9561350073494857e-08, "timer/dataset_eval_avg": 2.956390380859375e-05, "timer/dataset_eval_min": 2.956390380859375e-05, "timer/dataset_eval_max": 2.956390380859375e-05, "fps": 7.3472623981302965}
{"step": 120280, "time": 16349.607877254486, "episode/length": 173.0, "episode/score": 4.2593402511120075, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.15934006684983615}
{"step": 120296, "time": 16353.08423781395, "episode/length": 159.0, "episode/score": 4.2504343829969, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.15043419930225355}
{"step": 120536, "time": 16383.879105091095, "episode/length": 193.0, "episode/score": 5.296589854391641, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.19658972341858316}
{"step": 120536, "time": 16383.901210308075, "episode/length": 180.0, "episode/score": 5.265866391262534, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.16586620206726366}
{"step": 120568, "time": 16390.94714450836, "episode/length": 170.0, "episode/score": 4.265156652290898, "episode/reward_rate": 0.9649122807017544, "episode/intrinsic_return": 0.16515654963586712}
{"step": 120624, "time": 16399.253380298615, "episode/length": 40.0, "episode/score": 2.142734218228725, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.04273421656398568}
{"step": 121224, "time": 16474.095020532608, "episode/length": 140.0, "episode/score": 5.215196691384335, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.11519651183698443}
{"step": 121408, "time": 16498.01115179062, "episode/length": 227.0, "episode/score": 4.3547834257515206, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.25478336390006007}
{"step": 121512, "time": 16512.25919651985, "episode/length": 304.0, "episode/score": 5.4261024965308025, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.3261023497543647}
{"step": 121536, "time": 16516.623398780823, "episode/length": 38.0, "episode/score": 1.1389931347584934, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0389930949677364}
{"step": 121584, "time": 16523.96458053589, "episode/length": 130.0, "episode/score": 4.226901320553225, "episode/reward_rate": 0.9923664122137404, "episode/intrinsic_return": 0.12690108703282021}
{"step": 121744, "time": 16545.27819442749, "episode/length": 139.0, "episode/score": 4.22707303028983, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.1270728205327032}
{"step": 121752, "time": 16547.797587633133, "episode/length": 147.0, "episode/score": 4.232205566659104, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.1322054337215377}
{"step": 122064, "time": 16587.610269784927, "episode/length": 222.0, "episode/score": 4.319521431905741, "episode/reward_rate": 0.9775784753363229, "episode/intrinsic_return": 0.21952130911085987}
{"step": 122144, "time": 16599.06555700302, "episode/length": 49.0, "episode/score": 1.1579291249008747, "episode/reward_rate": 0.92, "episode/intrinsic_return": 0.05792904180361802}
{"step": 122488, "time": 16642.709295988083, "episode/length": 243.0, "episode/score": 6.344677749872062, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.24467754081342719}
{"step": 122624, "time": 16660.94966030121, "episode/length": 135.0, "episode/score": 3.2477294101017833, "episode/reward_rate": 0.9485294117647058, "episode/intrinsic_return": 0.14772935162636713}
{"step": 122848, "time": 16689.85019850731, "episode/length": 179.0, "episode/score": 3.2499870717520025, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.14998693510369776}
{"step": 122864, "time": 16693.336711645126, "episode/length": 168.0, "episode/score": 5.264211471283488, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.16421126536806696}
{"step": 123192, "time": 16736.214995145798, "episode/length": 200.0, "episode/score": 3.270364002363749, "episode/reward_rate": 0.9800995024875622, "episode/intrinsic_return": 0.17036399452899786}
{"step": 123280, "time": 16748.642334222794, "episode/length": 190.0, "episode/score": 5.298832330028745, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.19883214844412578}
{"step": 123512, "time": 16778.63356947899, "episode/length": 180.0, "episode/score": 5.265826280049623, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.16582616562936892}
{"step": 123632, "time": 16794.825139522552, "episode/length": 185.0, "episode/score": 5.290416850118163, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.19041665852182632}
{"step": 123840, "time": 16821.819181203842, "episode/length": 168.0, "episode/score": 3.2575726929744633, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.15757269365258253}
{"step": 123984, "time": 16841.104958295822, "episode/length": 139.0, "episode/score": 3.2224814511582736, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.12248127443399426}
{"step": 124032, "time": 16848.578013896942, "episode/length": 147.0, "episode/score": 2.2265145085766562, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.12651438624743605}
{"step": 124048, "time": 16852.078926086426, "episode/length": 177.0, "episode/score": 4.301515865835427, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.20151572581107757}
{"step": 124592, "time": 16920.257449626923, "episode/length": 163.0, "episode/score": 5.247169734588169, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.14716953625429596}
{"step": 124648, "time": 16928.563414812088, "episode/length": 181.0, "episode/score": 5.287057307359646, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.1870571257750271}
{"step": 124760, "time": 16943.666994333267, "episode/length": 155.0, "episode/score": 4.22301729889341, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.12301714478280701}
{"step": 125000, "time": 16974.511930942535, "episode/length": 50.0, "episode/score": 2.158465031138803, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.05846491113788943}
{"step": 125056, "time": 16982.943151712418, "episode/length": 151.0, "episode/score": 5.23582396438951, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.13582379089575625}
{"step": 125120, "time": 16992.279363393784, "episode/length": 185.0, "episode/score": 4.282471101907959, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.18247091880994049}
{"step": 125256, "time": 17010.3494887352, "episode/length": 158.0, "episode/score": 5.260800654597915, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.1608005680664064}
{"step": 125440, "time": 17034.471929311752, "episode/length": 175.0, "episode/score": 5.261513239388478, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.1615131154876508}
{"step": 125472, "time": 17039.909423351288, "episode/length": 177.0, "episode/score": 5.272195136060418, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.17219498171698433}
{"step": 125648, "time": 17062.801394462585, "episode/length": 80.0, "episode/score": 3.191845816626028, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.09184572875574304}
{"step": 125832, "time": 17086.838218927383, "episode/length": 133.0, "episode/score": 4.247856511844475, "episode/reward_rate": 0.9925373134328358, "episode/intrinsic_return": 0.14785641557773488}
{"step": 125968, "time": 17105.162019729614, "episode/length": 164.0, "episode/score": 4.266913919889248, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.1669137970943666}
{"step": 126256, "time": 17141.774923086166, "episode/length": 35.0, "episode/score": 2.1429167325841263, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.04291666590142995}
{"step": 126360, "time": 17156.005356550217, "episode/length": 137.0, "episode/score": 4.224996952893889, "episode/reward_rate": 0.9927536231884058, "episode/intrinsic_return": 0.12499678993572161}
{"step": 126584, "time": 17185.09077525139, "episode/length": 182.0, "episode/score": 5.292992917277843, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.19299273569322395}
{"step": 126856, "time": 17220.021334171295, "episode/length": 224.0, "episode/score": 1.3200174832586526, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.22001744521412547}
{"step": 127040, "time": 17243.95654320717, "episode/length": 97.0, "episode/score": 3.204962853745201, "episode/reward_rate": 0.9489795918367347, "episode/intrinsic_return": 0.10496276191679499}
{"step": 127128, "time": 17256.398265123367, "episode/length": 184.0, "episode/score": 2.303648560516649, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.20364849697716636}
{"step": 127392, "time": 17290.247710227966, "episode/length": 239.0, "episode/score": 4.347666192933502, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.24766608445770544}
{"step": 127424, "time": 17295.523067474365, "episode/length": 36.0, "episode/score": 2.138753097940935, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.038752975611714646}
{"step": 127456, "time": 17300.803634643555, "episode/length": 251.0, "episode/score": 3.3752151462808797, "episode/reward_rate": 0.9841269841269841, "episode/intrinsic_return": 0.2752150509600142}
{"step": 127528, "time": 17311.103053569794, "episode/length": 145.0, "episode/score": 5.272346809331793, "episode/reward_rate": 0.9657534246575342, "episode/intrinsic_return": 0.17234672280028462}
{"step": 127757, "time": 17341.84892463684, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.266910290591931, "train/action_min": 0.0, "train/action_std": 3.1587052698488587, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0472424224255577, "train/actor_opt_grad_steps": 30610.0, "train/actor_opt_loss": -5.774962401263928, "train/adv_mag": 0.8506025487468356, "train/adv_max": 0.8338153430078395, "train/adv_mean": 0.0032500280984133793, "train/adv_min": -0.5250478809472745, "train/adv_std": 0.06925941934740101, "train/cont_avg": 0.9944351438492064, "train/cont_loss_mean": 0.0002211030175662139, "train/cont_loss_std": 0.006793173010215642, "train/cont_neg_acc": 0.9965041579392852, "train/cont_neg_loss": 0.020314496859901693, "train/cont_pos_acc": 0.99996879176488, "train/cont_pos_loss": 8.826870527930626e-05, "train/cont_pred": 0.9944271432659614, "train/cont_rate": 0.9944351438492064, "train/dyn_loss_mean": 6.322470788602476, "train/dyn_loss_std": 8.372594341399177, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.2040265830105574, "train/extr_critic_critic_opt_grad_steps": 30610.0, "train/extr_critic_critic_opt_loss": 15092.031730530754, "train/extr_critic_mag": 5.63767984430626, "train/extr_critic_max": 5.63767984430626, "train/extr_critic_mean": 0.8832717476383088, "train/extr_critic_min": -0.6667577160729302, "train/extr_critic_std": 1.1895963729373993, "train/extr_return_normed_mag": 1.891984609699754, "train/extr_return_normed_max": 1.891984609699754, "train/extr_return_normed_mean": 0.3289885099129702, "train/extr_return_normed_min": -0.19870543621835254, "train/extr_return_normed_std": 0.3375655925147748, "train/extr_return_rate": 0.47917082543095585, "train/extr_return_raw_mag": 6.573187141822129, "train/extr_return_raw_max": 6.573187141822129, "train/extr_return_raw_mean": 0.8950592659453236, "train/extr_return_raw_min": -1.0199360913700528, "train/extr_return_raw_std": 1.2258486082314184, "train/extr_reward_mag": 1.0106508454317769, "train/extr_reward_max": 1.0106508454317769, "train/extr_reward_mean": 0.020079166924078313, "train/extr_reward_min": -0.665513103601163, "train/extr_reward_std": 0.14287863005563695, "train/image_loss_mean": 4.602686917340314, "train/image_loss_std": 8.993589560190836, "train/model_loss_mean": 8.463375724812664, "train/model_loss_std": 12.756498079451303, "train/model_opt_grad_norm": 46.2838093169192, "train/model_opt_grad_steps": 30579.95238095238, "train/model_opt_loss": 11008.795738260582, "train/model_opt_model_opt_grad_overflow": 0.005291005291005291, "train/model_opt_model_opt_grad_scale": 1296.2962962962963, "train/policy_entropy_mag": 2.3602499444648704, "train/policy_entropy_max": 2.3602499444648704, "train/policy_entropy_mean": 0.5234786084404698, "train/policy_entropy_min": 0.07937509988350842, "train/policy_entropy_std": 0.4946317273788351, "train/policy_logprob_mag": 7.438382981315492, "train/policy_logprob_max": -0.00945566695124384, "train/policy_logprob_mean": -0.5238432901561576, "train/policy_logprob_min": -7.438382981315492, "train/policy_logprob_std": 1.0780860630292741, "train/policy_randomness_mag": 0.8330646554629008, "train/policy_randomness_max": 0.8330646554629008, "train/policy_randomness_mean": 0.18476497709120393, "train/policy_randomness_min": 0.02801592697305654, "train/policy_randomness_std": 0.1745832933004571, "train/post_ent_mag": 51.259437076629155, "train/post_ent_max": 51.259437076629155, "train/post_ent_mean": 32.72902782379635, "train/post_ent_min": 17.293615633848482, "train/post_ent_std": 5.591693701567473, "train/prior_ent_mag": 71.1599835592603, "train/prior_ent_max": 71.1599835592603, "train/prior_ent_mean": 39.08243645562066, "train/prior_ent_min": 21.589002235856636, "train/prior_ent_std": 8.839742567173388, "train/rep_loss_mean": 6.322470788602476, "train/rep_loss_std": 8.372594341399177, "train/reward_avg": 0.012908675613019753, "train/reward_loss_mean": 0.06698528562904035, "train/reward_loss_std": 0.1641140025128763, "train/reward_max_data": 1.0060119345074607, "train/reward_max_pred": 1.0065725240757857, "train/reward_neg_acc": 0.9992634786499871, "train/reward_neg_loss": 0.04985153515424047, "train/reward_pos_acc": 0.8502284420861138, "train/reward_pos_loss": 0.7652345220878641, "train/reward_pred": 0.012647080127391274, "train/reward_rate": 0.023933531746031748, "train_stats/sum_log_reward": 3.875510120878414, "train_stats/max_log_achievement_collect_drink": 3.63265306122449, "train_stats/max_log_achievement_collect_sapling": 2.4285714285714284, "train_stats/max_log_achievement_collect_wood": 1.7551020408163265, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.10204081632653061, "train_stats/max_log_achievement_eat_cow": 0.02040816326530612, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 2.0, "train_stats/max_log_achievement_place_table": 0.46938775510204084, "train_stats/max_log_achievement_wake_up": 2.4081632653061225, "train_stats/mean_log_entropy": 0.481431427962926, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 0.00016308511840179563, "report/cont_loss_std": 0.003486638655886054, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.01667003147304058, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 3.3109150535892695e-05, "report/cont_pred": 0.9922798275947571, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 7.055617332458496, "report/dyn_loss_std": 8.882316589355469, "report/image_loss_mean": 3.9848108291625977, "report/image_loss_std": 6.725730895996094, "report/model_loss_mean": 8.295757293701172, "report/model_loss_std": 10.84582805633545, "report/post_ent_mag": 53.75851821899414, "report/post_ent_max": 53.75851821899414, "report/post_ent_mean": 33.10125732421875, "report/post_ent_min": 15.728869438171387, "report/post_ent_std": 6.428916931152344, "report/prior_ent_mag": 71.62213134765625, "report/prior_ent_max": 71.62213134765625, "report/prior_ent_mean": 40.18885040283203, "report/prior_ent_min": 21.972442626953125, "report/prior_ent_std": 9.44188117980957, "report/rep_loss_mean": 7.055617332458496, "report/rep_loss_std": 8.882316589355469, "report/reward_avg": 0.014735154807567596, "report/reward_loss_mean": 0.07741273939609528, "report/reward_loss_std": 0.18088971078395844, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0042412281036377, "report/reward_neg_acc": 0.9989939332008362, "report/reward_neg_loss": 0.055917058140039444, "report/reward_pos_acc": 0.7333333492279053, "report/reward_pos_loss": 0.7896361351013184, "report/reward_pred": 0.014139769598841667, "report/reward_rate": 0.029296875, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 9.749370292411186e-06, "eval/cont_loss_std": 0.0001807319204090163, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0017787115648388863, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 4.551635356619954e-06, "eval/cont_pred": 0.9970710873603821, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 24.720705032348633, "eval/dyn_loss_std": 13.49084186553955, "eval/image_loss_mean": 34.129520416259766, "eval/image_loss_std": 37.115501403808594, "eval/model_loss_mean": 49.08026123046875, "eval/model_loss_std": 42.44690704345703, "eval/post_ent_mag": 50.16660690307617, "eval/post_ent_max": 50.16660690307617, "eval/post_ent_mean": 34.222869873046875, "eval/post_ent_min": 19.42969512939453, "eval/post_ent_std": 5.399021148681641, "eval/prior_ent_mag": 71.62213134765625, "eval/prior_ent_max": 71.62213134765625, "eval/prior_ent_mean": 46.07817840576172, "eval/prior_ent_min": 25.178020477294922, "eval/prior_ent_std": 8.44415283203125, "eval/rep_loss_mean": 24.720705032348633, "eval/rep_loss_std": 13.49084186553955, "eval/reward_avg": 0.0185546875, "eval/reward_loss_mean": 0.11830772459506989, "eval/reward_loss_std": 0.7839487195014954, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0059905052185059, "eval/reward_neg_acc": 0.9960039854049683, "eval/reward_neg_loss": 0.047807928174734116, "eval/reward_pos_acc": 0.6521739363670349, "eval/reward_pos_loss": 3.18658185005188, "eval/reward_pred": 0.012347344309091568, "eval/reward_rate": 0.0224609375, "replay/size": 127253.0, "replay/inserts": 7544.0, "replay/samples": 30176.0, "replay/insert_wait_avg": 1.6183640772312847e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.974570528194229e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 25480.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 1.1026859283447266e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3862442970276, "timer/env.step_count": 943.0, "timer/env.step_total": 99.35103940963745, "timer/env.step_frac": 0.09931268045318989, "timer/env.step_avg": 0.10535635144182126, "timer/env.step_min": 0.023083209991455078, "timer/env.step_max": 3.182311773300171, "timer/replay._sample_count": 30176.0, "timer/replay._sample_total": 15.775824308395386, "timer/replay._sample_frac": 0.015769733338827616, "timer/replay._sample_avg": 0.0005227937535921058, "timer/replay._sample_min": 0.0003910064697265625, "timer/replay._sample_max": 0.011229515075683594, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 943.0, "timer/agent.policy_total": 15.405866384506226, "timer/agent.policy_frac": 0.015399918253905963, "timer/agent.policy_avg": 0.016337079941151883, "timer/agent.policy_min": 0.014729499816894531, "timer/agent.policy_max": 0.04698896408081055, "timer/dataset_train_count": 1886.0, "timer/dataset_train_total": 0.31574106216430664, "timer/dataset_train_frac": 0.0003156191560652438, "timer/dataset_train_avg": 0.00016741307643918698, "timer/dataset_train_min": 0.00010085105895996094, "timer/dataset_train_max": 0.0012247562408447266, "timer/agent.train_count": 1886.0, "timer/agent.train_total": 852.020473241806, "timer/agent.train_frac": 0.8516915122523717, "timer/agent.train_avg": 0.45176059026606896, "timer/agent.train_min": 0.4402618408203125, "timer/agent.train_max": 0.9750876426696777, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4767458438873291, "timer/agent.report_frac": 0.00047656177461970087, "timer/agent.report_avg": 0.23837292194366455, "timer/agent.report_min": 0.23237919807434082, "timer/agent.report_max": 0.24436664581298828, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8848648071289062e-05, "timer/dataset_eval_frac": 2.8837509747608573e-08, "timer/dataset_eval_avg": 2.8848648071289062e-05, "timer/dataset_eval_min": 2.8848648071289062e-05, "timer/dataset_eval_max": 2.8848648071289062e-05, "fps": 7.540976727992063}
{"step": 127816, "time": 17348.924285888672, "episode/length": 119.0, "episode/score": 3.235327724213221, "episode/reward_rate": 0.95, "episode/intrinsic_return": 0.1353276209761134}
{"step": 127920, "time": 17363.17830514908, "episode/length": 260.0, "episode/score": 5.396868503998576, "episode/reward_rate": 0.9808429118773946, "episode/intrinsic_return": 0.29686835256552513}
{"step": 128064, "time": 17382.51370882988, "episode/length": 184.0, "episode/score": 4.286022788670834, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.18602274755585313}
{"step": 128192, "time": 17399.649653673172, "episode/length": 143.0, "episode/score": 4.2332508632816825, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.1332507425240692}
{"step": 128624, "time": 17453.62293291092, "episode/length": 87.0, "episode/score": 2.176959538923711, "episode/reward_rate": 0.9886363636363636, "episode/intrinsic_return": 0.07695948516311546}
{"step": 128720, "time": 17466.993886709213, "episode/length": 148.0, "episode/score": 5.2346658263136305, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.1346655879183345}
{"step": 129160, "time": 17522.314894914627, "episode/length": 216.0, "episode/score": 5.341001521856015, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.24100137507957697}
{"step": 129224, "time": 17531.552317857742, "episode/length": 144.0, "episode/score": 3.2570382937410614, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.15703815685992595}
{"step": 129232, "time": 17534.14507174492, "episode/length": 176.0, "episode/score": 5.29823573758631, "episode/reward_rate": 0.96045197740113, "episode/intrinsic_return": 0.1982356448847895}
{"step": 129448, "time": 17562.22761273384, "episode/length": 256.0, "episode/score": 6.394839427154238, "episode/reward_rate": 0.980544747081712, "episode/intrinsic_return": 0.29483922589543}
{"step": 129608, "time": 17583.35851764679, "episode/length": 268.0, "episode/score": 6.379455947109818, "episode/reward_rate": 0.9962825278810409, "episode/intrinsic_return": 0.2794557364213688}
{"step": 129720, "time": 17598.570860385895, "episode/length": 190.0, "episode/score": 4.286888123857352, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.18688802152246353}
{"step": 129880, "time": 17619.66875886917, "episode/length": 144.0, "episode/score": 4.236635047489472, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.13663484006065119}
{"step": 130000, "time": 17650.275522232056, "eval_episode/length": 34.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 130000, "time": 17656.57348227501, "eval_episode/length": 142.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.993006993006993}
{"step": 130000, "time": 17658.1414270401, "eval_episode/length": 143.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9930555555555556}
{"step": 130000, "time": 17659.963429689407, "eval_episode/length": 152.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9934640522875817}
{"step": 130000, "time": 17661.68196249008, "eval_episode/length": 155.0, "eval_episode/score": 4.099999971687794, "eval_episode/reward_rate": 0.9935897435897436}
{"step": 130000, "time": 17663.849132061005, "eval_episode/length": 168.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9940828402366864}
{"step": 130000, "time": 17666.171155929565, "eval_episode/length": 186.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9679144385026738}
{"step": 130000, "time": 17666.181859731674, "eval_episode/length": 42.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9767441860465116}
{"step": 130024, "time": 17669.21718764305, "episode/length": 174.0, "episode/score": 5.28385714551905, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.18385690980130676}
{"step": 130192, "time": 17691.206062555313, "episode/length": 58.0, "episode/score": 2.1490125115155934, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.049012391165433655}
{"step": 130208, "time": 17694.843366146088, "episode/length": 121.0, "episode/score": 5.235948658068992, "episode/reward_rate": 0.9508196721311475, "episode/intrinsic_return": 0.13594851245670725}
{"step": 130624, "time": 17747.105721712112, "episode/length": 182.0, "episode/score": 3.263944110198281, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.1639439646514802}
{"step": 130880, "time": 17780.438588619232, "episode/length": 158.0, "episode/score": 6.2569375133016365, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.15693728483074665}
{"step": 130920, "time": 17786.866342782974, "episode/length": 183.0, "episode/score": 6.299698026447913, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.19969787092577462}
{"step": 130944, "time": 17792.03084897995, "episode/length": 132.0, "episode/score": 4.249917312409025, "episode/reward_rate": 0.9924812030075187, "episode/intrinsic_return": 0.14991718390979258}
{"step": 131608, "time": 17875.49904847145, "episode/length": 176.0, "episode/score": 4.268104588127244, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.1681045401655865}
{"step": 131808, "time": 17901.386164426804, "episode/length": 222.0, "episode/score": 4.343940038319488, "episode/reward_rate": 0.9730941704035875, "episode/intrinsic_return": 0.24393991901706613}
{"step": 131944, "time": 17919.57940864563, "episode/length": 216.0, "episode/score": 3.33584222791319, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.23584214411744142}
{"step": 132104, "time": 17940.495012760162, "episode/length": 184.0, "episode/score": 3.266209236632676, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.16620904398860148}
{"step": 132208, "time": 17954.616810321808, "episode/length": 165.0, "episode/score": 1.2788330923681315, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.17883302533618917}
{"step": 132248, "time": 17961.024507045746, "episode/length": 37.0, "episode/score": 0.14298615933512338, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.04298611034755595}
{"step": 132368, "time": 17977.21161365509, "episode/length": 180.0, "episode/score": 5.289139517620015, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.18913933487124268}
{"step": 132648, "time": 18012.476408481598, "episode/length": 34.0, "episode/score": -0.8581250188872218, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.041874999180436134}
{"step": 132776, "time": 18029.576639413834, "episode/length": 145.0, "episode/score": 3.233423523509373, "episode/reward_rate": 0.9657534246575342, "episode/intrinsic_return": 0.1334235250023994}
{"step": 133184, "time": 18080.59934401512, "episode/length": 494.0, "episode/score": 7.562040325923817, "episode/reward_rate": 0.5818181818181818, "episode/intrinsic_return": 0.46204012070688805}
{"step": 133344, "time": 18101.50620150566, "episode/length": 191.0, "episode/score": 2.2670558577003703, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.16705573391595863}
{"step": 133400, "time": 18109.78444647789, "episode/length": 161.0, "episode/score": 6.24251570130923, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.14251553672124828}
{"step": 133464, "time": 18119.60593032837, "episode/length": 151.0, "episode/score": 3.2595650918715364, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.15956492833129232}
{"step": 133960, "time": 18181.448355436325, "episode/length": 147.0, "episode/score": 3.237967200297817, "episode/reward_rate": 0.9527027027027027, "episode/intrinsic_return": 0.13796710614110452}
{"step": 134112, "time": 18201.42912006378, "episode/length": 182.0, "episode/score": 4.301908673331582, "episode/reward_rate": 0.9672131147540983, "episode/intrinsic_return": 0.20190869628868313}
{"step": 134376, "time": 18235.18245434761, "episode/length": 428.0, "episode/score": 5.53052562287121, "episode/reward_rate": 0.8344988344988346, "episode/intrinsic_return": 0.4305254739992961}
{"step": 134416, "time": 18241.706246376038, "episode/length": 275.0, "episode/score": 5.401777172869743, "episode/reward_rate": 0.9818840579710145, "episode/intrinsic_return": 0.3017770357557765}
{"step": 134600, "time": 18265.602323055267, "episode/length": 149.0, "episode/score": 5.261244324473864, "episode/reward_rate": 0.9733333333333334, "episode/intrinsic_return": 0.1612441718766604}
{"step": 134704, "time": 18279.787497758865, "episode/length": 189.0, "episode/score": 5.282356375725385, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.18235624242402082}
{"step": 134808, "time": 18293.91042637825, "episode/length": 182.0, "episode/score": 5.31870847241953, "episode/reward_rate": 0.9672131147540983, "episode/intrinsic_return": 0.21870832913555205}
{"step": 135168, "time": 18339.16347503662, "episode/length": 212.0, "episode/score": 4.327164516873154, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.22716439920054654}
{"step": 135173, "time": 18342.17135167122, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.196313146642736, "train/action_min": 0.0, "train/action_std": 3.120215352805885, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04812739190418978, "train/actor_opt_grad_steps": 32480.0, "train/actor_opt_loss": -6.4405159475030125, "train/adv_mag": 0.8003931019757246, "train/adv_max": 0.7745334686459722, "train/adv_mean": 0.0034566221764622683, "train/adv_min": -0.5524430867787954, "train/adv_std": 0.06992676135253262, "train/cont_avg": 0.994383445945946, "train/cont_loss_mean": 9.294699154738e-05, "train/cont_loss_std": 0.002696642579836235, "train/cont_neg_acc": 0.9977678578832875, "train/cont_neg_loss": 0.006465639792346021, "train/cont_pos_acc": 0.9999734108512466, "train/cont_pos_loss": 5.240174376564409e-05, "train/cont_pred": 0.9943731581842578, "train/cont_rate": 0.994383445945946, "train/dyn_loss_mean": 6.367443631146405, "train/dyn_loss_std": 8.381256031345677, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.2227981615710903, "train/extr_critic_critic_opt_grad_steps": 32480.0, "train/extr_critic_critic_opt_loss": 15259.430125633446, "train/extr_critic_mag": 6.000933415180928, "train/extr_critic_max": 6.000933415180928, "train/extr_critic_mean": 0.9414436635133382, "train/extr_critic_min": -0.655406152235495, "train/extr_critic_std": 1.248942349408124, "train/extr_return_normed_mag": 1.8982453146496334, "train/extr_return_normed_max": 1.8982453146496334, "train/extr_return_normed_mean": 0.3271233598928194, "train/extr_return_normed_min": -0.18886830790622813, "train/extr_return_normed_std": 0.34011230919812174, "train/extr_return_rate": 0.4908206921171498, "train/extr_return_raw_mag": 6.906567753972234, "train/extr_return_raw_max": 6.906567753972234, "train/extr_return_raw_mean": 0.9544780927735406, "train/extr_return_raw_min": -1.001511868592855, "train/extr_return_raw_std": 1.2891703563767511, "train/extr_reward_mag": 1.0112835033519847, "train/extr_reward_max": 1.0112835033519847, "train/extr_reward_mean": 0.021458466773903048, "train/extr_reward_min": -0.6599716128529729, "train/extr_reward_std": 0.14609061765509682, "train/image_loss_mean": 4.477792678008209, "train/image_loss_std": 8.689599248525258, "train/model_loss_mean": 8.366329907082223, "train/model_loss_std": 12.479025345879633, "train/model_opt_grad_norm": 50.668008721841346, "train/model_opt_grad_steps": 32447.94054054054, "train/model_opt_loss": 8684.698999683276, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1064.1891891891892, "train/policy_entropy_mag": 2.407306855433696, "train/policy_entropy_max": 2.407306855433696, "train/policy_entropy_mean": 0.5215795354263203, "train/policy_entropy_min": 0.07937511668817417, "train/policy_entropy_std": 0.5078099640640052, "train/policy_logprob_mag": 7.4383830250920475, "train/policy_logprob_max": -0.009455671629591569, "train/policy_logprob_mean": -0.521422778754621, "train/policy_logprob_min": -7.4383830250920475, "train/policy_logprob_std": 1.079847006862228, "train/policy_randomness_mag": 0.8496736784239073, "train/policy_randomness_max": 0.8496736784239073, "train/policy_randomness_mean": 0.18409468732975626, "train/policy_randomness_min": 0.02801593284349184, "train/policy_randomness_std": 0.17923463220531877, "train/post_ent_mag": 52.40499772767763, "train/post_ent_max": 52.40499772767763, "train/post_ent_mean": 33.34192540967786, "train/post_ent_min": 17.40467226698592, "train/post_ent_std": 5.6840341026718555, "train/prior_ent_mag": 71.44988898199958, "train/prior_ent_max": 71.44988898199958, "train/prior_ent_mean": 39.75114713101774, "train/prior_ent_min": 21.95919663712785, "train/prior_ent_std": 8.745395724837845, "train/rep_loss_mean": 6.367443631146405, "train/rep_loss_std": 8.381256031345677, "train/reward_avg": 0.013888942879448469, "train/reward_loss_mean": 0.06797818456952637, "train/reward_loss_std": 0.17195710805622308, "train/reward_max_data": 1.0077365166432148, "train/reward_max_pred": 1.0069405111106666, "train/reward_neg_acc": 0.9989714873803629, "train/reward_neg_loss": 0.050181363966013935, "train/reward_pos_acc": 0.8494907897871894, "train/reward_pos_loss": 0.7762728884413436, "train/reward_pred": 0.013672508339624146, "train/reward_rate": 0.024451013513513514, "train_stats/sum_log_reward": 4.075609686898022, "train_stats/max_log_achievement_collect_drink": 4.780487804878049, "train_stats/max_log_achievement_collect_sapling": 2.024390243902439, "train_stats/max_log_achievement_collect_wood": 2.6097560975609757, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.17073170731707318, "train_stats/max_log_achievement_eat_cow": 0.14634146341463414, "train_stats/max_log_achievement_make_wood_sword": 0.0975609756097561, "train_stats/max_log_achievement_place_plant": 1.6829268292682926, "train_stats/max_log_achievement_place_table": 0.9024390243902439, "train_stats/max_log_achievement_wake_up": 2.926829268292683, "train_stats/mean_log_entropy": 0.5151611617425593, "eval_stats/sum_log_reward": 3.3499999195337296, "eval_stats/max_log_achievement_collect_drink": 3.75, "eval_stats/max_log_achievement_collect_sapling": 1.5, "eval_stats/max_log_achievement_collect_wood": 1.625, "eval_stats/max_log_achievement_defeat_skeleton": 0.125, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 1.0, "eval_stats/max_log_achievement_place_table": 0.5, "eval_stats/max_log_achievement_wake_up": 1.75, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 1.6931971913436428e-05, "report/cont_loss_std": 0.00014327398093882948, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00023863508249633014, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.562527359055821e-05, "report/cont_pred": 0.9941264986991882, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 5.050717353820801, "report/dyn_loss_std": 7.564901351928711, "report/image_loss_mean": 3.2059054374694824, "report/image_loss_std": 6.566725254058838, "report/model_loss_mean": 6.299853801727295, "report/model_loss_std": 10.037557601928711, "report/post_ent_mag": 51.43028259277344, "report/post_ent_max": 51.43028259277344, "report/post_ent_mean": 33.08464813232422, "report/post_ent_min": 19.50855827331543, "report/post_ent_std": 5.276785373687744, "report/prior_ent_mag": 71.96019744873047, "report/prior_ent_max": 71.96019744873047, "report/prior_ent_mean": 38.5814208984375, "report/prior_ent_min": 23.274532318115234, "report/prior_ent_std": 8.234195709228516, "report/rep_loss_mean": 5.050717353820801, "report/rep_loss_std": 7.564901351928711, "report/reward_avg": 0.0042780302464962006, "report/reward_loss_mean": 0.06350080668926239, "report/reward_loss_std": 0.20306527614593506, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.004157304763794, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.055044181644916534, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6735857129096985, "report/reward_pred": 0.004877680912613869, "report/reward_rate": 0.013671875, "eval/cont_avg": 0.990234375, "eval/cont_loss_mean": 0.004549709614366293, "eval/cont_loss_std": 0.11764176189899445, "eval/cont_neg_acc": 0.9000000357627869, "eval/cont_neg_loss": 0.10121752321720123, "eval/cont_pos_acc": 0.9990138411521912, "eval/cont_pos_loss": 0.0035963784903287888, "eval/cont_pred": 0.989892840385437, "eval/cont_rate": 0.990234375, "eval/dyn_loss_mean": 24.44092559814453, "eval/dyn_loss_std": 12.993305206298828, "eval/image_loss_mean": 30.246292114257812, "eval/image_loss_std": 31.334308624267578, "eval/model_loss_mean": 45.06285858154297, "eval/model_loss_std": 36.56160354614258, "eval/post_ent_mag": 47.20764923095703, "eval/post_ent_max": 47.20764923095703, "eval/post_ent_mean": 32.36444091796875, "eval/post_ent_min": 19.302480697631836, "eval/post_ent_std": 4.953290939331055, "eval/prior_ent_mag": 71.96019744873047, "eval/prior_ent_max": 71.96019744873047, "eval/prior_ent_mean": 44.66824722290039, "eval/prior_ent_min": 26.982789993286133, "eval/prior_ent_std": 8.652833938598633, "eval/rep_loss_mean": 24.44092559814453, "eval/rep_loss_std": 12.993305206298828, "eval/reward_avg": 0.01416015625, "eval/reward_loss_mean": 0.14746034145355225, "eval/reward_loss_std": 0.8837979435920715, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0041425228118896, "eval/reward_neg_acc": 0.9970059990882874, "eval/reward_neg_loss": 0.06203547865152359, "eval/reward_pos_acc": 0.5909091234207153, "eval/reward_pos_loss": 4.038175106048584, "eval/reward_pred": 0.00597523245960474, "eval/reward_rate": 0.021484375, "replay/size": 134669.0, "replay/inserts": 7416.0, "replay/samples": 29664.0, "replay/insert_wait_avg": 1.6585458572371236e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.044537345696936e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 26976.0, "eval_replay/inserts": 1496.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1987864652419473e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.08970832824707e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3072338104248, "timer/env.step_count": 927.0, "timer/env.step_total": 88.84951710700989, "timer/env.step_frac": 0.08882222791547699, "timer/env.step_avg": 0.09584629677131595, "timer/env.step_min": 0.023056983947753906, "timer/env.step_max": 2.2512125968933105, "timer/replay._sample_count": 29664.0, "timer/replay._sample_total": 15.414337635040283, "timer/replay._sample_frac": 0.015409603283906234, "timer/replay._sample_avg": 0.0005196311230798369, "timer/replay._sample_min": 0.0003800392150878906, "timer/replay._sample_max": 0.025847673416137695, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1114.0, "timer/agent.policy_total": 18.041681051254272, "timer/agent.policy_frac": 0.01803613973931681, "timer/agent.policy_avg": 0.016195404893405988, "timer/agent.policy_min": 0.00986170768737793, "timer/agent.policy_max": 0.057457923889160156, "timer/dataset_train_count": 1854.0, "timer/dataset_train_total": 0.3089909553527832, "timer/dataset_train_frac": 0.0003088960520416893, "timer/dataset_train_avg": 0.00016666178821617218, "timer/dataset_train_min": 0.00010156631469726562, "timer/dataset_train_max": 0.0007679462432861328, "timer/agent.train_count": 1854.0, "timer/agent.train_total": 833.39737200737, "timer/agent.train_frac": 0.8331414027995652, "timer/agent.train_avg": 0.44951314563504313, "timer/agent.train_min": 0.43576550483703613, "timer/agent.train_max": 0.959801435470581, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4794623851776123, "timer/agent.report_frac": 0.00047931512336586637, "timer/agent.report_avg": 0.23973119258880615, "timer/agent.report_min": 0.23208260536193848, "timer/agent.report_max": 0.24737977981567383, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.47955322265625e-05, "timer/dataset_eval_frac": 2.4787916540511268e-08, "timer/dataset_eval_avg": 2.47955322265625e-05, "timer/dataset_eval_min": 2.47955322265625e-05, "timer/dataset_eval_max": 2.47955322265625e-05, "fps": 7.413613000240438}
{"step": 135456, "time": 18376.414788246155, "episode/length": 186.0, "episode/score": 3.2855503739524465, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.1855502229850572}
{"step": 135544, "time": 18389.28229856491, "episode/length": 140.0, "episode/score": 3.2517434896901705, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.15174335090273416}
{"step": 135576, "time": 18395.158883094788, "episode/length": 182.0, "episode/score": 5.266899951018786, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.16689976827001374}
{"step": 135856, "time": 18430.403953790665, "episode/length": 184.0, "episode/score": 5.281361949931352, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.18136191882808816}
{"step": 136152, "time": 18468.026094198227, "episode/length": 180.0, "episode/score": 4.299986044618436, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.19998592298770745}
{"step": 136176, "time": 18472.40985417366, "episode/length": 170.0, "episode/score": 4.269335530995249, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.1693353780487996}
{"step": 136496, "time": 18512.80901145935, "episode/length": 236.0, "episode/score": 4.357301471782648, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.25730134782361347}
{"step": 136560, "time": 18521.936718940735, "episode/length": 173.0, "episode/score": 5.281707583096249, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.18170743049904559}
{"step": 136680, "time": 18537.839059591293, "episode/length": 141.0, "episode/score": 3.2473038283724236, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.1473036236502594}
{"step": 136880, "time": 18563.504360437393, "episode/length": 177.0, "episode/score": 6.29164122391785, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.1916411886672904}
{"step": 137240, "time": 18608.506513118744, "episode/length": 132.0, "episode/score": 4.240629578933294, "episode/reward_rate": 0.9624060150375939, "episode/intrinsic_return": 0.14062942831515102}
{"step": 137336, "time": 18621.562140226364, "episode/length": 184.0, "episode/score": 4.287466336424131, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.18746621362924998}
{"step": 137560, "time": 18650.065175533295, "episode/length": 247.0, "episode/score": 5.372030827628123, "episode/reward_rate": 0.9959677419354839, "episode/intrinsic_return": 0.2720306033190809}
{"step": 137968, "time": 18701.035541534424, "episode/length": 183.0, "episode/score": 5.2632730959121545, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.16327294331495068}
{"step": 138112, "time": 18719.96243238449, "episode/length": 178.0, "episode/score": 4.26355427913586, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.16355409953030176}
{"step": 138200, "time": 18732.11997294426, "episode/length": 164.0, "episode/score": 5.266641515685478, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.16664133410085924}
{"step": 138328, "time": 18749.572500944138, "episode/length": 220.0, "episode/score": 4.321198572881258, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.22119841993480804}
{"step": 138600, "time": 18783.720835208893, "episode/length": 305.0, "episode/score": 5.404284177500813, "episode/reward_rate": 0.9869281045751634, "episode/intrinsic_return": 0.3042840163470828}
{"step": 138680, "time": 18794.76191830635, "episode/length": 179.0, "episode/score": 5.2729423402452085, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.17294215866058948}
{"step": 138912, "time": 18824.292287111282, "episode/length": 38.0, "episode/score": 2.1441825874717324, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.04418248865840724}
{"step": 139432, "time": 18889.722547769547, "episode/length": 153.0, "episode/score": 4.253669559544505, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.15366944716879516}
{"step": 139432, "time": 18889.7303044796, "episode/length": 182.0, "episode/score": 5.275400971338968, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.17540080721664708}
{"step": 139456, "time": 18895.571900844574, "episode/length": 167.0, "episode/score": 4.279212659525001, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.17921247991944256}
{"step": 139696, "time": 18925.964302301407, "episode/length": 266.0, "episode/score": 6.412130900909688, "episode/reward_rate": 0.9962546816479401, "episode/intrinsic_return": 0.3121307488363527}
{"step": 139880, "time": 18949.629274845123, "episode/length": 149.0, "episode/score": 4.270758485290571, "episode/reward_rate": 0.96, "episode/intrinsic_return": 0.1707583803072339}
{"step": 139944, "time": 18958.92227458954, "episode/length": 201.0, "episode/score": 4.307323274349983, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.2073231237318396}
{"step": 140088, "time": 18991.82201552391, "eval_episode/length": 29.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.8333333333333334}
{"step": 140088, "time": 18998.448347091675, "eval_episode/length": 153.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9675324675324676}
{"step": 140088, "time": 19000.677281856537, "eval_episode/length": 170.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9707602339181286}
{"step": 140088, "time": 19002.513122797012, "eval_episode/length": 178.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.994413407821229}
{"step": 140088, "time": 19004.701390504837, "eval_episode/length": 195.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9795918367346939}
{"step": 140088, "time": 19006.516694545746, "eval_episode/length": 202.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9753694581280788}
{"step": 140088, "time": 19009.339850902557, "eval_episode/length": 231.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9956896551724138}
{"step": 140088, "time": 19011.14107966423, "eval_episode/length": 207.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9951923076923077}
{"step": 140088, "time": 19011.150965213776, "eval_episode/length": 237.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9831932773109243}
{"step": 140256, "time": 19031.31549859047, "episode/length": 167.0, "episode/score": 4.253187180056557, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.15318707772166817}
{"step": 140568, "time": 19070.44203686714, "episode/length": 141.0, "episode/score": 4.227094225330802, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.1270940874601365}
{"step": 140736, "time": 19092.356950044632, "episode/length": 424.0, "episode/score": 5.538605511026617, "episode/reward_rate": 0.6894117647058824, "episode/intrinsic_return": 0.4386054121550842}
{"step": 140816, "time": 19103.448327064514, "episode/length": 169.0, "episode/score": 2.2443685466132592, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.1443684799305629}
{"step": 140928, "time": 19118.596616983414, "episode/length": 186.0, "episode/score": 5.295103160377039, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.19510289532263414}
{"step": 141072, "time": 19137.34156179428, "episode/length": 171.0, "episode/score": 6.281636371068998, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.1816361749324642}
{"step": 141320, "time": 19168.83619737625, "episode/length": 171.0, "episode/score": 5.2762114688730435, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.17621130044335587}
{"step": 141504, "time": 19192.438306331635, "episode/length": 155.0, "episode/score": 6.266578837206907, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.16657874418524443}
{"step": 141856, "time": 19236.401436567307, "episode/length": 129.0, "episode/score": 5.249843214279281, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.14984306284623017}
{"step": 141912, "time": 19244.730768442154, "episode/length": 253.0, "episode/score": 5.391096887041385, "episode/reward_rate": 0.9724409448818898, "episode/intrinsic_return": 0.2910967712314232}
{"step": 142168, "time": 19277.23905968666, "episode/length": 199.0, "episode/score": 5.318410936073633, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.21841086499625817}
{"step": 142320, "time": 19297.238545417786, "episode/length": 173.0, "episode/score": 4.282118224390615, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.18211818267900526}
{"step": 142336, "time": 19300.606868743896, "episode/length": 199.0, "episode/score": 5.296244903202023, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.19624472045325092}
{"step": 142608, "time": 19334.941437721252, "episode/length": 160.0, "episode/score": 5.259109649836319, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.15910939537570812}
{"step": 142649, "time": 19342.34677863121, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 3.8961893173462565, "train/action_min": 0.0, "train/action_std": 2.9522492324604706, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04568290824996915, "train/actor_opt_grad_steps": 34340.0, "train/actor_opt_loss": -4.894188522475766, "train/adv_mag": 0.6965958174855952, "train/adv_max": 0.6723425517426455, "train/adv_mean": 0.004192463462527363, "train/adv_min": -0.48338160476582576, "train/adv_std": 0.06564773035479739, "train/cont_avg": 0.9942450701871658, "train/cont_loss_mean": 0.00019196628623645168, "train/cont_loss_std": 0.005308500448509683, "train/cont_neg_acc": 0.9956497760380015, "train/cont_neg_loss": 0.019436001944912053, "train/cont_pos_acc": 0.9999894895018103, "train/cont_pos_loss": 5.442058210235094e-05, "train/cont_pred": 0.9942611790595846, "train/cont_rate": 0.9942450701871658, "train/dyn_loss_mean": 6.270109704471527, "train/dyn_loss_std": 8.535196623062705, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1771753618423952, "train/extr_critic_critic_opt_grad_steps": 34340.0, "train/extr_critic_critic_opt_loss": 15087.851249164438, "train/extr_critic_mag": 5.5871966076407205, "train/extr_critic_max": 5.5871966076407205, "train/extr_critic_mean": 1.0091892295980198, "train/extr_critic_min": -0.6629908046620415, "train/extr_critic_std": 1.262656836904944, "train/extr_return_normed_mag": 1.7910874425408674, "train/extr_return_normed_max": 1.7910874425408674, "train/extr_return_normed_mean": 0.34131523663984903, "train/extr_return_normed_min": -0.17690816772653456, "train/extr_return_normed_std": 0.34066756770891304, "train/extr_return_rate": 0.5288161082382508, "train/extr_return_raw_mag": 6.565399345867137, "train/extr_return_raw_max": 6.565399345867137, "train/extr_return_raw_mean": 1.0252602549797711, "train/extr_return_raw_min": -0.9560538370979024, "train/extr_return_raw_std": 1.3027875627425902, "train/extr_reward_mag": 1.0125780794072279, "train/extr_reward_max": 1.0125780794072279, "train/extr_reward_mean": 0.02207902023060755, "train/extr_reward_min": -0.6497559368929123, "train/extr_reward_std": 0.14805288565031346, "train/image_loss_mean": 4.408260789147035, "train/image_loss_std": 8.796537960276885, "train/model_loss_mean": 8.24012193067826, "train/model_loss_std": 12.693264015218153, "train/model_opt_grad_norm": 45.552112048959984, "train/model_opt_grad_steps": 34306.66844919786, "train/model_opt_loss": 9730.753988500584, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1186.4973262032086, "train/policy_entropy_mag": 2.4094247881741446, "train/policy_entropy_max": 2.4094247881741446, "train/policy_entropy_mean": 0.5065657810412626, "train/policy_entropy_min": 0.07937507291528631, "train/policy_entropy_std": 0.5145154340381928, "train/policy_logprob_mag": 7.438383173815069, "train/policy_logprob_max": -0.009455661359118586, "train/policy_logprob_mean": -0.5072961927735232, "train/policy_logprob_min": -7.438383173815069, "train/policy_logprob_std": 1.0738668795575432, "train/policy_randomness_mag": 0.8504212157611541, "train/policy_randomness_max": 0.8504212157611541, "train/policy_randomness_mean": 0.17879549146973514, "train/policy_randomness_min": 0.02801591737624158, "train/policy_randomness_std": 0.18160137000249668, "train/post_ent_mag": 52.63253139557048, "train/post_ent_max": 52.63253139557048, "train/post_ent_mean": 33.86065798264774, "train/post_ent_min": 17.199415910690227, "train/post_ent_std": 5.571845646210533, "train/prior_ent_mag": 71.69347903817733, "train/prior_ent_max": 71.69347903817733, "train/prior_ent_mean": 40.13677140098205, "train/prior_ent_min": 22.869344048321565, "train/prior_ent_std": 8.62429339872962, "train/rep_loss_mean": 6.270109704471527, "train/rep_loss_std": 8.535196623062705, "train/reward_avg": 0.014277656693360145, "train/reward_loss_mean": 0.06960332572938287, "train/reward_loss_std": 0.1770435495969446, "train/reward_max_data": 1.0087366614112243, "train/reward_max_pred": 1.0077957297391433, "train/reward_neg_acc": 0.9990184090354226, "train/reward_neg_loss": 0.051184442113427556, "train/reward_pos_acc": 0.8598597409890935, "train/reward_pos_loss": 0.776799021876432, "train/reward_pred": 0.014020661667816061, "train/reward_rate": 0.025468958890374333, "train_stats/sum_log_reward": 4.549999952316284, "train_stats/max_log_achievement_collect_drink": 3.65, "train_stats/max_log_achievement_collect_sapling": 2.375, "train_stats/max_log_achievement_collect_wood": 3.25, "train_stats/max_log_achievement_defeat_skeleton": 0.05, "train_stats/max_log_achievement_defeat_zombie": 0.1, "train_stats/max_log_achievement_eat_cow": 0.025, "train_stats/max_log_achievement_make_wood_sword": 0.075, "train_stats/max_log_achievement_place_plant": 2.05, "train_stats/max_log_achievement_place_table": 1.1, "train_stats/max_log_achievement_wake_up": 2.725, "train_stats/mean_log_entropy": 0.4898217499256134, "eval_stats/sum_log_reward": 4.099999957614475, "eval_stats/max_log_achievement_collect_drink": 2.5555555555555554, "eval_stats/max_log_achievement_collect_sapling": 1.5555555555555556, "eval_stats/max_log_achievement_collect_wood": 2.888888888888889, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 1.3333333333333333, "eval_stats/max_log_achievement_place_table": 1.3333333333333333, "eval_stats/max_log_achievement_wake_up": 2.2222222222222223, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 7.05467118677916e-06, "report/cont_loss_std": 0.00013369655061978847, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0009293332695960999, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.61884429417114e-06, "report/cont_pred": 0.9941445589065552, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 5.480207920074463, "report/dyn_loss_std": 8.622180938720703, "report/image_loss_mean": 3.847919464111328, "report/image_loss_std": 9.544145584106445, "report/model_loss_mean": 7.20554256439209, "report/model_loss_std": 13.479002952575684, "report/post_ent_mag": 55.43096160888672, "report/post_ent_max": 55.43096160888672, "report/post_ent_mean": 34.88396453857422, "report/post_ent_min": 15.115036964416504, "report/post_ent_std": 6.347254276275635, "report/prior_ent_mag": 71.14971160888672, "report/prior_ent_max": 71.14971160888672, "report/prior_ent_mean": 40.582763671875, "report/prior_ent_min": 22.758960723876953, "report/prior_ent_std": 8.182872772216797, "report/rep_loss_mean": 5.480207920074463, "report/rep_loss_std": 8.622180938720703, "report/reward_avg": 0.012576653622090816, "report/reward_loss_mean": 0.06949082016944885, "report/reward_loss_std": 0.16002999246120453, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0035741329193115, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.050958938896656036, "report/reward_pos_acc": 0.9199999570846558, "report/reward_pos_loss": 0.8100248575210571, "report/reward_pred": 0.011064436286687851, "report/reward_rate": 0.0244140625, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 7.228192771435715e-06, "eval/cont_loss_std": 0.00019822797912638634, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.002293463796377182, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 5.105569584884506e-07, "eval/cont_pred": 0.9970765709877014, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 22.496692657470703, "eval/dyn_loss_std": 12.1032075881958, "eval/image_loss_mean": 42.38791275024414, "eval/image_loss_std": 36.64810562133789, "eval/model_loss_mean": 55.956077575683594, "eval/model_loss_std": 41.145835876464844, "eval/post_ent_mag": 47.902549743652344, "eval/post_ent_max": 47.902549743652344, "eval/post_ent_mean": 34.73012161254883, "eval/post_ent_min": 19.66476058959961, "eval/post_ent_std": 4.706137180328369, "eval/prior_ent_mag": 71.14971160888672, "eval/prior_ent_max": 71.14971160888672, "eval/prior_ent_mean": 45.9713249206543, "eval/prior_ent_min": 23.882837295532227, "eval/prior_ent_std": 8.097743034362793, "eval/rep_loss_mean": 22.496692657470703, "eval/rep_loss_std": 12.1032075881958, "eval/reward_avg": 0.010449218563735485, "eval/reward_loss_mean": 0.07014384865760803, "eval/reward_loss_std": 0.6145171523094177, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0000097751617432, "eval/reward_neg_acc": 0.9940652251243591, "eval/reward_neg_loss": 0.031002748757600784, "eval/reward_pos_acc": 0.692307710647583, "eval/reward_pos_loss": 3.1141176223754883, "eval/reward_pred": 0.008135410957038403, "eval/reward_rate": 0.0126953125, "replay/size": 142145.0, "replay/inserts": 7476.0, "replay/samples": 29904.0, "replay/insert_wait_avg": 1.6559184458626982e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.883663034617677e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 28880.0, "eval_replay/inserts": 1904.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2048653193882534e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.152557373046875e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.162026643753, "timer/env.step_count": 935.0, "timer/env.step_total": 86.0247015953064, "timer/env.step_frac": 0.08601076555963613, "timer/env.step_avg": 0.09200502844417796, "timer/env.step_min": 0.022571563720703125, "timer/env.step_max": 2.9807116985321045, "timer/replay._sample_count": 29904.0, "timer/replay._sample_total": 15.13272500038147, "timer/replay._sample_frac": 0.015130273492948342, "timer/replay._sample_avg": 0.0005060435058982567, "timer/replay._sample_min": 0.00037026405334472656, "timer/replay._sample_max": 0.022594928741455078, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1173.0, "timer/agent.policy_total": 18.502263069152832, "timer/agent.policy_frac": 0.01849926569522034, "timer/agent.policy_avg": 0.015773455301920574, "timer/agent.policy_min": 0.009464502334594727, "timer/agent.policy_max": 0.049837350845336914, "timer/dataset_train_count": 1869.0, "timer/dataset_train_total": 0.3342251777648926, "timer/dataset_train_frac": 0.0003341710331539512, "timer/dataset_train_avg": 0.00017882567028619186, "timer/dataset_train_min": 9.870529174804688e-05, "timer/dataset_train_max": 0.019534826278686523, "timer/agent.train_count": 1869.0, "timer/agent.train_total": 833.196578502655, "timer/agent.train_frac": 0.8330616003275144, "timer/agent.train_avg": 0.44579806233421887, "timer/agent.train_min": 0.42999696731567383, "timer/agent.train_max": 1.0952963829040527, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4771275520324707, "timer/agent.report_frac": 0.00047705025718039826, "timer/agent.report_avg": 0.23856377601623535, "timer/agent.report_min": 0.23238158226013184, "timer/agent.report_max": 0.24474596977233887, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9802322387695312e-05, "timer/dataset_eval_frac": 2.979749439968548e-08, "timer/dataset_eval_avg": 2.9802322387695312e-05, "timer/dataset_eval_min": 2.9802322387695312e-05, "timer/dataset_eval_max": 2.9802322387695312e-05, "fps": 7.474678621075982}
{"step": 142728, "time": 19351.772898197174, "episode/length": 206.0, "episode/score": 4.32434782670407, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.2243476192752496}
{"step": 142936, "time": 19378.327224969864, "episode/length": 178.0, "episode/score": 5.2718406484418665, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.17184053059463622}
{"step": 143304, "time": 19424.34898686409, "episode/length": 180.0, "episode/score": 5.30453395546283, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.20453374721910222}
{"step": 143416, "time": 19439.48616051674, "episode/length": 187.0, "episode/score": 1.2935289902634395, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.19352886642082012}
{"step": 143568, "time": 19459.359487056732, "episode/length": 155.0, "episode/score": 5.2783554249872395, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.17835525632472127}
{"step": 143608, "time": 19465.64557814598, "episode/length": 158.0, "episode/score": 5.274285804513056, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.17428565540831187}
{"step": 143624, "time": 19469.242881774902, "episode/length": 39.0, "episode/score": 0.14472026280418504, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.044720237332512625}
{"step": 143944, "time": 19510.133098840714, "episode/length": 221.0, "episode/score": 5.33653611727641, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.2365359499817714}
{"step": 143952, "time": 19512.691675901413, "episode/length": 152.0, "episode/score": 6.274949169008323, "episode/reward_rate": 0.954248366013072, "episode/intrinsic_return": 0.17494904685372603}
{"step": 144096, "time": 19531.633771896362, "episode/length": 185.0, "episode/score": 3.306047629139357, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.20604753498264472}
{"step": 144144, "time": 19539.061948537827, "episode/length": 150.0, "episode/score": 2.244215070757491, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.14421491827670252}
{"step": 144864, "time": 19627.65794301033, "episode/length": 154.0, "episode/score": 4.2722545532760705, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.1722544163949351}
{"step": 145080, "time": 19655.276938676834, "episode/length": 141.0, "episode/score": 2.246219655893583, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.14621965422884386}
{"step": 145096, "time": 19659.265478610992, "episode/length": 190.0, "episode/score": 5.276119621221369, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.17611944301279436}
{"step": 145168, "time": 19669.94442152977, "episode/length": 218.0, "episode/score": 5.313617566462199, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.2136172906975844}
{"step": 145408, "time": 19700.557539463043, "episode/length": 181.0, "episode/score": 3.2830439263452718, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.18304383102440624}
{"step": 145584, "time": 19723.608523368835, "episode/length": 246.0, "episode/score": 5.3540120016605215, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.25401184248585196}
{"step": 145824, "time": 19754.356054782867, "episode/length": 209.0, "episode/score": 5.311793866222615, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.21179371478956455}
{"step": 145896, "time": 19764.636429309845, "episode/length": 224.0, "episode/score": 4.308761289533322, "episode/reward_rate": 0.9911111111111112, "episode/intrinsic_return": 0.20876112447967898}
{"step": 146328, "time": 19818.76943874359, "episode/length": 144.0, "episode/score": 2.2397124009321487, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.1397122484513602}
{"step": 146584, "time": 19851.454134225845, "episode/length": 85.0, "episode/score": 4.177838668136246, "episode/reward_rate": 0.9534883720930233, "episode/intrinsic_return": 0.07783860302515677}
{"step": 146688, "time": 19865.693481445312, "episode/length": 227.0, "episode/score": 5.361005491434298, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.2610053976850395}
{"step": 146896, "time": 19892.485230207443, "episode/length": 133.0, "episode/score": 5.2438792175935305, "episode/reward_rate": 0.9925373134328358, "episode/intrinsic_return": 0.14387901284226245}
{"step": 146904, "time": 19894.95120882988, "episode/length": 225.0, "episode/score": 5.351951373151678, "episode/reward_rate": 0.9778761061946902, "episode/intrinsic_return": 0.2519512217186275}
{"step": 147040, "time": 19913.0017786026, "episode/length": 181.0, "episode/score": 5.292360766700767, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.19236062958680122}
{"step": 147216, "time": 19936.143124103546, "episode/length": 39.0, "episode/score": 4.14812517631799, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.04812499904073775}
{"step": 147328, "time": 19951.45858979225, "episode/length": 239.0, "episode/score": 5.352348197297033, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.2523480384134018}
{"step": 147416, "time": 19963.580307006836, "episode/length": 135.0, "episode/score": 5.252812987141624, "episode/reward_rate": 0.9632352941176471, "episode/intrinsic_return": 0.15281280788531149}
{"step": 148216, "time": 20062.730338573456, "episode/length": 163.0, "episode/score": 4.266051822298323, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.1660516822739737}
{"step": 148440, "time": 20091.406017541885, "episode/length": 231.0, "episode/score": 6.345418164365583, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.2454179447131537}
{"step": 148512, "time": 20101.614188432693, "episode/length": 161.0, "episode/score": 5.275097762634687, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.17509751166653587}
{"step": 148528, "time": 20105.040714502335, "episode/length": 38.0, "episode/score": 1.147916759364307, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.04791666567325592}
{"step": 148592, "time": 20114.20456457138, "episode/length": 146.0, "episode/score": 2.243819386443647, "episode/reward_rate": 0.9659863945578231, "episode/intrinsic_return": 0.14381932092510397}
{"step": 148600, "time": 20116.742643117905, "episode/length": 439.0, "episode/score": 5.56998077724711, "episode/reward_rate": 0.8272727272727273, "episode/intrinsic_return": 0.4699805988057051}
{"step": 149008, "time": 20167.57311487198, "episode/length": 209.0, "episode/score": 4.3335984075965825, "episode/reward_rate": 0.9619047619047619, "episode/intrinsic_return": 0.23359829527908005}
{"step": 149464, "time": 20223.775799512863, "episode/length": 346.0, "episode/score": 5.455779881654053, "episode/reward_rate": 0.9942363112391931, "episode/intrinsic_return": 0.3557797313851552}
{"step": 149576, "time": 20238.7350795269, "episode/length": 316.0, "episode/score": 6.456101774914714, "episode/reward_rate": 0.9873817034700315, "episode/intrinsic_return": 0.3561015926898108}
{"step": 149872, "time": 20276.516083717346, "episode/length": 158.0, "episode/score": 6.243828485023187, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.1438282320759754}
{"step": 149880, "time": 20279.21473956108, "episode/length": 37.0, "episode/score": 1.1420833867159672, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.04208333260612562}
{"step": 149936, "time": 20287.529567956924, "episode/length": 177.0, "episode/score": 4.2923113469842065, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.19231122651763144}
{"step": 150032, "time": 20300.928236961365, "episode/length": 198.0, "episode/score": 5.341739383926324, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.24173918615997536}
{"step": 150056, "time": 20305.391401052475, "episode/length": 182.0, "episode/score": 6.309719885002778, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.20971961796931282}
{"step": 150072, "time": 20327.320202589035, "eval_episode/length": 135.0, "eval_episode/score": 4.099999971687794, "eval_episode/reward_rate": 0.9926470588235294}
{"step": 150072, "time": 20328.88266468048, "eval_episode/length": 136.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9927007299270073}
{"step": 150072, "time": 20330.71474337578, "eval_episode/length": 144.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9586206896551724}
{"step": 150072, "time": 20334.145389795303, "eval_episode/length": 191.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9947916666666666}
{"step": 150072, "time": 20335.704921245575, "eval_episode/length": 194.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 150072, "time": 20337.61868238449, "eval_episode/length": 204.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9951219512195122}
{"step": 150072, "time": 20340.004138469696, "eval_episode/length": 220.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.995475113122172}
{"step": 150072, "time": 20341.97234725952, "eval_episode/length": 231.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9956896551724138}
{"step": 150073, "time": 20343.013301849365, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.0975955447635135, "train/action_min": 0.0, "train/action_std": 3.1168337757522995, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04427070962013425, "train/actor_opt_grad_steps": 36200.0, "train/actor_opt_loss": -9.785997005954787, "train/adv_mag": 0.6343459477295746, "train/adv_max": 0.6071226140937289, "train/adv_mean": 0.0030037011864289917, "train/adv_min": -0.4714317038252547, "train/adv_std": 0.06260413432846199, "train/cont_avg": 0.9942831503378379, "train/cont_loss_mean": 0.0001668597930763031, "train/cont_loss_std": 0.004842706701702576, "train/cont_neg_acc": 0.9928314038225122, "train/cont_neg_loss": 0.02347988019451018, "train/cont_pos_acc": 0.9999946822991242, "train/cont_pos_loss": 2.3760059688943576e-05, "train/cont_pred": 0.994311388118847, "train/cont_rate": 0.9942831503378379, "train/dyn_loss_mean": 6.51798872818818, "train/dyn_loss_std": 8.533001190907246, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1409693920934523, "train/extr_critic_critic_opt_grad_steps": 36200.0, "train/extr_critic_critic_opt_loss": 15226.408910472974, "train/extr_critic_mag": 5.730798832145897, "train/extr_critic_max": 5.730798832145897, "train/extr_critic_mean": 1.0472797450181601, "train/extr_critic_min": -0.6764615110448888, "train/extr_critic_std": 1.3658112293965108, "train/extr_return_normed_mag": 1.684889502138705, "train/extr_return_normed_max": 1.684889502138705, "train/extr_return_normed_mean": 0.32011634594685323, "train/extr_return_normed_min": -0.17603868205805082, "train/extr_return_normed_std": 0.33328973248198224, "train/extr_return_rate": 0.49902275985962635, "train/extr_return_raw_mag": 6.811616116601067, "train/extr_return_raw_max": 6.811616116601067, "train/extr_return_raw_mean": 1.0599413568909104, "train/extr_return_raw_min": -1.029312323557364, "train/extr_return_raw_std": 1.4041260451883883, "train/extr_reward_mag": 1.0145478300146153, "train/extr_reward_max": 1.0145478300146153, "train/extr_reward_mean": 0.022263990327514506, "train/extr_reward_min": -0.6711214909682403, "train/extr_reward_std": 0.1487902712983054, "train/image_loss_mean": 4.593275620486285, "train/image_loss_std": 9.221507250296103, "train/model_loss_mean": 8.574639632250811, "train/model_loss_std": 13.088712292748529, "train/model_opt_grad_norm": 50.87656536617794, "train/model_opt_grad_steps": 36164.718918918916, "train/model_opt_loss": 8189.7833522487335, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 959.4594594594595, "train/policy_entropy_mag": 2.438513739044602, "train/policy_entropy_max": 2.438513739044602, "train/policy_entropy_mean": 0.5561125436344663, "train/policy_entropy_min": 0.07937504117553298, "train/policy_entropy_std": 0.5696790662971702, "train/policy_logprob_mag": 7.438383393674283, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5562969051502846, "train/policy_logprob_min": -7.438383393674283, "train/policy_logprob_std": 1.1075321606687598, "train/policy_randomness_mag": 0.8606883390529736, "train/policy_randomness_max": 0.8606883390529736, "train/policy_randomness_mean": 0.19628332112286542, "train/policy_randomness_min": 0.028015906192563677, "train/policy_randomness_std": 0.20107171164976584, "train/post_ent_mag": 53.924216914821315, "train/post_ent_max": 53.924216914821315, "train/post_ent_mean": 34.53799323004645, "train/post_ent_min": 17.659704414573877, "train/post_ent_std": 5.754405248487318, "train/prior_ent_mag": 71.80911485826647, "train/prior_ent_max": 71.80911485826647, "train/prior_ent_mean": 41.01784245259053, "train/prior_ent_min": 23.549468313681114, "train/prior_ent_std": 8.48601679673066, "train/rep_loss_mean": 6.51798872818818, "train/rep_loss_std": 8.533001190907246, "train/reward_avg": 0.01535416511831352, "train/reward_loss_mean": 0.07040395732666994, "train/reward_loss_std": 0.175202231471603, "train/reward_max_data": 1.0098986793208766, "train/reward_max_pred": 1.0077614861565667, "train/reward_neg_acc": 0.9987033782778559, "train/reward_neg_loss": 0.051410888457620464, "train/reward_pos_acc": 0.8617065523121809, "train/reward_pos_loss": 0.7669826037174946, "train/reward_pred": 0.015238870622439159, "train/reward_rate": 0.026610008445945944, "train_stats/sum_log_reward": 4.242857090064457, "train_stats/max_log_achievement_collect_drink": 4.071428571428571, "train_stats/max_log_achievement_collect_sapling": 1.6428571428571428, "train_stats/max_log_achievement_collect_wood": 3.4047619047619047, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.14285714285714285, "train_stats/max_log_achievement_eat_cow": 0.09523809523809523, "train_stats/max_log_achievement_make_wood_sword": 0.047619047619047616, "train_stats/max_log_achievement_place_plant": 1.4523809523809523, "train_stats/max_log_achievement_place_table": 1.4761904761904763, "train_stats/max_log_achievement_wake_up": 2.761904761904762, "train_stats/mean_log_entropy": 0.5075808142622312, "eval_stats/sum_log_reward": 4.974999964237213, "eval_stats/max_log_achievement_collect_drink": 3.75, "eval_stats/max_log_achievement_collect_sapling": 1.625, "eval_stats/max_log_achievement_collect_wood": 4.375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_make_wood_sword": 0.125, "eval_stats/max_log_achievement_place_plant": 1.5, "eval_stats/max_log_achievement_place_table": 1.875, "eval_stats/max_log_achievement_wake_up": 2.75, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.000630232912953943, "report/cont_loss_std": 0.020076319575309753, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.10753967612981796, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.1824044321429028e-07, "report/cont_pred": 0.9946059584617615, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 7.50051212310791, "report/dyn_loss_std": 9.565491676330566, "report/image_loss_mean": 5.743675708770752, "report/image_loss_std": 12.681819915771484, "report/model_loss_mean": 10.311956405639648, "report/model_loss_std": 17.358549118041992, "report/post_ent_mag": 52.94358825683594, "report/post_ent_max": 52.94358825683594, "report/post_ent_mean": 33.821800231933594, "report/post_ent_min": 18.6142578125, "report/post_ent_std": 4.79134464263916, "report/prior_ent_mag": 71.4027099609375, "report/prior_ent_max": 71.4027099609375, "report/prior_ent_mean": 41.195125579833984, "report/prior_ent_min": 23.059471130371094, "report/prior_ent_std": 8.678274154663086, "report/rep_loss_mean": 7.50051212310791, "report/rep_loss_std": 9.565491676330566, "report/reward_avg": 0.016906343400478363, "report/reward_loss_mean": 0.06734240055084229, "report/reward_loss_std": 0.14030958712100983, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.004183292388916, "report/reward_neg_acc": 0.9979899525642395, "report/reward_neg_loss": 0.04815967381000519, "report/reward_pos_acc": 0.7931034564971924, "report/reward_pos_loss": 0.725508451461792, "report/reward_pred": 0.017119552940130234, "report/reward_rate": 0.0283203125, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.005709501914680004, "eval/cont_loss_std": 0.17705997824668884, "eval/cont_neg_acc": 0.8333333730697632, "eval/cont_neg_loss": 0.9743872880935669, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.0409025580647722e-07, "eval/cont_pred": 0.9952811002731323, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 25.472246170043945, "eval/dyn_loss_std": 12.490774154663086, "eval/image_loss_mean": 45.7901725769043, "eval/image_loss_std": 35.59565734863281, "eval/model_loss_mean": 61.20813751220703, "eval/model_loss_std": 40.43349838256836, "eval/post_ent_mag": 49.59662628173828, "eval/post_ent_max": 49.59662628173828, "eval/post_ent_mean": 35.912540435791016, "eval/post_ent_min": 20.101736068725586, "eval/post_ent_std": 5.151182651519775, "eval/prior_ent_mag": 71.4027099609375, "eval/prior_ent_max": 71.4027099609375, "eval/prior_ent_mean": 48.069766998291016, "eval/prior_ent_min": 28.177749633789062, "eval/prior_ent_std": 7.433455467224121, "eval/rep_loss_mean": 25.472246170043945, "eval/rep_loss_std": 12.490774154663086, "eval/reward_avg": 0.01113281212747097, "eval/reward_loss_mean": 0.12890659272670746, "eval/reward_loss_std": 0.8726392984390259, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0052673816680908, "eval/reward_neg_acc": 0.9920555949211121, "eval/reward_neg_loss": 0.08281508833169937, "eval/reward_pos_acc": 0.7058823704719543, "eval/reward_pos_loss": 2.8591506481170654, "eval/reward_pred": 0.008733662776648998, "eval/reward_rate": 0.0166015625, "replay/size": 149569.0, "replay/inserts": 7424.0, "replay/samples": 29696.0, "replay/insert_wait_avg": 1.6389671584655498e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.660369035498849e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 30736.0, "eval_replay/inserts": 1856.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1611344485447324e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.642673492431641e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.6519601345062, "timer/env.step_count": 928.0, "timer/env.step_total": 89.98563194274902, "timer/env.step_frac": 0.08992700312169806, "timer/env.step_avg": 0.0969672758003761, "timer/env.step_min": 0.022326231002807617, "timer/env.step_max": 2.042304039001465, "timer/replay._sample_count": 29696.0, "timer/replay._sample_total": 14.685473680496216, "timer/replay._sample_frac": 0.014675905575123457, "timer/replay._sample_avg": 0.0004945269962451581, "timer/replay._sample_min": 0.0003540515899658203, "timer/replay._sample_max": 0.029206275939941406, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1160.0, "timer/agent.policy_total": 18.419751167297363, "timer/agent.policy_frac": 0.018407750048100045, "timer/agent.policy_avg": 0.015879095833877036, "timer/agent.policy_min": 0.009453058242797852, "timer/agent.policy_max": 0.0486142635345459, "timer/dataset_train_count": 1856.0, "timer/dataset_train_total": 0.30727219581604004, "timer/dataset_train_frac": 0.0003070719971154975, "timer/dataset_train_avg": 0.00016555613998709055, "timer/dataset_train_min": 9.655952453613281e-05, "timer/dataset_train_max": 0.0010859966278076172, "timer/agent.train_count": 1856.0, "timer/agent.train_total": 829.9159195423126, "timer/agent.train_frac": 0.8293751999753806, "timer/agent.train_avg": 0.44715297389133224, "timer/agent.train_min": 0.4338195323944092, "timer/agent.train_max": 1.0561439990997314, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47679829597473145, "timer/agent.report_frac": 0.00047648764502559, "timer/agent.report_avg": 0.23839914798736572, "timer/agent.report_min": 0.23183083534240723, "timer/agent.report_max": 0.24496746063232422, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.5987625122070312e-05, "timer/dataset_eval_frac": 2.5970693265395784e-08, "timer/dataset_eval_avg": 2.5987625122070312e-05, "timer/dataset_eval_min": 2.5987625122070312e-05, "timer/dataset_eval_max": 2.5987625122070312e-05, "fps": 7.419067332285523}
{"step": 150360, "time": 20377.59186220169, "episode/length": 228.0, "episode/score": 6.368895577192234, "episode/reward_rate": 0.9781659388646288, "episode/intrinsic_return": 0.26889539712101396}
{"step": 150464, "time": 20391.482705831528, "episode/length": 181.0, "episode/score": 5.290585677816125, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.19058550915360684}
{"step": 151184, "time": 20480.593316316605, "episode/length": 163.0, "episode/score": 4.266270214438919, "episode/reward_rate": 0.9634146341463414, "episode/intrinsic_return": 0.16627009513649682}
{"step": 151264, "time": 20491.84831094742, "episode/length": 224.0, "episode/score": 6.336353999382482, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.23635381931126176}
{"step": 151376, "time": 20506.877465486526, "episode/length": 179.0, "episode/score": 6.283467902510893, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.1834676621365361}
{"step": 151424, "time": 20514.27244067192, "episode/length": 173.0, "episode/score": 4.292093882149857, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.19209376168328163}
{"step": 151624, "time": 20540.24515724182, "episode/length": 195.0, "episode/score": 6.318547828916053, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.21854763510782504}
{"step": 151728, "time": 20554.44215774536, "episode/length": 170.0, "episode/score": 4.272147744352878, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.17214768645953882}
{"step": 151880, "time": 20574.3837621212, "episode/length": 249.0, "episode/score": 5.37417916637969, "episode/reward_rate": 0.996, "episode/intrinsic_return": 0.27417892798439425}
{"step": 152488, "time": 20649.773188114166, "episode/length": 162.0, "episode/score": 6.259370006489917, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.15936983904975932}
{"step": 152560, "time": 20660.072509765625, "episode/length": 147.0, "episode/score": 5.253876121024405, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.1538760408957387}
{"step": 152624, "time": 20669.523721694946, "episode/length": 169.0, "episode/score": 5.290476279965333, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.19047617178057408}
{"step": 152808, "time": 20693.353052854538, "episode/length": 172.0, "episode/score": 6.275935777503037, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.17593565627976204}
{"step": 152864, "time": 20701.74605512619, "episode/length": 37.0, "episode/score": 1.1439896366500761, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.04398958254023455}
{"step": 152872, "time": 20704.17772436142, "episode/length": 142.0, "episode/score": 5.255830007790792, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.15582979954706389}
{"step": 152896, "time": 20708.728514909744, "episode/length": 303.0, "episode/score": 5.420031247904262, "episode/reward_rate": 0.9967105263157895, "episode/intrinsic_return": 0.32003095036998275}
{"step": 152968, "time": 20718.99120092392, "episode/length": 42.0, "episode/score": 2.151041748467833, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.05104166571982205}
{"step": 153344, "time": 20766.049095630646, "episode/length": 182.0, "episode/score": 4.27217817557721, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.17217806940061564}
{"step": 154248, "time": 20877.432250499725, "episode/length": 179.0, "episode/score": 5.274532567947972, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.17453241651492135}
{"step": 154304, "time": 20885.832783937454, "episode/length": 175.0, "episode/score": 5.279202382086623, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.17920223065357277}
{"step": 154312, "time": 20888.379034519196, "episode/length": 180.0, "episode/score": 3.309777934601698, "episode/reward_rate": 0.9558011049723757, "episode/intrinsic_return": 0.20977785022387252}
{"step": 154360, "time": 20895.779640197754, "episode/length": 233.0, "episode/score": 6.346465982416703, "episode/reward_rate": 0.9829059829059829, "episode/intrinsic_return": 0.24646580118132988}
{"step": 154416, "time": 20904.015288591385, "episode/length": 348.0, "episode/score": 5.454234141714551, "episode/reward_rate": 0.994269340974212, "episode/intrinsic_return": 0.354233961294085}
{"step": 154424, "time": 20906.6341881752, "episode/length": 181.0, "episode/score": 6.286328519694507, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.1863282831182005}
{"step": 154672, "time": 20938.01828622818, "episode/length": 224.0, "episode/score": 4.341304184697037, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.24130404700099461}
{"step": 154808, "time": 20956.014186143875, "episode/length": 182.0, "episode/score": 3.236099215168906, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.1360991210121938}
{"step": 155672, "time": 21063.787887573242, "episode/length": 170.0, "episode/score": 4.2872907788841985, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.1872906761127524}
{"step": 155720, "time": 21071.723952770233, "episode/length": 161.0, "episode/score": 6.259845917902567, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.1598457509862783}
{"step": 155872, "time": 21092.207825899124, "episode/length": 188.0, "episode/score": 5.303748837384774, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.20374865463600145}
{"step": 155896, "time": 21096.68336749077, "episode/length": 184.0, "episode/score": 4.31508813864275, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.21508795903719147}
{"step": 155944, "time": 21104.041927337646, "episode/length": 158.0, "episode/score": 5.263488902128302, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.16348869039211422}
{"step": 155960, "time": 21107.435459136963, "episode/length": 205.0, "episode/score": 5.303035922624986, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.203035714381258}
{"step": 156392, "time": 21161.411899089813, "episode/length": 267.0, "episode/score": 5.336218954889773, "episode/reward_rate": 0.9888059701492538, "episode/intrinsic_return": 0.2362187862272549}
{"step": 156424, "time": 21166.805693864822, "episode/length": 201.0, "episode/score": 5.313520031348162, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.21351990343100624}
{"step": 156752, "time": 21207.995444059372, "episode/length": 44.0, "episode/score": 1.1460914529889124, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.046091359297861345}
{"step": 156864, "time": 21223.324264764786, "episode/length": 54.0, "episode/score": 2.1634168156888336, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0634166655363515}
{"step": 157056, "time": 21247.916555166245, "episode/length": 172.0, "episode/score": 5.274209923445596, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.17420971520186868}
{"step": 157064, "time": 21250.36097216606, "episode/length": 139.0, "episode/score": 4.243627271625883, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.14362710633940878}
{"step": 157368, "time": 21288.995057582855, "episode/length": 38.0, "episode/score": 0.1366289404395502, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.03662890518899076}
{"step": 157384, "time": 21292.466927051544, "episode/length": 207.0, "episode/score": 4.319024084456032, "episode/reward_rate": 0.9711538461538461, "episode/intrinsic_return": 0.2190239671326708}
{"step": 157528, "time": 21311.606001377106, "episode/length": 203.0, "episode/score": 5.336326611626646, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.23632645902944205}
{"step": 157769, "time": 21343.339840888977, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.140522220591807, "train/action_min": 0.0, "train/action_std": 3.129690649595903, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04625637982754818, "train/actor_opt_grad_steps": 38090.0, "train/actor_opt_loss": -9.493242359831157, "train/adv_mag": 0.6775667915998963, "train/adv_max": 0.6476692415272016, "train/adv_mean": 0.0027798538265254896, "train/adv_min": -0.47835420697464226, "train/adv_std": 0.06383588674618172, "train/cont_avg": 0.9942519430051814, "train/cont_loss_mean": 0.00014789704959608274, "train/cont_loss_std": 0.00445593694004757, "train/cont_neg_acc": 0.997265400355344, "train/cont_neg_loss": 0.0071233136024350455, "train/cont_pos_acc": 0.9999847094012048, "train/cont_pos_loss": 9.874638562372511e-05, "train/cont_pred": 0.9942319390069635, "train/cont_rate": 0.9942519430051814, "train/dyn_loss_mean": 6.4003682655374, "train/dyn_loss_std": 8.530393971062695, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1989296566637069, "train/extr_critic_critic_opt_grad_steps": 38090.0, "train/extr_critic_critic_opt_loss": 15546.39940900259, "train/extr_critic_mag": 6.101073707323618, "train/extr_critic_max": 6.101073707323618, "train/extr_critic_mean": 1.0798850587612607, "train/extr_critic_min": -0.6769811600601118, "train/extr_critic_std": 1.4316988763413898, "train/extr_return_normed_mag": 1.7432763391208155, "train/extr_return_normed_max": 1.7432763391208155, "train/extr_return_normed_mean": 0.3218486441849427, "train/extr_return_normed_min": -0.17317571238146545, "train/extr_return_normed_std": 0.3418186875204966, "train/extr_return_rate": 0.499689684939508, "train/extr_return_raw_mag": 7.202171918641718, "train/extr_return_raw_max": 7.202171918641718, "train/extr_return_raw_mean": 1.0918272221026644, "train/extr_return_raw_min": -1.035719391286682, "train/extr_return_raw_std": 1.4695709894358184, "train/extr_reward_mag": 1.0191583065171317, "train/extr_reward_max": 1.0191583065171317, "train/extr_reward_mean": 0.02391164862777594, "train/extr_reward_min": -0.6677859996884598, "train/extr_reward_std": 0.1540167205460331, "train/image_loss_mean": 4.228882238654893, "train/image_loss_std": 8.810648253544624, "train/model_loss_mean": 8.140249729156494, "train/model_loss_std": 12.710092613734112, "train/model_opt_grad_norm": 44.14254750859552, "train/model_opt_grad_steps": 38053.58031088083, "train/model_opt_loss": 10275.954021868929, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1269.4300518134714, "train/policy_entropy_mag": 2.478527768288252, "train/policy_entropy_max": 2.478527768288252, "train/policy_entropy_mean": 0.5741469636173446, "train/policy_entropy_min": 0.07937502930510229, "train/policy_entropy_std": 0.6008012526393555, "train/policy_logprob_mag": 7.438383477957138, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5732001737918261, "train/policy_logprob_min": -7.438383477957138, "train/policy_logprob_std": 1.1211437703414284, "train/policy_randomness_mag": 0.8748115347457056, "train/policy_randomness_max": 0.8748115347457056, "train/policy_randomness_mean": 0.2026486826066526, "train/policy_randomness_min": 0.028015902014980044, "train/policy_randomness_std": 0.21205647830209584, "train/post_ent_mag": 53.98255272109274, "train/post_ent_max": 53.98255272109274, "train/post_ent_mean": 35.19241141284686, "train/post_ent_min": 17.593175472990836, "train/post_ent_std": 5.779997430317143, "train/prior_ent_mag": 72.01299985579259, "train/prior_ent_max": 72.01299985579259, "train/prior_ent_mean": 41.588549915373015, "train/prior_ent_min": 24.242287334382844, "train/prior_ent_std": 8.380102115591573, "train/rep_loss_mean": 6.4003682655374, "train/rep_loss_std": 8.530393971062695, "train/reward_avg": 0.015813661932250377, "train/reward_loss_mean": 0.07099869484419649, "train/reward_loss_std": 0.18027840763176042, "train/reward_max_data": 1.0116127253814065, "train/reward_max_pred": 1.0118081822914162, "train/reward_neg_acc": 0.9990529399461697, "train/reward_neg_loss": 0.05161616094217399, "train/reward_pos_acc": 0.8698780329733933, "train/reward_pos_loss": 0.7695280378346616, "train/reward_pred": 0.015538441620458284, "train/reward_rate": 0.026994616256476683, "train_stats/sum_log_reward": 4.539024312321732, "train_stats/max_log_achievement_collect_drink": 4.512195121951219, "train_stats/max_log_achievement_collect_sapling": 2.0, "train_stats/max_log_achievement_collect_wood": 3.4146341463414633, "train_stats/max_log_achievement_defeat_skeleton": 0.024390243902439025, "train_stats/max_log_achievement_defeat_zombie": 0.2682926829268293, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.12195121951219512, "train_stats/max_log_achievement_place_plant": 1.6585365853658536, "train_stats/max_log_achievement_place_table": 1.2439024390243902, "train_stats/max_log_achievement_wake_up": 2.6097560975609757, "train_stats/mean_log_entropy": 0.5354433710255274, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 6.897816638229415e-05, "report/cont_loss_std": 0.0017780138878151774, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.007121204398572445, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.3448835488816258e-05, "report/cont_pred": 0.9922282695770264, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 5.7894792556762695, "report/dyn_loss_std": 8.35588550567627, "report/image_loss_mean": 4.331020355224609, "report/image_loss_std": 7.117059230804443, "report/model_loss_mean": 7.875244140625, "report/model_loss_std": 10.831108093261719, "report/post_ent_mag": 54.562252044677734, "report/post_ent_max": 54.562252044677734, "report/post_ent_mean": 34.756072998046875, "report/post_ent_min": 17.178592681884766, "report/post_ent_std": 5.765359401702881, "report/prior_ent_mag": 70.85662841796875, "report/prior_ent_max": 70.85662841796875, "report/prior_ent_mean": 40.904052734375, "report/prior_ent_min": 24.118013381958008, "report/prior_ent_std": 8.318756103515625, "report/rep_loss_mean": 5.7894792556762695, "report/rep_loss_std": 8.35588550567627, "report/reward_avg": 0.009699098765850067, "report/reward_loss_mean": 0.07046787440776825, "report/reward_loss_std": 0.15454329550266266, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0027709007263184, "report/reward_neg_acc": 0.999002993106842, "report/reward_neg_loss": 0.057788509875535965, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.676058828830719, "report/reward_pred": 0.010143609717488289, "report/reward_rate": 0.0205078125, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 5.639307346427813e-05, "eval/cont_loss_std": 0.0014850880252197385, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0100229037925601, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 7.489679319405695e-06, "eval/cont_pred": 0.9951575994491577, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 23.278118133544922, "eval/dyn_loss_std": 13.782092094421387, "eval/image_loss_mean": 34.28950500488281, "eval/image_loss_std": 35.589073181152344, "eval/model_loss_mean": 48.35673141479492, "eval/model_loss_std": 41.05769348144531, "eval/post_ent_mag": 54.18046951293945, "eval/post_ent_max": 54.18046951293945, "eval/post_ent_mean": 35.30867004394531, "eval/post_ent_min": 18.14324188232422, "eval/post_ent_std": 6.102195739746094, "eval/prior_ent_mag": 70.85662841796875, "eval/prior_ent_max": 70.85662841796875, "eval/prior_ent_mean": 47.38481140136719, "eval/prior_ent_min": 29.198610305786133, "eval/prior_ent_std": 8.26722526550293, "eval/rep_loss_mean": 23.278118133544922, "eval/rep_loss_std": 13.782092094421387, "eval/reward_avg": 0.00800781324505806, "eval/reward_loss_mean": 0.10029764473438263, "eval/reward_loss_std": 0.714915931224823, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.001758337020874, "eval/reward_neg_acc": 0.9940652251243591, "eval/reward_neg_loss": 0.06615997850894928, "eval/reward_pos_acc": 0.7692307829856873, "eval/reward_pos_loss": 2.7551581859588623, "eval/reward_pred": 0.006398212164640427, "eval/reward_rate": 0.0126953125, "replay/size": 157265.0, "replay/inserts": 7696.0, "replay/samples": 30784.0, "replay/insert_wait_avg": 1.6194247406386536e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.314425496202497e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 30736.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 8.642673492431641e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3146727085114, "timer/env.step_count": 962.0, "timer/env.step_total": 88.61002898216248, "timer/env.step_frac": 0.0885821545956501, "timer/env.step_avg": 0.09211021723717513, "timer/env.step_min": 0.02302098274230957, "timer/env.step_max": 2.001079797744751, "timer/replay._sample_count": 30784.0, "timer/replay._sample_total": 14.590355396270752, "timer/replay._sample_frac": 0.014585765653886732, "timer/replay._sample_avg": 0.0004739590500347827, "timer/replay._sample_min": 0.0003371238708496094, "timer/replay._sample_max": 0.009607791900634766, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 962.0, "timer/agent.policy_total": 15.176937103271484, "timer/agent.policy_frac": 0.015172162837697371, "timer/agent.policy_avg": 0.015776441895292603, "timer/agent.policy_min": 0.014421224594116211, "timer/agent.policy_max": 0.05545306205749512, "timer/dataset_train_count": 1924.0, "timer/dataset_train_total": 0.30762481689453125, "timer/dataset_train_frac": 0.00030752804621128675, "timer/dataset_train_avg": 0.00015988815846909108, "timer/dataset_train_min": 9.417533874511719e-05, "timer/dataset_train_max": 0.0012524127960205078, "timer/agent.train_count": 1924.0, "timer/agent.train_total": 863.0246391296387, "timer/agent.train_frac": 0.8627531542578116, "timer/agent.train_avg": 0.44855750474513445, "timer/agent.train_min": 0.43569254875183105, "timer/agent.train_max": 1.0619614124298096, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47707056999206543, "timer/agent.report_frac": 0.0004769204961278043, "timer/agent.report_avg": 0.23853528499603271, "timer/agent.report_min": 0.2323470115661621, "timer/agent.report_max": 0.24472355842590332, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0040740966796875e-05, "timer/dataset_eval_frac": 3.0031290939136967e-08, "timer/dataset_eval_avg": 3.0040740966796875e-05, "timer/dataset_eval_min": 3.0040740966796875e-05, "timer/dataset_eval_max": 3.0040740966796875e-05, "fps": 7.693461295929116}
{"step": 157856, "time": 21353.73863220215, "episode/length": 247.0, "episode/score": 4.373695236310596, "episode/reward_rate": 0.9959677419354839, "episode/intrinsic_return": 0.27369505670503713}
{"step": 157896, "time": 21360.262277841568, "episode/length": 241.0, "episode/score": 6.361462564189424, "episode/reward_rate": 0.9793388429752066, "episode/intrinsic_return": 0.26146237387365545}
{"step": 158176, "time": 21395.823717594147, "episode/length": 177.0, "episode/score": 6.304565980990446, "episode/reward_rate": 0.9662921348314607, "episode/intrinsic_return": 0.20456580441168626}
{"step": 158672, "time": 21457.798255443573, "episode/length": 200.0, "episode/score": 6.32592807896981, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.22592789889858977}
{"step": 158896, "time": 21486.713477134705, "episode/length": 190.0, "episode/score": 6.305903758540808, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.20590357846958796}
{"step": 159104, "time": 21513.73664832115, "episode/length": 279.0, "episode/score": 5.406245873176886, "episode/reward_rate": 0.9857142857142858, "episode/intrinsic_return": 0.30624566528240393}
{"step": 159168, "time": 21523.235601186752, "episode/length": 222.0, "episode/score": 4.354836397575127, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.25483624916887493}
{"step": 159200, "time": 21528.674304246902, "episode/length": 167.0, "episode/score": 5.2781378101644805, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.17813767421466764}
{"step": 159328, "time": 21545.750214338303, "episode/length": 178.0, "episode/score": 4.265495273448323, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.16549512283017975}
{"step": 159384, "time": 21554.023387908936, "episode/length": 231.0, "episode/score": 5.344377967386208, "episode/reward_rate": 0.9741379310344828, "episode/intrinsic_return": 0.2443777591424805}
{"step": 160056, "time": 21657.50644302368, "eval_episode/length": 155.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 160056, "time": 21659.40118789673, "eval_episode/length": 158.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9748427672955975}
{"step": 160056, "time": 21662.562634944916, "eval_episode/length": 190.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9738219895287958}
{"step": 160056, "time": 21665.603338956833, "eval_episode/length": 191.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.96875}
{"step": 160056, "time": 21667.375680923462, "eval_episode/length": 199.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.995}
{"step": 160056, "time": 21671.01186990738, "eval_episode/length": 250.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9721115537848606}
{"step": 160056, "time": 21673.871952533722, "eval_episode/length": 283.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9859154929577465}
{"step": 160056, "time": 21676.666825532913, "eval_episode/length": 313.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9904458598726115}
{"step": 160088, "time": 21680.555862665176, "episode/length": 114.0, "episode/score": 3.2306416546416585, "episode/reward_rate": 0.9652173913043478, "episode/intrinsic_return": 0.13064156164909946}
{"step": 160120, "time": 21686.024391412735, "episode/length": 242.0, "episode/score": 5.366384420573013, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.26638427496072836}
{"step": 160440, "time": 21726.627400398254, "episode/length": 138.0, "episode/score": 3.2465382750051504, "episode/reward_rate": 0.9640287769784173, "episode/intrinsic_return": 0.14653818282749853}
{"step": 160576, "time": 21744.677223682404, "episode/length": 148.0, "episode/score": 5.2509101894756895, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.1509099510803935}
{"step": 160584, "time": 21747.16993713379, "episode/length": 172.0, "episode/score": 4.288476750789414, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.18847662799453246}
{"step": 160736, "time": 21767.250241279602, "episode/length": 203.0, "episode/score": 5.300275952919037, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.20027574700361583}
{"step": 161072, "time": 21809.618777751923, "episode/length": 299.0, "episode/score": 4.4387728706497, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.3387727490189718}
{"step": 161424, "time": 21853.919676303864, "episode/length": 166.0, "episode/score": 5.274357960337511, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.17435775092963013}
{"step": 161504, "time": 21865.240243673325, "episode/length": 325.0, "episode/score": 5.464584347748314, "episode/reward_rate": 0.99079754601227, "episode/intrinsic_return": 0.36458416616369504}
{"step": 161832, "time": 21906.780801296234, "episode/length": 173.0, "episode/score": 4.2845169768661435, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.18451682357044774}
{"step": 162000, "time": 21928.79715323448, "episode/length": 177.0, "episode/score": 6.307756632595556, "episode/reward_rate": 0.9662921348314607, "episode/intrinsic_return": 0.2077564560167957}
{"step": 162032, "time": 21934.13994860649, "episode/length": 238.0, "episode/score": 6.370647020405158, "episode/reward_rate": 0.9748953974895398, "episode/intrinsic_return": 0.27064678352326155}
{"step": 162072, "time": 21940.6051633358, "episode/length": 185.0, "episode/score": 4.318916836229619, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.21891666244482622}
{"step": 162248, "time": 21963.697202682495, "episode/length": 188.0, "episode/score": 6.277687960451658, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.17768773439638608}
{"step": 162408, "time": 21984.66147828102, "episode/length": 166.0, "episode/score": 5.264781465531996, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.16478132725387695}
{"step": 162984, "time": 22056.037319660187, "episode/length": 184.0, "episode/score": 7.297716425635372, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.1977162620951276}
{"step": 163176, "time": 22081.03433728218, "episode/length": 167.0, "episode/score": 4.254389819747303, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.15438968551461585}
{"step": 163304, "time": 22098.068984031677, "episode/length": 153.0, "episode/score": 5.258777291146544, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.15877707941035624}
{"step": 163312, "time": 22100.516141414642, "episode/length": 159.0, "episode/score": 5.274271068035887, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.1742709754507814}
{"step": 163568, "time": 22133.280522823334, "episode/length": 195.0, "episode/score": 6.294375663261235, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.19437556631055486}
{"step": 163584, "time": 22136.84742331505, "episode/length": 146.0, "episode/score": 1.2488811739149241, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.1488810500723048}
{"step": 163592, "time": 22139.40285205841, "episode/length": 167.0, "episode/score": 4.254315634607337, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.15431539819110185}
{"step": 164216, "time": 22218.342289686203, "episode/length": 348.0, "episode/score": 5.476574868400348, "episode/reward_rate": 0.994269340974212, "episode/intrinsic_return": 0.37657472275896}
{"step": 164336, "time": 22234.48085641861, "episode/length": 168.0, "episode/score": 4.298347184902013, "episode/reward_rate": 0.9585798816568047, "episode/intrinsic_return": 0.19834706909205124}
{"step": 164464, "time": 22251.911620616913, "episode/length": 143.0, "episode/score": 5.259172241924716, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.15917208932751237}
{"step": 164680, "time": 22279.738048791885, "episode/length": 187.0, "episode/score": 6.320960826801638, "episode/reward_rate": 0.9680851063829787, "episode/intrinsic_return": 0.22096063765002327}
{"step": 164752, "time": 22289.99769449234, "episode/length": 180.0, "episode/score": 5.296487040607644, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.19648688801044045}
{"step": 164752, "time": 22290.00304889679, "episode/length": 35.0, "episode/score": 3.144166739890352, "episode/reward_rate": 0.8888888888888888, "episode/intrinsic_return": 0.04416666575707495}
{"step": 165157, "time": 22343.465873241425, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.290383168813345, "train/action_min": 0.0, "train/action_std": 3.2430083390828726, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.048445841750583134, "train/actor_opt_grad_steps": 39980.0, "train/actor_opt_loss": -7.250820930261869, "train/adv_mag": 0.6816580928660728, "train/adv_max": 0.6556068910134806, "train/adv_mean": 0.0035343991869996065, "train/adv_min": -0.5027805455633112, "train/adv_std": 0.06654274971098513, "train/cont_avg": 0.9943201013513514, "train/cont_loss_mean": 0.00011043989705645136, "train/cont_loss_std": 0.0033288984519510845, "train/cont_neg_acc": 0.9971171176111376, "train/cont_neg_loss": 0.012238870999918446, "train/cont_pos_acc": 0.9999893668535593, "train/cont_pos_loss": 4.552405793580069e-05, "train/cont_pred": 0.9943162119066393, "train/cont_rate": 0.9943201013513514, "train/dyn_loss_mean": 6.473651352444211, "train/dyn_loss_std": 8.576291285334406, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1921004156808594, "train/extr_critic_critic_opt_grad_steps": 39980.0, "train/extr_critic_critic_opt_loss": 15681.78767947635, "train/extr_critic_mag": 6.142604583018535, "train/extr_critic_max": 6.142604583018535, "train/extr_critic_mean": 1.0657941943890339, "train/extr_critic_min": -0.6453131946357521, "train/extr_critic_std": 1.3664455806886828, "train/extr_return_normed_mag": 1.7635267238359194, "train/extr_return_normed_max": 1.7635267238359194, "train/extr_return_normed_mean": 0.3186748159898294, "train/extr_return_normed_min": -0.1763278645035383, "train/extr_return_normed_std": 0.33685998248087395, "train/extr_return_rate": 0.4956148207187653, "train/extr_return_raw_mag": 7.100247911504797, "train/extr_return_raw_max": 7.100247911504797, "train/extr_return_raw_mean": 1.0805015058130831, "train/extr_return_raw_min": -0.9814836859703064, "train/extr_return_raw_std": 1.4037455993729668, "train/extr_reward_mag": 1.0147132358035527, "train/extr_reward_max": 1.0147132358035527, "train/extr_reward_mean": 0.024060034938156605, "train/extr_reward_min": -0.6660516255610698, "train/extr_reward_std": 0.15413889743991802, "train/image_loss_mean": 4.347545751365455, "train/image_loss_std": 8.824194549869846, "train/model_loss_mean": 8.303536250140215, "train/model_loss_std": 12.740350584081702, "train/model_opt_grad_norm": 44.082729514869484, "train/model_opt_grad_steps": 39942.04324324324, "train/model_opt_loss": 12245.57805373733, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1486.4864864864865, "train/policy_entropy_mag": 2.5116103094977302, "train/policy_entropy_max": 2.5116103094977302, "train/policy_entropy_mean": 0.5725209917571094, "train/policy_entropy_min": 0.07937501894461142, "train/policy_entropy_std": 0.6024798077505988, "train/policy_logprob_mag": 7.438383530281685, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5734288922838262, "train/policy_logprob_min": -7.438383530281685, "train/policy_logprob_std": 1.126102461041631, "train/policy_randomness_mag": 0.8864882192096195, "train/policy_randomness_max": 0.8864882192096195, "train/policy_randomness_mean": 0.20207478669849602, "train/policy_randomness_min": 0.028015898409727458, "train/policy_randomness_std": 0.21264893372316618, "train/post_ent_mag": 55.10609238083298, "train/post_ent_max": 55.10609238083298, "train/post_ent_mean": 35.87836344950908, "train/post_ent_min": 17.715608138007088, "train/post_ent_std": 5.968554190042856, "train/prior_ent_mag": 72.2789722339527, "train/prior_ent_max": 72.2789722339527, "train/prior_ent_mean": 42.38636256037532, "train/prior_ent_min": 24.696642066336967, "train/prior_ent_std": 8.266805210629025, "train/rep_loss_mean": 6.473651352444211, "train/rep_loss_std": 8.576291285334406, "train/reward_avg": 0.01595852819799974, "train/reward_loss_mean": 0.07168924009075035, "train/reward_loss_std": 0.18231664219418087, "train/reward_max_data": 1.010439219990292, "train/reward_max_pred": 1.0099537984744922, "train/reward_neg_acc": 0.9989252857259802, "train/reward_neg_loss": 0.05157369812195366, "train/reward_pos_acc": 0.8696596053806511, "train/reward_pos_loss": 0.7853071605837023, "train/reward_pred": 0.015649876680627867, "train/reward_rate": 0.02738597972972973, "train_stats/sum_log_reward": 4.863157858974056, "train_stats/max_log_achievement_collect_drink": 3.789473684210526, "train_stats/max_log_achievement_collect_sapling": 2.263157894736842, "train_stats/max_log_achievement_collect_wood": 3.8157894736842106, "train_stats/max_log_achievement_defeat_skeleton": 0.02631578947368421, "train_stats/max_log_achievement_defeat_zombie": 0.23684210526315788, "train_stats/max_log_achievement_eat_cow": 0.05263157894736842, "train_stats/max_log_achievement_make_wood_sword": 0.07894736842105263, "train_stats/max_log_achievement_place_plant": 2.1052631578947367, "train_stats/max_log_achievement_place_table": 1.5526315789473684, "train_stats/max_log_achievement_wake_up": 2.3684210526315788, "train_stats/mean_log_entropy": 0.5492085234114998, "train_stats/max_log_achievement_collect_stone": 0.05555555555555555, "train_stats/max_log_achievement_make_wood_pickaxe": 0.05555555555555555, "eval_stats/sum_log_reward": 4.849999904632568, "eval_stats/max_log_achievement_collect_drink": 3.625, "eval_stats/max_log_achievement_collect_sapling": 2.375, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 4.125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.625, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.125, "eval_stats/max_log_achievement_place_plant": 2.0, "eval_stats/max_log_achievement_place_table": 1.625, "eval_stats/max_log_achievement_wake_up": 3.0, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 1.713278834358789e-06, "report/cont_loss_std": 1.670155870669987e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 1.1528240065672435e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.6359957726308494e-06, "report/cont_pred": 0.9921860694885254, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 6.348803520202637, "report/dyn_loss_std": 8.937052726745605, "report/image_loss_mean": 3.3060688972473145, "report/image_loss_std": 4.878856658935547, "report/model_loss_mean": 7.190685749053955, "report/model_loss_std": 9.196861267089844, "report/post_ent_mag": 53.84874725341797, "report/post_ent_max": 53.84874725341797, "report/post_ent_mean": 35.745399475097656, "report/post_ent_min": 17.506216049194336, "report/post_ent_std": 6.099342346191406, "report/prior_ent_mag": 72.47787475585938, "report/prior_ent_max": 72.47787475585938, "report/prior_ent_mean": 42.37902069091797, "report/prior_ent_min": 22.826683044433594, "report/prior_ent_std": 8.25465202331543, "report/rep_loss_mean": 6.348803520202637, "report/rep_loss_std": 8.937052726745605, "report/reward_avg": 0.01938864216208458, "report/reward_loss_mean": 0.07533302903175354, "report/reward_loss_std": 0.20467087626457214, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0020763874053955, "report/reward_neg_acc": 1.0000001192092896, "report/reward_neg_loss": 0.053419649600982666, "report/reward_pos_acc": 0.8928571939468384, "report/reward_pos_loss": 0.8548235297203064, "report/reward_pred": 0.018337402492761612, "report/reward_rate": 0.02734375, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 1.1665756574075203e-06, "eval/cont_loss_std": 1.3117904018145055e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 1.9989118300145492e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.1481762385301408e-06, "eval/cont_pred": 0.999022364616394, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 21.145179748535156, "eval/dyn_loss_std": 12.828824043273926, "eval/image_loss_mean": 25.811492919921875, "eval/image_loss_std": 29.59613037109375, "eval/model_loss_mean": 38.5709342956543, "eval/model_loss_std": 34.38780975341797, "eval/post_ent_mag": 54.99154281616211, "eval/post_ent_max": 54.99154281616211, "eval/post_ent_mean": 35.927425384521484, "eval/post_ent_min": 21.225196838378906, "eval/post_ent_std": 6.385803699493408, "eval/prior_ent_mag": 72.47787475585938, "eval/prior_ent_max": 72.47787475585938, "eval/prior_ent_mean": 47.998924255371094, "eval/prior_ent_min": 27.11991310119629, "eval/prior_ent_std": 8.847220420837402, "eval/rep_loss_mean": 21.145179748535156, "eval/rep_loss_std": 12.828824043273926, "eval/reward_avg": 0.02499999850988388, "eval/reward_loss_mean": 0.07232969999313354, "eval/reward_loss_std": 0.560234546661377, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0047497749328613, "eval/reward_neg_acc": 0.9919840097427368, "eval/reward_neg_loss": 0.021062731742858887, "eval/reward_pos_acc": 0.7692307829856873, "eval/reward_pos_loss": 2.0401926040649414, "eval/reward_pred": 0.023120511323213577, "eval/reward_rate": 0.025390625, "replay/size": 164653.0, "replay/inserts": 7388.0, "replay/samples": 29552.0, "replay/insert_wait_avg": 1.6570543042375517e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.52714368286298e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 33248.0, "eval_replay/inserts": 2512.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1950351630046868e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.046627044677734e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1064059734344, "timer/env.step_count": 923.0, "timer/env.step_total": 82.63864088058472, "timer/env.step_frac": 0.08262984857111276, "timer/env.step_avg": 0.08953265534191193, "timer/env.step_min": 0.02300548553466797, "timer/env.step_max": 3.3324222564697266, "timer/replay._sample_count": 29552.0, "timer/replay._sample_total": 14.516504049301147, "timer/replay._sample_frac": 0.014514959570898643, "timer/replay._sample_avg": 0.0004912190054582143, "timer/replay._sample_min": 0.00035381317138671875, "timer/replay._sample_max": 0.029250144958496094, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1237.0, "timer/agent.policy_total": 19.942429542541504, "timer/agent.policy_frac": 0.019940307774682156, "timer/agent.policy_avg": 0.01612160836098747, "timer/agent.policy_min": 0.009632349014282227, "timer/agent.policy_max": 0.04701519012451172, "timer/dataset_train_count": 1847.0, "timer/dataset_train_total": 0.3037736415863037, "timer/dataset_train_frac": 0.00030374132169529644, "timer/dataset_train_avg": 0.00016446867438348875, "timer/dataset_train_min": 0.0001010894775390625, "timer/dataset_train_max": 0.0007128715515136719, "timer/agent.train_count": 1847.0, "timer/agent.train_total": 831.2832987308502, "timer/agent.train_frac": 0.8311948546332293, "timer/agent.train_avg": 0.45007217040111, "timer/agent.train_min": 0.4375152587890625, "timer/agent.train_max": 1.0080180168151855, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47971057891845703, "timer/agent.report_frac": 0.0004796595402781566, "timer/agent.report_avg": 0.23985528945922852, "timer/agent.report_min": 0.23186922073364258, "timer/agent.report_max": 0.24784135818481445, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0994415283203125e-05, "timer/dataset_eval_frac": 3.0991117643162483e-08, "timer/dataset_eval_avg": 3.0994415283203125e-05, "timer/dataset_eval_min": 3.0994415283203125e-05, "timer/dataset_eval_max": 3.0994415283203125e-05, "fps": 7.387112499416663}
{"step": 165248, "time": 22354.55580687523, "episode/length": 209.0, "episode/score": 5.324099156608099, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.22409900517504866}
{"step": 165288, "time": 22360.95069026947, "episode/length": 133.0, "episode/score": 5.246748388627566, "episode/reward_rate": 0.9701492537313433, "episode/intrinsic_return": 0.14674823835866846}
{"step": 165392, "time": 22375.153794527054, "episode/length": 225.0, "episode/score": 5.338573342748532, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.23857313450480433}
{"step": 165544, "time": 22395.146257400513, "episode/length": 243.0, "episode/score": 4.361373900610488, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.2613737909705378}
{"step": 165704, "time": 22416.145565271378, "episode/length": 170.0, "episode/score": 5.269021280785637, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.16902109885177197}
{"step": 165880, "time": 22438.92852497101, "episode/length": 140.0, "episode/score": 4.251310263080995, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.15131013912196067}
{"step": 166024, "time": 22458.082530736923, "episode/length": 167.0, "episode/score": 4.275368556928697, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.17536845575796178}
{"step": 166080, "time": 22466.337698936462, "episode/length": 165.0, "episode/score": 3.2414196754534714, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.14141966121587757}
{"step": 166616, "time": 22532.942801475525, "episode/length": 170.0, "episode/score": 5.265472751183552, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.16547261977393646}
{"step": 166688, "time": 22543.27157139778, "episode/length": 174.0, "episode/score": 3.2800756974320393, "episode/reward_rate": 0.9657142857142857, "episode/intrinsic_return": 0.18007560676778667}
{"step": 166952, "time": 22577.035301923752, "episode/length": 194.0, "episode/score": 4.314109530470887, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.2141093649515824}
{"step": 167368, "time": 22629.397936344147, "episode/length": 227.0, "episode/score": 5.332917330179043, "episode/reward_rate": 0.9780701754385965, "episode/intrinsic_return": 0.23291719539338374}
{"step": 167520, "time": 22649.420577526093, "episode/length": 204.0, "episode/score": 7.321569290888874, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.2215690543562232}
{"step": 167544, "time": 22653.766315221786, "episode/length": 189.0, "episode/score": 5.312707942746783, "episode/reward_rate": 0.968421052631579, "episode/intrinsic_return": 0.2127077948061924}
{"step": 167552, "time": 22656.16693997383, "episode/length": 183.0, "episode/score": 5.3141779591132945, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.21417777985698194}
{"step": 167784, "time": 22685.981511831284, "episode/length": 259.0, "episode/score": 7.386129223552416, "episode/reward_rate": 0.9961538461538462, "episode/intrinsic_return": 0.28612898352730554}
{"step": 167920, "time": 22704.058698892593, "episode/length": 162.0, "episode/score": 3.274395411606747, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.17439531512172834}
{"step": 168592, "time": 22787.572318792343, "episode/length": 152.0, "episode/score": 5.281254146553692, "episode/reward_rate": 0.9869281045751634, "episode/intrinsic_return": 0.18125399279233534}
{"step": 168936, "time": 22831.23114466667, "episode/length": 173.0, "episode/score": 4.275066729194805, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.17506660872822977}
{"step": 168968, "time": 22836.51380133629, "episode/length": 251.0, "episode/score": 5.373874650449579, "episode/reward_rate": 0.9801587301587301, "episode/intrinsic_return": 0.27387448318404495}
{"step": 169048, "time": 22847.81198477745, "episode/length": 186.0, "episode/score": 5.284451853369319, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.18445176078421355}
{"step": 169104, "time": 22856.593213558197, "episode/length": 301.0, "episode/score": 6.417016398660053, "episode/reward_rate": 0.9966887417218543, "episode/intrinsic_return": 0.31701625962523394}
{"step": 169152, "time": 22864.16883468628, "episode/length": 170.0, "episode/score": 5.27907004077133, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.1790698893382796}
{"step": 169224, "time": 22874.338973283768, "episode/length": 35.0, "episode/score": 2.1378155379206873, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.037815475632669404}
{"step": 169256, "time": 22879.77837252617, "episode/length": 216.0, "episode/score": 5.338302172358453, "episode/reward_rate": 0.9815668202764977, "episode/intrinsic_return": 0.2383019896096812}
{"step": 169280, "time": 22884.29328894615, "episode/length": 169.0, "episode/score": 5.262432789148079, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.16243259985094483}
{"step": 169824, "time": 22952.018463134766, "episode/length": 153.0, "episode/score": 3.24543214114874, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.14543201684045926}
{"step": 170040, "time": 22998.521114349365, "eval_episode/length": 153.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.974025974025974}
{"step": 170040, "time": 23000.46408033371, "eval_episode/length": 161.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.9753086419753086}
{"step": 170040, "time": 23002.345690727234, "eval_episode/length": 169.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9705882352941176}
{"step": 170040, "time": 23004.644892692566, "eval_episode/length": 188.0, "eval_episode/score": 6.099999971687794, "eval_episode/reward_rate": 0.9947089947089947}
{"step": 170040, "time": 23006.21584057808, "eval_episode/length": 191.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9947916666666666}
{"step": 170040, "time": 23007.795988321304, "eval_episode/length": 193.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9948453608247423}
{"step": 170040, "time": 23009.5918238163, "eval_episode/length": 32.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.8787878787878788}
{"step": 170040, "time": 23012.07560157776, "eval_episode/length": 212.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9812206572769953}
{"step": 170168, "time": 23027.614961624146, "episode/length": 132.0, "episode/score": 5.240070793650375, "episode/reward_rate": 0.9924812030075187, "episode/intrinsic_return": 0.14007062498785672}
{"step": 170288, "time": 23043.723663568497, "episode/length": 141.0, "episode/score": 2.2612441933742957, "episode/reward_rate": 0.9507042253521126, "episode/intrinsic_return": 0.1612441348406719}
{"step": 170336, "time": 23051.111716508865, "episode/length": 170.0, "episode/score": 5.289846610264249, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.18984641843508143}
{"step": 170616, "time": 23086.889811515808, "episode/length": 173.0, "episode/score": 3.27779784366885, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.17779768920900096}
{"step": 170904, "time": 23123.926592588425, "episode/length": 231.0, "episode/score": 7.36269991942936, "episode/reward_rate": 0.978448275862069, "episode/intrinsic_return": 0.26269964680795965}
{"step": 170952, "time": 23131.38831090927, "episode/length": 208.0, "episode/score": 5.33932478245606, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.23932457421233266}
{"step": 171296, "time": 23174.925298452377, "episode/length": 183.0, "episode/score": 4.252901077523347, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.1529009153800871}
{"step": 171360, "time": 23184.181130170822, "episode/length": 262.0, "episode/score": 5.400531350005622, "episode/reward_rate": 0.9961977186311787, "episode/intrinsic_return": 0.3005311801789503}
{"step": 171560, "time": 23210.183665275574, "episode/length": 173.0, "episode/score": 5.280678912753501, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.18067873116888222}
{"step": 172040, "time": 23271.509994506836, "episode/length": 92.0, "episode/score": 4.20298796123825, "episode/reward_rate": 0.989247311827957, "episode/intrinsic_return": 0.10298779734876007}
{"step": 172064, "time": 23275.97345328331, "episode/length": 221.0, "episode/score": 5.332198925669218, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.2321986884380749}
{"step": 172072, "time": 23278.45001935959, "episode/length": 181.0, "episode/score": 5.295517915936216, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.19551770769248833}
{"step": 172240, "time": 23300.45623612404, "episode/length": 166.0, "episode/score": 4.279524195617341, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.17952407282245986}
{"step": 172328, "time": 23312.79098534584, "episode/length": 171.0, "episode/score": 3.2299761948124797, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.12997609832746093}
{"step": 172561, "time": 23343.761608362198, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.1193844357052365, "train/action_min": 0.0, "train/action_std": 3.0664679140657993, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.05031875943815386, "train/actor_opt_grad_steps": 41830.0, "train/actor_opt_loss": -8.383686011385274, "train/adv_mag": 0.6747813756401474, "train/adv_max": 0.6578253522112563, "train/adv_mean": 0.0031737066792138155, "train/adv_min": -0.501193879746102, "train/adv_std": 0.06753385056917732, "train/cont_avg": 0.9941986908783784, "train/cont_loss_mean": 7.055230745943329e-05, "train/cont_loss_std": 0.002064145099623331, "train/cont_neg_acc": 0.9985521239203375, "train/cont_neg_loss": 0.004761067978034663, "train/cont_pos_acc": 0.9999787059990135, "train/cont_pos_loss": 3.930607678299609e-05, "train/cont_pred": 0.994189398030977, "train/cont_rate": 0.9941986908783784, "train/dyn_loss_mean": 6.675401393787281, "train/dyn_loss_std": 8.696136121492128, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.2158363335841411, "train/extr_critic_critic_opt_grad_steps": 41830.0, "train/extr_critic_critic_opt_loss": 15681.48851879223, "train/extr_critic_mag": 5.909258744523332, "train/extr_critic_max": 5.909258744523332, "train/extr_critic_mean": 1.0839151087644938, "train/extr_critic_min": -0.6314925316217783, "train/extr_critic_std": 1.3521739453882784, "train/extr_return_normed_mag": 1.7451538343687316, "train/extr_return_normed_max": 1.7451538343687316, "train/extr_return_normed_mean": 0.3194160591911625, "train/extr_return_normed_min": -0.17445678078644986, "train/extr_return_normed_std": 0.3364608100137195, "train/extr_return_rate": 0.49694400220303925, "train/extr_return_raw_mag": 6.981629265965642, "train/extr_return_raw_max": 6.981629265965642, "train/extr_return_raw_mean": 1.0969733326821713, "train/extr_return_raw_min": -0.9395524666116044, "train/extr_return_raw_std": 1.3883207433932536, "train/extr_reward_mag": 1.01281371374388, "train/extr_reward_max": 1.01281371374388, "train/extr_reward_mean": 0.02482161931693554, "train/extr_reward_min": -0.6501646434938585, "train/extr_reward_std": 0.15516886429206744, "train/image_loss_mean": 4.489031718228315, "train/image_loss_std": 9.332418383778753, "train/model_loss_mean": 8.56645407547822, "train/model_loss_std": 13.303022876945702, "train/model_opt_grad_norm": 47.573015317239395, "train/model_opt_grad_steps": 41790.40540540541, "train/model_opt_loss": 11476.991052576013, "train/model_opt_model_opt_grad_overflow": 0.010810810810810811, "train/model_opt_model_opt_grad_scale": 1324.3243243243244, "train/policy_entropy_mag": 2.526636585029396, "train/policy_entropy_max": 2.526636585029396, "train/policy_entropy_mean": 0.5226289600939364, "train/policy_entropy_min": 0.07937501636711326, "train/policy_entropy_std": 0.5561762732428474, "train/policy_logprob_mag": 7.438383530281685, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5222740751665992, "train/policy_logprob_min": -7.438383530281685, "train/policy_logprob_std": 1.0914926519265047, "train/policy_randomness_mag": 0.8917918388907974, "train/policy_randomness_max": 0.8917918388907974, "train/policy_randomness_mean": 0.1844650890376117, "train/policy_randomness_min": 0.028015897503575762, "train/policy_randomness_std": 0.19630581720455273, "train/post_ent_mag": 55.53451278274124, "train/post_ent_max": 55.53451278274124, "train/post_ent_mean": 36.395374133135824, "train/post_ent_min": 17.770281812306997, "train/post_ent_std": 6.063227076143832, "train/prior_ent_mag": 72.4210751920133, "train/prior_ent_max": 72.4210751920133, "train/prior_ent_mean": 43.019622101654875, "train/prior_ent_min": 25.217993782662056, "train/prior_ent_std": 8.250440048527073, "train/rep_loss_mean": 6.675401393787281, "train/rep_loss_std": 8.696136121492128, "train/reward_avg": 0.016807097134910323, "train/reward_loss_mean": 0.07211100062405741, "train/reward_loss_std": 0.18237742580272057, "train/reward_max_data": 1.006655435304384, "train/reward_max_pred": 1.0080872561480547, "train/reward_neg_acc": 0.9987507771801304, "train/reward_neg_loss": 0.05166645793093217, "train/reward_pos_acc": 0.8677217536681407, "train/reward_pos_loss": 0.7851732260472065, "train/reward_pred": 0.016416605161754666, "train/reward_rate": 0.02787162162162162, "train_stats/sum_log_reward": 4.636585287931489, "train_stats/max_log_achievement_collect_drink": 5.073170731707317, "train_stats/max_log_achievement_collect_sapling": 2.097560975609756, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 3.5609756097560976, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.21951219512195122, "train_stats/max_log_achievement_eat_cow": 0.07317073170731707, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.1951219512195122, "train_stats/max_log_achievement_place_plant": 1.8780487804878048, "train_stats/max_log_achievement_place_table": 1.3658536585365855, "train_stats/max_log_achievement_wake_up": 2.073170731707317, "train_stats/mean_log_entropy": 0.5246969861228291, "eval_stats/sum_log_reward": 4.224999912083149, "eval_stats/max_log_achievement_collect_drink": 5.75, "eval_stats/max_log_achievement_collect_sapling": 2.25, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 2.75, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.375, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 1.75, "eval_stats/max_log_achievement_place_table": 1.25, "eval_stats/max_log_achievement_wake_up": 1.625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 5.568001597566763e-06, "report/cont_loss_std": 1.732894997985568e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 1.167609116237145e-05, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 5.5259592954826076e-06, "report/cont_pred": 0.9931586384773254, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 4.944913864135742, "report/dyn_loss_std": 7.895860195159912, "report/image_loss_mean": 2.834465742111206, "report/image_loss_std": 5.365901947021484, "report/model_loss_mean": 5.86831521987915, "report/model_loss_std": 9.06234073638916, "report/post_ent_mag": 52.50785827636719, "report/post_ent_max": 52.50785827636719, "report/post_ent_mean": 35.209293365478516, "report/post_ent_min": 16.31385612487793, "report/post_ent_std": 5.500429153442383, "report/prior_ent_mag": 72.02631378173828, "report/prior_ent_max": 72.02631378173828, "report/prior_ent_mean": 40.21344757080078, "report/prior_ent_min": 18.56722640991211, "report/prior_ent_std": 7.950197219848633, "report/rep_loss_mean": 4.944913864135742, "report/rep_loss_std": 7.895860195159912, "report/reward_avg": 0.02025255188345909, "report/reward_loss_mean": 0.06689561903476715, "report/reward_loss_std": 0.1349109560251236, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0006225109100342, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.045850325375795364, "report/reward_pos_acc": 0.8181818127632141, "report/reward_pos_loss": 0.6988924145698547, "report/reward_pred": 0.019667113199830055, "report/reward_rate": 0.0322265625, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.0019095262978225946, "eval/cont_loss_std": 0.05671655759215355, "eval/cont_neg_acc": 0.5, "eval/cont_neg_loss": 0.905640721321106, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.00014097192615736276, "eval/cont_pred": 0.9987310767173767, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 22.160205841064453, "eval/dyn_loss_std": 14.151541709899902, "eval/image_loss_mean": 30.18984603881836, "eval/image_loss_std": 37.61689758300781, "eval/model_loss_mean": 43.594207763671875, "eval/model_loss_std": 42.975440979003906, "eval/post_ent_mag": 52.0367546081543, "eval/post_ent_max": 52.0367546081543, "eval/post_ent_mean": 36.979698181152344, "eval/post_ent_min": 21.858110427856445, "eval/post_ent_std": 5.790916442871094, "eval/prior_ent_mag": 72.02631378173828, "eval/prior_ent_max": 72.02631378173828, "eval/prior_ent_mean": 49.4598388671875, "eval/prior_ent_min": 31.285043716430664, "eval/prior_ent_std": 7.353613376617432, "eval/rep_loss_mean": 22.160205841064453, "eval/rep_loss_std": 14.151541709899902, "eval/reward_avg": 0.01972656138241291, "eval/reward_loss_mean": 0.1063295379281044, "eval/reward_loss_std": 0.6726623773574829, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0011200904846191, "eval/reward_neg_acc": 0.9930069446563721, "eval/reward_neg_loss": 0.04975476115942001, "eval/reward_pos_acc": 0.695652186870575, "eval/reward_pos_loss": 2.5685627460479736, "eval/reward_pred": 0.015402005985379219, "eval/reward_rate": 0.0224609375, "replay/size": 172057.0, "replay/inserts": 7404.0, "replay/samples": 29616.0, "replay/insert_wait_avg": 1.628710604048883e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.52399960831653e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 34952.0, "eval_replay/inserts": 1704.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1492782915142221e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.791685104370117e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2825343608856, "timer/env.step_count": 926.0, "timer/env.step_total": 87.0298810005188, "timer/env.step_frac": 0.08700529901396822, "timer/env.step_avg": 0.09398475270034427, "timer/env.step_min": 0.02273726463317871, "timer/env.step_max": 1.9566285610198975, "timer/replay._sample_count": 29616.0, "timer/replay._sample_total": 14.637640237808228, "timer/replay._sample_frac": 0.014633505769608096, "timer/replay._sample_avg": 0.0004942477119735355, "timer/replay._sample_min": 0.0003383159637451172, "timer/replay._sample_max": 0.022390365600585938, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1139.0, "timer/agent.policy_total": 18.307138681411743, "timer/agent.policy_frac": 0.018301967746651493, "timer/agent.policy_avg": 0.016072992696586255, "timer/agent.policy_min": 0.009539604187011719, "timer/agent.policy_max": 0.050510406494140625, "timer/dataset_train_count": 1851.0, "timer/dataset_train_total": 0.32703399658203125, "timer/dataset_train_frac": 0.0003269416243391517, "timer/dataset_train_avg": 0.00017667963078445771, "timer/dataset_train_min": 9.465217590332031e-05, "timer/dataset_train_max": 0.025086641311645508, "timer/agent.train_count": 1851.0, "timer/agent.train_total": 833.4558885097504, "timer/agent.train_frac": 0.8332204750953425, "timer/agent.train_avg": 0.45027330551580247, "timer/agent.train_min": 0.4401867389678955, "timer/agent.train_max": 0.9978780746459961, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48021507263183594, "timer/agent.report_frac": 0.0004800794336958623, "timer/agent.report_avg": 0.24010753631591797, "timer/agent.report_min": 0.23247051239013672, "timer/agent.report_max": 0.24774456024169922, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0279159545898438e-05, "timer/dataset_eval_frac": 3.027060705927933e-08, "timer/dataset_eval_avg": 3.0279159545898438e-05, "timer/dataset_eval_min": 3.0279159545898438e-05, "timer/dataset_eval_max": 3.0279159545898438e-05, "fps": 7.401794174614969}
{"step": 172984, "time": 23394.906327724457, "episode/length": 330.0, "episode/score": 7.460177823708364, "episode/reward_rate": 0.9818731117824774, "episode/intrinsic_return": 0.36017759765309165}
{"step": 173024, "time": 23401.26363015175, "episode/length": 182.0, "episode/score": 4.288530718440597, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.18853059564571595}
{"step": 173264, "time": 23432.030199289322, "episode/length": 152.0, "episode/score": 4.2527145851636305, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.15271447668783367}
{"step": 173344, "time": 23443.21099305153, "episode/length": 159.0, "episode/score": 3.262031388558171, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.16203129323730536}
{"step": 173360, "time": 23446.63467001915, "episode/length": 249.0, "episode/score": 5.372321709764947, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.27232157265098067}
{"step": 173536, "time": 23469.482956409454, "episode/length": 182.0, "episode/score": 4.263316957401003, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.16331680445455277}
{"step": 173824, "time": 23505.894227981567, "episode/length": 186.0, "episode/score": 5.2690027356420615, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.16900256663029722}
{"step": 174168, "time": 23549.259402513504, "episode/length": 240.0, "episode/score": 7.3701993888707875, "episode/reward_rate": 0.979253112033195, "episode/intrinsic_return": 0.27019918016139854}
{"step": 174584, "time": 23601.174505233765, "episode/length": 154.0, "episode/score": 5.272483486221972, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.17248333478892164}
{"step": 174704, "time": 23617.373641252518, "episode/length": 179.0, "episode/score": 6.281476394453421, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.18147621263597102}
{"step": 174848, "time": 23636.33812069893, "episode/length": 232.0, "episode/score": 6.344129050790798, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.24412886676145718}
{"step": 175072, "time": 23665.152475357056, "episode/length": 255.0, "episode/score": 6.382687979993534, "episode/reward_rate": 0.98046875, "episode/intrinsic_return": 0.28268777407811285}
{"step": 175144, "time": 23675.61736893654, "episode/length": 164.0, "episode/score": 6.258829161856738, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.15882892497484136}
{"step": 175424, "time": 23710.9451444149, "episode/length": 235.0, "episode/score": 5.364477371761495, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.264477193669336}
{"step": 175552, "time": 23727.969777345657, "episode/length": 172.0, "episode/score": 5.290553307037044, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.1905530941367033}
{"step": 175768, "time": 23755.768756628036, "episode/length": 300.0, "episode/score": 5.44739105010467, "episode/reward_rate": 0.9833887043189369, "episode/intrinsic_return": 0.34739087084835774}
{"step": 175888, "time": 23771.909905910492, "episode/length": 162.0, "episode/score": 3.2781594898924595, "episode/reward_rate": 0.9631901840490797, "episode/intrinsic_return": 0.17815944800622674}
{"step": 176576, "time": 23856.610526561737, "episode/length": 178.0, "episode/score": 5.296673246823957, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.19667305429629778}
{"step": 176584, "time": 23859.172960996628, "episode/length": 188.0, "episode/score": 7.298500949907975, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.19850070161737676}
{"step": 176888, "time": 23897.662343740463, "episode/length": 254.0, "episode/score": 6.388345503773053, "episode/reward_rate": 0.9686274509803922, "episode/intrinsic_return": 0.28834530635595}
{"step": 176904, "time": 23901.122169971466, "episode/length": 168.0, "episode/score": 6.269158665545547, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.16915849234283087}
{"step": 176920, "time": 23904.56145620346, "episode/length": 186.0, "episode/score": 5.292721357443952, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.1927211143047316}
{"step": 177040, "time": 23920.644369602203, "episode/length": 291.0, "episode/score": 6.4059101538414325, "episode/reward_rate": 0.9863013698630136, "episode/intrinsic_return": 0.30590994478279754}
{"step": 177144, "time": 23934.702300071716, "episode/length": 171.0, "episode/score": 5.249888183537223, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.14988804642325704}
{"step": 177352, "time": 23961.440417051315, "episode/length": 182.0, "episode/score": 5.295909910218143, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.1959097608223601}
{"step": 177936, "time": 24033.68371987343, "episode/length": 169.0, "episode/score": 5.2685413767894715, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.16854117877574026}
{"step": 178304, "time": 24079.695325374603, "episode/length": 172.0, "episode/score": 5.276383746666397, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.1763836431382515}
{"step": 178408, "time": 24093.75898861885, "episode/length": 189.0, "episode/score": 5.303755248878588, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.20375509977384354}
{"step": 178456, "time": 24100.964779138565, "episode/length": 163.0, "episode/score": 4.263317474983523, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.16331733399874793}
{"step": 178520, "time": 24110.231447696686, "episode/length": 201.0, "episode/score": 5.283746945708117, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.1837467974764877}
{"step": 178520, "time": 24110.240455150604, "episode/length": 184.0, "episode/score": 5.297288224584918, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.19728807315186714}
{"step": 178592, "time": 24122.17877960205, "episode/length": 35.0, "episode/score": 2.1405417486384977, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.04054166589048691}
{"step": 178976, "time": 24170.04350543022, "episode/length": 298.0, "episode/score": 6.424059942487929, "episode/reward_rate": 0.9966555183946488, "episode/intrinsic_return": 0.32405972108927017}
{"step": 179056, "time": 24181.218067646027, "episode/length": 139.0, "episode/score": 5.233178563357342, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.13317841425259758}
{"step": 179112, "time": 24189.53876185417, "episode/length": 219.0, "episode/score": 5.337759161272061, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.2377589495358734}
{"step": 179552, "time": 24244.226623296738, "episode/length": 142.0, "episode/score": 7.266499805999047, "episode/reward_rate": 0.972027972027972, "episode/intrinsic_return": 0.16649959612550447}
{"step": 179744, "time": 24268.920289993286, "episode/length": 152.0, "episode/score": 6.261796225782746, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.16179599972747383}
{"step": 179872, "time": 24285.829197883606, "episode/length": 168.0, "episode/score": 4.285545676535548, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.18554553767535253}
{"step": 180024, "time": 24321.076297283173, "eval_episode/length": 38.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 180024, "time": 24322.81528711319, "eval_episode/length": 42.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9767441860465116}
{"step": 180024, "time": 24328.362196207047, "eval_episode/length": 140.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9929078014184397}
{"step": 180024, "time": 24330.117591142654, "eval_episode/length": 142.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.958041958041958}
{"step": 180024, "time": 24332.32214641571, "eval_episode/length": 156.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9681528662420382}
{"step": 180024, "time": 24334.576699733734, "eval_episode/length": 175.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9715909090909091}
{"step": 180024, "time": 24336.372052192688, "eval_episode/length": 39.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.975}
{"step": 180024, "time": 24338.39761376381, "eval_episode/length": 154.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9741935483870968}
{"step": 180065, "time": 24344.23709011078, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.067679175718583, "train/action_min": 0.0, "train/action_std": 2.9727779990211527, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04978079729300132, "train/actor_opt_grad_steps": 43690.0, "train/actor_opt_loss": -8.245718391821347, "train/adv_mag": 0.6519549704171756, "train/adv_max": 0.6341199156116036, "train/adv_mean": 0.003258765752877144, "train/adv_min": -0.48269609588990237, "train/adv_std": 0.06656045612087225, "train/cont_avg": 0.9944017379679144, "train/cont_loss_mean": 0.00011274151923093095, "train/cont_loss_std": 0.0034225250394066755, "train/cont_neg_acc": 0.996309736514474, "train/cont_neg_loss": 0.011769863237766628, "train/cont_pos_acc": 0.9999894630462728, "train/cont_pos_loss": 3.1531238897498606e-05, "train/cont_pred": 0.994410256650996, "train/cont_rate": 0.9944017379679144, "train/dyn_loss_mean": 6.537893838423459, "train/dyn_loss_std": 8.679956803347338, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.233739528426512, "train/extr_critic_critic_opt_grad_steps": 43690.0, "train/extr_critic_critic_opt_loss": 15986.599468373997, "train/extr_critic_mag": 6.213212084642706, "train/extr_critic_max": 6.213212084642706, "train/extr_critic_mean": 1.1268457834095877, "train/extr_critic_min": -0.6327184119964029, "train/extr_critic_std": 1.4054868779080436, "train/extr_return_normed_mag": 1.7332781457646007, "train/extr_return_normed_max": 1.7332781457646007, "train/extr_return_normed_mean": 0.31950466677466816, "train/extr_return_normed_min": -0.16532843540059053, "train/extr_return_normed_std": 0.3370058409829828, "train/extr_return_rate": 0.5129554059734956, "train/extr_return_raw_mag": 7.200693232490417, "train/extr_return_raw_max": 7.200693232490417, "train/extr_return_raw_mean": 1.1407855095710346, "train/extr_return_raw_min": -0.9371713355263287, "train/extr_return_raw_std": 1.445340526932701, "train/extr_reward_mag": 1.0169586472332797, "train/extr_reward_max": 1.0169586472332797, "train/extr_reward_mean": 0.024625292391501328, "train/extr_reward_min": -0.6382321476298858, "train/extr_reward_std": 0.15615052180016104, "train/image_loss_mean": 4.381868811214671, "train/image_loss_std": 9.105150577218774, "train/model_loss_mean": 8.377382258042932, "train/model_loss_std": 13.076602089213814, "train/model_opt_grad_norm": 44.963288159293924, "train/model_opt_grad_steps": 43648.342245989305, "train/model_opt_loss": 7695.182165462065, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 915.7754010695187, "train/policy_entropy_mag": 2.5133830430035924, "train/policy_entropy_max": 2.5133830430035924, "train/policy_entropy_mean": 0.5085619380448592, "train/policy_entropy_min": 0.07937501438639381, "train/policy_entropy_std": 0.5449905797121997, "train/policy_logprob_mag": 7.4383836430024335, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5097071561902602, "train/policy_logprob_min": -7.4383836430024335, "train/policy_logprob_std": 1.0853205932015404, "train/policy_randomness_mag": 0.8871139157264628, "train/policy_randomness_max": 0.8871139157264628, "train/policy_randomness_mean": 0.1795000454640006, "train/policy_randomness_min": 0.02801589689710561, "train/policy_randomness_std": 0.19235775807005837, "train/post_ent_mag": 56.13345045201919, "train/post_ent_max": 56.13345045201919, "train/post_ent_mean": 37.042252423291536, "train/post_ent_min": 17.888169237636628, "train/post_ent_std": 6.205083686400225, "train/prior_ent_mag": 72.6254786527093, "train/prior_ent_max": 72.6254786527093, "train/prior_ent_mean": 43.537389643052045, "train/prior_ent_min": 25.662383808809167, "train/prior_ent_std": 8.17352124076476, "train/rep_loss_mean": 6.537893838423459, "train/rep_loss_std": 8.679956803347338, "train/reward_avg": 0.01653658861374074, "train/reward_loss_mean": 0.07266440967665637, "train/reward_loss_std": 0.1825872075589583, "train/reward_max_data": 1.0103409398685803, "train/reward_max_pred": 1.0102605571083845, "train/reward_neg_acc": 0.9987636189409755, "train/reward_neg_loss": 0.05262033559660861, "train/reward_pos_acc": 0.8686882706886945, "train/reward_pos_loss": 0.7629778955709487, "train/reward_pred": 0.016395100265402685, "train/reward_rate": 0.02819497827540107, "train_stats/sum_log_reward": 5.2315789147427205, "train_stats/max_log_achievement_collect_drink": 6.552631578947368, "train_stats/max_log_achievement_collect_sapling": 2.473684210526316, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 4.131578947368421, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.3684210526315789, "train_stats/max_log_achievement_eat_cow": 0.18421052631578946, "train_stats/max_log_achievement_make_wood_pickaxe": 0.02631578947368421, "train_stats/max_log_achievement_make_wood_sword": 0.23684210526315788, "train_stats/max_log_achievement_place_plant": 2.0526315789473686, "train_stats/max_log_achievement_place_table": 1.5, "train_stats/max_log_achievement_wake_up": 2.0526315789473686, "train_stats/mean_log_entropy": 0.45318905107284846, "eval_stats/sum_log_reward": 3.2249999791383743, "eval_stats/max_log_achievement_collect_drink": 2.5, "eval_stats/max_log_achievement_collect_sapling": 1.5, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 2.75, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 1.375, "eval_stats/max_log_achievement_place_table": 1.125, "eval_stats/max_log_achievement_wake_up": 1.25, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 5.524120751942974e-06, "report/cont_loss_std": 9.349226456834003e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0001304995676036924, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 4.9108948587672785e-06, "report/cont_pred": 0.9951130151748657, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 5.916052341461182, "report/dyn_loss_std": 8.209075927734375, "report/image_loss_mean": 3.7146711349487305, "report/image_loss_std": 8.442611694335938, "report/model_loss_mean": 7.326114654541016, "report/model_loss_std": 12.253852844238281, "report/post_ent_mag": 54.09538650512695, "report/post_ent_max": 54.09538650512695, "report/post_ent_mean": 36.876426696777344, "report/post_ent_min": 15.371648788452148, "report/post_ent_std": 5.719302654266357, "report/prior_ent_mag": 72.96196746826172, "report/prior_ent_max": 72.96196746826172, "report/prior_ent_mean": 42.95735168457031, "report/prior_ent_min": 22.96517562866211, "report/prior_ent_std": 8.026113510131836, "report/rep_loss_mean": 5.916052341461182, "report/rep_loss_std": 8.209075927734375, "report/reward_avg": 0.007916096597909927, "report/reward_loss_mean": 0.06180659681558609, "report/reward_loss_std": 0.12706035375595093, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0023415088653564, "report/reward_neg_acc": 0.9990060329437256, "report/reward_neg_loss": 0.04922553524374962, "report/reward_pos_acc": 0.8888888955116272, "report/reward_pos_loss": 0.7649485468864441, "report/reward_pred": 0.007587450090795755, "report/reward_rate": 0.017578125, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.0002190322265960276, "eval/cont_loss_std": 0.006359310355037451, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.03633823245763779, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 6.1489226936828345e-06, "eval/cont_pred": 0.9943285584449768, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 24.073719024658203, "eval/dyn_loss_std": 14.631391525268555, "eval/image_loss_mean": 31.873741149902344, "eval/image_loss_std": 41.17952346801758, "eval/model_loss_mean": 46.54857635498047, "eval/model_loss_std": 46.9021110534668, "eval/post_ent_mag": 51.6525993347168, "eval/post_ent_max": 51.6525993347168, "eval/post_ent_mean": 35.65654754638672, "eval/post_ent_min": 19.075382232666016, "eval/post_ent_std": 5.052918434143066, "eval/prior_ent_mag": 72.96196746826172, "eval/prior_ent_max": 72.96196746826172, "eval/prior_ent_mean": 48.614166259765625, "eval/prior_ent_min": 27.05590057373047, "eval/prior_ent_std": 7.611311912536621, "eval/rep_loss_mean": 24.073719024658203, "eval/rep_loss_std": 14.631391525268555, "eval/reward_avg": 0.02939453348517418, "eval/reward_loss_mean": 0.23038220405578613, "eval/reward_loss_std": 1.1701793670654297, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 1.0073189735412598, "eval/reward_neg_acc": 0.9929220676422119, "eval/reward_neg_loss": 0.12154190242290497, "eval/reward_pos_acc": 0.6000000238418579, "eval/reward_pos_loss": 3.3058977127075195, "eval/reward_pred": 0.01707572676241398, "eval/reward_rate": 0.0341796875, "replay/size": 179561.0, "replay/inserts": 7504.0, "replay/samples": 30016.0, "replay/insert_wait_avg": 1.6377932989775246e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.630172950118336e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 36504.0, "eval_replay/inserts": 1552.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1621369529016239e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.897615432739258e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4623153209686, "timer/env.step_count": 938.0, "timer/env.step_total": 81.64089727401733, "timer/env.step_frac": 0.08160317087788087, "timer/env.step_avg": 0.08703720391686283, "timer/env.step_min": 0.02308511734008789, "timer/env.step_max": 3.1836676597595215, "timer/replay._sample_count": 30016.0, "timer/replay._sample_total": 14.875496864318848, "timer/replay._sample_frac": 0.014868622872163341, "timer/replay._sample_avg": 0.0004955855831662729, "timer/replay._sample_min": 0.00034117698669433594, "timer/replay._sample_max": 0.012446880340576172, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1132.0, "timer/agent.policy_total": 18.107480764389038, "timer/agent.policy_frac": 0.018099113267029742, "timer/agent.policy_avg": 0.015996007742393143, "timer/agent.policy_min": 0.009332418441772461, "timer/agent.policy_max": 0.04460549354553223, "timer/dataset_train_count": 1876.0, "timer/dataset_train_total": 0.3169972896575928, "timer/dataset_train_frac": 0.00031685080467612974, "timer/dataset_train_avg": 0.00016897510109679784, "timer/dataset_train_min": 9.846687316894531e-05, "timer/dataset_train_max": 0.011732339859008789, "timer/agent.train_count": 1876.0, "timer/agent.train_total": 838.3499677181244, "timer/agent.train_frac": 0.8379625647860256, "timer/agent.train_avg": 0.4468816459051836, "timer/agent.train_min": 0.4362766742706299, "timer/agent.train_max": 0.6029791831970215, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4756038188934326, "timer/agent.report_frac": 0.0004753840415676719, "timer/agent.report_avg": 0.2378019094467163, "timer/agent.report_min": 0.23190760612487793, "timer/agent.report_max": 0.2436962127685547, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8848648071289062e-05, "timer/dataset_eval_frac": 2.8835317062426115e-08, "timer/dataset_eval_avg": 2.8848648071289062e-05, "timer/dataset_eval_min": 2.8848648071289062e-05, "timer/dataset_eval_max": 2.8848648071289062e-05, "fps": 7.500424758023812}
{"step": 180344, "time": 24379.086641311646, "episode/length": 170.0, "episode/score": 6.282691333846742, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.18269113794303848}
{"step": 180376, "time": 24384.47306036949, "episode/length": 164.0, "episode/score": 5.28301249123615, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.18301232890371466}
{"step": 180808, "time": 24438.170215845108, "episode/length": 276.0, "episode/score": 5.417431480986124, "episode/reward_rate": 0.9819494584837545, "episode/intrinsic_return": 0.31743132955307374}
{"step": 181024, "time": 24465.602586984634, "episode/length": 238.0, "episode/score": 5.33498767286801, "episode/reward_rate": 0.9790794979079498, "episode/intrinsic_return": 0.23498758668574737}
{"step": 181080, "time": 24473.86191010475, "episode/length": 190.0, "episode/score": 5.287527989099544, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.1875278519855783}
{"step": 181176, "time": 24486.985258579254, "episode/length": 178.0, "episode/score": 4.285534848058887, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.18553466845332878}
{"step": 181832, "time": 24567.933831691742, "episode/length": 181.0, "episode/score": 5.289552877104143, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.18955267817364074}
{"step": 182000, "time": 24589.790552854538, "episode/length": 442.0, "episode/score": 6.498101978523664, "episode/reward_rate": 0.9932279909706546, "episode/intrinsic_return": 0.3981017917585632}
{"step": 182184, "time": 24613.509511232376, "episode/length": 229.0, "episode/score": 6.3451173156026925, "episode/reward_rate": 0.9826086956521739, "episode/intrinsic_return": 0.24511708931458998}
{"step": 182208, "time": 24617.92781329155, "episode/length": 174.0, "episode/score": 4.25686522689648, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.15686510410159826}
{"step": 182224, "time": 24621.392273187637, "episode/length": 293.0, "episode/score": 6.401169938704697, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.3011697526962962}
{"step": 182384, "time": 24642.070836544037, "episode/length": 150.0, "episode/score": 6.237471873813774, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.1374717018334195}
{"step": 182552, "time": 24663.822013139725, "episode/length": 190.0, "episode/score": 4.294618091178563, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.19461791157300468}
{"step": 182608, "time": 24672.107644557953, "episode/length": 190.0, "episode/score": 5.294292326691902, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.19429217409469857}
{"step": 182912, "time": 24710.059983968735, "episode/length": 44.0, "episode/score": 3.1496668024919927, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.04966666584368795}
{"step": 183320, "time": 24760.843292236328, "episode/length": 136.0, "episode/score": 5.233001447857532, "episode/reward_rate": 0.9927007299270073, "episode/intrinsic_return": 0.13300127919501392}
{"step": 183368, "time": 24768.183445215225, "episode/length": 144.0, "episode/score": 6.272718024832102, "episode/reward_rate": 0.9586206896551724, "episode/intrinsic_return": 0.17271783568048704}
{"step": 183408, "time": 24774.527254104614, "episode/length": 196.0, "episode/score": 5.3077591487590325, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.2077589103637365}
{"step": 183416, "time": 24777.507209300995, "episode/length": 176.0, "episode/score": 5.2804183869375265, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.1804182459236472}
{"step": 183528, "time": 24792.743428468704, "episode/length": 167.0, "episode/score": 4.257224281946947, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.15722418901259516}
{"step": 183600, "time": 24803.08316206932, "episode/length": 151.0, "episode/score": 4.241893728015384, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.14189367012204457}
{"step": 184048, "time": 24858.768159627914, "episode/length": 179.0, "episode/score": 5.288396335065045, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.18839624355678097}
{"step": 184352, "time": 24897.02022957802, "episode/length": 179.0, "episode/score": 5.287013667515566, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.18701348593094735}
{"step": 184784, "time": 24951.127907037735, "episode/length": 156.0, "episode/score": 5.254673004926644, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.15467285198019454}
{"step": 184856, "time": 24961.489375829697, "episode/length": 185.0, "episode/score": 6.292090148398074, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.192089972692429}
{"step": 184928, "time": 24971.85551428795, "episode/length": 188.0, "episode/score": 5.299811523021162, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.19981132339216856}
{"step": 185032, "time": 24985.838480472565, "episode/length": 213.0, "episode/score": 4.348390773769552, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.24839059765645288}
{"step": 185064, "time": 24991.462582588196, "episode/length": 206.0, "episode/score": 5.30281158313619, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.20281137722076892}
{"step": 185160, "time": 25004.57858300209, "episode/length": 194.0, "episode/score": 5.304701746702904, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.20470160039212715}
{"step": 185816, "time": 25085.354212760925, "episode/length": 220.0, "episode/score": 5.3633335063641425, "episode/reward_rate": 0.9728506787330317, "episode/intrinsic_return": 0.2633333282719832}
{"step": 186128, "time": 25124.851281881332, "episode/length": 167.0, "episode/score": 5.2576213674510655, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.15762127281413996}
{"step": 186152, "time": 25129.238298892975, "episode/length": 224.0, "episode/score": 6.330556797234749, "episode/reward_rate": 0.9688888888888889, "episode/intrinsic_return": 0.23055676821240922}
{"step": 186216, "time": 25138.548842191696, "episode/length": 147.0, "episode/score": 3.2533517888405186, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.15335169468380627}
{"step": 186320, "time": 25152.584270715714, "episode/length": 173.0, "episode/score": 5.26851338269762, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.16851329733026432}
{"step": 186336, "time": 25156.492259263992, "episode/length": 146.0, "episode/score": 5.25321274589578, "episode/reward_rate": 0.9591836734693877, "episode/intrinsic_return": 0.15321258858375586}
{"step": 186384, "time": 25163.90630531311, "episode/length": 164.0, "episode/score": 4.283870975682021, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.18387085288713934}
{"step": 186384, "time": 25163.914290189743, "episode/length": 190.0, "episode/score": 5.283272223055974, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.1832721492719429}
{"step": 187432, "time": 25293.532337665558, "episode/length": 201.0, "episode/score": 5.319770794050783, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.21977064931161294}
{"step": 187480, "time": 25300.74736404419, "episode/length": 157.0, "episode/score": 5.275103666822815, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.17510346207154726}
{"step": 187568, "time": 25312.871142864227, "episode/length": 176.0, "episode/score": 4.293646087622619, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.19364588485041168}
{"step": 187616, "time": 25320.236290454865, "episode/length": 159.0, "episode/score": 5.2709875342220585, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.17098735263743947}
{"step": 187696, "time": 25331.337780237198, "episode/length": 163.0, "episode/score": 5.260439353593938, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.1604392270446624}
{"step": 187785, "time": 25344.46761584282, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 3.9282761015422603, "train/action_min": 0.0, "train/action_std": 2.876993922989603, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.048932417570926985, "train/actor_opt_grad_steps": 45590.0, "train/actor_opt_loss": -6.996867404121501, "train/adv_mag": 0.6068819035520208, "train/adv_max": 0.576509068512546, "train/adv_mean": 0.0033734671120808795, "train/adv_min": -0.4692798994983416, "train/adv_std": 0.06491581302309901, "train/cont_avg": 0.9942823024611399, "train/cont_loss_mean": 7.450149285875236e-05, "train/cont_loss_std": 0.0021474314717233774, "train/cont_neg_acc": 0.9984887739537294, "train/cont_neg_loss": 0.004785415549023891, "train/cont_pos_acc": 0.9999846763561426, "train/cont_pos_loss": 4.461998497855431e-05, "train/cont_pred": 0.9942719318706137, "train/cont_rate": 0.9942823024611399, "train/dyn_loss_mean": 6.535927053560247, "train/dyn_loss_std": 8.636227261834811, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1736871028811202, "train/extr_critic_critic_opt_grad_steps": 45590.0, "train/extr_critic_critic_opt_loss": 15940.540767689443, "train/extr_critic_mag": 6.372160657082197, "train/extr_critic_max": 6.372160657082197, "train/extr_critic_mean": 1.1867873563667652, "train/extr_critic_min": -0.6337610359636613, "train/extr_critic_std": 1.43497094867143, "train/extr_return_normed_mag": 1.7211091697524867, "train/extr_return_normed_max": 1.7211091697524867, "train/extr_return_normed_mean": 0.3252625807424901, "train/extr_return_normed_min": -0.1623152152977768, "train/extr_return_normed_std": 0.33396026214169716, "train/extr_return_rate": 0.5409714636716201, "train/extr_return_raw_mag": 7.349962891692325, "train/extr_return_raw_max": 7.349962891692325, "train/extr_return_raw_mean": 1.2016393468169968, "train/extr_return_raw_min": -0.9457536512705946, "train/extr_return_raw_std": 1.4707930480260305, "train/extr_reward_mag": 1.0161296271289568, "train/extr_reward_max": 1.0161296271289568, "train/extr_reward_mean": 0.027164641478209916, "train/extr_reward_min": -0.649240614219033, "train/extr_reward_std": 0.16243097857798938, "train/image_loss_mean": 4.167518452659172, "train/image_loss_std": 8.806816712562284, "train/model_loss_mean": 8.16141279250229, "train/model_loss_std": 12.771941278882595, "train/model_opt_grad_norm": 46.521883656581245, "train/model_opt_grad_steps": 45547.34715025907, "train/model_opt_loss": 10426.800181650744, "train/model_opt_model_opt_grad_overflow": 0.0051813471502590676, "train/model_opt_model_opt_grad_scale": 1275.9067357512954, "train/policy_entropy_mag": 2.5006747739920345, "train/policy_entropy_max": 2.5006747739920345, "train/policy_entropy_mean": 0.49352050275382603, "train/policy_entropy_min": 0.07937501394069256, "train/policy_entropy_std": 0.5208724585839504, "train/policy_logprob_mag": 7.438383655844575, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.494254740254249, "train/policy_logprob_min": -7.438383655844575, "train/policy_logprob_std": 1.0707359774125054, "train/policy_randomness_mag": 0.8826284547543897, "train/policy_randomness_max": 0.8826284547543897, "train/policy_randomness_mean": 0.17419107984075893, "train/policy_randomness_min": 0.028015896745527964, "train/policy_randomness_std": 0.18384512093091876, "train/post_ent_mag": 56.51377253952422, "train/post_ent_max": 56.51377253952422, "train/post_ent_mean": 37.341466992630245, "train/post_ent_min": 18.03933056648531, "train/post_ent_std": 6.265494010609048, "train/prior_ent_mag": 72.70947060066183, "train/prior_ent_max": 72.70947060066183, "train/prior_ent_mean": 43.822692001421835, "train/prior_ent_min": 25.75182765506092, "train/prior_ent_std": 8.16760941737674, "train/rep_loss_mean": 6.535927053560247, "train/rep_loss_std": 8.636227261834811, "train/reward_avg": 0.017561460825870383, "train/reward_loss_mean": 0.07226361067955976, "train/reward_loss_std": 0.1872833551829343, "train/reward_max_data": 1.009540186027171, "train/reward_max_pred": 1.0081612544973897, "train/reward_neg_acc": 0.99881751642326, "train/reward_neg_loss": 0.05152611803128312, "train/reward_pos_acc": 0.8842347937544393, "train/reward_pos_loss": 0.780475873712431, "train/reward_pred": 0.017257800678013212, "train/reward_rate": 0.028482229598445596, "train_stats/sum_log_reward": 5.0047618207477385, "train_stats/max_log_achievement_collect_drink": 4.428571428571429, "train_stats/max_log_achievement_collect_sapling": 2.380952380952381, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 4.571428571428571, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.14285714285714285, "train_stats/max_log_achievement_eat_cow": 0.07142857142857142, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.19047619047619047, "train_stats/max_log_achievement_place_plant": 1.9761904761904763, "train_stats/max_log_achievement_place_table": 1.7142857142857142, "train_stats/max_log_achievement_wake_up": 2.2142857142857144, "train_stats/mean_log_entropy": 0.4525985976769811, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.00024653287255205214, "report/cont_loss_std": 0.007675139233469963, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0007746791816316545, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.00024342001415789127, "report/cont_pred": 0.9939303994178772, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 7.124330520629883, "report/dyn_loss_std": 8.786252975463867, "report/image_loss_mean": 4.103161811828613, "report/image_loss_std": 8.405167579650879, "report/model_loss_mean": 8.444192886352539, "report/model_loss_std": 12.664962768554688, "report/post_ent_mag": 55.17229461669922, "report/post_ent_max": 55.17229461669922, "report/post_ent_mean": 36.82319259643555, "report/post_ent_min": 16.933326721191406, "report/post_ent_std": 5.775994777679443, "report/prior_ent_mag": 72.82196044921875, "report/prior_ent_max": 72.82196044921875, "report/prior_ent_mean": 44.03391647338867, "report/prior_ent_min": 26.502670288085938, "report/prior_ent_std": 7.72861909866333, "report/rep_loss_mean": 7.124330520629883, "report/rep_loss_std": 8.786252975463867, "report/reward_avg": 0.015087842009961605, "report/reward_loss_mean": 0.06618588417768478, "report/reward_loss_std": 0.1226031705737114, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.00528883934021, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.05098406597971916, "report/reward_pos_acc": 0.8399999737739563, "report/reward_pos_loss": 0.6736502051353455, "report/reward_pred": 0.015003087930381298, "report/reward_rate": 0.0244140625, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 8.381024372283719e-07, "eval/cont_loss_std": 5.3075614232511725e-06, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00010310743527952582, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 7.381324280686385e-07, "eval/cont_pred": 0.999022901058197, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 23.252649307250977, "eval/dyn_loss_std": 12.671625137329102, "eval/image_loss_mean": 33.69287872314453, "eval/image_loss_std": 34.350257873535156, "eval/model_loss_mean": 47.756324768066406, "eval/model_loss_std": 39.04642105102539, "eval/post_ent_mag": 56.697479248046875, "eval/post_ent_max": 56.697479248046875, "eval/post_ent_mean": 37.450950622558594, "eval/post_ent_min": 20.5787296295166, "eval/post_ent_std": 6.155803203582764, "eval/prior_ent_mag": 72.82196044921875, "eval/prior_ent_max": 72.82196044921875, "eval/prior_ent_mean": 49.786895751953125, "eval/prior_ent_min": 28.310794830322266, "eval/prior_ent_std": 6.700880527496338, "eval/rep_loss_mean": 23.252649307250977, "eval/rep_loss_std": 12.671625137329102, "eval/reward_avg": 0.01933593861758709, "eval/reward_loss_mean": 0.1118566244840622, "eval/reward_loss_std": 0.9382083415985107, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0029795169830322, "eval/reward_neg_acc": 0.9960079789161682, "eval/reward_neg_loss": 0.031682513654232025, "eval/reward_pos_acc": 0.6818181872367859, "eval/reward_pos_loss": 3.763422966003418, "eval/reward_pred": 0.015459314920008183, "eval/reward_rate": 0.021484375, "replay/size": 187281.0, "replay/inserts": 7720.0, "replay/samples": 30880.0, "replay/insert_wait_avg": 1.63993069544975e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.62854524227004e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 36504.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 7.301568984985352e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2176623344421, "timer/env.step_count": 965.0, "timer/env.step_total": 90.80953335762024, "timer/env.step_frac": 0.09078977184393722, "timer/env.step_avg": 0.09410314337577227, "timer/env.step_min": 0.023286104202270508, "timer/env.step_max": 3.1969096660614014, "timer/replay._sample_count": 30880.0, "timer/replay._sample_total": 15.08313536643982, "timer/replay._sample_frac": 0.01507985305042182, "timer/replay._sample_avg": 0.000488443502799217, "timer/replay._sample_min": 0.0003650188446044922, "timer/replay._sample_max": 0.01099848747253418, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 965.0, "timer/agent.policy_total": 15.368025541305542, "timer/agent.policy_frac": 0.015364681228921295, "timer/agent.policy_avg": 0.015925415068710407, "timer/agent.policy_min": 0.01460409164428711, "timer/agent.policy_max": 0.04910898208618164, "timer/dataset_train_count": 1930.0, "timer/dataset_train_total": 0.3196597099304199, "timer/dataset_train_frac": 0.0003195901471929172, "timer/dataset_train_avg": 0.00016562679271006213, "timer/dataset_train_min": 9.989738464355469e-05, "timer/dataset_train_max": 0.0017726421356201172, "timer/agent.train_count": 1930.0, "timer/agent.train_total": 860.1447775363922, "timer/agent.train_frac": 0.8599575971582735, "timer/agent.train_avg": 0.4456708691898405, "timer/agent.train_min": 0.431704044342041, "timer/agent.train_max": 0.9602231979370117, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47955894470214844, "timer/agent.report_frac": 0.00047945458549781, "timer/agent.report_avg": 0.23977947235107422, "timer/agent.report_min": 0.2350754737854004, "timer/agent.report_max": 0.24448347091674805, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.956390380859375e-05, "timer/dataset_eval_frac": 2.955747026061662e-08, "timer/dataset_eval_avg": 2.956390380859375e-05, "timer/dataset_eval_min": 2.956390380859375e-05, "timer/dataset_eval_max": 2.956390380859375e-05, "fps": 7.718206664623875}
{"step": 187800, "time": 25346.146546125412, "episode/length": 176.0, "episode/score": 5.280169136177847, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.18016898474479603}
{"step": 187888, "time": 25358.41423845291, "episode/length": 195.0, "episode/score": 4.323143578123563, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.2231433996821579}
{"step": 187936, "time": 25365.80278801918, "episode/length": 225.0, "episode/score": 5.333255344156441, "episode/reward_rate": 0.9734513274336283, "episode/intrinsic_return": 0.23325516571503613}
{"step": 188056, "time": 25381.90349984169, "episode/length": 60.0, "episode/score": 3.1595121234322505, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.05951192624797841}
{"step": 188768, "time": 25470.82695364952, "episode/length": 143.0, "episode/score": 5.2552331145634525, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.1552329156329506}
{"step": 188832, "time": 25480.097291469574, "episode/length": 168.0, "episode/score": 6.276805453797806, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.17680528918072014}
{"step": 189160, "time": 25521.272945404053, "episode/length": 182.0, "episode/score": 5.286946807861568, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.18694660904748162}
{"step": 189224, "time": 25530.655175447464, "episode/length": 166.0, "episode/score": 5.278125782388088, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.17812560080346884}
{"step": 189232, "time": 25533.234406232834, "episode/length": 178.0, "episode/score": 6.302947608488012, "episode/reward_rate": 0.9664804469273743, "episode/intrinsic_return": 0.20294748016340236}
{"step": 189248, "time": 25536.6651866436, "episode/length": 148.0, "episode/score": 6.26560822735928, "episode/reward_rate": 0.9798657718120806, "episode/intrinsic_return": 0.1656080581437891}
{"step": 189248, "time": 25536.676458597183, "episode/length": 226.0, "episode/score": 6.361291774694109, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.261291509057628}
{"step": 189632, "time": 25586.160638570786, "episode/length": 211.0, "episode/score": 6.334218591679019, "episode/reward_rate": 0.9622641509433962, "episode/intrinsic_return": 0.23421842441348417}
{"step": 189912, "time": 25622.378212451935, "episode/length": 142.0, "episode/score": 5.2510277516953465, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.1510275469440785}
{"step": 190008, "time": 25654.844828367233, "eval_episode/length": 162.0, "eval_episode/score": 3.0999999716877937, "eval_episode/reward_rate": 0.9938650306748467}
{"step": 190008, "time": 25656.83385848999, "eval_episode/length": 171.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9709302325581395}
{"step": 190008, "time": 25656.84223842621, "eval_episode/length": 171.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9941860465116279}
{"step": 190008, "time": 25660.122137069702, "eval_episode/length": 175.0, "eval_episode/score": 6.099999971687794, "eval_episode/reward_rate": 0.9943181818181818}
{"step": 190008, "time": 25662.057545900345, "eval_episode/length": 184.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9567567567567568}
{"step": 190008, "time": 25663.918288707733, "eval_episode/length": 187.0, "eval_episode/score": 4.099999971687794, "eval_episode/reward_rate": 0.9946808510638298}
{"step": 190008, "time": 25667.543114423752, "eval_episode/length": 223.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9955357142857143}
{"step": 190008, "time": 25669.931938886642, "eval_episode/length": 230.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9826839826839827}
{"step": 190272, "time": 25701.642998933792, "episode/length": 138.0, "episode/score": 5.249070147203838, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.1490699088085421}
{"step": 190488, "time": 25729.324090480804, "episode/length": 206.0, "episode/score": 6.323813915668325, "episode/reward_rate": 0.9710144927536232, "episode/intrinsic_return": 0.22381372555628332}
{"step": 190552, "time": 25738.543524503708, "episode/length": 162.0, "episode/score": 5.275183387240304, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.17518314884500796}
{"step": 190688, "time": 25756.41339492798, "episode/length": 181.0, "episode/score": 4.28952400245862, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.18952389968717398}
{"step": 191056, "time": 25802.655524730682, "episode/length": 70.0, "episode/score": 4.186125121021178, "episode/reward_rate": 0.9295774647887324, "episode/intrinsic_return": 0.08612499822629616}
{"step": 191232, "time": 25825.44239258766, "episode/length": 199.0, "episode/score": 5.305034877143044, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.20503466249647317}
{"step": 191280, "time": 25832.76680278778, "episode/length": 253.0, "episode/score": 5.387832954433179, "episode/reward_rate": 0.9803149606299213, "episode/intrinsic_return": 0.2878328030001285}
{"step": 191360, "time": 25843.8920006752, "episode/length": 37.0, "episode/score": 0.13971728668548167, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.03971726121380925}
{"step": 191416, "time": 25852.09664273262, "episode/length": 273.0, "episode/score": 6.400973207934385, "episode/reward_rate": 0.9744525547445255, "episode/intrinsic_return": 0.3009729915270327}
{"step": 191792, "time": 25899.220799684525, "episode/length": 189.0, "episode/score": 4.2987599739317375, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.1987598499727028}
{"step": 191856, "time": 25908.50627017021, "episode/length": 242.0, "episode/score": 5.353008080142445, "episode/reward_rate": 0.9794238683127572, "episode/intrinsic_return": 0.2530079800776548}
{"step": 192472, "time": 25985.337528944016, "episode/length": 239.0, "episode/score": 7.360249364676292, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.2602490811118514}
{"step": 192504, "time": 25990.713020563126, "episode/length": 152.0, "episode/score": 6.2473683410678404, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.1473681449022024}
{"step": 192672, "time": 26012.514004468918, "episode/length": 156.0, "episode/score": 5.2632098383160155, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.16320965198747217}
{"step": 192928, "time": 26045.48047399521, "episode/length": 279.0, "episode/score": 5.404586074461804, "episode/reward_rate": 0.9857142857142858, "episode/intrinsic_return": 0.3045859456569815}
{"step": 193032, "time": 26059.490681886673, "episode/length": 224.0, "episode/score": 7.363323910931285, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.26332364541121933}
{"step": 193184, "time": 26079.37422966957, "episode/length": 165.0, "episode/score": 5.292173382581723, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.19217323114867213}
{"step": 193200, "time": 26082.88125514984, "episode/length": 229.0, "episode/score": 5.364571450671747, "episode/reward_rate": 0.9695652173913043, "episode/intrinsic_return": 0.2645713331010029}
{"step": 193256, "time": 26091.17359828949, "episode/length": 182.0, "episode/score": 4.263040916134742, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.16304073827541288}
{"step": 193824, "time": 26161.479333400726, "episode/length": 164.0, "episode/score": 6.268045392389013, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.16804529281898795}
{"step": 193984, "time": 26182.822429180145, "episode/length": 188.0, "episode/score": 5.31939976441322, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.21939953463265738}
{"step": 194080, "time": 26196.034178972244, "episode/length": 175.0, "episode/score": 5.284665534319856, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.18466538288680567}
{"step": 194240, "time": 26216.889763832092, "episode/length": 163.0, "episode/score": 5.2547254174414775, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.1547252358568585}
{"step": 194272, "time": 26222.462394475937, "episode/length": 154.0, "episode/score": 5.267101702193486, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.16710154959628198}
{"step": 194376, "time": 26236.49673628807, "episode/length": 139.0, "episode/score": 6.236858226300683, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.13685802213149145}
{"step": 194480, "time": 26250.600409030914, "episode/length": 161.0, "episode/score": 5.264790886842093, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.16479069291744963}
{"step": 194576, "time": 26263.62338757515, "episode/length": 171.0, "episode/score": 3.2897605546741033, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.18976043036582269}
{"step": 194792, "time": 26291.1068046093, "episode/length": 51.0, "episode/score": 3.156253196731768, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.05625310106165671}
{"step": 195217, "time": 26344.726684570312, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.135132820375504, "train/action_min": 0.0, "train/action_std": 3.218087020740714, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04735760401774158, "train/actor_opt_grad_steps": 47485.0, "train/actor_opt_loss": -10.811017398552227, "train/adv_mag": 0.593643085290027, "train/adv_max": 0.562498729075155, "train/adv_mean": 0.0025916840512304248, "train/adv_min": -0.4449123333218277, "train/adv_std": 0.0630656274896796, "train/cont_avg": 0.9942981350806451, "train/cont_loss_mean": 0.00015103675660723014, "train/cont_loss_std": 0.004222576331306798, "train/cont_neg_acc": 0.9959677419354839, "train/cont_neg_loss": 0.012843598123803071, "train/cont_pos_acc": 0.9999683422427024, "train/cont_pos_loss": 0.0001169116026243432, "train/cont_pred": 0.9942772593549503, "train/cont_rate": 0.9942981350806451, "train/dyn_loss_mean": 6.49752531256727, "train/dyn_loss_std": 8.624529848816575, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1211264908954661, "train/extr_critic_critic_opt_grad_steps": 47485.0, "train/extr_critic_critic_opt_loss": 15753.690377184139, "train/extr_critic_mag": 6.24712662799384, "train/extr_critic_max": 6.24712662799384, "train/extr_critic_mean": 1.201566316748178, "train/extr_critic_min": -0.6550206740697225, "train/extr_critic_std": 1.469046317121034, "train/extr_return_normed_mag": 1.6788958073944173, "train/extr_return_normed_max": 1.6788958073944173, "train/extr_return_normed_mean": 0.3285577664131759, "train/extr_return_normed_min": -0.16283253095643493, "train/extr_return_normed_std": 0.33938611827550397, "train/extr_return_rate": 0.5309868121659884, "train/extr_return_raw_mag": 7.1950547643887095, "train/extr_return_raw_max": 7.1950547643887095, "train/extr_return_raw_mean": 1.2130518731891469, "train/extr_return_raw_min": -0.9628370966642134, "train/extr_return_raw_std": 1.5038163495320145, "train/extr_reward_mag": 1.0165142756636425, "train/extr_reward_max": 1.0165142756636425, "train/extr_reward_mean": 0.02617981938785443, "train/extr_reward_min": -0.659097740086176, "train/extr_reward_std": 0.16079014359462646, "train/image_loss_mean": 4.148558256446674, "train/image_loss_std": 8.73364382918163, "train/model_loss_mean": 8.11985670879323, "train/model_loss_std": 12.674894860995714, "train/model_opt_grad_norm": 43.26262621725759, "train/model_opt_grad_steps": 47440.48924731183, "train/model_opt_loss": 10215.37155577957, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1263.4408602150538, "train/policy_entropy_mag": 2.533519785891297, "train/policy_entropy_max": 2.533519785891297, "train/policy_entropy_mean": 0.5391554271662107, "train/policy_entropy_min": 0.07937501374912519, "train/policy_entropy_std": 0.5665442350731101, "train/policy_logprob_mag": 7.438383671545213, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5387949161632086, "train/policy_logprob_min": -7.438383671545213, "train/policy_logprob_std": 1.0990822488261807, "train/policy_randomness_mag": 0.8942213039244374, "train/policy_randomness_max": 0.8942213039244374, "train/policy_randomness_mean": 0.19029820662352345, "train/policy_randomness_min": 0.02801589668798511, "train/policy_randomness_std": 0.19996525347232819, "train/post_ent_mag": 57.16972174695743, "train/post_ent_max": 57.16972174695743, "train/post_ent_mean": 37.947201698057114, "train/post_ent_min": 18.17703721856558, "train/post_ent_std": 6.3303447436260925, "train/prior_ent_mag": 72.79223255444599, "train/prior_ent_max": 72.79223255444599, "train/prior_ent_mean": 44.41851484647361, "train/prior_ent_min": 26.230853655005014, "train/prior_ent_std": 8.015505172873056, "train/rep_loss_mean": 6.49752531256727, "train/rep_loss_std": 8.624529848816575, "train/reward_avg": 0.01696611983452483, "train/reward_loss_mean": 0.07263226034019583, "train/reward_loss_std": 0.17734105684744414, "train/reward_max_data": 1.0098521811987764, "train/reward_max_pred": 1.0111005838199327, "train/reward_neg_acc": 0.998821848182268, "train/reward_neg_loss": 0.05204568116334818, "train/reward_pos_acc": 0.8566219242670203, "train/reward_pos_loss": 0.7692424571642311, "train/reward_pred": 0.016666087322562972, "train/reward_rate": 0.0287088373655914, "train_stats/sum_log_reward": 5.051219466982818, "train_stats/max_log_achievement_collect_drink": 4.536585365853658, "train_stats/max_log_achievement_collect_sapling": 2.1219512195121952, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 5.073170731707317, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.17073170731707318, "train_stats/max_log_achievement_eat_cow": 0.12195121951219512, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.3170731707317073, "train_stats/max_log_achievement_place_plant": 1.7560975609756098, "train_stats/max_log_achievement_place_table": 1.8048780487804879, "train_stats/max_log_achievement_wake_up": 2.2439024390243905, "train_stats/mean_log_entropy": 0.4376714941931934, "eval_stats/sum_log_reward": 4.974999964237213, "eval_stats/max_log_achievement_collect_drink": 4.25, "eval_stats/max_log_achievement_collect_sapling": 1.875, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 6.125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.5, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.5, "eval_stats/max_log_achievement_place_plant": 1.625, "eval_stats/max_log_achievement_place_table": 2.375, "eval_stats/max_log_achievement_wake_up": 2.75, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 5.265853542368859e-05, "report/cont_loss_std": 0.0015306525165215135, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0004549240111373365, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 4.988974615116604e-05, "report/cont_pred": 0.9931188225746155, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 5.917837142944336, "report/dyn_loss_std": 8.742145538330078, "report/image_loss_mean": 4.111793041229248, "report/image_loss_std": 7.978998184204102, "report/model_loss_mean": 7.738478660583496, "report/model_loss_std": 12.060620307922363, "report/post_ent_mag": 60.924678802490234, "report/post_ent_max": 60.924678802490234, "report/post_ent_mean": 38.53300476074219, "report/post_ent_min": 18.88569450378418, "report/post_ent_std": 6.897493839263916, "report/prior_ent_mag": 73.04618835449219, "report/prior_ent_max": 73.04618835449219, "report/prior_ent_mean": 43.98021697998047, "report/prior_ent_min": 27.222192764282227, "report/prior_ent_std": 8.877123832702637, "report/rep_loss_mean": 5.917837142944336, "report/rep_loss_std": 8.742145538330078, "report/reward_avg": 0.01929542049765587, "report/reward_loss_mean": 0.07593061029911041, "report/reward_loss_std": 0.15298648178577423, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0024020671844482, "report/reward_neg_acc": 0.9969635605812073, "report/reward_neg_loss": 0.053961131721735, "report/reward_pos_acc": 0.7222222089767456, "report/reward_pos_loss": 0.6788707375526428, "report/reward_pred": 0.020724009722471237, "report/reward_rate": 0.03515625, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 2.1383595594670624e-05, "eval/cont_loss_std": 0.0003594607696868479, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0027888508047908545, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 5.072392468719045e-06, "eval/cont_pred": 0.9941518902778625, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 23.246877670288086, "eval/dyn_loss_std": 13.215079307556152, "eval/image_loss_mean": 34.837364196777344, "eval/image_loss_std": 39.76056671142578, "eval/model_loss_mean": 48.905452728271484, "eval/model_loss_std": 44.638946533203125, "eval/post_ent_mag": 58.40277862548828, "eval/post_ent_max": 58.40277862548828, "eval/post_ent_mean": 38.67646408081055, "eval/post_ent_min": 22.327056884765625, "eval/post_ent_std": 6.491264820098877, "eval/prior_ent_mag": 73.04618835449219, "eval/prior_ent_max": 73.04618835449219, "eval/prior_ent_mean": 51.45805740356445, "eval/prior_ent_min": 26.148178100585938, "eval/prior_ent_std": 7.961638450622559, "eval/rep_loss_mean": 23.246877670288086, "eval/rep_loss_std": 13.215079307556152, "eval/reward_avg": 0.02011718787252903, "eval/reward_loss_mean": 0.11994439363479614, "eval/reward_loss_std": 0.8633226752281189, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.000610589981079, "eval/reward_neg_acc": 0.9989979863166809, "eval/reward_neg_loss": 0.04395674541592598, "eval/reward_pos_acc": 0.6538462042808533, "eval/reward_pos_loss": 3.03670072555542, "eval/reward_pred": 0.012425139546394348, "eval/reward_rate": 0.025390625, "replay/size": 194713.0, "replay/inserts": 7432.0, "replay/samples": 29728.0, "replay/insert_wait_avg": 1.6742874141401571e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.559331805636731e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 38352.0, "eval_replay/inserts": 1848.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1891255647073061e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.493661880493164e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2395260334015, "timer/env.step_count": 929.0, "timer/env.step_total": 88.98229885101318, "timer/env.step_frac": 0.08896099037786051, "timer/env.step_avg": 0.09578288358559008, "timer/env.step_min": 0.023249149322509766, "timer/env.step_max": 3.206148624420166, "timer/replay._sample_count": 29728.0, "timer/replay._sample_total": 14.55008840560913, "timer/replay._sample_frac": 0.01454660411522595, "timer/replay._sample_avg": 0.0004894405410928798, "timer/replay._sample_min": 0.0003833770751953125, "timer/replay._sample_max": 0.028478622436523438, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1160.0, "timer/agent.policy_total": 18.55911374092102, "timer/agent.policy_frac": 0.018554669414555077, "timer/agent.policy_avg": 0.015999235983552604, "timer/agent.policy_min": 0.010205745697021484, "timer/agent.policy_max": 0.04105401039123535, "timer/dataset_train_count": 1858.0, "timer/dataset_train_total": 0.303358793258667, "timer/dataset_train_frac": 0.0003032861483305718, "timer/dataset_train_avg": 0.0001632716863609618, "timer/dataset_train_min": 9.465217590332031e-05, "timer/dataset_train_max": 0.0004999637603759766, "timer/agent.train_count": 1858.0, "timer/agent.train_total": 829.2263133525848, "timer/agent.train_frac": 0.8290277396265323, "timer/agent.train_avg": 0.44630049157835566, "timer/agent.train_min": 0.43498682975769043, "timer/agent.train_max": 1.165602207183838, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48068714141845703, "timer/agent.report_frac": 0.0004805720319058909, "timer/agent.report_avg": 0.24034357070922852, "timer/agent.report_min": 0.23577570915222168, "timer/agent.report_max": 0.24491143226623535, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.384185791015625e-05, "timer/dataset_eval_frac": 2.38361485320468e-08, "timer/dataset_eval_avg": 2.384185791015625e-05, "timer/dataset_eval_min": 2.384185791015625e-05, "timer/dataset_eval_max": 2.384185791015625e-05, "fps": 7.430114919481479}
{"step": 195296, "time": 26354.197380542755, "episode/length": 89.0, "episode/score": 5.191400866036474, "episode/reward_rate": 0.9333333333333333, "episode/intrinsic_return": 0.09140070243802256}
{"step": 195368, "time": 26364.462568044662, "episode/length": 71.0, "episode/score": 4.176700804027178, "episode/reward_rate": 0.9305555555555556, "episode/intrinsic_return": 0.07670068123229612}
{"step": 195432, "time": 26373.79275751114, "episode/length": 144.0, "episode/score": 4.255373796346703, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.1553736735518214}
{"step": 195544, "time": 26389.051660060883, "episode/length": 162.0, "episode/score": 5.289881370649937, "episode/reward_rate": 0.9631901840490797, "episode/intrinsic_return": 0.18988119255777747}
{"step": 195592, "time": 26396.450345277786, "episode/length": 188.0, "episode/score": 5.310280042484237, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.2102798910511865}
{"step": 195952, "time": 26441.853237628937, "episode/length": 245.0, "episode/score": 6.370879465878261, "episode/reward_rate": 0.9959349593495935, "episode/intrinsic_return": 0.27087919209270694}
{"step": 196208, "time": 26474.362047433853, "episode/length": 215.0, "episode/score": 6.33998357448877, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.23998343041898806}
{"step": 196512, "time": 26512.720591068268, "episode/length": 151.0, "episode/score": 6.258327219464036, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.15832700807709443}
{"step": 196608, "time": 26526.747051477432, "episode/length": 347.0, "episode/score": 5.478331055107674, "episode/reward_rate": 0.9971264367816092, "episode/intrinsic_return": 0.3783309412185645}
{"step": 196680, "time": 26537.659446954727, "episode/length": 155.0, "episode/score": 5.255605288384686, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.15560513543823618}
{"step": 196760, "time": 26549.55806875229, "episode/length": 173.0, "episode/score": 4.28653333030752, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.18653320984094535}
{"step": 197064, "time": 26588.19168663025, "episode/length": 189.0, "episode/score": 4.292275291569922, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.19227517116155468}
{"step": 197208, "time": 26607.219814300537, "episode/length": 124.0, "episode/score": 1.2147802306419635, "episode/reward_rate": 0.992, "episode/intrinsic_return": 0.1147802020270774}
{"step": 197440, "time": 26636.95871067047, "episode/length": 230.0, "episode/score": 6.337207978515835, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.23720793569827947}
{"step": 197552, "time": 26652.205510616302, "episode/length": 129.0, "episode/score": 5.221140879265022, "episode/reward_rate": 0.9923076923076923, "episode/intrinsic_return": 0.12114067102129411}
{"step": 197560, "time": 26654.882304430008, "episode/length": 200.0, "episode/score": 5.317007778974585, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.2170075733502017}
{"step": 197968, "time": 26705.805094242096, "episode/length": 169.0, "episode/score": 5.264871035321903, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.16487085638573262}
{"step": 198224, "time": 26738.270720243454, "episode/length": 192.0, "episode/score": 5.285722200212149, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.18572196181685285}
{"step": 198248, "time": 26742.646458387375, "episode/length": 185.0, "episode/score": 7.286170354543174, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.18617009814715857}
{"step": 198456, "time": 26769.648063898087, "episode/length": 173.0, "episode/score": 4.288912251395004, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.18891208238323998}
{"step": 198664, "time": 26796.499591350555, "episode/length": 181.0, "episode/score": 5.288636795015918, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.18863664591117413}
{"step": 198808, "time": 26815.43062210083, "episode/length": 156.0, "episode/score": 7.270810091105659, "episode/reward_rate": 0.9808917197452229, "episode/intrinsic_return": 0.17080980986952454}
{"step": 199176, "time": 26861.522701501846, "episode/length": 201.0, "episode/score": 6.298718002270107, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.19871788710042892}
{"step": 199280, "time": 26875.690472602844, "episode/length": 229.0, "episode/score": 6.343976383949212, "episode/reward_rate": 0.9826086956521739, "episode/intrinsic_return": 0.24397631191141045}
{"step": 199416, "time": 26893.77960753441, "episode/length": 180.0, "episode/score": 5.300392874587033, "episode/reward_rate": 0.9668508287292817, "episode/intrinsic_return": 0.20039272862550206}
{"step": 199664, "time": 26925.29260492325, "episode/length": 179.0, "episode/score": 5.2975726260795, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.19757253349439452}
{"step": 199752, "time": 26937.341885089874, "episode/length": 187.0, "episode/score": 4.308786571236169, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.20878644844128758}
{"step": 200096, "time": 26994.922307014465, "eval_episode/length": 34.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 200096, "time": 27001.086691617966, "eval_episode/length": 145.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9931506849315068}
{"step": 200096, "time": 27003.91286921501, "eval_episode/length": 175.0, "eval_episode/score": 6.100000016391277, "eval_episode/reward_rate": 0.9829545454545454}
{"step": 200096, "time": 27005.587334871292, "eval_episode/length": 178.0, "eval_episode/score": 4.099999971687794, "eval_episode/reward_rate": 0.994413407821229}
{"step": 200096, "time": 27007.420350313187, "eval_episode/length": 186.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9732620320855615}
{"step": 200096, "time": 27009.915227413177, "eval_episode/length": 208.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9952153110047847}
{"step": 200096, "time": 27011.67712163925, "eval_episode/length": 213.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9766355140186916}
{"step": 200096, "time": 27014.748575925827, "eval_episode/length": 251.0, "eval_episode/score": 3.0999999940395355, "eval_episode/reward_rate": 0.996031746031746}
{"step": 200344, "time": 27044.730902433395, "episode/length": 209.0, "episode/score": 4.3357224331616635, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.2357223914500537}
{"step": 200496, "time": 27064.64239525795, "episode/length": 254.0, "episode/score": 6.360410118091295, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.2604099415125347}
{"step": 200888, "time": 27113.778911828995, "episode/length": 259.0, "episode/score": 5.381900337297793, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.28190021456111936}
{"step": 201016, "time": 27131.596447706223, "episode/length": 157.0, "episode/score": 5.248771549066987, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.14877137806161045}
{"step": 201224, "time": 27158.400071144104, "episode/length": 225.0, "episode/score": 4.324868699830404, "episode/reward_rate": 0.9778761061946902, "episode/intrinsic_return": 0.22486854688395397}
{"step": 201360, "time": 27176.411129951477, "episode/length": 211.0, "episode/score": 5.317697789599833, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.21769765819021814}
{"step": 201632, "time": 27211.02546596527, "episode/length": 306.0, "episode/score": 3.4491360900569816, "episode/reward_rate": 0.9869706840390879, "episode/intrinsic_return": 0.34913596924116064}
{"step": 202000, "time": 27257.17949128151, "episode/length": 339.0, "episode/score": 6.458852532199671, "episode/reward_rate": 0.9882352941176471, "episode/intrinsic_return": 0.35885235000387183}
{"step": 202096, "time": 27270.528647184372, "episode/length": 218.0, "episode/score": 5.363982273818692, "episode/reward_rate": 0.9634703196347032, "episode/intrinsic_return": 0.2639821375196334}
{"step": 202248, "time": 27290.3393137455, "episode/length": 218.0, "episode/score": 4.32120798139772, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.22120785860283831}
{"step": 202304, "time": 27298.803983211517, "episode/length": 176.0, "episode/score": 3.2690070975872914, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.16900706198020998}
{"step": 202665, "time": 27344.861965417862, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.33860828030494, "train/action_min": 0.0, "train/action_std": 3.2865992246135587, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04810380004346371, "train/actor_opt_grad_steps": 49345.0, "train/actor_opt_loss": -14.32936475998772, "train/adv_mag": 0.6357595888517236, "train/adv_max": 0.6078788758285584, "train/adv_mean": 0.0016311646135148696, "train/adv_min": -0.48505083447502506, "train/adv_std": 0.06363489534906162, "train/cont_avg": 0.9945081485215054, "train/cont_loss_mean": 0.0001271364360614906, "train/cont_loss_std": 0.00359464622030928, "train/cont_neg_acc": 0.996460573968067, "train/cont_neg_loss": 0.008023605223599824, "train/cont_pos_acc": 0.9999841451644897, "train/cont_pos_loss": 8.391470531069968e-05, "train/cont_pred": 0.994512613101672, "train/cont_rate": 0.9945081485215054, "train/dyn_loss_mean": 6.627682291051393, "train/dyn_loss_std": 8.739678893038022, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1078463411459358, "train/extr_critic_critic_opt_grad_steps": 49345.0, "train/extr_critic_critic_opt_loss": 15660.868179813508, "train/extr_critic_mag": 6.429500341415405, "train/extr_critic_max": 6.429500341415405, "train/extr_critic_mean": 1.0898439067025338, "train/extr_critic_min": -0.6248781181150868, "train/extr_critic_std": 1.4207379856417257, "train/extr_return_normed_mag": 1.7494641683434928, "train/extr_return_normed_max": 1.7494641683434928, "train/extr_return_normed_mean": 0.3108005636642056, "train/extr_return_normed_min": -0.16343232600759433, "train/extr_return_normed_std": 0.33781728316699305, "train/extr_return_rate": 0.49042201394675883, "train/extr_return_raw_mag": 7.274558908195906, "train/extr_return_raw_max": 7.274558908195906, "train/extr_return_raw_mean": 1.096798472667253, "train/extr_return_raw_min": -0.9383465340060573, "train/extr_return_raw_std": 1.4507871289407053, "train/extr_reward_mag": 1.02093509833018, "train/extr_reward_max": 1.02093509833018, "train/extr_reward_mean": 0.026073314745219484, "train/extr_reward_min": -0.6529706235854856, "train/extr_reward_std": 0.1589758358094641, "train/image_loss_mean": 4.111153264199534, "train/image_loss_std": 9.063064104767255, "train/model_loss_mean": 8.160758992677094, "train/model_loss_std": 13.08894564772165, "train/model_opt_grad_norm": 44.858965760918075, "train/model_opt_grad_steps": 49298.66129032258, "train/model_opt_loss": 10852.754746303763, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1330.6451612903227, "train/policy_entropy_mag": 2.5595241938867876, "train/policy_entropy_max": 2.5595241938867876, "train/policy_entropy_mean": 0.5785293521419648, "train/policy_entropy_min": 0.07937501382923895, "train/policy_entropy_std": 0.6066254393387867, "train/policy_logprob_mag": 7.43838365616337, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5776518789991256, "train/policy_logprob_min": -7.43838365616337, "train/policy_logprob_std": 1.124150162742984, "train/policy_randomness_mag": 0.9033997206277745, "train/policy_randomness_max": 0.9033997206277745, "train/policy_randomness_mean": 0.20419547370364588, "train/policy_randomness_min": 0.02801589670801355, "train/policy_randomness_std": 0.2141121587445659, "train/post_ent_mag": 57.42955574938046, "train/post_ent_max": 57.42955574938046, "train/post_ent_mean": 38.29651391634377, "train/post_ent_min": 18.244990974344233, "train/post_ent_std": 6.392655952002412, "train/prior_ent_mag": 72.98213437808457, "train/prior_ent_max": 72.98213437808457, "train/prior_ent_mean": 44.90370139255319, "train/prior_ent_min": 26.624557833517752, "train/prior_ent_std": 7.9495587425847205, "train/rep_loss_mean": 6.627682291051393, "train/rep_loss_std": 8.739678893038022, "train/reward_avg": 0.017696715459497945, "train/reward_loss_mean": 0.07286921039383898, "train/reward_loss_std": 0.18185816072328118, "train/reward_max_data": 1.0120027193459131, "train/reward_max_pred": 1.0118497526773842, "train/reward_neg_acc": 0.9987772882625621, "train/reward_neg_loss": 0.05175880755307854, "train/reward_pos_acc": 0.8654425836378529, "train/reward_pos_loss": 0.7788882435009044, "train/reward_pred": 0.01737783104056112, "train/reward_rate": 0.029123613911290324, "train_stats/sum_log_reward": 4.968421007457533, "train_stats/max_log_achievement_collect_drink": 6.315789473684211, "train_stats/max_log_achievement_collect_sapling": 2.1578947368421053, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 5.578947368421052, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.2631578947368421, "train_stats/max_log_achievement_eat_cow": 0.10526315789473684, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.2631578947368421, "train_stats/max_log_achievement_place_plant": 1.631578947368421, "train_stats/max_log_achievement_place_table": 2.0526315789473686, "train_stats/max_log_achievement_wake_up": 2.3684210526315788, "train_stats/mean_log_entropy": 0.5154010575068625, "eval_stats/sum_log_reward": 4.0999999195337296, "eval_stats/max_log_achievement_collect_drink": 2.375, "eval_stats/max_log_achievement_collect_sapling": 1.875, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 4.375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.125, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.25, "eval_stats/max_log_achievement_place_plant": 1.5, "eval_stats/max_log_achievement_place_table": 1.75, "eval_stats/max_log_achievement_wake_up": 2.125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 9.881141522782855e-06, "report/cont_loss_std": 0.00014765663945581764, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0002544939052313566, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 8.439416887995321e-06, "report/cont_pred": 0.9941338300704956, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 6.688460350036621, "report/dyn_loss_std": 8.800641059875488, "report/image_loss_mean": 3.834880828857422, "report/image_loss_std": 8.561553955078125, "report/model_loss_mean": 7.915370941162109, "report/model_loss_std": 12.790140151977539, "report/post_ent_mag": 61.69027328491211, "report/post_ent_max": 61.69027328491211, "report/post_ent_mean": 38.36541748046875, "report/post_ent_min": 16.47500991821289, "report/post_ent_std": 6.801050662994385, "report/prior_ent_mag": 72.83056640625, "report/prior_ent_max": 72.83056640625, "report/prior_ent_mean": 44.837711334228516, "report/prior_ent_min": 27.236705780029297, "report/prior_ent_std": 8.67121696472168, "report/rep_loss_mean": 6.688460350036621, "report/rep_loss_std": 8.800641059875488, "report/reward_avg": 0.010530768893659115, "report/reward_loss_mean": 0.06740404665470123, "report/reward_loss_std": 0.17283456027507782, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0023324489593506, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.04831330478191376, "report/reward_pos_acc": 0.8695652484893799, "report/reward_pos_loss": 0.898266613483429, "report/reward_pred": 0.009647222235798836, "report/reward_rate": 0.0224609375, "eval/cont_avg": 0.9931640625, "eval/cont_loss_mean": 0.015779731795191765, "eval/cont_loss_std": 0.4263613820075989, "eval/cont_neg_acc": 0.7142857313156128, "eval/cont_neg_loss": 2.3082480430603027, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 7.009173828009807e-07, "eval/cont_pred": 0.9950944781303406, "eval/cont_rate": 0.9931640625, "eval/dyn_loss_mean": 20.716691970825195, "eval/dyn_loss_std": 13.171422004699707, "eval/image_loss_mean": 29.719039916992188, "eval/image_loss_std": 40.15904998779297, "eval/model_loss_mean": 42.32182312011719, "eval/model_loss_std": 45.331214904785156, "eval/post_ent_mag": 56.68306350708008, "eval/post_ent_max": 56.68306350708008, "eval/post_ent_mean": 37.98368835449219, "eval/post_ent_min": 20.553516387939453, "eval/post_ent_std": 5.715893268585205, "eval/prior_ent_mag": 72.83056640625, "eval/prior_ent_max": 72.83056640625, "eval/prior_ent_mean": 50.04637145996094, "eval/prior_ent_min": 31.38545036315918, "eval/prior_ent_std": 7.047005653381348, "eval/rep_loss_mean": 20.716691970825195, "eval/rep_loss_std": 13.171422004699707, "eval/reward_avg": 0.01083984412252903, "eval/reward_loss_mean": 0.15699037909507751, "eval/reward_loss_std": 0.9944341778755188, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.000617504119873, "eval/reward_neg_acc": 0.991062581539154, "eval/reward_neg_loss": 0.08158206194639206, "eval/reward_pos_acc": 0.4117647111415863, "eval/reward_pos_loss": 4.623824119567871, "eval/reward_pred": 0.006484074052423239, "eval/reward_rate": 0.0166015625, "replay/size": 202161.0, "replay/inserts": 7448.0, "replay/samples": 29792.0, "replay/insert_wait_avg": 1.5942481867608912e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.281642083066619e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 40368.0, "eval_replay/inserts": 2016.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1595705198863196e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.791685104370117e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1253070831299, "timer/env.step_count": 931.0, "timer/env.step_total": 84.49433732032776, "timer/env.step_frac": 0.08448375090792962, "timer/env.step_avg": 0.09075653847511038, "timer/env.step_min": 0.023120403289794922, "timer/env.step_max": 2.136176586151123, "timer/replay._sample_count": 29792.0, "timer/replay._sample_total": 14.340502977371216, "timer/replay._sample_frac": 0.014338706235916937, "timer/replay._sample_avg": 0.0004813541547184216, "timer/replay._sample_min": 0.0003669261932373047, "timer/replay._sample_max": 0.02900981903076172, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1183.0, "timer/agent.policy_total": 19.031104564666748, "timer/agent.policy_frac": 0.019028720131251405, "timer/agent.policy_avg": 0.016087155168780006, "timer/agent.policy_min": 0.009657144546508789, "timer/agent.policy_max": 0.057920217514038086, "timer/dataset_train_count": 1862.0, "timer/dataset_train_total": 0.30495691299438477, "timer/dataset_train_frac": 0.0003049187045209295, "timer/dataset_train_avg": 0.00016377922287560943, "timer/dataset_train_min": 9.679794311523438e-05, "timer/dataset_train_max": 0.001252889633178711, "timer/agent.train_count": 1862.0, "timer/agent.train_total": 834.1618371009827, "timer/agent.train_frac": 0.8340573238105728, "timer/agent.train_avg": 0.4479923937169617, "timer/agent.train_min": 0.4354889392852783, "timer/agent.train_max": 0.9640600681304932, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48043107986450195, "timer/agent.report_frac": 0.00048037088598995803, "timer/agent.report_avg": 0.24021553993225098, "timer/agent.report_min": 0.23282361030578613, "timer/agent.report_max": 0.24760746955871582, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7894973754882812e-05, "timer/dataset_eval_frac": 2.789147875503584e-08, "timer/dataset_eval_avg": 2.7894973754882812e-05, "timer/dataset_eval_min": 2.7894973754882812e-05, "timer/dataset_eval_max": 2.7894973754882812e-05, "fps": 7.446965468820656}
{"step": 202872, "time": 27369.86083292961, "episode/length": 231.0, "episode/score": 4.345105137153041, "episode/reward_rate": 0.978448275862069, "episode/intrinsic_return": 0.24510508722687518}
{"step": 202896, "time": 27374.252640485764, "episode/length": 208.0, "episode/score": 5.312167424796826, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.21216721888140455}
{"step": 203392, "time": 27435.70897603035, "episode/length": 173.0, "episode/score": 6.279505191479075, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.1795049511047182}
{"step": 203400, "time": 27438.238968610764, "episode/length": 162.0, "episode/score": 5.277850401395426, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.1778502563506663}
{"step": 203472, "time": 27448.446295022964, "episode/length": 263.0, "episode/score": 6.3920164634432695, "episode/reward_rate": 0.9848484848484849, "episode/intrinsic_return": 0.2920164150668825}
{"step": 203544, "time": 27458.762870788574, "episode/length": 154.0, "episode/score": 6.2307370435321445, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.13073688633653546}
{"step": 203696, "time": 27478.775496006012, "episode/length": 257.0, "episode/score": 6.3988371978327905, "episode/reward_rate": 0.9806201550387597, "episode/intrinsic_return": 0.29883702241818355}
{"step": 203728, "time": 27484.203689813614, "episode/length": 184.0, "episode/score": 4.311432752042492, "episode/reward_rate": 0.9675675675675676, "episode/intrinsic_return": 0.21143263448630023}
{"step": 204272, "time": 27551.41582250595, "episode/length": 171.0, "episode/score": 6.288862026040988, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.18886189707609446}
{"step": 204400, "time": 27568.258400917053, "episode/length": 83.0, "episode/score": 4.183561588358998, "episode/reward_rate": 0.9404761904761905, "episode/intrinsic_return": 0.08356142517527587}
{"step": 204408, "time": 27570.800359487534, "episode/length": 191.0, "episode/score": 4.3210908916423705, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.22109071203681196}
{"step": 204656, "time": 27602.29306268692, "episode/length": 156.0, "episode/score": 5.281019118950098, "episode/reward_rate": 0.9617834394904459, "episode/intrinsic_return": 0.1810189733378138}
{"step": 204744, "time": 27614.831172943115, "episode/length": 149.0, "episode/score": 6.238112318278809, "episode/reward_rate": 0.9733333333333334, "episode/intrinsic_return": 0.13811210628068693}
{"step": 204896, "time": 27636.223670244217, "episode/length": 177.0, "episode/score": 6.297051274376599, "episode/reward_rate": 0.9662921348314607, "episode/intrinsic_return": 0.19705109779783925}
{"step": 205040, "time": 27655.153791189194, "episode/length": 167.0, "episode/score": 3.2951061591525104, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.19510609200415274}
{"step": 205136, "time": 27668.334565401077, "episode/length": 217.0, "episode/score": 4.347511941890161, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.24751182083423373}
{"step": 205520, "time": 27716.397174596786, "episode/length": 155.0, "episode/score": 5.252150851079477, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.1521507811662559}
{"step": 205528, "time": 27718.92517566681, "episode/length": 139.0, "episode/score": 4.25208026039968, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.15208007683600044}
{"step": 205936, "time": 27770.24531340599, "episode/length": 191.0, "episode/score": 5.276128392808232, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.17612825488663475}
{"step": 206128, "time": 27795.12417435646, "episode/length": 172.0, "episode/score": 6.2842562343723785, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.18425606239202352}
{"step": 206200, "time": 27805.35651755333, "episode/length": 162.0, "episode/score": 4.284505481707356, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.18450535891247455}
{"step": 206288, "time": 27817.659593105316, "episode/length": 143.0, "episode/score": 4.247546524808172, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.14754631505104499}
{"step": 206328, "time": 27823.990765810013, "episode/length": 208.0, "episode/score": 4.310218126303425, "episode/reward_rate": 0.9808612440191388, "episode/intrinsic_return": 0.21021797219282234}
{"step": 206784, "time": 27880.50747680664, "episode/length": 56.0, "episode/score": 3.1675001066178083, "episode/reward_rate": 0.9298245614035088, "episode/intrinsic_return": 0.06749999872408807}
{"step": 206864, "time": 27891.707877397537, "episode/length": 167.0, "episode/score": 5.269504607416366, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.16950440997015903}
{"step": 207096, "time": 27921.189427137375, "episode/length": 256.0, "episode/score": 5.3784331790755004, "episode/reward_rate": 0.9766536964980544, "episode/intrinsic_return": 0.27843303694112365}
{"step": 207288, "time": 27945.880436182022, "episode/length": 219.0, "episode/score": 6.353816954494391, "episode/reward_rate": 0.9727272727272728, "episode/intrinsic_return": 0.2538167899573409}
{"step": 207424, "time": 27964.63685321808, "episode/length": 185.0, "episode/score": 1.312949914204637, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.21294983448342464}
{"step": 207640, "time": 27992.288236141205, "episode/length": 168.0, "episode/score": 3.262364267949806, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.16236411931072325}
{"step": 207672, "time": 27997.639488697052, "episode/length": 192.0, "episode/score": 5.305158356385732, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.20515820378852823}
{"step": 207704, "time": 28003.00167107582, "episode/length": 187.0, "episode/score": 5.288739614996416, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.18873946472751868}
{"step": 207968, "time": 28036.431941986084, "episode/length": 40.0, "episode/score": 3.1477917772135697, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.047791665827389807}
{"step": 208232, "time": 28069.95946073532, "episode/length": 180.0, "episode/score": 5.276006767270019, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.17600669161606675}
{"step": 208344, "time": 28085.06448698044, "episode/length": 46.0, "episode/score": 2.151517022907001, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.05151690022853472}
{"step": 208688, "time": 28128.309372663498, "episode/length": 227.0, "episode/score": 6.344400012636129, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.2443998360573687}
{"step": 208712, "time": 28132.758246660233, "episode/length": 201.0, "episode/score": 5.286356498387249, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.18635633088888426}
{"step": 208784, "time": 28143.170494556427, "episode/length": 169.0, "episode/score": 6.268223443800252, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.168223246499565}
{"step": 209056, "time": 28177.53332424164, "episode/length": 220.0, "episode/score": 6.327730836009891, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.22773073072096395}
{"step": 209320, "time": 28211.010668754578, "episode/length": 201.0, "episode/score": 7.320779480260057, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.22077921357583818}
{"step": 209480, "time": 28231.900550365448, "episode/length": 155.0, "episode/score": 6.266552188610035, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.1665519783872469}
{"step": 209888, "time": 28283.330109119415, "episode/length": 192.0, "episode/score": 5.313854118200538, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.2138539652540885}
{"step": 210080, "time": 28328.158385276794, "eval_episode/length": 142.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.993006993006993}
{"step": 210080, "time": 28330.95417523384, "eval_episode/length": 171.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.9767441860465116}
{"step": 210080, "time": 28332.71421432495, "eval_episode/length": 175.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9715909090909091}
{"step": 210080, "time": 28334.60843515396, "eval_episode/length": 183.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9782608695652174}
{"step": 210080, "time": 28336.463719129562, "eval_episode/length": 191.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9739583333333334}
{"step": 210080, "time": 28339.085247516632, "eval_episode/length": 218.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9954337899543378}
{"step": 210080, "time": 28341.031879663467, "eval_episode/length": 228.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9781659388646288}
{"step": 210080, "time": 28342.560449123383, "eval_episode/length": 53.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9814814814814815}
{"step": 210093, "time": 28345.01380085945, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.319944320186492, "train/action_min": 0.0, "train/action_std": 3.3682850009651593, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.05031076328007765, "train/actor_opt_grad_steps": 51205.0, "train/actor_opt_loss": -7.23779387595833, "train/adv_mag": 0.6228929822162915, "train/adv_max": 0.588391780693044, "train/adv_mean": 0.003685753741000974, "train/adv_min": -0.4931514340062295, "train/adv_std": 0.06600722728637598, "train/cont_avg": 0.9944398941532258, "train/cont_loss_mean": 0.00014927661820985532, "train/cont_loss_std": 0.004319759130121456, "train/cont_neg_acc": 0.995351170339892, "train/cont_neg_loss": 0.01387756706215011, "train/cont_pos_acc": 0.999984142280394, "train/cont_pos_loss": 6.49011634429809e-05, "train/cont_pred": 0.994444050135151, "train/cont_rate": 0.9944398941532258, "train/dyn_loss_mean": 6.582128255598007, "train/dyn_loss_std": 8.680503229941092, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1037416964448907, "train/extr_critic_critic_opt_grad_steps": 51205.0, "train/extr_critic_critic_opt_loss": 15925.888246597782, "train/extr_critic_mag": 6.132008078277752, "train/extr_critic_max": 6.132008078277752, "train/extr_critic_mean": 1.086941054431341, "train/extr_critic_min": -0.62353596315589, "train/extr_critic_std": 1.3798307744405602, "train/extr_return_normed_mag": 1.7251633232639683, "train/extr_return_normed_max": 1.7251633232639683, "train/extr_return_normed_mean": 0.313544363824911, "train/extr_return_normed_min": -0.16623344136181697, "train/extr_return_normed_std": 0.33467275240728933, "train/extr_return_rate": 0.4976674755734782, "train/extr_return_raw_mag": 7.07783527271722, "train/extr_return_raw_max": 7.07783527271722, "train/extr_return_raw_mean": 1.1025365719231226, "train/extr_return_raw_min": -0.9269298965572029, "train/extr_return_raw_std": 1.416256554665104, "train/extr_reward_mag": 1.015550442921218, "train/extr_reward_max": 1.015550442921218, "train/extr_reward_mean": 0.028118764250589314, "train/extr_reward_min": -0.6399887088806399, "train/extr_reward_std": 0.16486287481522047, "train/image_loss_mean": 4.062212506930034, "train/image_loss_std": 8.711412663100868, "train/model_loss_mean": 8.085687004109865, "train/model_loss_std": 12.71926438423895, "train/model_opt_grad_norm": 43.41923440469278, "train/model_opt_grad_steps": 51157.17204301075, "train/model_opt_loss": 11675.651212302588, "train/model_opt_model_opt_grad_overflow": 0.005376344086021506, "train/model_opt_model_opt_grad_scale": 1444.8924731182797, "train/policy_entropy_mag": 2.5535609529864405, "train/policy_entropy_max": 2.5535609529864405, "train/policy_entropy_mean": 0.5511019439786993, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.5964545463362048, "train/policy_logprob_mag": 7.43838373819987, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5506128085556851, "train/policy_logprob_min": -7.43838373819987, "train/policy_logprob_std": 1.1088870122868528, "train/policy_randomness_mag": 0.9012949569250948, "train/policy_randomness_max": 0.9012949569250948, "train/policy_randomness_mean": 0.1945148023866838, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.2105222811461777, "train/post_ent_mag": 57.69731021183793, "train/post_ent_max": 57.69731021183793, "train/post_ent_mean": 38.90517312736922, "train/post_ent_min": 18.455435311922464, "train/post_ent_std": 6.495450350546068, "train/prior_ent_mag": 73.10855221491988, "train/prior_ent_max": 73.10855221491988, "train/prior_ent_mean": 45.44745906706779, "train/prior_ent_min": 26.90813970053068, "train/prior_ent_std": 7.797128905532181, "train/rep_loss_mean": 6.582128255598007, "train/rep_loss_std": 8.680503229941092, "train/reward_avg": 0.019214751877351312, "train/reward_loss_mean": 0.07404830871570495, "train/reward_loss_std": 0.18815237211604272, "train/reward_max_data": 1.0103898157355606, "train/reward_max_pred": 1.0104297232884232, "train/reward_neg_acc": 0.9987154772845648, "train/reward_neg_loss": 0.052207572145327445, "train/reward_pos_acc": 0.8750624329813065, "train/reward_pos_loss": 0.7718821142309455, "train/reward_pred": 0.018945574530109924, "train/reward_rate": 0.030525453629032258, "train_stats/sum_log_reward": 4.8804877124181605, "train_stats/max_log_achievement_collect_drink": 4.146341463414634, "train_stats/max_log_achievement_collect_sapling": 2.6097560975609757, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 4.926829268292683, "train_stats/max_log_achievement_defeat_skeleton": 0.024390243902439025, "train_stats/max_log_achievement_defeat_zombie": 0.2682926829268293, "train_stats/max_log_achievement_eat_cow": 0.0975609756097561, "train_stats/max_log_achievement_make_wood_pickaxe": 0.024390243902439025, "train_stats/max_log_achievement_make_wood_sword": 0.36585365853658536, "train_stats/max_log_achievement_place_plant": 2.097560975609756, "train_stats/max_log_achievement_place_table": 1.6585365853658536, "train_stats/max_log_achievement_wake_up": 1.951219512195122, "train_stats/mean_log_entropy": 0.46743305427272147, "eval_stats/sum_log_reward": 4.4749999195337296, "eval_stats/max_log_achievement_collect_drink": 7.125, "eval_stats/max_log_achievement_collect_sapling": 2.5, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 4.5, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.125, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.25, "eval_stats/max_log_achievement_place_plant": 2.0, "eval_stats/max_log_achievement_place_table": 1.375, "eval_stats/max_log_achievement_wake_up": 1.875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 1.3201706678955816e-06, "report/cont_loss_std": 1.818649070628453e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0002109254419337958, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 8.477609725332513e-08, "report/cont_pred": 0.9941418170928955, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 5.745349407196045, "report/dyn_loss_std": 8.557022094726562, "report/image_loss_mean": 3.7252330780029297, "report/image_loss_std": 6.600305080413818, "report/model_loss_mean": 7.236135482788086, "report/model_loss_std": 10.637747764587402, "report/post_ent_mag": 59.42719268798828, "report/post_ent_max": 59.42719268798828, "report/post_ent_mean": 39.15995788574219, "report/post_ent_min": 19.966075897216797, "report/post_ent_std": 6.896706581115723, "report/prior_ent_mag": 73.26976013183594, "report/prior_ent_max": 73.26976013183594, "report/prior_ent_mean": 44.85393524169922, "report/prior_ent_min": 25.787860870361328, "report/prior_ent_std": 8.180160522460938, "report/rep_loss_mean": 5.745349407196045, "report/rep_loss_std": 8.557022094726562, "report/reward_avg": 0.016976412385702133, "report/reward_loss_mean": 0.06369169801473618, "report/reward_loss_std": 0.1219310462474823, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0036017894744873, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.04778704792261124, "report/reward_pos_acc": 0.9230769872665405, "report/reward_pos_loss": 0.6741853952407837, "report/reward_pred": 0.017122112214565277, "report/reward_rate": 0.025390625, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 3.180509156663902e-05, "eval/cont_loss_std": 0.0008663909393362701, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.005357678513973951, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 4.148747905219352e-07, "eval/cont_pred": 0.9941712617874146, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 21.159088134765625, "eval/dyn_loss_std": 12.06562328338623, "eval/image_loss_mean": 23.175739288330078, "eval/image_loss_std": 23.82108497619629, "eval/model_loss_mean": 36.00411605834961, "eval/model_loss_std": 28.551515579223633, "eval/post_ent_mag": 56.39334487915039, "eval/post_ent_max": 56.39334487915039, "eval/post_ent_mean": 38.292579650878906, "eval/post_ent_min": 23.660385131835938, "eval/post_ent_std": 6.4920196533203125, "eval/prior_ent_mag": 73.26976013183594, "eval/prior_ent_max": 73.26976013183594, "eval/prior_ent_mean": 50.1776123046875, "eval/prior_ent_min": 33.18623733520508, "eval/prior_ent_std": 7.931685924530029, "eval/rep_loss_mean": 21.159088134765625, "eval/rep_loss_std": 12.06562328338623, "eval/reward_avg": 0.01689453050494194, "eval/reward_loss_mean": 0.13289064168930054, "eval/reward_loss_std": 0.8827370405197144, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0040669441223145, "eval/reward_neg_acc": 0.9930139780044556, "eval/reward_neg_loss": 0.04782254993915558, "eval/reward_pos_acc": 0.5909091234207153, "eval/reward_pos_loss": 4.007355690002441, "eval/reward_pred": 0.007929187268018723, "eval/reward_rate": 0.021484375, "replay/size": 209589.0, "replay/inserts": 7428.0, "replay/samples": 29712.0, "replay/insert_wait_avg": 1.598348139946218e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.198937939390676e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 42208.0, "eval_replay/inserts": 1840.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2903109840724778e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.642673492431641e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1365888118744, "timer/env.step_count": 928.0, "timer/env.step_total": 87.91361689567566, "timer/env.step_frac": 0.087901610519133, "timer/env.step_avg": 0.09473450096516774, "timer/env.step_min": 0.023051023483276367, "timer/env.step_max": 2.1280059814453125, "timer/replay._sample_count": 29712.0, "timer/replay._sample_total": 14.175520658493042, "timer/replay._sample_frac": 0.01417358470539813, "timer/replay._sample_avg": 0.00047709749119860805, "timer/replay._sample_min": 0.0003495216369628906, "timer/replay._sample_max": 0.025925874710083008, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1158.0, "timer/agent.policy_total": 19.78921604156494, "timer/agent.policy_frac": 0.019786513425205057, "timer/agent.policy_avg": 0.01708913302380392, "timer/agent.policy_min": 0.009590387344360352, "timer/agent.policy_max": 0.12344098091125488, "timer/dataset_train_count": 1857.0, "timer/dataset_train_total": 0.3018805980682373, "timer/dataset_train_frac": 0.0003018393701872865, "timer/dataset_train_avg": 0.00016256359615952467, "timer/dataset_train_min": 9.274482727050781e-05, "timer/dataset_train_max": 0.002883434295654297, "timer/agent.train_count": 1857.0, "timer/agent.train_total": 830.5186681747437, "timer/agent.train_frac": 0.8304052441090766, "timer/agent.train_avg": 0.44723676261429385, "timer/agent.train_min": 0.4345982074737549, "timer/agent.train_max": 1.066965103149414, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4769749641418457, "timer/agent.report_frac": 0.00047690982359566955, "timer/agent.report_avg": 0.23848748207092285, "timer/agent.report_min": 0.23116588592529297, "timer/agent.report_max": 0.24580907821655273, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7418136596679688e-05, "timer/dataset_eval_frac": 2.741439209743484e-08, "timer/dataset_eval_avg": 2.7418136596679688e-05, "timer/dataset_eval_min": 2.7418136596679688e-05, "timer/dataset_eval_max": 2.7418136596679688e-05, "fps": 7.426884868722859}
{"step": 210144, "time": 28351.189527511597, "episode/length": 178.0, "episode/score": 5.2904396196317975, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.19043943804717856}
{"step": 210528, "time": 28399.067583560944, "episode/length": 150.0, "episode/score": 3.2553449930346687, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.15534489887795644}
{"step": 210600, "time": 28409.322707414627, "episode/length": 192.0, "episode/score": 5.298015651897003, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.19801547031238442}
{"step": 210688, "time": 28421.54938030243, "episode/length": 249.0, "episode/score": 6.38208219781518, "episode/reward_rate": 0.976, "episode/intrinsic_return": 0.2820820212364197}
{"step": 211064, "time": 28468.816695451736, "episode/length": 284.0, "episode/score": 7.436315658938838, "episode/reward_rate": 0.9649122807017544, "episode/intrinsic_return": 0.33631546967080794}
{"step": 211160, "time": 28481.91061758995, "episode/length": 209.0, "episode/score": 5.317303017058293, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.21730286911770236}
{"step": 211368, "time": 28508.54627752304, "episode/length": 95.0, "episode/score": 3.195292150187015, "episode/reward_rate": 0.9895833333333334, "episode/intrinsic_return": 0.09529200783435954}
{"step": 211472, "time": 28523.08642911911, "episode/length": 197.0, "episode/score": 5.30829892172369, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.20829868682085362}
{"step": 211480, "time": 28525.692362308502, "episode/length": 475.0, "episode/score": 7.593564145105574, "episode/reward_rate": 0.9873949579831933, "episode/intrinsic_return": 0.49356392978961594}
{"step": 211752, "time": 28560.274612665176, "episode/length": 152.0, "episode/score": 5.250343613462974, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.15034353519695287}
{"step": 211888, "time": 28578.158883333206, "episode/length": 149.0, "episode/score": 5.25005359592069, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.15005344448763935}
{"step": 212304, "time": 28630.22855758667, "episode/length": 154.0, "episode/score": 5.280462274053207, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.18046209130443458}
{"step": 212432, "time": 28647.16012620926, "episode/length": 158.0, "episode/score": 5.275880785045956, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.17588060229718394}
{"step": 212584, "time": 28667.157876491547, "episode/length": 304.0, "episode/score": 6.406637906435208, "episode/reward_rate": 0.9901639344262295, "episode/intrinsic_return": 0.30663769621241954}
{"step": 212752, "time": 28689.043968439102, "episode/length": 172.0, "episode/score": 4.230460608515386, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.13046048572050495}
{"step": 213088, "time": 28732.586532354355, "episode/length": 200.0, "episode/score": 7.306900519730334, "episode/reward_rate": 0.9800995024875622, "episode/intrinsic_return": 0.20690030944933824}
{"step": 213096, "time": 28735.005788326263, "episode/length": 167.0, "episode/score": 6.27682621720578, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.1768261669376443}
{"step": 213144, "time": 28742.46728515625, "episode/length": 156.0, "episode/score": 5.271312839563507, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.17131269010951655}
{"step": 213392, "time": 28773.89017891884, "episode/length": 239.0, "episode/score": 4.363642322742635, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.26364225763154536}
{"step": 213688, "time": 28811.36047053337, "episode/length": 156.0, "episode/score": 5.257490569555557, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.157490340793629}
{"step": 213784, "time": 28824.413298606873, "episode/length": 184.0, "episode/score": 7.291156781761856, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.19115657538077357}
{"step": 214160, "time": 28871.495117902756, "episode/length": 95.0, "episode/score": 6.194123702205616, "episode/reward_rate": 0.9895833333333334, "episode/intrinsic_return": 0.09412348453224695}
{"step": 214200, "time": 28877.920710086823, "episode/length": 201.0, "episode/score": 5.325335850687225, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.2253356424434969}
{"step": 214240, "time": 28884.24355149269, "episode/length": 185.0, "episode/score": 5.29925185002503, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.19925161512219347}
{"step": 214448, "time": 28911.086089372635, "episode/length": 169.0, "episode/score": 5.264372313217791, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.16437210730236984}
{"step": 214696, "time": 28942.569419384003, "episode/length": 199.0, "episode/score": 2.318111732275611, "episode/reward_rate": 0.97, "episode/intrinsic_return": 0.21811167490614025}
{"step": 215064, "time": 28988.587856292725, "episode/length": 171.0, "episode/score": 7.278359246509353, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.1783590366358112}
{"step": 215112, "time": 28995.933298110962, "episode/length": 165.0, "episode/score": 5.250295437570003, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.1502953209160296}
{"step": 215496, "time": 29044.137424230576, "episode/length": 166.0, "episode/score": 5.275989255689183, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.17598917730674657}
{"step": 215640, "time": 29063.05085682869, "episode/length": 179.0, "episode/score": 5.26361906127886, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.1636188940133252}
{"step": 215880, "time": 29093.750192642212, "episode/length": 178.0, "episode/score": 5.295188712632353, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.19518854513398765}
{"step": 215888, "time": 29096.293072462082, "episode/length": 148.0, "episode/score": 5.250464045456283, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.15046380706098716}
{"step": 216256, "time": 29142.39755177498, "episode/length": 142.0, "episode/score": 5.226818373525475, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.12681824138826414}
{"step": 216264, "time": 29144.855610847473, "episode/length": 389.0, "episode/score": 6.498927386448486, "episode/reward_rate": 0.9897435897435898, "episode/intrinsic_return": 0.3989272372855339}
{"step": 216416, "time": 29164.721701860428, "episode/length": 271.0, "episode/score": 6.41458952244875, "episode/reward_rate": 0.9852941176470589, "episode/intrinsic_return": 0.31458934121337734}
{"step": 216472, "time": 29173.10454058647, "episode/length": 175.0, "episode/score": 4.281870597680609, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.18187041458259046}
{"step": 216800, "time": 29214.271696805954, "episode/length": 162.0, "episode/score": 4.225894563914153, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.1258944554383561}
{"step": 217032, "time": 29243.94750905037, "episode/length": 96.0, "episode/score": 3.2088051945902407, "episode/reward_rate": 0.9484536082474226, "episode/intrinsic_return": 0.10880505770910531}
{"step": 217200, "time": 29265.90151667595, "episode/length": 164.0, "episode/score": 5.282042440351688, "episode/reward_rate": 0.9636363636363636, "episode/intrinsic_return": 0.18204231045547203}
{"step": 217248, "time": 29273.282463550568, "episode/length": 169.0, "episode/score": 6.275044348663414, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.17504413844062583}
{"step": 217520, "time": 29307.850911140442, "episode/length": 156.0, "episode/score": 5.266413350098901, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.16641311170360495}
{"step": 217752, "time": 29337.474932432175, "episode/length": 263.0, "episode/score": 5.3977271327567, "episode/reward_rate": 0.9810606060606061, "episode/intrinsic_return": 0.29772700291869114}
{"step": 217784, "time": 29343.10825228691, "episode/length": 32.0, "episode/score": 1.1334405310626607, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.033440475788665935}
{"step": 217785, "time": 29345.621136903763, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.452038129170735, "train/action_min": 0.0, "train/action_std": 3.53835187976559, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04968063145255049, "train/actor_opt_grad_steps": 53095.0, "train/actor_opt_loss": -8.38344317410762, "train/adv_mag": 0.5953012094832957, "train/adv_max": 0.5790486903861165, "train/adv_mean": 0.0030475085903939694, "train/adv_min": -0.4483004583356281, "train/adv_std": 0.06494832867368434, "train/cont_avg": 0.99444580078125, "train/cont_loss_mean": 0.00011704953566312366, "train/cont_loss_std": 0.003567684702652526, "train/cont_neg_acc": 0.9955871361088379, "train/cont_neg_loss": 0.017623904227979277, "train/cont_pos_acc": 0.9999897656962276, "train/cont_pos_loss": 3.333190146273535e-05, "train/cont_pred": 0.9944535136843721, "train/cont_rate": 0.99444580078125, "train/dyn_loss_mean": 6.593131944537163, "train/dyn_loss_std": 8.703426470359167, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1173370042815804, "train/extr_critic_critic_opt_grad_steps": 53095.0, "train/extr_critic_critic_opt_loss": 15998.56094868978, "train/extr_critic_mag": 6.0519144386053085, "train/extr_critic_max": 6.0519144386053085, "train/extr_critic_mean": 1.0732182596499722, "train/extr_critic_min": -0.6302649776140848, "train/extr_critic_std": 1.3495376727854211, "train/extr_return_normed_mag": 1.724796399474144, "train/extr_return_normed_max": 1.724796399474144, "train/extr_return_normed_mean": 0.309586901916191, "train/extr_return_normed_min": -0.17305371219602725, "train/extr_return_normed_std": 0.32901154256736237, "train/extr_return_rate": 0.5055223500045637, "train/extr_return_raw_mag": 7.04017844547828, "train/extr_return_raw_max": 7.04017844547828, "train/extr_return_raw_mean": 1.086035097638766, "train/extr_return_raw_min": -0.9443470959862074, "train/extr_return_raw_std": 1.384274094675978, "train/extr_reward_mag": 1.0138908550143242, "train/extr_reward_max": 1.0138908550143242, "train/extr_reward_mean": 0.027103236483526416, "train/extr_reward_min": -0.6656408508618673, "train/extr_reward_std": 0.16232086423163614, "train/image_loss_mean": 4.0323631676534815, "train/image_loss_std": 8.817044362425804, "train/model_loss_mean": 8.061985870202383, "train/model_loss_std": 12.795942033330599, "train/model_opt_grad_norm": 43.103778352340065, "train/model_opt_grad_steps": 53045.234375, "train/model_opt_loss": 7398.653091430664, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 924.4791666666666, "train/policy_entropy_mag": 2.543291039764881, "train/policy_entropy_max": 2.543291039764881, "train/policy_entropy_mean": 0.5483714121704301, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.5907712979242206, "train/policy_logprob_mag": 7.438383748133977, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5485053247151276, "train/policy_logprob_min": -7.438383748133977, "train/policy_logprob_std": 1.108961866858105, "train/policy_randomness_mag": 0.8976701277618607, "train/policy_randomness_max": 0.8976701277618607, "train/policy_randomness_mean": 0.1935510435141623, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.2085163437295705, "train/post_ent_mag": 57.70583566029867, "train/post_ent_max": 57.70583566029867, "train/post_ent_mean": 39.16668260097504, "train/post_ent_min": 18.260373930136364, "train/post_ent_std": 6.498866627613704, "train/prior_ent_mag": 73.31314194202423, "train/prior_ent_max": 73.31314194202423, "train/prior_ent_mean": 45.710659543673195, "train/prior_ent_min": 26.950669169425964, "train/prior_ent_std": 7.740174355606238, "train/rep_loss_mean": 6.593131944537163, "train/rep_loss_std": 8.703426470359167, "train/reward_avg": 0.018975959096375544, "train/reward_loss_mean": 0.0736265269612583, "train/reward_loss_std": 0.18211996788159013, "train/reward_max_data": 1.0090625304728746, "train/reward_max_pred": 1.0087323716531198, "train/reward_neg_acc": 0.9986717669914166, "train/reward_neg_loss": 0.05168198330405479, "train/reward_pos_acc": 0.8692095692579945, "train/reward_pos_loss": 0.7751089157536626, "train/reward_pred": 0.018723324935611647, "train/reward_rate": 0.030359903971354168, "train_stats/sum_log_reward": 5.099999954534131, "train_stats/max_log_achievement_collect_drink": 7.255813953488372, "train_stats/max_log_achievement_collect_sapling": 2.7209302325581395, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 4.813953488372093, "train_stats/max_log_achievement_defeat_skeleton": 0.023255813953488372, "train_stats/max_log_achievement_defeat_zombie": 0.20930232558139536, "train_stats/max_log_achievement_eat_cow": 0.13953488372093023, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.6511627906976745, "train_stats/max_log_achievement_place_plant": 1.8837209302325582, "train_stats/max_log_achievement_place_table": 1.5348837209302326, "train_stats/max_log_achievement_wake_up": 2.2093023255813953, "train_stats/mean_log_entropy": 0.4645258791224901, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 1.1283661933703115e-06, "report/cont_loss_std": 2.772028346953448e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 2.8341908546281047e-05, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 9.410557026967581e-07, "report/cont_pred": 0.9931633472442627, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 6.193357467651367, "report/dyn_loss_std": 8.962676048278809, "report/image_loss_mean": 5.064194679260254, "report/image_loss_std": 10.757838249206543, "report/model_loss_mean": 8.854158401489258, "report/model_loss_std": 14.84851360321045, "report/post_ent_mag": 60.530094146728516, "report/post_ent_max": 60.530094146728516, "report/post_ent_mean": 39.80043411254883, "report/post_ent_min": 17.929569244384766, "report/post_ent_std": 6.614401817321777, "report/prior_ent_mag": 73.20712280273438, "report/prior_ent_max": 73.20712280273438, "report/prior_ent_mean": 46.142860412597656, "report/prior_ent_min": 27.22577476501465, "report/prior_ent_std": 7.970515251159668, "report/rep_loss_mean": 6.193357467651367, "report/rep_loss_std": 8.962676048278809, "report/reward_avg": 0.012874450534582138, "report/reward_loss_mean": 0.07394798845052719, "report/reward_loss_std": 0.17759153246879578, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0014674663543701, "report/reward_neg_acc": 0.9989989995956421, "report/reward_neg_loss": 0.05531653016805649, "report/reward_pos_acc": 0.8399999737739563, "report/reward_pos_loss": 0.818461000919342, "report/reward_pred": 0.011971168220043182, "report/reward_rate": 0.0244140625, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 5.519771093531745e-07, "eval/cont_loss_std": 1.1240400453971233e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00025148189160972834, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 6.092059834372776e-08, "eval/cont_pred": 0.9980473518371582, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 22.953458786010742, "eval/dyn_loss_std": 11.780466079711914, "eval/image_loss_mean": 31.564979553222656, "eval/image_loss_std": 30.24296760559082, "eval/model_loss_mean": 45.44224548339844, "eval/model_loss_std": 34.762908935546875, "eval/post_ent_mag": 51.631099700927734, "eval/post_ent_max": 51.631099700927734, "eval/post_ent_mean": 36.974090576171875, "eval/post_ent_min": 20.495647430419922, "eval/post_ent_std": 5.319253444671631, "eval/prior_ent_mag": 73.20712280273438, "eval/prior_ent_max": 73.20712280273438, "eval/prior_ent_mean": 49.91694641113281, "eval/prior_ent_min": 33.07252502441406, "eval/prior_ent_std": 6.428482532501221, "eval/rep_loss_mean": 22.953458786010742, "eval/rep_loss_std": 11.780466079711914, "eval/reward_avg": 0.02177734300494194, "eval/reward_loss_mean": 0.10519064962863922, "eval/reward_loss_std": 0.7586640119552612, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0004613399505615, "eval/reward_neg_acc": 0.9900000691413879, "eval/reward_neg_loss": 0.03476860374212265, "eval/reward_pos_acc": 0.6666666865348816, "eval/reward_pos_loss": 3.039442777633667, "eval/reward_pred": 0.015998966991901398, "eval/reward_rate": 0.0234375, "replay/size": 217281.0, "replay/inserts": 7692.0, "replay/samples": 30768.0, "replay/insert_wait_avg": 1.632231198061399e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.241824859761969e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 42208.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 8.195638656616211e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.5972497463226, "timer/env.step_count": 962.0, "timer/env.step_total": 90.89816427230835, "timer/env.step_frac": 0.0908439077714369, "timer/env.step_avg": 0.09448873624980078, "timer/env.step_min": 0.023166656494140625, "timer/env.step_max": 1.9766647815704346, "timer/replay._sample_count": 30768.0, "timer/replay._sample_total": 14.819251537322998, "timer/replay._sample_frac": 0.014810406026080986, "timer/replay._sample_avg": 0.00048164494076062786, "timer/replay._sample_min": 0.00036525726318359375, "timer/replay._sample_max": 0.034822940826416016, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 962.0, "timer/agent.policy_total": 15.446141242980957, "timer/agent.policy_frac": 0.015436921545503902, "timer/agent.policy_avg": 0.016056279878358583, "timer/agent.policy_min": 0.014645576477050781, "timer/agent.policy_max": 0.05750751495361328, "timer/dataset_train_count": 1923.0, "timer/dataset_train_total": 0.34308695793151855, "timer/dataset_train_frac": 0.00034288217164148713, "timer/dataset_train_avg": 0.00017841235461857439, "timer/dataset_train_min": 8.988380432128906e-05, "timer/dataset_train_max": 0.046884775161743164, "timer/agent.train_count": 1923.0, "timer/agent.train_total": 860.4321482181549, "timer/agent.train_frac": 0.8599185620750974, "timer/agent.train_avg": 0.44744261477803166, "timer/agent.train_min": 0.4354724884033203, "timer/agent.train_max": 0.9972813129425049, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4766881465911865, "timer/agent.report_frac": 0.00047640361465318775, "timer/agent.report_avg": 0.23834407329559326, "timer/agent.report_min": 0.2311999797821045, "timer/agent.report_max": 0.24548816680908203, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9802322387695312e-05, "timer/dataset_eval_frac": 2.9784533582568785e-08, "timer/dataset_eval_avg": 2.9802322387695312e-05, "timer/dataset_eval_min": 2.9802322387695312e-05, "timer/dataset_eval_max": 2.9802322387695312e-05, "fps": 7.687305482503494}
{"step": 217808, "time": 29348.291590213776, "episode/length": 173.0, "episode/score": 5.291594272355724, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.1915941352417576}
{"step": 217952, "time": 29367.283138751984, "episode/length": 184.0, "episode/score": 4.298758195080154, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.1987580154745956}
{"step": 218432, "time": 29427.120011091232, "episode/length": 203.0, "episode/score": 4.3164360837618005, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.21643596096691908}
{"step": 218496, "time": 29436.6553273201, "episode/length": 161.0, "episode/score": 5.259610329347197, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.1596101682225708}
{"step": 218904, "time": 29487.655009031296, "episode/length": 143.0, "episode/score": 4.262819533272705, "episode/reward_rate": 0.9583333333333334, "episode/intrinsic_return": 0.1628193838187144}
{"step": 219040, "time": 29505.78111052513, "episode/length": 156.0, "episode/score": 4.248500726827842, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.14850057388139248}
{"step": 219040, "time": 29505.790608406067, "episode/length": 250.0, "episode/score": 8.400114832649706, "episode/reward_rate": 0.9681274900398407, "episode/intrinsic_return": 0.30011457737418823}
{"step": 219416, "time": 29554.81133532524, "episode/length": 46.0, "episode/score": 1.1538334260694683, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.053833332378417253}
{"step": 219432, "time": 29558.326653957367, "episode/length": 48.0, "episode/score": 4.154844988221157, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.05484486426212243}
{"step": 219736, "time": 29596.675932884216, "episode/length": 162.0, "episode/score": 4.2688160253037495, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.16881590250886802}
{"step": 219872, "time": 29614.723787784576, "episode/length": 239.0, "episode/score": 6.366349752770475, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.26634957619171473}
{"step": 220064, "time": 29654.05462193489, "eval_episode/length": 41.0, "eval_episode/score": 1.0999999940395355, "eval_episode/reward_rate": 0.9761904761904762}
{"step": 220064, "time": 29659.584743738174, "eval_episode/length": 135.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9558823529411765}
{"step": 220064, "time": 29661.774423122406, "eval_episode/length": 149.0, "eval_episode/score": 3.100000023841858, "eval_episode/reward_rate": 0.9933333333333333}
{"step": 220064, "time": 29663.85788345337, "eval_episode/length": 162.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9693251533742331}
{"step": 220064, "time": 29665.460515737534, "eval_episode/length": 165.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.963855421686747}
{"step": 220064, "time": 29668.73072862625, "eval_episode/length": 190.0, "eval_episode/score": 5.099999971687794, "eval_episode/reward_rate": 0.9947643979057592}
{"step": 220064, "time": 29671.386310338974, "eval_episode/length": 162.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9693251533742331}
{"step": 220064, "time": 29674.020138263702, "eval_episode/length": 218.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9726027397260274}
{"step": 220160, "time": 29685.763420581818, "episode/length": 207.0, "episode/score": 5.324828508451901, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.2248283558546973}
{"step": 220224, "time": 29695.079501628876, "episode/length": 301.0, "episode/score": 5.41838107086005, "episode/reward_rate": 0.9966887417218543, "episode/intrinsic_return": 0.31838092868201784}
{"step": 220384, "time": 29716.117790937424, "episode/length": 120.0, "episode/score": 4.231064425372097, "episode/reward_rate": 0.9586776859504132, "episode/intrinsic_return": 0.13106436864291027}
{"step": 220536, "time": 29736.103288412094, "episode/length": 203.0, "episode/score": 6.311454390313884, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.21145418009109562}
{"step": 220712, "time": 29759.290040254593, "episode/length": 432.0, "episode/score": 6.556785926929479, "episode/reward_rate": 0.7090069284064665, "episode/intrinsic_return": 0.45678580919866363}
{"step": 221040, "time": 29801.22851395607, "episode/length": 162.0, "episode/score": 7.24940368154239, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.14940355112230463}
{"step": 221384, "time": 29845.78076863289, "episode/length": 152.0, "episode/score": 3.270606801555914, "episode/reward_rate": 0.9607843137254902, "episode/intrinsic_return": 0.1706067132199678}
{"step": 221616, "time": 29875.747236967087, "episode/length": 272.0, "episode/score": 6.392124794381743, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.29212465659838927}
{"step": 221864, "time": 29907.334433317184, "episode/length": 248.0, "episode/score": 5.385316237426196, "episode/reward_rate": 0.9678714859437751, "episode/intrinsic_return": 0.28531606631895556}
{"step": 221968, "time": 29921.64201259613, "episode/length": 197.0, "episode/score": 5.315028347123189, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.21502816553856974}
{"step": 222064, "time": 29934.77683019638, "episode/length": 55.0, "episode/score": 5.160846138834131, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.06084593291870988}
{"step": 222080, "time": 29938.260493516922, "episode/length": 192.0, "episode/score": 6.318344999544024, "episode/reward_rate": 0.9637305699481865, "episode/intrinsic_return": 0.21834484215924022}
{"step": 222232, "time": 29958.30650615692, "episode/length": 148.0, "episode/score": 6.249151243892811, "episode/reward_rate": 0.9731543624161074, "episode/intrinsic_return": 0.14915111265781889}
{"step": 222272, "time": 29964.724556922913, "episode/length": 194.0, "episode/score": 6.286850659391348, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.186850430774939}
{"step": 222784, "time": 30028.461562633514, "episode/length": 174.0, "episode/score": 5.277158547076397, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.17715847841463983}
{"step": 222968, "time": 30052.36248421669, "episode/length": 342.0, "episode/score": 5.494317976354978, "episode/reward_rate": 0.9854227405247813, "episode/intrinsic_return": 0.3943177915107299}
{"step": 223056, "time": 30064.69092440605, "episode/length": 148.0, "episode/score": 5.235817421465981, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.13581718307068513}
{"step": 223384, "time": 30105.952700138092, "episode/length": 162.0, "episode/score": 5.249933980195237, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.14993381292970298}
{"step": 223560, "time": 30129.07990002632, "episode/length": 198.0, "episode/score": 5.32257482746445, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.22257465170059731}
{"step": 223880, "time": 30169.512209415436, "episode/length": 226.0, "episode/score": 6.357182821933748, "episode/reward_rate": 0.9647577092511013, "episode/intrinsic_return": 0.2571827579577075}
{"step": 224080, "time": 30195.293278455734, "episode/length": 138.0, "episode/score": 2.2634396090938935, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.16343952983834242}
{"step": 224104, "time": 30199.82189488411, "episode/length": 233.0, "episode/score": 5.358051942648672, "episode/reward_rate": 0.9700854700854701, "episode/intrinsic_return": 0.2580517674523435}
{"step": 224168, "time": 30209.135648489, "episode/length": 138.0, "episode/score": 4.251017224086354, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.15101708726342622}
{"step": 224256, "time": 30221.36718249321, "episode/length": 183.0, "episode/score": 5.300815545349906, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.20081541056424612}
{"step": 224424, "time": 30243.15525650978, "episode/length": 268.0, "episode/score": 5.3873645349731305, "episode/reward_rate": 0.9962825278810409, "episode/intrinsic_return": 0.2873643267294028}
{"step": 224992, "time": 30313.615213394165, "episode/length": 178.0, "episode/score": 4.313840915888704, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.21384078762230274}
{"step": 225237, "time": 30345.75604367256, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.505355426971925, "train/action_min": 0.0, "train/action_std": 3.6138745833208215, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.05087058971272433, "train/actor_opt_grad_steps": 54990.0, "train/actor_opt_loss": -9.905483675154453, "train/adv_mag": 0.6359542447296693, "train/adv_max": 0.621551534390067, "train/adv_mean": 0.0031861426897597856, "train/adv_min": -0.4578877540833172, "train/adv_std": 0.06535640914730209, "train/cont_avg": 0.9941928475935828, "train/cont_loss_mean": 0.00012005839565746711, "train/cont_loss_std": 0.003741502654572729, "train/cont_neg_acc": 0.9967765897353065, "train/cont_neg_loss": 0.016602390140450975, "train/cont_pos_acc": 0.9999947455477587, "train/cont_pos_loss": 1.3644752565697637e-05, "train/cont_pred": 0.9942128463862414, "train/cont_rate": 0.9941928475935828, "train/dyn_loss_mean": 6.526444373921277, "train/dyn_loss_std": 8.687240952476461, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1053523580658244, "train/extr_critic_critic_opt_grad_steps": 54990.0, "train/extr_critic_critic_opt_loss": 15788.871558531084, "train/extr_critic_mag": 6.305240613253996, "train/extr_critic_max": 6.305240613253996, "train/extr_critic_mean": 1.161912127612109, "train/extr_critic_min": -0.6068965840467158, "train/extr_critic_std": 1.4036297951152619, "train/extr_return_normed_mag": 1.7638824107175204, "train/extr_return_normed_max": 1.7638824107175204, "train/extr_return_normed_mean": 0.3240828211294776, "train/extr_return_normed_min": -0.17145193694906438, "train/extr_return_normed_std": 0.3385717001031427, "train/extr_return_rate": 0.5197467811923614, "train/extr_return_raw_mag": 7.297723316253825, "train/extr_return_raw_max": 7.297723316253825, "train/extr_return_raw_mean": 1.1754539972320597, "train/extr_return_raw_min": -0.9324709438385173, "train/extr_return_raw_std": 1.4401188801954137, "train/extr_reward_mag": 1.0167950066653164, "train/extr_reward_max": 1.0167950066653164, "train/extr_reward_mean": 0.02869345565490863, "train/extr_reward_min": -0.6735771480091115, "train/extr_reward_std": 0.16627710938134932, "train/image_loss_mean": 3.9032636874499804, "train/image_loss_std": 8.604596862180985, "train/model_loss_mean": 7.894284623191956, "train/model_loss_std": 12.607715010005522, "train/model_opt_grad_norm": 44.8534711337982, "train/model_opt_grad_steps": 54939.16577540107, "train/model_opt_loss": 10477.594590783756, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1330.2139037433155, "train/policy_entropy_mag": 2.5309664476364055, "train/policy_entropy_max": 2.5309664476364055, "train/policy_entropy_mean": 0.5539062710050593, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6046826429864302, "train/policy_logprob_mag": 7.438383821497626, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5536056180051304, "train/policy_logprob_min": -7.438383821497626, "train/policy_logprob_std": 1.1119217346696293, "train/policy_randomness_mag": 0.8933200880805439, "train/policy_randomness_max": 0.8933200880805439, "train/policy_randomness_mean": 0.19550460624822322, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.21342643792616492, "train/post_ent_mag": 58.29590606689453, "train/post_ent_max": 58.29590606689453, "train/post_ent_mean": 39.66672468950404, "train/post_ent_min": 18.38048780410685, "train/post_ent_std": 6.5847088461891214, "train/prior_ent_mag": 73.38527504008084, "train/prior_ent_max": 73.38527504008084, "train/prior_ent_mean": 46.1604350084927, "train/prior_ent_min": 27.77364757354247, "train/prior_ent_std": 7.700267697400588, "train/rep_loss_mean": 6.526444373921277, "train/rep_loss_std": 8.687240952476461, "train/reward_avg": 0.019430259388328635, "train/reward_loss_mean": 0.07503424997237276, "train/reward_loss_std": 0.18248531935527362, "train/reward_max_data": 1.0135494967832923, "train/reward_max_pred": 1.0135044044351833, "train/reward_neg_acc": 0.998709753554135, "train/reward_neg_loss": 0.052927056954984356, "train/reward_pos_acc": 0.8733378059086315, "train/reward_pos_loss": 0.7574397134270897, "train/reward_pred": 0.01917676081853535, "train/reward_rate": 0.03127088903743316, "train_stats/sum_log_reward": 4.964864846822378, "train_stats/max_log_achievement_collect_drink": 5.351351351351352, "train_stats/max_log_achievement_collect_sapling": 2.8378378378378377, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 5.081081081081081, "train_stats/max_log_achievement_defeat_skeleton": 0.02702702702702703, "train_stats/max_log_achievement_defeat_zombie": 0.1891891891891892, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.02702702702702703, "train_stats/max_log_achievement_make_wood_sword": 0.32432432432432434, "train_stats/max_log_achievement_place_plant": 2.4054054054054053, "train_stats/max_log_achievement_place_table": 1.8918918918918919, "train_stats/max_log_achievement_wake_up": 2.4054054054054053, "train_stats/mean_log_entropy": 0.5005654688622501, "eval_stats/sum_log_reward": 3.9749999791383743, "eval_stats/max_log_achievement_collect_drink": 3.875, "eval_stats/max_log_achievement_collect_sapling": 1.875, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 2.625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.25, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 1.75, "eval_stats/max_log_achievement_place_table": 1.0, "eval_stats/max_log_achievement_wake_up": 2.25, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 2.5335452846775297e-07, "report/cont_loss_std": 2.5613862817408517e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 3.846378604066558e-05, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 1.0350966306305054e-07, "report/cont_pred": 0.9960938692092896, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 5.203611373901367, "report/dyn_loss_std": 8.131961822509766, "report/image_loss_mean": 3.1231958866119385, "report/image_loss_std": 7.2174763679504395, "report/model_loss_mean": 6.314948558807373, "report/model_loss_std": 11.220349311828613, "report/post_ent_mag": 58.55529022216797, "report/post_ent_max": 58.55529022216797, "report/post_ent_mean": 39.73618698120117, "report/post_ent_min": 17.599720001220703, "report/post_ent_std": 6.4254326820373535, "report/prior_ent_mag": 73.97877502441406, "report/prior_ent_max": 73.97877502441406, "report/prior_ent_mean": 44.86405563354492, "report/prior_ent_min": 27.74976348876953, "report/prior_ent_std": 7.433651447296143, "report/rep_loss_mean": 5.203611373901367, "report/rep_loss_std": 8.131961822509766, "report/reward_avg": 0.012144854292273521, "report/reward_loss_mean": 0.06958550214767456, "report/reward_loss_std": 0.21045154333114624, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0006129741668701, "report/reward_neg_acc": 0.9989989995956421, "report/reward_neg_loss": 0.05029284209012985, "report/reward_pos_acc": 0.7199999690055847, "report/reward_pos_loss": 0.8405200839042664, "report/reward_pred": 0.011808435432612896, "report/reward_rate": 0.0244140625, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 7.75647731643403e-06, "eval/cont_loss_std": 0.00024224273511208594, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 5.064599827164784e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 7.714551429671701e-06, "eval/cont_pred": 0.9990158081054688, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 22.65066909790039, "eval/dyn_loss_std": 13.272448539733887, "eval/image_loss_mean": 37.167236328125, "eval/image_loss_std": 44.57582473754883, "eval/model_loss_mean": 50.91127014160156, "eval/model_loss_std": 49.36365509033203, "eval/post_ent_mag": 56.76239013671875, "eval/post_ent_max": 56.76239013671875, "eval/post_ent_mean": 38.369239807128906, "eval/post_ent_min": 20.503671646118164, "eval/post_ent_std": 5.932715892791748, "eval/prior_ent_mag": 73.97877502441406, "eval/prior_ent_max": 73.97877502441406, "eval/prior_ent_mean": 51.10002899169922, "eval/prior_ent_min": 36.411163330078125, "eval/prior_ent_std": 6.229763031005859, "eval/rep_loss_mean": 22.65066909790039, "eval/rep_loss_std": 13.272448539733887, "eval/reward_avg": 0.02812499925494194, "eval/reward_loss_mean": 0.15362310409545898, "eval/reward_loss_std": 0.8417338728904724, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0012156963348389, "eval/reward_neg_acc": 0.9889000654220581, "eval/reward_neg_loss": 0.06670188158750534, "eval/reward_pos_acc": 0.6969696879386902, "eval/reward_pos_loss": 2.7638936042785645, "eval/reward_pred": 0.026587210595607758, "eval/reward_rate": 0.0322265625, "replay/size": 224733.0, "replay/inserts": 7452.0, "replay/samples": 29808.0, "replay/insert_wait_avg": 1.6173558790582645e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.364437008057623e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 43960.0, "eval_replay/inserts": 1752.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2274746481142087e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.043081283569336e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1190831661224, "timer/env.step_count": 931.0, "timer/env.step_total": 82.49075436592102, "timer/env.step_frac": 0.08248093227536094, "timer/env.step_avg": 0.08860446226199895, "timer/env.step_min": 0.023304462432861328, "timer/env.step_max": 3.3383188247680664, "timer/replay._sample_count": 29808.0, "timer/replay._sample_total": 14.384681224822998, "timer/replay._sample_frac": 0.01438296845540109, "timer/replay._sample_avg": 0.00048257787254505496, "timer/replay._sample_min": 0.00036907196044921875, "timer/replay._sample_max": 0.024512290954589844, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1150.0, "timer/agent.policy_total": 18.630561351776123, "timer/agent.policy_frac": 0.01862834302970853, "timer/agent.policy_avg": 0.01620048813197924, "timer/agent.policy_min": 0.00961160659790039, "timer/agent.policy_max": 0.0598607063293457, "timer/dataset_train_count": 1863.0, "timer/dataset_train_total": 0.3099679946899414, "timer/dataset_train_frac": 0.000309931087114808, "timer/dataset_train_avg": 0.00016638110289315158, "timer/dataset_train_min": 8.893013000488281e-05, "timer/dataset_train_max": 0.024932384490966797, "timer/agent.train_count": 1863.0, "timer/agent.train_total": 835.7147943973541, "timer/agent.train_frac": 0.8356152866833556, "timer/agent.train_avg": 0.44858550423905214, "timer/agent.train_min": 0.43694305419921875, "timer/agent.train_max": 0.9867124557495117, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47811174392700195, "timer/agent.report_frac": 0.00047805481564597475, "timer/agent.report_avg": 0.23905587196350098, "timer/agent.report_min": 0.23290348052978516, "timer/agent.report_max": 0.2452082633972168, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.6702880859375e-05, "timer/dataset_eval_frac": 2.6699701374400813e-08, "timer/dataset_eval_avg": 2.6702880859375e-05, "timer/dataset_eval_min": 2.6702880859375e-05, "timer/dataset_eval_max": 2.6702880859375e-05, "fps": 7.451013267071681}
{"step": 225256, "time": 30347.984561920166, "episode/length": 171.0, "episode/score": 5.2690687511749275, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.16906859517257544}
{"step": 225328, "time": 30358.180294036865, "episode/length": 242.0, "episode/score": 5.372832993675729, "episode/reward_rate": 0.9958847736625515, "episode/intrinsic_return": 0.27283279474522715}
{"step": 225400, "time": 30368.489788770676, "episode/length": 161.0, "episode/score": 5.269315493419072, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.1693154230692926}
{"step": 225832, "time": 30422.45088171959, "episode/length": 218.0, "episode/score": 4.33918295066178, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.2391828181753226}
{"step": 225888, "time": 30430.70192170143, "episode/length": 214.0, "episode/score": 5.330747987225095, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.23074779330045203}
{"step": 226648, "time": 30524.498859405518, "episode/length": 173.0, "episode/score": 4.288438519298779, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.18843836440237283}
{"step": 226664, "time": 30527.871270895004, "episode/length": 208.0, "episode/score": 3.343803171372201, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.24380308187210176}
{"step": 226728, "time": 30537.09401345253, "episode/length": 287.0, "episode/score": 4.41945190102706, "episode/reward_rate": 0.9965277777777778, "episode/intrinsic_return": 0.31945174982683966}
{"step": 226832, "time": 30551.289658784866, "episode/length": 187.0, "episode/score": 5.309129432424015, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.20912936021159112}
{"step": 227232, "time": 30601.53732061386, "episode/length": 228.0, "episode/score": 5.3435515852220306, "episode/reward_rate": 0.9781659388646288, "episode/intrinsic_return": 0.24355143378897992}
{"step": 227248, "time": 30605.01418375969, "episode/length": 169.0, "episode/score": 5.265043177893858, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.16504293484194932}
{"step": 227480, "time": 30634.67254304886, "episode/length": 205.0, "episode/score": 6.342137101340086, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.24213688797408395}
{"step": 227704, "time": 30663.448709964752, "episode/length": 430.0, "episode/score": 5.522909211990282, "episode/reward_rate": 0.6125290023201856, "episode/intrinsic_return": 0.4229090338981223}
{"step": 227920, "time": 30691.2467110157, "episode/length": 135.0, "episode/score": 5.236258339669803, "episode/reward_rate": 0.9926470588235294, "episode/intrinsic_return": 0.13625813142607512}
{"step": 228024, "time": 30705.4430437088, "episode/length": 171.0, "episode/score": 4.28259106549649, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.18259088239847188}
{"step": 228072, "time": 30712.77801346779, "episode/length": 175.0, "episode/score": 6.282574052923337, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.18257392378382065}
{"step": 228528, "time": 30770.255420923233, "episode/length": 224.0, "episode/score": 5.343078220193547, "episode/reward_rate": 0.9822222222222222, "episode/intrinsic_return": 0.24307813249788524}
{"step": 228576, "time": 30777.549616336823, "episode/length": 136.0, "episode/score": 5.252256414816657, "episode/reward_rate": 0.9927007299270073, "episode/intrinsic_return": 0.15225621600257}
{"step": 228680, "time": 30791.78948879242, "episode/length": 180.0, "episode/score": 5.277643592991808, "episode/reward_rate": 0.9834254143646409, "episode/intrinsic_return": 0.17764344155875733}
{"step": 229000, "time": 30832.294222593307, "episode/length": 218.0, "episode/score": 6.356099864671705, "episode/reward_rate": 0.9634703196347032, "episode/intrinsic_return": 0.2560996974061709}
{"step": 229224, "time": 30861.08069038391, "episode/length": 162.0, "episode/score": 5.26250317980157, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.16250304501591017}
{"step": 229296, "time": 30871.445822238922, "episode/length": 158.0, "episode/score": 3.2766961351808277, "episode/reward_rate": 0.9622641509433962, "episode/intrinsic_return": 0.1766960468448815}
{"step": 229480, "time": 30896.964257478714, "episode/length": 175.0, "episode/score": 5.301514229267923, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.20151406060540467}
{"step": 229832, "time": 30942.578124523163, "episode/length": 265.0, "episode/score": 8.363114578631212, "episode/reward_rate": 0.9962406015037594, "episode/intrinsic_return": 0.2631143489088572}
{"step": 229904, "time": 30952.725685596466, "episode/length": 171.0, "episode/score": 6.286113250480412, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.18611307273749844}
{"step": 229968, "time": 30962.18680167198, "episode/length": 173.0, "episode/score": 5.289957689788935, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.18995745139363862}
{"step": 230048, "time": 30992.524260044098, "eval_episode/length": 158.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9748427672955975}
{"step": 230048, "time": 30992.53183865547, "eval_episode/length": 158.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9685534591194969}
{"step": 230048, "time": 30995.983155965805, "eval_episode/length": 159.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.975}
{"step": 230048, "time": 30997.69726920128, "eval_episode/length": 166.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9700598802395209}
{"step": 230048, "time": 30999.836153507233, "eval_episode/length": 180.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.9779005524861878}
{"step": 230048, "time": 31001.928820371628, "eval_episode/length": 195.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9948979591836735}
{"step": 230048, "time": 31003.737264871597, "eval_episode/length": 202.0, "eval_episode/score": 6.099999964237213, "eval_episode/reward_rate": 0.9753694581280788}
{"step": 230048, "time": 31007.015169143677, "eval_episode/length": 245.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.975609756097561}
{"step": 230160, "time": 31020.700971603394, "episode/length": 184.0, "episode/score": 5.315578604067923, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.2155784248116106}
{"step": 230224, "time": 31030.136510372162, "episode/length": 152.0, "episode/score": 4.261341248597091, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.16134107248399232}
{"step": 230904, "time": 31114.691455602646, "episode/length": 177.0, "episode/score": 6.295135283184209, "episode/reward_rate": 0.9662921348314607, "episode/intrinsic_return": 0.19513504630231182}
{"step": 231128, "time": 31143.23029279709, "episode/length": 161.0, "episode/score": 5.276230301475152, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.17623016436118633}
{"step": 231160, "time": 31148.656590938568, "episode/length": 148.0, "episode/score": 5.257203953151475, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.15720381603750866}
{"step": 231192, "time": 31154.214466810226, "episode/length": 245.0, "episode/score": 4.382995128620678, "episode/reward_rate": 0.9796747967479674, "episode/intrinsic_return": 0.28299500815410283}
{"step": 231216, "time": 31158.6449303627, "episode/length": 239.0, "episode/score": 5.3616498537085135, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.2616497143826564}
{"step": 231344, "time": 31175.789267778397, "episode/length": 179.0, "episode/score": 3.309804875323607, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.20980478349520126}
{"step": 232128, "time": 31272.411645889282, "episode/length": 237.0, "episode/score": 5.363970538135618, "episode/reward_rate": 0.9831932773109243, "episode/intrinsic_return": 0.26397040599840693}
{"step": 232512, "time": 31320.558950424194, "episode/length": 172.0, "episode/score": 5.294480748671049, "episode/reward_rate": 0.9595375722543352, "episode/intrinsic_return": 0.1944805740713491}
{"step": 232584, "time": 31331.28318452835, "episode/length": 302.0, "episode/score": 5.440098820838102, "episode/reward_rate": 0.976897689768977, "episode/intrinsic_return": 0.34009874827643216}
{"step": 232632, "time": 31338.619687318802, "episode/length": 215.0, "episode/score": 5.333379208299448, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.2333790545380907}
{"step": 232673, "time": 31345.98820090294, "train_stats/sum_log_reward": 4.9947367592861776, "train_stats/max_log_achievement_collect_drink": 5.684210526315789, "train_stats/max_log_achievement_collect_sapling": 3.0, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 4.973684210526316, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.13157894736842105, "train_stats/max_log_achievement_eat_cow": 0.05263157894736842, "train_stats/max_log_achievement_make_wood_pickaxe": 0.02631578947368421, "train_stats/max_log_achievement_make_wood_sword": 0.10526315789473684, "train_stats/max_log_achievement_place_plant": 2.473684210526316, "train_stats/max_log_achievement_place_table": 2.0, "train_stats/max_log_achievement_wake_up": 2.8684210526315788, "train_stats/mean_log_entropy": 0.49469939344807673, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.4255555848817565, "train/action_min": 0.0, "train/action_std": 3.3825057609661204, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.05118219056040854, "train/actor_opt_grad_steps": 56850.0, "train/actor_opt_loss": -10.663639653620084, "train/adv_mag": 0.6256900995164304, "train/adv_max": 0.6010083274261372, "train/adv_mean": 0.0028333677271262245, "train/adv_min": -0.4820438568656509, "train/adv_std": 0.06595223149335062, "train/cont_avg": 0.994288429054054, "train/cont_loss_mean": 0.00019260888824665262, "train/cont_loss_std": 0.00584649872479826, "train/cont_neg_acc": 0.9954890615231282, "train/cont_neg_loss": 0.01193424116850602, "train/cont_pos_acc": 0.9999786844124665, "train/cont_pos_loss": 0.00010819857641032237, "train/cont_pred": 0.9942934493760804, "train/cont_rate": 0.994288429054054, "train/dyn_loss_mean": 6.447667822966705, "train/dyn_loss_std": 8.669140869862325, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1019533637407664, "train/extr_critic_critic_opt_grad_steps": 56850.0, "train/extr_critic_critic_opt_loss": 15755.905178420608, "train/extr_critic_mag": 6.2596443588669235, "train/extr_critic_max": 6.2596443588669235, "train/extr_critic_mean": 1.1178623379887762, "train/extr_critic_min": -0.5902526571943953, "train/extr_critic_std": 1.3764905107987893, "train/extr_return_normed_mag": 1.7601949517791335, "train/extr_return_normed_max": 1.7601949517791335, "train/extr_return_normed_mean": 0.31741820388549086, "train/extr_return_normed_min": -0.16701788914364737, "train/extr_return_normed_std": 0.3365494476782309, "train/extr_return_rate": 0.5072389089577907, "train/extr_return_raw_mag": 7.174192183726543, "train/extr_return_raw_max": 7.174192183726543, "train/extr_return_raw_mean": 1.1297227218344406, "train/extr_return_raw_min": -0.9001518903551875, "train/extr_return_raw_std": 1.4102430201865532, "train/extr_reward_mag": 1.0118305180523846, "train/extr_reward_max": 1.0118305180523846, "train/extr_reward_mean": 0.02829285674300548, "train/extr_reward_min": -0.6698138327211947, "train/extr_reward_std": 0.16446265332602167, "train/image_loss_mean": 3.854064687522682, "train/image_loss_std": 8.543403746630695, "train/model_loss_mean": 7.796823081454715, "train/model_loss_std": 12.514299325685244, "train/model_opt_grad_norm": 43.85211839418154, "train/model_opt_grad_steps": 56797.40540540541, "train/model_opt_loss": 9847.093707770271, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1263.5135135135135, "train/policy_entropy_mag": 2.4939962116447654, "train/policy_entropy_max": 2.4939962116447654, "train/policy_entropy_mean": 0.5322114878409617, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.5876120688142004, "train/policy_logprob_mag": 7.438383798341493, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5319352570417765, "train/policy_logprob_min": -7.438383798341493, "train/policy_logprob_std": 1.0978872888797038, "train/policy_randomness_mag": 0.8802712147300308, "train/policy_randomness_max": 0.8802712147300308, "train/policy_randomness_mean": 0.18784730055847684, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.20740127305726747, "train/post_ent_mag": 58.64675769290409, "train/post_ent_max": 58.64675769290409, "train/post_ent_mean": 40.1392904539366, "train/post_ent_min": 18.19105867952914, "train/post_ent_std": 6.658006760880753, "train/prior_ent_mag": 73.53364410400391, "train/prior_ent_max": 73.53364410400391, "train/prior_ent_mean": 46.56258765555717, "train/prior_ent_min": 28.230719952969938, "train/prior_ent_std": 7.62330247002679, "train/rep_loss_mean": 6.447667822966705, "train/rep_loss_std": 8.669140869862325, "train/reward_avg": 0.01912978633206237, "train/reward_loss_mean": 0.07396506697342202, "train/reward_loss_std": 0.18021595083378456, "train/reward_max_data": 1.0088175979820457, "train/reward_max_pred": 1.0094306327201226, "train/reward_neg_acc": 0.9988450546522398, "train/reward_neg_loss": 0.052191688402279, "train/reward_pos_acc": 0.875019030313234, "train/reward_pos_loss": 0.7644895150854781, "train/reward_pred": 0.01887162008599655, "train/reward_rate": 0.03059543918918919, "eval_stats/sum_log_reward": 5.099999904632568, "eval_stats/max_log_achievement_collect_drink": 7.375, "eval_stats/max_log_achievement_collect_sapling": 2.5, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 6.5, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.25, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.125, "eval_stats/max_log_achievement_place_plant": 1.875, "eval_stats/max_log_achievement_place_table": 2.5, "eval_stats/max_log_achievement_wake_up": 1.625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 6.258763960431679e-07, "report/cont_loss_std": 1.106962918129284e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 8.921523112803698e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.911887750338792e-07, "report/cont_pred": 0.9951174855232239, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 5.506423473358154, "report/dyn_loss_std": 7.941767692565918, "report/image_loss_mean": 2.5439679622650146, "report/image_loss_std": 4.940965175628662, "report/model_loss_mean": 5.916089057922363, "report/model_loss_std": 8.921250343322754, "report/post_ent_mag": 59.09248352050781, "report/post_ent_max": 59.09248352050781, "report/post_ent_mean": 41.2380485534668, "report/post_ent_min": 20.740676879882812, "report/post_ent_std": 6.8532586097717285, "report/prior_ent_mag": 73.25379943847656, "report/prior_ent_max": 73.25379943847656, "report/prior_ent_mean": 46.95487594604492, "report/prior_ent_min": 26.23275375366211, "report/prior_ent_std": 7.493492603302002, "report/rep_loss_mean": 5.506423473358154, "report/rep_loss_std": 7.941767692565918, "report/reward_avg": 0.012508737854659557, "report/reward_loss_mean": 0.068266361951828, "report/reward_loss_std": 0.20265863835811615, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.001166582107544, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.04701707139611244, "report/reward_pos_acc": 0.7999999523162842, "report/reward_pos_loss": 0.9173880815505981, "report/reward_pred": 0.011644558981060982, "report/reward_rate": 0.0244140625, "eval/cont_avg": 0.9931640625, "eval/cont_loss_mean": 2.368558125454001e-05, "eval/cont_loss_std": 0.000373535294784233, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.002530326135456562, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 6.432401278289035e-06, "eval/cont_pred": 0.9931749701499939, "eval/cont_rate": 0.9931640625, "eval/dyn_loss_mean": 21.714277267456055, "eval/dyn_loss_std": 12.222655296325684, "eval/image_loss_mean": 22.980731964111328, "eval/image_loss_std": 25.684343338012695, "eval/model_loss_mean": 36.13798522949219, "eval/model_loss_std": 30.679018020629883, "eval/post_ent_mag": 57.39206314086914, "eval/post_ent_max": 57.39206314086914, "eval/post_ent_mean": 39.9353141784668, "eval/post_ent_min": 22.377944946289062, "eval/post_ent_std": 6.9030046463012695, "eval/prior_ent_mag": 73.25379943847656, "eval/prior_ent_max": 73.25379943847656, "eval/prior_ent_mean": 53.33060836791992, "eval/prior_ent_min": 28.687889099121094, "eval/prior_ent_std": 7.685455799102783, "eval/rep_loss_mean": 21.714277267456055, "eval/rep_loss_std": 12.222655296325684, "eval/reward_avg": 0.00742187537252903, "eval/reward_loss_mean": 0.12866313755512238, "eval/reward_loss_std": 0.7764506340026855, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0011661052703857, "eval/reward_neg_acc": 0.9920713901519775, "eval/reward_neg_loss": 0.08069334924221039, "eval/reward_pos_acc": 0.6000000238418579, "eval/reward_pos_loss": 3.355430841445923, "eval/reward_pred": 0.005038895178586245, "eval/reward_rate": 0.0146484375, "replay/size": 232169.0, "replay/inserts": 7436.0, "replay/samples": 29744.0, "replay/insert_wait_avg": 1.617822036620043e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.548291815295535e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 45928.0, "eval_replay/inserts": 1968.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.153325646873412e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.5367431640625e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2158257961273, "timer/env.step_count": 930.0, "timer/env.step_total": 84.04765295982361, "timer/env.step_frac": 0.0840295172223709, "timer/env.step_avg": 0.09037382038690711, "timer/env.step_min": 0.02287912368774414, "timer/env.step_max": 2.0471463203430176, "timer/replay._sample_count": 29744.0, "timer/replay._sample_total": 14.774088144302368, "timer/replay._sample_frac": 0.014770900203006537, "timer/replay._sample_avg": 0.0004967081812904239, "timer/replay._sample_min": 0.0003693103790283203, "timer/replay._sample_max": 0.020800352096557617, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1176.0, "timer/agent.policy_total": 18.891849040985107, "timer/agent.policy_frac": 0.01888777257243259, "timer/agent.policy_avg": 0.016064497483830875, "timer/agent.policy_min": 0.009595155715942383, "timer/agent.policy_max": 0.05027890205383301, "timer/dataset_train_count": 1859.0, "timer/dataset_train_total": 0.29486560821533203, "timer/dataset_train_frac": 0.00029480198234279296, "timer/dataset_train_avg": 0.0001586151738651598, "timer/dataset_train_min": 9.083747863769531e-05, "timer/dataset_train_max": 0.0005168914794921875, "timer/agent.train_count": 1859.0, "timer/agent.train_total": 834.4523859024048, "timer/agent.train_frac": 0.8342723284129381, "timer/agent.train_avg": 0.4488716438420682, "timer/agent.train_min": 0.4360048770904541, "timer/agent.train_max": 0.9865679740905762, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4803791046142578, "timer/agent.report_frac": 0.0004802754487831638, "timer/agent.report_avg": 0.2401895523071289, "timer/agent.report_min": 0.2316732406616211, "timer/agent.report_max": 0.24870586395263672, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.361701965332031e-05, "timer/dataset_eval_frac": 3.360976579885912e-08, "timer/dataset_eval_avg": 3.361701965332031e-05, "timer/dataset_eval_min": 3.361701965332031e-05, "timer/dataset_eval_max": 3.361701965332031e-05, "fps": 7.4342892483644105}
{"step": 232704, "time": 31349.831542015076, "episode/length": 169.0, "episode/score": 4.278612233294552, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.17861212598290876}
{"step": 232728, "time": 31354.705661058426, "episode/length": 195.0, "episode/score": 5.289288273525017, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.1892880809973576}
{"step": 232952, "time": 31383.486558914185, "episode/length": 219.0, "episode/score": 4.344518892678025, "episode/reward_rate": 0.990909090909091, "episode/intrinsic_return": 0.24451878164109075}
{"step": 233384, "time": 31437.178737163544, "episode/length": 53.0, "episode/score": 0.15636410209117457, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.05636408639838919}
{"step": 233616, "time": 31467.04283285141, "episode/length": 299.0, "episode/score": 6.414941411203472, "episode/reward_rate": 0.9966666666666667, "episode/intrinsic_return": 0.3149411754857283}
{"step": 233624, "time": 31469.576890945435, "episode/length": 186.0, "episode/score": 6.301260219901451, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.20126001549942885}
{"step": 233832, "time": 31496.144202709198, "episode/length": 137.0, "episode/score": 5.246803030606316, "episode/reward_rate": 0.9710144927536232, "episode/intrinsic_return": 0.14680282003428147}
{"step": 233984, "time": 31516.23151922226, "episode/length": 44.0, "episode/score": 3.1474793012603186, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.04747916600899771}
{"step": 234080, "time": 31529.55478477478, "episode/length": 171.0, "episode/score": 3.29907804612958, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.1990779577936337}
{"step": 234256, "time": 31552.284507751465, "episode/length": 208.0, "episode/score": 5.332741446454747, "episode/reward_rate": 0.9665071770334929, "episode/intrinsic_return": 0.23274130433492246}
{"step": 234272, "time": 31556.047288894653, "episode/length": 204.0, "episode/score": 5.327667767736784, "episode/reward_rate": 0.9707317073170731, "episode/intrinsic_return": 0.22766761979619332}
{"step": 234336, "time": 31565.389912605286, "episode/length": 227.0, "episode/score": 6.341591121426973, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.2415909170249506}
{"step": 234656, "time": 31605.62330508232, "episode/length": 39.0, "episode/score": 1.145083454088308, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.045083332573994994}
{"step": 234960, "time": 31643.955306768417, "episode/length": 196.0, "episode/score": 5.324150512649794, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.22415029369585682}
{"step": 235128, "time": 31665.92318558693, "episode/length": 188.0, "episode/score": 5.306855869879655, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.20685571844660444}
{"step": 235248, "time": 31681.858469247818, "episode/length": 176.0, "episode/score": 4.259342526951514, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.15934240299247904}
{"step": 235304, "time": 31690.190334558487, "episode/length": 42.0, "episode/score": 1.1494584261672571, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.049458332476206124}
{"step": 235368, "time": 31699.373089790344, "episode/length": 172.0, "episode/score": 4.301809247685014, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.20180909473856445}
{"step": 235624, "time": 31732.139929533005, "episode/length": 192.0, "episode/score": 4.305546467519889, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.20554632749554003}
{"step": 235704, "time": 31743.36719584465, "episode/length": 180.0, "episode/score": 4.305300643369264, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.20530050357774599}
{"step": 235736, "time": 31748.753308296204, "episode/length": 53.0, "episode/score": 2.1581155683852558, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.05811544605603558}
{"step": 235928, "time": 31773.635506153107, "episode/length": 37.0, "episode/score": 2.1454167787451297, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0454166658455506}
{"step": 236128, "time": 31799.570467233658, "episode/length": 231.0, "episode/score": 7.3488534737043665, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.24885321877809474}
{"step": 236560, "time": 31853.40714597702, "episode/length": 148.0, "episode/score": 3.2681473740194633, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.16814722654453362}
{"step": 236584, "time": 31857.702110290527, "episode/length": 181.0, "episode/score": 5.236182094671676, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.13618194323862554}
{"step": 237168, "time": 31930.227023601532, "episode/length": 178.0, "episode/score": 7.313232338085072, "episode/reward_rate": 0.9608938547486033, "episode/intrinsic_return": 0.2132321386889089}
{"step": 237392, "time": 31958.951241493225, "episode/length": 267.0, "episode/score": 7.410530049302906, "episode/reward_rate": 0.9813432835820896, "episode/intrinsic_return": 0.31052984292182373}
{"step": 237400, "time": 31961.614241361618, "episode/length": 211.0, "episode/score": 4.320177744859393, "episode/reward_rate": 0.9716981132075472, "episode/intrinsic_return": 0.22017759540540283}
{"step": 237408, "time": 31964.177663087845, "episode/length": 159.0, "episode/score": 3.2738196261125267, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.17381953195581445}
{"step": 237608, "time": 31991.131705760956, "episode/length": 209.0, "episode/score": 6.330517568594587, "episode/reward_rate": 0.9857142857142858, "episode/intrinsic_return": 0.23051731099076278}
{"step": 238016, "time": 32042.03702545166, "episode/length": 419.0, "episode/score": 6.5486091848651995, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.44860898279148387}
{"step": 238160, "time": 32060.960059404373, "episode/length": 196.0, "episode/score": 6.299930287292227, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.19993007590528578}
{"step": 238424, "time": 32094.412130594254, "episode/length": 232.0, "episode/score": 6.355824946493158, "episode/reward_rate": 0.9785407725321889, "episode/intrinsic_return": 0.2558247362703696}
{"step": 238448, "time": 32098.901484012604, "episode/length": 131.0, "episode/score": 4.256416779535357, "episode/reward_rate": 0.946969696969697, "episode/intrinsic_return": 0.15641666372539476}
{"step": 238488, "time": 32105.221072912216, "episode/length": 164.0, "episode/score": 5.285131335636834, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.18513118536793627}
{"step": 238712, "time": 32133.8556368351, "episode/length": 163.0, "episode/score": 7.283804303930083, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.18380407915537944}
{"step": 239208, "time": 32195.478060007095, "episode/length": 224.0, "episode/score": 5.342224641433859, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.2422244930276065}
{"step": 239336, "time": 32212.72528529167, "episode/length": 215.0, "episode/score": 5.352379592386569, "episode/reward_rate": 0.9675925925925926, "episode/intrinsic_return": 0.25237941778686945}
{"step": 239392, "time": 32221.161038160324, "episode/length": 171.0, "episode/score": 5.277300608511723, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.1773004096976365}
{"step": 239704, "time": 32260.6992521286, "episode/length": 192.0, "episode/score": 5.295623583087945, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.19562343974575924}
{"step": 239760, "time": 32269.032633066177, "episode/length": 166.0, "episode/score": 4.253611257916418, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.15361110380581522}
{"step": 239952, "time": 32293.75211071968, "episode/length": 154.0, "episode/score": 5.265230025110213, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.16522982268725173}
{"step": 239968, "time": 32297.18942451477, "episode/length": 184.0, "episode/score": 6.282481456199093, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.18248112886249146}
{"step": 240032, "time": 32324.76205420494, "eval_episode/length": 139.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9928571428571429}
{"step": 240032, "time": 32326.87872862816, "eval_episode/length": 154.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.967741935483871}
{"step": 240032, "time": 32326.886575460434, "eval_episode/length": 154.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9612903225806452}
{"step": 240032, "time": 32330.158767938614, "eval_episode/length": 156.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9681528662420382}
{"step": 240032, "time": 32332.956116199493, "eval_episode/length": 186.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9946524064171123}
{"step": 240032, "time": 32334.94479393959, "eval_episode/length": 196.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9746192893401016}
{"step": 240032, "time": 32337.848675489426, "eval_episode/length": 230.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.974025974025974}
{"step": 240032, "time": 32342.43284225464, "eval_episode/length": 299.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9866666666666667}
{"step": 240057, "time": 32346.38529896736, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.467201686549831, "train/action_min": 0.0, "train/action_std": 3.4663121159012253, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.05120987793481028, "train/actor_opt_grad_steps": 58700.0, "train/actor_opt_loss": -11.18082712727624, "train/adv_mag": 0.6317180615824622, "train/adv_max": 0.6132221333078436, "train/adv_mean": 0.0028512425977414995, "train/adv_min": -0.4647509679600999, "train/adv_std": 0.06595994940883404, "train/cont_avg": 0.9943676097972973, "train/cont_loss_mean": 0.0001310311930322197, "train/cont_loss_std": 0.0037226244369564384, "train/cont_neg_acc": 0.9964846453588941, "train/cont_neg_loss": 0.00754388554709907, "train/cont_pos_acc": 0.9999734382371644, "train/cont_pos_loss": 7.90428710000451e-05, "train/cont_pred": 0.9943693624960409, "train/cont_rate": 0.9943676097972973, "train/dyn_loss_mean": 6.491204382922199, "train/dyn_loss_std": 8.65988836546202, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1198230231130446, "train/extr_critic_critic_opt_grad_steps": 58700.0, "train/extr_critic_critic_opt_loss": 15818.393575802365, "train/extr_critic_mag": 6.291142705968908, "train/extr_critic_max": 6.291142705968908, "train/extr_critic_mean": 1.1283569977090167, "train/extr_critic_min": -0.5857284307479859, "train/extr_critic_std": 1.3811130613894076, "train/extr_return_normed_mag": 1.772934443241841, "train/extr_return_normed_max": 1.772934443241841, "train/extr_return_normed_mean": 0.31755210620325963, "train/extr_return_normed_min": -0.16481050375748324, "train/extr_return_normed_std": 0.3375500024975957, "train/extr_return_rate": 0.5122251819919895, "train/extr_return_raw_mag": 7.237494924906138, "train/extr_return_raw_max": 7.237494924906138, "train/extr_return_raw_mean": 1.14030699311076, "train/extr_return_raw_min": -0.881064864751455, "train/extr_return_raw_std": 1.414589817781706, "train/extr_reward_mag": 1.016312313079834, "train/extr_reward_max": 1.016312313079834, "train/extr_reward_mean": 0.02890726808156516, "train/extr_reward_min": -0.6548214719102189, "train/extr_reward_std": 0.16601322534922006, "train/image_loss_mean": 3.9151513860032363, "train/image_loss_std": 8.60355443438968, "train/model_loss_mean": 7.884420062400199, "train/model_loss_std": 12.56969616348679, "train/model_opt_grad_norm": 43.99611777228278, "train/model_opt_grad_steps": 58645.52972972973, "train/model_opt_loss": 10013.615912690033, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1270.2702702702702, "train/policy_entropy_mag": 2.505528853390668, "train/policy_entropy_max": 2.505528853390668, "train/policy_entropy_mean": 0.5314919864809191, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.5859344293942322, "train/policy_logprob_mag": 7.438383826693973, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5310173952901686, "train/policy_logprob_min": -7.438383826693973, "train/policy_logprob_std": 1.0952338901725975, "train/policy_randomness_mag": 0.8843417338422827, "train/policy_randomness_max": 0.8843417338422827, "train/policy_randomness_mean": 0.18759334610926137, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.20680914182920715, "train/post_ent_mag": 58.77897064621384, "train/post_ent_max": 58.77897064621384, "train/post_ent_mean": 40.466988249082824, "train/post_ent_min": 18.307888572280472, "train/post_ent_std": 6.732633325215932, "train/prior_ent_mag": 73.59248310810811, "train/prior_ent_max": 73.59248310810811, "train/prior_ent_mean": 46.93763914366026, "train/prior_ent_min": 28.022826766967775, "train/prior_ent_std": 7.6217213269826525, "train/rep_loss_mean": 6.491204382922199, "train/rep_loss_std": 8.65988836546202, "train/reward_avg": 0.01961268315318267, "train/reward_loss_mean": 0.07441501905386512, "train/reward_loss_std": 0.17886781986500766, "train/reward_max_data": 1.010439219990292, "train/reward_max_pred": 1.0108856987308812, "train/reward_neg_acc": 0.9989196555034534, "train/reward_neg_loss": 0.05258244372702934, "train/reward_pos_acc": 0.8739525859420364, "train/reward_pos_loss": 0.7476914154516684, "train/reward_pred": 0.019368538167327642, "train/reward_rate": 0.03145059121621622, "train_stats/sum_log_reward": 4.634883662988973, "train_stats/max_log_achievement_collect_drink": 5.534883720930233, "train_stats/max_log_achievement_collect_sapling": 2.4186046511627906, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 4.767441860465116, "train_stats/max_log_achievement_defeat_skeleton": 0.023255813953488372, "train_stats/max_log_achievement_defeat_zombie": 0.20930232558139536, "train_stats/max_log_achievement_eat_cow": 0.06976744186046512, "train_stats/max_log_achievement_make_wood_pickaxe": 0.023255813953488372, "train_stats/max_log_achievement_make_wood_sword": 0.20930232558139536, "train_stats/max_log_achievement_place_plant": 2.0, "train_stats/max_log_achievement_place_table": 1.697674418604651, "train_stats/max_log_achievement_wake_up": 2.2790697674418605, "train_stats/mean_log_entropy": 0.47173433005809784, "eval_stats/sum_log_reward": 4.724999964237213, "eval_stats/max_log_achievement_collect_drink": 3.0, "eval_stats/max_log_achievement_collect_sapling": 3.25, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 5.875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.375, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.125, "eval_stats/max_log_achievement_place_plant": 2.125, "eval_stats/max_log_achievement_place_table": 2.0, "eval_stats/max_log_achievement_wake_up": 2.625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 6.549111049025669e-07, "report/cont_loss_std": 8.948426511778962e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 4.7979570808820426e-05, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 3.291760037882341e-07, "report/cont_pred": 0.9931641221046448, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 6.251968860626221, "report/dyn_loss_std": 8.767728805541992, "report/image_loss_mean": 3.594625949859619, "report/image_loss_std": 7.078188419342041, "report/model_loss_mean": 7.430971145629883, "report/model_loss_std": 11.277233123779297, "report/post_ent_mag": 56.535003662109375, "report/post_ent_max": 56.535003662109375, "report/post_ent_mean": 40.29521560668945, "report/post_ent_min": 18.00853729248047, "report/post_ent_std": 6.326215744018555, "report/prior_ent_mag": 73.65504455566406, "report/prior_ent_max": 73.65504455566406, "report/prior_ent_mean": 46.28000259399414, "report/prior_ent_min": 30.954132080078125, "report/prior_ent_std": 7.365888595581055, "report/rep_loss_mean": 6.251968860626221, "report/rep_loss_std": 8.767728805541992, "report/reward_avg": 0.024765407666563988, "report/reward_loss_mean": 0.08516346663236618, "report/reward_loss_std": 0.23982445895671844, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0023787021636963, "report/reward_neg_acc": 0.9989888072013855, "report/reward_neg_loss": 0.06039145216345787, "report/reward_pos_acc": 0.8857142925262451, "report/reward_pos_loss": 0.7851497530937195, "report/reward_pred": 0.024094711989164352, "report/reward_rate": 0.0341796875, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 1.1777580766647588e-05, "eval/cont_loss_std": 0.0003714976483024657, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.005960164126008749, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.3690240052710578e-07, "eval/cont_pred": 0.9980583190917969, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 20.675704956054688, "eval/dyn_loss_std": 12.0631742477417, "eval/image_loss_mean": 24.55674171447754, "eval/image_loss_std": 34.843109130859375, "eval/model_loss_mean": 37.07817840576172, "eval/model_loss_std": 39.27510070800781, "eval/post_ent_mag": 57.77268981933594, "eval/post_ent_max": 57.77268981933594, "eval/post_ent_mean": 38.43295669555664, "eval/post_ent_min": 20.87466049194336, "eval/post_ent_std": 6.488455295562744, "eval/prior_ent_mag": 73.65504455566406, "eval/prior_ent_max": 73.65504455566406, "eval/prior_ent_mean": 51.28407669067383, "eval/prior_ent_min": 34.21894073486328, "eval/prior_ent_std": 6.883007049560547, "eval/rep_loss_mean": 20.675704956054688, "eval/rep_loss_std": 12.0631742477417, "eval/reward_avg": 0.03193359076976776, "eval/reward_loss_mean": 0.1159985214471817, "eval/reward_loss_std": 0.7371490597724915, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0018010139465332, "eval/reward_neg_acc": 0.9939332008361816, "eval/reward_neg_loss": 0.04441976174712181, "eval/reward_pos_acc": 0.7714285850524902, "eval/reward_pos_loss": 2.1386096477508545, "eval/reward_pred": 0.024882083758711815, "eval/reward_rate": 0.0341796875, "replay/size": 239553.0, "replay/inserts": 7384.0, "replay/samples": 29536.0, "replay/insert_wait_avg": 1.6637961758565024e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.524602074793591e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 48328.0, "eval_replay/inserts": 2400.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1988480885823568e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.834766387939453e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3832330703735, "timer/env.step_count": 923.0, "timer/env.step_total": 90.2808928489685, "timer/env.step_frac": 0.09024630747946327, "timer/env.step_avg": 0.09781245162401789, "timer/env.step_min": 0.02317023277282715, "timer/env.step_max": 1.9492218494415283, "timer/replay._sample_count": 29536.0, "timer/replay._sample_total": 14.310290813446045, "timer/replay._sample_frac": 0.014304808737672401, "timer/replay._sample_avg": 0.0004845033455256651, "timer/replay._sample_min": 0.0003578662872314453, "timer/replay._sample_max": 0.029145002365112305, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1223.0, "timer/agent.policy_total": 19.508792877197266, "timer/agent.policy_frac": 0.019501319326715352, "timer/agent.policy_avg": 0.015951588615860397, "timer/agent.policy_min": 0.009519338607788086, "timer/agent.policy_max": 0.04346752166748047, "timer/dataset_train_count": 1846.0, "timer/dataset_train_total": 0.286574125289917, "timer/dataset_train_frac": 0.00028646434268031907, "timer/dataset_train_avg": 0.00015524058791436456, "timer/dataset_train_min": 9.012222290039062e-05, "timer/dataset_train_max": 0.0012216567993164062, "timer/agent.train_count": 1846.0, "timer/agent.train_total": 826.92657995224, "timer/agent.train_frac": 0.8266097957422168, "timer/agent.train_avg": 0.4479558937986132, "timer/agent.train_min": 0.43300533294677734, "timer/agent.train_max": 0.9574053287506104, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.474306583404541, "timer/agent.report_frac": 0.0004741248830698617, "timer/agent.report_avg": 0.2371532917022705, "timer/agent.report_min": 0.22982382774353027, "timer/agent.report_max": 0.24448275566101074, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0279159545898438e-05, "timer/dataset_eval_frac": 3.026756001594081e-08, "timer/dataset_eval_avg": 3.0279159545898438e-05, "timer/dataset_eval_min": 3.0279159545898438e-05, "timer/dataset_eval_max": 3.0279159545898438e-05, "fps": 7.381059855111464}
{"step": 240064, "time": 32347.001626253128, "episode/length": 201.0, "episode/score": 5.330183874029899, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.23018367277109064}
{"step": 240096, "time": 32352.599714517593, "episode/length": 48.0, "episode/score": 2.1542805010276425, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.05428039441449073}
{"step": 240624, "time": 32418.248109579086, "episode/length": 160.0, "episode/score": 5.26284952306105, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.16284937162799906}
{"step": 240752, "time": 32435.48699760437, "episode/length": 169.0, "episode/score": 4.270848811136602, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.17084863735180988}
{"step": 240984, "time": 32465.118410348892, "episode/length": 152.0, "episode/score": 6.266794313571154, "episode/reward_rate": 0.9607843137254902, "episode/intrinsic_return": 0.16679415131147834}
{"step": 241104, "time": 32481.07154250145, "episode/length": 236.0, "episode/score": 6.359655500016743, "episode/reward_rate": 0.9831223628691983, "episode/intrinsic_return": 0.2596553331004543}
{"step": 241368, "time": 32514.786212921143, "episode/length": 174.0, "episode/score": 4.276191989323706, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.17619184499199037}
{"step": 241432, "time": 32524.275830745697, "episode/length": 170.0, "episode/score": 4.2840423505094805, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.18404222655044578}
{"step": 241448, "time": 32527.734267234802, "episode/length": 168.0, "episode/score": 4.304608955710137, "episode/reward_rate": 0.9585798816568047, "episode/intrinsic_return": 0.20460883990017464}
{"step": 241856, "time": 32578.611926794052, "episode/length": 50.0, "episode/score": 2.157593329407973, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.05759325294638984}
{"step": 242032, "time": 32601.242049455643, "episode/length": 175.0, "episode/score": 6.302232349378755, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.20223213915596716}
{"step": 242136, "time": 32615.594001054764, "episode/length": 172.0, "episode/score": 5.27765602774798, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.17765581950425258}
{"step": 242912, "time": 32711.37083888054, "episode/length": 131.0, "episode/score": 5.238055907827402, "episode/reward_rate": 0.9924242424242424, "episode/intrinsic_return": 0.13805567292456544}
{"step": 242984, "time": 32721.532021284103, "episode/length": 193.0, "episode/score": 3.3116212077484306, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.2116211124275651}
{"step": 243016, "time": 32726.989844083786, "episode/length": 238.0, "episode/score": 6.349315810503867, "episode/reward_rate": 0.9748953974895398, "episode/intrinsic_return": 0.24931560610184533}
{"step": 243168, "time": 32747.03545665741, "episode/length": 224.0, "episode/score": 6.33538621183925, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.2353860097073266}
{"step": 243456, "time": 32783.343428611755, "episode/length": 437.0, "episode/score": 5.51512221172834, "episode/reward_rate": 0.6050228310502284, "episode/intrinsic_return": 0.4151220034846119}
{"step": 243624, "time": 32805.194551706314, "episode/length": 198.0, "episode/score": 5.321420583449253, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.22142035087472323}
{"step": 243648, "time": 32809.57292628288, "episode/length": 188.0, "episode/score": 5.295315036616557, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.19531490564349951}
{"step": 244536, "time": 32918.72863173485, "episode/length": 443.0, "episode/score": 5.522444120665568, "episode/reward_rate": 0.5855855855855856, "episode/intrinsic_return": 0.4224440376265193}
{"step": 244560, "time": 32923.10452890396, "episode/length": 205.0, "episode/score": 4.330245509648648, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.23024547026534492}
{"step": 244608, "time": 32930.4096391201, "episode/length": 143.0, "episode/score": 6.251693524842722, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.15169325780925647}
{"step": 244704, "time": 32943.523233652115, "episode/length": 214.0, "episode/score": 5.359458546969108, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.259458328015171}
{"step": 244872, "time": 32965.3901488781, "episode/length": 155.0, "episode/score": 3.2537529794826696, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.15375288532595732}
{"step": 245016, "time": 32984.93415117264, "episode/length": 170.0, "episode/score": 4.281859115485531, "episode/reward_rate": 0.9649122807017544, "episode/intrinsic_return": 0.18185909388466825}
{"step": 245168, "time": 33005.0962665081, "episode/length": 36.0, "episode/score": 1.1443750532343984, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.04437499912455678}
{"step": 245208, "time": 33011.77125644684, "episode/length": 254.0, "episode/score": 6.393540959637448, "episode/reward_rate": 0.984313725490196, "episode/intrinsic_return": 0.2935408271800952}
{"step": 245512, "time": 33050.244037628174, "episode/length": 311.0, "episode/score": 7.449489242403615, "episode/reward_rate": 0.9903846153846154, "episode/intrinsic_return": 0.34948907449779654}
{"step": 245744, "time": 33080.97204756737, "episode/length": 129.0, "episode/score": 5.230999816731128, "episode/reward_rate": 0.9923076923076923, "episode/intrinsic_return": 0.1309995818282914}
{"step": 245768, "time": 33086.639654397964, "episode/length": 150.0, "episode/score": 5.266150712282524, "episode/reward_rate": 0.9602649006622517, "episode/intrinsic_return": 0.16615058328852683}
{"step": 246432, "time": 33168.82227063179, "episode/length": 236.0, "episode/score": 5.331258676747439, "episode/reward_rate": 0.9831223628691983, "episode/intrinsic_return": 0.23125854493036968}
{"step": 246928, "time": 33230.48315691948, "episode/length": 144.0, "episode/score": 5.2427282086764535, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.14272800043272582}
{"step": 246936, "time": 33232.99674272537, "episode/length": 290.0, "episode/score": 6.401119826728063, "episode/reward_rate": 0.9965635738831615, "episode/intrinsic_return": 0.3011196773759366}
{"step": 246968, "time": 33238.45124220848, "episode/length": 224.0, "episode/score": 6.351065805301005, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.25106570674961404}
{"step": 247016, "time": 33245.84512376785, "episode/length": 187.0, "episode/score": 5.304061405297944, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.2040612509545099}
{"step": 247040, "time": 33250.24291086197, "episode/length": 161.0, "episode/score": 5.257900805897862, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.15790058182165012}
{"step": 247336, "time": 33288.15049672127, "episode/length": 265.0, "episode/score": 7.384933173339505, "episode/reward_rate": 0.981203007518797, "episode/intrinsic_return": 0.2849329878840763}
{"step": 247344, "time": 33290.666449308395, "episode/length": 290.0, "episode/score": 5.412659641279788, "episode/reward_rate": 0.9862542955326461, "episode/intrinsic_return": 0.3126595517796886}
{"step": 247768, "time": 33343.63671851158, "episode/length": 166.0, "episode/score": 4.283876243850955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.18387612070682735}
{"step": 247773, "time": 33346.68213057518, "train_stats/sum_log_reward": 4.894871690334418, "train_stats/max_log_achievement_collect_drink": 7.153846153846154, "train_stats/max_log_achievement_collect_sapling": 2.2564102564102564, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 5.102564102564102, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.1794871794871795, "train_stats/max_log_achievement_eat_cow": 0.02564102564102564, "train_stats/max_log_achievement_make_wood_pickaxe": 0.02564102564102564, "train_stats/max_log_achievement_make_wood_sword": 0.358974358974359, "train_stats/max_log_achievement_place_plant": 1.8717948717948718, "train_stats/max_log_achievement_place_table": 1.6666666666666667, "train_stats/max_log_achievement_wake_up": 2.4615384615384617, "train_stats/mean_log_entropy": 0.5237616789646637, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.393374744474579, "train/action_min": 0.0, "train/action_std": 3.3819283512589844, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0533334501473706, "train/actor_opt_grad_steps": 60590.0, "train/actor_opt_loss": -7.7604235018087175, "train/adv_mag": 0.6184405908374588, "train/adv_max": 0.5952059427382415, "train/adv_mean": 0.0037668002944228457, "train/adv_min": -0.4829832269120093, "train/adv_std": 0.06742979147968514, "train/cont_avg": 0.994246883095855, "train/cont_loss_mean": 8.544105535880635e-05, "train/cont_loss_std": 0.0026204321948583463, "train/cont_neg_acc": 0.9965457687723822, "train/cont_neg_loss": 0.012456948380908677, "train/cont_pos_acc": 0.9999898045174198, "train/cont_pos_loss": 2.178619468465358e-05, "train/cont_pred": 0.9942476391174633, "train/cont_rate": 0.994246883095855, "train/dyn_loss_mean": 6.587377239385417, "train/dyn_loss_std": 8.693939115099338, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1049003777108661, "train/extr_critic_critic_opt_grad_steps": 60590.0, "train/extr_critic_critic_opt_loss": 15913.30543636658, "train/extr_critic_mag": 6.270456583388729, "train/extr_critic_max": 6.270456583388729, "train/extr_critic_mean": 1.1335572504626654, "train/extr_critic_min": -0.6024910637751762, "train/extr_critic_std": 1.3531656394968379, "train/extr_return_normed_mag": 1.772060444317951, "train/extr_return_normed_max": 1.772060444317951, "train/extr_return_normed_mean": 0.319970018968681, "train/extr_return_normed_min": -0.1692050656815267, "train/extr_return_normed_std": 0.33314082204060236, "train/extr_return_rate": 0.5275431375738253, "train/extr_return_raw_mag": 7.218543336799108, "train/extr_return_raw_max": 7.218543336799108, "train/extr_return_raw_mean": 1.1492921277649044, "train/extr_return_raw_min": -0.8955059582705325, "train/extr_return_raw_std": 1.3924146591072872, "train/extr_reward_mag": 1.0191668377021434, "train/extr_reward_max": 1.0191668377021434, "train/extr_reward_mean": 0.028916742961487003, "train/extr_reward_min": -0.668291316131236, "train/extr_reward_std": 0.16606737302683797, "train/image_loss_mean": 3.907903074600536, "train/image_loss_std": 8.536745904023165, "train/model_loss_mean": 7.93465319075115, "train/model_loss_std": 12.530093655067404, "train/model_opt_grad_norm": 43.1043659200271, "train/model_opt_grad_steps": 60533.81865284974, "train/model_opt_loss": 11189.346004189605, "train/model_opt_model_opt_grad_overflow": 0.0051813471502590676, "train/model_opt_model_opt_grad_scale": 1405.440414507772, "train/policy_entropy_mag": 2.4785057435999263, "train/policy_entropy_max": 2.4785057435999263, "train/policy_entropy_mean": 0.5196547480444834, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.5742454125782369, "train/policy_logprob_mag": 7.438383846085307, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5194505998198851, "train/policy_logprob_min": -7.438383846085307, "train/policy_logprob_std": 1.0869743311343416, "train/policy_randomness_mag": 0.8748037586558051, "train/policy_randomness_max": 0.8748037586558051, "train/policy_randomness_mean": 0.18341532052335344, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.20268343203734857, "train/post_ent_mag": 59.10533088723613, "train/post_ent_max": 59.10533088723613, "train/post_ent_mean": 40.801711383878875, "train/post_ent_min": 18.684039278969244, "train/post_ent_std": 6.830072978617614, "train/prior_ent_mag": 73.7076654384791, "train/prior_ent_max": 73.7076654384791, "train/prior_ent_mean": 47.36721068466266, "train/prior_ent_min": 27.908964364639836, "train/prior_ent_std": 7.518876871296779, "train/rep_loss_mean": 6.587377239385417, "train/rep_loss_std": 8.693939115099338, "train/reward_avg": 0.019355051434198346, "train/reward_loss_mean": 0.07423835407961836, "train/reward_loss_std": 0.17698414469321158, "train/reward_max_data": 1.010576455704289, "train/reward_max_pred": 1.0106334118027762, "train/reward_neg_acc": 0.9987304664646406, "train/reward_neg_loss": 0.05212794047408771, "train/reward_pos_acc": 0.8767347064042956, "train/reward_pos_loss": 0.7586255632533928, "train/reward_pred": 0.019113823293751695, "train/reward_rate": 0.03130059909326425, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 2.8353562811389565e-05, "report/cont_loss_std": 0.0002704846556298435, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.000392636691685766, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.62065113929566e-05, "report/cont_pred": 0.9941169023513794, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 5.959344387054443, "report/dyn_loss_std": 8.78264331817627, "report/image_loss_mean": 4.037045478820801, "report/image_loss_std": 6.104445457458496, "report/model_loss_mean": 7.691407680511475, "report/model_loss_std": 9.944293022155762, "report/post_ent_mag": 55.64253234863281, "report/post_ent_max": 55.64253234863281, "report/post_ent_mean": 40.21324157714844, "report/post_ent_min": 13.077362060546875, "report/post_ent_std": 6.6518754959106445, "report/prior_ent_mag": 73.43468475341797, "report/prior_ent_max": 73.43468475341797, "report/prior_ent_mean": 46.16668701171875, "report/prior_ent_min": 29.2506046295166, "report/prior_ent_std": 7.581353187561035, "report/rep_loss_mean": 5.959344387054443, "report/rep_loss_std": 8.78264331817627, "report/reward_avg": 0.01164809986948967, "report/reward_loss_mean": 0.07872690260410309, "report/reward_loss_std": 0.19926109910011292, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0040433406829834, "report/reward_neg_acc": 1.0000001192092896, "report/reward_neg_loss": 0.058970529586076736, "report/reward_pos_acc": 0.785714328289032, "report/reward_pos_loss": 0.7814896702766418, "report/reward_pred": 0.010555965825915337, "report/reward_rate": 0.02734375, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.00014041713438928127, "eval/cont_loss_std": 0.0024360399693250656, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.01103498600423336, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 8.695997530594468e-05, "eval/cont_pred": 0.9950860142707825, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 22.324066162109375, "eval/dyn_loss_std": 12.918943405151367, "eval/image_loss_mean": 26.251873016357422, "eval/image_loss_std": 29.051122665405273, "eval/model_loss_mean": 39.77647399902344, "eval/model_loss_std": 34.16154479980469, "eval/post_ent_mag": 57.152217864990234, "eval/post_ent_max": 57.152217864990234, "eval/post_ent_mean": 38.183570861816406, "eval/post_ent_min": 22.671186447143555, "eval/post_ent_std": 5.985532760620117, "eval/prior_ent_mag": 73.43468475341797, "eval/prior_ent_max": 73.43468475341797, "eval/prior_ent_mean": 51.77886199951172, "eval/prior_ent_min": 32.691062927246094, "eval/prior_ent_std": 6.6442341804504395, "eval/rep_loss_mean": 22.324066162109375, "eval/rep_loss_std": 12.918943405151367, "eval/reward_avg": 0.01503906212747097, "eval/reward_loss_mean": 0.13001808524131775, "eval/reward_loss_std": 0.7872987985610962, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0017704963684082, "eval/reward_neg_acc": 0.9940239191055298, "eval/reward_neg_loss": 0.0631551668047905, "eval/reward_pos_acc": 0.550000011920929, "eval/reward_pos_loss": 3.486536741256714, "eval/reward_pred": 0.00784358847886324, "eval/reward_rate": 0.01953125, "replay/size": 247269.0, "replay/inserts": 7716.0, "replay/samples": 30864.0, "replay/insert_wait_avg": 1.665253043483736e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.473059798102728e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 48328.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 8.940696716308594e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2831785678864, "timer/env.step_count": 964.0, "timer/env.step_total": 85.33646202087402, "timer/env.step_frac": 0.08531230340497271, "timer/env.step_avg": 0.08852330085152907, "timer/env.step_min": 0.022845745086669922, "timer/env.step_max": 2.0415403842926025, "timer/replay._sample_count": 30864.0, "timer/replay._sample_total": 14.934694290161133, "timer/replay._sample_frac": 0.014930466302095829, "timer/replay._sample_avg": 0.0004838871918792487, "timer/replay._sample_min": 0.0004017353057861328, "timer/replay._sample_max": 0.00877523422241211, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 964.0, "timer/agent.policy_total": 15.457398891448975, "timer/agent.policy_frac": 0.01545302292654712, "timer/agent.policy_avg": 0.016034646152955367, "timer/agent.policy_min": 0.014565706253051758, "timer/agent.policy_max": 0.051645517349243164, "timer/dataset_train_count": 1929.0, "timer/dataset_train_total": 0.35619568824768066, "timer/dataset_train_frac": 0.00035609484981807745, "timer/dataset_train_avg": 0.00018465302656696768, "timer/dataset_train_min": 9.179115295410156e-05, "timer/dataset_train_max": 0.04690408706665039, "timer/agent.train_count": 1929.0, "timer/agent.train_total": 865.1770520210266, "timer/agent.train_frac": 0.8649321217814616, "timer/agent.train_avg": 0.4485106542358873, "timer/agent.train_min": 0.4362833499908447, "timer/agent.train_max": 1.2694897651672363, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4798860549926758, "timer/agent.report_frac": 0.0004797502000180915, "timer/agent.report_avg": 0.2399430274963379, "timer/agent.report_min": 0.2327275276184082, "timer/agent.report_max": 0.24715852737426758, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.123283386230469e-05, "timer/dataset_eval_frac": 3.12239918969956e-08, "timer/dataset_eval_avg": 3.123283386230469e-05, "timer/dataset_eval_min": 3.123283386230469e-05, "timer/dataset_eval_max": 3.123283386230469e-05, "fps": 7.71370127948657}
{"step": 248144, "time": 33391.72493505478, "episode/length": 46.0, "episode/score": 2.151990174825187, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.051990006511914544}
{"step": 248232, "time": 33403.77748847008, "episode/length": 111.0, "episode/score": 4.222397070183888, "episode/reward_rate": 0.9553571428571429, "episode/intrinsic_return": 0.12239694971731296}
{"step": 248288, "time": 33412.04675865173, "episode/length": 164.0, "episode/score": 5.270472580506066, "episode/reward_rate": 0.9878787878787879, "episode/intrinsic_return": 0.17047239577823348}
{"step": 248296, "time": 33414.497614860535, "episode/length": 169.0, "episode/score": 4.300777896743966, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.2007777739490848}
{"step": 248336, "time": 33421.50567293167, "episode/length": 175.0, "episode/score": 5.284035181920444, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.18403500925614935}
{"step": 248344, "time": 33423.94605207443, "episode/length": 165.0, "episode/score": 5.265221088114231, "episode/reward_rate": 0.963855421686747, "episode/intrinsic_return": 0.16522091002207162}
{"step": 248448, "time": 33438.040680885315, "episode/length": 37.0, "episode/score": -0.8606007156631676, "episode/reward_rate": 0.868421052631579, "episode/intrinsic_return": 0.039399304732796736}
{"step": 248696, "time": 33469.64850687981, "episode/length": 57.0, "episode/score": 3.1628886129924467, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.06288846400411785}
{"step": 248800, "time": 33483.89163184166, "episode/length": 181.0, "episode/score": 4.288504893132085, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.18850472315989464}
{"step": 249248, "time": 33540.124188899994, "episode/length": 275.0, "episode/score": 5.382446253242506, "episode/reward_rate": 0.9963768115942029, "episode/intrinsic_return": 0.28244607977785563}
{"step": 249576, "time": 33581.75702667236, "episode/length": 154.0, "episode/score": 5.258452805394427, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.158452568163284}
{"step": 249592, "time": 33585.24348759651, "episode/length": 161.0, "episode/score": 3.2656656005751756, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.16566544611532663}
{"step": 249776, "time": 33609.21194267273, "episode/length": 178.0, "episode/score": 5.2801127819284375, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.18011263049538684}
{"step": 249880, "time": 33623.49015426636, "episode/length": 178.0, "episode/score": 5.294925381684607, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.19492521418624165}
{"step": 250016, "time": 33657.27284479141, "eval_episode/length": 47.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9791666666666666}
{"step": 250016, "time": 33661.32921910286, "eval_episode/length": 44.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9111111111111111}
{"step": 250016, "time": 33666.41976070404, "eval_episode/length": 172.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.976878612716763}
{"step": 250016, "time": 33668.49304819107, "eval_episode/length": 185.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9731182795698925}
{"step": 250016, "time": 33670.21302318573, "eval_episode/length": 188.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9947089947089947}
{"step": 250016, "time": 33670.221152067184, "eval_episode/length": 188.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9629629629629629}
{"step": 250016, "time": 33673.954974889755, "eval_episode/length": 196.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9949238578680203}
{"step": 250016, "time": 33675.63038277626, "eval_episode/length": 106.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9906542056074766}
{"step": 250224, "time": 33700.94822692871, "episode/length": 121.0, "episode/score": 3.2425834560999647, "episode/reward_rate": 0.9672131147540983, "episode/intrinsic_return": 0.1425833306275308}
{"step": 250296, "time": 33711.20632839203, "episode/length": 250.0, "episode/score": 5.400925687192284, "episode/reward_rate": 0.9840637450199203, "episode/intrinsic_return": 0.30092553459508053}
{"step": 250336, "time": 33717.57695579529, "episode/length": 191.0, "episode/score": 6.324579103578344, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.2245789258354307}
{"step": 250512, "time": 33740.54384684563, "episode/length": 226.0, "episode/score": 7.330049511604557, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.230049295648314}
{"step": 251088, "time": 33812.24851799011, "episode/length": 186.0, "episode/score": 4.313978721584135, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.21397854430688312}
{"step": 251160, "time": 33822.56229352951, "episode/length": 172.0, "episode/score": 5.2731468980855425, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.1731466898418148}
{"step": 251184, "time": 33826.90260505676, "episode/length": 162.0, "episode/score": 5.270263866124878, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.17026371469182777}
{"step": 251336, "time": 33846.987996816635, "episode/length": 219.0, "episode/score": 5.335948731393728, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.2359485787965241}
{"step": 251640, "time": 33885.51757359505, "episode/length": 167.0, "episode/score": 4.25069359563895, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.1506934728440683}
{"step": 251792, "time": 33905.56754183769, "episode/length": 159.0, "episode/score": 7.273762373788486, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.1737621051252063}
{"step": 251840, "time": 33912.89634227753, "episode/length": 187.0, "episode/score": 5.297079080517506, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.19707888286757225}
{"step": 251984, "time": 33931.77573490143, "episode/length": 219.0, "episode/score": 5.340600306773922, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.24060009853019437}
{"step": 252608, "time": 34009.19354701042, "episode/length": 180.0, "episode/score": 5.293020790471928, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.19302062448696233}
{"step": 252744, "time": 34027.190359830856, "episode/length": 194.0, "episode/score": 5.305596330223125, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.20559611988392135}
{"step": 252824, "time": 34038.33000874519, "episode/length": 185.0, "episode/score": 6.3026679997510655, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.20266775821255578}
{"step": 253256, "time": 34092.382022857666, "episode/length": 182.0, "episode/score": 4.27722922360681, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.17722908986888797}
{"step": 253552, "time": 34129.90953207016, "episode/length": 238.0, "episode/score": 5.3328248861616885, "episode/reward_rate": 0.9790794979079498, "episode/intrinsic_return": 0.2328247835066577}
{"step": 253824, "time": 34164.73700404167, "episode/length": 247.0, "episode/score": 5.390536792241619, "episode/reward_rate": 0.9717741935483871, "episode/intrinsic_return": 0.2905366501217941}
{"step": 253928, "time": 34178.95857954025, "episode/length": 242.0, "episode/score": 5.355412230813272, "episode/reward_rate": 0.9958847736625515, "episode/intrinsic_return": 0.25541204535784345}
{"step": 254576, "time": 34260.49065089226, "episode/length": 435.0, "episode/score": 4.529424225985167, "episode/reward_rate": 0.6146788990825688, "episode/intrinsic_return": 0.42942410668274533}
{"step": 254592, "time": 34263.90298581123, "episode/length": 230.0, "episode/score": 6.339023800584073, "episode/reward_rate": 0.9783549783549783, "episode/intrinsic_return": 0.23902362516946596}
{"step": 254648, "time": 34272.1786134243, "episode/length": 254.0, "episode/score": 6.387772137851243, "episode/reward_rate": 0.9686274509803922, "episode/intrinsic_return": 0.2877719822272411}
{"step": 254824, "time": 34294.96352434158, "episode/length": 195.0, "episode/score": 5.312665771575666, "episode/reward_rate": 0.9846938775510204, "episode/intrinsic_return": 0.21266560291314818}
{"step": 255136, "time": 34334.42393755913, "episode/length": 150.0, "episode/score": 4.261867221448483, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.16186709865360172}
{"step": 255217, "time": 34346.72425889969, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.46364011046707, "train/action_min": 0.0, "train/action_std": 3.4877885336517007, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.05231996675732956, "train/actor_opt_grad_steps": 62485.0, "train/actor_opt_loss": -11.026527135706788, "train/adv_mag": 0.6190576494060537, "train/adv_max": 0.5859148713850206, "train/adv_mean": 0.0025166306745240848, "train/adv_min": -0.49997660918261416, "train/adv_std": 0.0664702884612545, "train/cont_avg": 0.9942298807123656, "train/cont_loss_mean": 0.00011537957277443629, "train/cont_loss_std": 0.003538045822880019, "train/cont_neg_acc": 0.9972072076153111, "train/cont_neg_loss": 0.004080501796977694, "train/cont_pos_acc": 0.9999629861565047, "train/cont_pos_loss": 8.827211794988856e-05, "train/cont_pred": 0.9942069021604394, "train/cont_rate": 0.9942298807123656, "train/dyn_loss_mean": 6.667163100293887, "train/dyn_loss_std": 8.789509857854535, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.109558827774499, "train/extr_critic_critic_opt_grad_steps": 62485.0, "train/extr_critic_critic_opt_loss": 15873.238832535282, "train/extr_critic_mag": 6.410739583353842, "train/extr_critic_max": 6.410739583353842, "train/extr_critic_mean": 1.1329832282117618, "train/extr_critic_min": -0.5747245165609545, "train/extr_critic_std": 1.3919830895880216, "train/extr_return_normed_mag": 1.7620231557276942, "train/extr_return_normed_max": 1.7620231557276942, "train/extr_return_normed_mean": 0.3142370404575461, "train/extr_return_normed_min": -0.1589550656737179, "train/extr_return_normed_std": 0.33618396096011643, "train/extr_return_rate": 0.5029955182665138, "train/extr_return_raw_mag": 7.287316781218334, "train/extr_return_raw_max": 7.287316781218334, "train/extr_return_raw_mean": 1.1436636422270088, "train/extr_return_raw_min": -0.8643767721550439, "train/extr_return_raw_std": 1.4266213239521108, "train/extr_reward_mag": 1.0160832020544237, "train/extr_reward_max": 1.0160832020544237, "train/extr_reward_mean": 0.028975650367717588, "train/extr_reward_min": -0.6524099803739979, "train/extr_reward_std": 0.16686321214161892, "train/image_loss_mean": 3.9501988849332257, "train/image_loss_std": 8.957771616597329, "train/model_loss_mean": 8.026252569690827, "train/model_loss_std": 12.978633049995668, "train/model_opt_grad_norm": 43.07061641447006, "train/model_opt_grad_steps": 62427.29569892473, "train/model_opt_loss": 11527.855279737903, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1444.8924731182797, "train/policy_entropy_mag": 2.4811896354921403, "train/policy_entropy_max": 2.4811896354921403, "train/policy_entropy_mean": 0.5433595159681894, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.5968996030028149, "train/policy_logprob_mag": 7.438383876636464, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5429138964222323, "train/policy_logprob_min": -7.438383876636464, "train/policy_logprob_std": 1.1006574034690857, "train/policy_randomness_mag": 0.8757510563378693, "train/policy_randomness_max": 0.8757510563378693, "train/policy_randomness_mean": 0.1917820653767996, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.21067936726475275, "train/post_ent_mag": 59.128684320757465, "train/post_ent_max": 59.128684320757465, "train/post_ent_mean": 40.837142123970935, "train/post_ent_min": 18.876555104409494, "train/post_ent_std": 6.835468938273769, "train/prior_ent_mag": 73.7650626397902, "train/prior_ent_max": 73.7650626397902, "train/prior_ent_mean": 47.47774733266523, "train/prior_ent_min": 27.88442834218343, "train/prior_ent_std": 7.54687871215164, "train/rep_loss_mean": 6.667163100293887, "train/rep_loss_std": 8.789509857854535, "train/reward_avg": 0.020197443225951767, "train/reward_loss_mean": 0.07564047806125174, "train/reward_loss_std": 0.1816937414308389, "train/reward_max_data": 1.0093145466619922, "train/reward_max_pred": 1.009742062578919, "train/reward_neg_acc": 0.9987672157185052, "train/reward_neg_loss": 0.05279686840711742, "train/reward_pos_acc": 0.8772117739082664, "train/reward_pos_loss": 0.7608629067738851, "train/reward_pred": 0.01980623867242567, "train/reward_rate": 0.03237357190860215, "train_stats/sum_log_reward": 4.705263097035258, "train_stats/max_log_achievement_collect_drink": 5.052631578947368, "train_stats/max_log_achievement_collect_sapling": 2.1052631578947367, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 4.7894736842105265, "train_stats/max_log_achievement_defeat_skeleton": 0.02631578947368421, "train_stats/max_log_achievement_defeat_zombie": 0.15789473684210525, "train_stats/max_log_achievement_eat_cow": 0.18421052631578946, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.21052631578947367, "train_stats/max_log_achievement_place_plant": 1.9210526315789473, "train_stats/max_log_achievement_place_table": 1.4736842105263157, "train_stats/max_log_achievement_wake_up": 2.210526315789474, "train_stats/mean_log_entropy": 0.49895938681928736, "eval_stats/sum_log_reward": 4.34999992698431, "eval_stats/max_log_achievement_collect_drink": 7.625, "eval_stats/max_log_achievement_collect_sapling": 1.625, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 4.5, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.25, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.375, "eval_stats/max_log_achievement_place_plant": 1.625, "eval_stats/max_log_achievement_place_table": 1.5, "eval_stats/max_log_achievement_wake_up": 1.375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 4.511733550316421e-06, "report/cont_loss_std": 2.7738677090383135e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 3.714141030286555e-06, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 4.517222805588972e-06, "report/cont_pred": 0.9931595921516418, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 6.144436836242676, "report/dyn_loss_std": 8.504286766052246, "report/image_loss_mean": 3.3106744289398193, "report/image_loss_std": 6.944235801696777, "report/model_loss_mean": 7.082578659057617, "report/model_loss_std": 10.951363563537598, "report/post_ent_mag": 61.094024658203125, "report/post_ent_max": 61.094024658203125, "report/post_ent_mean": 41.49463653564453, "report/post_ent_min": 19.92180633544922, "report/post_ent_std": 7.095297813415527, "report/prior_ent_mag": 73.4493408203125, "report/prior_ent_max": 73.4493408203125, "report/prior_ent_mean": 47.463714599609375, "report/prior_ent_min": 29.85079002380371, "report/prior_ent_std": 7.797386646270752, "report/rep_loss_mean": 6.144436836242676, "report/rep_loss_std": 8.504286766052246, "report/reward_avg": 0.030097421258687973, "report/reward_loss_mean": 0.085237517952919, "report/reward_loss_std": 0.3285068869590759, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0024030208587646, "report/reward_neg_acc": 0.9989817142486572, "report/reward_neg_loss": 0.059780921787023544, "report/reward_pos_acc": 0.9761905074119568, "report/reward_pos_loss": 0.6804370880126953, "report/reward_pred": 0.030224567279219627, "report/reward_rate": 0.041015625, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 1.918029556691181e-05, "eval/cont_loss_std": 0.00036891739000566304, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 1.6329744539689273e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.9185876226401888e-05, "eval/cont_pred": 0.9980278015136719, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 21.918020248413086, "eval/dyn_loss_std": 12.62885856628418, "eval/image_loss_mean": 25.218984603881836, "eval/image_loss_std": 27.371501922607422, "eval/model_loss_mean": 38.53570556640625, "eval/model_loss_std": 32.473846435546875, "eval/post_ent_mag": 57.42243194580078, "eval/post_ent_max": 57.42243194580078, "eval/post_ent_mean": 38.686485290527344, "eval/post_ent_min": 18.8597469329834, "eval/post_ent_std": 6.502005100250244, "eval/prior_ent_mag": 73.4493408203125, "eval/prior_ent_max": 73.4493408203125, "eval/prior_ent_mean": 52.20162582397461, "eval/prior_ent_min": 35.58025360107422, "eval/prior_ent_std": 5.9844255447387695, "eval/rep_loss_mean": 21.918020248413086, "eval/rep_loss_std": 12.62885856628418, "eval/reward_avg": 0.02324218675494194, "eval/reward_loss_mean": 0.16589051485061646, "eval/reward_loss_std": 1.0593562126159668, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0020623207092285, "eval/reward_neg_acc": 0.9929789304733276, "eval/reward_neg_loss": 0.045588333159685135, "eval/reward_pos_acc": 0.5185185074806213, "eval/reward_pos_loss": 4.60815954208374, "eval/reward_pred": 0.011945756152272224, "eval/reward_rate": 0.0263671875, "replay/size": 254713.0, "replay/inserts": 7444.0, "replay/samples": 29776.0, "replay/insert_wait_avg": 1.6201829987146213e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.553871827122987e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 49928.0, "eval_replay/inserts": 1600.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2375414371490478e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.344650268554688e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0275278091431, "timer/env.step_count": 931.0, "timer/env.step_total": 82.48035836219788, "timer/env.step_frac": 0.0824780879211351, "timer/env.step_avg": 0.08859329577035217, "timer/env.step_min": 0.023150205612182617, "timer/env.step_max": 1.9818053245544434, "timer/replay._sample_count": 29776.0, "timer/replay._sample_total": 14.498746395111084, "timer/replay._sample_frac": 0.014498347287374067, "timer/replay._sample_avg": 0.0004869272701206033, "timer/replay._sample_min": 0.00036525726318359375, "timer/replay._sample_max": 0.009865283966064453, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1131.0, "timer/agent.policy_total": 19.045403480529785, "timer/agent.policy_frac": 0.019044879216729555, "timer/agent.policy_avg": 0.0168394372064808, "timer/agent.policy_min": 0.009935140609741211, "timer/agent.policy_max": 0.12546825408935547, "timer/dataset_train_count": 1861.0, "timer/dataset_train_total": 0.3044602870941162, "timer/dataset_train_frac": 0.0003044519062001491, "timer/dataset_train_avg": 0.00016360036920694046, "timer/dataset_train_min": 9.751319885253906e-05, "timer/dataset_train_max": 0.0012402534484863281, "timer/agent.train_count": 1861.0, "timer/agent.train_total": 835.5532011985779, "timer/agent.train_frac": 0.8355302008826747, "timer/agent.train_avg": 0.44898076367467915, "timer/agent.train_min": 0.43712949752807617, "timer/agent.train_max": 0.9614012241363525, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47783756256103516, "timer/agent.report_frac": 0.0004778244091018975, "timer/agent.report_avg": 0.23891878128051758, "timer/agent.report_min": 0.23158574104309082, "timer/agent.report_max": 0.24625182151794434, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.147125244140625e-05, "timer/dataset_eval_frac": 3.147038613062319e-08, "timer/dataset_eval_avg": 3.147125244140625e-05, "timer/dataset_eval_min": 3.147125244140625e-05, "timer/dataset_eval_max": 3.147125244140625e-05, "fps": 7.443687091424579}
{"step": 255224, "time": 34347.3130710125, "episode/length": 208.0, "episode/score": 6.334977063614133, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.23497679774482094}
{"step": 255672, "time": 34403.80076313019, "episode/length": 230.0, "episode/score": 6.363197845505056, "episode/reward_rate": 0.9653679653679653, "episode/intrinsic_return": 0.2631977408127568}
{"step": 255760, "time": 34416.21163105965, "episode/length": 147.0, "episode/score": 4.278833446733188, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.1788333297590725}
{"step": 255784, "time": 34420.73766732216, "episode/length": 141.0, "episode/score": 4.244660599184499, "episode/reward_rate": 0.9577464788732394, "episode/intrinsic_return": 0.14466044973050884}
{"step": 256080, "time": 34458.209918022156, "episode/length": 406.0, "episode/score": 5.536144349265669, "episode/reward_rate": 0.9926289926289926, "episode/intrinsic_return": 0.4361442214649287}
{"step": 256224, "time": 34477.228384017944, "episode/length": 203.0, "episode/score": 5.327935277842698, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.22793512640964764}
{"step": 256352, "time": 34494.20990538597, "episode/length": 190.0, "episode/score": 4.296381747877604, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.19638156955261366}
{"step": 256536, "time": 34518.33036732674, "episode/length": 174.0, "episode/score": 5.293237571736427, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.1932373403260499}
{"step": 256600, "time": 34527.67110037804, "episode/length": 46.0, "episode/score": 3.153556253860188, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.053556158539322496}
{"step": 257080, "time": 34587.76011991501, "episode/length": 161.0, "episode/score": 4.274666139810961, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.17466601701607942}
{"step": 257112, "time": 34593.263548374176, "episode/length": 235.0, "episode/score": 6.362894747499013, "episode/reward_rate": 0.9703389830508474, "episode/intrinsic_return": 0.26289454658945033}
{"step": 257128, "time": 34596.743934869766, "episode/length": 181.0, "episode/score": 5.269792776608938, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.1697925637085973}
{"step": 257352, "time": 34625.651280879974, "episode/length": 198.0, "episode/score": 5.307746576502268, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.20774633810697196}
{"step": 257560, "time": 34652.84648132324, "episode/length": 184.0, "episode/score": 5.306024248141512, "episode/reward_rate": 0.9621621621621622, "episode/intrinsic_return": 0.2060241503177167}
{"step": 257800, "time": 34683.66896390915, "episode/length": 157.0, "episode/score": 4.259378558872413, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.1593784384058381}
{"step": 258208, "time": 34734.77994155884, "episode/length": 231.0, "episode/score": 6.36778956454782, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.26778938331244717}
{"step": 258288, "time": 34746.122755527496, "episode/length": 210.0, "episode/score": 4.289952414831987, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.1899522920371055}
{"step": 258424, "time": 34764.214980602264, "episode/length": 167.0, "episode/score": 5.280955865732267, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.18095571546336942}
{"step": 258432, "time": 34766.81690263748, "episode/length": 164.0, "episode/score": 5.291988508338363, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.1919883580694659}
{"step": 258536, "time": 34781.05835223198, "episode/length": 40.0, "episode/score": 2.149375105276704, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.04937499901279807}
{"step": 258560, "time": 34785.46513223648, "episode/length": 178.0, "episode/score": 3.2940455343218673, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.1940454123418931}
{"step": 258624, "time": 34794.751026153564, "episode/length": 158.0, "episode/score": 6.275883528875511, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.17588334880429102}
{"step": 258840, "time": 34822.723589897156, "episode/length": 37.0, "episode/score": 2.1424445104203187, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.04244444373762235}
{"step": 258880, "time": 34829.27773451805, "episode/length": 164.0, "episode/score": 4.24758403888427, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.14758382912714296}
{"step": 259376, "time": 34890.94170951843, "episode/length": 196.0, "episode/score": 7.333059297803175, "episode/reward_rate": 0.9644670050761421, "episode/intrinsic_return": 0.23305906557789058}
{"step": 259384, "time": 34893.37180042267, "episode/length": 136.0, "episode/score": 5.234140385267892, "episode/reward_rate": 0.9927007299270073, "episode/intrinsic_return": 0.13414014687259623}
{"step": 259544, "time": 34914.338941812515, "episode/length": 139.0, "episode/score": 4.246116410980903, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.14611626126497868}
{"step": 259648, "time": 34928.666771650314, "episode/length": 135.0, "episode/score": 4.248336693135116, "episode/reward_rate": 0.9558823529411765, "episode/intrinsic_return": 0.148336632680639}
{"step": 259816, "time": 34951.22688817978, "episode/length": 172.0, "episode/score": 3.2795629799302333, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.17956288577352097}
{"step": 259952, "time": 34969.1759390831, "episode/length": 165.0, "episode/score": 3.2885062282230137, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.1885061363946079}
{"step": 260000, "time": 34990.93549847603, "eval_episode/length": 44.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9777777777777777}
{"step": 260000, "time": 34998.527322769165, "eval_episode/length": 173.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9712643678160919}
{"step": 260000, "time": 35000.580072402954, "eval_episode/length": 175.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9715909090909091}
{"step": 260000, "time": 35003.25107216835, "eval_episode/length": 145.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9931506849315068}
{"step": 260000, "time": 35007.10538625717, "eval_episode/length": 224.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9777777777777777}
{"step": 260000, "time": 35010.27988624573, "eval_episode/length": 245.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9796747967479674}
{"step": 260000, "time": 35012.400712013245, "eval_episode/length": 247.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9798387096774194}
{"step": 260000, "time": 35015.52447462082, "eval_episode/length": 271.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9742647058823529}
{"step": 260648, "time": 35094.122109889984, "episode/length": 220.0, "episode/score": 6.340324279781271, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.24032410168911156}
{"step": 260680, "time": 35099.7387919426, "episode/length": 229.0, "episode/score": 3.3530159922902385, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.2530159124526108}
{"step": 260752, "time": 35109.91361999512, "episode/length": 137.0, "episode/score": 5.234010751761616, "episode/reward_rate": 0.9927536231884058, "episode/intrinsic_return": 0.13401058309909786}
{"step": 260760, "time": 35112.46923804283, "episode/length": 172.0, "episode/score": 5.261374667064956, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.16137451563190552}
{"step": 261048, "time": 35149.05048084259, "episode/length": 187.0, "episode/score": 4.29910101506448, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.19910089110544504}
{"step": 261144, "time": 35162.50921750069, "episode/length": 165.0, "episode/score": 3.290378060977673, "episode/reward_rate": 0.963855421686747, "episode/intrinsic_return": 0.19037797264172696}
{"step": 261168, "time": 35167.355479478836, "episode/length": 222.0, "episode/score": 5.355365471476944, "episode/reward_rate": 0.968609865470852, "episode/intrinsic_return": 0.2553653270288123}
{"step": 261392, "time": 35196.109843969345, "episode/length": 179.0, "episode/score": 7.270334121070391, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.17033382539875674}
{"step": 262064, "time": 35279.28791952133, "episode/length": 111.0, "episode/score": 4.211394961380847, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.11139485901685475}
{"step": 262112, "time": 35286.54763698578, "episode/length": 178.0, "episode/score": 5.290191618741119, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.19019146730806824}
{"step": 262256, "time": 35306.88110089302, "episode/length": 186.0, "episode/score": 5.27960952546573, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.17960937606994776}
{"step": 262488, "time": 35336.627029657364, "episode/length": 216.0, "episode/score": 4.316312060236669, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.21631200234332937}
{"step": 262553, "time": 35347.005821704865, "train_stats/sum_log_reward": 4.623809434118725, "train_stats/max_log_achievement_collect_drink": 5.119047619047619, "train_stats/max_log_achievement_collect_sapling": 2.0714285714285716, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 5.023809523809524, "train_stats/max_log_achievement_defeat_skeleton": 0.023809523809523808, "train_stats/max_log_achievement_defeat_zombie": 0.11904761904761904, "train_stats/max_log_achievement_eat_cow": 0.07142857142857142, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.23809523809523808, "train_stats/max_log_achievement_place_plant": 1.7142857142857142, "train_stats/max_log_achievement_place_table": 1.8095238095238095, "train_stats/max_log_achievement_wake_up": 2.261904761904762, "train_stats/mean_log_entropy": 0.4979745078654516, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.508485887871414, "train/action_min": 0.0, "train/action_std": 3.5781125071270217, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.05160041114753061, "train/actor_opt_grad_steps": 64330.0, "train/actor_opt_loss": -11.993080967569043, "train/adv_mag": 0.6021507250480964, "train/adv_max": 0.5801254554850156, "train/adv_mean": 0.002411305382509931, "train/adv_min": -0.47428453701441403, "train/adv_std": 0.06509502502819879, "train/cont_avg": 0.994535519125683, "train/cont_loss_mean": 5.576278296258809e-05, "train/cont_loss_std": 0.0016507436417113554, "train/cont_neg_acc": 0.9985363001380462, "train/cont_neg_loss": 0.00560365639176852, "train/cont_pos_acc": 0.9999946251593, "train/cont_pos_loss": 2.375864455430976e-05, "train/cont_pred": 0.9945436484826718, "train/cont_rate": 0.994535519125683, "train/dyn_loss_mean": 6.4822370940870275, "train/dyn_loss_std": 8.719265812733134, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0717198288505847, "train/extr_critic_critic_opt_grad_steps": 64330.0, "train/extr_critic_critic_opt_loss": 15744.068909024933, "train/extr_critic_mag": 6.191765047813374, "train/extr_critic_max": 6.191765047813374, "train/extr_critic_mean": 1.084069628858827, "train/extr_critic_min": -0.6078002022915199, "train/extr_critic_std": 1.3398770963559385, "train/extr_return_normed_mag": 1.7493726901017903, "train/extr_return_normed_max": 1.7493726901017903, "train/extr_return_normed_mean": 0.31165919253409236, "train/extr_return_normed_min": -0.17272480528374187, "train/extr_return_normed_std": 0.33127813195921685, "train/extr_return_rate": 0.5016546689096044, "train/extr_return_raw_mag": 7.053047425108529, "train/extr_return_raw_max": 7.053047425108529, "train/extr_return_raw_mean": 1.094086388584043, "train/extr_return_raw_min": -0.9137645956597041, "train/extr_return_raw_std": 1.3729959797989475, "train/extr_reward_mag": 1.0209133872568934, "train/extr_reward_max": 1.0209133872568934, "train/extr_reward_mean": 0.028284897534125816, "train/extr_reward_min": -0.6607370604582823, "train/extr_reward_std": 0.16522266556982135, "train/image_loss_mean": 3.8254208160879832, "train/image_loss_std": 8.555609562357919, "train/model_loss_mean": 7.789822411667454, "train/model_loss_std": 12.572738277456148, "train/model_opt_grad_norm": 41.58079072295642, "train/model_opt_grad_steps": 64270.502732240435, "train/model_opt_loss": 9959.352541730703, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1277.3224043715848, "train/policy_entropy_mag": 2.5111293089194375, "train/policy_entropy_max": 2.5111293089194375, "train/policy_entropy_mean": 0.5529499228209094, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6122471164158785, "train/policy_logprob_mag": 7.438383889328587, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5537016500866478, "train/policy_logprob_min": -7.438383889328587, "train/policy_logprob_std": 1.1096327187585049, "train/policy_randomness_mag": 0.8863184474856476, "train/policy_randomness_max": 0.8863184474856476, "train/policy_randomness_mean": 0.19516705815257923, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.2160963633509933, "train/post_ent_mag": 59.73224468960788, "train/post_ent_max": 59.73224468960788, "train/post_ent_mean": 41.37997926388933, "train/post_ent_min": 18.515748096945508, "train/post_ent_std": 6.906550780020125, "train/prior_ent_mag": 73.91797404471642, "train/prior_ent_max": 73.91797404471642, "train/prior_ent_mean": 47.85133047051769, "train/prior_ent_min": 28.631928918140183, "train/prior_ent_std": 7.427552027780502, "train/rep_loss_mean": 6.4822370940870275, "train/rep_loss_std": 8.719265812733134, "train/reward_avg": 0.01976885679279724, "train/reward_loss_mean": 0.07500365437542805, "train/reward_loss_std": 0.1844179594044477, "train/reward_max_data": 1.012725441182246, "train/reward_max_pred": 1.0110922029109601, "train/reward_neg_acc": 0.9989147427303543, "train/reward_neg_loss": 0.05234038316812672, "train/reward_pos_acc": 0.8749898082571603, "train/reward_pos_loss": 0.7717608434906422, "train/reward_pred": 0.019351823597668055, "train/reward_rate": 0.031484801912568305, "eval_stats/sum_log_reward": 4.5999998562037945, "eval_stats/max_log_achievement_collect_drink": 6.625, "eval_stats/max_log_achievement_collect_sapling": 1.75, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 5.75, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.25, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.125, "eval_stats/max_log_achievement_make_wood_sword": 0.375, "eval_stats/max_log_achievement_place_plant": 1.5, "eval_stats/max_log_achievement_place_table": 1.75, "eval_stats/max_log_achievement_wake_up": 2.375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9912109375, "report/cont_loss_mean": 1.0726180335041136e-06, "report/cont_loss_std": 9.474561920796987e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 2.116080759151373e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 8.944961109591532e-07, "report/cont_pred": 0.9912102818489075, "report/cont_rate": 0.9912109375, "report/dyn_loss_mean": 6.737914085388184, "report/dyn_loss_std": 8.93469524383545, "report/image_loss_mean": 3.6120924949645996, "report/image_loss_std": 9.027432441711426, "report/model_loss_mean": 7.735673904418945, "report/model_loss_std": 12.74332046508789, "report/post_ent_mag": 60.26256561279297, "report/post_ent_max": 60.26256561279297, "report/post_ent_mean": 42.21333312988281, "report/post_ent_min": 17.317710876464844, "report/post_ent_std": 7.732879161834717, "report/prior_ent_mag": 73.89608764648438, "report/prior_ent_max": 73.89608764648438, "report/prior_ent_mean": 48.924705505371094, "report/prior_ent_min": 27.85923194885254, "report/prior_ent_std": 8.073958396911621, "report/rep_loss_mean": 6.737914085388184, "report/rep_loss_std": 8.93469524383545, "report/reward_avg": 0.022533901035785675, "report/reward_loss_mean": 0.08083199709653854, "report/reward_loss_std": 0.170907661318779, "report/reward_max_data": 1.1012500524520874, "report/reward_max_pred": 1.1248159408569336, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.05728427693247795, "report/reward_pos_acc": 0.9210526347160339, "report/reward_pos_loss": 0.6918330788612366, "report/reward_pred": 0.02252153307199478, "report/reward_rate": 0.037109375, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 2.5866904707072536e-06, "eval/cont_loss_std": 5.7896628277376294e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 7.939398346934468e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.3610080006619683e-06, "eval/cont_pred": 0.9970682859420776, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 20.333938598632812, "eval/dyn_loss_std": 12.496811866760254, "eval/image_loss_mean": 21.49317741394043, "eval/image_loss_std": 21.750041961669922, "eval/model_loss_mean": 33.79783630371094, "eval/model_loss_std": 26.80422592163086, "eval/post_ent_mag": 56.93994140625, "eval/post_ent_max": 56.93994140625, "eval/post_ent_mean": 39.85134506225586, "eval/post_ent_min": 20.350910186767578, "eval/post_ent_std": 6.858952522277832, "eval/prior_ent_mag": 73.89608764648438, "eval/prior_ent_max": 73.89608764648438, "eval/prior_ent_mean": 52.224853515625, "eval/prior_ent_min": 36.34991455078125, "eval/prior_ent_std": 5.9316816329956055, "eval/rep_loss_mean": 20.333938598632812, "eval/rep_loss_std": 12.496811866760254, "eval/reward_avg": 0.02353515475988388, "eval/reward_loss_mean": 0.10429470241069794, "eval/reward_loss_std": 0.7678741216659546, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0071823596954346, "eval/reward_neg_acc": 0.9959879517555237, "eval/reward_neg_loss": 0.050351180136203766, "eval/reward_pos_acc": 0.8518518805503845, "eval/reward_pos_loss": 2.0962092876434326, "eval/reward_pred": 0.021552685648202896, "eval/reward_rate": 0.0263671875, "replay/size": 262049.0, "replay/inserts": 7336.0, "replay/samples": 29344.0, "replay/insert_wait_avg": 1.5987629718842917e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.581798564906728e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 52104.0, "eval_replay/inserts": 2176.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3725503402597764e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.301568984985352e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2653782367706, "timer/env.step_count": 917.0, "timer/env.step_total": 89.85307693481445, "timer/env.step_frac": 0.08982923820996784, "timer/env.step_avg": 0.09798590723534836, "timer/env.step_min": 0.023299217224121094, "timer/env.step_max": 1.969283103942871, "timer/replay._sample_count": 29344.0, "timer/replay._sample_total": 14.364697694778442, "timer/replay._sample_frac": 0.01436088662800664, "timer/replay._sample_avg": 0.0004895275931971934, "timer/replay._sample_min": 0.00034999847412109375, "timer/replay._sample_max": 0.010502338409423828, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1189.0, "timer/agent.policy_total": 19.47586989402771, "timer/agent.policy_frac": 0.019470702793251752, "timer/agent.policy_avg": 0.016380041963017417, "timer/agent.policy_min": 0.009836435317993164, "timer/agent.policy_max": 0.05205845832824707, "timer/dataset_train_count": 1834.0, "timer/dataset_train_total": 0.29794979095458984, "timer/dataset_train_frac": 0.0002978707425421485, "timer/dataset_train_avg": 0.00016245899179639578, "timer/dataset_train_min": 9.822845458984375e-05, "timer/dataset_train_max": 0.0010387897491455078, "timer/agent.train_count": 1834.0, "timer/agent.train_total": 824.1056380271912, "timer/agent.train_frac": 0.8238869963488019, "timer/agent.train_avg": 0.4493487666451424, "timer/agent.train_min": 0.43526482582092285, "timer/agent.train_max": 0.9898977279663086, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4796457290649414, "timer/agent.report_frac": 0.000479518475297468, "timer/agent.report_avg": 0.2398228645324707, "timer/agent.report_min": 0.23270654678344727, "timer/agent.report_max": 0.24693918228149414, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9802322387695312e-05, "timer/dataset_eval_frac": 2.9794415598218245e-08, "timer/dataset_eval_avg": 2.9802322387695312e-05, "timer/dataset_eval_min": 2.9802322387695312e-05, "timer/dataset_eval_max": 2.9802322387695312e-05, "fps": 7.333931778306545}
{"step": 262632, "time": 35356.410787820816, "episode/length": 185.0, "episode/score": 3.2945146794158973, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.19451456826254798}
{"step": 262936, "time": 35394.82542181015, "episode/length": 55.0, "episode/score": 1.1602278223663234, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0602277304215022}
{"step": 263000, "time": 35404.2441368103, "episode/length": 200.0, "episode/score": 5.312004725485622, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.21200452038510775}
{"step": 263136, "time": 35422.29804944992, "episode/length": 310.0, "episode/score": 7.437494406684891, "episode/reward_rate": 0.9807073954983923, "episode/intrinsic_return": 0.3374942370910503}
{"step": 263208, "time": 35432.51314043999, "episode/length": 136.0, "episode/score": 4.258053670414483, "episode/reward_rate": 0.9635036496350365, "episode/intrinsic_return": 0.15805361484945024}
{"step": 263272, "time": 35441.71164703369, "episode/length": 150.0, "episode/score": 5.241422969459109, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.1414228121470842}
{"step": 263320, "time": 35449.038454294205, "episode/length": 283.0, "episode/score": 6.421631902885565, "episode/reward_rate": 0.9894366197183099, "episode/intrinsic_return": 0.32163170558487764}
{"step": 263384, "time": 35458.221593379974, "episode/length": 140.0, "episode/score": 5.232447593111829, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.13244757215124991}
{"step": 263864, "time": 35518.33876657486, "episode/length": 153.0, "episode/score": 5.275534337989939, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.1755341262537513}
{"step": 264232, "time": 35565.24402093887, "episode/length": 161.0, "episode/score": 5.270028898731198, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.1700287167973329}
{"step": 264448, "time": 35593.13843536377, "episode/length": 154.0, "episode/score": 6.273511674800375, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.17351149472915495}
{"step": 264488, "time": 35599.43364238739, "episode/length": 168.0, "episode/score": 4.266470888077947, "episode/reward_rate": 0.9585798816568047, "episode/intrinsic_return": 0.16647079272797782}
{"step": 264528, "time": 35605.65124964714, "episode/length": 150.0, "episode/score": 5.25265553677923, "episode/reward_rate": 0.9735099337748344, "episode/intrinsic_return": 0.15265536775291366}
{"step": 264640, "time": 35620.98053741455, "episode/length": 170.0, "episode/score": 6.27157676316142, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.1715765517744785}
{"step": 264680, "time": 35627.25562644005, "episode/length": 55.0, "episode/score": 3.1622535799951947, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.06225343764253921}
{"step": 264952, "time": 35661.6569211483, "episode/length": 243.0, "episode/score": 6.366082217639132, "episode/reward_rate": 0.9795081967213115, "episode/intrinsic_return": 0.2660820074163439}
{"step": 265000, "time": 35669.09169435501, "episode/length": 141.0, "episode/score": 5.244441665458908, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.14444144135359238}
{"step": 265080, "time": 35680.286130428314, "episode/length": 211.0, "episode/score": 5.305327983355028, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.20532785471027637}
{"step": 265720, "time": 35759.79738855362, "episode/length": 153.0, "episode/score": 4.249995980601625, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.14999585390683023}
{"step": 265984, "time": 35793.48782634735, "episode/length": 181.0, "episode/score": 5.3010852108373, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.2010851393233679}
{"step": 266008, "time": 35797.90883207321, "episode/length": 194.0, "episode/score": 5.25623950786121, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.15623932511243765}
{"step": 266184, "time": 35820.886332035065, "episode/length": 147.0, "episode/score": 5.262038933460872, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.16203879297086132}
{"step": 266376, "time": 35845.599314928055, "episode/length": 161.0, "episode/score": 5.272091232576258, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.172091020840071}
{"step": 266480, "time": 35860.032709121704, "episode/length": 229.0, "episode/score": 6.344037633942435, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.24403738798014274}
{"step": 266552, "time": 35870.312212228775, "episode/length": 45.0, "episode/score": 1.1526737037929706, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.05267361010191962}
{"step": 267088, "time": 35936.83809423447, "episode/length": 137.0, "episode/score": 7.2524628226431105, "episode/reward_rate": 0.9927536231884058, "episode/intrinsic_return": 0.15246253987902492}
{"step": 267136, "time": 35944.404344797134, "episode/length": 176.0, "episode/score": 5.281338702241328, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.18133848049342305}
{"step": 267336, "time": 35970.25416445732, "episode/length": 165.0, "episode/score": 5.270164285764167, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.17016410534370152}
{"step": 267424, "time": 35982.437140226364, "episode/length": 308.0, "episode/score": 7.433920040420389, "episode/reward_rate": 0.9870550161812298, "episode/intrinsic_return": 0.3339198735914124}
{"step": 267520, "time": 35995.46097278595, "episode/length": 47.0, "episode/score": 3.1591667607426643, "episode/reward_rate": 0.9166666666666666, "episode/intrinsic_return": 0.059166665421798825}
{"step": 267584, "time": 36004.762605428696, "episode/length": 137.0, "episode/score": 5.248785207396168, "episode/reward_rate": 0.9927536231884058, "episode/intrinsic_return": 0.1487850134715245}
{"step": 267880, "time": 36042.14531517029, "episode/length": 44.0, "episode/score": 3.1539584832498804, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.05395833228249103}
{"step": 268152, "time": 36076.73227930069, "episode/length": 221.0, "episode/score": 4.3521039087145255, "episode/reward_rate": 0.9684684684684685, "episode/intrinsic_return": 0.252103779400386}
{"step": 268168, "time": 36080.25352740288, "episode/length": 435.0, "episode/score": 6.536389054791471, "episode/reward_rate": 0.6513761467889908, "episode/intrinsic_return": 0.43638887821271055}
{"step": 268448, "time": 36115.71926355362, "episode/length": 236.0, "episode/score": 4.344229431632812, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.24422928380863596}
{"step": 268584, "time": 36133.9068543911, "episode/length": 51.0, "episode/score": 3.1591081800627308, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.05910808474186524}
{"step": 268920, "time": 36176.235325336456, "episode/length": 186.0, "episode/score": 5.29159003603786, "episode/reward_rate": 0.9625668449197861, "episode/intrinsic_return": 0.19158983128659202}
{"step": 268936, "time": 36179.77065896988, "episode/length": 168.0, "episode/score": 5.264764603046615, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.16476445044941102}
{"step": 269232, "time": 36217.296859025955, "episode/length": 134.0, "episode/score": 3.2499732178785052, "episode/reward_rate": 0.9481481481481482, "episode/intrinsic_return": 0.1499731135500042}
{"step": 269296, "time": 36226.653269052505, "episode/length": 244.0, "episode/score": 5.365704078252293, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.2657040079025137}
{"step": 269424, "time": 36243.752529621124, "episode/length": 192.0, "episode/score": 5.309749684916596, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.20974944592467182}
{"step": 269512, "time": 36255.885026454926, "episode/length": 302.0, "episode/score": 6.417098709971015, "episode/reward_rate": 0.9735973597359736, "episode/intrinsic_return": 0.31709848053969836}
{"step": 269920, "time": 36306.79275918007, "episode/length": 183.0, "episode/score": 5.290761322599565, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.19076121883858832}
{"step": 269968, "time": 36314.133110284805, "episode/length": 172.0, "episode/score": 5.289310653410894, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.18931045501881272}
{"step": 270088, "time": 36344.48023533821, "eval_episode/length": 36.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.972972972972973}
{"step": 270088, "time": 36351.4649617672, "eval_episode/length": 166.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9760479041916168}
{"step": 270088, "time": 36353.26777839661, "eval_episode/length": 175.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9943181818181818}
{"step": 270088, "time": 36354.9014146328, "eval_episode/length": 178.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9720670391061452}
{"step": 270088, "time": 36356.61927366257, "eval_episode/length": 183.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9728260869565217}
{"step": 270088, "time": 36358.25122857094, "eval_episode/length": 186.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9732620320855615}
{"step": 270088, "time": 36361.675461769104, "eval_episode/length": 226.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9779735682819384}
{"step": 270088, "time": 36366.07740688324, "eval_episode/length": 237.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9789915966386554}
{"step": 270089, "time": 36367.17069005966, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.3551742311507935, "train/action_min": 0.0, "train/action_std": 3.382655007498605, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.05249159124793199, "train/actor_opt_grad_steps": 66190.0, "train/actor_opt_loss": -8.575480123262398, "train/adv_mag": 0.6376647222294378, "train/adv_max": 0.6143090911012478, "train/adv_mean": 0.0029455814642773397, "train/adv_min": -0.47791504828387465, "train/adv_std": 0.0670867601912173, "train/cont_avg": 0.9941561259920635, "train/cont_loss_mean": 0.00012891251232789483, "train/cont_loss_std": 0.003652447911731819, "train/cont_neg_acc": 0.9960317463471146, "train/cont_neg_loss": 0.010908635359115463, "train/cont_pos_acc": 0.9999895918936956, "train/cont_pos_loss": 7.418071336127963e-05, "train/cont_pred": 0.9941594840357544, "train/cont_rate": 0.9941561259920635, "train/dyn_loss_mean": 6.5609791720355, "train/dyn_loss_std": 8.764244225920823, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0513416658002863, "train/extr_critic_critic_opt_grad_steps": 66190.0, "train/extr_critic_critic_opt_loss": 15761.105086392196, "train/extr_critic_mag": 6.132817354151811, "train/extr_critic_max": 6.132817354151811, "train/extr_critic_mean": 1.0961550297560516, "train/extr_critic_min": -0.6037220532301242, "train/extr_critic_std": 1.3470673775546764, "train/extr_return_normed_mag": 1.7745405353566326, "train/extr_return_normed_max": 1.7745405353566326, "train/extr_return_normed_mean": 0.31741118762228226, "train/extr_return_normed_min": -0.17127391092834018, "train/extr_return_normed_std": 0.3373696473698137, "train/extr_return_rate": 0.49847472912420043, "train/extr_return_raw_mag": 7.076921180442527, "train/extr_return_raw_max": 7.076921180442527, "train/extr_return_raw_mean": 1.108221601872217, "train/extr_return_raw_min": -0.8936445069691491, "train/extr_return_raw_std": 1.3820932097535916, "train/extr_reward_mag": 1.0196354376575933, "train/extr_reward_max": 1.0196354376575933, "train/extr_reward_mean": 0.02930878468902496, "train/extr_reward_min": -0.6584042897300114, "train/extr_reward_std": 0.16815700303152126, "train/image_loss_mean": 3.7933424339092596, "train/image_loss_std": 8.361532445937868, "train/model_loss_mean": 7.8054308033494095, "train/model_loss_std": 12.378652880431483, "train/model_opt_grad_norm": 42.882112059012925, "train/model_opt_grad_steps": 66128.87830687831, "train/model_opt_loss": 11595.523781105325, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1481.4814814814815, "train/policy_entropy_mag": 2.498254724280544, "train/policy_entropy_max": 2.498254724280544, "train/policy_entropy_mean": 0.5372617966914303, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.606043056836204, "train/policy_logprob_mag": 7.438383897145589, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5365162912815337, "train/policy_logprob_min": -7.438383897145589, "train/policy_logprob_std": 1.0983045589986933, "train/policy_randomness_mag": 0.8817742835907709, "train/policy_randomness_max": 0.8817742835907709, "train/policy_randomness_mean": 0.18962983645143963, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.2139066040673584, "train/post_ent_mag": 59.563676844198234, "train/post_ent_max": 59.563676844198234, "train/post_ent_mean": 41.50969772742539, "train/post_ent_min": 18.436575788669487, "train/post_ent_std": 6.9126170148294435, "train/prior_ent_mag": 73.9596190679641, "train/prior_ent_max": 73.9596190679641, "train/prior_ent_mean": 48.04761057051401, "train/prior_ent_min": 28.518257605335698, "train/prior_ent_std": 7.413044389593538, "train/rep_loss_mean": 6.5609791720355, "train/rep_loss_std": 8.764244225920823, "train/reward_avg": 0.01987038323626159, "train/reward_loss_mean": 0.07537198297324635, "train/reward_loss_std": 0.18137896490633174, "train/reward_max_data": 1.0081283371284526, "train/reward_max_pred": 1.006767679143835, "train/reward_neg_acc": 0.9989163194383893, "train/reward_neg_loss": 0.05312760621703491, "train/reward_pos_acc": 0.8816215143632636, "train/reward_pos_loss": 0.7535805058857751, "train/reward_pred": 0.019625958713096758, "train/reward_rate": 0.0318338707010582, "train_stats/sum_log_reward": 4.82727265087041, "train_stats/max_log_achievement_collect_drink": 5.318181818181818, "train_stats/max_log_achievement_collect_sapling": 2.1363636363636362, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 4.704545454545454, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.20454545454545456, "train_stats/max_log_achievement_eat_cow": 0.022727272727272728, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.2727272727272727, "train_stats/max_log_achievement_place_plant": 1.75, "train_stats/max_log_achievement_place_table": 1.6818181818181819, "train_stats/max_log_achievement_wake_up": 2.1818181818181817, "train_stats/mean_log_entropy": 0.4521126388148828, "eval_stats/sum_log_reward": 4.849999979138374, "eval_stats/max_log_achievement_collect_drink": 4.5, "eval_stats/max_log_achievement_collect_sapling": 2.25, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 5.375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.375, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.125, "eval_stats/max_log_achievement_place_plant": 2.0, "eval_stats/max_log_achievement_place_table": 2.375, "eval_stats/max_log_achievement_wake_up": 2.375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 2.6930654712487012e-05, "report/cont_loss_std": 0.0005924614379182458, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 1.9196064386051148e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.6968606107402593e-05, "report/cont_pred": 0.995090663433075, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 6.45191764831543, "report/dyn_loss_std": 8.925700187683105, "report/image_loss_mean": 3.3569746017456055, "report/image_loss_std": 8.451780319213867, "report/model_loss_mean": 7.292142868041992, "report/model_loss_std": 12.80263900756836, "report/post_ent_mag": 55.687904357910156, "report/post_ent_max": 55.687904357910156, "report/post_ent_mean": 41.074066162109375, "report/post_ent_min": 17.906442642211914, "report/post_ent_std": 6.3453545570373535, "report/prior_ent_mag": 73.92753601074219, "report/prior_ent_max": 73.92753601074219, "report/prior_ent_mean": 47.567344665527344, "report/prior_ent_min": 31.131410598754883, "report/prior_ent_std": 6.8779425621032715, "report/rep_loss_mean": 6.45191764831543, "report/rep_loss_std": 8.925700187683105, "report/reward_avg": 0.012558545917272568, "report/reward_loss_mean": 0.06399084627628326, "report/reward_loss_std": 0.1256348341703415, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0035841464996338, "report/reward_neg_acc": 0.999000072479248, "report/reward_neg_loss": 0.049368053674697876, "report/reward_pos_acc": 0.75, "report/reward_pos_loss": 0.6732743978500366, "report/reward_pred": 0.013215259648859501, "report/reward_rate": 0.0234375, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 1.0593421393423341e-05, "eval/cont_loss_std": 0.00013334750838112086, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00037384190363809466, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 8.811044608592056e-06, "eval/cont_pred": 0.995110273361206, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 18.298595428466797, "eval/dyn_loss_std": 12.19716739654541, "eval/image_loss_mean": 16.063383102416992, "eval/image_loss_std": 18.652023315429688, "eval/model_loss_mean": 27.158912658691406, "eval/model_loss_std": 23.80836296081543, "eval/post_ent_mag": 59.831947326660156, "eval/post_ent_max": 59.831947326660156, "eval/post_ent_mean": 40.69150161743164, "eval/post_ent_min": 21.154319763183594, "eval/post_ent_std": 7.290855407714844, "eval/prior_ent_mag": 73.92753601074219, "eval/prior_ent_max": 73.92753601074219, "eval/prior_ent_mean": 52.32740020751953, "eval/prior_ent_min": 30.080217361450195, "eval/prior_ent_std": 8.490214347839355, "eval/rep_loss_mean": 18.298595428466797, "eval/rep_loss_std": 12.19716739654541, "eval/reward_avg": 0.01972656324505806, "eval/reward_loss_mean": 0.11636105924844742, "eval/reward_loss_std": 0.6482681632041931, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0030083656311035, "eval/reward_neg_acc": 0.9939819574356079, "eval/reward_neg_loss": 0.0678965300321579, "eval/reward_pos_acc": 0.8518518805503845, "eval/reward_pos_loss": 1.9059585332870483, "eval/reward_pred": 0.018953371793031693, "eval/reward_rate": 0.0263671875, "replay/size": 269585.0, "replay/inserts": 7536.0, "replay/samples": 30144.0, "replay/insert_wait_avg": 1.6314398710894736e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.533312096970349e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 54304.0, "eval_replay/inserts": 2200.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2288310311057351e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.08970832824707e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1020.148859500885, "timer/env.step_count": 942.0, "timer/env.step_total": 91.3259768486023, "timer/env.step_frac": 0.089522206487869, "timer/env.step_avg": 0.09694902000913194, "timer/env.step_min": 0.02314615249633789, "timer/env.step_max": 2.1799964904785156, "timer/replay._sample_count": 30144.0, "timer/replay._sample_total": 14.889494180679321, "timer/replay._sample_frac": 0.0145954132497527, "timer/replay._sample_avg": 0.0004939455341255082, "timer/replay._sample_min": 0.0003669261932373047, "timer/replay._sample_max": 0.026352405548095703, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1217.0, "timer/agent.policy_total": 19.69632077217102, "timer/agent.policy_frac": 0.019307300683360645, "timer/agent.policy_avg": 0.01618432273802056, "timer/agent.policy_min": 0.009786128997802734, "timer/agent.policy_max": 0.037094831466674805, "timer/dataset_train_count": 1884.0, "timer/dataset_train_total": 0.30559206008911133, "timer/dataset_train_frac": 0.00029955634145258407, "timer/dataset_train_avg": 0.00016220385355048372, "timer/dataset_train_min": 9.942054748535156e-05, "timer/dataset_train_max": 0.0006232261657714844, "timer/agent.train_count": 1884.0, "timer/agent.train_total": 844.7271275520325, "timer/agent.train_frac": 0.8280430053760205, "timer/agent.train_avg": 0.448368963668807, "timer/agent.train_min": 0.43378710746765137, "timer/agent.train_max": 0.6031622886657715, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4798252582550049, "timer/agent.report_frac": 0.00047034827690711995, "timer/agent.report_avg": 0.23991262912750244, "timer/agent.report_min": 0.23254895210266113, "timer/agent.report_max": 0.24727630615234375, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.409385681152344e-05, "timer/dataset_eval_frac": 3.342047240851114e-08, "timer/dataset_eval_avg": 3.409385681152344e-05, "timer/dataset_eval_min": 3.409385681152344e-05, "timer/dataset_eval_max": 3.409385681152344e-05, "fps": 7.387046576362925}
{"step": 270216, "time": 36382.4369995594, "episode/length": 159.0, "episode/score": 4.281388976226253, "episode/reward_rate": 0.95625, "episode/intrinsic_return": 0.1813888604162912}
{"step": 270440, "time": 36412.37453222275, "episode/length": 189.0, "episode/score": 6.302379973740699, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.20237973685880206}
{"step": 270632, "time": 36437.20796203613, "episode/length": 166.0, "episode/score": 6.278383903420263, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.17838367911122077}
{"step": 270640, "time": 36439.63444900513, "episode/length": 175.0, "episode/score": 6.286750698126298, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.18675045460872752}
{"step": 270688, "time": 36447.002868652344, "episode/length": 89.0, "episode/score": 4.198093447477049, "episode/reward_rate": 0.9888888888888889, "episode/intrinsic_return": 0.09809333294765565}
{"step": 271008, "time": 36487.49723315239, "episode/length": 39.0, "episode/score": 2.1472322642221116, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.04723214189289138}
{"step": 271072, "time": 36496.84465551376, "episode/length": 143.0, "episode/score": 5.248318718395012, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.1483185101512845}
{"step": 271224, "time": 36517.06779265404, "episode/length": 213.0, "episode/score": 5.32140265940734, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.2214025702564868}
{"step": 271368, "time": 36536.12138056755, "episode/length": 143.0, "episode/score": 4.27190888588143, "episode/reward_rate": 0.9583333333333334, "episode/intrinsic_return": 0.17190875400615369}
{"step": 271688, "time": 36576.61167573929, "episode/length": 155.0, "episode/score": 5.270334291582685, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.17033414014963455}
{"step": 272080, "time": 36626.15128135681, "episode/length": 331.0, "episode/score": 5.486079282040237, "episode/reward_rate": 0.9909638554216867, "episode/intrinsic_return": 0.38607910045561766}
{"step": 272448, "time": 36672.57189369202, "episode/length": 179.0, "episode/score": 5.303492760039717, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.2034926006904243}
{"step": 272576, "time": 36689.59875655174, "episode/length": 187.0, "episode/score": 5.296238881315503, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.196238676564235}
{"step": 272576, "time": 36689.607013463974, "episode/length": 242.0, "episode/score": 5.358755423345201, "episode/reward_rate": 0.9835390946502057, "episode/intrinsic_return": 0.2587552893744487}
{"step": 272616, "time": 36697.63089418411, "episode/length": 246.0, "episode/score": 6.367236610376267, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.2672364748339078}
{"step": 272776, "time": 36718.86780714989, "episode/length": 193.0, "episode/score": 6.295271131566778, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.19527092134399027}
{"step": 272856, "time": 36730.144938230515, "episode/length": 145.0, "episode/score": 5.2370845267021195, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.13708434035174832}
{"step": 273200, "time": 36773.4458565712, "episode/length": 228.0, "episode/score": 7.349872984344756, "episode/reward_rate": 0.9781659388646288, "episode/intrinsic_return": 0.2498727630625126}
{"step": 273976, "time": 36869.53985095024, "episode/length": 174.0, "episode/score": 5.276350759324259, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.1763506078912087}
{"step": 274048, "time": 36879.68109536171, "episode/length": 158.0, "episode/score": 6.236253803665022, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.13625363220853615}
{"step": 274400, "time": 36924.23010754585, "episode/length": 227.0, "episode/score": 6.349821171493659, "episode/reward_rate": 0.9692982456140351, "episode/intrinsic_return": 0.2498209980581123}
{"step": 274464, "time": 36933.67300796509, "episode/length": 251.0, "episode/score": 5.349946081725648, "episode/reward_rate": 0.9801587301587301, "episode/intrinsic_return": 0.24994586998946033}
{"step": 274656, "time": 36958.34285116196, "episode/length": 181.0, "episode/score": 5.279122526774927, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.17912231439845527}
{"step": 275112, "time": 37015.41896772385, "episode/length": 132.0, "episode/score": 2.2496447120233825, "episode/reward_rate": 0.9624060150375939, "episode/intrinsic_return": 0.14964464883314577}
{"step": 275208, "time": 37028.599477767944, "episode/length": 293.0, "episode/score": 5.437672045880163, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.3376719018976928}
{"step": 275480, "time": 37063.069462537766, "episode/length": 187.0, "episode/score": 5.286881835666918, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.1868815753709896}
{"step": 275552, "time": 37073.350866794586, "episode/length": 433.0, "episode/score": 3.537114463595344, "episode/reward_rate": 0.6612903225806451, "episode/intrinsic_return": 0.43711437293109157}
{"step": 275584, "time": 37078.82671666145, "episode/length": 139.0, "episode/score": 5.240641641663387, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.14064140559639782}
{"step": 275832, "time": 37110.463297605515, "episode/length": 401.0, "episode/score": 6.519374538575903, "episode/reward_rate": 0.8009950248756219, "episode/intrinsic_return": 0.41937433114708256}
{"step": 275872, "time": 37117.130883932114, "episode/length": 183.0, "episode/score": 4.27728319746484, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.1772831475386738}
{"step": 276064, "time": 37141.846103191376, "episode/length": 175.0, "episode/score": 5.2804493036449, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.18044915221184965}
{"step": 276512, "time": 37197.62568569183, "episode/length": 174.0, "episode/score": 6.271558167136391, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.17155808547977358}
{"step": 276576, "time": 37207.07175374031, "episode/length": 170.0, "episode/score": 3.2410281191278045, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.14102804359754373}
{"step": 276592, "time": 37210.48670506477, "episode/length": 129.0, "episode/score": 5.239854834129801, "episode/reward_rate": 0.9923076923076923, "episode/intrinsic_return": 0.13985467245220207}
{"step": 277016, "time": 37263.52346992493, "episode/length": 147.0, "episode/score": 4.256198961818882, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.15619878221332328}
{"step": 277224, "time": 37290.3501060009, "episode/length": 204.0, "episode/score": 4.316606202315597, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.21660611054539913}
{"step": 277384, "time": 37311.207639455795, "episode/length": 188.0, "episode/score": 5.297316325733846, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.1973160908310092}
{"step": 277440, "time": 37319.617587804794, "episode/length": 244.0, "episode/score": 7.37499060745904, "episode/reward_rate": 0.9755102040816327, "episode/intrinsic_return": 0.27499038873793324}
{"step": 277808, "time": 37365.87122583389, "episode/length": 153.0, "episode/score": 5.25880885794686, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.15880861955156433}
{"step": 277809, "time": 37368.42694067955, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.474048673797766, "train/action_min": 0.0, "train/action_std": 3.498507492282848, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.05201786513310022, "train/actor_opt_grad_steps": 68100.0, "train/actor_opt_loss": -9.928092703035034, "train/adv_mag": 0.6019189081352609, "train/adv_max": 0.5812365948536236, "train/adv_mean": 0.0029543568333429936, "train/adv_min": -0.4690602872655799, "train/adv_std": 0.06608958135074285, "train/cont_avg": 0.9942418231865285, "train/cont_loss_mean": 0.00014159963604436085, "train/cont_loss_std": 0.004306886760975661, "train/cont_neg_acc": 0.9985196158058285, "train/cont_neg_loss": 0.0051169144144838224, "train/cont_pos_acc": 0.9999745299779071, "train/cont_pos_loss": 0.00010862254666220435, "train/cont_pred": 0.9942202651438935, "train/cont_rate": 0.9942418231865285, "train/dyn_loss_mean": 6.579235020079143, "train/dyn_loss_std": 8.772102872324732, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0799670648698363, "train/extr_critic_critic_opt_grad_steps": 68100.0, "train/extr_critic_critic_opt_loss": 15858.201632326749, "train/extr_critic_mag": 6.104595967525028, "train/extr_critic_max": 6.104595967525028, "train/extr_critic_mean": 1.0802809802979385, "train/extr_critic_min": -0.6226928382339872, "train/extr_critic_std": 1.3595436876301938, "train/extr_return_normed_mag": 1.7341634158643415, "train/extr_return_normed_max": 1.7341634158643415, "train/extr_return_normed_mean": 0.3131874955688734, "train/extr_return_normed_min": -0.18600809477617086, "train/extr_return_normed_std": 0.33805450086766575, "train/extr_return_rate": 0.48609438198835736, "train/extr_return_raw_mag": 6.951528064945201, "train/extr_return_raw_max": 6.951528064945201, "train/extr_return_raw_mean": 1.0924703664112585, "train/extr_return_raw_min": -0.9658309613484792, "train/extr_return_raw_std": 1.3941844318814847, "train/extr_reward_mag": 1.0163032650329906, "train/extr_reward_max": 1.0163032650329906, "train/extr_reward_mean": 0.029353078276189187, "train/extr_reward_min": -0.6639523147919018, "train/extr_reward_std": 0.16837918368491483, "train/image_loss_mean": 3.7614459250257424, "train/image_loss_std": 8.521539334806135, "train/model_loss_mean": 7.784911061815647, "train/model_loss_std": 12.544129218462217, "train/model_opt_grad_norm": 43.38486110114063, "train/model_opt_grad_steps": 68037.0932642487, "train/model_opt_loss": 9786.894273194624, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1256.4766839378237, "train/policy_entropy_mag": 2.4906891182914297, "train/policy_entropy_max": 2.4906891182914297, "train/policy_entropy_mean": 0.5490265934887327, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6137992477169927, "train/policy_logprob_mag": 7.438383910322436, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.547997103608334, "train/policy_logprob_min": -7.438383910322436, "train/policy_logprob_std": 1.1036965670980938, "train/policy_randomness_mag": 0.8791039592243847, "train/policy_randomness_max": 0.8791039592243847, "train/policy_randomness_mean": 0.19378229388918902, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.21664419916936153, "train/post_ent_mag": 59.55339775678407, "train/post_ent_max": 59.55339775678407, "train/post_ent_mean": 41.82793171541678, "train/post_ent_min": 18.872790529320277, "train/post_ent_std": 6.941649478951884, "train/prior_ent_mag": 73.98029833383511, "train/prior_ent_max": 73.98029833383511, "train/prior_ent_mean": 48.38727925354953, "train/prior_ent_min": 28.85456481498758, "train/prior_ent_std": 7.292182811183633, "train/rep_loss_mean": 6.579235020079143, "train/rep_loss_std": 8.772102872324732, "train/reward_avg": 0.020020752336945714, "train/reward_loss_mean": 0.07578260490159297, "train/reward_loss_std": 0.18257167228917384, "train/reward_max_data": 1.0079857815114945, "train/reward_max_pred": 1.0080112626515523, "train/reward_neg_acc": 0.9988238956644128, "train/reward_neg_loss": 0.05306822829759183, "train/reward_pos_acc": 0.875264738507839, "train/reward_pos_loss": 0.7604843226739162, "train/reward_pred": 0.019773197145601783, "train/reward_rate": 0.03217090349740933, "train_stats/sum_log_reward": 5.023076827709492, "train_stats/max_log_achievement_collect_drink": 4.923076923076923, "train_stats/max_log_achievement_collect_sapling": 2.5128205128205128, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 4.794871794871795, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.15384615384615385, "train_stats/max_log_achievement_eat_cow": 0.05128205128205128, "train_stats/max_log_achievement_make_wood_pickaxe": 0.05128205128205128, "train_stats/max_log_achievement_make_wood_sword": 0.10256410256410256, "train_stats/max_log_achievement_place_plant": 2.358974358974359, "train_stats/max_log_achievement_place_table": 1.7692307692307692, "train_stats/max_log_achievement_wake_up": 2.282051282051282, "train_stats/mean_log_entropy": 0.5436990154095185, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 1.2919540495204274e-06, "report/cont_loss_std": 7.308553904294968e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 8.79499566508457e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 8.667429369779711e-07, "report/cont_pred": 0.9951168298721313, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 6.440267562866211, "report/dyn_loss_std": 8.524100303649902, "report/image_loss_mean": 3.567718505859375, "report/image_loss_std": 7.3697428703308105, "report/model_loss_mean": 7.517486572265625, "report/model_loss_std": 11.634885787963867, "report/post_ent_mag": 60.511566162109375, "report/post_ent_max": 60.511566162109375, "report/post_ent_mean": 41.78522491455078, "report/post_ent_min": 20.06719970703125, "report/post_ent_std": 6.985907077789307, "report/prior_ent_mag": 73.77989959716797, "report/prior_ent_max": 73.77989959716797, "report/prior_ent_mean": 48.425018310546875, "report/prior_ent_min": 28.227577209472656, "report/prior_ent_std": 7.106396198272705, "report/rep_loss_mean": 6.440267562866211, "report/rep_loss_std": 8.524100303649902, "report/reward_avg": 0.02186189591884613, "report/reward_loss_mean": 0.08560635149478912, "report/reward_loss_std": 0.2597687840461731, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.002244234085083, "report/reward_neg_acc": 0.997965395450592, "report/reward_neg_loss": 0.0551423542201519, "report/reward_pos_acc": 0.7317072749137878, "report/reward_pos_loss": 0.8159992694854736, "report/reward_pred": 0.021511957049369812, "report/reward_rate": 0.0400390625, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 4.8013120249379426e-05, "eval/cont_loss_std": 0.0013221744447946548, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0011019123485311866, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 4.284187889425084e-05, "eval/cont_pred": 0.9950808882713318, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 21.995098114013672, "eval/dyn_loss_std": 12.488517761230469, "eval/image_loss_mean": 29.54231071472168, "eval/image_loss_std": 32.309696197509766, "eval/model_loss_mean": 42.82771682739258, "eval/model_loss_std": 36.354820251464844, "eval/post_ent_mag": 56.29053497314453, "eval/post_ent_max": 56.29053497314453, "eval/post_ent_mean": 39.62444305419922, "eval/post_ent_min": 19.82935333251953, "eval/post_ent_std": 6.692887306213379, "eval/prior_ent_mag": 73.77989959716797, "eval/prior_ent_max": 73.77989959716797, "eval/prior_ent_mean": 53.169532775878906, "eval/prior_ent_min": 34.78459167480469, "eval/prior_ent_std": 6.001729488372803, "eval/rep_loss_mean": 21.995098114013672, "eval/rep_loss_std": 12.488517761230469, "eval/reward_avg": 0.01953125, "eval/reward_loss_mean": 0.08830136060714722, "eval/reward_loss_std": 0.6514374613761902, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0010712146759033, "eval/reward_neg_acc": 0.9950000643730164, "eval/reward_neg_loss": 0.029314497485756874, "eval/reward_pos_acc": 0.7083333730697632, "eval/reward_pos_loss": 2.5460872650146484, "eval/reward_pred": 0.013758496381342411, "eval/reward_rate": 0.0234375, "replay/size": 277305.0, "replay/inserts": 7720.0, "replay/samples": 30880.0, "replay/insert_wait_avg": 1.6300171768109416e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.600209873575003e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 54304.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 7.152557373046875e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1001.2410888671875, "timer/env.step_count": 965.0, "timer/env.step_total": 85.29680633544922, "timer/env.step_frac": 0.08519107663864928, "timer/env.step_avg": 0.08839047288647588, "timer/env.step_min": 0.022960186004638672, "timer/env.step_max": 3.196143388748169, "timer/replay._sample_count": 30880.0, "timer/replay._sample_total": 15.16763162612915, "timer/replay._sample_frac": 0.015148830581143984, "timer/replay._sample_avg": 0.0004911797806388974, "timer/replay._sample_min": 0.0003552436828613281, "timer/replay._sample_max": 0.01094198226928711, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 965.0, "timer/agent.policy_total": 15.565669536590576, "timer/agent.policy_frac": 0.015546375103524471, "timer/agent.policy_avg": 0.01613022749905759, "timer/agent.policy_min": 0.014628171920776367, "timer/agent.policy_max": 0.053762197494506836, "timer/dataset_train_count": 1930.0, "timer/dataset_train_total": 0.3978002071380615, "timer/dataset_train_frac": 0.0003973071137023911, "timer/dataset_train_avg": 0.00020611409696272618, "timer/dataset_train_min": 9.703636169433594e-05, "timer/dataset_train_max": 0.04430747032165527, "timer/agent.train_count": 1930.0, "timer/agent.train_total": 866.4048457145691, "timer/agent.train_frac": 0.8653308931766142, "timer/agent.train_avg": 0.44891442783138297, "timer/agent.train_min": 0.43828582763671875, "timer/agent.train_max": 0.9206225872039795, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4762279987335205, "timer/agent.report_frac": 0.0004756376900915331, "timer/agent.report_avg": 0.23811399936676025, "timer/agent.report_min": 0.23141908645629883, "timer/agent.report_max": 0.24480891227722168, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.218650817871094e-05, "timer/dataset_eval_frac": 3.2146611377212877e-08, "timer/dataset_eval_avg": 3.218650817871094e-05, "timer/dataset_eval_min": 3.218650817871094e-05, "timer/dataset_eval_max": 3.218650817871094e-05, "fps": 7.7103020988816455}
{"step": 278000, "time": 37391.48141360283, "episode/length": 175.0, "episode/score": 4.279390665851679, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.179390500565205}
{"step": 278312, "time": 37431.00685119629, "episode/length": 161.0, "episode/score": 5.259071210439288, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.15907106249869685}
{"step": 278496, "time": 37455.170288562775, "episode/length": 22.0, "episode/score": 2.127083430881612, "episode/reward_rate": 0.9565217391304348, "episode/intrinsic_return": 0.02708333288319409}
{"step": 278632, "time": 37475.14460802078, "episode/length": 175.0, "episode/score": 7.291093729061686, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.19109355502951075}
{"step": 278888, "time": 37507.73171019554, "episode/length": 187.0, "episode/score": 7.3140478417044505, "episode/reward_rate": 0.9680851063829787, "episode/intrinsic_return": 0.21404761529993266}
{"step": 278896, "time": 37510.26232004166, "episode/length": 135.0, "episode/score": 4.234558200496394, "episode/reward_rate": 0.9926470588235294, "episode/intrinsic_return": 0.134557993067574}
{"step": 278992, "time": 37523.92919135094, "episode/length": 193.0, "episode/score": 7.307321768390466, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.20732149541981926}
{"step": 279184, "time": 37548.78161430359, "episode/length": 333.0, "episode/score": 6.450975888778885, "episode/reward_rate": 0.9970059880239521, "episode/intrinsic_return": 0.350975661675875}
{"step": 279200, "time": 37552.23725271225, "episode/length": 38.0, "episode/score": -0.866169373581215, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.03383062958528171}
{"step": 279824, "time": 37629.32205724716, "episode/length": 227.0, "episode/score": 4.3619836285924976, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.26198350463346287}
{"step": 279880, "time": 37637.700050115585, "episode/length": 172.0, "episode/score": 6.279592612614579, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.17959260966927104}
{"step": 279920, "time": 37644.103335380554, "episode/length": 481.0, "episode/score": 8.60881152478396, "episode/reward_rate": 0.9979253112033195, "episode/intrinsic_return": 0.5088112358644139}
{"step": 279928, "time": 37646.578298568726, "episode/length": 161.0, "episode/score": 5.266456583717627, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.16645637780220568}
{"step": 280072, "time": 37685.35237288475, "eval_episode/length": 158.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9685534591194969}
{"step": 280072, "time": 37687.06413269043, "eval_episode/length": 164.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9818181818181818}
{"step": 280072, "time": 37688.635390520096, "eval_episode/length": 166.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9760479041916168}
{"step": 280072, "time": 37690.42759203911, "eval_episode/length": 173.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9770114942528736}
{"step": 280072, "time": 37692.281913518906, "eval_episode/length": 183.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9945652173913043}
{"step": 280072, "time": 37694.480494976044, "eval_episode/length": 199.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.975}
{"step": 280072, "time": 37699.961450338364, "eval_episode/length": 273.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9781021897810219}
{"step": 280072, "time": 37703.155559301376, "eval_episode/length": 298.0, "eval_episode/score": 6.100000016391277, "eval_episode/reward_rate": 0.9933110367892977}
{"step": 280336, "time": 37735.37672019005, "episode/length": 50.0, "episode/score": 4.1603227131518, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.060322579413877975}
{"step": 280440, "time": 37749.584183216095, "episode/length": 180.0, "episode/score": 3.255841240224072, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.15584112883789203}
{"step": 280504, "time": 37758.862313747406, "episode/length": 200.0, "episode/score": 5.328369097450377, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.22836895183809247}
{"step": 280672, "time": 37780.953909635544, "episode/length": 183.0, "episode/score": 3.2600925052774983, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.16009240995663276}
{"step": 280688, "time": 37784.36409211159, "episode/length": 187.0, "episode/score": 5.286108673941271, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.18610855120459746}
{"step": 281088, "time": 37834.71107673645, "episode/length": 145.0, "episode/score": 5.2446537664191055, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.14465355817537784}
{"step": 281280, "time": 37859.64763760567, "episode/length": 174.0, "episode/score": 6.273023272780847, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.17302303589895018}
{"step": 281376, "time": 37872.82908964157, "episode/length": 193.0, "episode/score": 5.318540853045306, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.21854063176306227}
{"step": 281672, "time": 37910.28121423721, "episode/length": 166.0, "episode/score": 6.269340599476891, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.1693404337247557}
{"step": 282024, "time": 37954.680418252945, "episode/length": 189.0, "episode/score": 5.310164703691953, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.21016459387737996}
{"step": 282296, "time": 37989.29061102867, "episode/length": 150.0, "episode/score": 5.256928016872735, "episode/reward_rate": 0.9602649006622517, "episode/intrinsic_return": 0.1569278086290069}
{"step": 282792, "time": 38051.32740044594, "episode/length": 188.0, "episode/score": 5.309118848827893, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.2091186139250567}
{"step": 282856, "time": 38060.75563406944, "episode/length": 272.0, "episode/score": 6.367003401356669, "episode/reward_rate": 0.9853479853479854, "episode/intrinsic_return": 0.2670031899697278}
{"step": 283072, "time": 38088.4436378479, "episode/length": 211.0, "episode/score": 4.320505617742583, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.22050544046533105}
{"step": 283192, "time": 38104.59892463684, "episode/length": 189.0, "episode/score": 5.307220405611588, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.2072202881136036}
{"step": 283296, "time": 38118.81346130371, "episode/length": 158.0, "episode/score": 5.270213066442011, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.1702129659406637}
{"step": 283392, "time": 38132.06232905388, "episode/length": 337.0, "episode/score": 6.472711518717915, "episode/reward_rate": 0.9911242603550295, "episode/intrinsic_return": 0.372711308495127}
{"step": 283456, "time": 38141.41871762276, "episode/length": 144.0, "episode/score": 5.266769900551935, "episode/reward_rate": 0.9517241379310345, "episode/intrinsic_return": 0.16676975610380396}
{"step": 283976, "time": 38206.04770708084, "episode/length": 441.0, "episode/score": 6.527359084005639, "episode/reward_rate": 0.997737556561086, "episode/intrinsic_return": 0.42735891516849733}
{"step": 284352, "time": 38253.14911222458, "episode/length": 186.0, "episode/score": 5.307743293004023, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.20774311141940416}
{"step": 284616, "time": 38286.65048098564, "episode/length": 227.0, "episode/score": 3.351724314808962, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.2517241035384359}
{"step": 284680, "time": 38295.82649445534, "episode/length": 185.0, "episode/score": 8.29785569775595, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.19785546040839108}
{"step": 284880, "time": 38322.155633211136, "episode/length": 177.0, "episode/score": 5.297646982200604, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.1976468319317064}
{"step": 284944, "time": 38331.26413440704, "episode/length": 193.0, "episode/score": 4.305941864809938, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.20594165505281126}
{"step": 284992, "time": 38338.68888449669, "episode/length": 38.0, "episode/score": 0.1404265123856021, "episode/reward_rate": 0.8974358974358975, "episode/intrinsic_return": 0.04042652416683268}
{"step": 285152, "time": 38359.68412947655, "episode/length": 146.0, "episode/score": 6.254109640252864, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.15410942001835792}
{"step": 285205, "time": 38368.62270784378, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.494958166173986, "train/action_min": 0.0, "train/action_std": 3.5507159142880824, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.05088385021364367, "train/actor_opt_grad_steps": 69990.0, "train/actor_opt_loss": -12.38960053791871, "train/adv_mag": 0.6238485880800195, "train/adv_max": 0.5946211715002317, "train/adv_mean": 0.0024634949343955077, "train/adv_min": -0.4822900261427905, "train/adv_std": 0.06515427332472157, "train/cont_avg": 0.9944626266891892, "train/cont_loss_mean": 9.271260291925317e-05, "train/cont_loss_std": 0.0027193398279664323, "train/cont_neg_acc": 0.9982432433076807, "train/cont_neg_loss": 0.010017799302216657, "train/cont_pos_acc": 0.9999893314129598, "train/cont_pos_loss": 4.0604957707705274e-05, "train/cont_pred": 0.9944603262720881, "train/cont_rate": 0.9944626266891892, "train/dyn_loss_mean": 6.5310185148909286, "train/dyn_loss_std": 8.7415179974324, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0326656099912284, "train/extr_critic_critic_opt_grad_steps": 69990.0, "train/extr_critic_critic_opt_loss": 15773.834802576013, "train/extr_critic_mag": 6.220823267343882, "train/extr_critic_max": 6.220823267343882, "train/extr_critic_mean": 1.074242504222973, "train/extr_critic_min": -0.6212370679185197, "train/extr_critic_std": 1.3718004207353334, "train/extr_return_normed_mag": 1.7405752658843994, "train/extr_return_normed_max": 1.7405752658843994, "train/extr_return_normed_mean": 0.30728078420097765, "train/extr_return_normed_min": -0.166810444480664, "train/extr_return_normed_std": 0.33546409091433965, "train/extr_return_rate": 0.4833340633559871, "train/extr_return_raw_mag": 7.090134803668873, "train/extr_return_raw_max": 7.090134803668873, "train/extr_return_raw_mean": 1.0845530290861387, "train/extr_return_raw_min": -0.9019856021210954, "train/extr_return_raw_std": 1.4057762023564933, "train/extr_reward_mag": 1.019871880557086, "train/extr_reward_max": 1.019871880557086, "train/extr_reward_mean": 0.028949273407861992, "train/extr_reward_min": -0.6572223933967384, "train/extr_reward_std": 0.1669525361544377, "train/image_loss_mean": 3.728796738547248, "train/image_loss_std": 8.663315739502778, "train/model_loss_mean": 7.722268916465141, "train/model_loss_std": 12.651654684221421, "train/model_opt_grad_norm": 42.414863967895506, "train/model_opt_grad_steps": 69925.50810810812, "train/model_opt_loss": 11259.932002217061, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1459.4594594594594, "train/policy_entropy_mag": 2.477861602886303, "train/policy_entropy_max": 2.477861602886303, "train/policy_entropy_mean": 0.5533406873007078, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6280823151807527, "train/policy_logprob_mag": 7.438383937526393, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5538302213759035, "train/policy_logprob_min": -7.438383937526393, "train/policy_logprob_std": 1.1104854812493195, "train/policy_randomness_mag": 0.8745764094430047, "train/policy_randomness_max": 0.8745764094430047, "train/policy_randomness_mean": 0.1953049808740616, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.22168549444224384, "train/post_ent_mag": 59.59079563037769, "train/post_ent_max": 59.59079563037769, "train/post_ent_mean": 42.00443059560415, "train/post_ent_min": 18.772272058435387, "train/post_ent_std": 6.960455933132687, "train/prior_ent_mag": 73.97934339368666, "train/prior_ent_max": 73.97934339368666, "train/prior_ent_mean": 48.51150704461175, "train/prior_ent_min": 29.026689611898885, "train/prior_ent_std": 7.197162656526308, "train/rep_loss_mean": 6.5310185148909286, "train/rep_loss_std": 8.7415179974324, "train/reward_avg": 0.020380156384025877, "train/reward_loss_mean": 0.07476838919762019, "train/reward_loss_std": 0.1746862306788161, "train/reward_max_data": 1.0088175979820457, "train/reward_max_pred": 1.009527908789145, "train/reward_neg_acc": 0.9987221827378144, "train/reward_neg_loss": 0.052341929380152676, "train/reward_pos_acc": 0.886193834446572, "train/reward_pos_loss": 0.7521950692743868, "train/reward_pred": 0.020114057993113593, "train/reward_rate": 0.03212098817567568, "train_stats/sum_log_reward": 4.94615379625406, "train_stats/max_log_achievement_collect_drink": 6.128205128205129, "train_stats/max_log_achievement_collect_sapling": 2.4358974358974357, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 5.461538461538462, "train_stats/max_log_achievement_defeat_skeleton": 0.02564102564102564, "train_stats/max_log_achievement_defeat_zombie": 0.1794871794871795, "train_stats/max_log_achievement_eat_cow": 0.07692307692307693, "train_stats/max_log_achievement_make_wood_pickaxe": 0.07692307692307693, "train_stats/max_log_achievement_make_wood_sword": 0.38461538461538464, "train_stats/max_log_achievement_place_plant": 2.1025641025641026, "train_stats/max_log_achievement_place_table": 1.9230769230769231, "train_stats/max_log_achievement_wake_up": 2.0256410256410255, "train_stats/mean_log_entropy": 0.5406766614088645, "eval_stats/sum_log_reward": 5.599999904632568, "eval_stats/max_log_achievement_collect_drink": 5.25, "eval_stats/max_log_achievement_collect_sapling": 3.375, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 5.0, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.75, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.375, "eval_stats/max_log_achievement_place_plant": 1.75, "eval_stats/max_log_achievement_place_table": 1.625, "eval_stats/max_log_achievement_wake_up": 2.125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 3.6449415574679733e-07, "report/cont_loss_std": 5.543220140680205e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 3.5605422453954816e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.5678730846957478e-07, "report/cont_pred": 0.9941407442092896, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 6.2087507247924805, "report/dyn_loss_std": 8.944028854370117, "report/image_loss_mean": 3.873136043548584, "report/image_loss_std": 9.620209693908691, "report/model_loss_mean": 7.677568435668945, "report/model_loss_std": 13.877603530883789, "report/post_ent_mag": 61.935813903808594, "report/post_ent_max": 61.935813903808594, "report/post_ent_mean": 41.89654541015625, "report/post_ent_min": 17.984880447387695, "report/post_ent_std": 7.284571170806885, "report/prior_ent_mag": 73.57026672363281, "report/prior_ent_max": 73.57026672363281, "report/prior_ent_mean": 48.78939437866211, "report/prior_ent_min": 23.21717071533203, "report/prior_ent_std": 7.3934478759765625, "report/rep_loss_mean": 6.2087507247924805, "report/rep_loss_std": 8.944028854370117, "report/reward_avg": 0.01856723427772522, "report/reward_loss_mean": 0.07918217778205872, "report/reward_loss_std": 0.16800227761268616, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.003007411956787, "report/reward_neg_acc": 0.9979776740074158, "report/reward_neg_loss": 0.05594859644770622, "report/reward_pos_acc": 0.9428571462631226, "report/reward_pos_loss": 0.7356967329978943, "report/reward_pred": 0.018294326961040497, "report/reward_rate": 0.0341796875, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 7.618680797349953e-07, "eval/cont_loss_std": 1.879655428638216e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00011549978808034211, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 8.561310949062317e-08, "eval/cont_pred": 0.9941412210464478, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 19.22661781311035, "eval/dyn_loss_std": 12.141205787658691, "eval/image_loss_mean": 18.10128402709961, "eval/image_loss_std": 20.32014274597168, "eval/model_loss_mean": 29.749534606933594, "eval/model_loss_std": 24.51761817932129, "eval/post_ent_mag": 61.19422912597656, "eval/post_ent_max": 61.19422912597656, "eval/post_ent_mean": 40.46669006347656, "eval/post_ent_min": 21.522233963012695, "eval/post_ent_std": 7.067692279815674, "eval/prior_ent_mag": 73.57026672363281, "eval/prior_ent_max": 73.57026672363281, "eval/prior_ent_mean": 53.585731506347656, "eval/prior_ent_min": 34.7687873840332, "eval/prior_ent_std": 6.895288467407227, "eval/rep_loss_mean": 19.22661781311035, "eval/rep_loss_std": 12.141205787658691, "eval/reward_avg": 0.02460937574505806, "eval/reward_loss_mean": 0.11227739602327347, "eval/reward_loss_std": 0.6523251533508301, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.003584384918213, "eval/reward_neg_acc": 0.9929506778717041, "eval/reward_neg_loss": 0.062043748795986176, "eval/reward_pos_acc": 0.8387096524238586, "eval/reward_pos_loss": 1.721374273300171, "eval/reward_pred": 0.024243026971817017, "eval/reward_rate": 0.0302734375, "replay/size": 284701.0, "replay/inserts": 7396.0, "replay/samples": 29584.0, "replay/insert_wait_avg": 1.608938575113316e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.51473053911043e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 56696.0, "eval_replay/inserts": 2392.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2213968513003958e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.2218952178955078e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1764078140259, "timer/env.step_count": 924.0, "timer/env.step_total": 84.49957346916199, "timer/env.step_frac": 0.08448466971325917, "timer/env.step_avg": 0.0914497548367554, "timer/env.step_min": 0.02275824546813965, "timer/env.step_max": 2.059612512588501, "timer/replay._sample_count": 29584.0, "timer/replay._sample_total": 14.612029314041138, "timer/replay._sample_frac": 0.014609452092533379, "timer/replay._sample_avg": 0.0004939166209451439, "timer/replay._sample_min": 0.0003688335418701172, "timer/replay._sample_max": 0.028531551361083984, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1223.0, "timer/agent.policy_total": 19.857877254486084, "timer/agent.policy_frac": 0.019854374787630948, "timer/agent.policy_avg": 0.01623702146728216, "timer/agent.policy_min": 0.009769201278686523, "timer/agent.policy_max": 0.06226921081542969, "timer/dataset_train_count": 1849.0, "timer/dataset_train_total": 0.29124021530151367, "timer/dataset_train_frac": 0.00029118884731349037, "timer/dataset_train_avg": 0.00015751228518199765, "timer/dataset_train_min": 9.179115295410156e-05, "timer/dataset_train_max": 0.0008194446563720703, "timer/agent.train_count": 1849.0, "timer/agent.train_total": 830.5255169868469, "timer/agent.train_frac": 0.830379031637063, "timer/agent.train_avg": 0.4491755094574618, "timer/agent.train_min": 0.4369988441467285, "timer/agent.train_max": 1.101738452911377, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.502084493637085, "timer/agent.report_frac": 0.0005019959376310776, "timer/agent.report_avg": 0.2510422468185425, "timer/agent.report_min": 0.23548340797424316, "timer/agent.report_max": 0.2666010856628418, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8133392333984375e-05, "timer/dataset_eval_frac": 2.812843025909039e-08, "timer/dataset_eval_avg": 2.8133392333984375e-05, "timer/dataset_eval_min": 2.8133392333984375e-05, "timer/dataset_eval_max": 2.8133392333984375e-05, "fps": 7.3945623572675325}
{"step": 285400, "time": 38392.231848716736, "episode/length": 56.0, "episode/score": 3.1608699771495594, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.06086989861432812}
{"step": 285456, "time": 38400.660595178604, "episode/length": 269.0, "episode/score": 5.410153379401891, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.3101532951986883}
{"step": 285736, "time": 38436.38122200966, "episode/length": 34.0, "episode/score": 1.1418750372249633, "episode/reward_rate": 0.8857142857142857, "episode/intrinsic_return": 0.041874999180436134}
{"step": 285872, "time": 38454.444566488266, "episode/length": 189.0, "episode/score": 5.301896369399401, "episode/reward_rate": 0.9631578947368421, "episode/intrinsic_return": 0.20189623927035427}
{"step": 286144, "time": 38489.27087330818, "episode/length": 33.0, "episode/score": 1.1318817958090222, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.031881702117971145}
{"step": 286176, "time": 38494.67532658577, "episode/length": 147.0, "episode/score": 3.253492155277854, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.15349216880531458}
{"step": 286216, "time": 38501.07076358795, "episode/length": 392.0, "episode/score": 5.53243423073036, "episode/reward_rate": 0.9923664122137404, "episode/intrinsic_return": 0.4324340870971355}
{"step": 286240, "time": 38505.532844781876, "episode/length": 202.0, "episode/score": 5.315377823309973, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.21537761739455163}
{"step": 286360, "time": 38521.512971162796, "episode/length": 184.0, "episode/score": 5.2860489493687055, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.18604882866929984}
{"step": 286464, "time": 38535.40351176262, "episode/length": 39.0, "episode/score": 4.147708466160111, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.047708332422189415}
{"step": 286592, "time": 38552.431903362274, "episode/length": 43.0, "episode/score": 3.149190626310883, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.049190475343493745}
{"step": 286688, "time": 38565.837485075, "episode/length": 191.0, "episode/score": 5.298887513179579, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.19888736174652877}
{"step": 286896, "time": 38593.869086027145, "episode/length": 66.0, "episode/score": 5.1773875749768195, "episode/reward_rate": 0.9402985074626866, "episode/intrinsic_return": 0.07738743634945422}
{"step": 287192, "time": 38631.34858131409, "episode/length": 181.0, "episode/score": 6.29239136455999, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.19239118681707623}
{"step": 287192, "time": 38631.35874271393, "episode/length": 223.0, "episode/score": 5.352961908596626, "episode/reward_rate": 0.9776785714285714, "episode/intrinsic_return": 0.25296172701200703}
{"step": 287528, "time": 38675.70540714264, "episode/length": 163.0, "episode/score": 4.266405056468102, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.16640485602420085}
{"step": 287696, "time": 38697.50537586212, "episode/length": 137.0, "episode/score": 5.23053709591386, "episode/reward_rate": 0.9927536231884058, "episode/intrinsic_return": 0.13053693851452408}
{"step": 287768, "time": 38707.92276954651, "episode/length": 162.0, "episode/score": 5.270598826985406, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.17059867520310945}
{"step": 287840, "time": 38718.18072319031, "episode/length": 38.0, "episode/score": 3.146666777203791, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.04666666581761092}
{"step": 288048, "time": 38745.15719604492, "episode/length": 169.0, "episode/score": 5.2604868686175905, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.1604867016139906}
{"step": 288488, "time": 38800.38248419762, "episode/length": 198.0, "episode/score": 6.300023349345793, "episode/reward_rate": 0.9698492462311558, "episode/intrinsic_return": 0.20002317276703252}
{"step": 288536, "time": 38807.734439611435, "episode/length": 167.0, "episode/score": 4.289406964133377, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.18940683266555425}
{"step": 288600, "time": 38817.13049888611, "episode/length": 175.0, "episode/score": 6.281252758122719, "episode/reward_rate": 0.9659090909090909, "episode/intrinsic_return": 0.1812525251407351}
{"step": 288968, "time": 38863.51812338829, "episode/length": 158.0, "episode/score": 5.249782532463541, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.14978236380102317}
{"step": 288976, "time": 38866.05123806, "episode/length": 349.0, "episode/score": 6.469233792832711, "episode/reward_rate": 0.9885714285714285, "episode/intrinsic_return": 0.36923360600940214}
{"step": 289096, "time": 38882.1756541729, "episode/length": 156.0, "episode/score": 3.2613218239457638, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.16132166832176154}
{"step": 289248, "time": 38902.23364710808, "episode/length": 184.0, "episode/score": 7.304840307558152, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.2048400526318801}
{"step": 289248, "time": 38902.24150919914, "episode/length": 94.0, "episode/score": 6.197626860238415, "episode/reward_rate": 0.9894736842105263, "episode/intrinsic_return": 0.09762663278615946}
{"step": 289544, "time": 38942.69323182106, "episode/length": 186.0, "episode/score": 5.31059581619229, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.21059566679650743}
{"step": 290056, "time": 39022.73140621185, "eval_episode/length": 39.0, "eval_episode/score": 3.0999999791383743, "eval_episode/reward_rate": 0.975}
{"step": 290056, "time": 39028.80089020729, "eval_episode/length": 144.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.993103448275862}
{"step": 290056, "time": 39032.42053604126, "eval_episode/length": 193.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9948453608247423}
{"step": 290056, "time": 39034.81062030792, "eval_episode/length": 211.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9952830188679245}
{"step": 290056, "time": 39036.540009498596, "eval_episode/length": 215.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9768518518518519}
{"step": 290056, "time": 39038.070803403854, "eval_episode/length": 216.0, "eval_episode/score": 6.099999971687794, "eval_episode/reward_rate": 0.9953917050691244}
{"step": 290056, "time": 39040.40390539169, "eval_episode/length": 232.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9785407725321889}
{"step": 290056, "time": 39044.1891002655, "eval_episode/length": 285.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9895104895104895}
{"step": 290192, "time": 39060.78313994408, "episode/length": 152.0, "episode/score": 5.260959262222059, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.16095911078900826}
{"step": 290192, "time": 39060.79132580757, "episode/length": 198.0, "episode/score": 5.288359359033166, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.1883592886833867}
{"step": 290416, "time": 39091.30256485939, "episode/length": 234.0, "episode/score": 6.376745798385855, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.2767456855444834}
{"step": 290584, "time": 39113.10750889778, "episode/length": 200.0, "episode/score": 5.314944398894113, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.2149442302315947}
{"step": 290720, "time": 39131.27577710152, "episode/length": 183.0, "episode/score": 6.298445873675519, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.19844570559507702}
{"step": 290760, "time": 39137.655896902084, "episode/length": 188.0, "episode/score": 5.313768161200187, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.21376797845141482}
{"step": 290992, "time": 39168.394055366516, "episode/length": 180.0, "episode/score": 6.270086011869807, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.17008590141495006}
{"step": 291440, "time": 39224.889110803604, "episode/length": 155.0, "episode/score": 4.262814991765481, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.16281483881903114}
{"step": 291696, "time": 39257.81192827225, "episode/length": 159.0, "episode/score": 7.272770922289055, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.1727706963501987}
{"step": 292024, "time": 39299.358530044556, "episode/length": 162.0, "episode/score": 6.259124488336965, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.15912427776493132}
{"step": 292072, "time": 39306.721705913544, "episode/length": 134.0, "episode/score": 5.256614187488594, "episode/reward_rate": 0.9925925925925926, "episode/intrinsic_return": 0.15661399845339474}
{"step": 292080, "time": 39309.24633979797, "episode/length": 186.0, "episode/score": 5.298614475193972, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.19861448592746456}
{"step": 292120, "time": 39315.64011597633, "episode/length": 169.0, "episode/score": 5.289680640245933, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.18968048764872947}
{"step": 292320, "time": 39341.46768498421, "episode/length": 402.0, "episode/score": 6.537546716800989, "episode/reward_rate": 0.9925558312655087, "episode/intrinsic_return": 0.43754657433191824}
{"step": 292400, "time": 39352.69216990471, "episode/length": 275.0, "episode/score": 7.398535034393717, "episode/reward_rate": 0.9963768115942029, "episode/intrinsic_return": 0.2985347553403699}
{"step": 292513, "time": 39369.093467473984, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.4776014390882555, "train/action_min": 0.0, "train/action_std": 3.4601822986707584, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.05188903535951625, "train/actor_opt_grad_steps": 71825.0, "train/actor_opt_loss": -11.157216322986962, "train/adv_mag": 0.6179073467686936, "train/adv_max": 0.5998933257964941, "train/adv_mean": 0.003075123142240285, "train/adv_min": -0.46552593465689773, "train/adv_std": 0.0661778010141391, "train/cont_avg": 0.9943552541208791, "train/cont_loss_mean": 9.830643982875988e-05, "train/cont_loss_std": 0.0029630272373216606, "train/cont_neg_acc": 0.9979395604395604, "train/cont_neg_loss": 0.007364226956407752, "train/cont_pos_acc": 0.999983773454205, "train/cont_pos_loss": 4.218114169969116e-05, "train/cont_pred": 0.9943516274074932, "train/cont_rate": 0.9943552541208791, "train/dyn_loss_mean": 6.52474090555212, "train/dyn_loss_std": 8.699152590154291, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0426076483595503, "train/extr_critic_critic_opt_grad_steps": 71825.0, "train/extr_critic_critic_opt_loss": 15909.607974544986, "train/extr_critic_mag": 6.1821279001759954, "train/extr_critic_max": 6.1821279001759954, "train/extr_critic_mean": 1.0784596502780914, "train/extr_critic_min": -0.6143550728703593, "train/extr_critic_std": 1.357988994200151, "train/extr_return_normed_mag": 1.764404949906108, "train/extr_return_normed_max": 1.764404949906108, "train/extr_return_normed_mean": 0.3124034549672525, "train/extr_return_normed_min": -0.17748822103981132, "train/extr_return_normed_std": 0.33680183989006085, "train/extr_return_rate": 0.4965505785011983, "train/extr_return_raw_mag": 7.106392124196986, "train/extr_return_raw_max": 7.106392124196986, "train/extr_return_raw_mean": 1.0912103276331346, "train/extr_return_raw_min": -0.938036424445582, "train/extr_return_raw_std": 1.3955319969208686, "train/extr_reward_mag": 1.025170209643605, "train/extr_reward_max": 1.025170209643605, "train/extr_reward_mean": 0.029523245519497893, "train/extr_reward_min": -0.6639292469391456, "train/extr_reward_std": 0.16879899808011212, "train/image_loss_mean": 3.683284358008877, "train/image_loss_std": 8.356700030001965, "train/model_loss_mean": 7.674412952674614, "train/model_loss_std": 12.327936730542026, "train/model_opt_grad_norm": 42.76435448573186, "train/model_opt_grad_steps": 71759.51098901099, "train/model_opt_loss": 14019.136555095296, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1826.923076923077, "train/policy_entropy_mag": 2.500560205061357, "train/policy_entropy_max": 2.500560205061357, "train/policy_entropy_mean": 0.5402308070397639, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6220505057455419, "train/policy_logprob_mag": 7.438383940811995, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5415034130379394, "train/policy_logprob_min": -7.438383940811995, "train/policy_logprob_std": 1.1054848016618373, "train/policy_randomness_mag": 0.8825880194103325, "train/policy_randomness_max": 0.8825880194103325, "train/policy_randomness_mean": 0.19067776784464552, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.21955653189957797, "train/post_ent_mag": 60.03677529555101, "train/post_ent_max": 60.03677529555101, "train/post_ent_mean": 42.250103772341554, "train/post_ent_min": 18.674402540856665, "train/post_ent_std": 7.041785140613933, "train/prior_ent_mag": 74.16079762217763, "train/prior_ent_max": 74.16079762217763, "train/prior_ent_mean": 48.7658208490728, "train/prior_ent_min": 29.649472404312302, "train/prior_ent_std": 7.241787991680941, "train/rep_loss_mean": 6.52474090555212, "train/rep_loss_std": 8.699152590154291, "train/reward_avg": 0.020623480952293664, "train/reward_loss_mean": 0.07618577373060552, "train/reward_loss_std": 0.18222865237148253, "train/reward_max_data": 1.0127884928996747, "train/reward_max_pred": 1.0110880948685028, "train/reward_neg_acc": 0.9987507239802853, "train/reward_neg_loss": 0.053031168632454925, "train/reward_pos_acc": 0.879429558803747, "train/reward_pos_loss": 0.7660137709680495, "train/reward_pred": 0.020308378395614224, "train/reward_rate": 0.032612894917582416, "train_stats/sum_log_reward": 4.963636295361952, "train_stats/max_log_achievement_collect_drink": 5.568181818181818, "train_stats/max_log_achievement_collect_sapling": 2.3863636363636362, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 5.113636363636363, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.25, "train_stats/max_log_achievement_eat_cow": 0.09090909090909091, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.3181818181818182, "train_stats/max_log_achievement_place_plant": 2.1818181818181817, "train_stats/max_log_achievement_place_table": 1.75, "train_stats/max_log_achievement_wake_up": 1.9772727272727273, "train_stats/mean_log_entropy": 0.4370370151644403, "eval_stats/sum_log_reward": 4.974999934434891, "eval_stats/max_log_achievement_collect_drink": 3.0, "eval_stats/max_log_achievement_collect_sapling": 3.25, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 6.875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.25, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.375, "eval_stats/max_log_achievement_place_plant": 3.0, "eval_stats/max_log_achievement_place_table": 2.25, "eval_stats/max_log_achievement_wake_up": 2.0, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 5.4608249229204375e-06, "report/cont_loss_std": 7.787366484990343e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.000405346043407917, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 3.103937615378527e-06, "report/cont_pred": 0.9941399097442627, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 5.741145133972168, "report/dyn_loss_std": 8.569401741027832, "report/image_loss_mean": 3.6900529861450195, "report/image_loss_std": 9.252596855163574, "report/model_loss_mean": 7.210170745849609, "report/model_loss_std": 13.16082763671875, "report/post_ent_mag": 59.92719650268555, "report/post_ent_max": 59.92719650268555, "report/post_ent_mean": 41.62226867675781, "report/post_ent_min": 21.011886596679688, "report/post_ent_std": 6.116575241088867, "report/prior_ent_mag": 73.7835464477539, "report/prior_ent_max": 73.7835464477539, "report/prior_ent_mean": 47.294193267822266, "report/prior_ent_min": 29.114835739135742, "report/prior_ent_std": 6.974080562591553, "report/rep_loss_mean": 5.741145133972168, "report/rep_loss_std": 8.569401741027832, "report/reward_avg": 0.014551965519785881, "report/reward_loss_mean": 0.07542507350444794, "report/reward_loss_std": 0.19873693585395813, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0030124187469482, "report/reward_neg_acc": 1.0000001192092896, "report/reward_neg_loss": 0.05616169422864914, "report/reward_pos_acc": 0.8571429252624512, "report/reward_pos_loss": 0.7606510519981384, "report/reward_pred": 0.014109162613749504, "report/reward_rate": 0.02734375, "eval/cont_avg": 0.9931640625, "eval/cont_loss_mean": 1.734746911097318e-05, "eval/cont_loss_std": 0.00033906189491972327, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00038713772664777935, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 1.480220726080006e-05, "eval/cont_pred": 0.9931520223617554, "eval/cont_rate": 0.9931640625, "eval/dyn_loss_mean": 21.605188369750977, "eval/dyn_loss_std": 12.612154006958008, "eval/image_loss_mean": 26.607685089111328, "eval/image_loss_std": 30.108226776123047, "eval/model_loss_mean": 39.68146514892578, "eval/model_loss_std": 34.54471969604492, "eval/post_ent_mag": 57.47871780395508, "eval/post_ent_max": 57.47871780395508, "eval/post_ent_mean": 40.04710388183594, "eval/post_ent_min": 21.535661697387695, "eval/post_ent_std": 7.111831188201904, "eval/prior_ent_mag": 73.7835464477539, "eval/prior_ent_max": 73.7835464477539, "eval/prior_ent_mean": 54.01418685913086, "eval/prior_ent_min": 34.210601806640625, "eval/prior_ent_std": 6.552212238311768, "eval/rep_loss_mean": 21.605188369750977, "eval/rep_loss_std": 12.612154006958008, "eval/reward_avg": 0.01513671875, "eval/reward_loss_mean": 0.11065241694450378, "eval/reward_loss_std": 0.7101054191589355, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 1.0023488998413086, "eval/reward_neg_acc": 0.9950149655342102, "eval/reward_neg_loss": 0.06672786921262741, "eval/reward_pos_acc": 0.6666666865348816, "eval/reward_pos_loss": 2.2085723876953125, "eval/reward_pred": 0.011847276240587234, "eval/reward_rate": 0.0205078125, "replay/size": 292009.0, "replay/inserts": 7308.0, "replay/samples": 29232.0, "replay/insert_wait_avg": 1.6462235223679316e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.321632945870335e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 58984.0, "eval_replay/inserts": 2288.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2161640020517202e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.046627044677734e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4549536705017, "timer/env.step_count": 914.0, "timer/env.step_total": 92.49989342689514, "timer/env.step_frac": 0.09245782939804388, "timer/env.step_avg": 0.10120338449332072, "timer/env.step_min": 0.023421764373779297, "timer/env.step_max": 4.267034530639648, "timer/replay._sample_count": 29232.0, "timer/replay._sample_total": 14.118629693984985, "timer/replay._sample_frac": 0.014112209292568442, "timer/replay._sample_avg": 0.0004829854164608985, "timer/replay._sample_min": 0.0003714561462402344, "timer/replay._sample_max": 0.010190486907958984, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1200.0, "timer/agent.policy_total": 20.47089457511902, "timer/agent.policy_frac": 0.02046158550169074, "timer/agent.policy_avg": 0.01705907881259918, "timer/agent.policy_min": 0.009377717971801758, "timer/agent.policy_max": 0.12616968154907227, "timer/dataset_train_count": 1827.0, "timer/dataset_train_total": 0.28250575065612793, "timer/dataset_train_frac": 0.0002823772820751815, "timer/dataset_train_avg": 0.00015462821601320632, "timer/dataset_train_min": 8.654594421386719e-05, "timer/dataset_train_max": 0.0006949901580810547, "timer/agent.train_count": 1827.0, "timer/agent.train_total": 823.7165336608887, "timer/agent.train_frac": 0.8233419512181039, "timer/agent.train_avg": 0.4508574349539621, "timer/agent.train_min": 0.43666672706604004, "timer/agent.train_max": 1.0048432350158691, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4784402847290039, "timer/agent.report_frac": 0.0004782227155492475, "timer/agent.report_avg": 0.23922014236450195, "timer/agent.report_min": 0.2311849594116211, "timer/agent.report_max": 0.2472553253173828, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9087066650390625e-05, "timer/dataset_eval_frac": 2.9073839400439816e-08, "timer/dataset_eval_avg": 2.9087066650390625e-05, "timer/dataset_eval_min": 2.9087066650390625e-05, "timer/dataset_eval_max": 2.9087066650390625e-05, "fps": 7.304573436802764}
{"step": 292920, "time": 39418.58934426308, "episode/length": 184.0, "episode/score": 7.314444957683008, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.21444472080111154}
{"step": 293416, "time": 39480.544090270996, "episode/length": 166.0, "episode/score": 5.268489046153263, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.16848889355605934}
{"step": 293656, "time": 39511.465732336044, "episode/length": 166.0, "episode/score": 6.259086164060136, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.15908595616565435}
{"step": 293664, "time": 39513.88829088211, "episode/length": 192.0, "episode/score": 6.282564175682637, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.18256392273542588}
{"step": 293776, "time": 39529.07700943947, "episode/length": 212.0, "episode/score": 5.343170896638185, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.24317063041962683}
{"step": 293896, "time": 39545.355519771576, "episode/length": 233.0, "episode/score": 6.360306142803893, "episode/reward_rate": 0.9786324786324786, "episode/intrinsic_return": 0.2603059627326729}
{"step": 294008, "time": 39560.46812105179, "episode/length": 200.0, "episode/score": 5.3097542919858824, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.20975406930665486}
{"step": 294272, "time": 39594.1394777298, "episode/length": 168.0, "episode/score": 7.270720193895613, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.17071991114607954}
{"step": 294704, "time": 39648.48757004738, "episode/length": 375.0, "episode/score": 8.5030610634185, "episode/reward_rate": 0.9893617021276596, "episode/intrinsic_return": 0.4030608318917075}
{"step": 294840, "time": 39667.139862298965, "episode/length": 147.0, "episode/score": 5.269484697164444, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.16948446889728075}
{"step": 294848, "time": 39669.561143398285, "episode/length": 178.0, "episode/score": 3.2661901670708176, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.1661900415983837}
{"step": 294992, "time": 39689.797095537186, "episode/length": 165.0, "episode/score": 5.270046035531777, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.1700458682662429}
{"step": 295464, "time": 39749.068795681, "episode/length": 210.0, "episode/score": 6.3322463398053515, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.23224610525176104}
{"step": 295592, "time": 39766.584004879, "episode/length": 197.0, "episode/score": 4.316625337463847, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.21662521350481256}
{"step": 295752, "time": 39788.03184247017, "episode/length": 231.0, "episode/score": 7.369756076757767, "episode/reward_rate": 0.9741379310344828, "episode/intrinsic_return": 0.26975584138926934}
{"step": 296224, "time": 39847.35964798927, "episode/length": 243.0, "episode/score": 4.388573702824942, "episode/reward_rate": 0.9754098360655737, "episode/intrinsic_return": 0.28857358585082693}
{"step": 296344, "time": 39863.55205440521, "episode/length": 187.0, "episode/score": 6.305610499480281, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.205610262598384}
{"step": 296696, "time": 39907.91972351074, "episode/length": 248.0, "episode/score": 7.385369889286267, "episode/reward_rate": 0.9799196787148594, "episode/intrinsic_return": 0.2853696805768777}
{"step": 296864, "time": 39929.91415262222, "episode/length": 174.0, "episode/score": 7.2813297571156, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.18132947203775984}
{"step": 297040, "time": 39952.81462955475, "episode/length": 273.0, "episode/score": 5.3949871089216686, "episode/reward_rate": 0.9817518248175182, "episode/intrinsic_return": 0.2949869574886179}
{"step": 297104, "time": 39962.206356048584, "episode/length": 50.0, "episode/score": 1.1536935369949788, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.05369345156941563}
{"step": 297480, "time": 40009.714681863785, "episode/length": 235.0, "episode/score": 5.352707714731878, "episode/reward_rate": 0.9788135593220338, "episode/intrinsic_return": 0.2527075497946498}
{"step": 297592, "time": 40024.95164632797, "episode/length": 170.0, "episode/score": 2.273890421430224, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.17389035474752745}
{"step": 297704, "time": 40040.07564878464, "episode/length": 169.0, "episode/score": 3.2733760498103948, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.17337595448952925}
{"step": 297744, "time": 40046.38980054855, "episode/length": 32.0, "episode/score": 1.1375000546686351, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.037499999394640326}
{"step": 297880, "time": 40064.533541440964, "episode/length": 35.0, "episode/score": 3.1433334834873676, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.043333332519978285}
{"step": 298080, "time": 40090.56851577759, "episode/length": 290.0, "episode/score": 5.443139695072205, "episode/reward_rate": 0.9896907216494846, "episode/intrinsic_return": 0.343139543639154}
{"step": 298320, "time": 40121.39018845558, "episode/length": 181.0, "episode/score": 5.296782381630692, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.1967822371825605}
{"step": 298448, "time": 40138.48845529556, "episode/length": 431.0, "episode/score": 5.547241181654499, "episode/reward_rate": 0.7152777777777778, "episode/intrinsic_return": 0.4472410684638817}
{"step": 298528, "time": 40149.749247550964, "episode/length": 177.0, "episode/score": 5.296558482121327, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.19655832638090942}
{"step": 298952, "time": 40202.82691693306, "episode/length": 150.0, "episode/score": 6.264430232879022, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.16443002498454007}
{"step": 299048, "time": 40216.15889906883, "episode/length": 167.0, "episode/score": 6.264973117333284, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.1649728910451813}
{"step": 299656, "time": 40292.29378223419, "episode/length": 196.0, "episode/score": 5.317794990945913, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.21779483951286238}
{"step": 299720, "time": 40301.5899002552, "episode/length": 148.0, "episode/score": 5.26249297335562, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.16249276511189237}
{"step": 299760, "time": 40308.03468775749, "episode/length": 234.0, "episode/score": 7.355110140313627, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.2551098610565532}
{"step": 299824, "time": 40317.28147029877, "episode/length": 187.0, "episode/score": 5.312182131245208, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.2121818928499124}
{"step": 300040, "time": 40360.10664558411, "eval_episode/length": 50.0, "eval_episode/score": 2.100000001490116, "eval_episode/reward_rate": 0.9803921568627451}
{"step": 300040, "time": 40365.735218048096, "eval_episode/length": 150.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9668874172185431}
{"step": 300040, "time": 40367.86661481857, "eval_episode/length": 162.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9693251533742331}
{"step": 300040, "time": 40370.21728134155, "eval_episode/length": 169.0, "eval_episode/score": 6.100000023841858, "eval_episode/reward_rate": 0.9941176470588236}
{"step": 300040, "time": 40372.423620700836, "eval_episode/length": 172.0, "eval_episode/score": 6.100000016391277, "eval_episode/reward_rate": 0.9710982658959537}
{"step": 300040, "time": 40374.70752811432, "eval_episode/length": 180.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9723756906077348}
{"step": 300040, "time": 40377.4554142952, "eval_episode/length": 196.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9695431472081218}
{"step": 300040, "time": 40379.98411273956, "eval_episode/length": 162.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9693251533742331}
{"step": 300041, "time": 40381.052453279495, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.481027431588955, "train/action_min": 0.0, "train/action_std": 3.5609134252739962, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.05286758034317582, "train/actor_opt_grad_steps": 73680.0, "train/actor_opt_loss": -10.891459142956784, "train/adv_mag": 0.6302717003242049, "train/adv_max": 0.6050187882292207, "train/adv_mean": 0.002985548973714849, "train/adv_min": -0.4934398065168391, "train/adv_std": 0.06707681305509396, "train/cont_avg": 0.9945849867724867, "train/cont_loss_mean": 0.0001181478836685598, "train/cont_loss_std": 0.003624446666590879, "train/cont_neg_acc": 0.9967246165981999, "train/cont_neg_loss": 0.015062344229179825, "train/cont_pos_acc": 0.9999895871631683, "train/cont_pos_loss": 4.838410657996628e-05, "train/cont_pred": 0.9945872094896104, "train/cont_rate": 0.9945849867724867, "train/dyn_loss_mean": 6.475051988369573, "train/dyn_loss_std": 8.705736442848488, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0500683787638547, "train/extr_critic_critic_opt_grad_steps": 73680.0, "train/extr_critic_critic_opt_loss": 15948.75122974537, "train/extr_critic_mag": 6.153780316549634, "train/extr_critic_max": 6.153780316549634, "train/extr_critic_mean": 1.0871675392938038, "train/extr_critic_min": -0.5876129480896803, "train/extr_critic_std": 1.3377590557885548, "train/extr_return_normed_mag": 1.7584846593715526, "train/extr_return_normed_max": 1.7584846593715526, "train/extr_return_normed_mean": 0.31608928732140357, "train/extr_return_normed_min": -0.16003765595495387, "train/extr_return_normed_std": 0.33498520455347797, "train/extr_return_rate": 0.5017674834955306, "train/extr_return_raw_mag": 7.015859303651033, "train/extr_return_raw_max": 7.015859303651033, "train/extr_return_raw_mean": 1.099417663755871, "train/extr_return_raw_min": -0.853611739854964, "train/extr_return_raw_std": 1.3740789798832445, "train/extr_reward_mag": 1.0201628157701441, "train/extr_reward_max": 1.0201628157701441, "train/extr_reward_mean": 0.03058782009476865, "train/extr_reward_min": -0.6526620186195171, "train/extr_reward_std": 0.1698434905558036, "train/image_loss_mean": 3.5864622012648004, "train/image_loss_std": 8.29855459203165, "train/model_loss_mean": 7.547796050076762, "train/model_loss_std": 12.315281746879457, "train/model_opt_grad_norm": 42.82206538366893, "train/model_opt_grad_steps": 73612.71957671958, "train/model_opt_loss": 9766.203892299107, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1296.2962962962963, "train/policy_entropy_mag": 2.5149550715451516, "train/policy_entropy_max": 2.5149550715451516, "train/policy_entropy_mean": 0.5394922209479821, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6170034142082961, "train/policy_logprob_mag": 7.438383934989808, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5396034362770262, "train/policy_logprob_min": -7.438383934989808, "train/policy_logprob_std": 1.1015632505770083, "train/policy_randomness_mag": 0.8876687767644408, "train/policy_randomness_max": 0.8876687767644408, "train/policy_randomness_mean": 0.190417079185998, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.217775131028796, "train/post_ent_mag": 59.71561492435516, "train/post_ent_max": 59.71561492435516, "train/post_ent_mean": 42.394574019013255, "train/post_ent_min": 18.92978958856492, "train/post_ent_std": 6.899091574250075, "train/prior_ent_mag": 74.243366342373, "train/prior_ent_max": 74.243366342373, "train/prior_ent_mean": 48.84654389235078, "train/prior_ent_min": 29.821588798805518, "train/prior_ent_std": 7.115451494852702, "train/rep_loss_mean": 6.475051988369573, "train/rep_loss_std": 8.705736442848488, "train/reward_avg": 0.021620632607548956, "train/reward_loss_mean": 0.07618454425896286, "train/reward_loss_std": 0.19431783526978164, "train/reward_max_data": 1.011832041715188, "train/reward_max_pred": 1.009833533927877, "train/reward_neg_acc": 0.9987127575924788, "train/reward_neg_loss": 0.052483079807152826, "train/reward_pos_acc": 0.8865501196296127, "train/reward_pos_loss": 0.777232205110883, "train/reward_pred": 0.021290408210858466, "train/reward_rate": 0.03293960813492063, "train_stats/sum_log_reward": 5.183333287636439, "train_stats/max_log_achievement_collect_drink": 5.25, "train_stats/max_log_achievement_collect_sapling": 2.25, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 6.444444444444445, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.2777777777777778, "train_stats/max_log_achievement_eat_cow": 0.08333333333333333, "train_stats/max_log_achievement_make_wood_pickaxe": 0.027777777777777776, "train_stats/max_log_achievement_make_wood_sword": 0.6388888888888888, "train_stats/max_log_achievement_place_plant": 1.6944444444444444, "train_stats/max_log_achievement_place_table": 2.0, "train_stats/max_log_achievement_wake_up": 2.361111111111111, "train_stats/mean_log_entropy": 0.5339979016118579, "eval_stats/sum_log_reward": 5.099999964237213, "eval_stats/max_log_achievement_collect_drink": 5.125, "eval_stats/max_log_achievement_collect_sapling": 2.5, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 5.875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.25, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.625, "eval_stats/max_log_achievement_place_plant": 2.125, "eval_stats/max_log_achievement_place_table": 1.875, "eval_stats/max_log_achievement_wake_up": 1.625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 5.46610749552201e-07, "report/cont_loss_std": 2.952508111775387e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 4.6682776883244514e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 4.1104897263721796e-07, "report/cont_pred": 0.9970701336860657, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 6.434928894042969, "report/dyn_loss_std": 8.976574897766113, "report/image_loss_mean": 3.8015050888061523, "report/image_loss_std": 12.253122329711914, "report/model_loss_mean": 7.723870277404785, "report/model_loss_std": 16.276622772216797, "report/post_ent_mag": 60.067440032958984, "report/post_ent_max": 60.067440032958984, "report/post_ent_mean": 42.907752990722656, "report/post_ent_min": 18.621288299560547, "report/post_ent_std": 6.97036075592041, "report/prior_ent_mag": 73.41897583007812, "report/prior_ent_max": 73.41897583007812, "report/prior_ent_mean": 48.98677062988281, "report/prior_ent_min": 27.35474395751953, "report/prior_ent_std": 6.639839172363281, "report/rep_loss_mean": 6.434928894042969, "report/rep_loss_std": 8.976574897766113, "report/reward_avg": 0.022738123312592506, "report/reward_loss_mean": 0.061407171189785004, "report/reward_loss_std": 0.134566992521286, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0018160343170166, "report/reward_neg_acc": 1.0000001192092896, "report/reward_neg_loss": 0.042471930384635925, "report/reward_pos_acc": 0.9642857313156128, "report/reward_pos_loss": 0.7349609732627869, "report/reward_pred": 0.02204812504351139, "report/reward_rate": 0.02734375, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 7.4973763730668e-07, "eval/cont_loss_std": 4.166025064478163e-06, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 3.377090615686029e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 6.851169018773362e-07, "eval/cont_pred": 0.998046338558197, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 18.885833740234375, "eval/dyn_loss_std": 12.290501594543457, "eval/image_loss_mean": 26.210874557495117, "eval/image_loss_std": 29.177669525146484, "eval/model_loss_mean": 37.63611602783203, "eval/model_loss_std": 33.634307861328125, "eval/post_ent_mag": 61.765846252441406, "eval/post_ent_max": 61.765846252441406, "eval/post_ent_mean": 41.71599197387695, "eval/post_ent_min": 22.050569534301758, "eval/post_ent_std": 6.7365007400512695, "eval/prior_ent_mag": 73.41897583007812, "eval/prior_ent_max": 73.41897583007812, "eval/prior_ent_mean": 53.21729278564453, "eval/prior_ent_min": 32.653480529785156, "eval/prior_ent_std": 6.042805194854736, "eval/rep_loss_mean": 18.885833740234375, "eval/rep_loss_std": 12.290501594543457, "eval/reward_avg": 0.02167968824505806, "eval/reward_loss_mean": 0.09374365955591202, "eval/reward_loss_std": 0.6659966111183167, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0017523765563965, "eval/reward_neg_acc": 0.9959959983825684, "eval/reward_neg_loss": 0.04287524148821831, "eval/reward_pos_acc": 0.7999999523162842, "eval/reward_pos_loss": 2.1264455318450928, "eval/reward_pred": 0.018801771104335785, "eval/reward_rate": 0.0244140625, "replay/size": 299537.0, "replay/inserts": 7528.0, "replay/samples": 30112.0, "replay/insert_wait_avg": 1.6138226775636582e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.118748681071461e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 60696.0, "eval_replay/inserts": 1712.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2207811123856875e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.450580596923828e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1011.9484977722168, "timer/env.step_count": 941.0, "timer/env.step_total": 80.6887743473053, "timer/env.step_frac": 0.07973604835121544, "timer/env.step_avg": 0.08574790047535101, "timer/env.step_min": 0.022859573364257812, "timer/env.step_max": 2.0316855907440186, "timer/replay._sample_count": 30112.0, "timer/replay._sample_total": 14.271541118621826, "timer/replay._sample_frac": 0.014103031083143383, "timer/replay._sample_avg": 0.00047394862907219133, "timer/replay._sample_min": 0.00036835670471191406, "timer/replay._sample_max": 0.009479284286499023, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1155.0, "timer/agent.policy_total": 18.412607669830322, "timer/agent.policy_frac": 0.018195202335262405, "timer/agent.policy_avg": 0.015941651662190755, "timer/agent.policy_min": 0.009509086608886719, "timer/agent.policy_max": 0.046581268310546875, "timer/dataset_train_count": 1882.0, "timer/dataset_train_total": 0.2880880832672119, "timer/dataset_train_frac": 0.00028468650717050495, "timer/dataset_train_avg": 0.00015307549589118594, "timer/dataset_train_min": 8.96453857421875e-05, "timer/dataset_train_max": 0.0012328624725341797, "timer/agent.train_count": 1882.0, "timer/agent.train_total": 848.6528429985046, "timer/agent.train_frac": 0.8386324450965597, "timer/agent.train_avg": 0.4509313724752947, "timer/agent.train_min": 0.43738222122192383, "timer/agent.train_max": 0.927818775177002, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48006105422973633, "timer/agent.report_frac": 0.0004743927732355753, "timer/agent.report_avg": 0.24003052711486816, "timer/agent.report_min": 0.2341005802154541, "timer/agent.report_max": 0.24596047401428223, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.6226043701171875e-05, "timer/dataset_eval_frac": 2.5916381870132675e-08, "timer/dataset_eval_avg": 2.6226043701171875e-05, "timer/dataset_eval_min": 2.6226043701171875e-05, "timer/dataset_eval_max": 2.6226043701171875e-05, "fps": 7.439015835979473}
{"step": 300272, "time": 40408.856106996536, "episode/length": 227.0, "episode/score": 5.310290885403447, "episode/reward_rate": 0.9780701754385965, "episode/intrinsic_return": 0.21029082937275234}
{"step": 300432, "time": 40429.623521089554, "episode/length": 423.0, "episode/score": 6.554042583111368, "episode/reward_rate": 0.7287735849056604, "episode/intrinsic_return": 0.45404240653260786}
{"step": 300496, "time": 40438.95101857185, "episode/length": 192.0, "episode/score": 5.290773323502435, "episode/reward_rate": 0.9689119170984456, "episode/intrinsic_return": 0.19077310716784268}
{"step": 300664, "time": 40460.69684767723, "episode/length": 201.0, "episode/score": 4.298172004948356, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.19817179751953518}
{"step": 301080, "time": 40512.66291832924, "episode/length": 177.0, "episode/score": 4.278753560249243, "episode/reward_rate": 0.9662921348314607, "episode/intrinsic_return": 0.1787534100967605}
{"step": 301224, "time": 40531.75984930992, "episode/length": 187.0, "episode/score": 5.2929500132840985, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.1929498394993061}
{"step": 301408, "time": 40555.956924676895, "episode/length": 197.0, "episode/score": 6.320994194797095, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.22099401146624587}
{"step": 301592, "time": 40579.74162173271, "episode/length": 228.0, "episode/score": 6.3597773348501505, "episode/reward_rate": 0.9694323144104804, "episode/intrinsic_return": 0.25977724284712167}
{"step": 301640, "time": 40587.1312918663, "episode/length": 142.0, "episode/score": 2.2332682510996165, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.1332681287703963}
{"step": 301704, "time": 40596.59487915039, "episode/length": 129.0, "episode/score": 5.217372509956476, "episode/reward_rate": 0.9923076923076923, "episode/intrinsic_return": 0.1173723017127486}
{"step": 301720, "time": 40599.963853120804, "episode/length": 180.0, "episode/score": 7.282114697252837, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.1821144650275528}
{"step": 301848, "time": 40616.85888838768, "episode/length": 176.0, "episode/score": 4.261323794808959, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.16132362603002548}
{"step": 302104, "time": 40649.547996520996, "episode/length": 49.0, "episode/score": 3.1608411445467937, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.06084104806177493}
{"step": 302400, "time": 40687.03678178787, "episode/length": 164.0, "episode/score": 9.263971259413665, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.16397099342793808}
{"step": 302952, "time": 40755.41085243225, "episode/length": 192.0, "episode/score": 6.318330424787746, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.21833024471652607}
{"step": 303072, "time": 40771.37451291084, "episode/length": 184.0, "episode/score": 6.301222326880634, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.20122217135849496}
{"step": 303168, "time": 40785.85596179962, "episode/length": 190.0, "episode/score": 5.305051569533134, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.20505141810008354}
{"step": 303240, "time": 40796.07814621925, "episode/length": 189.0, "episode/score": 5.3163451770715255, "episode/reward_rate": 0.968421052631579, "episode/intrinsic_return": 0.2163449989793662}
{"step": 303320, "time": 40807.26897644997, "episode/length": 183.0, "episode/score": 5.303402927010211, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.20340277441300714}
{"step": 303640, "time": 40847.683764219284, "episode/length": 154.0, "episode/score": 3.2553461249326574, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.1553460307759451}
{"step": 303688, "time": 40854.920924425125, "episode/length": 307.0, "episode/score": 7.452868551593383, "episode/reward_rate": 0.9967532467532467, "episode/intrinsic_return": 0.352868305980337}
{"step": 304016, "time": 40896.454406023026, "episode/length": 40.0, "episode/score": 2.143225354491733, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.04322528780903667}
{"step": 304488, "time": 40955.2421643734, "episode/length": 191.0, "episode/score": 6.282583778032858, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.18258358550519915}
{"step": 304520, "time": 40960.67158770561, "episode/length": 159.0, "episode/score": 7.264623961200414, "episode/reward_rate": 0.9625, "episode/intrinsic_return": 0.16462375598348444}
{"step": 304576, "time": 40969.967689991, "episode/length": 175.0, "episode/score": 6.292136306030443, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.19213609580765478}
{"step": 304632, "time": 40978.34349679947, "episode/length": 194.0, "episode/score": 3.3131281222340476, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.21312794460754958}
{"step": 304768, "time": 40996.432668447495, "episode/length": 180.0, "episode/score": 7.277705006425094, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.17770474323333474}
{"step": 304920, "time": 41016.34590935707, "episode/length": 159.0, "episode/score": 6.252736175916652, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.152736009000364}
{"step": 305376, "time": 41072.9229490757, "episode/length": 169.0, "episode/score": 4.270740522395499, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.17074036944904947}
{"step": 305544, "time": 41094.77079439163, "episode/length": 429.0, "episode/score": 6.555066809630262, "episode/reward_rate": 0.8813953488372093, "episode/intrinsic_return": 0.45506662315619906}
{"step": 305672, "time": 41111.81165122986, "episode/length": 143.0, "episode/score": 6.2515849028077355, "episode/reward_rate": 0.9513888888888888, "episode/intrinsic_return": 0.1515847291393584}
{"step": 306080, "time": 41162.73399114609, "episode/length": 187.0, "episode/score": 6.303733263628601, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.20373306004148617}
{"step": 306088, "time": 41165.52492642403, "episode/length": 164.0, "episode/score": 5.280149715773405, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.1801495362260539}
{"step": 306480, "time": 41214.84354877472, "episode/length": 194.0, "episode/score": 8.30458187554268, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.20458157800840127}
{"step": 306576, "time": 41228.0689766407, "episode/length": 60.0, "episode/score": 4.171054532905146, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.07105435562789353}
{"step": 306688, "time": 41243.0441365242, "episode/length": 256.0, "episode/score": 5.400047681285287, "episode/reward_rate": 0.9961089494163424, "episode/intrinsic_return": 0.30004744288999063}
{"step": 306768, "time": 41254.43444609642, "episode/length": 284.0, "episode/score": 7.400537677696775, "episode/reward_rate": 0.9964912280701754, "episode/intrinsic_return": 0.30053747410966025}
{"step": 307080, "time": 41293.744482040405, "episode/length": 191.0, "episode/score": 5.314951970868606, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.2149517869556803}
{"step": 307168, "time": 41305.81109571457, "episode/length": 186.0, "episode/score": 5.318021260530259, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.2180211114255144}
{"step": 307192, "time": 41310.23740744591, "episode/length": 226.0, "episode/score": 7.361258312163045, "episode/reward_rate": 0.9779735682819384, "episode/intrinsic_return": 0.26125811134079413}
{"step": 307761, "time": 41381.17771720886, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.50587139228465, "train/action_min": 0.0, "train/action_std": 3.5192448116954744, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.05383727911840449, "train/actor_opt_grad_steps": 75590.0, "train/actor_opt_loss": -9.030937139388811, "train/adv_mag": 0.6438474230506878, "train/adv_max": 0.6248087981821959, "train/adv_mean": 0.0032421213474634818, "train/adv_min": -0.47679865900716634, "train/adv_std": 0.06827564807753489, "train/cont_avg": 0.9944897587435233, "train/cont_loss_mean": 0.00011052473578471254, "train/cont_loss_std": 0.003171383950584706, "train/cont_neg_acc": 0.9968048361916616, "train/cont_neg_loss": 0.01374860411376595, "train/cont_pos_acc": 0.9999948925304907, "train/cont_pos_loss": 1.91793362433114e-05, "train/cont_pred": 0.994496275723907, "train/cont_rate": 0.9944897587435233, "train/dyn_loss_mean": 6.521094023254869, "train/dyn_loss_std": 8.712348745276891, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0679924614688894, "train/extr_critic_critic_opt_grad_steps": 75590.0, "train/extr_critic_critic_opt_loss": 16010.76336322053, "train/extr_critic_mag": 6.246538009050597, "train/extr_critic_max": 6.246538009050597, "train/extr_critic_mean": 1.0923135800991652, "train/extr_critic_min": -0.5889065339775283, "train/extr_critic_std": 1.3330172661672601, "train/extr_return_normed_mag": 1.7780995171304812, "train/extr_return_normed_max": 1.7780995171304812, "train/extr_return_normed_mean": 0.3153307728971224, "train/extr_return_normed_min": -0.16884505007551123, "train/extr_return_normed_std": 0.3333221284836685, "train/extr_return_rate": 0.5052808841275428, "train/extr_return_raw_mag": 7.115784667316496, "train/extr_return_raw_max": 7.115784667316496, "train/extr_return_raw_mean": 1.105634639300213, "train/extr_return_raw_min": -0.8837439061137679, "train/extr_return_raw_std": 1.3696361069852205, "train/extr_reward_mag": 1.023381579107571, "train/extr_reward_max": 1.023381579107571, "train/extr_reward_mean": 0.030913368731235284, "train/extr_reward_min": -0.6594587539761795, "train/extr_reward_std": 0.17120681359514672, "train/image_loss_mean": 3.7537663625311977, "train/image_loss_std": 8.851838378708598, "train/model_loss_mean": 7.742976336899199, "train/model_loss_std": 12.844002091205182, "train/model_opt_grad_norm": 42.3046932220459, "train/model_opt_grad_steps": 75521.04145077721, "train/model_opt_loss": 11113.22625384553, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1437.823834196891, "train/policy_entropy_mag": 2.512059981341189, "train/policy_entropy_max": 2.512059981341189, "train/policy_entropy_mean": 0.5540340005424974, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6210858391047759, "train/policy_logprob_mag": 7.4383839152637545, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5550624715849526, "train/policy_logprob_min": -7.4383839152637545, "train/policy_logprob_std": 1.1110179726941598, "train/policy_randomness_mag": 0.8866469375210105, "train/policy_randomness_max": 0.8866469375210105, "train/policy_randomness_mean": 0.19554968911749093, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.21921604678729656, "train/post_ent_mag": 59.827317232912684, "train/post_ent_max": 59.827317232912684, "train/post_ent_mean": 42.56799241298221, "train/post_ent_min": 18.887083419246377, "train/post_ent_std": 7.037921124789381, "train/prior_ent_mag": 74.20468163366762, "train/prior_ent_max": 74.20468163366762, "train/prior_ent_mean": 49.07280302294795, "train/prior_ent_min": 29.536035517954456, "train/prior_ent_std": 7.178896236913809, "train/rep_loss_mean": 6.521094023254869, "train/rep_loss_std": 8.712348745276891, "train/reward_avg": 0.02152538288220609, "train/reward_loss_mean": 0.07644309549365637, "train/reward_loss_std": 0.18589893848167183, "train/reward_max_data": 1.0136852647356418, "train/reward_max_pred": 1.0121445309930515, "train/reward_neg_acc": 0.9987177206444616, "train/reward_neg_loss": 0.052763446277596174, "train/reward_pos_acc": 0.883429046430736, "train/reward_pos_loss": 0.7665115644277068, "train/reward_pred": 0.021175640381853354, "train/reward_rate": 0.03331950291450777, "train_stats/sum_log_reward": 5.42499994635582, "train_stats/max_log_achievement_collect_drink": 5.95, "train_stats/max_log_achievement_collect_sapling": 2.25, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 6.275, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.3, "train_stats/max_log_achievement_eat_cow": 0.1, "train_stats/max_log_achievement_make_wood_pickaxe": 0.1, "train_stats/max_log_achievement_make_wood_sword": 0.65, "train_stats/max_log_achievement_place_plant": 1.85, "train_stats/max_log_achievement_place_table": 1.95, "train_stats/max_log_achievement_wake_up": 2.15, "train_stats/mean_log_entropy": 0.528436991199851, "report/cont_avg": 0.990234375, "report/cont_loss_mean": 5.372231316869147e-05, "report/cont_loss_std": 0.00143976672552526, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.000648452143650502, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 4.7857123718131334e-05, "report/cont_pred": 0.9901944398880005, "report/cont_rate": 0.990234375, "report/dyn_loss_mean": 5.708785057067871, "report/dyn_loss_std": 8.723679542541504, "report/image_loss_mean": 3.822892427444458, "report/image_loss_std": 7.627045631408691, "report/model_loss_mean": 7.325198650360107, "report/model_loss_std": 11.316564559936523, "report/post_ent_mag": 60.33498001098633, "report/post_ent_max": 60.33498001098633, "report/post_ent_mean": 42.96553039550781, "report/post_ent_min": 16.768226623535156, "report/post_ent_std": 7.756015777587891, "report/prior_ent_mag": 74.08103942871094, "report/prior_ent_max": 74.08103942871094, "report/prior_ent_mean": 48.977779388427734, "report/prior_ent_min": 26.02783203125, "report/prior_ent_std": 7.130856990814209, "report/rep_loss_mean": 5.708785057067871, "report/rep_loss_std": 8.723679542541504, "report/reward_avg": 0.011786985211074352, "report/reward_loss_mean": 0.07698142528533936, "report/reward_loss_std": 0.17717240750789642, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0029528141021729, "report/reward_neg_acc": 1.0000001192092896, "report/reward_neg_loss": 0.057278458029031754, "report/reward_pos_acc": 0.8571429252624512, "report/reward_pos_loss": 0.7778444886207581, "report/reward_pred": 0.010899549350142479, "report/reward_rate": 0.02734375, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.00021336563804652542, "eval/cont_loss_std": 0.006045766174793243, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.003402375616133213, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.00019456993322819471, "eval/cont_pred": 0.9939842224121094, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 19.34758186340332, "eval/dyn_loss_std": 12.45726203918457, "eval/image_loss_mean": 20.024988174438477, "eval/image_loss_std": 23.55718421936035, "eval/model_loss_mean": 31.758590698242188, "eval/model_loss_std": 28.689374923706055, "eval/post_ent_mag": 59.52568054199219, "eval/post_ent_max": 59.52568054199219, "eval/post_ent_mean": 39.10877227783203, "eval/post_ent_min": 21.54583740234375, "eval/post_ent_std": 6.838717460632324, "eval/prior_ent_mag": 74.08103942871094, "eval/prior_ent_max": 74.08103942871094, "eval/prior_ent_mean": 52.24249267578125, "eval/prior_ent_min": 36.05109405517578, "eval/prior_ent_std": 6.752830505371094, "eval/rep_loss_mean": 19.34758186340332, "eval/rep_loss_std": 12.45726203918457, "eval/reward_avg": 0.02451171725988388, "eval/reward_loss_mean": 0.12484285235404968, "eval/reward_loss_std": 0.7609545588493347, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0042526721954346, "eval/reward_neg_acc": 0.9959757924079895, "eval/reward_neg_loss": 0.05349171161651611, "eval/reward_pos_acc": 0.7000000476837158, "eval/reward_pos_loss": 2.488943576812744, "eval/reward_pred": 0.017518892884254456, "eval/reward_rate": 0.029296875, "replay/size": 307257.0, "replay/inserts": 7720.0, "replay/samples": 30880.0, "replay/insert_wait_avg": 1.6282259491441162e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.208533237635163e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 60696.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 7.152557373046875e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1115393638611, "timer/env.step_count": 965.0, "timer/env.step_total": 86.57747983932495, "timer/env.step_frac": 0.08656782411929184, "timer/env.step_avg": 0.08971759568841964, "timer/env.step_min": 0.0230410099029541, "timer/env.step_max": 1.953444004058838, "timer/replay._sample_count": 30880.0, "timer/replay._sample_total": 14.685189247131348, "timer/replay._sample_frac": 0.014683551453143042, "timer/replay._sample_avg": 0.00047555664660399444, "timer/replay._sample_min": 0.0003647804260253906, "timer/replay._sample_max": 0.010680198669433594, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 965.0, "timer/agent.policy_total": 15.298906326293945, "timer/agent.policy_frac": 0.015297200086327461, "timer/agent.policy_avg": 0.015853788939164712, "timer/agent.policy_min": 0.014440774917602539, "timer/agent.policy_max": 0.04501008987426758, "timer/dataset_train_count": 1930.0, "timer/dataset_train_total": 0.29096102714538574, "timer/dataset_train_frac": 0.00029092857715696066, "timer/dataset_train_avg": 0.00015075700888361957, "timer/dataset_train_min": 8.7738037109375e-05, "timer/dataset_train_max": 0.00035381317138671875, "timer/agent.train_count": 1930.0, "timer/agent.train_total": 864.7555611133575, "timer/agent.train_frac": 0.8646591175854254, "timer/agent.train_avg": 0.4480598762245376, "timer/agent.train_min": 0.43590283393859863, "timer/agent.train_max": 1.3871715068817139, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4741947650909424, "timer/agent.report_frac": 0.00047414187960731106, "timer/agent.report_avg": 0.2370973825454712, "timer/agent.report_min": 0.23085808753967285, "timer/agent.report_max": 0.24333667755126953, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.147125244140625e-05, "timer/dataset_eval_frac": 3.1467742549420144e-08, "timer/dataset_eval_avg": 3.147125244140625e-05, "timer/dataset_eval_min": 3.147125244140625e-05, "timer/dataset_eval_max": 3.147125244140625e-05, "fps": 7.719028418857296}
{"step": 307816, "time": 41387.654941082, "episode/length": 216.0, "episode/score": 7.328903058191827, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.22890284377808712}
{"step": 307848, "time": 41393.13809514046, "episode/length": 144.0, "episode/score": 6.259653774418439, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.159653537536542}
{"step": 308040, "time": 41418.04580807686, "episode/length": 182.0, "episode/score": 3.286975096381866, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.18697497090943216}
{"step": 308064, "time": 41422.51515722275, "episode/length": 161.0, "episode/score": 5.269988375164758, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.1699881924159854}
{"step": 308200, "time": 41440.50318455696, "episode/length": 214.0, "episode/score": 5.323689612363523, "episode/reward_rate": 0.9813953488372092, "episode/intrinsic_return": 0.2236894764137105}
{"step": 308856, "time": 41521.50679516792, "episode/length": 221.0, "episode/score": 5.332642125310485, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.23264190100144333}
{"step": 308880, "time": 41525.91109418869, "episode/length": 213.0, "episode/score": 6.3051264818141135, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.20512630057874048}
{"step": 308920, "time": 41532.31970858574, "episode/length": 215.0, "episode/score": 6.31660299075611, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.2166027538742128}
{"step": 309008, "time": 41544.52225804329, "episode/length": 148.0, "episode/score": 5.270700971676888, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.1707007692539264}
{"step": 309072, "time": 41553.8362929821, "episode/length": 152.0, "episode/score": 6.241579190757875, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.14157899485417147}
{"step": 309392, "time": 41593.97089910507, "episode/length": 165.0, "episode/score": 6.259420410380244, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.15942019899330262}
{"step": 309944, "time": 41662.10497236252, "episode/length": 237.0, "episode/score": 6.3638498073669325, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.263849540217052}
{"step": 309976, "time": 41667.46939444542, "episode/length": 221.0, "episode/score": 5.345392469710077, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.24539221361965247}
{"step": 310024, "time": 41694.973622083664, "eval_episode/length": 179.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9833333333333333}
{"step": 310024, "time": 41696.91851067543, "eval_episode/length": 189.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9947368421052631}
{"step": 310024, "time": 41698.69323325157, "eval_episode/length": 191.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9947916666666666}
{"step": 310024, "time": 41700.29676270485, "eval_episode/length": 192.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9689119170984456}
{"step": 310024, "time": 41701.900983572006, "eval_episode/length": 193.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9948453608247423}
{"step": 310024, "time": 41704.61015248299, "eval_episode/length": 219.0, "eval_episode/score": 7.099999971687794, "eval_episode/reward_rate": 0.9954545454545455}
{"step": 310024, "time": 41706.46000599861, "eval_episode/length": 227.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9649122807017544}
{"step": 310024, "time": 41713.53307723999, "eval_episode/length": 167.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9702380952380952}
{"step": 310024, "time": 41713.53995895386, "eval_episode/length": 171.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9941860465116279}
{"step": 310296, "time": 41746.38082957268, "episode/length": 160.0, "episode/score": 3.2552323323106975, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.15523222232150147}
{"step": 310328, "time": 41751.799729824066, "episode/length": 180.0, "episode/score": 4.2773000143224635, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.1772997999087238}
{"step": 310360, "time": 41757.12752914429, "episode/length": 179.0, "episode/score": 5.2909860087597735, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.19098593840999456}
{"step": 310552, "time": 41782.06650900841, "episode/length": 184.0, "episode/score": 5.306265982439527, "episode/reward_rate": 0.9675675675675676, "episode/intrinsic_return": 0.20626583449893587}
{"step": 311192, "time": 41861.33391952515, "episode/length": 291.0, "episode/score": 7.402451831559574, "episode/reward_rate": 0.9828767123287672, "episode/intrinsic_return": 0.30245162983510454}
{"step": 311464, "time": 41897.08709740639, "episode/length": 145.0, "episode/score": 5.2616544310676545, "episode/reward_rate": 0.9657534246575342, "episode/intrinsic_return": 0.16165431441368128}
{"step": 311512, "time": 41904.359535217285, "episode/length": 264.0, "episode/score": 3.381998285831287, "episode/reward_rate": 0.9849056603773585, "episode/intrinsic_return": 0.28199816035885306}
{"step": 311536, "time": 41908.887437820435, "episode/length": 150.0, "episode/score": 5.247357837114578, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.14735763236330968}
{"step": 311560, "time": 41913.265486717224, "episode/length": 201.0, "episode/score": 7.310965113335442, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.21096490189029282}
{"step": 311752, "time": 41937.690928697586, "episode/length": 173.0, "episode/score": 6.284951250547238, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.18495107047601778}
{"step": 312728, "time": 42057.857021808624, "episode/length": 157.0, "episode/score": 5.270167047536233, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.1701669153990224}
{"step": 312744, "time": 42061.52450680733, "episode/length": 147.0, "episode/score": 5.2654620868379425, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.16546188522988814}
{"step": 312768, "time": 42066.00866818428, "episode/length": 348.0, "episode/score": 6.481272702381375, "episode/reward_rate": 0.994269340974212, "episode/intrinsic_return": 0.3812725823222536}
{"step": 312920, "time": 42085.92934465408, "episode/length": 215.0, "episode/score": 6.336741137329682, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.23674090044778495}
{"step": 313088, "time": 42107.91349339485, "episode/length": 316.0, "episode/score": 7.429610833828519, "episode/reward_rate": 0.9936908517350158, "episode/intrinsic_return": 0.32961060806428577}
{"step": 313224, "time": 42126.03917384148, "episode/length": 213.0, "episode/score": 7.321276442860835, "episode/reward_rate": 0.9813084112149533, "episode/intrinsic_return": 0.22127625417488161}
{"step": 313304, "time": 42137.18736600876, "episode/length": 193.0, "episode/score": 6.311591340443556, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.21159117469142075}
{"step": 313968, "time": 42219.81451368332, "episode/length": 154.0, "episode/score": 7.2751881512049295, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.17518793225099216}
{"step": 313984, "time": 42223.35852408409, "episode/length": 154.0, "episode/score": 6.270057915491634, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.17005773542041425}
{"step": 314008, "time": 42227.8045732975, "episode/length": 308.0, "episode/score": 7.447383796075883, "episode/reward_rate": 0.9838187702265372, "episode/intrinsic_return": 0.34738355721492553}
{"step": 314296, "time": 42264.246759176254, "episode/length": 190.0, "episode/score": 4.283528924745042, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.18352880195016041}
{"step": 314552, "time": 42297.25970220566, "episode/length": 155.0, "episode/score": 4.253843795540888, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.15384367274600663}
{"step": 314632, "time": 42308.6058447361, "episode/length": 192.0, "episode/score": 5.310583266793401, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.21058311419619713}
{"step": 314688, "time": 42316.90868759155, "episode/length": 182.0, "episode/score": 5.2977700106039265, "episode/reward_rate": 0.9672131147540983, "episode/intrinsic_return": 0.197769834257997}
{"step": 314912, "time": 42345.50542759895, "episode/length": 44.0, "episode/score": 3.1523932114068884, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.05239311492186971}
{"step": 315189, "time": 42381.59505915642, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.595381123310811, "train/action_min": 0.0, "train/action_std": 3.533070082277865, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.053257355979970986, "train/actor_opt_grad_steps": 77480.0, "train/actor_opt_loss": -9.75162765013205, "train/adv_mag": 0.6349131527784708, "train/adv_max": 0.6029675367716196, "train/adv_mean": 0.0032854697762534643, "train/adv_min": -0.49157043260497013, "train/adv_std": 0.06756759469170828, "train/cont_avg": 0.9942567567567567, "train/cont_loss_mean": 5.570195674261265e-05, "train/cont_loss_std": 0.0014474707793670565, "train/cont_neg_acc": 0.9983268989099039, "train/cont_neg_loss": 0.003522559342812545, "train/cont_pos_acc": 0.9999893729751175, "train/cont_pos_loss": 3.3243843194490426e-05, "train/cont_pred": 0.9942482919306368, "train/cont_rate": 0.9942567567567567, "train/dyn_loss_mean": 6.579427043811695, "train/dyn_loss_std": 8.771971968057994, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0770285029669067, "train/extr_critic_critic_opt_grad_steps": 77480.0, "train/extr_critic_critic_opt_loss": 15831.391527660473, "train/extr_critic_mag": 6.276239067799336, "train/extr_critic_max": 6.276239067799336, "train/extr_critic_mean": 1.1398463294312762, "train/extr_critic_min": -0.5727053784035347, "train/extr_critic_std": 1.367149236073365, "train/extr_return_normed_mag": 1.7779804075086438, "train/extr_return_normed_max": 1.7779804075086438, "train/extr_return_normed_mean": 0.32136198395007365, "train/extr_return_normed_min": -0.1695030363226259, "train/extr_return_normed_std": 0.33800625011727614, "train/extr_return_rate": 0.5171980854627248, "train/extr_return_raw_mag": 7.203494069382951, "train/extr_return_raw_max": 7.203494069382951, "train/extr_return_raw_mean": 1.1534940068786208, "train/extr_return_raw_min": -0.8855949007176064, "train/extr_return_raw_std": 1.403999018024754, "train/extr_reward_mag": 1.0233394816115096, "train/extr_reward_max": 1.0233394816115096, "train/extr_reward_mean": 0.031659624262436015, "train/extr_reward_min": -0.6586621284484864, "train/extr_reward_std": 0.17364715329698613, "train/image_loss_mean": 3.7599417757343603, "train/image_loss_std": 8.636906879012649, "train/model_loss_mean": 7.786457536027238, "train/model_loss_std": 12.662687023265942, "train/model_opt_grad_norm": 40.76133979591163, "train/model_opt_grad_steps": 77409.42702702702, "train/model_opt_loss": 10814.585180004224, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1385.1351351351352, "train/policy_entropy_mag": 2.5015561902845227, "train/policy_entropy_max": 2.5015561902845227, "train/policy_entropy_mean": 0.5371407755323359, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6001859526376466, "train/policy_logprob_mag": 7.438383955568881, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5376403647500115, "train/policy_logprob_min": -7.438383955568881, "train/policy_logprob_std": 1.0990899849582363, "train/policy_randomness_mag": 0.8829395584157995, "train/policy_randomness_max": 0.8829395584157995, "train/policy_randomness_mean": 0.18958712445723044, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.21183930490468, "train/post_ent_mag": 59.69744336927259, "train/post_ent_max": 59.69744336927259, "train/post_ent_mean": 42.77340170370566, "train/post_ent_min": 18.802207802437447, "train/post_ent_std": 7.041819783803579, "train/prior_ent_mag": 74.29411249934016, "train/prior_ent_max": 74.29411249934016, "train/prior_ent_mean": 49.32675507004197, "train/prior_ent_min": 29.878337076547982, "train/prior_ent_std": 7.120050373592893, "train/rep_loss_mean": 6.579427043811695, "train/rep_loss_std": 8.771971968057994, "train/reward_avg": 0.022038533100606623, "train/reward_loss_mean": 0.0788038512138096, "train/reward_loss_std": 0.19370204983530817, "train/reward_max_data": 1.010439219990292, "train/reward_max_pred": 1.0092467262938216, "train/reward_neg_acc": 0.9984787805660351, "train/reward_neg_loss": 0.054264884905235185, "train/reward_pos_acc": 0.8852193410332139, "train/reward_pos_loss": 0.7682936391314945, "train/reward_pred": 0.02176201208620458, "train/reward_rate": 0.03445945945945946, "train_stats/sum_log_reward": 5.468421001183359, "train_stats/max_log_achievement_collect_drink": 6.157894736842105, "train_stats/max_log_achievement_collect_sapling": 2.526315789473684, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 5.921052631578948, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.3157894736842105, "train_stats/max_log_achievement_eat_cow": 0.05263157894736842, "train_stats/max_log_achievement_make_wood_pickaxe": 0.18421052631578946, "train_stats/max_log_achievement_make_wood_sword": 0.6842105263157895, "train_stats/max_log_achievement_place_plant": 1.868421052631579, "train_stats/max_log_achievement_place_table": 1.894736842105263, "train_stats/max_log_achievement_wake_up": 1.7894736842105263, "train_stats/mean_log_entropy": 0.5335286945888871, "eval_stats/sum_log_reward": 5.544444349077013, "eval_stats/max_log_achievement_collect_drink": 6.555555555555555, "eval_stats/max_log_achievement_collect_sapling": 3.0, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 4.777777777777778, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.2222222222222222, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.3333333333333333, "eval_stats/max_log_achievement_make_wood_sword": 0.4444444444444444, "eval_stats/max_log_achievement_place_plant": 2.111111111111111, "eval_stats/max_log_achievement_place_table": 1.5555555555555556, "eval_stats/max_log_achievement_wake_up": 1.7777777777777777, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 2.4414080144197214e-06, "report/cont_loss_std": 5.069964754511602e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 1.8873090084525757e-05, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 2.3283087102754507e-06, "report/cont_pred": 0.9931619167327881, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 5.76148796081543, "report/dyn_loss_std": 8.585871696472168, "report/image_loss_mean": 2.794534683227539, "report/image_loss_std": 7.5760297775268555, "report/model_loss_mean": 6.330533027648926, "report/model_loss_std": 11.625545501708984, "report/post_ent_mag": 61.5638313293457, "report/post_ent_max": 61.5638313293457, "report/post_ent_mean": 44.061851501464844, "report/post_ent_min": 19.76520347595215, "report/post_ent_std": 7.558574676513672, "report/prior_ent_mag": 74.01077270507812, "report/prior_ent_max": 74.01077270507812, "report/prior_ent_mean": 49.745059967041016, "report/prior_ent_min": 32.01926803588867, "report/prior_ent_std": 6.787699222564697, "report/rep_loss_mean": 5.76148796081543, "report/rep_loss_std": 8.585871696472168, "report/reward_avg": 0.020309988409280777, "report/reward_loss_mean": 0.07910319417715073, "report/reward_loss_std": 0.21985717117786407, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0089902877807617, "report/reward_neg_acc": 0.9989919066429138, "report/reward_neg_loss": 0.05289410799741745, "report/reward_pos_acc": 0.875, "report/reward_pos_loss": 0.8915848135948181, "report/reward_pred": 0.018591992557048798, "report/reward_rate": 0.03125, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 1.6211272395594278e-06, "eval/cont_loss_std": 2.9637152692885138e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0005295143346302211, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 5.880681328562787e-07, "eval/cont_pred": 0.9980473518371582, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 19.285625457763672, "eval/dyn_loss_std": 11.956528663635254, "eval/image_loss_mean": 18.377094268798828, "eval/image_loss_std": 22.33939552307129, "eval/model_loss_mean": 30.138961791992188, "eval/model_loss_std": 27.489179611206055, "eval/post_ent_mag": 57.69529724121094, "eval/post_ent_max": 57.69529724121094, "eval/post_ent_mean": 40.35914611816406, "eval/post_ent_min": 21.714542388916016, "eval/post_ent_std": 6.621043682098389, "eval/prior_ent_mag": 74.01077270507812, "eval/prior_ent_max": 74.01077270507812, "eval/prior_ent_mean": 53.372947692871094, "eval/prior_ent_min": 32.77359390258789, "eval/prior_ent_std": 5.898462772369385, "eval/rep_loss_mean": 19.285625457763672, "eval/rep_loss_std": 11.956528663635254, "eval/reward_avg": 0.02988281287252903, "eval/reward_loss_mean": 0.19049270451068878, "eval/reward_loss_std": 1.1333019733428955, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.001817226409912, "eval/reward_neg_acc": 0.9949545860290527, "eval/reward_neg_loss": 0.07199258357286453, "eval/reward_pos_acc": 0.5757575631141663, "eval/reward_pos_loss": 3.749087333679199, "eval/reward_pred": 0.01927143521606922, "eval/reward_rate": 0.0322265625, "replay/size": 314685.0, "replay/inserts": 7428.0, "replay/samples": 29712.0, "replay/insert_wait_avg": 1.6281023164172936e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.251096015728861e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 63592.0, "eval_replay/inserts": 2896.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1630315148369383e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.748603820800781e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3995304107666, "timer/env.step_count": 928.0, "timer/env.step_total": 83.0700786113739, "timer/env.step_frac": 0.08303690284347207, "timer/env.step_avg": 0.08951517091742878, "timer/env.step_min": 0.02357935905456543, "timer/env.step_max": 1.873412847518921, "timer/replay._sample_count": 29712.0, "timer/replay._sample_total": 14.156580448150635, "timer/replay._sample_frac": 0.014150926722584433, "timer/replay._sample_avg": 0.0004764600312382416, "timer/replay._sample_min": 0.0003495216369628906, "timer/replay._sample_max": 0.010669708251953125, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1290.0, "timer/agent.policy_total": 20.47763967514038, "timer/agent.policy_frac": 0.020469461502778005, "timer/agent.policy_avg": 0.015874139283054558, "timer/agent.policy_min": 0.009655237197875977, "timer/agent.policy_max": 0.05267620086669922, "timer/dataset_train_count": 1857.0, "timer/dataset_train_total": 0.3027067184448242, "timer/dataset_train_frac": 0.00030258582620538825, "timer/dataset_train_avg": 0.0001630084644290922, "timer/dataset_train_min": 9.202957153320312e-05, "timer/dataset_train_max": 0.010307788848876953, "timer/agent.train_count": 1857.0, "timer/agent.train_total": 831.8276915550232, "timer/agent.train_frac": 0.8314954838228209, "timer/agent.train_avg": 0.4479416755815957, "timer/agent.train_min": 0.4359431266784668, "timer/agent.train_max": 0.9724202156066895, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47685718536376953, "timer/agent.report_frac": 0.000476666742504338, "timer/agent.report_avg": 0.23842859268188477, "timer/agent.report_min": 0.23190784454345703, "timer/agent.report_max": 0.2449493408203125, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 5.0067901611328125e-05, "timer/dataset_eval_frac": 5.004790595090555e-08, "timer/dataset_eval_avg": 5.0067901611328125e-05, "timer/dataset_eval_min": 5.0067901611328125e-05, "timer/dataset_eval_max": 5.0067901611328125e-05, "fps": 7.424931480889402}
{"step": 315256, "time": 42389.7407040596, "episode/length": 155.0, "episode/score": 6.266959807469902, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.16695969230022456}
{"step": 315560, "time": 42427.968652009964, "episode/length": 196.0, "episode/score": 6.303955248960847, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.2039550744193548}
{"step": 315696, "time": 42445.78015065193, "episode/length": 346.0, "episode/score": 7.463558897156872, "episode/reward_rate": 0.9942363112391931, "episode/intrinsic_return": 0.36355867552538257}
{"step": 315752, "time": 42454.052914619446, "episode/length": 222.0, "episode/score": 5.356304714512589, "episode/reward_rate": 0.9775784753363229, "episode/intrinsic_return": 0.2563045329279703}
{"step": 315936, "time": 42477.805193185806, "episode/length": 162.0, "episode/score": 5.271083503983391, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.17108326873130864}
{"step": 316152, "time": 42505.524188518524, "episode/length": 231.0, "episode/score": 6.339229644179795, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.23922946178026905}
{"step": 316280, "time": 42522.59550881386, "episode/length": 198.0, "episode/score": 5.320579527757218, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.220579328128224}
{"step": 316552, "time": 42557.26732683182, "episode/length": 204.0, "episode/score": 5.303778082052304, "episode/reward_rate": 0.9658536585365853, "episode/intrinsic_return": 0.20377793760417262}
{"step": 316656, "time": 42571.494507074356, "episode/length": 174.0, "episode/score": 6.286969444238821, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.18696927732253243}
{"step": 317024, "time": 42617.760553359985, "episode/length": 182.0, "episode/score": 5.286734825717758, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.18673467428470758}
{"step": 317056, "time": 42623.0257191658, "episode/length": 162.0, "episode/score": 6.268128206599613, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.16812793607368803}
{"step": 317496, "time": 42678.18887734413, "episode/length": 224.0, "episode/score": 5.322105922189621, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.22210577075657056}
{"step": 317568, "time": 42688.58488202095, "episode/length": 160.0, "episode/score": 6.273711797990472, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.17371166669727245}
{"step": 317672, "time": 42702.77476143837, "episode/length": 189.0, "episode/score": 7.313564045230123, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.21356385945455258}
{"step": 317848, "time": 42725.694819927216, "episode/length": 98.0, "episode/score": 3.2125447263242677, "episode/reward_rate": 0.98989898989899, "episode/intrinsic_return": 0.11254464078228921}
{"step": 318088, "time": 42756.341529369354, "episode/length": 191.0, "episode/score": 7.3125576792936045, "episode/reward_rate": 0.984375, "episode/intrinsic_return": 0.21255745335474785}
{"step": 318616, "time": 42821.98432087898, "episode/length": 244.0, "episode/score": 5.379330605341238, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.2793304423830705}
{"step": 318648, "time": 42827.36654305458, "episode/length": 202.0, "episode/score": 5.322724612167804, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.22272438308573328}
{"step": 319040, "time": 42876.76193380356, "episode/length": 148.0, "episode/score": 3.23512626532829, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.13512617117157788}
{"step": 319088, "time": 42884.116983652115, "episode/length": 198.0, "episode/score": 6.333567483932711, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.2335673033958301}
{"step": 319296, "time": 42910.90014100075, "episode/length": 215.0, "episode/score": 6.335019629135786, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.2350192971425713}
{"step": 319360, "time": 42920.26684594154, "episode/length": 158.0, "episode/score": 6.274736174031204, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.1747359383134608}
{"step": 319456, "time": 42933.49672794342, "episode/length": 222.0, "episode/score": 7.326635889559839, "episode/reward_rate": 0.9775784753363229, "episode/intrinsic_return": 0.22663568317875615}
{"step": 319496, "time": 42941.20002222061, "episode/length": 444.0, "episode/score": 6.5438846460647255, "episode/reward_rate": 0.6382022471910113, "episode/intrinsic_return": 0.4438844091828287}
{"step": 320008, "time": 43023.55353426933, "eval_episode/length": 140.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9929078014184397}
{"step": 320008, "time": 43025.380266427994, "eval_episode/length": 148.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9932885906040269}
{"step": 320008, "time": 43028.28972816467, "eval_episode/length": 178.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9720670391061452}
{"step": 320008, "time": 43031.539684057236, "eval_episode/length": 190.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9947643979057592}
{"step": 320008, "time": 43033.962491989136, "eval_episode/length": 202.0, "eval_episode/score": 7.099999971687794, "eval_episode/reward_rate": 0.9950738916256158}
{"step": 320008, "time": 43035.59111905098, "eval_episode/length": 203.0, "eval_episode/score": 5.099999971687794, "eval_episode/reward_rate": 0.9950980392156863}
{"step": 320008, "time": 43037.18490147591, "eval_episode/length": 205.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9951456310679612}
{"step": 320008, "time": 43039.316761016846, "eval_episode/length": 219.0, "eval_episode/score": 7.100000023841858, "eval_episode/reward_rate": 0.9954545454545455}
{"step": 320040, "time": 43043.19622015953, "episode/length": 173.0, "episode/score": 5.2844171114902565, "episode/reward_rate": 0.9597701149425287, "episode/intrinsic_return": 0.18441696704212518}
{"step": 320320, "time": 43078.6485555172, "episode/length": 212.0, "episode/score": 7.335032451492225, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.23503224394698918}
{"step": 320456, "time": 43096.59168744087, "episode/length": 176.0, "episode/score": 6.304143162531545, "episode/reward_rate": 0.9661016949152542, "episode/intrinsic_return": 0.2041429346136283}
{"step": 320680, "time": 43125.270859241486, "episode/length": 147.0, "episode/score": 5.260961259753458, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.1609611164112721}
{"step": 320824, "time": 43144.22346949577, "episode/length": 170.0, "episode/score": 4.2769951748250605, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.17699500383423583}
{"step": 321128, "time": 43182.79700374603, "episode/length": 254.0, "episode/score": 6.371124731540476, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.271124582435732}
{"step": 321224, "time": 43196.40545964241, "episode/length": 147.0, "episode/score": 5.259352921028949, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.15935276039908786}
{"step": 321232, "time": 43198.939180612564, "episode/length": 241.0, "episode/score": 5.384301956042691, "episode/reward_rate": 0.9834710743801653, "episode/intrinsic_return": 0.28430180344548717}
{"step": 321344, "time": 43214.17906498909, "episode/length": 247.0, "episode/score": 7.3706775827668025, "episode/reward_rate": 0.9717741935483871, "episode/intrinsic_return": 0.27067735752643785}
{"step": 321712, "time": 43260.34880876541, "episode/length": 173.0, "episode/score": 6.257998284898349, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.15799816856451798}
{"step": 321848, "time": 43278.38042020798, "episode/length": 173.0, "episode/score": 6.292898992327537, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.19289873111483757}
{"step": 322000, "time": 43298.57209920883, "episode/length": 164.0, "episode/score": 6.281600310690919, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.18160013294800592}
{"step": 322256, "time": 43331.26680016518, "episode/length": 178.0, "episode/score": 8.268169502574892, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.1681693240752793}
{"step": 322408, "time": 43351.2165620327, "episode/length": 159.0, "episode/score": 6.265117641696634, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.16511743030969228}
{"step": 322641, "time": 43381.926602602005, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.524674196294285, "train/action_min": 0.0, "train/action_std": 3.5547662278547643, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.05260135940609769, "train/actor_opt_grad_steps": 79340.0, "train/actor_opt_loss": -11.477638772783433, "train/adv_mag": 0.6129212266302364, "train/adv_max": 0.5855591183996456, "train/adv_mean": 0.0024951577562463555, "train/adv_min": -0.48393789507488516, "train/adv_std": 0.0656570375045353, "train/cont_avg": 0.9946262951203209, "train/cont_loss_mean": 0.00022720328942401322, "train/cont_loss_std": 0.007077567288483635, "train/cont_neg_acc": 0.9910873442410147, "train/cont_neg_loss": 0.0513994125381105, "train/cont_pos_acc": 0.999973712757947, "train/cont_pos_loss": 0.00011922206297464474, "train/cont_pred": 0.9946149801187975, "train/cont_rate": 0.9946262951203209, "train/dyn_loss_mean": 6.489213657889136, "train/dyn_loss_std": 8.676244832615163, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0337324639692664, "train/extr_critic_critic_opt_grad_steps": 79340.0, "train/extr_critic_critic_opt_loss": 15700.523244276405, "train/extr_critic_mag": 6.369019786304331, "train/extr_critic_max": 6.369019786304331, "train/extr_critic_mean": 1.1273265226002045, "train/extr_critic_min": -0.5872125740357261, "train/extr_critic_std": 1.345825079609366, "train/extr_return_normed_mag": 1.7944677717545454, "train/extr_return_normed_max": 1.7944677717545454, "train/extr_return_normed_mean": 0.3172287390353208, "train/extr_return_normed_min": -0.17063469013428306, "train/extr_return_normed_std": 0.33291651228851177, "train/extr_return_rate": 0.5125431973028948, "train/extr_return_raw_mag": 7.253779944251566, "train/extr_return_raw_max": 7.253779944251566, "train/extr_return_raw_mean": 1.1376626035746407, "train/extr_return_raw_min": -0.8818571545223501, "train/extr_return_raw_std": 1.3782332259065964, "train/extr_reward_mag": 1.02759792842967, "train/extr_reward_max": 1.02759792842967, "train/extr_reward_mean": 0.03021438383960469, "train/extr_reward_min": -0.6399018401130635, "train/extr_reward_std": 0.169186904388953, "train/image_loss_mean": 3.5654095149932696, "train/image_loss_std": 8.164757078344172, "train/model_loss_mean": 7.53504449670965, "train/model_loss_std": 12.157105864050553, "train/model_opt_grad_norm": 41.947544985276494, "train/model_opt_grad_steps": 79267.60427807487, "train/model_opt_loss": 9813.426937980448, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1303.475935828877, "train/policy_entropy_mag": 2.5309428939207352, "train/policy_entropy_max": 2.5309428939207352, "train/policy_entropy_mean": 0.533575174483386, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.5952436439493761, "train/policy_logprob_mag": 7.438384007642614, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.533430868769712, "train/policy_logprob_min": -7.438384007642614, "train/policy_logprob_std": 1.0927768142465601, "train/policy_randomness_mag": 0.8933117724357442, "train/policy_randomness_max": 0.8933117724357442, "train/policy_randomness_mean": 0.18832861950850105, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.21009488435671292, "train/post_ent_mag": 59.71606296396511, "train/post_ent_max": 59.71606296396511, "train/post_ent_mean": 42.94574496835311, "train/post_ent_min": 18.940984312863275, "train/post_ent_std": 7.024708778462945, "train/prior_ent_mag": 74.38461666821159, "train/prior_ent_max": 74.38461666821159, "train/prior_ent_mean": 49.406015712309646, "train/prior_ent_min": 29.740000964486025, "train/prior_ent_std": 7.074040091611485, "train/rep_loss_mean": 6.489213657889136, "train/rep_loss_std": 8.676244832615163, "train/reward_avg": 0.02139606511713389, "train/reward_loss_mean": 0.0758795497172019, "train/reward_loss_std": 0.18801165603220782, "train/reward_max_data": 1.014619015754863, "train/reward_max_pred": 1.0136460397332747, "train/reward_neg_acc": 0.998682027832072, "train/reward_neg_loss": 0.052602785853619244, "train/reward_pos_acc": 0.882741144952927, "train/reward_pos_loss": 0.7697165433098289, "train/reward_pred": 0.021026598630761877, "train/reward_rate": 0.032508564505347594, "train_stats/sum_log_reward": 5.784210462319224, "train_stats/max_log_achievement_collect_drink": 6.026315789473684, "train_stats/max_log_achievement_collect_sapling": 2.9473684210526314, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 6.526315789473684, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.3157894736842105, "train_stats/max_log_achievement_eat_cow": 0.13157894736842105, "train_stats/max_log_achievement_make_wood_pickaxe": 0.18421052631578946, "train_stats/max_log_achievement_make_wood_sword": 0.7368421052631579, "train_stats/max_log_achievement_place_plant": 2.0789473684210527, "train_stats/max_log_achievement_place_table": 2.236842105263158, "train_stats/max_log_achievement_wake_up": 2.236842105263158, "train_stats/mean_log_entropy": 0.4922292177614413, "eval_stats/sum_log_reward": 6.224999964237213, "eval_stats/max_log_achievement_collect_drink": 3.375, "eval_stats/max_log_achievement_collect_sapling": 3.25, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 5.875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.5, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.25, "eval_stats/max_log_achievement_make_wood_sword": 0.75, "eval_stats/max_log_achievement_place_plant": 2.375, "eval_stats/max_log_achievement_place_table": 1.75, "eval_stats/max_log_achievement_wake_up": 2.25, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 3.3315341170236934e-06, "report/cont_loss_std": 6.031103112036362e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00043729189201258123, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 3.445895799814025e-07, "report/cont_pred": 0.9931667447090149, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 7.227583408355713, "report/dyn_loss_std": 8.708773612976074, "report/image_loss_mean": 3.704679012298584, "report/image_loss_std": 8.240375518798828, "report/model_loss_mean": 8.119698524475098, "report/model_loss_std": 11.902009963989258, "report/post_ent_mag": 60.55115509033203, "report/post_ent_max": 60.55115509033203, "report/post_ent_mean": 42.92308044433594, "report/post_ent_min": 21.826534271240234, "report/post_ent_std": 7.571549415588379, "report/prior_ent_mag": 74.55754089355469, "report/prior_ent_max": 74.55754089355469, "report/prior_ent_mean": 49.95890808105469, "report/prior_ent_min": 28.657018661499023, "report/prior_ent_std": 7.565089225769043, "report/rep_loss_mean": 7.227583408355713, "report/rep_loss_std": 8.708773612976074, "report/reward_avg": 0.0219449270516634, "report/reward_loss_mean": 0.07846647500991821, "report/reward_loss_std": 0.14928793907165527, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.002354383468628, "report/reward_neg_acc": 0.996966540813446, "report/reward_neg_loss": 0.05707405507564545, "report/reward_pos_acc": 0.800000011920929, "report/reward_pos_loss": 0.6829548478126526, "report/reward_pred": 0.02240695245563984, "report/reward_rate": 0.0341796875, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 4.9689955631038174e-05, "eval/cont_loss_std": 0.0009627640247344971, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0011861362727358937, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 4.7465990064665675e-05, "eval/cont_pred": 0.998002290725708, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 18.689964294433594, "eval/dyn_loss_std": 13.19062328338623, "eval/image_loss_mean": 19.618206024169922, "eval/image_loss_std": 23.663436889648438, "eval/model_loss_mean": 30.912921905517578, "eval/model_loss_std": 29.463504791259766, "eval/post_ent_mag": 59.39813232421875, "eval/post_ent_max": 59.39813232421875, "eval/post_ent_mean": 39.90146255493164, "eval/post_ent_min": 18.170183181762695, "eval/post_ent_std": 7.290508270263672, "eval/prior_ent_mag": 74.55754089355469, "eval/prior_ent_max": 74.55754089355469, "eval/prior_ent_mean": 51.81904602050781, "eval/prior_ent_min": 34.165428161621094, "eval/prior_ent_std": 7.13925838470459, "eval/rep_loss_mean": 18.689964294433594, "eval/rep_loss_std": 13.19062328338623, "eval/reward_avg": 0.02060546912252903, "eval/reward_loss_mean": 0.08068609237670898, "eval/reward_loss_std": 0.6140129566192627, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0024149417877197, "eval/reward_neg_acc": 0.9930069446563721, "eval/reward_neg_loss": 0.02926461398601532, "eval/reward_pos_acc": 0.739130437374115, "eval/reward_pos_loss": 2.318638563156128, "eval/reward_pred": 0.015673687681555748, "eval/reward_rate": 0.0224609375, "replay/size": 322137.0, "replay/inserts": 7452.0, "replay/samples": 29808.0, "replay/insert_wait_avg": 1.6274659529976223e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.323004901249179e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 65352.0, "eval_replay/inserts": 1760.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2134963815862482e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.195638656616211e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3175315856934, "timer/env.step_count": 932.0, "timer/env.step_total": 82.41571164131165, "timer/env.step_frac": 0.08238955035674231, "timer/env.step_avg": 0.08842887515162194, "timer/env.step_min": 0.023419618606567383, "timer/env.step_max": 1.9810502529144287, "timer/replay._sample_count": 29808.0, "timer/replay._sample_total": 14.25333857536316, "timer/replay._sample_frac": 0.01424881412681922, "timer/replay._sample_avg": 0.0004781715839829294, "timer/replay._sample_min": 0.0003485679626464844, "timer/replay._sample_max": 0.027071714401245117, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1152.0, "timer/agent.policy_total": 19.210282564163208, "timer/agent.policy_frac": 0.019204184628966024, "timer/agent.policy_avg": 0.016675592503613897, "timer/agent.policy_min": 0.009750843048095703, "timer/agent.policy_max": 0.11299276351928711, "timer/dataset_train_count": 1863.0, "timer/dataset_train_total": 0.3003108501434326, "timer/dataset_train_frac": 0.00030021552223260834, "timer/dataset_train_avg": 0.00016119745042588975, "timer/dataset_train_min": 9.655952453613281e-05, "timer/dataset_train_max": 0.0021898746490478516, "timer/agent.train_count": 1863.0, "timer/agent.train_total": 836.5628411769867, "timer/agent.train_frac": 0.8362972903722637, "timer/agent.train_avg": 0.44904070916639116, "timer/agent.train_min": 0.431957483291626, "timer/agent.train_max": 1.0065526962280273, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4695923328399658, "timer/agent.report_frac": 0.0004694432697741214, "timer/agent.report_avg": 0.2347961664199829, "timer/agent.report_min": 0.22387290000915527, "timer/agent.report_max": 0.24571943283081055, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.5987625122070312e-05, "timer/dataset_eval_frac": 2.5979375849661447e-08, "timer/dataset_eval_avg": 2.5987625122070312e-05, "timer/dataset_eval_min": 2.5987625122070312e-05, "timer/dataset_eval_max": 2.5987625122070312e-05, "fps": 7.449530503329682}
{"step": 322704, "time": 43389.47428441048, "episode/length": 55.0, "episode/score": 4.160935772744779, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.06093571333803993}
{"step": 322752, "time": 43396.772644758224, "episode/length": 175.0, "episode/score": 4.2775337600614876, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.17753358278423548}
{"step": 322800, "time": 43404.095257759094, "episode/length": 195.0, "episode/score": 6.315349863998563, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.215349683927343}
{"step": 322952, "time": 43424.10206389427, "episode/length": 215.0, "episode/score": 6.317981114863869, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.21798090813354065}
{"step": 323168, "time": 43451.85012793541, "episode/length": 145.0, "episode/score": 6.266828489314321, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.16682828025568597}
{"step": 323336, "time": 43473.761004924774, "episode/length": 185.0, "episode/score": 6.31236541904218, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.21236516562930774}
{"step": 323528, "time": 43498.6149764061, "episode/length": 44.0, "episode/score": 3.1545834832359105, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.05458333226852119}
{"step": 323536, "time": 43501.11315584183, "episode/length": 227.0, "episode/score": 4.352977921071215, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.2529778248772345}
{"step": 323904, "time": 43547.28226709366, "episode/length": 186.0, "episode/score": 7.30612684888365, "episode/reward_rate": 0.9679144385026738, "episode/intrinsic_return": 0.20612664366672107}
{"step": 324128, "time": 43576.07696032524, "episode/length": 171.0, "episode/score": 5.273362026745417, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.17336187531236646}
{"step": 324136, "time": 43578.51918196678, "episode/length": 147.0, "episode/score": 5.265069056655193, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.16506881825989694}
{"step": 324400, "time": 43612.0860247612, "episode/length": 132.0, "episode/score": 5.250531873995897, "episode/reward_rate": 0.9924812030075187, "episode/intrinsic_return": 0.1505317210494468}
{"step": 324560, "time": 43633.51629757881, "episode/length": 231.0, "episode/score": 6.356157825495757, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.2561575703221024}
{"step": 324616, "time": 43641.85125732422, "episode/length": 60.0, "episode/score": 5.166043032903417, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.06604289154029175}
{"step": 324864, "time": 43673.58931326866, "episode/length": 165.0, "episode/score": 7.284115405274861, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.1841151965654717}
{"step": 324992, "time": 43690.730479717255, "episode/length": 182.0, "episode/score": 6.313406768144887, "episode/reward_rate": 0.9672131147540983, "episode/intrinsic_return": 0.2134065935451872}
{"step": 325152, "time": 43711.73104786873, "episode/length": 155.0, "episode/score": 6.262633233078759, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.1626329683736003}
{"step": 325328, "time": 43734.65798950195, "episode/length": 315.0, "episode/score": 3.454947587222705, "episode/reward_rate": 0.990506329113924, "episode/intrinsic_return": 0.35494752784507}
{"step": 325624, "time": 43772.75176882744, "episode/length": 185.0, "episode/score": 5.287033258559859, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.18703313582318515}
{"step": 325656, "time": 43778.11052489281, "episode/length": 156.0, "episode/score": 5.265285197294361, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.1652850458613102}
{"step": 326408, "time": 43871.20803451538, "episode/length": 176.0, "episode/score": 6.290150928939511, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.19015076315827173}
{"step": 326784, "time": 43918.74367213249, "episode/length": 203.0, "episode/score": 6.313280576370744, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.21328039979198365}
{"step": 327136, "time": 43963.18095207214, "episode/length": 188.0, "episode/score": 6.299188863940344, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.19918867013211639}
{"step": 327232, "time": 43976.36506152153, "episode/length": 196.0, "episode/score": 5.315858994277733, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.21585888446315948}
{"step": 327288, "time": 43984.749106645584, "episode/length": 333.0, "episode/score": 7.470448704130831, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.3704484965855954}
{"step": 327400, "time": 43999.87289428711, "episode/length": 354.0, "episode/score": 7.482290486983857, "episode/reward_rate": 0.9971830985915493, "episode/intrinsic_return": 0.3822902099386738}
{"step": 327800, "time": 44051.3007941246, "episode/length": 173.0, "episode/score": 6.288145614166297, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.18814540394350843}
{"step": 327856, "time": 44059.668680906296, "episode/length": 315.0, "episode/score": 7.4268564397734735, "episode/reward_rate": 0.9968354430379747, "episode/intrinsic_return": 0.3268561495733593}
{"step": 328040, "time": 44083.762397289276, "episode/length": 156.0, "episode/score": 5.255850044588897, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.1558498422532466}
{"step": 328128, "time": 44096.3860681057, "episode/length": 40.0, "episode/score": 3.1439700429764343, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.043969961974653415}
{"step": 328496, "time": 44142.59318828583, "episode/length": 453.0, "episode/score": 5.551439183738239, "episode/reward_rate": 0.9933920704845814, "episode/intrinsic_return": 0.4514390161234587}
{"step": 328736, "time": 44173.1503534317, "episode/length": 166.0, "episode/score": 5.273191208995286, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.1731910572129891}
{"step": 329112, "time": 44220.475529909134, "episode/length": 156.0, "episode/score": 5.277367617366963, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.17736746593391217}
{"step": 329224, "time": 44235.518427848816, "episode/length": 248.0, "episode/score": 6.380683836557182, "episode/reward_rate": 0.9879518072289156, "episode/intrinsic_return": 0.2806836564859623}
{"step": 329264, "time": 44241.82846593857, "episode/length": 265.0, "episode/score": 6.391334003747488, "episode/reward_rate": 0.981203007518797, "episode/intrinsic_return": 0.29133382367626837}
{"step": 329296, "time": 44247.24618768692, "episode/length": 69.0, "episode/score": 3.181818640772235, "episode/reward_rate": 0.9142857142857143, "episode/intrinsic_return": 0.08181855010798245}
{"step": 329496, "time": 44273.08267951012, "episode/length": 275.0, "episode/score": 5.423319278112103, "episode/reward_rate": 0.9963768115942029, "episode/intrinsic_return": 0.3233191243507463}
{"step": 329576, "time": 44284.44746661186, "episode/length": 191.0, "episode/score": 5.308979831794204, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.2089796305353957}
{"step": 329792, "time": 44312.19717001915, "episode/length": 207.0, "episode/score": 6.316856681678928, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.21685644479703114}
{"step": 330096, "time": 44351.248816251755, "episode/length": 199.0, "episode/score": 5.299736336003207, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.19973616297511398}
{"step": 330096, "time": 44368.209376335144, "eval_episode/length": 109.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9454545454545454}
{"step": 330096, "time": 44371.69347834587, "eval_episode/length": 152.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9738562091503268}
{"step": 330096, "time": 44373.2835893631, "eval_episode/length": 155.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.967948717948718}
{"step": 330096, "time": 44375.405092954636, "eval_episode/length": 166.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9700598802395209}
{"step": 330096, "time": 44377.474153995514, "eval_episode/length": 181.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.978021978021978}
{"step": 330096, "time": 44377.48129224777, "eval_episode/length": 181.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9725274725274725}
{"step": 330096, "time": 44382.203600645065, "eval_episode/length": 216.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9953917050691244}
{"step": 330096, "time": 44384.76567387581, "eval_episode/length": 240.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.995850622406639}
{"step": 330097, "time": 44387.272940158844, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.713291947559644, "train/action_min": 0.0, "train/action_std": 3.6870347786975164, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.05458158482947657, "train/actor_opt_grad_steps": 81205.0, "train/actor_opt_loss": -7.854763678285063, "train/adv_mag": 0.6557686320876562, "train/adv_max": 0.6254642700315803, "train/adv_mean": 0.0037562438590866415, "train/adv_min": -0.5081796192674226, "train/adv_std": 0.06851969453035503, "train/cont_avg": 0.9943296370967742, "train/cont_loss_mean": 6.376888228227819e-05, "train/cont_loss_std": 0.001899682660124011, "train/cont_neg_acc": 0.9992319512110884, "train/cont_neg_loss": 0.0047503906346619065, "train/cont_pos_acc": 0.999989410882355, "train/cont_pos_loss": 3.168180588763525e-05, "train/cont_pred": 0.9943136467087653, "train/cont_rate": 0.9943296370967742, "train/dyn_loss_mean": 6.507942302252657, "train/dyn_loss_std": 8.737025776217061, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0379482879433581, "train/extr_critic_critic_opt_grad_steps": 81205.0, "train/extr_critic_critic_opt_loss": 15837.923282090054, "train/extr_critic_mag": 6.289773312948084, "train/extr_critic_max": 6.289773312948084, "train/extr_critic_mean": 1.159259616207051, "train/extr_critic_min": -0.5828494461633826, "train/extr_critic_std": 1.3374658646763011, "train/extr_return_normed_mag": 1.8094874383300863, "train/extr_return_normed_max": 1.8094874383300863, "train/extr_return_normed_mean": 0.33003109357049387, "train/extr_return_normed_min": -0.16930254094142427, "train/extr_return_normed_std": 0.33639254725428036, "train/extr_return_rate": 0.5287711681217275, "train/extr_return_raw_mag": 7.226684221657374, "train/extr_return_raw_max": 7.226684221657374, "train/extr_return_raw_mean": 1.1746443721555895, "train/extr_return_raw_min": -0.8678478531299099, "train/extr_return_raw_std": 1.376086365151149, "train/extr_reward_mag": 1.026853922874697, "train/extr_reward_max": 1.026853922874697, "train/extr_reward_mean": 0.03189204410419509, "train/extr_reward_min": -0.6486679386067135, "train/extr_reward_std": 0.17392918026895934, "train/image_loss_mean": 3.577422341992778, "train/image_loss_std": 8.466854305677517, "train/model_loss_mean": 7.5598166296558995, "train/model_loss_std": 12.480643882546374, "train/model_opt_grad_norm": 41.135145136105116, "train/model_opt_grad_steps": 81131.25806451614, "train/model_opt_loss": 11903.132263839885, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1586.021505376344, "train/policy_entropy_mag": 2.49871132322537, "train/policy_entropy_max": 2.49871132322537, "train/policy_entropy_mean": 0.5291787565395396, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.578390317097787, "train/policy_logprob_mag": 7.438383953545683, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5291871545455789, "train/policy_logprob_min": -7.438383953545683, "train/policy_logprob_std": 1.0906212531751203, "train/policy_randomness_mag": 0.8819354445703568, "train/policy_randomness_max": 0.8819354445703568, "train/policy_randomness_mean": 0.18677687869277051, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.20414640153608016, "train/post_ent_mag": 60.240132834321706, "train/post_ent_max": 60.240132834321706, "train/post_ent_mean": 43.05654023283272, "train/post_ent_min": 19.202266200896233, "train/post_ent_std": 7.0771279719568065, "train/prior_ent_mag": 74.43149976832892, "train/prior_ent_max": 74.43149976832892, "train/prior_ent_mean": 49.5594305017943, "train/prior_ent_min": 30.108346067449098, "train/prior_ent_std": 7.0857602473228205, "train/rep_loss_mean": 6.507942302252657, "train/rep_loss_std": 8.737025776217061, "train/reward_avg": 0.022370635456736048, "train/reward_loss_mean": 0.07756518850964243, "train/reward_loss_std": 0.1820376538220913, "train/reward_max_data": 1.0157661611034023, "train/reward_max_pred": 1.012975308202928, "train/reward_neg_acc": 0.9985253592973115, "train/reward_neg_loss": 0.05361163656237305, "train/reward_pos_acc": 0.8885682407886751, "train/reward_pos_loss": 0.7506125559729915, "train/reward_pred": 0.02215020078664986, "train/reward_rate": 0.03442120295698925, "train_stats/sum_log_reward": 5.424999910593033, "train_stats/max_log_achievement_collect_drink": 4.8, "train_stats/max_log_achievement_collect_sapling": 2.1, "train_stats/max_log_achievement_collect_stone": 0.025, "train_stats/max_log_achievement_collect_wood": 6.6, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.15, "train_stats/max_log_achievement_eat_cow": 0.1, "train_stats/max_log_achievement_make_wood_pickaxe": 0.2, "train_stats/max_log_achievement_make_wood_sword": 0.5, "train_stats/max_log_achievement_place_plant": 1.85, "train_stats/max_log_achievement_place_table": 2.2, "train_stats/max_log_achievement_wake_up": 1.825, "train_stats/mean_log_entropy": 0.49893666207790377, "eval_stats/sum_log_reward": 4.724999904632568, "eval_stats/max_log_achievement_collect_drink": 3.625, "eval_stats/max_log_achievement_collect_sapling": 1.125, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 7.25, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.125, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.375, "eval_stats/max_log_achievement_place_plant": 1.0, "eval_stats/max_log_achievement_place_table": 2.25, "eval_stats/max_log_achievement_wake_up": 1.375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 5.228203463047976e-06, "report/cont_loss_std": 6.455890252254903e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 2.656648121046601e-06, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 5.235759545030305e-06, "report/cont_pred": 0.9970651268959045, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 5.98769474029541, "report/dyn_loss_std": 8.011608123779297, "report/image_loss_mean": 3.0230581760406494, "report/image_loss_std": 6.593202114105225, "report/model_loss_mean": 6.687106132507324, "report/model_loss_std": 10.267848014831543, "report/post_ent_mag": 59.99299621582031, "report/post_ent_max": 59.99299621582031, "report/post_ent_mean": 44.79240417480469, "report/post_ent_min": 20.733272552490234, "report/post_ent_std": 7.1408305168151855, "report/prior_ent_mag": 74.20631408691406, "report/prior_ent_max": 74.20631408691406, "report/prior_ent_mean": 50.89801788330078, "report/prior_ent_min": 28.184391021728516, "report/prior_ent_std": 6.929502010345459, "report/rep_loss_mean": 5.98769474029541, "report/rep_loss_std": 8.011608123779297, "report/reward_avg": 0.021882064640522003, "report/reward_loss_mean": 0.07142633944749832, "report/reward_loss_std": 0.1723221093416214, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0023715496063232, "report/reward_neg_acc": 0.9989949464797974, "report/reward_neg_loss": 0.04948806390166283, "report/reward_pos_acc": 0.931034505367279, "report/reward_pos_loss": 0.8241360187530518, "report/reward_pred": 0.020786218345165253, "report/reward_rate": 0.0283203125, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 2.2644582713837735e-05, "eval/cont_loss_std": 0.0004836461157537997, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 1.8442258806317113e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.2669353711535223e-05, "eval/cont_pred": 0.994118332862854, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 21.953948974609375, "eval/dyn_loss_std": 12.432540893554688, "eval/image_loss_mean": 25.766002655029297, "eval/image_loss_std": 25.899709701538086, "eval/model_loss_mean": 39.069732666015625, "eval/model_loss_std": 30.67902183532715, "eval/post_ent_mag": 58.18495178222656, "eval/post_ent_max": 58.18495178222656, "eval/post_ent_mean": 40.60602569580078, "eval/post_ent_min": 21.107868194580078, "eval/post_ent_std": 7.120375633239746, "eval/prior_ent_mag": 74.20631408691406, "eval/prior_ent_max": 74.20631408691406, "eval/prior_ent_mean": 54.280982971191406, "eval/prior_ent_min": 34.683990478515625, "eval/prior_ent_std": 6.143070697784424, "eval/rep_loss_mean": 21.953948974609375, "eval/rep_loss_std": 12.432540893554688, "eval/reward_avg": 0.02285156212747097, "eval/reward_loss_mean": 0.13133740425109863, "eval/reward_loss_std": 0.9266031980514526, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0016818046569824, "eval/reward_neg_acc": 0.9939759969711304, "eval/reward_neg_loss": 0.035881198942661285, "eval/reward_pos_acc": 0.6785714626312256, "eval/reward_pos_loss": 3.5268518924713135, "eval/reward_pred": 0.01588229089975357, "eval/reward_rate": 0.02734375, "replay/size": 329593.0, "replay/inserts": 7456.0, "replay/samples": 29824.0, "replay/insert_wait_avg": 1.623107384202818e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.51821140362981e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 67280.0, "eval_replay/inserts": 1928.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.18764109631297e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.685754776000977e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1005.3343214988708, "timer/env.step_count": 932.0, "timer/env.step_total": 86.19321036338806, "timer/env.step_frac": 0.08573586768119193, "timer/env.step_avg": 0.09248198536844213, "timer/env.step_min": 0.0230100154876709, "timer/env.step_max": 2.0988094806671143, "timer/replay._sample_count": 29824.0, "timer/replay._sample_total": 14.36448860168457, "timer/replay._sample_frac": 0.014288270373847676, "timer/replay._sample_avg": 0.00048164191931614035, "timer/replay._sample_min": 0.00035309791564941406, "timer/replay._sample_max": 0.010279178619384766, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1173.0, "timer/agent.policy_total": 18.7399742603302, "timer/agent.policy_frac": 0.018640539629036477, "timer/agent.policy_avg": 0.015976107638815174, "timer/agent.policy_min": 0.009537935256958008, "timer/agent.policy_max": 0.05596351623535156, "timer/dataset_train_count": 1864.0, "timer/dataset_train_total": 0.30298376083374023, "timer/dataset_train_frac": 0.0003013761236978524, "timer/dataset_train_avg": 0.00016254493606960313, "timer/dataset_train_min": 9.655952453613281e-05, "timer/dataset_train_max": 0.0008566379547119141, "timer/agent.train_count": 1864.0, "timer/agent.train_total": 838.4217746257782, "timer/agent.train_frac": 0.8339730940208628, "timer/agent.train_avg": 0.4497970893915119, "timer/agent.train_min": 0.4385080337524414, "timer/agent.train_max": 0.9942965507507324, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47766542434692383, "timer/agent.report_frac": 0.0004751309232482623, "timer/agent.report_avg": 0.23883271217346191, "timer/agent.report_min": 0.23137760162353516, "timer/agent.report_max": 0.24628782272338867, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9325485229492188e-05, "timer/dataset_eval_frac": 2.916988369179548e-08, "timer/dataset_eval_avg": 2.9325485229492188e-05, "timer/dataset_eval_min": 2.9325485229492188e-05, "timer/dataset_eval_max": 2.9325485229492188e-05, "fps": 7.416325720606833}
{"step": 330384, "time": 44421.96542906761, "episode/length": 135.0, "episode/score": 5.24834537497145, "episode/reward_rate": 0.9926470588235294, "episode/intrinsic_return": 0.14834521402144674}
{"step": 330584, "time": 44447.7825858593, "episode/length": 169.0, "episode/score": 5.292668129948652, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.19266797851560113}
{"step": 330584, "time": 44447.791504621506, "episode/length": 164.0, "episode/score": 7.268616686049427, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.1686164761758846}
{"step": 330888, "time": 44487.967114686966, "episode/length": 221.0, "episode/score": 5.333273966508841, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.23327374928658173}
{"step": 330904, "time": 44491.60210227966, "episode/length": 175.0, "episode/score": 6.283897836159213, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.1838977353086193}
{"step": 330984, "time": 44502.74762678146, "episode/length": 175.0, "episode/score": 4.298927075787105, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.1989269228406556}
{"step": 331624, "time": 44582.51985883713, "episode/length": 228.0, "episode/score": 6.343497148897313, "episode/reward_rate": 0.982532751091703, "episode/intrinsic_return": 0.24349690676217506}
{"step": 331768, "time": 44601.6277782917, "episode/length": 208.0, "episode/score": 8.33540380869863, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.23540354527403906}
{"step": 331768, "time": 44601.63503789902, "episode/length": 147.0, "episode/score": 6.24957087718758, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.14957066580063838}
{"step": 332120, "time": 44647.73710107803, "episode/length": 191.0, "episode/score": 5.314239037564221, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.21423885481544858}
{"step": 332216, "time": 44660.962799310684, "episode/length": 228.0, "episode/score": 7.351814483538419, "episode/reward_rate": 0.9737991266375546, "episode/intrinsic_return": 0.25181421440947815}
{"step": 332336, "time": 44677.094691991806, "episode/length": 168.0, "episode/score": 6.28422342611475, "episode/reward_rate": 0.9644970414201184, "episode/intrinsic_return": 0.18422326385507404}
{"step": 332960, "time": 44754.58670473099, "episode/length": 166.0, "episode/score": 4.2483372433753175, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.14833714979340584}
{"step": 332984, "time": 44759.00600743294, "episode/length": 261.0, "episode/score": 7.375270493320386, "episode/reward_rate": 0.9809160305343512, "episode/intrinsic_return": 0.2752703091600779}
{"step": 333360, "time": 44806.34798288345, "episode/length": 198.0, "episode/score": 5.334458501951303, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.23445832898141816}
{"step": 333456, "time": 44819.595900774, "episode/length": 318.0, "episode/score": 7.454102997159225, "episode/reward_rate": 0.9937304075235109, "episode/intrinsic_return": 0.3541027594624211}
{"step": 333512, "time": 44827.99235987663, "episode/length": 161.0, "episode/score": 8.28183092774998, "episode/reward_rate": 0.9567901234567902, "episode/intrinsic_return": 0.18183069738734048}
{"step": 333600, "time": 44840.15042209625, "episode/length": 184.0, "episode/score": 6.287318431554013, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.1873182342533255}
{"step": 333728, "time": 44857.32883262634, "episode/length": 173.0, "episode/score": 4.272816691969638, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.1728165691747563}
{"step": 334232, "time": 44920.564671993256, "episode/length": 307.0, "episode/score": 7.4601251957356, "episode/reward_rate": 0.9967532467532467, "episode/intrinsic_return": 0.36012499331263825}
{"step": 334400, "time": 44942.556503772736, "episode/length": 176.0, "episode/score": 5.3075841019744985, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.20758397068129852}
{"step": 334456, "time": 44950.866503953934, "episode/length": 186.0, "episode/score": 5.3058736321982, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.20587350719142705}
{"step": 334712, "time": 44983.57964515686, "episode/length": 168.0, "episode/score": 5.269523931725416, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.16952377912821248}
{"step": 334928, "time": 45011.49664020538, "episode/length": 183.0, "episode/score": 6.3085722772848385, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.20857209954192513}
{"step": 335048, "time": 45027.71925497055, "episode/length": 191.0, "episode/score": 3.3072991254848603, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.2072990336564544}
{"step": 335112, "time": 45037.069093465805, "episode/length": 49.0, "episode/score": 4.162083524162881, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.062083331984467804}
{"step": 335216, "time": 45051.20941066742, "episode/length": 201.0, "episode/score": 5.303593304979586, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.20359312339496682}
{"step": 335584, "time": 45097.5429854393, "episode/length": 168.0, "episode/score": 6.286383893340826, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.18638377817114815}
{"step": 335704, "time": 45113.695583343506, "episode/length": 162.0, "episode/score": 5.284673833928537, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.18467363499803469}
{"step": 335888, "time": 45138.86286044121, "episode/length": 269.0, "episode/score": 8.395684649054601, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.2956843835345353}
{"step": 336104, "time": 45166.49395108223, "episode/length": 205.0, "episode/score": 8.319013628828543, "episode/reward_rate": 0.9805825242718447, "episode/intrinsic_return": 0.21901339666146669}
{"step": 336256, "time": 45186.61077332497, "episode/length": 150.0, "episode/score": 5.255376447639719, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.15537626570585417}
{"step": 336464, "time": 45213.48571443558, "episode/length": 155.0, "episode/score": 6.271156371358302, "episode/reward_rate": 0.9551282051282052, "episode/intrinsic_return": 0.17115619827200135}
{"step": 336472, "time": 45215.971024274826, "episode/length": 169.0, "episode/score": 4.273837914413889, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.1738377603032859}
{"step": 337120, "time": 45296.35294628143, "episode/length": 191.0, "episode/score": 7.310168903120939, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.2101686642599816}
{"step": 337384, "time": 45329.98222780228, "episode/length": 209.0, "episode/score": 6.330744249686177, "episode/reward_rate": 0.9809523809523809, "episode/intrinsic_return": 0.23074408276988834}
{"step": 337608, "time": 45358.83022093773, "episode/length": 214.0, "episode/score": 7.331160471556359, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.2311601934634382}
{"step": 337824, "time": 45386.657690525055, "episode/length": 195.0, "episode/score": 6.312313517692019, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.2123133712066192}
{"step": 337825, "time": 45389.36725640297, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.55672126730489, "train/action_min": 0.0, "train/action_std": 3.6370605693579954, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.054625287478297486, "train/actor_opt_grad_steps": 83100.0, "train/actor_opt_loss": -9.154784718349847, "train/adv_mag": 0.6228084721713486, "train/adv_max": 0.5971539071495668, "train/adv_mean": 0.0038093032274356623, "train/adv_min": -0.47656119456562973, "train/adv_std": 0.06762553178198596, "train/cont_avg": 0.9945555375647669, "train/cont_loss_mean": 4.441957744746828e-05, "train/cont_loss_std": 0.001309921481629258, "train/cont_neg_acc": 0.9986979166666666, "train/cont_neg_loss": 0.0026911378223128204, "train/cont_pos_acc": 0.9999897980319403, "train/cont_pos_loss": 3.337199296941734e-05, "train/cont_pred": 0.994546160487931, "train/cont_rate": 0.9945555375647669, "train/dyn_loss_mean": 6.580406858513392, "train/dyn_loss_std": 8.74705825321415, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0559333772856954, "train/extr_critic_critic_opt_grad_steps": 83100.0, "train/extr_critic_critic_opt_loss": 16043.15076505829, "train/extr_critic_mag": 6.486906664359137, "train/extr_critic_max": 6.486906664359137, "train/extr_critic_mean": 1.309611263670452, "train/extr_critic_min": -0.5840602971111555, "train/extr_critic_std": 1.3967083856231808, "train/extr_return_normed_mag": 1.7479992376090332, "train/extr_return_normed_max": 1.7479992376090332, "train/extr_return_normed_mean": 0.3498025883973571, "train/extr_return_normed_min": -0.16847580184899463, "train/extr_return_normed_std": 0.33427682071152126, "train/extr_return_rate": 0.5901143174097327, "train/extr_return_raw_mag": 7.330732491349927, "train/extr_return_raw_max": 7.330732491349927, "train/extr_return_raw_mean": 1.325914879228167, "train/extr_return_raw_min": -0.9004405319999537, "train/extr_return_raw_std": 1.436308568932232, "train/extr_reward_mag": 1.0263363141470006, "train/extr_reward_max": 1.0263363141470006, "train/extr_reward_mean": 0.03300575876290007, "train/extr_reward_min": -0.6624969744311713, "train/extr_reward_std": 0.17531408485353303, "train/image_loss_mean": 3.631183246256774, "train/image_loss_std": 8.52502267224801, "train/model_loss_mean": 7.656470493949139, "train/model_loss_std": 12.524253904510656, "train/model_opt_grad_norm": 40.89366390050384, "train/model_opt_grad_steps": 83024.44559585492, "train/model_opt_loss": 9916.788493260201, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1301.8134715025906, "train/policy_entropy_mag": 2.470959119846166, "train/policy_entropy_max": 2.470959119846166, "train/policy_entropy_mean": 0.48968710028445783, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.5525290159981485, "train/policy_logprob_mag": 7.438383954794296, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.4907299703266954, "train/policy_logprob_min": -7.438383954794296, "train/policy_logprob_std": 1.0662502754537553, "train/policy_randomness_mag": 0.8721401357897822, "train/policy_randomness_max": 0.8721401357897822, "train/policy_randomness_mean": 0.1728380561029355, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.19501849599761667, "train/post_ent_mag": 60.28155468164948, "train/post_ent_max": 60.28155468164948, "train/post_ent_mean": 43.139376289486265, "train/post_ent_min": 19.406551790978625, "train/post_ent_std": 7.088174288754636, "train/prior_ent_mag": 74.49550992343092, "train/prior_ent_max": 74.49550992343092, "train/prior_ent_mean": 49.69966414061235, "train/prior_ent_min": 30.06370345792622, "train/prior_ent_std": 7.065241166347049, "train/rep_loss_mean": 6.580406858513392, "train/rep_loss_std": 8.74705825321415, "train/reward_avg": 0.022459013223493654, "train/reward_loss_mean": 0.0769987790000871, "train/reward_loss_std": 0.1844555245316708, "train/reward_max_data": 1.0121287014817943, "train/reward_max_pred": 1.0113230393958215, "train/reward_neg_acc": 0.998502080304635, "train/reward_neg_loss": 0.052634845010048364, "train/reward_pos_acc": 0.8876793294990618, "train/reward_pos_loss": 0.7645996645324589, "train/reward_pred": 0.022065363971545442, "train/reward_rate": 0.0342808856865285, "train_stats/sum_log_reward": 5.863157862111142, "train_stats/max_log_achievement_collect_drink": 5.0, "train_stats/max_log_achievement_collect_sapling": 2.3157894736842106, "train_stats/max_log_achievement_collect_stone": 0.05263157894736842, "train_stats/max_log_achievement_collect_wood": 7.026315789473684, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.15789473684210525, "train_stats/max_log_achievement_eat_cow": 0.07894736842105263, "train_stats/max_log_achievement_make_wood_pickaxe": 0.6052631578947368, "train_stats/max_log_achievement_make_wood_sword": 0.5, "train_stats/max_log_achievement_place_plant": 2.0789473684210527, "train_stats/max_log_achievement_place_table": 2.1052631578947367, "train_stats/max_log_achievement_wake_up": 1.736842105263158, "train_stats/mean_log_entropy": 0.4408128598802968, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 1.7149284303741297e-06, "report/cont_loss_std": 2.214556843682658e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 2.5865432689897716e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.5725876210126444e-06, "report/cont_pred": 0.9941393136978149, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 6.175602912902832, "report/dyn_loss_std": 8.35413932800293, "report/image_loss_mean": 3.413114547729492, "report/image_loss_std": 7.802470684051514, "report/model_loss_mean": 7.202632904052734, "report/model_loss_std": 11.616198539733887, "report/post_ent_mag": 60.51055145263672, "report/post_ent_max": 60.51055145263672, "report/post_ent_mean": 42.394073486328125, "report/post_ent_min": 17.653732299804688, "report/post_ent_std": 6.72999382019043, "report/prior_ent_mag": 74.38689422607422, "report/prior_ent_max": 74.38689422607422, "report/prior_ent_mean": 48.91679000854492, "report/prior_ent_min": 31.298851013183594, "report/prior_ent_std": 7.197690963745117, "report/rep_loss_mean": 6.175602912902832, "report/rep_loss_std": 8.35413932800293, "report/reward_avg": 0.028147105127573013, "report/reward_loss_mean": 0.08415552228689194, "report/reward_loss_std": 0.16352760791778564, "report/reward_max_data": 1.1012500524520874, "report/reward_max_pred": 1.099684476852417, "report/reward_neg_acc": 0.998976469039917, "report/reward_neg_loss": 0.05488281697034836, "report/reward_pos_acc": 0.9787233471870422, "report/reward_pos_loss": 0.692654013633728, "report/reward_pred": 0.028727103024721146, "report/reward_rate": 0.0458984375, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 3.323036071378738e-05, "eval/cont_loss_std": 0.0010289371712133288, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.008281022310256958, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 8.860770321916789e-07, "eval/cont_pred": 0.9961247444152832, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 19.7446231842041, "eval/dyn_loss_std": 12.166219711303711, "eval/image_loss_mean": 18.751508712768555, "eval/image_loss_std": 24.570816040039062, "eval/model_loss_mean": 30.712366104125977, "eval/model_loss_std": 29.53948974609375, "eval/post_ent_mag": 57.43019104003906, "eval/post_ent_max": 57.43019104003906, "eval/post_ent_mean": 40.93479537963867, "eval/post_ent_min": 22.294414520263672, "eval/post_ent_std": 6.739584445953369, "eval/prior_ent_mag": 74.38689422607422, "eval/prior_ent_max": 74.38689422607422, "eval/prior_ent_mean": 54.02800750732422, "eval/prior_ent_min": 35.82054901123047, "eval/prior_ent_std": 6.231989860534668, "eval/rep_loss_mean": 19.7446231842041, "eval/rep_loss_std": 12.166219711303711, "eval/reward_avg": 0.01455078087747097, "eval/reward_loss_mean": 0.11405061185359955, "eval/reward_loss_std": 0.686679482460022, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0036168098449707, "eval/reward_neg_acc": 0.9950199723243713, "eval/reward_neg_loss": 0.06112046539783478, "eval/reward_pos_acc": 0.699999988079071, "eval/reward_pos_loss": 2.771144390106201, "eval/reward_pred": 0.0116967111825943, "eval/reward_rate": 0.01953125, "replay/size": 337321.0, "replay/inserts": 7728.0, "replay/samples": 30912.0, "replay/insert_wait_avg": 1.5665038525441172e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.528248657597765e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 67280.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 9.834766387939453e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1002.0781910419464, "timer/env.step_count": 966.0, "timer/env.step_total": 83.07760906219482, "timer/env.step_frac": 0.08290531597720127, "timer/env.step_avg": 0.08600166569585385, "timer/env.step_min": 0.023468971252441406, "timer/env.step_max": 3.2214393615722656, "timer/replay._sample_count": 30912.0, "timer/replay._sample_total": 14.898801326751709, "timer/replay._sample_frac": 0.01486790298395792, "timer/replay._sample_avg": 0.0004819746806014399, "timer/replay._sample_min": 0.00035381317138671875, "timer/replay._sample_max": 0.011173486709594727, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 966.0, "timer/agent.policy_total": 15.436506032943726, "timer/agent.policy_frac": 0.01540449255451121, "timer/agent.policy_avg": 0.015979819909879633, "timer/agent.policy_min": 0.014632225036621094, "timer/agent.policy_max": 0.044167518615722656, "timer/dataset_train_count": 1932.0, "timer/dataset_train_total": 0.30663108825683594, "timer/dataset_train_frac": 0.00030599517183185613, "timer/dataset_train_avg": 0.00015871174340415938, "timer/dataset_train_min": 9.298324584960938e-05, "timer/dataset_train_max": 0.0008740425109863281, "timer/agent.train_count": 1932.0, "timer/agent.train_total": 870.0950555801392, "timer/agent.train_frac": 0.8682905818710882, "timer/agent.train_avg": 0.45035975961704927, "timer/agent.train_min": 0.4401383399963379, "timer/agent.train_max": 0.9654905796051025, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4794125556945801, "timer/agent.report_frac": 0.0004784183110462606, "timer/agent.report_avg": 0.23970627784729004, "timer/agent.report_min": 0.2336876392364502, "timer/agent.report_max": 0.24572491645812988, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.86102294921875e-05, "timer/dataset_eval_frac": 2.8550895277382493e-08, "timer/dataset_eval_avg": 2.86102294921875e-05, "timer/dataset_eval_min": 2.86102294921875e-05, "timer/dataset_eval_max": 2.86102294921875e-05, "fps": 7.711859327146219}
{"step": 337928, "time": 45401.78758573532, "episode/length": 182.0, "episode/score": 5.282531903814743, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.18253176553662342}
{"step": 338016, "time": 45413.88627052307, "episode/length": 192.0, "episode/score": 7.31803062405379, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.2180304220673861}
{"step": 338408, "time": 45463.36496543884, "episode/length": 287.0, "episode/score": 6.437114319205648, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.3371141519401135}
{"step": 338488, "time": 45474.616448163986, "episode/length": 444.0, "episode/score": 6.498311006910626, "episode/reward_rate": 0.9955056179775281, "episode/intrinsic_return": 0.39831091840005683}
{"step": 338688, "time": 45500.24834704399, "episode/length": 195.0, "episode/score": 5.2981727945953025, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.19817272471118486}
{"step": 338888, "time": 45526.31350016594, "episode/length": 187.0, "episode/score": 8.29964460904921, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.19964437053749862}
{"step": 339128, "time": 45557.06187868118, "episode/length": 189.0, "episode/score": 6.326154429392773, "episode/reward_rate": 0.9578947368421052, "episode/intrinsic_return": 0.2261542597989319}
{"step": 339648, "time": 45621.85003352165, "episode/length": 203.0, "episode/score": 5.323021926844376, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.22302171860064846}
{"step": 339776, "time": 45639.04811787605, "episode/length": 160.0, "episode/score": 7.280083337709584, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.18008312900019519}
{"step": 339872, "time": 45652.50201487541, "episode/length": 147.0, "episode/score": 5.251728584049488, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.15172840246486885}
{"step": 340056, "time": 45676.2536816597, "episode/length": 205.0, "episode/score": 4.2947981628440175, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.19479800989756768}
{"step": 340056, "time": 45676.2638027668, "episode/length": 265.0, "episode/score": 7.41130661639545, "episode/reward_rate": 0.9774436090225563, "episode/intrinsic_return": 0.3113063899909321}
{"step": 340080, "time": 45701.38444638252, "eval_episode/length": 154.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.967741935483871}
{"step": 340080, "time": 45703.195038318634, "eval_episode/length": 160.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.968944099378882}
{"step": 340080, "time": 45705.10985994339, "eval_episode/length": 171.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9593023255813954}
{"step": 340080, "time": 45707.09651327133, "eval_episode/length": 183.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9945652173913043}
{"step": 340080, "time": 45709.03987288475, "eval_episode/length": 193.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.979381443298969}
{"step": 340080, "time": 45710.87509584427, "eval_episode/length": 46.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.8936170212765957}
{"step": 340080, "time": 45712.513053417206, "eval_episode/length": 204.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.975609756097561}
{"step": 340080, "time": 45714.32833504677, "eval_episode/length": 212.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9765258215962441}
{"step": 340080, "time": 45714.333879709244, "eval_episode/length": 40.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.975609756097561}
{"step": 340256, "time": 45735.63961315155, "episode/length": 303.0, "episode/score": 6.438610783396143, "episode/reward_rate": 0.9868421052631579, "episode/intrinsic_return": 0.33861057200920186}
{"step": 340504, "time": 45767.17578268051, "episode/length": 171.0, "episode/score": 7.273637011910978, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.17363680320158892}
{"step": 340616, "time": 45782.4118847847, "episode/length": 92.0, "episode/score": 4.195585439818387, "episode/reward_rate": 0.989247311827957, "episode/intrinsic_return": 0.0955853347768425}
{"step": 341040, "time": 45835.65149092674, "episode/length": 157.0, "episode/score": 4.237017272589583, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.13701713279806427}
{"step": 341064, "time": 45840.15611767769, "episode/length": 271.0, "episode/score": 6.4144230186084314, "episode/reward_rate": 0.9852941176470589, "episode/intrinsic_return": 0.314422851692143}
{"step": 341200, "time": 45858.098551511765, "episode/length": 193.0, "episode/score": 5.308802743937122, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.20880250903428532}
{"step": 341392, "time": 45882.99739956856, "episode/length": 166.0, "episode/score": 6.257224926991512, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.1572248106576808}
{"step": 341416, "time": 45887.40905022621, "episode/length": 169.0, "episode/score": 6.280219790141018, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.18021961006979836}
{"step": 341504, "time": 45899.649209976196, "episode/length": 155.0, "episode/score": 7.279008361007072, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.17900812389234488}
{"step": 341856, "time": 45943.68133020401, "episode/length": 154.0, "episode/score": 5.268601218180265, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.16860103484941646}
{"step": 341960, "time": 45957.66428518295, "episode/length": 181.0, "episode/score": 5.314825544133782, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.21482539270073175}
{"step": 342280, "time": 45997.87061858177, "episode/length": 151.0, "episode/score": 6.258392757437832, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.15839257736661239}
{"step": 342344, "time": 46007.156881809235, "episode/length": 162.0, "episode/score": 8.278423107622075, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.1784228134638397}
{"step": 342432, "time": 46019.3116877079, "episode/length": 153.0, "episode/score": 5.280492971996864, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.18049279041224509}
{"step": 342888, "time": 46076.047033548355, "episode/length": 183.0, "episode/score": 5.319815620867303, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.21981547176255845}
{"step": 343032, "time": 46095.13568544388, "episode/length": 190.0, "episode/score": 5.31833346845815, "episode/reward_rate": 0.9581151832460733, "episode/intrinsic_return": 0.21833332948153839}
{"step": 343072, "time": 46101.485578775406, "episode/length": 209.0, "episode/score": 6.340363710747624, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.24036350052483613}
{"step": 343192, "time": 46117.686876297, "episode/length": 166.0, "episode/score": 7.265831334567338, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.16583110234205378}
{"step": 343320, "time": 46134.7855887413, "episode/length": 169.0, "episode/score": 6.27188931528508, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.1718891035488923}
{"step": 343608, "time": 46171.42176771164, "episode/length": 165.0, "episode/score": 5.289269729326406, "episode/reward_rate": 0.9578313253012049, "episode/intrinsic_return": 0.18926953353911813}
{"step": 343952, "time": 46214.761647224426, "episode/length": 78.0, "episode/score": 5.1897842893649795, "episode/reward_rate": 0.9367088607594937, "episode/intrinsic_return": 0.08978413793192885}
{"step": 344320, "time": 46262.168909072876, "episode/length": 160.0, "episode/score": 6.261983757394773, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.16198357732355362}
{"step": 344368, "time": 46269.56835889816, "episode/length": 252.0, "episode/score": 8.367498065481414, "episode/reward_rate": 0.9841897233201581, "episode/intrinsic_return": 0.26749782696970215}
{"step": 344400, "time": 46275.017691612244, "episode/length": 188.0, "episode/score": 6.286779810727239, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.1867796326350799}
{"step": 344640, "time": 46305.78510260582, "episode/length": 195.0, "episode/score": 4.324415008084543, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.2244148876179679}
{"step": 344840, "time": 46331.68078446388, "episode/length": 205.0, "episode/score": 6.322505176600316, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.22250494204672577}
{"step": 345297, "time": 46389.54276585579, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.344286260757854, "train/action_min": 0.0, "train/action_std": 3.421585114881954, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0526786040773685, "train/actor_opt_grad_steps": 85000.0, "train/actor_opt_loss": -11.9267975151499, "train/adv_mag": 0.5977652511175942, "train/adv_max": 0.577207477016245, "train/adv_mean": 0.0024277230427700983, "train/adv_min": -0.45930848242764805, "train/adv_std": 0.06483189572385925, "train/cont_avg": 0.9946367396390374, "train/cont_loss_mean": 6.114348929274801e-05, "train/cont_loss_std": 0.0018599256022151381, "train/cont_neg_acc": 0.9992319512110884, "train/cont_neg_loss": 0.007624597216572975, "train/cont_pos_acc": 0.9999999821504807, "train/cont_pos_loss": 1.120250094446309e-05, "train/cont_pred": 0.9946375017497628, "train/cont_rate": 0.9946367396390374, "train/dyn_loss_mean": 6.563895075078954, "train/dyn_loss_std": 8.76969412686353, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0295299074866555, "train/extr_critic_critic_opt_grad_steps": 85000.0, "train/extr_critic_critic_opt_loss": 16058.103526069519, "train/extr_critic_mag": 6.630313707545479, "train/extr_critic_max": 6.630313707545479, "train/extr_critic_mean": 1.268376880788548, "train/extr_critic_min": -0.5901545719666914, "train/extr_critic_std": 1.461059054588889, "train/extr_return_normed_mag": 1.7271360688031039, "train/extr_return_normed_max": 1.7271360688031039, "train/extr_return_normed_mean": 0.32885563732149764, "train/extr_return_normed_min": -0.15443243444922136, "train/extr_return_normed_std": 0.334831474219414, "train/extr_return_rate": 0.5494147902504009, "train/extr_return_raw_mag": 7.5165415881151825, "train/extr_return_raw_max": 7.5165415881151825, "train/extr_return_raw_mean": 1.2791800852765374, "train/extr_return_raw_min": -0.8770381655285066, "train/extr_return_raw_std": 1.4939905459230596, "train/extr_reward_mag": 1.0253079562263692, "train/extr_reward_max": 1.0253079562263692, "train/extr_reward_mean": 0.032689634805176664, "train/extr_reward_min": -0.648173531108999, "train/extr_reward_std": 0.17516544054855, "train/image_loss_mean": 3.6300440178835456, "train/image_loss_std": 8.496955614038967, "train/model_loss_mean": 7.645399001830402, "train/model_loss_std": 12.518810088621741, "train/model_opt_grad_norm": 40.19311567296319, "train/model_opt_grad_steps": 84922.71122994652, "train/model_opt_loss": 11023.717637658756, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1443.850267379679, "train/policy_entropy_mag": 2.4655534940607406, "train/policy_entropy_max": 2.4655534940607406, "train/policy_entropy_mean": 0.4865222302350131, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.5580721185169119, "train/policy_logprob_mag": 7.438384007642614, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.48630035417602663, "train/policy_logprob_min": -7.438384007642614, "train/policy_logprob_std": 1.0614553144908845, "train/policy_randomness_mag": 0.8702321862154466, "train/policy_randomness_max": 0.8702321862154466, "train/policy_randomness_mean": 0.1717209983716674, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.19697496773087406, "train/post_ent_mag": 60.382819252218155, "train/post_ent_max": 60.382819252218155, "train/post_ent_mean": 43.32129081685275, "train/post_ent_min": 19.17071343488234, "train/post_ent_std": 7.1118446594891065, "train/prior_ent_mag": 74.52118213673964, "train/prior_ent_max": 74.52118213673964, "train/prior_ent_mean": 49.84631274218228, "train/prior_ent_min": 30.070059057225517, "train/prior_ent_std": 7.0743736149793, "train/rep_loss_mean": 6.563895075078954, "train/rep_loss_std": 8.76969412686353, "train/reward_avg": 0.022344533939233278, "train/reward_loss_mean": 0.07695679854661386, "train/reward_loss_std": 0.18594576390509937, "train/reward_max_data": 1.0162188382072246, "train/reward_max_pred": 1.0147130387352112, "train/reward_neg_acc": 0.9987732175199743, "train/reward_neg_loss": 0.05327319756229931, "train/reward_pos_acc": 0.8925771885377201, "train/reward_pos_loss": 0.7562060222268742, "train/reward_pred": 0.022048508061125953, "train/reward_rate": 0.03361568348930481, "train_stats/sum_log_reward": 5.889473588843095, "train_stats/max_log_achievement_collect_drink": 4.394736842105263, "train_stats/max_log_achievement_collect_sapling": 2.736842105263158, "train_stats/max_log_achievement_collect_stone": 0.05263157894736842, "train_stats/max_log_achievement_collect_wood": 7.552631578947368, "train_stats/max_log_achievement_defeat_skeleton": 0.02631578947368421, "train_stats/max_log_achievement_defeat_zombie": 0.21052631578947367, "train_stats/max_log_achievement_eat_cow": 0.10526315789473684, "train_stats/max_log_achievement_make_wood_pickaxe": 0.7894736842105263, "train_stats/max_log_achievement_make_wood_sword": 0.5789473684210527, "train_stats/max_log_achievement_place_plant": 2.3421052631578947, "train_stats/max_log_achievement_place_table": 2.210526315789474, "train_stats/max_log_achievement_wake_up": 1.6578947368421053, "train_stats/mean_log_entropy": 0.4326014652063972, "eval_stats/sum_log_reward": 5.099999957614475, "eval_stats/max_log_achievement_collect_drink": 3.0, "eval_stats/max_log_achievement_collect_sapling": 2.6666666666666665, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 4.555555555555555, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.1111111111111111, "eval_stats/max_log_achievement_make_wood_sword": 0.5555555555555556, "eval_stats/max_log_achievement_place_plant": 2.3333333333333335, "eval_stats/max_log_achievement_place_table": 1.3333333333333333, "eval_stats/max_log_achievement_wake_up": 1.1111111111111112, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 8.619323921266187e-07, "report/cont_loss_std": 1.9330615032231435e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0001663008879404515, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 5.0161226283762517e-08, "report/cont_pred": 0.9951180219650269, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 6.29898738861084, "report/dyn_loss_std": 8.488927841186523, "report/image_loss_mean": 2.747762441635132, "report/image_loss_std": 7.952264308929443, "report/model_loss_mean": 6.59979248046875, "report/model_loss_std": 12.138751029968262, "report/post_ent_mag": 60.230552673339844, "report/post_ent_max": 60.230552673339844, "report/post_ent_mean": 43.36516571044922, "report/post_ent_min": 23.30103302001953, "report/post_ent_std": 7.381778240203857, "report/prior_ent_mag": 74.39302825927734, "report/prior_ent_max": 74.39302825927734, "report/prior_ent_mean": 49.791160583496094, "report/prior_ent_min": 30.481460571289062, "report/prior_ent_std": 6.896280288696289, "report/rep_loss_mean": 6.29898738861084, "report/rep_loss_std": 8.488927841186523, "report/reward_avg": 0.02484750747680664, "report/reward_loss_mean": 0.07263709604740143, "report/reward_loss_std": 0.1455451250076294, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0030038356781006, "report/reward_neg_acc": 0.9979776740074158, "report/reward_neg_loss": 0.049888961017131805, "report/reward_pos_acc": 0.8571428656578064, "report/reward_pos_loss": 0.7154343724250793, "report/reward_pred": 0.02497110888361931, "report/reward_rate": 0.0341796875, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.0006885501788929105, "eval/cont_loss_std": 0.02192176878452301, "eval/cont_neg_acc": 0.8333333730697632, "eval/cont_neg_loss": 0.11748731136322021, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.487539122990711e-07, "eval/cont_pred": 0.994636058807373, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 18.576946258544922, "eval/dyn_loss_std": 12.85733413696289, "eval/image_loss_mean": 20.446651458740234, "eval/image_loss_std": 28.603527069091797, "eval/model_loss_mean": 31.739789962768555, "eval/model_loss_std": 32.8383674621582, "eval/post_ent_mag": 59.71782302856445, "eval/post_ent_max": 59.71782302856445, "eval/post_ent_mean": 40.84317398071289, "eval/post_ent_min": 20.768321990966797, "eval/post_ent_std": 7.617122173309326, "eval/prior_ent_mag": 74.39302825927734, "eval/prior_ent_max": 74.39302825927734, "eval/prior_ent_mean": 53.43766403198242, "eval/prior_ent_min": 30.705596923828125, "eval/prior_ent_std": 6.681766510009766, "eval/rep_loss_mean": 18.576946258544922, "eval/rep_loss_std": 12.85733413696289, "eval/reward_avg": 0.03623046725988388, "eval/reward_loss_mean": 0.14628025889396667, "eval/reward_loss_std": 0.8427476286888123, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0052835941314697, "eval/reward_neg_acc": 0.9969450831413269, "eval/reward_neg_loss": 0.06986520439386368, "eval/reward_pos_acc": 0.8333333730697632, "eval/reward_pos_loss": 1.9329369068145752, "eval/reward_pred": 0.029202595353126526, "eval/reward_rate": 0.041015625, "replay/size": 344793.0, "replay/inserts": 7472.0, "replay/samples": 29888.0, "replay/insert_wait_avg": 1.5448387991437566e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.54534815312453e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 68984.0, "eval_replay/inserts": 1704.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2766027674428735e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.599592208862305e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1602358818054, "timer/env.step_count": 934.0, "timer/env.step_total": 83.07054400444031, "timer/env.step_frac": 0.08305723525510889, "timer/env.step_avg": 0.08894062527242003, "timer/env.step_min": 0.023360013961791992, "timer/env.step_max": 3.32739520072937, "timer/replay._sample_count": 29888.0, "timer/replay._sample_total": 14.45015549659729, "timer/replay._sample_frac": 0.01444784043414514, "timer/replay._sample_avg": 0.0004834768300521042, "timer/replay._sample_min": 0.0003285408020019531, "timer/replay._sample_max": 0.009623289108276367, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1147.0, "timer/agent.policy_total": 18.481077909469604, "timer/agent.policy_frac": 0.018478117052089658, "timer/agent.policy_avg": 0.01611253523057507, "timer/agent.policy_min": 0.009737730026245117, "timer/agent.policy_max": 0.056853294372558594, "timer/dataset_train_count": 1868.0, "timer/dataset_train_total": 0.2912755012512207, "timer/dataset_train_frac": 0.0002912288359418864, "timer/dataset_train_avg": 0.0001559290691923023, "timer/dataset_train_min": 9.202957153320312e-05, "timer/dataset_train_max": 0.0012319087982177734, "timer/agent.train_count": 1868.0, "timer/agent.train_total": 837.768079996109, "timer/agent.train_frac": 0.8376338609957623, "timer/agent.train_avg": 0.448483982867296, "timer/agent.train_min": 0.4354712963104248, "timer/agent.train_max": 0.9885640144348145, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4835786819458008, "timer/agent.report_frac": 0.0004835012077034304, "timer/agent.report_avg": 0.2417893409729004, "timer/agent.report_min": 0.23615741729736328, "timer/agent.report_max": 0.2474212646484375, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.2649765014648438e-05, "timer/dataset_eval_frac": 2.264613629103036e-08, "timer/dataset_eval_avg": 2.2649765014648438e-05, "timer/dataset_eval_min": 2.2649765014648438e-05, "timer/dataset_eval_max": 2.2649765014648438e-05, "fps": 7.470676402164794}
{"step": 345312, "time": 46391.22513103485, "episode/length": 169.0, "episode/score": 3.295935792273667, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.19593569811695488}
{"step": 345688, "time": 46438.025950193405, "episode/length": 160.0, "episode/score": 3.2791611043294324, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.17916098002115177}
{"step": 345816, "time": 46455.180872917175, "episode/length": 186.0, "episode/score": 5.321972500899392, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.2219723739717665}
{"step": 345944, "time": 46472.20883464813, "episode/length": 438.0, "episode/score": 7.507126299640731, "episode/reward_rate": 0.9931662870159453, "episode/intrinsic_return": 0.4071261068293097}
{"step": 346160, "time": 46499.84339094162, "episode/length": 189.0, "episode/score": 6.313025015419953, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.21302483418457996}
{"step": 346264, "time": 46513.996128082275, "episode/length": 331.0, "episode/score": 6.478458674457215, "episode/reward_rate": 0.9849397590361446, "episode/intrinsic_return": 0.37845850137091475}
{"step": 346296, "time": 46519.333332300186, "episode/length": 240.0, "episode/score": 8.357062183706148, "episode/reward_rate": 0.979253112033195, "episode/intrinsic_return": 0.25706199263368035}
{"step": 346648, "time": 46563.62134718895, "episode/length": 225.0, "episode/score": 6.362733360142556, "episode/reward_rate": 0.9690265486725663, "episode/intrinsic_return": 0.2627331864741791}
{"step": 346936, "time": 46600.12214446068, "episode/length": 202.0, "episode/score": 4.308178953777315, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.20817888237979787}
{"step": 347416, "time": 46660.13914871216, "episode/length": 215.0, "episode/score": 6.324570245817995, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.2245700344310535}
{"step": 347536, "time": 46676.148357629776, "episode/length": 214.0, "episode/score": 9.32738236878049, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.2273821300941563}
{"step": 347752, "time": 46704.096693992615, "episode/length": 185.0, "episode/score": 5.311447586881513, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.2114474041327412}
{"step": 348024, "time": 46738.79741191864, "episode/length": 259.0, "episode/score": 8.406124215249292, "episode/reward_rate": 0.9846153846153847, "episode/intrinsic_return": 0.3061240416391229}
{"step": 348080, "time": 46747.11409115791, "episode/length": 178.0, "episode/score": 4.3048254740242555, "episode/reward_rate": 0.9664804469273743, "episode/intrinsic_return": 0.20482535472183372}
{"step": 348496, "time": 46799.474405527115, "episode/length": 274.0, "episode/score": 7.3919663874576145, "episode/reward_rate": 0.9890909090909091, "episode/intrinsic_return": 0.2919661313671895}
{"step": 348784, "time": 46835.87612223625, "episode/length": 170.0, "episode/score": 6.27454269118607, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.174542531138286}
{"step": 349136, "time": 46880.21562099457, "episode/length": 43.0, "episode/score": 3.1527778720483184, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.052777776727452874}
{"step": 349448, "time": 46919.718140125275, "episode/length": 211.0, "episode/score": 7.330478865726036, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.23047861312807072}
{"step": 349512, "time": 46928.963450431824, "episode/length": 185.0, "episode/score": 8.30289972393075, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.20289945526747033}
{"step": 349680, "time": 46951.188369989395, "episode/length": 439.0, "episode/score": 6.540981543804264, "episode/reward_rate": 0.9863636363636363, "episode/intrinsic_return": 0.44098144318650156}
{"step": 350064, "time": 47016.46240091324, "eval_episode/length": 108.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9908256880733946}
{"step": 350064, "time": 47020.28601050377, "eval_episode/length": 143.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9583333333333334}
{"step": 350064, "time": 47022.47461795807, "eval_episode/length": 147.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.972972972972973}
{"step": 350064, "time": 47025.15397787094, "eval_episode/length": 161.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9691358024691358}
{"step": 350064, "time": 47027.44861245155, "eval_episode/length": 167.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9642857142857143}
{"step": 350064, "time": 47029.62009429932, "eval_episode/length": 170.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9941520467836257}
{"step": 350064, "time": 47032.86393356323, "eval_episode/length": 196.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9796954314720813}
{"step": 350064, "time": 47035.04033732414, "eval_episode/length": 199.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.995}
{"step": 350096, "time": 47039.00610160828, "episode/length": 251.0, "episode/score": 4.357425335852895, "episode/reward_rate": 0.9801587301587301, "episode/intrinsic_return": 0.25742520569474436}
{"step": 350248, "time": 47058.99709224701, "episode/length": 138.0, "episode/score": 7.25512870041166, "episode/reward_rate": 0.9568345323741008, "episode/intrinsic_return": 0.15512849519473093}
{"step": 350424, "time": 47081.81457781792, "episode/length": 435.0, "episode/score": 6.530679047418744, "episode/reward_rate": 0.6467889908256881, "episode/intrinsic_return": 0.43067888515906816}
{"step": 350456, "time": 47087.1257314682, "episode/length": 44.0, "episode/score": 1.1500278620515019, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.05002777697518468}
{"step": 350624, "time": 47109.00083899498, "episode/length": 265.0, "episode/score": 7.406657426035963, "episode/reward_rate": 0.9699248120300752, "episode/intrinsic_return": 0.30665719765238464}
{"step": 350944, "time": 47149.1846408844, "episode/length": 178.0, "episode/score": 7.297376193970194, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.19737592495766876}
{"step": 351064, "time": 47165.30079174042, "episode/length": 440.0, "episode/score": 8.537862742959078, "episode/reward_rate": 0.9886621315192744, "episode/intrinsic_return": 0.4378625149247455}
{"step": 351176, "time": 47180.30676198006, "episode/length": 215.0, "episode/score": 7.31891644053394, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.2189162256254349}
{"step": 351208, "time": 47185.79206585884, "episode/length": 190.0, "episode/score": 8.303960438606737, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.20396012710261857}
{"step": 351656, "time": 47241.630101680756, "episode/length": 153.0, "episode/score": 6.274921654190621, "episode/reward_rate": 0.9545454545454546, "episode/intrinsic_return": 0.17492145060350595}
{"step": 351752, "time": 47254.66589927673, "episode/length": 187.0, "episode/score": 8.30744039100955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.20744015599029808}
{"step": 351936, "time": 47278.50470304489, "episode/length": 184.0, "episode/score": 6.275967772408876, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.17596757534101926}
{"step": 352112, "time": 47301.31031823158, "episode/length": 44.0, "episode/score": 2.144528087170329, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.04452798835700378}
{"step": 352128, "time": 47304.687195301056, "episode/length": 187.0, "episode/score": 5.303504156961935, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.20350394510933256}
{"step": 352392, "time": 47339.53011512756, "episode/length": 165.0, "episode/score": 6.273191317365672, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.1731911504493837}
{"step": 352528, "time": 47357.50238466263, "episode/length": 168.0, "episode/score": 6.277799661534118, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.17779948029874504}
{"step": 352600, "time": 47367.61339879036, "episode/length": 173.0, "episode/score": 7.283090847160565, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.18309063845117635}
{"step": 352761, "time": 47389.62340974808, "train_stats/sum_log_reward": 5.991891867405659, "train_stats/max_log_achievement_collect_drink": 5.4324324324324325, "train_stats/max_log_achievement_collect_sapling": 2.5945945945945947, "train_stats/max_log_achievement_collect_stone": 0.05405405405405406, "train_stats/max_log_achievement_collect_wood": 7.243243243243243, "train_stats/max_log_achievement_defeat_skeleton": 0.02702702702702703, "train_stats/max_log_achievement_defeat_zombie": 0.40540540540540543, "train_stats/max_log_achievement_eat_cow": 0.21621621621621623, "train_stats/max_log_achievement_make_wood_pickaxe": 0.40540540540540543, "train_stats/max_log_achievement_make_wood_sword": 1.1081081081081081, "train_stats/max_log_achievement_place_plant": 2.189189189189189, "train_stats/max_log_achievement_place_table": 2.108108108108108, "train_stats/max_log_achievement_wake_up": 1.7027027027027026, "train_stats/mean_log_entropy": 0.5073704232235212, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.299810236150568, "train/action_min": 0.0, "train/action_std": 3.4462634662893366, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.052950185609055074, "train/actor_opt_grad_steps": 86870.0, "train/actor_opt_loss": -9.86481420476647, "train/adv_mag": 0.5839002755555239, "train/adv_max": 0.5636842634907381, "train/adv_mean": 0.0030986526761306956, "train/adv_min": -0.4617491805935926, "train/adv_std": 0.06543554513052822, "train/cont_avg": 0.9945479612299465, "train/cont_loss_mean": 8.529641712356653e-05, "train/cont_loss_std": 0.002554588858510352, "train/cont_neg_acc": 0.9982174692306927, "train/cont_neg_loss": 0.006819612183588174, "train/cont_pos_acc": 0.9999894461529778, "train/cont_pos_loss": 4.8076251157965775e-05, "train/cont_pred": 0.9945511241010166, "train/cont_rate": 0.9945479612299465, "train/dyn_loss_mean": 6.625613987764573, "train/dyn_loss_std": 8.736741547916024, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.020793677332567, "train/extr_critic_critic_opt_grad_steps": 86870.0, "train/extr_critic_critic_opt_loss": 16176.160166694519, "train/extr_critic_mag": 6.518252043800558, "train/extr_critic_max": 6.518252043800558, "train/extr_critic_mean": 1.2616408397169674, "train/extr_critic_min": -0.5981176128999435, "train/extr_critic_std": 1.4388938584429696, "train/extr_return_normed_mag": 1.7103439767092945, "train/extr_return_normed_max": 1.7103439767092945, "train/extr_return_normed_mean": 0.3310978504266331, "train/extr_return_normed_min": -0.15235302995711086, "train/extr_return_normed_std": 0.331535452428986, "train/extr_return_rate": 0.5553838306251057, "train/extr_return_raw_mag": 7.411161093788351, "train/extr_return_raw_max": 7.411161093788351, "train/extr_return_raw_mean": 1.2754400238633794, "train/extr_return_raw_min": -0.8746285596314598, "train/extr_return_raw_std": 1.4746692658745668, "train/extr_reward_mag": 1.022734803949448, "train/extr_reward_max": 1.022734803949448, "train/extr_reward_mean": 0.03343809074796936, "train/extr_reward_min": -0.651264729346821, "train/extr_reward_std": 0.17723495413594068, "train/image_loss_mean": 3.570554457246301, "train/image_loss_std": 8.463729065369794, "train/model_loss_mean": 7.623002261401497, "train/model_loss_std": 12.479597708758186, "train/model_opt_grad_norm": 42.57734556759105, "train/model_opt_grad_steps": 86791.19251336898, "train/model_opt_loss": 10914.963767964573, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1430.48128342246, "train/policy_entropy_mag": 2.499014795782732, "train/policy_entropy_max": 2.499014795782732, "train/policy_entropy_mean": 0.4913955815335646, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.5696528464715112, "train/policy_logprob_mag": 7.438383989793094, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.49112123888444137, "train/policy_logprob_min": -7.438383989793094, "train/policy_logprob_std": 1.0661627264583813, "train/policy_randomness_mag": 0.8820425584354502, "train/policy_randomness_max": 0.8820425584354502, "train/policy_randomness_mean": 0.17344107490809843, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.20106245680926318, "train/post_ent_mag": 60.31119963702034, "train/post_ent_max": 60.31119963702034, "train/post_ent_mean": 43.39271857521751, "train/post_ent_min": 18.961211133130732, "train/post_ent_std": 7.064410306553152, "train/prior_ent_mag": 74.48496715525255, "train/prior_ent_max": 74.48496715525255, "train/prior_ent_mean": 50.01447863247305, "train/prior_ent_min": 30.427807904819755, "train/prior_ent_std": 6.9963751578713484, "train/rep_loss_mean": 6.625613987764573, "train/rep_loss_std": 8.736741547916024, "train/reward_avg": 0.022804397606554835, "train/reward_loss_mean": 0.07699414165341918, "train/reward_loss_std": 0.1824764332430248, "train/reward_max_data": 1.0108756993543655, "train/reward_max_pred": 1.0098352903988272, "train/reward_neg_acc": 0.9985445215102823, "train/reward_neg_loss": 0.053146009876288196, "train/reward_pos_acc": 0.8934561626158933, "train/reward_pos_loss": 0.7464569730554672, "train/reward_pred": 0.022582992184209952, "train/reward_rate": 0.03444080046791444, "train_stats/max_log_achievement_place_stone": 0.037037037037037035, "train_stats/max_log_achievement_collect_coal": 0.05263157894736842, "eval_stats/sum_log_reward": 6.099999904632568, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 2.125, "eval_stats/max_log_achievement_collect_sapling": 2.75, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 8.375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.375, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.25, "eval_stats/max_log_achievement_make_wood_sword": 1.5, "eval_stats/max_log_achievement_place_plant": 2.75, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.25, "eval_stats/max_log_achievement_wake_up": 1.625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.990234375, "report/cont_loss_mean": 0.000717664253897965, "report/cont_loss_std": 0.022597160190343857, "report/cont_neg_acc": 0.9000000357627869, "report/cont_neg_loss": 0.07296653836965561, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 5.150614924787078e-06, "report/cont_pred": 0.9907382726669312, "report/cont_rate": 0.990234375, "report/dyn_loss_mean": 7.7413835525512695, "report/dyn_loss_std": 9.45913314819336, "report/image_loss_mean": 4.828761100769043, "report/image_loss_std": 10.802833557128906, "report/model_loss_mean": 9.562193870544434, "report/model_loss_std": 14.956982612609863, "report/post_ent_mag": 61.73103332519531, "report/post_ent_max": 61.73103332519531, "report/post_ent_mean": 42.830055236816406, "report/post_ent_min": 17.74456787109375, "report/post_ent_std": 7.1291351318359375, "report/prior_ent_mag": 74.43251037597656, "report/prior_ent_max": 74.43251037597656, "report/prior_ent_mean": 50.68444061279297, "report/prior_ent_min": 29.10649871826172, "report/prior_ent_std": 6.959015369415283, "report/rep_loss_mean": 7.7413835525512695, "report/rep_loss_std": 9.45913314819336, "report/reward_avg": 0.0265948548913002, "report/reward_loss_mean": 0.087884321808815, "report/reward_loss_std": 0.19406893849372864, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0018246173858643, "report/reward_neg_acc": 0.9989774823188782, "report/reward_neg_loss": 0.05661778897047043, "report/reward_pos_acc": 0.9347826242446899, "report/reward_pos_loss": 0.7526379823684692, "report/reward_pred": 0.025813531130552292, "report/reward_rate": 0.044921875, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.00011766677198465914, "eval/cont_loss_std": 0.0037312631029635668, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00010308922355761752, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.00011770960554713383, "eval/cont_pred": 0.9969600439071655, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 20.322654724121094, "eval/dyn_loss_std": 12.146175384521484, "eval/image_loss_mean": 25.2950439453125, "eval/image_loss_std": 32.273536682128906, "eval/model_loss_mean": 37.578609466552734, "eval/model_loss_std": 36.03160858154297, "eval/post_ent_mag": 56.23812484741211, "eval/post_ent_max": 56.23812484741211, "eval/post_ent_mean": 40.13715362548828, "eval/post_ent_min": 20.962173461914062, "eval/post_ent_std": 6.843747138977051, "eval/prior_ent_mag": 74.43251037597656, "eval/prior_ent_max": 74.43251037597656, "eval/prior_ent_mean": 53.21354675292969, "eval/prior_ent_min": 38.3856201171875, "eval/prior_ent_std": 5.622398853302002, "eval/rep_loss_mean": 20.322654724121094, "eval/rep_loss_std": 12.146175384521484, "eval/reward_avg": 0.02685546875, "eval/reward_loss_mean": 0.08985678851604462, "eval/reward_loss_std": 0.6730294823646545, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0024194717407227, "eval/reward_neg_acc": 0.9959757924079895, "eval/reward_neg_loss": 0.022070029750466347, "eval/reward_pos_acc": 0.7333333492279053, "eval/reward_pos_loss": 2.335858106613159, "eval/reward_pred": 0.020276859402656555, "eval/reward_rate": 0.029296875, "replay/size": 352257.0, "replay/inserts": 7464.0, "replay/samples": 29856.0, "replay/insert_wait_avg": 1.5944721614432871e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.45680937813026e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 70584.0, "eval_replay/inserts": 1600.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2142956256866454e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.195638656616211e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0661127567291, "timer/env.step_count": 933.0, "timer/env.step_total": 80.26226043701172, "timer/env.step_frac": 0.08025695442850776, "timer/env.step_avg": 0.08602600261201684, "timer/env.step_min": 0.023131132125854492, "timer/env.step_max": 1.6872751712799072, "timer/replay._sample_count": 29856.0, "timer/replay._sample_total": 14.414270639419556, "timer/replay._sample_frac": 0.014413317735250465, "timer/replay._sample_avg": 0.000482793094835864, "timer/replay._sample_min": 0.0003561973571777344, "timer/replay._sample_max": 0.03255200386047363, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1133.0, "timer/agent.policy_total": 18.227306604385376, "timer/agent.policy_frac": 0.018226101626562418, "timer/agent.policy_avg": 0.016087649253649933, "timer/agent.policy_min": 0.01010751724243164, "timer/agent.policy_max": 0.0623166561126709, "timer/dataset_train_count": 1866.0, "timer/dataset_train_total": 0.2858242988586426, "timer/dataset_train_frac": 0.00028580540347553074, "timer/dataset_train_avg": 0.00015317486541191992, "timer/dataset_train_min": 8.893013000488281e-05, "timer/dataset_train_max": 0.0013408660888671875, "timer/agent.train_count": 1866.0, "timer/agent.train_total": 836.6099617481232, "timer/agent.train_frac": 0.8365546548137388, "timer/agent.train_avg": 0.44834403094754727, "timer/agent.train_min": 0.4362525939941406, "timer/agent.train_max": 0.9605562686920166, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4777967929840088, "timer/agent.report_frac": 0.0004777652066091306, "timer/agent.report_avg": 0.2388983964920044, "timer/agent.report_min": 0.23241281509399414, "timer/agent.report_max": 0.24538397789001465, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0279159545898438e-05, "timer/dataset_eval_frac": 3.0277157839527746e-08, "timer/dataset_eval_avg": 3.0279159545898438e-05, "timer/dataset_eval_min": 3.0279159545898438e-05, "timer/dataset_eval_max": 3.0279159545898438e-05, "fps": 7.463404360649042}
{"step": 353040, "time": 47423.35608839989, "episode/length": 261.0, "episode/score": 5.3844843117931305, "episode/reward_rate": 0.9809160305343512, "episode/intrinsic_return": 0.2844841302085115}
{"step": 353336, "time": 47460.76774263382, "episode/length": 209.0, "episode/score": 6.3300737236340865, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.230073553982038}
{"step": 353520, "time": 47484.62815093994, "episode/length": 197.0, "episode/score": 7.331083156615023, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.23108299301657098}
{"step": 353704, "time": 47508.34483909607, "episode/length": 163.0, "episode/score": 4.257777758843076, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.15777761998288042}
{"step": 353888, "time": 47532.14703011513, "episode/length": 219.0, "episode/score": 8.360642807707336, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.2606425149460847}
{"step": 353912, "time": 47536.49204707146, "episode/length": 224.0, "episode/score": 6.349506152956565, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.2495059125822081}
{"step": 353952, "time": 47542.89501261711, "episode/length": 53.0, "episode/score": 1.145224211454206, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.04522418679744078}
{"step": 354272, "time": 47583.3698425293, "episode/length": 153.0, "episode/score": 6.263644593836034, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.16364438361324574}
{"step": 354360, "time": 47595.483025312424, "episode/length": 228.0, "episode/score": 6.362774191360586, "episode/reward_rate": 0.982532751091703, "episode/intrinsic_return": 0.26277401012521295}
{"step": 354704, "time": 47638.749331474304, "episode/length": 42.0, "episode/score": 5.1484863188816234, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0484861102886498}
{"step": 354760, "time": 47647.06700468063, "episode/length": 177.0, "episode/score": 6.294820502812854, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.19482029142591273}
{"step": 354912, "time": 47666.94703769684, "episode/length": 150.0, "episode/score": 5.245230545512186, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.1452303840383138}
{"step": 355136, "time": 47695.78493142128, "episode/length": 316.0, "episode/score": 8.41852959897642, "episode/reward_rate": 0.9905362776025236, "episode/intrinsic_return": 0.31852934905600705}
{"step": 355312, "time": 47719.01659369469, "episode/length": 49.0, "episode/score": 2.151359291553945, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.051359172717184265}
{"step": 355392, "time": 47730.26780438423, "episode/length": 187.0, "episode/score": 6.312368753422561, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.21236857335134118}
{"step": 355408, "time": 47733.732802152634, "episode/length": 181.0, "episode/score": 8.28585588518672, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.18585573125074006}
{"step": 355728, "time": 47774.1619682312, "episode/length": 39.0, "episode/score": 5.144541843794286, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.044541665934957564}
{"step": 355912, "time": 47798.03912997246, "episode/length": 249.0, "episode/score": 8.393630234485045, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.2936299693142246}
{"step": 355976, "time": 47807.28085613251, "episode/length": 158.0, "episode/score": 4.281587945420142, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.18158782262526074}
{"step": 356112, "time": 47825.319543361664, "episode/length": 229.0, "episode/score": 7.3466317993752455, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.24663150987362314}
{"step": 356408, "time": 47862.650525808334, "episode/length": 205.0, "episode/score": 6.333681524287385, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.2336813101064763}
{"step": 356472, "time": 47871.83120369911, "episode/length": 166.0, "episode/score": 5.290672019187241, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.1906718665900371}
{"step": 356552, "time": 47883.11508727074, "episode/length": 154.0, "episode/score": 7.25441768548626, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.154417499419651}
{"step": 356736, "time": 47906.831095933914, "episode/length": 167.0, "episode/score": 8.287982407346135, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.1879821398470085}
{"step": 357160, "time": 47959.61861038208, "episode/length": 178.0, "episode/score": 6.292645439862099, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.1926452597908792}
{"step": 357424, "time": 47993.15479850769, "episode/length": 180.0, "episode/score": 7.292365991266706, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.1923657825573173}
{"step": 357744, "time": 48033.68825054169, "episode/length": 228.0, "episode/score": 8.361757116785157, "episode/reward_rate": 0.9737991266375546, "episode/intrinsic_return": 0.26175685242924374}
{"step": 357784, "time": 48040.13236403465, "episode/length": 163.0, "episode/score": 7.249621327455316, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.1496210885943583}
{"step": 357792, "time": 48042.69928884506, "episode/length": 209.0, "episode/score": 6.320791791051306, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.22079152401784086}
{"step": 357816, "time": 48047.20723986626, "episode/length": 48.0, "episode/score": 5.157335713214707, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.057335528486873955}
{"step": 357880, "time": 48056.653212308884, "episode/length": 165.0, "episode/score": 9.272426930956499, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.17242666497077153}
{"step": 358392, "time": 48120.49315285683, "episode/length": 247.0, "episode/score": 7.370622074024141, "episode/reward_rate": 0.9798387096774194, "episode/intrinsic_return": 0.27062186531475163}
{"step": 358464, "time": 48130.791805267334, "episode/length": 215.0, "episode/score": 6.325743207351479, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.22574296930542914}
{"step": 358496, "time": 48136.21663212776, "episode/length": 166.0, "episode/score": 7.270779946074981, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.17077967706245545}
{"step": 359104, "time": 48211.54597759247, "episode/length": 164.0, "episode/score": 5.2879853854028624, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.18798518065159442}
{"step": 359160, "time": 48219.8635225296, "episode/length": 176.0, "episode/score": 9.299563917120395, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.19956364997051423}
{"step": 359272, "time": 48234.892654418945, "episode/length": 181.0, "episode/score": 9.292860157293035, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.192859804345062}
{"step": 359544, "time": 48269.568910598755, "episode/length": 207.0, "episode/score": 7.320509973549633, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.22050976484024432}
{"step": 359568, "time": 48273.969307899475, "episode/length": 221.0, "episode/score": 7.357223211314704, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.25722298886830686}
{"step": 359720, "time": 48293.725216150284, "episode/length": 152.0, "episode/score": 6.272335128785926, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.17233494871470612}
{"step": 359792, "time": 48304.09619259834, "episode/length": 174.0, "episode/score": 8.309815709391842, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.20981547204428352}
{"step": 359800, "time": 48306.61059713364, "episode/length": 166.0, "episode/score": 5.289968958866666, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.18996880743361544}
{"step": 359960, "time": 48327.4477725029, "episode/length": 51.0, "episode/score": 3.1580047251845826, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.05800457770965295}
{"step": 360048, "time": 48357.32006716728, "eval_episode/length": 111.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9642857142857143}
{"step": 360048, "time": 48361.3612203598, "eval_episode/length": 163.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9695121951219512}
{"step": 360048, "time": 48363.49249577522, "eval_episode/length": 164.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9696969696969697}
{"step": 360048, "time": 48366.61959338188, "eval_episode/length": 189.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 360048, "time": 48366.62750506401, "eval_episode/length": 189.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 360048, "time": 48370.45036172867, "eval_episode/length": 190.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9790575916230366}
{"step": 360048, "time": 48373.27166390419, "eval_episode/length": 221.0, "eval_episode/score": 6.099999971687794, "eval_episode/reward_rate": 0.9954954954954955}
{"step": 360048, "time": 48374.94971752167, "eval_episode/length": 226.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9779735682819384}
{"step": 360161, "time": 48389.63487815857, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.234749129011824, "train/action_min": 0.0, "train/action_std": 3.3649862186328785, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.052546797209494824, "train/actor_opt_grad_steps": 88730.0, "train/actor_opt_loss": -9.187265442432585, "train/adv_mag": 0.6046854291413282, "train/adv_max": 0.5708349844893894, "train/adv_mean": 0.0030145893965095026, "train/adv_min": -0.48306251216579127, "train/adv_std": 0.06535321870768393, "train/cont_avg": 0.9946104307432433, "train/cont_loss_mean": 0.000133959810835136, "train/cont_loss_std": 0.004090120966528453, "train/cont_neg_acc": 0.996396396611188, "train/cont_neg_loss": 0.02809329667499506, "train/cont_pos_acc": 0.9999946813325624, "train/cont_pos_loss": 1.4028679349219085e-05, "train/cont_pred": 0.9946257665350631, "train/cont_rate": 0.9946104307432433, "train/dyn_loss_mean": 6.615790813033645, "train/dyn_loss_std": 8.830449676513672, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.041516756367039, "train/extr_critic_critic_opt_grad_steps": 88730.0, "train/extr_critic_critic_opt_loss": 16182.088666596284, "train/extr_critic_mag": 6.646204378798202, "train/extr_critic_max": 6.646204378798202, "train/extr_critic_mean": 1.2797245589462487, "train/extr_critic_min": -0.5890681041253579, "train/extr_critic_std": 1.4419530907192746, "train/extr_return_normed_mag": 1.744327195915016, "train/extr_return_normed_max": 1.744327195915016, "train/extr_return_normed_mean": 0.3311037600845904, "train/extr_return_normed_min": -0.15727255392718958, "train/extr_return_normed_std": 0.3305043003043613, "train/extr_return_rate": 0.5723258313295003, "train/extr_return_raw_mag": 7.597029657621642, "train/extr_return_raw_max": 7.597029657621642, "train/extr_return_raw_mean": 1.2931847417676772, "train/extr_return_raw_min": -0.8857302659266704, "train/extr_return_raw_std": 1.474587467232266, "train/extr_reward_mag": 1.0256676519239272, "train/extr_reward_max": 1.0256676519239272, "train/extr_reward_mean": 0.033607351533263115, "train/extr_reward_min": -0.6672220558733554, "train/extr_reward_std": 0.17752013866965835, "train/image_loss_mean": 3.6950850229005554, "train/image_loss_std": 8.640631170530577, "train/model_loss_mean": 7.742002069627916, "train/model_loss_std": 12.688636599360285, "train/model_opt_grad_norm": 40.41677266713735, "train/model_opt_grad_steps": 88649.0, "train/model_opt_loss": 7001.193715688345, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 912.1621621621622, "train/policy_entropy_mag": 2.538308585656656, "train/policy_entropy_max": 2.538308585656656, "train/policy_entropy_mean": 0.4931687645010046, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.5723082668072469, "train/policy_logprob_mag": 7.438384017428836, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.4925571742895487, "train/policy_logprob_min": -7.438384017428836, "train/policy_logprob_std": 1.0699215089952623, "train/policy_randomness_mag": 0.8959115411784198, "train/policy_randomness_max": 0.8959115411784198, "train/policy_randomness_mean": 0.1740669333451503, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.20199970329130018, "train/post_ent_mag": 60.03315483299462, "train/post_ent_max": 60.03315483299462, "train/post_ent_mean": 43.488890508703285, "train/post_ent_min": 19.16683489309775, "train/post_ent_std": 7.059597355610616, "train/prior_ent_mag": 74.50362767399969, "train/prior_ent_max": 74.50362767399969, "train/prior_ent_mean": 50.07426759874499, "train/prior_ent_min": 30.382558698911925, "train/prior_ent_std": 6.949050060478417, "train/rep_loss_mean": 6.615790813033645, "train/rep_loss_std": 8.830449676513672, "train/reward_avg": 0.02254336880570328, "train/reward_loss_mean": 0.07730861811621768, "train/reward_loss_std": 0.1816528935690184, "train/reward_max_data": 1.0109797606597075, "train/reward_max_pred": 1.0094043035764952, "train/reward_neg_acc": 0.9984566914068685, "train/reward_neg_loss": 0.0532423464228978, "train/reward_pos_acc": 0.8743258047748257, "train/reward_pos_loss": 0.7501303096075316, "train/reward_pred": 0.022413344983313533, "train/reward_rate": 0.03451224662162162, "train_stats/sum_log_reward": 6.286046554875928, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 5.6976744186046515, "train_stats/max_log_achievement_collect_sapling": 2.4186046511627906, "train_stats/max_log_achievement_collect_stone": 0.20930232558139536, "train_stats/max_log_achievement_collect_wood": 8.13953488372093, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.4186046511627907, "train_stats/max_log_achievement_eat_cow": 0.046511627906976744, "train_stats/max_log_achievement_make_wood_pickaxe": 0.7209302325581395, "train_stats/max_log_achievement_make_wood_sword": 1.2790697674418605, "train_stats/max_log_achievement_place_plant": 2.2325581395348837, "train_stats/max_log_achievement_place_stone": 0.023255813953488372, "train_stats/max_log_achievement_place_table": 2.302325581395349, "train_stats/max_log_achievement_wake_up": 1.2325581395348837, "train_stats/mean_log_entropy": 0.3914248513620953, "eval_stats/sum_log_reward": 6.975000023841858, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 6.375, "eval_stats/max_log_achievement_collect_sapling": 2.125, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 10.625, "eval_stats/max_log_achievement_defeat_skeleton": 0.25, "eval_stats/max_log_achievement_defeat_zombie": 0.5, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.5, "eval_stats/max_log_achievement_make_wood_sword": 3.0, "eval_stats/max_log_achievement_place_plant": 2.125, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 3.125, "eval_stats/max_log_achievement_wake_up": 1.0, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 1.8399117834633216e-05, "report/cont_loss_std": 0.00043093215208500624, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0043492489494383335, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 1.4153933989291545e-06, "report/cont_pred": 0.9961093068122864, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 6.858343124389648, "report/dyn_loss_std": 8.603409767150879, "report/image_loss_mean": 2.8556432723999023, "report/image_loss_std": 6.920022010803223, "report/model_loss_mean": 7.048389434814453, "report/model_loss_std": 11.007576942443848, "report/post_ent_mag": 56.06977081298828, "report/post_ent_max": 56.06977081298828, "report/post_ent_mean": 41.26543426513672, "report/post_ent_min": 17.956565856933594, "report/post_ent_std": 6.331066608428955, "report/prior_ent_mag": 74.45388793945312, "report/prior_ent_max": 74.45388793945312, "report/prior_ent_mean": 48.461585998535156, "report/prior_ent_min": 31.21759033203125, "report/prior_ent_std": 6.7677836418151855, "report/rep_loss_mean": 6.858343124389648, "report/rep_loss_std": 8.603409767150879, "report/reward_avg": 0.03414352610707283, "report/reward_loss_mean": 0.07772260904312134, "report/reward_loss_std": 0.20499296486377716, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.001826286315918, "report/reward_neg_acc": 0.9989743232727051, "report/reward_neg_loss": 0.04304734244942665, "report/reward_pos_acc": 0.8979591727256775, "report/reward_pos_loss": 0.76768958568573, "report/reward_pred": 0.032750193029642105, "report/reward_rate": 0.0478515625, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 4.136918505537324e-06, "eval/cont_loss_std": 6.193640001583844e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0008991078939288855, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.5072289443196496e-06, "eval/cont_pred": 0.9970715045928955, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 20.413681030273438, "eval/dyn_loss_std": 11.89209270477295, "eval/image_loss_mean": 17.403207778930664, "eval/image_loss_std": 21.013263702392578, "eval/model_loss_mean": 29.777095794677734, "eval/model_loss_std": 25.684125900268555, "eval/post_ent_mag": 53.87772750854492, "eval/post_ent_max": 53.87772750854492, "eval/post_ent_mean": 39.53114318847656, "eval/post_ent_min": 21.36724853515625, "eval/post_ent_std": 6.405694961547852, "eval/prior_ent_mag": 74.45388793945312, "eval/prior_ent_max": 74.45388793945312, "eval/prior_ent_mean": 53.6578369140625, "eval/prior_ent_min": 37.763553619384766, "eval/prior_ent_std": 5.9279608726501465, "eval/rep_loss_mean": 20.413681030273438, "eval/rep_loss_std": 11.89209270477295, "eval/reward_avg": 0.03173828125, "eval/reward_loss_mean": 0.12567336857318878, "eval/reward_loss_std": 0.7115910053253174, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.001727819442749, "eval/reward_neg_acc": 0.9929150342941284, "eval/reward_neg_loss": 0.050080932676792145, "eval/reward_pos_acc": 0.75, "eval/reward_pos_loss": 2.200265407562256, "eval/reward_pred": 0.02378356084227562, "eval/reward_rate": 0.03515625, "replay/size": 359657.0, "replay/inserts": 7400.0, "replay/samples": 29600.0, "replay/insert_wait_avg": 1.5644769410829287e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.263631434053988e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 72400.0, "eval_replay/inserts": 1816.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1959002406586635e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.493661880493164e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 999.9972016811371, "timer/env.step_count": 925.0, "timer/env.step_total": 89.72884631156921, "timer/env.step_frac": 0.08972909740219502, "timer/env.step_avg": 0.09700415817466942, "timer/env.step_min": 0.02308201789855957, "timer/env.step_max": 1.7713003158569336, "timer/replay._sample_count": 29600.0, "timer/replay._sample_total": 14.040092468261719, "timer/replay._sample_frac": 0.014040131757027252, "timer/replay._sample_avg": 0.0004743274482520851, "timer/replay._sample_min": 0.0003685951232910156, "timer/replay._sample_max": 0.02447056770324707, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1152.0, "timer/agent.policy_total": 18.52026128768921, "timer/agent.policy_frac": 0.01852031311343074, "timer/agent.policy_avg": 0.016076615701119106, "timer/agent.policy_min": 0.009456396102905273, "timer/agent.policy_max": 0.04421210289001465, "timer/dataset_train_count": 1850.0, "timer/dataset_train_total": 0.2796649932861328, "timer/dataset_train_frac": 0.00027966577588014877, "timer/dataset_train_avg": 0.00015117026664115287, "timer/dataset_train_min": 8.96453857421875e-05, "timer/dataset_train_max": 0.0009434223175048828, "timer/agent.train_count": 1850.0, "timer/agent.train_total": 828.5111939907074, "timer/agent.train_frac": 0.8285135124356974, "timer/agent.train_avg": 0.4478438886436256, "timer/agent.train_min": 0.43839335441589355, "timer/agent.train_max": 0.5826375484466553, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4802677631378174, "timer/agent.report_frac": 0.000480269107083919, "timer/agent.report_avg": 0.2401338815689087, "timer/agent.report_min": 0.23270368576049805, "timer/agent.report_max": 0.24756407737731934, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.956390380859375e-05, "timer/dataset_eval_frac": 2.9563986538054944e-08, "timer/dataset_eval_avg": 2.956390380859375e-05, "timer/dataset_eval_min": 2.956390380859375e-05, "timer/dataset_eval_max": 2.956390380859375e-05, "fps": 7.399924072472481}
{"step": 360352, "time": 48412.455892562866, "episode/length": 155.0, "episode/score": 5.271943998144707, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.17194383961032145}
{"step": 360448, "time": 48426.4820189476, "episode/length": 146.0, "episode/score": 5.2695577389677055, "episode/reward_rate": 0.9591836734693877, "episode/intrinsic_return": 0.169557593006175}
{"step": 361360, "time": 48539.85118031502, "episode/length": 194.0, "episode/score": 9.318724751203263, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.2187244852175354}
{"step": 361536, "time": 48562.80150461197, "episode/length": 196.0, "episode/score": 8.31077518400889, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.21077496098041593}
{"step": 361936, "time": 48613.193707704544, "episode/length": 197.0, "episode/score": 8.325155685799473, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.22515544670568488}
{"step": 362120, "time": 48637.22273802757, "episode/length": 290.0, "episode/score": 8.42473479736509, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.3247345658382983}
{"step": 362304, "time": 48661.72176814079, "episode/length": 45.0, "episode/score": 1.1527083802502602, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.05270833242684603}
{"step": 362600, "time": 48699.54393053055, "episode/length": 429.0, "episode/score": 6.5350953690813185, "episode/reward_rate": 0.9093023255813953, "episode/intrinsic_return": 0.4350951780379546}
{"step": 362656, "time": 48707.887471199036, "episode/length": 139.0, "episode/score": 6.251678530352365, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.1516783526094514}
{"step": 362744, "time": 48720.1108250618, "episode/length": 172.0, "episode/score": 6.2940407606238296, "episode/reward_rate": 0.9653179190751445, "episode/intrinsic_return": 0.19404055389350106}
{"step": 362872, "time": 48737.258113861084, "episode/length": 393.0, "episode/score": 8.50247445194509, "episode/reward_rate": 0.9923857868020305, "episode/intrinsic_return": 0.40247420423656877}
{"step": 363016, "time": 48756.421562194824, "episode/length": 430.0, "episode/score": 6.55426139184965, "episode/reward_rate": 0.6960556844547564, "episode/intrinsic_return": 0.45426118511932145}
{"step": 363328, "time": 48795.86771392822, "episode/length": 90.0, "episode/score": 5.204426130558204, "episode/reward_rate": 0.945054945054945, "episode/intrinsic_return": 0.10442598145345983}
{"step": 363608, "time": 48831.44614934921, "episode/length": 394.0, "episode/score": 6.502156504777304, "episode/reward_rate": 0.9949367088607595, "episode/intrinsic_return": 0.40215639865891717}
{"step": 363704, "time": 48844.69926548004, "episode/length": 174.0, "episode/score": 7.301533222045691, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.20153299750381848}
{"step": 364128, "time": 48897.964859485626, "episode/length": 183.0, "episode/score": 6.307583866544519, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.20758368647329917}
{"step": 364224, "time": 48911.33452486992, "episode/length": 262.0, "episode/score": 5.3932473511176795, "episode/reward_rate": 0.9809885931558935, "episode/intrinsic_return": 0.2932471695330605}
{"step": 364272, "time": 48918.80184817314, "episode/length": 190.0, "episode/score": 7.302045651977096, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.20204541311613866}
{"step": 364368, "time": 48932.10107445717, "episode/length": 186.0, "episode/score": 7.292516521381913, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.19251634014653973}
{"step": 364392, "time": 48936.676861763, "episode/length": 171.0, "episode/score": 8.284122935254345, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.18412270253429597}
{"step": 364688, "time": 48974.15616130829, "episode/length": 169.0, "episode/score": 9.28946983685637, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.18946960562061577}
{"step": 365208, "time": 49039.27440905571, "episode/length": 199.0, "episode/score": 5.326117185482872, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.2261170090205269}
{"step": 365488, "time": 49074.80478024483, "episode/length": 34.0, "episode/score": 3.143750094342977, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0437499990221113}
{"step": 365648, "time": 49095.84008860588, "episode/length": 177.0, "episode/score": 7.296405795028477, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.19640557851926133}
{"step": 365672, "time": 49100.347452402115, "episode/length": 162.0, "episode/score": 6.269569707966184, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.16956954221404885}
{"step": 365680, "time": 49102.998630046844, "episode/length": 160.0, "episode/score": 5.262660477534155, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.16266029478538258}
{"step": 365712, "time": 49108.54962396622, "episode/length": 197.0, "episode/score": 5.324828444235209, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.22482829513046454}
{"step": 366056, "time": 49151.887924432755, "episode/length": 293.0, "episode/score": 6.43577567403554, "episode/reward_rate": 0.9897959183673469, "episode/intrinsic_return": 0.3357755287142936}
{"step": 366648, "time": 49225.334241867065, "episode/length": 121.0, "episode/score": 5.229381955980898, "episode/reward_rate": 0.9590163934426229, "episode/intrinsic_return": 0.1293818115036629}
{"step": 366712, "time": 49234.76218318939, "episode/length": 304.0, "episode/score": 7.449591025137124, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.34959082341265457}
{"step": 366728, "time": 49238.19779276848, "episode/length": 154.0, "episode/score": 6.26355083819999, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.1635506100492421}
{"step": 366848, "time": 49254.33471941948, "episode/length": 145.0, "episode/score": 7.245239185559512, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.14523899282812636}
{"step": 367088, "time": 49285.02565860748, "episode/length": 44.0, "episode/score": 3.151684976506658, "episode/reward_rate": 0.9111111111111111, "episode/intrinsic_return": 0.05168488118579262}
{"step": 367352, "time": 49318.81681203842, "episode/length": 204.0, "episode/score": 6.322412311837979, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.22241208194100182}
{"step": 367496, "time": 49337.7131729126, "episode/length": 179.0, "episode/score": 7.2903729355703035, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.19037283972556907}
{"step": 367536, "time": 49344.109404563904, "episode/length": 235.0, "episode/score": 8.369574863414527, "episode/reward_rate": 0.9788135593220338, "episode/intrinsic_return": 0.2695746644258179}
{"step": 367889, "time": 49389.65953922272, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.0812286218830955, "train/action_min": 0.0, "train/action_std": 3.278219861687774, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0530818858294907, "train/actor_opt_grad_steps": 90620.0, "train/actor_opt_loss": -5.395800470688182, "train/adv_mag": 0.5877929732898356, "train/adv_max": 0.5664416426512862, "train/adv_mean": 0.004095768586846223, "train/adv_min": -0.4445074070920598, "train/adv_std": 0.06555220004113227, "train/cont_avg": 0.9943531411917098, "train/cont_loss_mean": 0.00011350544927518146, "train/cont_loss_std": 0.0033167959625783755, "train/cont_neg_acc": 0.9960253918109162, "train/cont_neg_loss": 0.010238496297953543, "train/cont_pos_acc": 0.9999897822814902, "train/cont_pos_loss": 3.853478523830699e-05, "train/cont_pred": 0.9943546513819324, "train/cont_rate": 0.9943531411917098, "train/dyn_loss_mean": 6.7608414511606485, "train/dyn_loss_std": 8.801265565842545, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.021551014845853, "train/extr_critic_critic_opt_grad_steps": 90620.0, "train/extr_critic_critic_opt_loss": 16445.412848121763, "train/extr_critic_mag": 6.649667043142368, "train/extr_critic_max": 6.649667043142368, "train/extr_critic_mean": 1.3669343220137562, "train/extr_critic_min": -0.5946331024169922, "train/extr_critic_std": 1.453110661222527, "train/extr_return_normed_mag": 1.6990377328556436, "train/extr_return_normed_max": 1.6990377328556436, "train/extr_return_normed_mean": 0.34648669090295703, "train/extr_return_normed_min": -0.1563307130274995, "train/extr_return_normed_std": 0.32958937146811906, "train/extr_return_rate": 0.6123546439131307, "train/extr_return_raw_mag": 7.498886007101425, "train/extr_return_raw_max": 7.498886007101425, "train/extr_return_raw_mean": 1.3854809032820667, "train/extr_return_raw_min": -0.887408656314247, "train/extr_return_raw_std": 1.4898150516915198, "train/extr_reward_mag": 1.0285111004824465, "train/extr_reward_max": 1.0285111004824465, "train/extr_reward_mean": 0.034327671076581266, "train/extr_reward_min": -0.6552983818894224, "train/extr_reward_std": 0.18019748266805638, "train/image_loss_mean": 3.6637371698191745, "train/image_loss_std": 8.716323582001918, "train/model_loss_mean": 7.797830791671041, "train/model_loss_std": 12.744420802654998, "train/model_opt_grad_norm": 40.844818154764916, "train/model_opt_grad_steps": 90537.84455958549, "train/model_opt_loss": 11170.444115831444, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1437.823834196891, "train/policy_entropy_mag": 2.5360172684328544, "train/policy_entropy_max": 2.5360172684328544, "train/policy_entropy_mean": 0.4549540583951486, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.5406455531947971, "train/policy_logprob_mag": 7.43838403138472, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.4544919871295672, "train/policy_logprob_min": -7.43838403138472, "train/policy_logprob_std": 1.0431939746431735, "train/policy_randomness_mag": 0.8951028035712366, "train/policy_randomness_max": 0.8951028035712366, "train/policy_randomness_mean": 0.16057881705192703, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.19082415497673608, "train/post_ent_mag": 60.03790921621372, "train/post_ent_max": 60.03790921621372, "train/post_ent_mean": 43.357146327359686, "train/post_ent_min": 19.23873440342246, "train/post_ent_std": 7.061299373448821, "train/prior_ent_mag": 74.49539987040308, "train/prior_ent_max": 74.49539987040308, "train/prior_ent_mean": 50.119427557436296, "train/prior_ent_min": 30.268024286457912, "train/prior_ent_std": 6.933460013236407, "train/rep_loss_mean": 6.7608414511606485, "train/rep_loss_std": 8.801265565842545, "train/reward_avg": 0.02257795880881616, "train/reward_loss_mean": 0.0774752427799714, "train/reward_loss_std": 0.18412754348831473, "train/reward_max_data": 1.0147193756745887, "train/reward_max_pred": 1.013083082406632, "train/reward_neg_acc": 0.9986749862759842, "train/reward_neg_loss": 0.05343549024950655, "train/reward_pos_acc": 0.8925815897902059, "train/reward_pos_loss": 0.7540533659989352, "train/reward_pred": 0.022320739997290267, "train/reward_rate": 0.034412443329015545, "train_stats/sum_log_reward": 6.266666723622216, "train_stats/max_log_achievement_collect_coal": 0.027777777777777776, "train_stats/max_log_achievement_collect_drink": 7.166666666666667, "train_stats/max_log_achievement_collect_sapling": 2.4166666666666665, "train_stats/max_log_achievement_collect_stone": 0.4166666666666667, "train_stats/max_log_achievement_collect_wood": 8.305555555555555, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.3611111111111111, "train_stats/max_log_achievement_eat_cow": 0.1111111111111111, "train_stats/max_log_achievement_make_wood_pickaxe": 0.4166666666666667, "train_stats/max_log_achievement_make_wood_sword": 1.4722222222222223, "train_stats/max_log_achievement_place_plant": 2.0833333333333335, "train_stats/max_log_achievement_place_stone": 0.08333333333333333, "train_stats/max_log_achievement_place_table": 2.5555555555555554, "train_stats/max_log_achievement_wake_up": 1.4722222222222223, "train_stats/mean_log_entropy": 0.4487700213988622, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 4.881470886175521e-06, "report/cont_loss_std": 6.481118180090562e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00012514382251538336, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 4.646124125429196e-06, "report/cont_pred": 0.9980424642562866, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 6.931017875671387, "report/dyn_loss_std": 8.631247520446777, "report/image_loss_mean": 3.645193576812744, "report/image_loss_std": 10.004881858825684, "report/model_loss_mean": 7.862964630126953, "report/model_loss_std": 13.815704345703125, "report/post_ent_mag": 58.33285903930664, "report/post_ent_max": 58.33285903930664, "report/post_ent_mean": 42.5644645690918, "report/post_ent_min": 20.77739143371582, "report/post_ent_std": 6.476271629333496, "report/prior_ent_mag": 74.56436157226562, "report/prior_ent_max": 74.56436157226562, "report/prior_ent_mean": 49.62876892089844, "report/prior_ent_min": 33.56414794921875, "report/prior_ent_std": 6.2397260665893555, "report/rep_loss_mean": 6.931017875671387, "report/rep_loss_std": 8.631247520446777, "report/reward_avg": 0.015569121576845646, "report/reward_loss_mean": 0.059155337512493134, "report/reward_loss_std": 0.10586114227771759, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0023715496063232, "report/reward_neg_acc": 0.9990019798278809, "report/reward_neg_loss": 0.04566562548279762, "report/reward_pos_acc": 0.8636363744735718, "report/reward_pos_loss": 0.673550546169281, "report/reward_pred": 0.01593245379626751, "report/reward_rate": 0.021484375, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 1.411342054780107e-05, "eval/cont_loss_std": 0.00030280198552645743, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0035498521756380796, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 3.7243742099235533e-06, "eval/cont_pred": 0.9970769286155701, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 19.731197357177734, "eval/dyn_loss_std": 11.474601745605469, "eval/image_loss_mean": 20.55524444580078, "eval/image_loss_std": 19.42094612121582, "eval/model_loss_mean": 32.50563049316406, "eval/model_loss_std": 23.719562530517578, "eval/post_ent_mag": 57.899112701416016, "eval/post_ent_max": 57.899112701416016, "eval/post_ent_mean": 41.65659713745117, "eval/post_ent_min": 21.263683319091797, "eval/post_ent_std": 7.600978374481201, "eval/prior_ent_mag": 74.56436157226562, "eval/prior_ent_max": 74.56436157226562, "eval/prior_ent_mean": 55.348777770996094, "eval/prior_ent_min": 37.899330139160156, "eval/prior_ent_std": 5.602019786834717, "eval/rep_loss_mean": 19.731197357177734, "eval/rep_loss_std": 11.474601745605469, "eval/reward_avg": 0.02080078050494194, "eval/reward_loss_mean": 0.11165380477905273, "eval/reward_loss_std": 0.7703334093093872, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0035898685455322, "eval/reward_neg_acc": 0.9979979991912842, "eval/reward_neg_loss": 0.04596580192446709, "eval/reward_pos_acc": 0.7599999904632568, "eval/reward_pos_loss": 2.736546277999878, "eval/reward_pred": 0.015684768557548523, "eval/reward_rate": 0.0244140625, "replay/size": 367385.0, "replay/inserts": 7728.0, "replay/samples": 30912.0, "replay/insert_wait_avg": 1.5446303053672268e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.242565939885489e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 72400.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 6.705522537231445e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0119090080261, "timer/env.step_count": 966.0, "timer/env.step_total": 82.08053588867188, "timer/env.step_frac": 0.08207955840255207, "timer/env.step_avg": 0.0849694988495568, "timer/env.step_min": 0.02299332618713379, "timer/env.step_max": 2.3320865631103516, "timer/replay._sample_count": 30912.0, "timer/replay._sample_total": 14.646336793899536, "timer/replay._sample_frac": 0.014646162372634289, "timer/replay._sample_avg": 0.0004738074790987169, "timer/replay._sample_min": 0.00035762786865234375, "timer/replay._sample_max": 0.010422468185424805, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 966.0, "timer/agent.policy_total": 15.347280025482178, "timer/agent.policy_frac": 0.01534709725677777, "timer/agent.policy_avg": 0.015887453442528135, "timer/agent.policy_min": 0.014611959457397461, "timer/agent.policy_max": 0.04737997055053711, "timer/dataset_train_count": 1932.0, "timer/dataset_train_total": 0.3007080554962158, "timer/dataset_train_frac": 0.00030070447440421665, "timer/dataset_train_avg": 0.00015564599145766864, "timer/dataset_train_min": 9.059906005859375e-05, "timer/dataset_train_max": 0.0010693073272705078, "timer/agent.train_count": 1932.0, "timer/agent.train_total": 869.4549598693848, "timer/agent.train_frac": 0.8694446056465979, "timer/agent.train_avg": 0.45002844713736273, "timer/agent.train_min": 0.4364333152770996, "timer/agent.train_max": 0.9360287189483643, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47637128829956055, "timer/agent.report_frac": 0.0004763656152576251, "timer/agent.report_avg": 0.23818564414978027, "timer/agent.report_min": 0.23274469375610352, "timer/agent.report_max": 0.24362659454345703, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0040740966796875e-05, "timer/dataset_eval_frac": 3.004038321563205e-08, "timer/dataset_eval_avg": 3.0040740966796875e-05, "timer/dataset_eval_min": 3.0040740966796875e-05, "timer/dataset_eval_max": 3.0040740966796875e-05, "fps": 7.727800761003806}
{"step": 368032, "time": 49406.86866521835, "episode/length": 164.0, "episode/score": 6.273353527557447, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.17335335260850115}
{"step": 368096, "time": 49416.36654376984, "episode/length": 155.0, "episode/score": 6.269183818836609, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.1691836519203207}
{"step": 368240, "time": 49435.2156894207, "episode/length": 443.0, "episode/score": 7.597413690104986, "episode/reward_rate": 0.7837837837837838, "episode/intrinsic_return": 0.4974134992071413}
{"step": 368392, "time": 49455.36525082588, "episode/length": 162.0, "episode/score": 6.2752826784617355, "episode/reward_rate": 0.9631901840490797, "episode/intrinsic_return": 0.1752826478677889}
{"step": 368936, "time": 49525.815120220184, "episode/length": 197.0, "episode/score": 6.3153030511939505, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.21530287112273072}
{"step": 369064, "time": 49543.573868989944, "episode/length": 190.0, "episode/score": 8.300840878381223, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.20084075235581622}
{"step": 369136, "time": 49553.83922958374, "episode/length": 310.0, "episode/score": 7.45794075055619, "episode/reward_rate": 0.9839228295819936, "episode/intrinsic_return": 0.35794051367429347}
{"step": 369728, "time": 49627.585361003876, "episode/length": 211.0, "episode/score": 7.3311851442244915, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.23118503033538218}
{"step": 369848, "time": 49643.642193078995, "episode/length": 181.0, "episode/score": 6.301357467989419, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.20135725949830885}
{"step": 370032, "time": 49688.443933963776, "eval_episode/length": 166.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9760479041916168}
{"step": 370032, "time": 49690.2244386673, "eval_episode/length": 172.0, "eval_episode/score": 5.099999971687794, "eval_episode/reward_rate": 0.9942196531791907}
{"step": 370032, "time": 49692.28490281105, "eval_episode/length": 186.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9946524064171123}
{"step": 370032, "time": 49693.88013958931, "eval_episode/length": 188.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9947089947089947}
{"step": 370032, "time": 49695.79425406456, "eval_episode/length": 196.0, "eval_episode/score": 6.099999979138374, "eval_episode/reward_rate": 0.9949238578680203}
{"step": 370032, "time": 49697.97968959808, "eval_episode/length": 211.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9952830188679245}
{"step": 370032, "time": 49699.89418506622, "eval_episode/length": 218.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9954337899543378}
{"step": 370032, "time": 49701.57127451897, "eval_episode/length": 221.0, "eval_episode/score": 7.0999999940395355, "eval_episode/reward_rate": 0.9954954954954955}
{"step": 370080, "time": 49707.42020082474, "episode/length": 43.0, "episode/score": 4.155000132508576, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0549999987706542}
{"step": 370144, "time": 49716.99565720558, "episode/length": 237.0, "episode/score": 7.369057387648809, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.2690570971867601}
{"step": 370272, "time": 49734.13469839096, "episode/length": 150.0, "episode/score": 6.274777727660876, "episode/reward_rate": 0.9602649006622517, "episode/intrinsic_return": 0.17477756540120026}
{"step": 370368, "time": 49747.31660532951, "episode/length": 283.0, "episode/score": 8.413584606518725, "episode/reward_rate": 0.971830985915493, "episode/intrinsic_return": 0.31358435846095745}
{"step": 371024, "time": 49829.026700258255, "episode/length": 260.0, "episode/score": 6.391155298565536, "episode/reward_rate": 0.9808429118773946, "episode/intrinsic_return": 0.2911551111310473}
{"step": 371088, "time": 49838.23202610016, "episode/length": 243.0, "episode/score": 11.386629309508407, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.286628969220601}
{"step": 371184, "time": 49851.41359949112, "episode/length": 166.0, "episode/score": 5.287276620796547, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.18727648368258087}
{"step": 371480, "time": 49888.94573712349, "episode/length": 174.0, "episode/score": 6.292602600410191, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.19260242895370538}
{"step": 371744, "time": 49922.69228601456, "episode/length": 530.0, "episode/score": 7.634728627547702, "episode/reward_rate": 0.687382297551789, "episode/intrinsic_return": 0.534728457080746}
{"step": 371800, "time": 49931.103603601456, "episode/length": 178.0, "episode/score": 6.29187779825088, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.19187758686393863}
{"step": 372424, "time": 50008.65210938454, "episode/length": 284.0, "episode/score": 9.412604183698477, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.31260388313739895}
{"step": 372544, "time": 50024.84658050537, "episode/length": 169.0, "episode/score": 5.298446038337261, "episode/reward_rate": 0.9647058823529412, "episode/intrinsic_return": 0.1984458903966697}
{"step": 372656, "time": 50040.51983809471, "episode/length": 297.0, "episode/score": 7.4113105347878445, "episode/reward_rate": 0.9865771812080537, "episode/intrinsic_return": 0.31131038189960236}
{"step": 372968, "time": 50080.19277501106, "episode/length": 152.0, "episode/score": 5.2791857843258185, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.17918560274119955}
{"step": 373056, "time": 50092.45030212402, "episode/length": 196.0, "episode/score": 6.33379176055314, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.23379166203085333}
{"step": 373240, "time": 50116.47602438927, "episode/length": 276.0, "episode/score": 6.40758314165987, "episode/reward_rate": 0.9927797833935018, "episode/intrinsic_return": 0.30758294785164253}
{"step": 373272, "time": 50121.80105113983, "episode/length": 272.0, "episode/score": 9.400681606214675, "episode/reward_rate": 0.9816849816849816, "episode/intrinsic_return": 0.300681462465036}
{"step": 373808, "time": 50188.83956694603, "episode/length": 157.0, "episode/score": 8.28586620259739, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.1858659652498318}
{"step": 373840, "time": 50194.236293554306, "episode/length": 254.0, "episode/score": 9.399133582264767, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.2991333220998058}
{"step": 373872, "time": 50199.519339084625, "episode/length": 151.0, "episode/score": 9.265000390048954, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.1650001240632264}
{"step": 374040, "time": 50221.47447037697, "episode/length": 201.0, "episode/score": 7.327238823912921, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.22723861403937917}
{"step": 374520, "time": 50281.400918245316, "episode/length": 159.0, "episode/score": 6.278972785534279, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.17897266663931077}
{"step": 374968, "time": 50337.59367656708, "episode/length": 238.0, "episode/score": 7.3684963692649035, "episode/reward_rate": 0.9707112970711297, "episode/intrinsic_return": 0.26849616986874025}
{"step": 375216, "time": 50369.49295282364, "episode/length": 242.0, "episode/score": 10.363161455919908, "episode/reward_rate": 0.9794238683127572, "episode/intrinsic_return": 0.2631611612960114}
{"step": 375328, "time": 50384.70870399475, "episode/length": 189.0, "episode/score": 6.311482541284931, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.21148233339044964}
{"step": 375349, "time": 50389.70831012726, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.175387146652386, "train/action_min": 0.0, "train/action_std": 3.3864127333446215, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.050619497494671935, "train/actor_opt_grad_steps": 92515.0, "train/actor_opt_loss": -8.439971297338445, "train/adv_mag": 0.5765540963539513, "train/adv_max": 0.544997846407275, "train/adv_mean": 0.0035300718755929324, "train/adv_min": -0.4478188716275718, "train/adv_std": 0.0632073146601518, "train/cont_avg": 0.9944556451612904, "train/cont_loss_mean": 0.0001378463619180708, "train/cont_loss_std": 0.004170588214791952, "train/cont_neg_acc": 0.9964975850737613, "train/cont_neg_loss": 0.01857206005206844, "train/cont_pos_acc": 0.9999999846181562, "train/cont_pos_loss": 1.7454066566920215e-05, "train/cont_pred": 0.9944690119835639, "train/cont_rate": 0.9944556451612904, "train/dyn_loss_mean": 6.735300889579198, "train/dyn_loss_std": 8.875352446750927, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0713488709542058, "train/extr_critic_critic_opt_grad_steps": 92515.0, "train/extr_critic_critic_opt_loss": 16171.208916120631, "train/extr_critic_mag": 6.928573895526188, "train/extr_critic_max": 6.928573895526188, "train/extr_critic_mean": 1.5193064199980868, "train/extr_critic_min": -0.5370660090959201, "train/extr_critic_std": 1.5108559750100619, "train/extr_return_normed_mag": 1.6745561752268063, "train/extr_return_normed_max": 1.6745561752268063, "train/extr_return_normed_mean": 0.3564931990638856, "train/extr_return_normed_min": -0.14107161654179456, "train/extr_return_normed_std": 0.3258651769770089, "train/extr_return_rate": 0.6561397767515593, "train/extr_return_raw_mag": 7.79927985642546, "train/extr_return_raw_max": 7.79927985642546, "train/extr_return_raw_mean": 1.5359983889646427, "train/extr_return_raw_min": -0.8289501477954209, "train/extr_return_raw_std": 1.548863661545579, "train/extr_reward_mag": 1.0259498319318217, "train/extr_reward_max": 1.0259498319318217, "train/extr_reward_mean": 0.03420782917409494, "train/extr_reward_min": -0.655508215068489, "train/extr_reward_std": 0.17938183872930466, "train/image_loss_mean": 3.6437229469258297, "train/image_loss_std": 8.712303397476033, "train/model_loss_mean": 7.763485746998941, "train/model_loss_std": 12.804453383209886, "train/model_opt_grad_norm": 39.73898141102124, "train/model_opt_grad_steps": 92431.28494623656, "train/model_opt_loss": 11427.589827998992, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1478.494623655914, "train/policy_entropy_mag": 2.516004826432915, "train/policy_entropy_max": 2.516004826432915, "train/policy_entropy_mean": 0.4558559436631459, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.544622054183355, "train/policy_logprob_mag": 7.4383840791640745, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.45647079040927274, "train/policy_logprob_min": -7.4383840791640745, "train/policy_logprob_std": 1.048292960530968, "train/policy_randomness_mag": 0.8880392912254539, "train/policy_randomness_max": 0.8880392912254539, "train/policy_randomness_mean": 0.16089714422661772, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.19222768588412192, "train/post_ent_mag": 59.986834331225324, "train/post_ent_max": 59.986834331225324, "train/post_ent_mean": 43.559212797431535, "train/post_ent_min": 19.32058878867857, "train/post_ent_std": 7.077411695193219, "train/prior_ent_mag": 74.57640711466472, "train/prior_ent_max": 74.57640711466472, "train/prior_ent_mean": 50.30279719445013, "train/prior_ent_min": 30.69380085442656, "train/prior_ent_std": 6.91958587913103, "train/rep_loss_mean": 6.735300889579198, "train/rep_loss_std": 8.875352446750927, "train/reward_avg": 0.023217401126780175, "train/reward_loss_mean": 0.07844440767201044, "train/reward_loss_std": 0.188756677292047, "train/reward_max_data": 1.0114606048471184, "train/reward_max_pred": 1.0099255756665302, "train/reward_neg_acc": 0.9987265454825535, "train/reward_neg_loss": 0.053738973954672455, "train/reward_pos_acc": 0.8858030992810444, "train/reward_pos_loss": 0.7572048457079036, "train/reward_pred": 0.022946641249682313, "train/reward_rate": 0.03510899697580645, "train_stats/sum_log_reward": 6.982352929956773, "train_stats/max_log_achievement_collect_coal": 0.058823529411764705, "train_stats/max_log_achievement_collect_drink": 5.588235294117647, "train_stats/max_log_achievement_collect_sapling": 2.5588235294117645, "train_stats/max_log_achievement_collect_stone": 1.1470588235294117, "train_stats/max_log_achievement_collect_wood": 9.411764705882353, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.35294117647058826, "train_stats/max_log_achievement_eat_cow": 0.14705882352941177, "train_stats/max_log_achievement_make_wood_pickaxe": 0.7647058823529411, "train_stats/max_log_achievement_make_wood_sword": 1.6176470588235294, "train_stats/max_log_achievement_place_plant": 2.323529411764706, "train_stats/max_log_achievement_place_stone": 0.058823529411764705, "train_stats/max_log_achievement_place_table": 2.9411764705882355, "train_stats/max_log_achievement_wake_up": 1.4705882352941178, "train_stats/mean_log_entropy": 0.4576915550757857, "eval_stats/sum_log_reward": 6.474999964237213, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 5.5, "eval_stats/max_log_achievement_collect_sapling": 2.375, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 8.375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.5, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.5, "eval_stats/max_log_achievement_make_wood_sword": 1.875, "eval_stats/max_log_achievement_place_plant": 1.875, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 3.0, "eval_stats/max_log_achievement_wake_up": 1.25, "eval_stats/mean_log_entropy": 0.0, "train_stats/max_log_achievement_place_furnace": 0.15, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 3.732174081960693e-05, "report/cont_loss_std": 0.0008612417732365429, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.004662135150283575, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 9.058884984369797e-07, "report/cont_pred": 0.9922226667404175, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 6.456949234008789, "report/dyn_loss_std": 8.853449821472168, "report/image_loss_mean": 3.7550995349884033, "report/image_loss_std": 9.638665199279785, "report/model_loss_mean": 7.713974952697754, "report/model_loss_std": 14.11915397644043, "report/post_ent_mag": 58.81238555908203, "report/post_ent_max": 58.81238555908203, "report/post_ent_mean": 44.03190612792969, "report/post_ent_min": 20.83456802368164, "report/post_ent_std": 7.146178722381592, "report/prior_ent_mag": 74.66520690917969, "report/prior_ent_max": 74.66520690917969, "report/prior_ent_mean": 50.66960906982422, "report/prior_ent_min": 30.641590118408203, "report/prior_ent_std": 7.404034614562988, "report/rep_loss_mean": 6.456949234008789, "report/rep_loss_std": 8.853449821472168, "report/reward_avg": 0.022628288716077805, "report/reward_loss_mean": 0.08466865867376328, "report/reward_loss_std": 0.23906472325325012, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0114548206329346, "report/reward_neg_acc": 0.9979757070541382, "report/reward_neg_loss": 0.06290553510189056, "report/reward_pos_acc": 0.8333333134651184, "report/reward_pos_loss": 0.6819456219673157, "report/reward_pred": 0.023330245167016983, "report/reward_rate": 0.03515625, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 2.3075674107531086e-05, "eval/cont_loss_std": 0.00055007851915434, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0076381005346775055, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 7.004791200415639e-07, "eval/cont_pred": 0.9970918893814087, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 19.84383773803711, "eval/dyn_loss_std": 11.928316116333008, "eval/image_loss_mean": 20.06429672241211, "eval/image_loss_std": 26.067974090576172, "eval/model_loss_mean": 32.109169006347656, "eval/model_loss_std": 30.596078872680664, "eval/post_ent_mag": 58.31229019165039, "eval/post_ent_max": 58.31229019165039, "eval/post_ent_mean": 40.93638610839844, "eval/post_ent_min": 21.3084774017334, "eval/post_ent_std": 6.896466255187988, "eval/prior_ent_mag": 74.66520690917969, "eval/prior_ent_max": 74.66520690917969, "eval/prior_ent_mean": 53.93994140625, "eval/prior_ent_min": 37.63552474975586, "eval/prior_ent_std": 5.641521453857422, "eval/rep_loss_mean": 19.84383773803711, "eval/rep_loss_std": 11.928316116333008, "eval/reward_avg": 0.02988281473517418, "eval/reward_loss_mean": 0.1385461688041687, "eval/reward_loss_std": 0.9295275807380676, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.001194715499878, "eval/reward_neg_acc": 0.992929220199585, "eval/reward_neg_loss": 0.04965261369943619, "eval/reward_pos_acc": 0.7352941036224365, "eval/reward_pos_loss": 2.7269175052642822, "eval/reward_pred": 0.024001091718673706, "eval/reward_rate": 0.033203125, "replay/size": 374845.0, "replay/inserts": 7460.0, "replay/samples": 29840.0, "replay/insert_wait_avg": 1.5722203190780516e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.280555551237459e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 74176.0, "eval_replay/inserts": 1776.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2134378020827835e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.344650268554688e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0342037677765, "timer/env.step_count": 932.0, "timer/env.step_total": 77.35290312767029, "timer/env.step_frac": 0.07735025745742677, "timer/env.step_avg": 0.08299667717561189, "timer/env.step_min": 0.023448705673217773, "timer/env.step_max": 1.9719061851501465, "timer/replay._sample_count": 29840.0, "timer/replay._sample_total": 14.198530197143555, "timer/replay._sample_frac": 0.014198044570524183, "timer/replay._sample_avg": 0.0004758220575450253, "timer/replay._sample_min": 0.00037550926208496094, "timer/replay._sample_max": 0.01054072380065918, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1154.0, "timer/agent.policy_total": 19.793757438659668, "timer/agent.policy_frac": 0.01979308044073269, "timer/agent.policy_avg": 0.017152302806464185, "timer/agent.policy_min": 0.009386062622070312, "timer/agent.policy_max": 0.11413812637329102, "timer/dataset_train_count": 1865.0, "timer/dataset_train_total": 0.2979576587677002, "timer/dataset_train_frac": 0.00029794746784170056, "timer/dataset_train_avg": 0.00015976281971458455, "timer/dataset_train_min": 9.489059448242188e-05, "timer/dataset_train_max": 0.0010733604431152344, "timer/agent.train_count": 1865.0, "timer/agent.train_total": 841.074636220932, "timer/agent.train_frac": 0.8410458692833297, "timer/agent.train_avg": 0.4509783572230198, "timer/agent.train_min": 0.4392993450164795, "timer/agent.train_max": 1.5596086978912354, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.478252649307251, "timer/agent.report_frac": 0.00047823629182418314, "timer/agent.report_avg": 0.2391263246536255, "timer/agent.report_min": 0.23407435417175293, "timer/agent.report_max": 0.24417829513549805, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.6941299438476562e-05, "timer/dataset_eval_frac": 2.694037797604446e-08, "timer/dataset_eval_avg": 2.6941299438476562e-05, "timer/dataset_eval_min": 2.6941299438476562e-05, "timer/dataset_eval_max": 2.6941299438476562e-05, "fps": 7.459649823815081}
{"step": 375424, "time": 50398.82880401611, "episode/length": 193.0, "episode/score": 9.318653470738354, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.21865323542806436}
{"step": 375560, "time": 50416.806069374084, "episode/length": 189.0, "episode/score": 5.253947526518459, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.15394736245434615}
{"step": 375600, "time": 50423.25991654396, "episode/length": 219.0, "episode/score": 8.346591020115739, "episode/reward_rate": 0.9727272727272728, "episode/intrinsic_return": 0.24659085116218193}
{"step": 375760, "time": 50444.164209127426, "episode/length": 41.0, "episode/score": 4.147463562592748, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.04746338298718911}
{"step": 375888, "time": 50461.229691028595, "episode/length": 170.0, "episode/score": 5.296414446685958, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.1964142337856174}
{"step": 375992, "time": 50475.30637049675, "episode/length": 377.0, "episode/score": 8.531237293093, "episode/reward_rate": 0.9920634920634921, "episode/intrinsic_return": 0.43123706040205434}
{"step": 376872, "time": 50585.36092662811, "episode/length": 192.0, "episode/score": 7.302516941554131, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.20251670502148045}
{"step": 376888, "time": 50588.82764315605, "episode/length": 165.0, "episode/score": 8.279936918535896, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.17993670062969613}
{"step": 376960, "time": 50599.163185834885, "episode/length": 169.0, "episode/score": 5.288439298283265, "episode/reward_rate": 0.9823529411764705, "episode/intrinsic_return": 0.18843912962074683}
{"step": 376984, "time": 50603.61871910095, "episode/length": 220.0, "episode/score": 8.34801142874312, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.24801117882270773}
{"step": 377144, "time": 50624.61173629761, "episode/length": 156.0, "episode/score": 6.268116162076694, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.1681159820054745}
{"step": 377248, "time": 50638.93197059631, "episode/length": 185.0, "episode/score": 8.303724665233858, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.2037244302146064}
{"step": 377272, "time": 50643.18031692505, "episode/length": 49.0, "episode/score": 3.1604296635332503, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.060429485906752234}
{"step": 377336, "time": 50652.52770805359, "episode/length": 167.0, "episode/score": 8.284900548085716, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.18490027942243614}
{"step": 378024, "time": 50737.76137971878, "episode/length": 381.0, "episode/score": 8.471028485997522, "episode/reward_rate": 0.9921465968586387, "episode/intrinsic_return": 0.3710282538886531}
{"step": 378512, "time": 50798.65321588516, "episode/length": 190.0, "episode/score": 7.3146847384723515, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.214684613960344}
{"step": 378664, "time": 50818.65145134926, "episode/length": 189.0, "episode/score": 5.2927785446563576, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.19277840987069794}
{"step": 378712, "time": 50825.99241423607, "episode/length": 182.0, "episode/score": 6.2892411834236555, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.1892409716583643}
{"step": 378752, "time": 50832.203543424606, "episode/length": 176.0, "episode/score": 6.299007456820618, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.19900727674939844}
{"step": 378816, "time": 50841.60440039635, "episode/length": 192.0, "episode/score": 7.309763607259811, "episode/reward_rate": 0.9637305699481865, "episode/intrinsic_return": 0.20976345431336085}
{"step": 378928, "time": 50856.80937361717, "episode/length": 254.0, "episode/score": 6.3787466002686415, "episode/reward_rate": 0.996078431372549, "episode/intrinsic_return": 0.2787463510467205}
{"step": 378952, "time": 50861.68314433098, "episode/length": 248.0, "episode/score": 5.388330533148292, "episode/reward_rate": 0.9678714859437751, "episode/intrinsic_return": 0.28833039452092635}
{"step": 379328, "time": 50908.83334207535, "episode/length": 162.0, "episode/score": 8.290899041079683, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.19089880606043153}
{"step": 380016, "time": 51007.880944013596, "eval_episode/length": 33.0, "eval_episode/score": 2.0999999716877937, "eval_episode/reward_rate": 0.9705882352941176}
{"step": 380016, "time": 51013.68044090271, "eval_episode/length": 134.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9703703703703703}
{"step": 380016, "time": 51016.04272890091, "eval_episode/length": 153.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.974025974025974}
{"step": 380016, "time": 51017.82489943504, "eval_episode/length": 159.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9625}
{"step": 380016, "time": 51019.645818948746, "eval_episode/length": 164.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9696969696969697}
{"step": 380016, "time": 51022.57933020592, "eval_episode/length": 196.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9949238578680203}
{"step": 380016, "time": 51026.097353458405, "eval_episode/length": 83.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9404761904761905}
{"step": 380016, "time": 51029.36227941513, "eval_episode/length": 281.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9716312056737588}
{"step": 380120, "time": 51041.9328186512, "episode/length": 181.0, "episode/score": 3.3025586854782887, "episode/reward_rate": 0.967032967032967, "episode/intrinsic_return": 0.20255859446479008}
{"step": 380200, "time": 51053.11191344261, "episode/length": 172.0, "episode/score": 7.2758326504408615, "episode/reward_rate": 0.9653179190751445, "episode/intrinsic_return": 0.1758324448746862}
{"step": 380240, "time": 51059.52713608742, "episode/length": 190.0, "episode/score": 6.303318768557801, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.20331855833501322}
{"step": 380336, "time": 51072.535783052444, "episode/length": 125.0, "episode/score": 5.235655031166971, "episode/reward_rate": 0.9523809523809523, "episode/intrinsic_return": 0.13565490185283124}
{"step": 380440, "time": 51086.667488098145, "episode/length": 188.0, "episode/score": 8.301941787107353, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.2019415485956415}
{"step": 380600, "time": 51107.60905790329, "episode/length": 230.0, "episode/score": 7.3739912440796616, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.2739910658710869}
{"step": 380752, "time": 51127.60246801376, "episode/length": 224.0, "episode/score": 7.349136875604017, "episode/reward_rate": 0.9822222222222222, "episode/intrinsic_return": 0.24913666573047522}
{"step": 381192, "time": 51182.69166517258, "episode/length": 334.0, "episode/score": 8.45797027269873, "episode/reward_rate": 0.9940298507462687, "episode/intrinsic_return": 0.3579700365153258}
{"step": 381520, "time": 51224.05795812607, "episode/length": 174.0, "episode/score": 5.288041849198635, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.18804169741633814}
{"step": 381600, "time": 51235.34066367149, "episode/length": 169.0, "episode/score": 8.274987747323394, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.17498742740826856}
{"step": 381808, "time": 51262.66923570633, "episode/length": 200.0, "episode/score": 8.329036320033993, "episode/reward_rate": 0.9800995024875622, "episode/intrinsic_return": 0.2290360513707128}
{"step": 381952, "time": 51281.68887138367, "episode/length": 201.0, "episode/score": 7.331043652842709, "episode/reward_rate": 0.9702970297029703, "episode/intrinsic_return": 0.23104344762577966}
{"step": 381984, "time": 51287.04728889465, "episode/length": 172.0, "episode/score": 7.282461895221786, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.18246175141393906}
{"step": 382112, "time": 51304.14559388161, "episode/length": 169.0, "episode/score": 8.292193928276902, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.1921936771923356}
{"step": 382224, "time": 51319.186631679535, "episode/length": 33.0, "episode/score": 4.139227482344722, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.03922727199096698}
{"step": 382600, "time": 51366.28687167168, "episode/length": 175.0, "episode/score": 6.301361316787734, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.20136110540079244}
{"step": 382773, "time": 51389.741793870926, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.142164004746304, "train/action_min": 0.0, "train/action_std": 3.2657295811560845, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.050411279283223615, "train/actor_opt_grad_steps": 94375.0, "train/actor_opt_loss": -9.467767389120674, "train/adv_mag": 0.5694245599931286, "train/adv_max": 0.5399176234840065, "train/adv_mean": 0.002857953067520015, "train/adv_min": -0.4396973434955843, "train/adv_std": 0.06233444791888037, "train/cont_avg": 0.9945238995295699, "train/cont_loss_mean": 0.00011718016659588273, "train/cont_loss_std": 0.0027536620912943237, "train/cont_neg_acc": 1.0, "train/cont_neg_loss": 0.0019223250143519132, "train/cont_pos_acc": 0.9999788547715833, "train/cont_pos_loss": 0.0001067933072278649, "train/cont_pred": 0.9944969697665142, "train/cont_rate": 0.9945238995295699, "train/dyn_loss_mean": 6.542380799529373, "train/dyn_loss_std": 8.76389366580594, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0513259047462093, "train/extr_critic_critic_opt_grad_steps": 94375.0, "train/extr_critic_critic_opt_loss": 16285.972756006384, "train/extr_critic_mag": 7.0209318078974245, "train/extr_critic_max": 7.0209318078974245, "train/extr_critic_mean": 1.5356074927314636, "train/extr_critic_min": -0.5761466776171038, "train/extr_critic_std": 1.5331709583600361, "train/extr_return_normed_mag": 1.67956171817677, "train/extr_return_normed_max": 1.67956171817677, "train/extr_return_normed_mean": 0.35723145618554086, "train/extr_return_normed_min": -0.14832167659876166, "train/extr_return_normed_std": 0.32744232212663976, "train/extr_return_rate": 0.6628385066024719, "train/extr_return_raw_mag": 7.879203224694857, "train/extr_return_raw_max": 7.879203224694857, "train/extr_return_raw_mean": 1.549319702771402, "train/extr_return_raw_min": -0.8711823311544233, "train/extr_return_raw_std": 1.5675039746428048, "train/extr_reward_mag": 1.0239980605340773, "train/extr_reward_max": 1.0239980605340773, "train/extr_reward_mean": 0.03393535737088451, "train/extr_reward_min": -0.6503216483259714, "train/extr_reward_std": 0.17838566041281145, "train/image_loss_mean": 3.5172978216601956, "train/image_loss_std": 8.226227375768847, "train/model_loss_mean": 7.520901874829364, "train/model_loss_std": 12.283506895906182, "train/model_opt_grad_norm": 39.011304393891365, "train/model_opt_grad_steps": 94289.70430107527, "train/model_opt_loss": 10873.174095892136, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1444.8924731182797, "train/policy_entropy_mag": 2.5044292224350797, "train/policy_entropy_max": 2.5044292224350797, "train/policy_entropy_mean": 0.45953648641545286, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.5493546312534681, "train/policy_logprob_mag": 7.438384045836746, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.4597800910793325, "train/policy_logprob_min": -7.438384045836746, "train/policy_logprob_std": 1.0477490079018377, "train/policy_randomness_mag": 0.8839536129787404, "train/policy_randomness_max": 0.8839536129787404, "train/policy_randomness_mean": 0.1621962123981086, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.19389807753345017, "train/post_ent_mag": 60.11622285330167, "train/post_ent_max": 60.11622285330167, "train/post_ent_mean": 43.80955866331695, "train/post_ent_min": 19.175622201734974, "train/post_ent_std": 7.051425462128014, "train/prior_ent_mag": 74.63418337093887, "train/prior_ent_max": 74.63418337093887, "train/prior_ent_mean": 50.36382730545536, "train/prior_ent_min": 30.58126562385149, "train/prior_ent_std": 6.926027321046399, "train/rep_loss_mean": 6.542380799529373, "train/rep_loss_std": 8.76389366580594, "train/reward_avg": 0.022617123950953767, "train/reward_loss_mean": 0.07805839259057276, "train/reward_loss_std": 0.1895533008200507, "train/reward_max_data": 1.0125403538826974, "train/reward_max_pred": 1.0128798202801776, "train/reward_neg_acc": 0.9986820006242363, "train/reward_neg_loss": 0.054120018297145446, "train/reward_pos_acc": 0.89161515684538, "train/reward_pos_loss": 0.7514631158562117, "train/reward_pred": 0.0223744800214165, "train/reward_rate": 0.03431094590053763, "train_stats/sum_log_reward": 6.612820606965285, "train_stats/max_log_achievement_collect_coal": 0.02564102564102564, "train_stats/max_log_achievement_collect_drink": 6.076923076923077, "train_stats/max_log_achievement_collect_sapling": 1.9743589743589745, "train_stats/max_log_achievement_collect_stone": 0.5641025641025641, "train_stats/max_log_achievement_collect_wood": 9.23076923076923, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.41025641025641024, "train_stats/max_log_achievement_eat_cow": 0.05128205128205128, "train_stats/max_log_achievement_make_wood_pickaxe": 1.9743589743589745, "train_stats/max_log_achievement_make_wood_sword": 0.7948717948717948, "train_stats/max_log_achievement_place_furnace": 0.02564102564102564, "train_stats/max_log_achievement_place_plant": 1.7692307692307692, "train_stats/max_log_achievement_place_stone": 0.15384615384615385, "train_stats/max_log_achievement_place_table": 2.871794871794872, "train_stats/max_log_achievement_wake_up": 1.1538461538461537, "train_stats/mean_log_entropy": 0.4001903537756357, "eval_stats/sum_log_reward": 5.350000083446503, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 4.375, "eval_stats/max_log_achievement_collect_sapling": 1.625, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 6.75, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.875, "eval_stats/max_log_achievement_make_wood_sword": 0.25, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.625, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.375, "eval_stats/max_log_achievement_wake_up": 1.0, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 8.589346407461562e-07, "report/cont_loss_std": 1.4450363778450992e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 7.235030352603644e-07, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 8.597328928772185e-07, "report/cont_pred": 0.9941397905349731, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 6.636333465576172, "report/dyn_loss_std": 8.596535682678223, "report/image_loss_mean": 3.278886079788208, "report/image_loss_std": 9.44173812866211, "report/model_loss_mean": 7.33927583694458, "report/model_loss_std": 13.057005882263184, "report/post_ent_mag": 62.28089141845703, "report/post_ent_max": 62.28089141845703, "report/post_ent_mean": 43.886871337890625, "report/post_ent_min": 19.210708618164062, "report/post_ent_std": 7.049859523773193, "report/prior_ent_mag": 73.92475891113281, "report/prior_ent_max": 73.92475891113281, "report/prior_ent_mean": 50.663597106933594, "report/prior_ent_min": 29.12005615234375, "report/prior_ent_std": 6.483240604400635, "report/rep_loss_mean": 6.636333465576172, "report/rep_loss_std": 8.596535682678223, "report/reward_avg": 0.01878688484430313, "report/reward_loss_mean": 0.07858866453170776, "report/reward_loss_std": 0.18691673874855042, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0035552978515625, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.051146250218153, "report/reward_pos_acc": 0.8888888955116272, "report/reward_pos_loss": 0.8317306041717529, "report/reward_pred": 0.017430379986763, "report/reward_rate": 0.03515625, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.00011602100857999176, "eval/cont_loss_std": 0.0036970830988138914, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.039455387741327286, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 4.303216201151372e-07, "eval/cont_pred": 0.9971789121627808, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 20.27262306213379, "eval/dyn_loss_std": 12.375617980957031, "eval/image_loss_mean": 21.426021575927734, "eval/image_loss_std": 24.113725662231445, "eval/model_loss_mean": 33.69955062866211, "eval/model_loss_std": 29.141910552978516, "eval/post_ent_mag": 62.386478424072266, "eval/post_ent_max": 62.386478424072266, "eval/post_ent_mean": 41.321319580078125, "eval/post_ent_min": 21.27578353881836, "eval/post_ent_std": 7.742290019989014, "eval/prior_ent_mag": 73.92475891113281, "eval/prior_ent_max": 73.92475891113281, "eval/prior_ent_mean": 54.91016387939453, "eval/prior_ent_min": 38.41682434082031, "eval/prior_ent_std": 5.545042991638184, "eval/rep_loss_mean": 20.27262306213379, "eval/rep_loss_std": 12.375617980957031, "eval/reward_avg": 0.01669921725988388, "eval/reward_loss_mean": 0.10983765125274658, "eval/reward_loss_std": 0.6812454462051392, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.012589931488037, "eval/reward_neg_acc": 0.9910179376602173, "eval/reward_neg_loss": 0.06635432690382004, "eval/reward_pos_acc": 0.7727273106575012, "eval/reward_pos_loss": 2.0903053283691406, "eval/reward_pred": 0.017359193414449692, "eval/reward_rate": 0.021484375, "replay/size": 382269.0, "replay/inserts": 7424.0, "replay/samples": 29696.0, "replay/insert_wait_avg": 1.5800690342640054e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.238865284056499e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 76432.0, "eval_replay/inserts": 2256.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2241145397754425e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.599592208862305e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0214145183563, "timer/env.step_count": 928.0, "timer/env.step_total": 84.30687999725342, "timer/env.step_frac": 0.08430507464468491, "timer/env.step_avg": 0.09084793103152308, "timer/env.step_min": 0.02281951904296875, "timer/env.step_max": 1.9882144927978516, "timer/replay._sample_count": 29696.0, "timer/replay._sample_total": 14.116240978240967, "timer/replay._sample_frac": 0.014115938692212726, "timer/replay._sample_avg": 0.000475358330355636, "timer/replay._sample_min": 0.000377655029296875, "timer/replay._sample_max": 0.010497331619262695, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1210.0, "timer/agent.policy_total": 19.302622318267822, "timer/agent.policy_frac": 0.019302208970759502, "timer/agent.policy_avg": 0.015952580428320515, "timer/agent.policy_min": 0.009558677673339844, "timer/agent.policy_max": 0.06028008460998535, "timer/dataset_train_count": 1856.0, "timer/dataset_train_total": 0.31302905082702637, "timer/dataset_train_frac": 0.00031302234760421764, "timer/dataset_train_avg": 0.0001686578937645616, "timer/dataset_train_min": 9.107589721679688e-05, "timer/dataset_train_max": 0.02513432502746582, "timer/agent.train_count": 1856.0, "timer/agent.train_total": 833.3053824901581, "timer/agent.train_frac": 0.8332875380388787, "timer/agent.train_avg": 0.44897919315202484, "timer/agent.train_min": 0.43805932998657227, "timer/agent.train_max": 0.9777882099151611, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47877979278564453, "timer/agent.report_frac": 0.00047876954016653816, "timer/agent.report_avg": 0.23938989639282227, "timer/agent.report_min": 0.23335719108581543, "timer/agent.report_max": 0.2454226016998291, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8133392333984375e-05, "timer/dataset_eval_frac": 2.8132789883838994e-08, "timer/dataset_eval_avg": 2.8133392333984375e-05, "timer/dataset_eval_min": 2.8133392333984375e-05, "timer/dataset_eval_max": 2.8133392333984375e-05, "fps": 7.423739626868894}
{"step": 382984, "time": 51415.24919629097, "episode/length": 317.0, "episode/score": 8.445734395101681, "episode/reward_rate": 0.9905660377358491, "episode/intrinsic_return": 0.3457342393030558}
{"step": 383312, "time": 51456.59709525108, "episode/length": 213.0, "episode/score": 6.3498453393731324, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.24984506209511892}
{"step": 383360, "time": 51463.864637851715, "episode/length": 229.0, "episode/score": 6.354763654540875, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.25476349199016113}
{"step": 383424, "time": 51473.213911771774, "episode/length": 201.0, "episode/score": 7.324776339732125, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.22477613102273608}
{"step": 383624, "time": 51499.29002594948, "episode/length": 174.0, "episode/score": 5.2972509087057915, "episode/reward_rate": 0.96, "episode/intrinsic_return": 0.1972507642576602}
{"step": 383744, "time": 51515.358951091766, "episode/length": 142.0, "episode/score": 6.260553547650488, "episode/reward_rate": 0.965034965034965, "episode/intrinsic_return": 0.16055336757926852}
{"step": 384040, "time": 51552.944742679596, "episode/length": 256.0, "episode/score": 4.392250170929401, "episode/reward_rate": 0.9766536964980544, "episode/intrinsic_return": 0.29225002380371734}
{"step": 384296, "time": 51585.76087260246, "episode/length": 272.0, "episode/score": 7.40338507704746, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.30338501409005403}
{"step": 384632, "time": 51629.03673386574, "episode/length": 205.0, "episode/score": 8.325479903942323, "episode/reward_rate": 0.970873786407767, "episode/intrinsic_return": 0.2254796700872248}
{"step": 384824, "time": 51653.976304769516, "episode/length": 174.0, "episode/score": 8.297924254089594, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.1979240367654711}
{"step": 384928, "time": 51668.69281435013, "episode/length": 201.0, "episode/score": 7.339337440833333, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.2393372933001956}
{"step": 384952, "time": 51673.03282546997, "episode/length": 150.0, "episode/score": 8.266352509348508, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.16635217246584943}
{"step": 385040, "time": 51686.55534505844, "episode/length": 176.0, "episode/score": 8.310166897659656, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.21016666264040396}
{"step": 385584, "time": 51754.7104947567, "episode/length": 160.0, "episode/score": 8.275745765942702, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.17574548639458953}
{"step": 385776, "time": 51779.79307246208, "episode/length": 216.0, "episode/score": 9.336744331129012, "episode/reward_rate": 0.9723502304147466, "episode/intrinsic_return": 0.2367440384841757}
{"step": 385800, "time": 51784.3869202137, "episode/length": 304.0, "episode/score": 7.430897609163367, "episode/reward_rate": 0.9901639344262295, "episode/intrinsic_return": 0.33089740045397775}
{"step": 386256, "time": 51841.72907662392, "episode/length": 178.0, "episode/score": 9.310955343073147, "episode/reward_rate": 0.9664804469273743, "episode/intrinsic_return": 0.21095507397330948}
{"step": 386304, "time": 51849.09190034866, "episode/length": 157.0, "episode/score": 5.262164388106612, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.16216421315766638}
{"step": 386312, "time": 51851.56808972359, "episode/length": 169.0, "episode/score": 6.265984549027053, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.1659843689558329}
{"step": 386376, "time": 51860.959953546524, "episode/length": 180.0, "episode/score": 7.286155254081677, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.18615498739745817}
{"step": 387152, "time": 51957.28494477272, "episode/length": 195.0, "episode/score": 8.332461580346717, "episode/reward_rate": 0.9693877551020408, "episode/intrinsic_return": 0.23246147990357713}
{"step": 387248, "time": 51970.698107242584, "episode/length": 180.0, "episode/score": 8.303781905420692, "episode/reward_rate": 0.9834254143646409, "episode/intrinsic_return": 0.2037816359425051}
{"step": 387424, "time": 51993.79688501358, "episode/length": 205.0, "episode/score": 8.34432950523842, "episode/reward_rate": 0.9854368932038835, "episode/intrinsic_return": 0.24432925066139433}
{"step": 387520, "time": 52006.96288442612, "episode/length": 33.0, "episode/score": 4.139458472665865, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.03945833264151588}
{"step": 387832, "time": 52047.31839323044, "episode/length": 50.0, "episode/score": 4.1625001289648935, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.06249999871943146}
{"step": 388200, "time": 52093.949947595596, "episode/length": 45.0, "episode/score": 3.153500104090199, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.05349999899044633}
{"step": 388256, "time": 52102.39698576927, "episode/length": 249.0, "episode/score": 6.3857180119885015, "episode/reward_rate": 0.976, "episode/intrinsic_return": 0.2857177950136247}
{"step": 388408, "time": 52122.67921805382, "episode/length": 156.0, "episode/score": 7.258505274908202, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.1585050249877895}
{"step": 388480, "time": 52133.0371530056, "episode/length": 262.0, "episode/score": 9.392526336279843, "episode/reward_rate": 0.9809885931558935, "episode/intrinsic_return": 0.2925260846132005}
{"step": 388752, "time": 52167.70185422897, "episode/length": 153.0, "episode/score": 8.253515110218359, "episode/reward_rate": 0.961038961038961, "episode/intrinsic_return": 0.1535148806124198}
{"step": 388808, "time": 52176.176852464676, "episode/length": 49.0, "episode/score": 2.154101284002536, "episode/reward_rate": 0.9, "episode/intrinsic_return": 0.054101342233479954}
{"step": 388848, "time": 52182.48845791817, "episode/length": 526.0, "episode/score": 12.638662844266946, "episode/reward_rate": 0.9981024667931688, "episode/intrinsic_return": 0.5386625281062152}
{"step": 389056, "time": 52209.275034189224, "episode/length": 342.0, "episode/score": 10.501195583161461, "episode/reward_rate": 0.9912536443148688, "episode/intrinsic_return": 0.4011953724148043}
{"step": 389376, "time": 52249.99287557602, "episode/length": 383.0, "episode/score": 10.538544152748727, "episode/reward_rate": 0.9973958333333334, "episode/intrinsic_return": 0.438543850208589}
{"step": 389416, "time": 52256.32952141762, "episode/length": 151.0, "episode/score": 7.272854475267195, "episode/reward_rate": 0.9539473684210527, "episode/intrinsic_return": 0.17285424280908046}
{"step": 389464, "time": 52263.83159828186, "episode/length": 150.0, "episode/score": 8.251786084495507, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.15178581699638016}
{"step": 390000, "time": 52349.847120046616, "eval_episode/length": 149.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9666666666666667}
{"step": 390000, "time": 52352.10943484306, "eval_episode/length": 165.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.963855421686747}
{"step": 390000, "time": 52353.803691625595, "eval_episode/length": 170.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9766081871345029}
{"step": 390000, "time": 52355.991191864014, "eval_episode/length": 36.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.972972972972973}
{"step": 390000, "time": 52358.36293387413, "eval_episode/length": 207.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9711538461538461}
{"step": 390000, "time": 52360.820484638214, "eval_episode/length": 229.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9739130434782609}
{"step": 390000, "time": 52362.48051261902, "eval_episode/length": 231.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.978448275862069}
{"step": 390000, "time": 52364.88133955002, "eval_episode/length": 43.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9772727272727273}
{"step": 390024, "time": 52367.790811538696, "episode/length": 192.0, "episode/score": 7.323573703314651, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.2235734483883789}
{"step": 390185, "time": 52389.776703596115, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.201797402871621, "train/action_min": 0.0, "train/action_std": 3.3231136141596616, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04941831760712572, "train/actor_opt_grad_steps": 96230.0, "train/actor_opt_loss": -6.169729439189306, "train/adv_mag": 0.5477132950280164, "train/adv_max": 0.5238022625446319, "train/adv_mean": 0.004006149283874972, "train/adv_min": -0.4172102733238323, "train/adv_std": 0.06119856494101318, "train/cont_avg": 0.994605152027027, "train/cont_loss_mean": 0.0002065447262516208, "train/cont_loss_std": 0.006344450784288901, "train/cont_neg_acc": 0.9937709147865708, "train/cont_neg_loss": 0.02916600357715793, "train/cont_pos_acc": 0.9999787465946094, "train/cont_pos_loss": 5.66417498329236e-05, "train/cont_pred": 0.9946048085753982, "train/cont_rate": 0.994605152027027, "train/dyn_loss_mean": 6.69244164389533, "train/dyn_loss_std": 8.895886140256314, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.086310282591227, "train/extr_critic_critic_opt_grad_steps": 96230.0, "train/extr_critic_critic_opt_loss": 16397.2452808277, "train/extr_critic_mag": 7.205358675363901, "train/extr_critic_max": 7.205358675363901, "train/extr_critic_mean": 1.6689604888091216, "train/extr_critic_min": -0.5549125632724247, "train/extr_critic_std": 1.6012664008784938, "train/extr_return_normed_mag": 1.6423827538619171, "train/extr_return_normed_max": 1.6423827538619171, "train/extr_return_normed_mean": 0.3680739526813095, "train/extr_return_normed_min": -0.13409421315064302, "train/extr_return_normed_std": 0.3261062532663345, "train/extr_return_rate": 0.6871935180715613, "train/extr_return_raw_mag": 8.09121616724375, "train/extr_return_raw_max": 8.09121616724375, "train/extr_return_raw_mean": 1.6890665727692682, "train/extr_return_raw_min": -0.8354789255438624, "train/extr_return_raw_std": 1.639574334428117, "train/extr_reward_mag": 1.02815362698323, "train/extr_reward_max": 1.02815362698323, "train/extr_reward_mean": 0.035198675700136135, "train/extr_reward_min": -0.6461683614833935, "train/extr_reward_std": 0.18134989351839634, "train/image_loss_mean": 3.7371518663457923, "train/image_loss_std": 9.004165622350332, "train/model_loss_mean": 7.831263637542724, "train/model_loss_std": 13.077916792276744, "train/model_opt_grad_norm": 40.26668626329173, "train/model_opt_grad_steps": 96143.34594594594, "train/model_opt_loss": 11921.638154560811, "train/model_opt_model_opt_grad_overflow": 0.005405405405405406, "train/model_opt_model_opt_grad_scale": 1506.7567567567567, "train/policy_entropy_mag": 2.5028751063991237, "train/policy_entropy_max": 2.5028751063991237, "train/policy_entropy_mean": 0.45974377715909803, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.5602520672050683, "train/policy_logprob_mag": 7.4383840689788, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.4595082141257621, "train/policy_logprob_min": -7.4383840689788, "train/policy_logprob_std": 1.047296625214654, "train/policy_randomness_mag": 0.8834050784239897, "train/policy_randomness_max": 0.8834050784239897, "train/policy_randomness_mean": 0.16226937750706802, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.19774439520127066, "train/post_ent_mag": 60.15855770626584, "train/post_ent_max": 60.15855770626584, "train/post_ent_mean": 43.78360940056878, "train/post_ent_min": 19.156336067818305, "train/post_ent_std": 7.07105757481343, "train/prior_ent_mag": 74.68237943907042, "train/prior_ent_max": 74.68237943907042, "train/prior_ent_mean": 50.458521559431745, "train/prior_ent_min": 30.536630919172957, "train/prior_ent_std": 6.924719689343426, "train/rep_loss_mean": 6.69244164389533, "train/rep_loss_std": 8.895886140256314, "train/reward_avg": 0.02304772256898719, "train/reward_loss_mean": 0.07844023048072248, "train/reward_loss_std": 0.18660309757735277, "train/reward_max_data": 1.0185473300315238, "train/reward_max_pred": 1.0157504081726074, "train/reward_neg_acc": 0.9985999004260914, "train/reward_neg_loss": 0.053605783207191005, "train/reward_pos_acc": 0.8777323062355454, "train/reward_pos_loss": 0.7589783027365401, "train/reward_pred": 0.022733758329539687, "train/reward_rate": 0.03524070945945946, "train_stats/sum_log_reward": 7.127027105640721, "train_stats/max_log_achievement_collect_coal": 0.1891891891891892, "train_stats/max_log_achievement_collect_drink": 5.918918918918919, "train_stats/max_log_achievement_collect_sapling": 2.5135135135135136, "train_stats/max_log_achievement_collect_stone": 1.2972972972972974, "train_stats/max_log_achievement_collect_wood": 9.0, "train_stats/max_log_achievement_defeat_skeleton": 0.02702702702702703, "train_stats/max_log_achievement_defeat_zombie": 0.6756756756756757, "train_stats/max_log_achievement_eat_cow": 0.16216216216216217, "train_stats/max_log_achievement_make_wood_pickaxe": 1.3513513513513513, "train_stats/max_log_achievement_make_wood_sword": 1.2702702702702702, "train_stats/max_log_achievement_place_furnace": 0.02702702702702703, "train_stats/max_log_achievement_place_plant": 2.3783783783783785, "train_stats/max_log_achievement_place_stone": 0.10810810810810811, "train_stats/max_log_achievement_place_table": 2.918918918918919, "train_stats/max_log_achievement_wake_up": 0.972972972972973, "train_stats/mean_log_entropy": 0.4003710227238165, "eval_stats/sum_log_reward": 6.100000083446503, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 2.875, "eval_stats/max_log_achievement_collect_sapling": 1.5, "eval_stats/max_log_achievement_collect_stone": 0.625, "eval_stats/max_log_achievement_collect_wood": 9.875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.125, "eval_stats/max_log_achievement_eat_cow": 0.375, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.75, "eval_stats/max_log_achievement_make_wood_sword": 1.25, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.125, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 3.125, "eval_stats/max_log_achievement_wake_up": 0.75, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9990234375, "report/cont_loss_mean": 2.04479920284939e-06, "report/cont_loss_std": 9.3809994723415e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 2.4824830688885413e-06, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.044371285592206e-06, "report/cont_pred": 0.9990214109420776, "report/cont_rate": 0.9990234375, "report/dyn_loss_mean": 7.312277793884277, "report/dyn_loss_std": 8.708086967468262, "report/image_loss_mean": 3.8322434425354004, "report/image_loss_std": 7.50286340713501, "report/model_loss_mean": 8.293397903442383, "report/model_loss_std": 11.761340141296387, "report/post_ent_mag": 59.45090103149414, "report/post_ent_max": 59.45090103149414, "report/post_ent_mean": 43.890037536621094, "report/post_ent_min": 19.343687057495117, "report/post_ent_std": 7.510846138000488, "report/prior_ent_mag": 75.13581848144531, "report/prior_ent_max": 75.13581848144531, "report/prior_ent_mean": 51.1844482421875, "report/prior_ent_min": 33.934688568115234, "report/prior_ent_std": 6.702042579650879, "report/rep_loss_mean": 7.312277793884277, "report/rep_loss_std": 8.708086967468262, "report/reward_avg": 0.030528094619512558, "report/reward_loss_mean": 0.07378587126731873, "report/reward_loss_std": 0.16235694289207458, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0020215511322021, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.04624610021710396, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7693415880203247, "report/reward_pred": 0.02840718999505043, "report/reward_rate": 0.0380859375, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 2.407041574770119e-05, "eval/cont_loss_std": 0.00038094885530881584, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.004187558311969042, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 7.743012247374281e-06, "eval/cont_pred": 0.9961023330688477, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 19.89826774597168, "eval/dyn_loss_std": 12.244487762451172, "eval/image_loss_mean": 28.206092834472656, "eval/image_loss_std": 35.58867263793945, "eval/model_loss_mean": 40.270477294921875, "eval/model_loss_std": 39.546119689941406, "eval/post_ent_mag": 57.27778625488281, "eval/post_ent_max": 57.27778625488281, "eval/post_ent_mean": 41.096649169921875, "eval/post_ent_min": 18.32373809814453, "eval/post_ent_std": 7.114047050476074, "eval/prior_ent_mag": 75.13581848144531, "eval/prior_ent_max": 75.13581848144531, "eval/prior_ent_mean": 53.7237663269043, "eval/prior_ent_min": 36.50285720825195, "eval/prior_ent_std": 6.138432502746582, "eval/rep_loss_mean": 19.89826774597168, "eval/rep_loss_std": 12.244487762451172, "eval/reward_avg": 0.01425781287252903, "eval/reward_loss_mean": 0.12540094554424286, "eval/reward_loss_std": 0.7285852432250977, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0028941631317139, "eval/reward_neg_acc": 0.9920319318771362, "eval/reward_neg_loss": 0.08043287694454193, "eval/reward_pos_acc": 0.75, "eval/reward_pos_loss": 2.382797956466675, "eval/reward_pred": 0.012214791029691696, "eval/reward_rate": 0.01953125, "replay/size": 389681.0, "replay/inserts": 7412.0, "replay/samples": 29648.0, "replay/insert_wait_avg": 1.5968447817510614e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.303177313230775e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 78448.0, "eval_replay/inserts": 2016.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1509373074486143e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.238719940185547e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0139317512512, "timer/env.step_count": 927.0, "timer/env.step_total": 82.66574120521545, "timer/env.step_frac": 0.08266458954271666, "timer/env.step_avg": 0.0891755568556801, "timer/env.step_min": 0.02333521842956543, "timer/env.step_max": 2.1249802112579346, "timer/replay._sample_count": 29648.0, "timer/replay._sample_total": 14.159389972686768, "timer/replay._sample_frac": 0.01415919271033601, "timer/replay._sample_avg": 0.00047758330992602425, "timer/replay._sample_min": 0.00037288665771484375, "timer/replay._sample_max": 0.010857105255126953, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1179.0, "timer/agent.policy_total": 18.941548109054565, "timer/agent.policy_frac": 0.01894128422379438, "timer/agent.policy_avg": 0.016065774477569607, "timer/agent.policy_min": 0.009405136108398438, "timer/agent.policy_max": 0.05680346488952637, "timer/dataset_train_count": 1853.0, "timer/dataset_train_total": 0.2835559844970703, "timer/dataset_train_frac": 0.00028355203412066415, "timer/dataset_train_avg": 0.00015302535590775516, "timer/dataset_train_min": 9.131431579589844e-05, "timer/dataset_train_max": 0.0009531974792480469, "timer/agent.train_count": 1853.0, "timer/agent.train_total": 836.0728623867035, "timer/agent.train_frac": 0.8360612145898311, "timer/agent.train_avg": 0.4511996019356198, "timer/agent.train_min": 0.4380486011505127, "timer/agent.train_max": 0.9899768829345703, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4748845100402832, "timer/agent.report_frac": 0.00047487789415958704, "timer/agent.report_avg": 0.2374422550201416, "timer/agent.report_min": 0.2303907871246338, "timer/agent.report_max": 0.24449372291564941, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9325485229492188e-05, "timer/dataset_eval_frac": 2.932507667981846e-08, "timer/dataset_eval_avg": 2.9325485229492188e-05, "timer/dataset_eval_min": 2.9325485229492188e-05, "timer/dataset_eval_max": 2.9325485229492188e-05, "fps": 7.411795248534236}
{"step": 390232, "time": 52395.33720898628, "episode/length": 184.0, "episode/score": 10.314196765933957, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.21419647363836702}
{"step": 390344, "time": 52410.53206896782, "episode/length": 39.0, "episode/score": 3.1440499849159096, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.04404988959504408}
{"step": 390360, "time": 52413.96608018875, "episode/length": 162.0, "episode/score": 5.273914417077322, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.17391423549270257}
{"step": 390496, "time": 52432.057711839676, "episode/length": 139.0, "episode/score": 7.265662862064346, "episode/reward_rate": 0.9571428571428572, "episode/intrinsic_return": 0.16566262902415474}
{"step": 390840, "time": 52475.87304854393, "episode/length": 248.0, "episode/score": 7.388331156917047, "episode/reward_rate": 0.9839357429718876, "episode/intrinsic_return": 0.28833094704350515}
{"step": 390848, "time": 52478.31189084053, "episode/length": 178.0, "episode/score": 8.270666756690844, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.1706666147456417}
{"step": 390912, "time": 52487.6670665741, "episode/length": 180.0, "episode/score": 9.300796188277673, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.20079592462025175}
{"step": 391240, "time": 52529.118288517, "episode/length": 303.0, "episode/score": 8.425545745434647, "episode/reward_rate": 0.9868421052631579, "episode/intrinsic_return": 0.3255455115795485}
{"step": 391584, "time": 52572.93544602394, "episode/length": 168.0, "episode/score": 8.276633498011506, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.17663317370170262}
{"step": 391928, "time": 52616.61105632782, "episode/length": 195.0, "episode/score": 8.32327634253852, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.22327612579647393}
{"step": 391952, "time": 52621.24065589905, "episode/length": 200.0, "episode/score": 9.334628118125693, "episode/reward_rate": 0.9701492537313433, "episode/intrinsic_return": 0.2346278254808567}
{"step": 392344, "time": 52671.3702352047, "episode/length": 178.0, "episode/score": 7.293666289428074, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.19366614562022733}
{"step": 392520, "time": 52694.73434495926, "episode/length": 209.0, "episode/score": 7.331356611364754, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.23135640498367138}
{"step": 393064, "time": 52763.45982313156, "episode/length": 184.0, "episode/score": 7.3151118762434635, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.2151116675340745}
{"step": 393136, "time": 52774.011248111725, "episode/length": 150.0, "episode/score": 7.2624041911476525, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.16240400173410308}
{"step": 393336, "time": 52801.44979763031, "episode/length": 261.0, "episode/score": 7.398926229452627, "episode/reward_rate": 0.9770992366412213, "episode/intrinsic_return": 0.2989260408830887}
{"step": 393424, "time": 52813.684249162674, "episode/length": 365.0, "episode/score": 10.510106325288689, "episode/reward_rate": 0.9972677595628415, "episode/intrinsic_return": 0.4101060329930988}
{"step": 393664, "time": 52844.74154281616, "episode/length": 213.0, "episode/score": 7.329141497055389, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.2291413307793846}
{"step": 393752, "time": 52857.05025982857, "episode/length": 175.0, "episode/score": 7.295325480694373, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.19532527198498428}
{"step": 394632, "time": 52966.20332980156, "episode/length": 186.0, "episode/score": 8.3051251029392, "episode/reward_rate": 0.9679144385026738, "episode/intrinsic_return": 0.20512486873485614}
{"step": 394728, "time": 52979.61682057381, "episode/length": 162.0, "episode/score": 5.272482986096293, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.1724828346632421}
{"step": 394872, "time": 52998.76575231552, "episode/length": 502.0, "episode/score": 12.641911991664529, "episode/reward_rate": 0.9980119284294234, "episode/intrinsic_return": 0.541911641626939}
{"step": 394904, "time": 53004.734800338745, "episode/length": 195.0, "episode/score": 8.32219572660324, "episode/reward_rate": 0.9693877551020408, "episode/intrinsic_return": 0.22219546259657363}
{"step": 394944, "time": 53011.115686416626, "episode/length": 159.0, "episode/score": 5.2761421721297665, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.1761420046314015}
{"step": 395128, "time": 53035.432381629944, "episode/length": 171.0, "episode/score": 8.284269175550435, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.18426897868630476}
{"step": 395192, "time": 53044.802214860916, "episode/length": 333.0, "episode/score": 10.494388286744652, "episode/reward_rate": 0.9970059880239521, "episode/intrinsic_return": 0.39438799957133597}
{"step": 395488, "time": 53082.60295009613, "episode/length": 302.0, "episode/score": 10.44921468823668, "episode/reward_rate": 0.9867986798679867, "episode/intrinsic_return": 0.3492143971052428}
{"step": 396056, "time": 53153.40610361099, "episode/length": 147.0, "episode/score": 6.2673544015542575, "episode/reward_rate": 0.9527027027027027, "episode/intrinsic_return": 0.16735430163498677}
{"step": 396416, "time": 53198.878589868546, "episode/length": 210.0, "episode/score": 7.32276547328911, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.22276526457972068}
{"step": 396560, "time": 53217.8339343071, "episode/length": 170.0, "episode/score": 6.289301429804254, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.1893011662632489}
{"step": 396864, "time": 53256.74711918831, "episode/length": 244.0, "episode/score": 10.37264453696298, "episode/reward_rate": 0.9836734693877551, "episode/intrinsic_return": 0.2726442698713072}
{"step": 397024, "time": 53277.69889545441, "episode/length": 236.0, "episode/score": 9.374427026445119, "episode/reward_rate": 0.9789029535864979, "episode/intrinsic_return": 0.2744267604593915}
{"step": 397072, "time": 53285.25365900993, "episode/length": 265.0, "episode/score": 7.397630312143519, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.297630205821406}
{"step": 397088, "time": 53288.842109918594, "episode/length": 306.0, "episode/score": 10.451658613135805, "episode/reward_rate": 0.9706840390879479, "episode/intrinsic_return": 0.35165830512414686}
{"step": 397360, "time": 53323.720610141754, "episode/length": 233.0, "episode/score": 8.379747800716359, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.2797475440438575}
{"step": 397480, "time": 53339.90493440628, "episode/length": 177.0, "episode/score": 7.29857789621019, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.1985777506561135}
{"step": 397624, "time": 53359.60349440575, "episode/length": 150.0, "episode/score": 7.266761052957008, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.16676092533089104}
{"step": 397849, "time": 53390.07814526558, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.224132537841797, "train/action_min": 0.0, "train/action_std": 3.3544221594929695, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.047575836341517665, "train/actor_opt_grad_steps": 98115.0, "train/actor_opt_loss": -10.470366101556769, "train/adv_mag": 0.5426174220629036, "train/adv_max": 0.498156798693041, "train/adv_mean": 0.002573920842185847, "train/adv_min": -0.4461321150884032, "train/adv_std": 0.058916233266548566, "train/cont_avg": 0.99462890625, "train/cont_loss_mean": 0.00016693119652592495, "train/cont_loss_std": 0.0051335752954055165, "train/cont_neg_acc": 0.9975694448997577, "train/cont_neg_loss": 0.009292463501700135, "train/cont_pos_acc": 0.999974399805069, "train/cont_pos_loss": 0.00011273862223548647, "train/cont_pred": 0.9946125599866112, "train/cont_rate": 0.99462890625, "train/dyn_loss_mean": 6.7604318261146545, "train/dyn_loss_std": 8.880870193243027, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.022318716160953, "train/extr_critic_critic_opt_grad_steps": 98115.0, "train/extr_critic_critic_opt_loss": 16208.141464233398, "train/extr_critic_mag": 7.495079214374225, "train/extr_critic_max": 7.495079214374225, "train/extr_critic_mean": 1.774519609908263, "train/extr_critic_min": -0.5622208087394635, "train/extr_critic_std": 1.7095563014348347, "train/extr_return_normed_mag": 1.6259254155059655, "train/extr_return_normed_max": 1.6259254155059655, "train/extr_return_normed_mean": 0.36833118336896103, "train/extr_return_normed_min": -0.12827494783171764, "train/extr_return_normed_std": 0.3286568521677206, "train/extr_return_rate": 0.6782745723612607, "train/extr_return_raw_mag": 8.452505193650723, "train/extr_return_raw_max": 8.452505193650723, "train/extr_return_raw_mean": 1.7881604687621195, "train/extr_return_raw_min": -0.8437548050036033, "train/extr_return_raw_std": 1.7419618088752031, "train/extr_reward_mag": 1.0314280949532986, "train/extr_reward_max": 1.0314280949532986, "train/extr_reward_mean": 0.03628706862218678, "train/extr_reward_min": -0.6505653361479441, "train/extr_reward_std": 0.18425491700569788, "train/image_loss_mean": 3.823210157454014, "train/image_loss_std": 8.948472633957863, "train/model_loss_mean": 7.9590025419990225, "train/model_loss_std": 13.032953465978304, "train/model_opt_grad_norm": 40.6989435950915, "train/model_opt_grad_steps": 98026.57291666667, "train/model_opt_loss": 10571.713366190592, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1334.6354166666667, "train/policy_entropy_mag": 2.5073714343210063, "train/policy_entropy_max": 2.5073714343210063, "train/policy_entropy_mean": 0.46314132927606505, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.5662733661010861, "train/policy_logprob_mag": 7.438384046157201, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.46294311340898275, "train/policy_logprob_min": -7.438384046157201, "train/policy_logprob_std": 1.050609093780319, "train/policy_randomness_mag": 0.8849920826032758, "train/policy_randomness_max": 0.8849920826032758, "train/policy_randomness_mean": 0.16346856552020958, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.19986964816537997, "train/post_ent_mag": 60.12660570939382, "train/post_ent_max": 60.12660570939382, "train/post_ent_mean": 43.79103231430054, "train/post_ent_min": 19.26173088947932, "train/post_ent_std": 7.0976754029591875, "train/prior_ent_mag": 74.66309495766957, "train/prior_ent_max": 74.66309495766957, "train/prior_ent_mean": 50.51729635397593, "train/prior_ent_min": 30.389414697885513, "train/prior_ent_std": 6.938270270824432, "train/rep_loss_mean": 6.7604318261146545, "train/rep_loss_std": 8.880870193243027, "train/reward_avg": 0.024075009748533677, "train/reward_loss_mean": 0.07936635887017474, "train/reward_loss_std": 0.18841767881531268, "train/reward_max_data": 1.0189583661655586, "train/reward_max_pred": 1.0174625366926193, "train/reward_neg_acc": 0.9985635997727513, "train/reward_neg_loss": 0.05393686485088741, "train/reward_pos_acc": 0.8880233451103171, "train/reward_pos_loss": 0.7570288696636757, "train/reward_pred": 0.023708669138917077, "train/reward_rate": 0.036127726236979164, "train_stats/sum_log_reward": 7.775675812283078, "train_stats/max_log_achievement_collect_coal": 0.10810810810810811, "train_stats/max_log_achievement_collect_drink": 7.297297297297297, "train_stats/max_log_achievement_collect_sapling": 2.081081081081081, "train_stats/max_log_achievement_collect_stone": 2.4594594594594597, "train_stats/max_log_achievement_collect_wood": 11.54054054054054, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.40540540540540543, "train_stats/max_log_achievement_eat_cow": 0.16216216216216217, "train_stats/max_log_achievement_make_wood_pickaxe": 2.324324324324324, "train_stats/max_log_achievement_make_wood_sword": 1.2432432432432432, "train_stats/max_log_achievement_place_furnace": 0.08108108108108109, "train_stats/max_log_achievement_place_plant": 2.0, "train_stats/max_log_achievement_place_stone": 0.6216216216216216, "train_stats/max_log_achievement_place_table": 3.4594594594594597, "train_stats/max_log_achievement_wake_up": 1.1081081081081081, "train_stats/mean_log_entropy": 0.3896414009300438, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 8.302359901790624e-07, "report/cont_loss_std": 1.1427469871705398e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 2.463659257045947e-05, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 7.368776664407051e-07, "report/cont_pred": 0.9960931539535522, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 6.27707576751709, "report/dyn_loss_std": 8.627799034118652, "report/image_loss_mean": 2.654879331588745, "report/image_loss_std": 5.284683704376221, "report/model_loss_mean": 6.491411209106445, "report/model_loss_std": 9.333468437194824, "report/post_ent_mag": 61.74567794799805, "report/post_ent_max": 61.74567794799805, "report/post_ent_mean": 44.5004997253418, "report/post_ent_min": 20.902969360351562, "report/post_ent_std": 6.939370632171631, "report/prior_ent_mag": 74.88838195800781, "report/prior_ent_max": 74.88838195800781, "report/prior_ent_mean": 50.78422546386719, "report/prior_ent_min": 31.97704315185547, "report/prior_ent_std": 6.272761821746826, "report/rep_loss_mean": 6.27707576751709, "report/rep_loss_std": 8.627799034118652, "report/reward_avg": 0.02549058385193348, "report/reward_loss_mean": 0.07028545439243317, "report/reward_loss_std": 0.1345483660697937, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0064427852630615, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.04697733372449875, "report/reward_pos_acc": 0.8947368264198303, "report/reward_pos_loss": 0.6750698685646057, "report/reward_pred": 0.025703055784106255, "report/reward_rate": 0.037109375, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 6.145971565274522e-05, "eval/cont_loss_std": 0.0015245139366015792, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.012526648119091988, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.958843765554775e-07, "eval/cont_pred": 0.9951769709587097, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 17.698606491088867, "eval/dyn_loss_std": 11.769432067871094, "eval/image_loss_mean": 19.74759292602539, "eval/image_loss_std": 31.715129852294922, "eval/model_loss_mean": 30.49264144897461, "eval/model_loss_std": 35.83356475830078, "eval/post_ent_mag": 61.82237243652344, "eval/post_ent_max": 61.82237243652344, "eval/post_ent_mean": 42.97567367553711, "eval/post_ent_min": 21.876819610595703, "eval/post_ent_std": 7.208524227142334, "eval/prior_ent_mag": 74.88838195800781, "eval/prior_ent_max": 74.88838195800781, "eval/prior_ent_mean": 54.821510314941406, "eval/prior_ent_min": 32.06818771362305, "eval/prior_ent_std": 6.188082695007324, "eval/rep_loss_mean": 17.698606491088867, "eval/rep_loss_std": 11.769432067871094, "eval/reward_avg": 0.015625, "eval/reward_loss_mean": 0.12582328915596008, "eval/reward_loss_std": 0.736609697341919, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0040807723999023, "eval/reward_neg_acc": 0.9870518445968628, "eval/reward_neg_loss": 0.08280496299266815, "eval/reward_pos_acc": 0.800000011920929, "eval/reward_pos_loss": 2.285343647003174, "eval/reward_pred": 0.01719548925757408, "eval/reward_rate": 0.01953125, "replay/size": 397345.0, "replay/inserts": 7664.0, "replay/samples": 30656.0, "replay/insert_wait_avg": 1.6424252743014215e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.501832503117699e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 78448.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 1.0281801223754883e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2969014644623, "timer/env.step_count": 958.0, "timer/env.step_total": 84.53683567047119, "timer/env.step_frac": 0.08451174400991039, "timer/env.step_avg": 0.08824304349736033, "timer/env.step_min": 0.023339271545410156, "timer/env.step_max": 2.156843423843384, "timer/replay._sample_count": 30656.0, "timer/replay._sample_total": 14.839550971984863, "timer/replay._sample_frac": 0.014835146395294587, "timer/replay._sample_avg": 0.0004840667723116148, "timer/replay._sample_min": 0.0003490447998046875, "timer/replay._sample_max": 0.025672435760498047, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 958.0, "timer/agent.policy_total": 15.572411060333252, "timer/agent.policy_frac": 0.015567788960992293, "timer/agent.policy_avg": 0.016255126367780013, "timer/agent.policy_min": 0.014681816101074219, "timer/agent.policy_max": 0.06058526039123535, "timer/dataset_train_count": 1916.0, "timer/dataset_train_total": 0.3305490016937256, "timer/dataset_train_frac": 0.00033045089034045065, "timer/dataset_train_avg": 0.00017252035579004468, "timer/dataset_train_min": 9.202957153320312e-05, "timer/dataset_train_max": 0.03016066551208496, "timer/agent.train_count": 1916.0, "timer/agent.train_total": 866.4565644264221, "timer/agent.train_frac": 0.8661993885594425, "timer/agent.train_avg": 0.4522215889490721, "timer/agent.train_min": 0.439359188079834, "timer/agent.train_max": 0.9466166496276855, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4764430522918701, "timer/agent.report_frac": 0.00047630163763812957, "timer/agent.report_avg": 0.23822152614593506, "timer/agent.report_min": 0.2303321361541748, "timer/agent.report_max": 0.2461109161376953, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9802322387695312e-05, "timer/dataset_eval_frac": 2.9793476660843284e-08, "timer/dataset_eval_avg": 2.9802322387695312e-05, "timer/dataset_eval_min": 2.9802322387695312e-05, "timer/dataset_eval_max": 2.9802322387695312e-05, "fps": 7.661616905681772}
{"step": 397928, "time": 53399.560537576675, "episode/length": 170.0, "episode/score": 5.30226911821228, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.20226893546350766}
{"step": 398048, "time": 53415.610875844955, "episode/length": 147.0, "episode/score": 7.259999041627452, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.15999891222600127}
{"step": 398232, "time": 53439.47156262398, "episode/length": 37.0, "episode/score": 3.1418225375236943, "episode/reward_rate": 0.868421052631579, "episode/intrinsic_return": 0.041822419851087034}
{"step": 398568, "time": 53481.9061024189, "episode/length": 184.0, "episode/score": 6.306834174167307, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.20683399642439326}
{"step": 398576, "time": 53484.518171310425, "episode/length": 193.0, "episode/score": 8.318079144599324, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.21807887593604391}
{"step": 398600, "time": 53489.04464221001, "episode/length": 190.0, "episode/score": 7.316093029592594, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.21609277984680375}
{"step": 399008, "time": 53540.09479665756, "episode/length": 172.0, "episode/score": 5.292637426297006, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.19263719023001613}
{"step": 399088, "time": 53551.42491078377, "episode/length": 215.0, "episode/score": 7.334885570737242, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.23488536086370004}
{"step": 399288, "time": 53577.124230861664, "episode/length": 225.0, "episode/score": 7.356106840452412, "episode/reward_rate": 0.9778761061946902, "episode/intrinsic_return": 0.2561066015914548}
{"step": 399552, "time": 53610.87068152428, "episode/length": 187.0, "episode/score": 8.301715571218665, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.20171533940083464}
{"step": 399752, "time": 53636.459190130234, "episode/length": 57.0, "episode/score": 3.160629103449537, "episode/reward_rate": 0.9137931034482759, "episode/intrinsic_return": 0.06062899884454964}
{"step": 399904, "time": 53656.423939704895, "episode/length": 166.0, "episode/score": 7.280894321151209, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.1808942139850842}
{"step": 400008, "time": 53670.618554353714, "episode/length": 178.0, "episode/score": 9.293865764617294, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.1938654774439783}
{"step": 400088, "time": 53696.71156477928, "eval_episode/length": 60.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9836065573770492}
{"step": 400088, "time": 53702.36832809448, "eval_episode/length": 156.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9936305732484076}
{"step": 400088, "time": 53703.99106812477, "eval_episode/length": 159.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.99375}
{"step": 400088, "time": 53705.98419690132, "eval_episode/length": 168.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9704142011834319}
{"step": 400088, "time": 53707.55727362633, "eval_episode/length": 169.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9764705882352941}
{"step": 400088, "time": 53710.00420999527, "eval_episode/length": 192.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9792746113989638}
{"step": 400088, "time": 53712.01230120659, "eval_episode/length": 45.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9782608695652174}
{"step": 400088, "time": 53714.76977109909, "eval_episode/length": 237.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9957983193277311}
{"step": 400344, "time": 53745.82490992546, "episode/length": 166.0, "episode/score": 6.286385266304933, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.18638501335772162}
{"step": 400568, "time": 53774.53929233551, "episode/length": 291.0, "episode/score": 7.428074319364896, "episode/reward_rate": 0.9726027397260274, "episode/intrinsic_return": 0.328074069793729}
{"step": 400600, "time": 53779.92904448509, "episode/length": 188.0, "episode/score": 7.320213805040112, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.22021369604044594}
{"step": 400656, "time": 53788.70387816429, "episode/length": 256.0, "episode/score": 6.385663066235793, "episode/reward_rate": 0.9961089494163424, "episode/intrinsic_return": 0.28566286113527894}
{"step": 400736, "time": 53800.01347446442, "episode/length": 48.0, "episode/score": 3.1509574599349435, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.05095735483519093}
{"step": 400848, "time": 53815.55608701706, "episode/length": 161.0, "episode/score": 8.267000681489662, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.16700051250700199}
{"step": 401176, "time": 53857.035811662674, "episode/length": 177.0, "episode/score": 7.286997212882852, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.18699698834097944}
{"step": 401728, "time": 53928.76434087753, "episode/length": 214.0, "episode/score": 8.342253399219771, "episode/reward_rate": 0.9813953488372092, "episode/intrinsic_return": 0.24225316070806002}
{"step": 401968, "time": 53959.5198032856, "episode/length": 153.0, "episode/score": 8.27559039065818, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.17559018101746915}
{"step": 402104, "time": 53977.770735025406, "episode/length": 187.0, "episode/score": 10.310690199011333, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.2106899043874364}
{"step": 402184, "time": 53989.1206510067, "episode/length": 190.0, "episode/score": 9.284334818568823, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.18433473037839576}
{"step": 402368, "time": 54013.14639592171, "episode/length": 307.0, "episode/score": 7.450345277882661, "episode/reward_rate": 0.987012987012987, "episode/intrinsic_return": 0.35034503867245803}
{"step": 402368, "time": 54013.15166044235, "episode/length": 49.0, "episode/score": 3.1606250929180533, "episode/reward_rate": 0.9, "episode/intrinsic_return": 0.060624998761340976}
{"step": 402760, "time": 54064.18148851395, "episode/length": 48.0, "episode/score": 5.156647825948312, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.05664761793741491}
{"step": 402776, "time": 54067.746388435364, "episode/length": 199.0, "episode/score": 7.315749666881857, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.21574949175828806}
{"step": 403064, "time": 54104.15527510643, "episode/length": 166.0, "episode/score": 8.29462958615568, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.19462931749239942}
{"step": 403072, "time": 54107.02748274803, "episode/length": 110.0, "episode/score": 6.203482983706635, "episode/reward_rate": 0.963963963963964, "episode/intrinsic_return": 0.1034828024712624}
{"step": 403536, "time": 54165.27613258362, "episode/length": 178.0, "episode/score": 9.298065916715132, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.1980656507294043}
{"step": 403768, "time": 54194.93040251732, "episode/length": 399.0, "episode/score": 11.491050798691504, "episode/reward_rate": 0.85, "episode/intrinsic_return": 0.3910505125659256}
{"step": 404040, "time": 54230.368863105774, "episode/length": 159.0, "episode/score": 7.2810009637069015, "episode/reward_rate": 0.9625, "episode/intrinsic_return": 0.1810007125059201}
{"step": 404144, "time": 54244.590346097946, "episode/length": 411.0, "episode/score": 8.519623857832812, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.4196236412071812}
{"step": 404360, "time": 54272.413964271545, "episode/length": 160.0, "episode/score": 8.284058674413245, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.18405839084880427}
{"step": 404616, "time": 54304.96242594719, "episode/length": 280.0, "episode/score": 9.418089977840282, "episode/reward_rate": 0.9857651245551602, "episode/intrinsic_return": 0.31808971069040126}
{"step": 404952, "time": 54347.2419257164, "episode/length": 271.0, "episode/score": 9.425061703790561, "episode/reward_rate": 0.9779411764705882, "episode/intrinsic_return": 0.32506144129729364}
{"step": 405032, "time": 54358.52096390724, "episode/length": 186.0, "episode/score": 9.309471315076735, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.20947104792685423}
{"step": 405273, "time": 54390.09532046318, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.203304476351351, "train/action_min": 0.0, "train/action_std": 3.3394379203383986, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04712806829326861, "train/actor_opt_grad_steps": 100000.0, "train/actor_opt_loss": -7.682159639472092, "train/adv_mag": 0.5213907720269384, "train/adv_max": 0.4874660172977963, "train/adv_mean": 0.0034104617969254883, "train/adv_min": -0.4246557326735677, "train/adv_std": 0.05829299714516949, "train/cont_avg": 0.9947001689189189, "train/cont_loss_mean": 7.167765861948749e-05, "train/cont_loss_std": 0.002157089541567468, "train/cont_neg_acc": 0.9958944665419088, "train/cont_neg_loss": 0.011433466764026741, "train/cont_pos_acc": 0.9999946620013263, "train/cont_pos_loss": 1.604392987194833e-05, "train/cont_pred": 0.9947136186264657, "train/cont_rate": 0.9947001689189189, "train/dyn_loss_mean": 6.868210521904198, "train/dyn_loss_std": 8.956906981081575, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0554234346827944, "train/extr_critic_critic_opt_grad_steps": 100000.0, "train/extr_critic_critic_opt_loss": 16385.56333403716, "train/extr_critic_mag": 7.612332292505212, "train/extr_critic_max": 7.612332292505212, "train/extr_critic_mean": 1.8370427241196503, "train/extr_critic_min": -0.5730438013334532, "train/extr_critic_std": 1.725268486383799, "train/extr_return_normed_mag": 1.611162610311766, "train/extr_return_normed_max": 1.611162610311766, "train/extr_return_normed_mean": 0.372687605506665, "train/extr_return_normed_min": -0.12651615243505787, "train/extr_return_normed_std": 0.32562513174237434, "train/extr_return_rate": 0.7051763460442827, "train/extr_return_raw_mag": 8.55688759571797, "train/extr_return_raw_max": 8.55688759571797, "train/extr_return_raw_mean": 1.8554634822381508, "train/extr_return_raw_min": -0.8452296940056053, "train/extr_return_raw_std": 1.761876242869609, "train/extr_reward_mag": 1.0247339802819329, "train/extr_reward_max": 1.0247339802819329, "train/extr_reward_mean": 0.03636046784955102, "train/extr_reward_min": -0.64937306094814, "train/extr_reward_std": 0.1838375566778956, "train/image_loss_mean": 3.7654815557840706, "train/image_loss_std": 8.800785069852262, "train/model_loss_mean": 7.965523286767908, "train/model_loss_std": 12.936914371799778, "train/model_opt_grad_norm": 41.18623349977576, "train/model_opt_grad_steps": 99910.02702702703, "train/model_opt_loss": 7239.972414748733, "train/model_opt_model_opt_grad_overflow": 0.005405405405405406, "train/model_opt_model_opt_grad_scale": 908.7837837837837, "train/policy_entropy_mag": 2.519191518989769, "train/policy_entropy_max": 2.519191518989769, "train/policy_entropy_mean": 0.4631807686509313, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.5671633937874356, "train/policy_logprob_mag": 7.438384071556298, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.46342281425321424, "train/policy_logprob_min": -7.438384071556298, "train/policy_logprob_std": 1.0534642483737018, "train/policy_randomness_mag": 0.8891640553603302, "train/policy_randomness_max": 0.8891640553603302, "train/policy_randomness_mean": 0.16348248583239477, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.20018378778083903, "train/post_ent_mag": 60.243721647520324, "train/post_ent_max": 60.243721647520324, "train/post_ent_mean": 43.88779653600744, "train/post_ent_min": 19.23846858256572, "train/post_ent_std": 7.097850392315839, "train/prior_ent_mag": 74.65624327788481, "train/prior_ent_max": 74.65624327788481, "train/prior_ent_mean": 50.74756935738228, "train/prior_ent_min": 30.58371459342338, "train/prior_ent_std": 6.8476576444265005, "train/rep_loss_mean": 6.868210521904198, "train/rep_loss_std": 8.956906981081575, "train/reward_avg": 0.024339102701963607, "train/reward_loss_mean": 0.07904373685250411, "train/reward_loss_std": 0.1878561309060535, "train/reward_max_data": 1.0142230046762002, "train/reward_max_pred": 1.012450679572853, "train/reward_neg_acc": 0.9985758478577073, "train/reward_neg_loss": 0.05355758830099493, "train/reward_pos_acc": 0.8901922464370727, "train/reward_pos_loss": 0.7605347646249307, "train/reward_pred": 0.023950013893379554, "train/reward_rate": 0.03605363175675676, "train_stats/sum_log_reward": 7.1263159325248315, "train_stats/max_log_achievement_collect_coal": 0.10526315789473684, "train_stats/max_log_achievement_collect_drink": 4.2368421052631575, "train_stats/max_log_achievement_collect_sapling": 1.868421052631579, "train_stats/max_log_achievement_collect_stone": 1.4736842105263157, "train_stats/max_log_achievement_collect_wood": 11.631578947368421, "train_stats/max_log_achievement_defeat_skeleton": 0.05263157894736842, "train_stats/max_log_achievement_defeat_zombie": 0.3684210526315789, "train_stats/max_log_achievement_eat_cow": 0.07894736842105263, "train_stats/max_log_achievement_make_wood_pickaxe": 2.473684210526316, "train_stats/max_log_achievement_make_wood_sword": 1.263157894736842, "train_stats/max_log_achievement_place_furnace": 0.02631578947368421, "train_stats/max_log_achievement_place_plant": 1.763157894736842, "train_stats/max_log_achievement_place_stone": 0.23684210526315788, "train_stats/max_log_achievement_place_table": 3.5526315789473686, "train_stats/max_log_achievement_wake_up": 0.9736842105263158, "train_stats/mean_log_entropy": 0.36523025718174484, "eval_stats/sum_log_reward": 6.60000005364418, "eval_stats/max_log_achievement_collect_coal": 0.125, "eval_stats/max_log_achievement_collect_drink": 2.75, "eval_stats/max_log_achievement_collect_sapling": 1.875, "eval_stats/max_log_achievement_collect_stone": 0.375, "eval_stats/max_log_achievement_collect_wood": 10.25, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.375, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.625, "eval_stats/max_log_achievement_make_wood_sword": 0.75, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.875, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 3.25, "eval_stats/max_log_achievement_wake_up": 0.75, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.0001019952105707489, "report/cont_loss_std": 0.003095311112701893, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.02514883130788803, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 3.772321633732645e-06, "report/cont_pred": 0.9961835741996765, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 6.9215521812438965, "report/dyn_loss_std": 8.572282791137695, "report/image_loss_mean": 3.9031639099121094, "report/image_loss_std": 10.476253509521484, "report/model_loss_mean": 8.131674766540527, "report/model_loss_std": 14.279921531677246, "report/post_ent_mag": 58.96758270263672, "report/post_ent_max": 58.96758270263672, "report/post_ent_mean": 44.269187927246094, "report/post_ent_min": 21.035917282104492, "report/post_ent_std": 6.966307163238525, "report/prior_ent_mag": 74.74320983886719, "report/prior_ent_max": 74.74320983886719, "report/prior_ent_mean": 51.19528579711914, "report/prior_ent_min": 34.135868072509766, "report/prior_ent_std": 6.236175060272217, "report/rep_loss_mean": 6.9215521812438965, "report/rep_loss_std": 8.572282791137695, "report/reward_avg": 0.0179697647690773, "report/reward_loss_mean": 0.07547803223133087, "report/reward_loss_std": 0.19218571484088898, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0058741569519043, "report/reward_neg_acc": 0.9989979863166809, "report/reward_neg_loss": 0.058615561574697495, "report/reward_pos_acc": 0.9615384936332703, "report/reward_pos_loss": 0.7227375507354736, "report/reward_pred": 0.017990604043006897, "report/reward_rate": 0.025390625, "eval/cont_avg": 0.9921875, "eval/cont_loss_mean": 3.429921707720496e-05, "eval/cont_loss_std": 0.0004984536790288985, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0028711867053061724, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.196151970361825e-05, "eval/cont_pred": 0.9921979904174805, "eval/cont_rate": 0.9921875, "eval/dyn_loss_mean": 21.406627655029297, "eval/dyn_loss_std": 12.364564895629883, "eval/image_loss_mean": 22.758258819580078, "eval/image_loss_std": 28.54848289489746, "eval/model_loss_mean": 35.79735565185547, "eval/model_loss_std": 33.37562561035156, "eval/post_ent_mag": 59.39048385620117, "eval/post_ent_max": 59.39048385620117, "eval/post_ent_mean": 40.79270553588867, "eval/post_ent_min": 19.409473419189453, "eval/post_ent_std": 7.290445804595947, "eval/prior_ent_mag": 74.74320983886719, "eval/prior_ent_max": 74.74320983886719, "eval/prior_ent_mean": 54.66852569580078, "eval/prior_ent_min": 37.06681823730469, "eval/prior_ent_std": 6.0250654220581055, "eval/rep_loss_mean": 21.406627655029297, "eval/rep_loss_std": 12.364564895629883, "eval/reward_avg": 0.04511718824505806, "eval/reward_loss_mean": 0.1950872838497162, "eval/reward_loss_std": 1.0884652137756348, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0029380321502686, "eval/reward_neg_acc": 0.9938335418701172, "eval/reward_neg_loss": 0.08133143931627274, "eval/reward_pos_acc": 0.7647058963775635, "eval/reward_pos_loss": 2.365370035171509, "eval/reward_pred": 0.0373726412653923, "eval/reward_rate": 0.0498046875, "replay/size": 404769.0, "replay/inserts": 7424.0, "replay/samples": 29696.0, "replay/insert_wait_avg": 1.6347922641655495e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.518583202156527e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 80352.0, "eval_replay/inserts": 1904.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1640436509076288e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.08970832824707e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 999.99369764328, "timer/env.step_count": 928.0, "timer/env.step_total": 84.8915662765503, "timer/env.step_frac": 0.08489210129685537, "timer/env.step_avg": 0.09147798090145506, "timer/env.step_min": 0.023436546325683594, "timer/env.step_max": 3.372445583343506, "timer/replay._sample_count": 29696.0, "timer/replay._sample_total": 14.711971044540405, "timer/replay._sample_frac": 0.01471206376521434, "timer/replay._sample_avg": 0.0004954192835580686, "timer/replay._sample_min": 0.0003733634948730469, "timer/replay._sample_max": 0.021886825561523438, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1166.0, "timer/agent.policy_total": 18.997389793395996, "timer/agent.policy_frac": 0.018997509522477796, "timer/agent.policy_avg": 0.016292787129842192, "timer/agent.policy_min": 0.009993553161621094, "timer/agent.policy_max": 0.05229043960571289, "timer/dataset_train_count": 1856.0, "timer/dataset_train_total": 0.29123997688293457, "timer/dataset_train_frac": 0.00029124181239272804, "timer/dataset_train_avg": 0.00015691809099296043, "timer/dataset_train_min": 9.107589721679688e-05, "timer/dataset_train_max": 0.0012221336364746094, "timer/agent.train_count": 1856.0, "timer/agent.train_total": 833.9639332294464, "timer/agent.train_frac": 0.8339691892007702, "timer/agent.train_avg": 0.44933401574862414, "timer/agent.train_min": 0.4372682571411133, "timer/agent.train_max": 1.0266432762145996, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4752776622772217, "timer/agent.report_frac": 0.0004752806576654684, "timer/agent.report_avg": 0.23763883113861084, "timer/agent.report_min": 0.2305927276611328, "timer/agent.report_max": 0.24468493461608887, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.075599670410156e-05, "timer/dataset_eval_frac": 3.07561905405857e-08, "timer/dataset_eval_avg": 3.075599670410156e-05, "timer/dataset_eval_min": 3.075599670410156e-05, "timer/dataset_eval_max": 3.075599670410156e-05, "fps": 7.423924859891378}
{"step": 405440, "time": 54410.21153712273, "episode/length": 161.0, "episode/score": 6.277959203189312, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.17795907195431937}
{"step": 405552, "time": 54425.30471324921, "episode/length": 188.0, "episode/score": 6.289246794916835, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.1892466662429797}
{"step": 405728, "time": 54448.060306310654, "episode/length": 244.0, "episode/score": 7.371001675714069, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.2710014599033457}
{"step": 405784, "time": 54456.42965269089, "episode/length": 339.0, "episode/score": 8.47597527831931, "episode/reward_rate": 0.9852941176470589, "episode/intrinsic_return": 0.37597505028497835}
{"step": 405824, "time": 54462.76232075691, "episode/length": 182.0, "episode/score": 8.30338452140677, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.20338420769076038}
{"step": 405976, "time": 54482.69842791557, "episode/length": 169.0, "episode/score": 6.275984954451815, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.1759847573839579}
{"step": 406304, "time": 54524.08046865463, "episode/length": 158.0, "episode/score": 7.265281286523532, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.1652810760679131}
{"step": 406648, "time": 54567.35621070862, "episode/length": 211.0, "episode/score": 8.30894438492578, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.2089441197549604}
{"step": 407080, "time": 54621.534286260605, "episode/length": 161.0, "episode/score": 6.277475722689815, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.17747554261859477}
{"step": 407216, "time": 54639.55320596695, "episode/length": 207.0, "episode/score": 4.335669181315097, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.2356690573560627}
{"step": 407584, "time": 54685.78953742981, "episode/length": 231.0, "episode/score": 3.358385260763498, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.2583851192257498}
{"step": 407720, "time": 54703.82069683075, "episode/length": 284.0, "episode/score": 7.3947524686600445, "episode/reward_rate": 0.9964912280701754, "episode/intrinsic_return": 0.2947522077965914}
{"step": 407840, "time": 54719.96070885658, "episode/length": 232.0, "episode/score": 8.370134105469333, "episode/reward_rate": 0.9785407725321889, "episode/intrinsic_return": 0.2701339330233168}
{"step": 407928, "time": 54732.33627843857, "episode/length": 88.0, "episode/score": 5.200405854702694, "episode/reward_rate": 0.9438202247191011, "episode/intrinsic_return": 0.10040575204766355}
{"step": 408144, "time": 54760.16831922531, "episode/length": 186.0, "episode/score": 3.31535780559625, "episode/reward_rate": 0.9572192513368984, "episode/intrinsic_return": 0.2153577219169165}
{"step": 408360, "time": 54787.97964525223, "episode/length": 159.0, "episode/score": 8.272874622475683, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.17287435206617374}
{"step": 408840, "time": 54847.665633678436, "episode/length": 59.0, "episode/score": 5.164121753988638, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.06412151559334234}
{"step": 408968, "time": 54864.71484255791, "episode/length": 172.0, "episode/score": 6.289561889608194, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.18956170953697438}
{"step": 409040, "time": 54875.208817481995, "episode/length": 401.0, "episode/score": 9.527566915877287, "episode/reward_rate": 0.9129353233830846, "episode/intrinsic_return": 0.4275666218936749}
{"step": 409072, "time": 54880.56327867508, "episode/length": 345.0, "episode/score": 8.473352895070548, "episode/reward_rate": 0.9855491329479769, "episode/intrinsic_return": 0.3733526608662032}
{"step": 409088, "time": 54883.9395532608, "episode/length": 30.0, "episode/score": 2.138333428185433, "episode/reward_rate": 0.8387096774193549, "episode/intrinsic_return": 0.03833333251532167}
{"step": 409120, "time": 54889.335320711136, "episode/length": 159.0, "episode/score": 7.274169565632292, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.17416940252860513}
{"step": 409488, "time": 54935.668123960495, "episode/length": 220.0, "episode/score": 4.371458446839824, "episode/reward_rate": 0.9728506787330317, "episode/intrinsic_return": 0.2714583275374025}
{"step": 409488, "time": 54935.674723148346, "episode/length": 49.0, "episode/score": 4.156680891038377, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.056680750664781954}
{"step": 409488, "time": 54935.683375597, "episode/length": 194.0, "episode/score": 7.322756443218168, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.2227561800264084}
{"step": 409840, "time": 54984.56887483597, "episode/length": 108.0, "episode/score": 5.2147862852852995, "episode/reward_rate": 0.944954128440367, "episode/intrinsic_return": 0.11478613967301499}
{"step": 410072, "time": 55031.006420850754, "eval_episode/length": 85.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9883720930232558}
{"step": 410072, "time": 55035.31945300102, "eval_episode/length": 136.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9927007299270073}
{"step": 410072, "time": 55038.275369644165, "eval_episode/length": 140.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9929078014184397}
{"step": 410072, "time": 55040.30623817444, "eval_episode/length": 151.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9671052631578947}
{"step": 410072, "time": 55042.209416627884, "eval_episode/length": 161.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9938271604938271}
{"step": 410072, "time": 55043.703419685364, "eval_episode/length": 162.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9754601226993865}
{"step": 410072, "time": 55046.03467273712, "eval_episode/length": 181.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.967032967032967}
{"step": 410072, "time": 55048.61393857002, "eval_episode/length": 204.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9951219512195122}
{"step": 410184, "time": 55062.1800467968, "episode/length": 254.0, "episode/score": 9.396714896568483, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.2967146851815414}
{"step": 410544, "time": 55107.42587685585, "episode/length": 187.0, "episode/score": 9.3140393431122, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.21403908521733683}
{"step": 410544, "time": 55107.43361616135, "episode/length": 177.0, "episode/score": 9.269600043907758, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.16959963065664851}
{"step": 410992, "time": 55165.04450201988, "episode/length": 187.0, "episode/score": 9.30533497081251, "episode/reward_rate": 0.9680851063829787, "episode/intrinsic_return": 0.20533468713165348}
{"step": 411176, "time": 55189.031577825546, "episode/length": 210.0, "episode/score": 7.325785281942444, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.2257850732330553}
{"step": 411384, "time": 55215.85981440544, "episode/length": 149.0, "episode/score": 9.270747936045609, "episode/reward_rate": 0.9733333333333334, "episode/intrinsic_return": 0.1707476563228738}
{"step": 411384, "time": 55215.86787319183, "episode/length": 192.0, "episode/score": 8.295519794558913, "episode/reward_rate": 0.9689119170984456, "episode/intrinsic_return": 0.1955195626828754}
{"step": 411464, "time": 55228.930512189865, "episode/length": 298.0, "episode/score": 7.4248204621612786, "episode/reward_rate": 0.979933110367893, "episode/intrinsic_return": 0.3248203106991241}
{"step": 411776, "time": 55268.254352808, "episode/length": 285.0, "episode/score": 11.41765148919967, "episode/reward_rate": 0.9825174825174825, "episode/intrinsic_return": 0.3176511889878384}
{"step": 412000, "time": 55296.9943189621, "episode/length": 181.0, "episode/score": 5.304860123924755, "episode/reward_rate": 0.967032967032967, "episode/intrinsic_return": 0.20486001073413718}
{"step": 412112, "time": 55312.11230635643, "episode/length": 195.0, "episode/score": 7.315034921777169, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.21503471190362689}
{"step": 412416, "time": 55350.55095100403, "episode/length": 128.0, "episode/score": 4.24866926186678, "episode/reward_rate": 0.9612403100775194, "episode/intrinsic_return": 0.14866911555600382}
{"step": 412616, "time": 55376.3551940918, "episode/length": 202.0, "episode/score": 9.331745995845722, "episode/reward_rate": 0.9704433497536946, "episode/intrinsic_return": 0.23174570320088606}
{"step": 412680, "time": 55385.71176695824, "episode/length": 187.0, "episode/score": 7.313293997337041, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.21329372506488653}
{"step": 412697, "time": 55390.25243663788, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.344073880103327, "train/action_min": 0.0, "train/action_std": 3.477824395702731, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04674380334715048, "train/actor_opt_grad_steps": 101855.0, "train/actor_opt_loss": -10.202358070560681, "train/adv_mag": 0.5243664704343324, "train/adv_max": 0.48413850014568655, "train/adv_mean": 0.0025031264829385204, "train/adv_min": -0.42758279005365984, "train/adv_std": 0.05773795039583278, "train/cont_avg": 0.9945606518817204, "train/cont_loss_mean": 7.039217953813025e-05, "train/cont_loss_std": 0.002153047414061783, "train/cont_neg_acc": 0.9971171176111376, "train/cont_neg_loss": 0.008444541683579823, "train/cont_pos_acc": 0.9999947015957166, "train/cont_pos_loss": 2.6301114972903737e-05, "train/cont_pred": 0.9945678355232361, "train/cont_rate": 0.9945606518817204, "train/dyn_loss_mean": 6.684579692861085, "train/dyn_loss_std": 8.899779919655092, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0849380054140603, "train/extr_critic_critic_opt_grad_steps": 101855.0, "train/extr_critic_critic_opt_loss": 16164.666173135081, "train/extr_critic_mag": 7.7618332191180155, "train/extr_critic_max": 7.7618332191180155, "train/extr_critic_mean": 1.8650578878900057, "train/extr_critic_min": -0.5599298457945546, "train/extr_critic_std": 1.7551012564730901, "train/extr_return_normed_mag": 1.6252368650128763, "train/extr_return_normed_max": 1.6252368650128763, "train/extr_return_normed_mean": 0.3731256455823939, "train/extr_return_normed_min": -0.13217630117170273, "train/extr_return_normed_std": 0.32878166381069407, "train/extr_return_rate": 0.6973076650211888, "train/extr_return_raw_mag": 8.686114593218731, "train/extr_return_raw_max": 8.686114593218731, "train/extr_return_raw_mean": 1.8786592810384688, "train/extr_return_raw_min": -0.8691191740574375, "train/extr_return_raw_std": 1.7878557398755064, "train/extr_reward_mag": 1.0302763408230198, "train/extr_reward_max": 1.0302763408230198, "train/extr_reward_mean": 0.03588294919820562, "train/extr_reward_min": -0.6501181016686142, "train/extr_reward_std": 0.18284611035418766, "train/image_loss_mean": 3.6883670040356216, "train/image_loss_std": 8.626915398464408, "train/model_loss_mean": 7.778486256958336, "train/model_loss_std": 12.750082687665058, "train/model_opt_grad_norm": 39.4492393924344, "train/model_opt_grad_steps": 101764.04301075269, "train/model_opt_loss": 12020.464680989584, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1552.4193548387098, "train/policy_entropy_mag": 2.531899793173677, "train/policy_entropy_max": 2.531899793173677, "train/policy_entropy_mean": 0.49219755988608127, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.5988962336253094, "train/policy_logprob_mag": 7.438384084291355, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.49295460649075046, "train/policy_logprob_min": -7.438384084291355, "train/policy_logprob_std": 1.0732767771008194, "train/policy_randomness_mag": 0.8936495149648318, "train/policy_randomness_max": 0.8936495149648318, "train/policy_randomness_mean": 0.17372413776734824, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.21138408980382387, "train/post_ent_mag": 60.23965271570349, "train/post_ent_max": 60.23965271570349, "train/post_ent_mean": 43.948127890145905, "train/post_ent_min": 19.237759938804054, "train/post_ent_std": 7.021690694234705, "train/prior_ent_mag": 74.7480346105432, "train/prior_ent_max": 74.7480346105432, "train/prior_ent_mean": 50.64014697331254, "train/prior_ent_min": 30.544725346308883, "train/prior_ent_std": 6.876237500098444, "train/rep_loss_mean": 6.684579692861085, "train/rep_loss_std": 8.899779919655092, "train/reward_avg": 0.024633319177214178, "train/reward_loss_mean": 0.0793010572031621, "train/reward_loss_std": 0.18586688797159862, "train/reward_max_data": 1.0157639211223972, "train/reward_max_pred": 1.0135170567420222, "train/reward_neg_acc": 0.9986753345176738, "train/reward_neg_loss": 0.053620658694736416, "train/reward_pos_acc": 0.892380424404657, "train/reward_pos_loss": 0.7535137444414118, "train/reward_pred": 0.024209561267046518, "train/reward_rate": 0.03672610047043011, "train_stats/sum_log_reward": 6.775000065565109, "train_stats/max_log_achievement_collect_coal": 0.125, "train_stats/max_log_achievement_collect_drink": 4.55, "train_stats/max_log_achievement_collect_sapling": 2.025, "train_stats/max_log_achievement_collect_stone": 1.15, "train_stats/max_log_achievement_collect_wood": 11.0, "train_stats/max_log_achievement_defeat_skeleton": 0.025, "train_stats/max_log_achievement_defeat_zombie": 0.375, "train_stats/max_log_achievement_eat_cow": 0.05, "train_stats/max_log_achievement_make_wood_pickaxe": 2.75, "train_stats/max_log_achievement_make_wood_sword": 0.95, "train_stats/max_log_achievement_place_furnace": 0.0, "train_stats/max_log_achievement_place_plant": 1.925, "train_stats/max_log_achievement_place_stone": 0.55, "train_stats/max_log_achievement_place_table": 3.175, "train_stats/max_log_achievement_wake_up": 1.175, "train_stats/mean_log_entropy": 0.43069327995181084, "eval_stats/sum_log_reward": 6.225000083446503, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 2.5, "eval_stats/max_log_achievement_collect_sapling": 1.125, "eval_stats/max_log_achievement_collect_stone": 0.625, "eval_stats/max_log_achievement_collect_wood": 8.875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.375, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 2.0, "eval_stats/max_log_achievement_make_wood_sword": 0.625, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.125, "eval_stats/max_log_achievement_place_stone": 0.125, "eval_stats/max_log_achievement_place_table": 2.625, "eval_stats/max_log_achievement_wake_up": 1.0, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 8.504009201715235e-06, "report/cont_loss_std": 0.00011127227480756119, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0011108889011666179, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.006653858188656e-06, "report/cont_pred": 0.9941451549530029, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 6.39401912689209, "report/dyn_loss_std": 8.147555351257324, "report/image_loss_mean": 3.5777273178100586, "report/image_loss_std": 6.442614555358887, "report/model_loss_mean": 7.488176345825195, "report/model_loss_std": 10.248817443847656, "report/post_ent_mag": 61.46764373779297, "report/post_ent_max": 61.46764373779297, "report/post_ent_mean": 44.950469970703125, "report/post_ent_min": 18.92276382446289, "report/post_ent_std": 7.227271556854248, "report/prior_ent_mag": 74.84168243408203, "report/prior_ent_max": 74.84168243408203, "report/prior_ent_mean": 51.336570739746094, "report/prior_ent_min": 30.878889083862305, "report/prior_ent_std": 6.504105567932129, "report/rep_loss_mean": 6.39401912689209, "report/rep_loss_std": 8.147555351257324, "report/reward_avg": 0.02350914105772972, "report/reward_loss_mean": 0.07402883470058441, "report/reward_loss_std": 0.13854874670505524, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0042011737823486, "report/reward_neg_acc": 0.9959636330604553, "report/reward_neg_loss": 0.05395399406552315, "report/reward_pos_acc": 0.9696969389915466, "report/reward_pos_loss": 0.6768821477890015, "report/reward_pred": 0.024339459836483, "report/reward_rate": 0.0322265625, "eval/cont_avg": 0.9931640625, "eval/cont_loss_mean": 0.01845559850335121, "eval/cont_loss_std": 0.589066743850708, "eval/cont_neg_acc": 0.8571429252624512, "eval/cont_neg_loss": 2.6993844509124756, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 2.7953244625678053e-06, "eval/cont_pred": 0.9941731691360474, "eval/cont_rate": 0.9931640625, "eval/dyn_loss_mean": 20.68101692199707, "eval/dyn_loss_std": 13.297304153442383, "eval/image_loss_mean": 24.906463623046875, "eval/image_loss_std": 32.361427307128906, "eval/model_loss_mean": 37.43342208862305, "eval/model_loss_std": 37.716590881347656, "eval/post_ent_mag": 55.020145416259766, "eval/post_ent_max": 55.020145416259766, "eval/post_ent_mean": 39.97720718383789, "eval/post_ent_min": 21.161407470703125, "eval/post_ent_std": 6.590832710266113, "eval/prior_ent_mag": 74.84168243408203, "eval/prior_ent_max": 74.84168243408203, "eval/prior_ent_mean": 53.091365814208984, "eval/prior_ent_min": 35.727169036865234, "eval/prior_ent_std": 6.232097148895264, "eval/rep_loss_mean": 20.68101692199707, "eval/rep_loss_std": 13.297304153442383, "eval/reward_avg": 0.03564453125, "eval/reward_loss_mean": 0.09989053755998611, "eval/reward_loss_std": 0.528251051902771, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0030217170715332, "eval/reward_neg_acc": 0.9928717613220215, "eval/reward_neg_loss": 0.05415556579828262, "eval/reward_pos_acc": 0.9047619104385376, "eval/reward_pos_loss": 1.1692177057266235, "eval/reward_pred": 0.035361677408218384, "eval/reward_rate": 0.041015625, "replay/size": 412193.0, "replay/inserts": 7424.0, "replay/samples": 29696.0, "replay/insert_wait_avg": 1.5471194838655406e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.499715891377679e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 81992.0, "eval_replay/inserts": 1640.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1968903425263196e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.897615432739258e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1472775936127, "timer/env.step_count": 928.0, "timer/env.step_total": 86.5906491279602, "timer/env.step_frac": 0.08657789814346159, "timer/env.step_avg": 0.09330888914650884, "timer/env.step_min": 0.023348331451416016, "timer/env.step_max": 4.920037031173706, "timer/replay._sample_count": 29696.0, "timer/replay._sample_total": 14.378812313079834, "timer/replay._sample_frac": 0.014376694948043783, "timer/replay._sample_avg": 0.00048420030687903537, "timer/replay._sample_min": 0.00037550926208496094, "timer/replay._sample_max": 0.02799820899963379, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1133.0, "timer/agent.policy_total": 18.60529851913452, "timer/agent.policy_frac": 0.018602558779042506, "timer/agent.policy_avg": 0.01642126965501723, "timer/agent.policy_min": 0.00982666015625, "timer/agent.policy_max": 0.1162405014038086, "timer/dataset_train_count": 1856.0, "timer/dataset_train_total": 0.3139076232910156, "timer/dataset_train_frac": 0.0003138613985395108, "timer/dataset_train_avg": 0.0001691312625490386, "timer/dataset_train_min": 9.34600830078125e-05, "timer/dataset_train_max": 0.02007150650024414, "timer/agent.train_count": 1856.0, "timer/agent.train_total": 832.493647813797, "timer/agent.train_frac": 0.8323710582073514, "timer/agent.train_avg": 0.44854183610657167, "timer/agent.train_min": 0.43917202949523926, "timer/agent.train_max": 1.0235915184020996, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4721205234527588, "timer/agent.report_frac": 0.00047205100091728125, "timer/agent.report_avg": 0.2360602617263794, "timer/agent.report_min": 0.22971844673156738, "timer/agent.report_max": 0.2424020767211914, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9087066650390625e-05, "timer/dataset_eval_frac": 2.908278340803473e-08, "timer/dataset_eval_avg": 2.9087066650390625e-05, "timer/dataset_eval_min": 2.9087066650390625e-05, "timer/dataset_eval_max": 2.9087066650390625e-05, "fps": 7.422801897241301}
{"step": 412800, "time": 55402.60736632347, "episode/length": 176.0, "episode/score": 6.2942202842423285, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.19422007285538712}
{"step": 412880, "time": 55414.02661037445, "episode/length": 57.0, "episode/score": 3.1653009762485453, "episode/reward_rate": 0.9137931034482759, "episode/intrinsic_return": 0.06530088209183305}
{"step": 412984, "time": 55428.16152071953, "episode/length": 189.0, "episode/score": 7.307650328627005, "episode/reward_rate": 0.968421052631579, "episode/intrinsic_return": 0.20765009558681413}
{"step": 413272, "time": 55465.319991111755, "episode/length": 186.0, "episode/score": 10.286731235766183, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.18673091099071826}
{"step": 413400, "time": 55482.42900276184, "episode/length": 160.0, "episode/score": 8.280043477390336, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.18004324004277805}
{"step": 413648, "time": 55514.10679101944, "episode/length": 105.0, "episode/score": 6.203916674384345, "episode/reward_rate": 0.9622641509433962, "episode/intrinsic_return": 0.10391649314897222}
{"step": 413872, "time": 55542.8506090641, "episode/length": 148.0, "episode/score": 8.25610805774204, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.15610785898616086}
{"step": 414104, "time": 55572.59908699989, "episode/length": 152.0, "episode/score": 9.242005245600467, "episode/reward_rate": 0.9738562091503268, "episode/intrinsic_return": 0.14200496354942516}
{"step": 414152, "time": 55579.97104859352, "episode/length": 268.0, "episode/score": 8.408536983340582, "episode/reward_rate": 0.9851301115241635, "episode/intrinsic_return": 0.3085368036768159}
{"step": 414320, "time": 55602.07330036163, "episode/length": 166.0, "episode/score": 7.277809445482035, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.1778092356084926}
{"step": 414520, "time": 55627.887602090836, "episode/length": 155.0, "episode/score": 8.270023153809689, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.1700230829942484}
{"step": 414600, "time": 55639.32583451271, "episode/length": 55.0, "episode/score": 4.157646636904701, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.05764648081503765}
{"step": 414688, "time": 55652.49250340462, "episode/length": 258.0, "episode/score": 9.389316749671707, "episode/reward_rate": 0.9961389961389961, "episode/intrinsic_return": 0.28931652958272025}
{"step": 414712, "time": 55657.319566488266, "episode/length": 48.0, "episode/score": 2.1564584916923195, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.056458332343026996}
{"step": 414960, "time": 55689.031041145325, "episode/length": 163.0, "episode/score": 8.264985437932864, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.16498524784992696}
{"step": 415504, "time": 55757.02574086189, "episode/length": 174.0, "episode/score": 7.29283404017815, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.192833815636277}
{"step": 415592, "time": 55769.320930719376, "episode/length": 273.0, "episode/score": 11.395940720177805, "episode/reward_rate": 0.9854014598540146, "episode/intrinsic_return": 0.29594038085042484}
{"step": 415936, "time": 55812.59997868538, "episode/length": 155.0, "episode/score": 7.270601583826647, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.17060135788779007}
{"step": 416128, "time": 55837.4879822731, "episode/length": 176.0, "episode/score": 6.307511024888527, "episode/reward_rate": 0.96045197740113, "episode/intrinsic_return": 0.20751090290855245}
{"step": 416472, "time": 55880.908116817474, "episode/length": 324.0, "episode/score": 11.458059848192534, "episode/reward_rate": 0.9876923076923076, "episode/intrinsic_return": 0.3580595330795404}
{"step": 416504, "time": 55886.22864794731, "episode/length": 192.0, "episode/score": 8.324406555860833, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.22440632084158096}
{"step": 416520, "time": 55890.35844874382, "episode/length": 239.0, "episode/score": 8.3686364969451, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.2686362126530639}
{"step": 416728, "time": 55917.081328868866, "episode/length": 152.0, "episode/score": 8.268535454056746, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.16853516244509592}
{"step": 416936, "time": 55943.81554841995, "episode/length": 57.0, "episode/score": 4.1660276955067275, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.06602763470300488}
{"step": 417408, "time": 56002.6828725338, "episode/length": 226.0, "episode/score": 7.3538951313387315, "episode/reward_rate": 0.9779735682819384, "episode/intrinsic_return": 0.25389492262934255}
{"step": 417464, "time": 56011.086992263794, "episode/length": 166.0, "episode/score": 7.284249909039545, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.1842496839155956}
{"step": 417528, "time": 56020.853046655655, "episode/length": 198.0, "episode/score": 9.318122856071113, "episode/reward_rate": 0.9798994974874372, "episode/intrinsic_return": 0.21812255876966447}
{"step": 417704, "time": 56043.767182826996, "episode/length": 121.0, "episode/score": 8.221581390808069, "episode/reward_rate": 0.9918032786885246, "episode/intrinsic_return": 0.12158105043295109}
{"step": 417928, "time": 56074.598645448685, "episode/length": 425.0, "episode/score": 10.553559723326316, "episode/reward_rate": 0.7183098591549296, "episode/intrinsic_return": 0.4535594020433109}
{"step": 418384, "time": 56131.7591240406, "episode/length": 180.0, "episode/score": 7.291067934436114, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.19106776689409344}
{"step": 418544, "time": 56152.693415403366, "episode/length": 254.0, "episode/score": 9.39283667887139, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.29283641602887656}
{"step": 418560, "time": 56156.154800891876, "episode/length": 143.0, "episode/score": 4.248057458778021, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.1480573411054138}
{"step": 418912, "time": 56200.4513669014, "episode/length": 180.0, "episode/score": 9.294202592505826, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.19420237328995427}
{"step": 419064, "time": 56220.46759390831, "episode/length": 191.0, "episode/score": 4.320525675847875, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.22052555305299393}
{"step": 419216, "time": 56240.23900389671, "episode/length": 188.0, "episode/score": 7.319203225464889, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.21920295645236365}
{"step": 419280, "time": 56249.58280110359, "episode/length": 344.0, "episode/score": 10.447256609173564, "episode/reward_rate": 0.9826086956521739, "episode/intrinsic_return": 0.3472562614133494}
{"step": 419752, "time": 56308.34560608864, "episode/length": 227.0, "episode/score": 8.353722875440099, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.25372263692838715}
{"step": 419944, "time": 56333.16874265671, "episode/length": 174.0, "episode/score": 7.2685672898137454, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.16856717470227522}
{"step": 420056, "time": 56362.709312200546, "eval_episode/length": 37.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 420056, "time": 56369.08733129501, "eval_episode/length": 143.0, "eval_episode/score": 6.099999964237213, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 420056, "time": 56373.069585323334, "eval_episode/length": 183.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.967391304347826}
{"step": 420056, "time": 56375.44590616226, "eval_episode/length": 190.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9790575916230366}
{"step": 420056, "time": 56377.49744153023, "eval_episode/length": 191.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.96875}
{"step": 420056, "time": 56379.42233991623, "eval_episode/length": 192.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9948186528497409}
{"step": 420056, "time": 56381.817113399506, "eval_episode/length": 160.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.968944099378882}
{"step": 420056, "time": 56383.84950208664, "eval_episode/length": 202.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9704433497536946}
{"step": 420105, "time": 56390.75725078583, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.367183540962838, "train/action_min": 0.0, "train/action_std": 3.3813108585976264, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.045472870062331895, "train/actor_opt_grad_steps": 103710.0, "train/actor_opt_loss": -7.916092280056831, "train/adv_mag": 0.5249341532990739, "train/adv_max": 0.48697294882825903, "train/adv_mean": 0.002881353161442471, "train/adv_min": -0.41585935676420055, "train/adv_std": 0.056690607824035594, "train/cont_avg": 0.9945629222972973, "train/cont_loss_mean": 5.075486526070993e-05, "train/cont_loss_std": 0.0014187115143131082, "train/cont_neg_acc": 0.9993243243243243, "train/cont_neg_loss": 0.0034860549922141955, "train/cont_pos_acc": 0.9999946703781952, "train/cont_pos_loss": 2.769885360523937e-05, "train/cont_pred": 0.9945552922583915, "train/cont_rate": 0.9945629222972973, "train/dyn_loss_mean": 6.836533048990611, "train/dyn_loss_std": 8.88918816849992, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0701502377922472, "train/extr_critic_critic_opt_grad_steps": 103710.0, "train/extr_critic_critic_opt_loss": 16121.347751266892, "train/extr_critic_mag": 7.811137792226431, "train/extr_critic_max": 7.811137792226431, "train/extr_critic_mean": 1.9539765473958608, "train/extr_critic_min": -0.5659868684974877, "train/extr_critic_std": 1.8145987530012389, "train/extr_return_normed_mag": 1.5862231087040257, "train/extr_return_normed_max": 1.5862231087040257, "train/extr_return_normed_mean": 0.3790684637991158, "train/extr_return_normed_min": -0.12325274114673201, "train/extr_return_normed_std": 0.32954324226121645, "train/extr_return_rate": 0.6976200392117371, "train/extr_return_raw_mag": 8.733716763676824, "train/extr_return_raw_max": 8.733716763676824, "train/extr_return_raw_mean": 1.9701091515051352, "train/extr_return_raw_min": -0.844072273293057, "train/extr_return_raw_std": 1.8463662392384297, "train/extr_reward_mag": 1.033393855997034, "train/extr_reward_max": 1.033393855997034, "train/extr_reward_mean": 0.03638538793736213, "train/extr_reward_min": -0.6323837093404822, "train/extr_reward_std": 0.18387789122156195, "train/image_loss_mean": 3.758201707376016, "train/image_loss_std": 8.714135051417996, "train/model_loss_mean": 7.939663474624221, "train/model_loss_std": 12.82175425452155, "train/model_opt_grad_norm": 39.78886449659193, "train/model_opt_grad_steps": 103617.68648648649, "train/model_opt_loss": 12450.613592694257, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1567.5675675675675, "train/policy_entropy_mag": 2.4954047654126144, "train/policy_entropy_max": 2.4954047654126144, "train/policy_entropy_mean": 0.4880152581511317, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.5739658963035893, "train/policy_logprob_mag": 7.4383840689788, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.48791254388319477, "train/policy_logprob_min": -7.4383840689788, "train/policy_logprob_std": 1.065467956259444, "train/policy_randomness_mag": 0.8807683751389787, "train/policy_randomness_max": 0.8807683751389787, "train/policy_randomness_mean": 0.1722479690571089, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.20258477370481234, "train/post_ent_mag": 60.11429835139094, "train/post_ent_max": 60.11429835139094, "train/post_ent_mean": 43.999629623825484, "train/post_ent_min": 19.669034117621344, "train/post_ent_std": 7.067208037505279, "train/prior_ent_mag": 74.64440480825063, "train/prior_ent_max": 74.64440480825063, "train/prior_ent_mean": 50.81232454454577, "train/prior_ent_min": 30.650698831919076, "train/prior_ent_std": 6.848622139080151, "train/rep_loss_mean": 6.836533048990611, "train/rep_loss_std": 8.88918816849992, "train/reward_avg": 0.024529573600109968, "train/reward_loss_mean": 0.07949124701522492, "train/reward_loss_std": 0.1874765307919399, "train/reward_max_data": 1.0180067893621083, "train/reward_max_pred": 1.0155579670055492, "train/reward_neg_acc": 0.9983653832126308, "train/reward_neg_loss": 0.054112853371613735, "train/reward_pos_acc": 0.8899984462841137, "train/reward_pos_loss": 0.7569298647545479, "train/reward_pred": 0.024257647720593457, "train/reward_rate": 0.03621199324324324, "train_stats/sum_log_reward": 7.4421054187573885, "train_stats/max_log_achievement_collect_coal": 0.05263157894736842, "train_stats/max_log_achievement_collect_drink": 3.6842105263157894, "train_stats/max_log_achievement_collect_sapling": 1.8421052631578947, "train_stats/max_log_achievement_collect_stone": 1.9210526315789473, "train_stats/max_log_achievement_collect_wood": 10.789473684210526, "train_stats/max_log_achievement_defeat_skeleton": 0.05263157894736842, "train_stats/max_log_achievement_defeat_zombie": 0.18421052631578946, "train_stats/max_log_achievement_eat_cow": 0.21052631578947367, "train_stats/max_log_achievement_make_wood_pickaxe": 2.3157894736842106, "train_stats/max_log_achievement_make_wood_sword": 1.5789473684210527, "train_stats/max_log_achievement_place_furnace": 0.02631578947368421, "train_stats/max_log_achievement_place_plant": 1.763157894736842, "train_stats/max_log_achievement_place_stone": 1.263157894736842, "train_stats/max_log_achievement_place_table": 3.0526315789473686, "train_stats/max_log_achievement_wake_up": 1.1578947368421053, "train_stats/mean_log_entropy": 0.42646505683660507, "eval_stats/sum_log_reward": 6.724999964237213, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 4.0, "eval_stats/max_log_achievement_collect_sapling": 1.75, "eval_stats/max_log_achievement_collect_stone": 0.125, "eval_stats/max_log_achievement_collect_wood": 10.75, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.5, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.875, "eval_stats/max_log_achievement_make_wood_sword": 2.625, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.5, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.875, "eval_stats/max_log_achievement_wake_up": 1.0, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 2.5021703550009988e-05, "report/cont_loss_std": 0.0005767135880887508, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0001562028337502852, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.4378026864724234e-05, "report/cont_pred": 0.9950939416885376, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 6.6586785316467285, "report/dyn_loss_std": 8.663671493530273, "report/image_loss_mean": 3.663137197494507, "report/image_loss_std": 9.322101593017578, "report/model_loss_mean": 7.739363193511963, "report/model_loss_std": 13.095409393310547, "report/post_ent_mag": 60.39011764526367, "report/post_ent_max": 60.39011764526367, "report/post_ent_mean": 44.84715270996094, "report/post_ent_min": 16.75750732421875, "report/post_ent_std": 7.296400547027588, "report/prior_ent_mag": 74.84259033203125, "report/prior_ent_max": 74.84259033203125, "report/prior_ent_mean": 51.86003112792969, "report/prior_ent_min": 33.06193542480469, "report/prior_ent_std": 6.631616115570068, "report/rep_loss_mean": 6.6586785316467285, "report/rep_loss_std": 8.663671493530273, "report/reward_avg": 0.024887684732675552, "report/reward_loss_mean": 0.08099439740180969, "report/reward_loss_std": 0.17183281481266022, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.001800298690796, "report/reward_neg_acc": 0.9999998807907104, "report/reward_neg_loss": 0.05662931501865387, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7694817185401917, "report/reward_pred": 0.022582191973924637, "report/reward_rate": 0.0341796875, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 3.657474962892593e-06, "eval/cont_loss_std": 8.746841922402382e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0007717405096627772, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 6.453842615883332e-07, "eval/cont_pred": 0.9960961937904358, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 19.272884368896484, "eval/dyn_loss_std": 12.65591812133789, "eval/image_loss_mean": 20.453536987304688, "eval/image_loss_std": 25.310068130493164, "eval/model_loss_mean": 32.11767578125, "eval/model_loss_std": 29.934707641601562, "eval/post_ent_mag": 60.08854293823242, "eval/post_ent_max": 60.08854293823242, "eval/post_ent_mean": 42.27760314941406, "eval/post_ent_min": 21.316280364990234, "eval/post_ent_std": 7.470719337463379, "eval/prior_ent_mag": 74.84259033203125, "eval/prior_ent_max": 74.84259033203125, "eval/prior_ent_mean": 54.684349060058594, "eval/prior_ent_min": 38.573890686035156, "eval/prior_ent_std": 6.337509632110596, "eval/rep_loss_mean": 19.272884368896484, "eval/rep_loss_std": 12.65591812133789, "eval/reward_avg": 0.03789062798023224, "eval/reward_loss_mean": 0.10040365159511566, "eval/reward_loss_std": 0.685356855392456, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0020949840545654, "eval/reward_neg_acc": 0.9938837289810181, "eval/reward_neg_loss": 0.03672751784324646, "eval/reward_pos_acc": 0.9069767594337463, "eval/reward_pos_loss": 1.5531078577041626, "eval/reward_pred": 0.037678077816963196, "eval/reward_rate": 0.0419921875, "replay/size": 419601.0, "replay/inserts": 7408.0, "replay/samples": 29632.0, "replay/insert_wait_avg": 1.5987047108924157e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.488638098245048e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 83616.0, "eval_replay/inserts": 1624.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2285016440405634e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0132789611816406e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4895050525665, "timer/env.step_count": 926.0, "timer/env.step_total": 85.35391330718994, "timer/env.step_frac": 0.08531215257745794, "timer/env.step_avg": 0.09217485238357445, "timer/env.step_min": 0.023314476013183594, "timer/env.step_max": 2.178523540496826, "timer/replay._sample_count": 29632.0, "timer/replay._sample_total": 14.375999927520752, "timer/replay._sample_frac": 0.014368966245943205, "timer/replay._sample_avg": 0.0004851511854589887, "timer/replay._sample_min": 0.0003612041473388672, "timer/replay._sample_max": 0.03315901756286621, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1129.0, "timer/agent.policy_total": 18.479613780975342, "timer/agent.policy_frac": 0.0184705723424899, "timer/agent.policy_avg": 0.01636812558102333, "timer/agent.policy_min": 0.010219097137451172, "timer/agent.policy_max": 0.0515286922454834, "timer/dataset_train_count": 1852.0, "timer/dataset_train_total": 0.30414748191833496, "timer/dataset_train_frac": 0.0003039986730319123, "timer/dataset_train_avg": 0.00016422650211573163, "timer/dataset_train_min": 0.00010013580322265625, "timer/dataset_train_max": 0.0008139610290527344, "timer/agent.train_count": 1852.0, "timer/agent.train_total": 832.1852850914001, "timer/agent.train_frac": 0.8317781254963553, "timer/agent.train_avg": 0.44934410642084244, "timer/agent.train_min": 0.43796658515930176, "timer/agent.train_max": 0.9555332660675049, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.473804235458374, "timer/agent.report_frac": 0.00047357241936633805, "timer/agent.report_avg": 0.236902117729187, "timer/agent.report_min": 0.23010778427124023, "timer/agent.report_max": 0.2436964511871338, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 5.555152893066406e-05, "timer/dataset_eval_frac": 5.552434948105262e-08, "timer/dataset_eval_avg": 5.555152893066406e-05, "timer/dataset_eval_min": 5.555152893066406e-05, "timer/dataset_eval_max": 5.555152893066406e-05, "fps": 7.4042577879176665}
{"step": 420152, "time": 56396.359277009964, "episode/length": 220.0, "episode/score": 8.337674241410923, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.23767408328399142}
{"step": 420240, "time": 56408.534098148346, "episode/length": 165.0, "episode/score": 6.270186367435599, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.17018615721281094}
{"step": 420624, "time": 56456.6593773365, "episode/length": 194.0, "episode/score": 7.308075692020566, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.20807548331117687}
{"step": 420768, "time": 56475.781648635864, "episode/length": 185.0, "episode/score": 7.312719458347146, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.2127192194861891}
{"step": 420832, "time": 56485.12444114685, "episode/length": 201.0, "episode/score": 10.315717317403823, "episode/reward_rate": 0.9702970297029703, "episode/intrinsic_return": 0.2157169961208183}
{"step": 421248, "time": 56537.290870666504, "episode/length": 335.0, "episode/score": 9.487384266607023, "episode/reward_rate": 0.9970238095238095, "episode/intrinsic_return": 0.3873840258834207}
{"step": 421608, "time": 56582.42997050285, "episode/length": 181.0, "episode/score": 5.3109408361672195, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.21094068473416883}
{"step": 421736, "time": 56599.48110151291, "episode/length": 186.0, "episode/score": 7.297993945126791, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.1979937340890956}
{"step": 422048, "time": 56638.909393548965, "episode/length": 286.0, "episode/score": 7.419061283499104, "episode/reward_rate": 0.9825783972125436, "episode/intrinsic_return": 0.31906109839292185}
{"step": 422816, "time": 56733.88605618477, "episode/length": 195.0, "episode/score": 8.306743389569874, "episode/reward_rate": 0.9693877551020408, "episode/intrinsic_return": 0.2067432979742989}
{"step": 422816, "time": 56733.89429163933, "episode/length": 247.0, "episode/score": 8.394165475105183, "episode/reward_rate": 0.9717741935483871, "episode/intrinsic_return": 0.294165244742544}
{"step": 422992, "time": 56758.57066702843, "episode/length": 156.0, "episode/score": 7.269767510239717, "episode/reward_rate": 0.9872611464968153, "episode/intrinsic_return": 0.16976725927156622}
{"step": 423136, "time": 56777.54406094551, "episode/length": 398.0, "episode/score": 9.493780155974946, "episode/reward_rate": 0.8596491228070176, "episode/intrinsic_return": 0.3937798319561807}
{"step": 423368, "time": 56807.25777006149, "episode/length": 164.0, "episode/score": 8.281362363603648, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.18136212450986022}
{"step": 423440, "time": 56817.43573260307, "episode/length": 228.0, "episode/score": 7.36107350380712, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.2610732417795134}
{"step": 423648, "time": 56844.264261722565, "episode/length": 377.0, "episode/score": 10.471977521035114, "episode/reward_rate": 0.9867724867724867, "episode/intrinsic_return": 0.3719772366557663}
{"step": 423936, "time": 56880.81913256645, "episode/length": 395.0, "episode/score": 9.454674614234364, "episode/reward_rate": 0.9873737373737373, "episode/intrinsic_return": 0.35467431064648736}
{"step": 424152, "time": 56908.83670902252, "episode/length": 166.0, "episode/score": 9.287089446728714, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.18708923248959763}
{"step": 424352, "time": 56934.52634334564, "episode/length": 169.0, "episode/score": 7.294124661923661, "episode/reward_rate": 0.9588235294117647, "episode/intrinsic_return": 0.19412446019919116}
{"step": 424376, "time": 56938.98538041115, "episode/length": 194.0, "episode/score": 9.299078633714089, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.19907843412875081}
{"step": 424464, "time": 56951.1620926857, "episode/length": 165.0, "episode/score": 8.27901205091257, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.17901190716293058}
{"step": 424928, "time": 57009.0724363327, "episode/length": 159.0, "episode/score": 9.278294231990685, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.17829396600495784}
{"step": 424976, "time": 57016.358676195145, "episode/length": 191.0, "episode/score": 7.324894227288723, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.22489401857933444}
{"step": 425256, "time": 57051.66421580315, "episode/length": 112.0, "episode/score": 5.2267569239872955, "episode/reward_rate": 0.9557522123893806, "episode/intrinsic_return": 0.12675674240267654}
{"step": 425272, "time": 57055.1283326149, "episode/length": 166.0, "episode/score": 7.280711462264662, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.18071123772278952}
{"step": 425720, "time": 57110.91996073723, "episode/length": 156.0, "episode/score": 7.272355861443657, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.1723556515701148}
{"step": 425752, "time": 57116.426721572876, "episode/length": 199.0, "episode/score": 8.324841775034429, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.22484154630160447}
{"step": 426064, "time": 57157.03760910034, "episode/length": 336.0, "episode/score": 7.489988376360088, "episode/reward_rate": 0.9940652818991098, "episode/intrinsic_return": 0.3899881386632842}
{"step": 426224, "time": 57178.10364460945, "episode/length": 230.0, "episode/score": 7.357858301886154, "episode/reward_rate": 0.9783549783549783, "episode/intrinsic_return": 0.2578580955050711}
{"step": 426616, "time": 57227.402091026306, "episode/length": 210.0, "episode/score": 7.348566707012651, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.24856649830326205}
{"step": 426704, "time": 57239.74419784546, "episode/length": 215.0, "episode/score": 8.349205945123686, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.24920567995286547}
{"step": 427000, "time": 57277.0377933979, "episode/length": 217.0, "episode/score": 8.342554327115067, "episode/reward_rate": 0.9724770642201835, "episode/intrinsic_return": 0.24255406310840044}
{"step": 427008, "time": 57279.54820847511, "episode/length": 216.0, "episode/score": 8.365158104381408, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.26515782267961185}
{"step": 427160, "time": 57299.57255792618, "episode/length": 179.0, "episode/score": 7.2902773128625995, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.19027710415321053}
{"step": 427560, "time": 57349.77429628372, "episode/length": 166.0, "episode/score": 10.273410924011841, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.17341059923637658}
{"step": 427864, "time": 57388.35342335701, "episode/length": 224.0, "episode/score": 6.362663341671578, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.26266316160035785}
{"step": 427865, "time": 57391.05145573616, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.37777647038096, "train/action_min": 0.0, "train/action_std": 3.4045509677572348, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04604642586686562, "train/actor_opt_grad_steps": 105605.0, "train/actor_opt_loss": -4.3832394543689555, "train/adv_mag": 0.5045629925641817, "train/adv_max": 0.4730963418164204, "train/adv_mean": 0.00434884976655048, "train/adv_min": -0.3985503403489123, "train/adv_std": 0.05760987842282683, "train/cont_avg": 0.9946742106958762, "train/cont_loss_mean": 0.00016685309617712357, "train/cont_loss_std": 0.005155188337700152, "train/cont_neg_acc": 0.9953931057825685, "train/cont_neg_loss": 0.0266354451831378, "train/cont_pos_acc": 0.9999898235822461, "train/cont_pos_loss": 3.765615102272342e-05, "train/cont_pred": 0.9946864898671809, "train/cont_rate": 0.9946742106958762, "train/dyn_loss_mean": 6.848318350683782, "train/dyn_loss_std": 8.921740453267835, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1564935882066942, "train/extr_critic_critic_opt_grad_steps": 105605.0, "train/extr_critic_critic_opt_loss": 16315.031088917525, "train/extr_critic_mag": 7.971168581972417, "train/extr_critic_max": 7.971168581972417, "train/extr_critic_mean": 2.1778919211367973, "train/extr_critic_min": -0.5393242313689792, "train/extr_critic_std": 1.8431564409708239, "train/extr_return_normed_mag": 1.5679130554199219, "train/extr_return_normed_max": 1.5679130554199219, "train/extr_return_normed_mean": 0.4041485617455748, "train/extr_return_normed_min": -0.11857687710717167, "train/extr_return_normed_std": 0.3269948323362881, "train/extr_return_rate": 0.7476905197212377, "train/extr_return_raw_mag": 8.894030956877875, "train/extr_return_raw_max": 8.894030956877875, "train/extr_return_raw_mean": 2.202782046549099, "train/extr_return_raw_min": -0.8051837639710338, "train/extr_return_raw_std": 1.8814233166655314, "train/extr_reward_mag": 1.0264733808556783, "train/extr_reward_max": 1.0264733808556783, "train/extr_reward_mean": 0.037227295497528366, "train/extr_reward_min": -0.6385264027978956, "train/extr_reward_std": 0.18560561940995687, "train/image_loss_mean": 3.751532592724279, "train/image_loss_std": 8.936238534671745, "train/model_loss_mean": 7.940326204004976, "train/model_loss_std": 13.049376758103518, "train/model_opt_grad_norm": 42.95685778942305, "train/model_opt_grad_steps": 105511.27835051547, "train/model_opt_loss": 12581.69369664143, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1585.0515463917525, "train/policy_entropy_mag": 2.502662915544412, "train/policy_entropy_max": 2.502662915544412, "train/policy_entropy_mean": 0.4795180066037424, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.5688889181798267, "train/policy_logprob_mag": 7.438384048717538, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.47929371755147715, "train/policy_logprob_min": -7.438384048717538, "train/policy_logprob_std": 1.06041449031879, "train/policy_randomness_mag": 0.8833301829308579, "train/policy_randomness_max": 0.8833301829308579, "train/policy_randomness_mean": 0.16924881278393195, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.2007928250991192, "train/post_ent_mag": 59.88188303131418, "train/post_ent_max": 59.88188303131418, "train/post_ent_mean": 43.97623148652696, "train/post_ent_min": 19.532802537544487, "train/post_ent_std": 7.025582520003171, "train/prior_ent_mag": 74.76048184424332, "train/prior_ent_max": 74.76048184424332, "train/prior_ent_mean": 50.84393200431902, "train/prior_ent_min": 30.544630778204535, "train/prior_ent_std": 6.887768423434386, "train/rep_loss_mean": 6.848318350683782, "train/rep_loss_std": 8.921740453267835, "train/reward_avg": 0.02538931897370932, "train/reward_loss_mean": 0.07963578389554295, "train/reward_loss_std": 0.18508746613239505, "train/reward_max_data": 1.0131014063186252, "train/reward_max_pred": 1.012571627331763, "train/reward_neg_acc": 0.9984198252564853, "train/reward_neg_loss": 0.05382619170260798, "train/reward_pos_acc": 0.8965206908196518, "train/reward_pos_loss": 0.7519548341785509, "train/reward_pred": 0.025083534861194717, "train/reward_rate": 0.03703890141752577, "train_stats/sum_log_reward": 7.766666769981384, "train_stats/max_log_achievement_collect_coal": 0.16666666666666666, "train_stats/max_log_achievement_collect_drink": 3.3333333333333335, "train_stats/max_log_achievement_collect_sapling": 1.8333333333333333, "train_stats/max_log_achievement_collect_stone": 1.3055555555555556, "train_stats/max_log_achievement_collect_wood": 12.194444444444445, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.1388888888888889, "train_stats/max_log_achievement_eat_cow": 0.1111111111111111, "train_stats/max_log_achievement_make_wood_pickaxe": 2.611111111111111, "train_stats/max_log_achievement_make_wood_sword": 1.5555555555555556, "train_stats/max_log_achievement_place_furnace": 0.0, "train_stats/max_log_achievement_place_plant": 1.8333333333333333, "train_stats/max_log_achievement_place_stone": 0.7777777777777778, "train_stats/max_log_achievement_place_table": 3.611111111111111, "train_stats/max_log_achievement_wake_up": 0.9722222222222222, "train_stats/mean_log_entropy": 0.4197593099541134, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 4.670388079830445e-06, "report/cont_loss_std": 3.970466059399769e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 8.902286026568618e-06, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 4.662107130570803e-06, "report/cont_pred": 0.9980422258377075, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 6.667834281921387, "report/dyn_loss_std": 8.424131393432617, "report/image_loss_mean": 3.184455633163452, "report/image_loss_std": 7.819149971008301, "report/model_loss_mean": 7.253801345825195, "report/model_loss_std": 11.852561950683594, "report/post_ent_mag": 58.03022003173828, "report/post_ent_max": 58.03022003173828, "report/post_ent_mean": 43.926361083984375, "report/post_ent_min": 20.082015991210938, "report/post_ent_std": 6.60466194152832, "report/prior_ent_mag": 74.73402404785156, "report/prior_ent_max": 74.73402404785156, "report/prior_ent_mean": 50.76152420043945, "report/prior_ent_min": 32.80792236328125, "report/prior_ent_std": 6.470936298370361, "report/rep_loss_mean": 6.667834281921387, "report/rep_loss_std": 8.424131393432617, "report/reward_avg": 0.030400391668081284, "report/reward_loss_mean": 0.06864088773727417, "report/reward_loss_std": 0.16979378461837769, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.003000259399414, "report/reward_neg_acc": 0.99798184633255, "report/reward_neg_loss": 0.047015272080898285, "report/reward_pos_acc": 0.9999999403953552, "report/reward_pos_loss": 0.718064546585083, "report/reward_pred": 0.030173081904649734, "report/reward_rate": 0.0322265625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 9.176661478704773e-06, "eval/cont_loss_std": 9.690304432297125e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0006644587847404182, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 6.6069269450963475e-06, "eval/cont_pred": 0.9960897564888, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 17.684234619140625, "eval/dyn_loss_std": 10.933122634887695, "eval/image_loss_mean": 18.9105224609375, "eval/image_loss_std": 22.651884078979492, "eval/model_loss_mean": 29.648357391357422, "eval/model_loss_std": 26.177452087402344, "eval/post_ent_mag": 62.212989807128906, "eval/post_ent_max": 62.212989807128906, "eval/post_ent_mean": 42.75804138183594, "eval/post_ent_min": 20.421234130859375, "eval/post_ent_std": 7.489552021026611, "eval/prior_ent_mag": 74.73402404785156, "eval/prior_ent_max": 74.73402404785156, "eval/prior_ent_mean": 54.65534973144531, "eval/prior_ent_min": 36.276519775390625, "eval/prior_ent_std": 6.040788173675537, "eval/rep_loss_mean": 17.684234619140625, "eval/rep_loss_std": 10.933122634887695, "eval/reward_avg": 0.01816406287252903, "eval/reward_loss_mean": 0.12728522717952728, "eval/reward_loss_std": 0.8612753748893738, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.001760482788086, "eval/reward_neg_acc": 0.9970000386238098, "eval/reward_neg_loss": 0.049928996711969376, "eval/reward_pos_acc": 0.6666666865348816, "eval/reward_pos_loss": 3.350461483001709, "eval/reward_pred": 0.011370302177965641, "eval/reward_rate": 0.0234375, "replay/size": 427361.0, "replay/inserts": 7760.0, "replay/samples": 31040.0, "replay/insert_wait_avg": 1.6121827449995218e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.517482202077649e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 83616.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 8.493661880493164e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2778933048248, "timer/env.step_count": 970.0, "timer/env.step_total": 81.0100998878479, "timer/env.step_frac": 0.08098759397770762, "timer/env.step_avg": 0.08351556689468856, "timer/env.step_min": 0.023296594619750977, "timer/env.step_max": 3.233083486557007, "timer/replay._sample_count": 31040.0, "timer/replay._sample_total": 15.131929397583008, "timer/replay._sample_frac": 0.015127725503948232, "timer/replay._sample_avg": 0.0004874977254375969, "timer/replay._sample_min": 0.00035500526428222656, "timer/replay._sample_max": 0.03268861770629883, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 970.0, "timer/agent.policy_total": 15.717029333114624, "timer/agent.policy_frac": 0.01571266288929672, "timer/agent.policy_avg": 0.016203123023829508, "timer/agent.policy_min": 0.014644145965576172, "timer/agent.policy_max": 0.05637788772583008, "timer/dataset_train_count": 1940.0, "timer/dataset_train_total": 0.38646984100341797, "timer/dataset_train_frac": 0.0003863624734588082, "timer/dataset_train_avg": 0.00019921125824918452, "timer/dataset_train_min": 9.775161743164062e-05, "timer/dataset_train_max": 0.0446321964263916, "timer/agent.train_count": 1940.0, "timer/agent.train_total": 869.5762417316437, "timer/agent.train_frac": 0.8693346594501303, "timer/agent.train_avg": 0.4482351761503318, "timer/agent.train_min": 0.43558216094970703, "timer/agent.train_max": 0.9269788265228271, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.474365234375, "timer/agent.report_frac": 0.000474233448074856, "timer/agent.report_avg": 0.2371826171875, "timer/agent.report_min": 0.22887849807739258, "timer/agent.report_max": 0.24548673629760742, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.6941299438476562e-05, "timer/dataset_eval_frac": 2.693381471169479e-08, "timer/dataset_eval_avg": 2.6941299438476562e-05, "timer/dataset_eval_min": 2.6941299438476562e-05, "timer/dataset_eval_max": 2.6941299438476562e-05, "fps": 7.757724558331599}
{"step": 427880, "time": 57392.74817585945, "episode/length": 157.0, "episode/score": 8.279729431087617, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.17972916358849034}
{"step": 428048, "time": 57414.67154741287, "episode/length": 167.0, "episode/score": 9.290042288484983, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.19004200643394142}
{"step": 428048, "time": 57414.67847943306, "episode/length": 130.0, "episode/score": 7.234577426803298, "episode/reward_rate": 0.9923664122137404, "episode/intrinsic_return": 0.13457713113166392}
{"step": 428232, "time": 57440.22783088684, "episode/length": 43.0, "episode/score": 2.152291772305034, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.05229166569188237}
{"step": 428496, "time": 57474.35997533798, "episode/length": 166.0, "episode/score": 8.288407101681514, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.18840684826864162}
{"step": 428656, "time": 57495.476665735245, "episode/length": 362.0, "episode/score": 8.475158162451407, "episode/reward_rate": 0.9917355371900827, "episode/intrinsic_return": 0.37515789920144016}
{"step": 428736, "time": 57506.734355926514, "episode/length": 215.0, "episode/score": 8.355136890590074, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.2551366254192544}
{"step": 429264, "time": 57572.72571206093, "episode/length": 212.0, "episode/score": 6.3453411162190605, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.24534087817301042}
{"step": 429616, "time": 57616.94578909874, "episode/length": 195.0, "episode/score": 6.334503250094713, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.2345030167052755}
{"step": 429656, "time": 57623.30618739128, "episode/length": 223.0, "episode/score": 8.36624998482148, "episode/reward_rate": 0.9776785714285714, "episode/intrinsic_return": 0.26624973455182044}
{"step": 429752, "time": 57636.41337132454, "episode/length": 212.0, "episode/score": 7.3558806923210796, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.25588049793077516}
{"step": 429800, "time": 57643.67701625824, "episode/length": 162.0, "episode/score": 7.280478319768008, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.1804781185091997}
{"step": 430040, "time": 57693.01848626137, "eval_episode/length": 142.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.972027972027972}
{"step": 430040, "time": 57694.7098531723, "eval_episode/length": 149.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9666666666666667}
{"step": 430040, "time": 57696.70915365219, "eval_episode/length": 162.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9938650306748467}
{"step": 430040, "time": 57700.18197655678, "eval_episode/length": 209.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9857142857142858}
{"step": 430040, "time": 57701.67183804512, "eval_episode/length": 210.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.981042654028436}
{"step": 430040, "time": 57704.50320291519, "eval_episode/length": 242.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9958847736625515}
{"step": 430040, "time": 57706.895845890045, "eval_episode/length": 262.0, "eval_episode/score": 10.099999964237213, "eval_episode/reward_rate": 0.9847908745247148}
{"step": 430040, "time": 57710.77655959129, "eval_episode/length": 319.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9875}
{"step": 430152, "time": 57724.34845042229, "episode/length": 61.0, "episode/score": 3.1580151899615885, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.05801503899419913}
{"step": 430600, "time": 57780.19114112854, "episode/length": 295.0, "episode/score": 7.43435073650835, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.3343505423508759}
{"step": 430616, "time": 57783.60643029213, "episode/length": 234.0, "episode/score": 6.366678099413548, "episode/reward_rate": 0.9829787234042553, "episode/intrinsic_return": 0.2666779181781749}
{"step": 430856, "time": 57814.35301399231, "episode/length": 154.0, "episode/score": 7.282760716539997, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.1827604639420315}
{"step": 431224, "time": 57860.7089574337, "episode/length": 183.0, "episode/score": 7.302840696718704, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.20284047101267788}
{"step": 431336, "time": 57875.91763448715, "episode/length": 191.0, "episode/score": 6.312967449064672, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.21296724408057344}
{"step": 431560, "time": 57904.63105797768, "episode/length": 175.0, "episode/score": 9.29606483337011, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.19606456738438283}
{"step": 431616, "time": 57912.895728349686, "episode/length": 369.0, "episode/score": 7.52543763705944, "episode/reward_rate": 0.9972972972972973, "episode/intrinsic_return": 0.42543743475289375}
{"step": 432080, "time": 57970.513785123825, "episode/length": 184.0, "episode/score": 8.304745587984144, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.20474530441970273}
{"step": 432248, "time": 57992.51813292503, "episode/length": 203.0, "episode/score": 12.331452472733872, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.2314521047683229}
{"step": 432408, "time": 58013.522327423096, "episode/length": 193.0, "episode/score": 8.31999849074964, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.21999822325051355}
{"step": 432488, "time": 58024.73746609688, "episode/length": 402.0, "episode/score": 9.517514590956125, "episode/reward_rate": 0.8535980148883374, "episode/intrinsic_return": 0.4175142675776442}
{"step": 432672, "time": 58048.59990525246, "episode/length": 180.0, "episode/score": 7.30463065488766, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.20463040601498506}
{"step": 432736, "time": 58057.8411257267, "episode/length": 174.0, "episode/score": 8.299690903653755, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.199690612638733}
{"step": 433096, "time": 58103.173961400986, "episode/length": 184.0, "episode/score": 5.296798855728412, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.19679871861444553}
{"step": 433248, "time": 58123.17895817757, "episode/length": 145.0, "episode/score": 6.265452457490028, "episode/reward_rate": 0.9657534246575342, "episode/intrinsic_return": 0.16545227741880808}
{"step": 433720, "time": 58182.18415260315, "episode/length": 163.0, "episode/score": 7.282902529164858, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.18290232045546873}
{"step": 433736, "time": 58185.666212558746, "episode/length": 185.0, "episode/score": 8.308803648018511, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.20880338051938452}
{"step": 433984, "time": 58217.2509560585, "episode/length": 186.0, "episode/score": 9.291426913783653, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.19142658574855886}
{"step": 434088, "time": 58231.50018930435, "episode/length": 176.0, "episode/score": 9.298232268069114, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.19823200592509238}
{"step": 434120, "time": 58236.87030649185, "episode/length": 172.0, "episode/score": 9.302546649229043, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.20254638266123948}
{"step": 434256, "time": 58256.15272164345, "episode/length": 336.0, "episode/score": 8.476069606163946, "episode/reward_rate": 0.9910979228486647, "episode/intrinsic_return": 0.37606937545206165}
{"step": 434520, "time": 58289.88384604454, "episode/length": 177.0, "episode/score": 7.307220973929361, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.20722076487072627}
{"step": 435000, "time": 58349.82650637627, "episode/length": 218.0, "episode/score": 10.35020287705811, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.2502026670390478}
{"step": 435321, "time": 58391.20861029625, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.5113424209349935, "train/action_min": 0.0, "train/action_std": 3.5871770165183325, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04365083127018602, "train/actor_opt_grad_steps": 107510.0, "train/actor_opt_loss": -9.358196166341497, "train/adv_mag": 0.5006091977185744, "train/adv_max": 0.45630343903832254, "train/adv_mean": 0.0028530644776181622, "train/adv_min": -0.3990593739053145, "train/adv_std": 0.05437422462086627, "train/cont_avg": 0.9946158506016043, "train/cont_loss_mean": 0.00010874170454935958, "train/cont_loss_std": 0.0032555908097191104, "train/cont_neg_acc": 0.9982174689119513, "train/cont_neg_loss": 0.009033653100135219, "train/cont_pos_acc": 0.9999894773896365, "train/cont_pos_loss": 7.555493680001898e-05, "train/cont_pred": 0.9946095223095328, "train/cont_rate": 0.9946158506016043, "train/dyn_loss_mean": 6.768646400880049, "train/dyn_loss_std": 8.878642393305977, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1076065219022373, "train/extr_critic_critic_opt_grad_steps": 107510.0, "train/extr_critic_critic_opt_loss": 16232.70907315341, "train/extr_critic_mag": 8.43817526771423, "train/extr_critic_max": 8.43817526771423, "train/extr_critic_mean": 2.310119157806437, "train/extr_critic_min": -0.5589151701187705, "train/extr_critic_std": 2.0218042638850084, "train/extr_return_normed_mag": 1.532436194266865, "train/extr_return_normed_max": 1.532436194266865, "train/extr_return_normed_mean": 0.39541429743409795, "train/extr_return_normed_min": -0.11643412476156485, "train/extr_return_normed_std": 0.33119718650764324, "train/extr_return_rate": 0.739787736678506, "train/extr_return_raw_mag": 9.378129265525125, "train/extr_return_raw_max": 9.378129265525125, "train/extr_return_raw_mean": 2.327770933747929, "train/extr_return_raw_min": -0.8461384068835865, "train/extr_return_raw_std": 2.053901135602737, "train/extr_reward_mag": 1.0287649746247154, "train/extr_reward_max": 1.0287649746247154, "train/extr_reward_mean": 0.03768530120465526, "train/extr_reward_min": -0.6510942428507269, "train/extr_reward_std": 0.1874752176955422, "train/image_loss_mean": 3.7163023215564177, "train/image_loss_std": 8.943304551476464, "train/model_loss_mean": 7.857671069588891, "train/model_loss_std": 13.015721101811863, "train/model_opt_grad_norm": 38.48941593272712, "train/model_opt_grad_steps": 107414.64171122995, "train/model_opt_loss": 10653.147272936163, "train/model_opt_model_opt_grad_overflow": 0.0053475935828877, "train/model_opt_model_opt_grad_scale": 1350.2673796791444, "train/policy_entropy_mag": 2.469727236956836, "train/policy_entropy_max": 2.469727236956836, "train/policy_entropy_mean": 0.47756659458665285, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.5681353216184014, "train/policy_logprob_mag": 7.438384089240416, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.47689920791330187, "train/policy_logprob_min": -7.438384089240416, "train/policy_logprob_std": 1.057277975872876, "train/policy_randomness_mag": 0.871705335410521, "train/policy_randomness_max": 0.871705335410521, "train/policy_randomness_mean": 0.16856004975058816, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.2005268382356766, "train/post_ent_mag": 60.43823378863819, "train/post_ent_max": 60.43823378863819, "train/post_ent_mean": 44.27420152062401, "train/post_ent_min": 19.520888328552246, "train/post_ent_std": 7.049772249823586, "train/prior_ent_mag": 74.75315954850957, "train/prior_ent_max": 74.75315954850957, "train/prior_ent_mean": 51.03297014287449, "train/prior_ent_min": 30.73909066960136, "train/prior_ent_std": 6.7947871697777735, "train/rep_loss_mean": 6.768646400880049, "train/rep_loss_std": 8.878642393305977, "train/reward_avg": 0.02503687048699448, "train/reward_loss_mean": 0.08007221184870139, "train/reward_loss_std": 0.19300360041346779, "train/reward_max_data": 1.009806180382795, "train/reward_max_pred": 1.009027399481299, "train/reward_neg_acc": 0.9985945094077983, "train/reward_neg_loss": 0.05418341503264432, "train/reward_pos_acc": 0.8970725698904558, "train/reward_pos_loss": 0.7574014730631986, "train/reward_pred": 0.024614786657001723, "train/reward_rate": 0.036874373328877004, "train_stats/sum_log_reward": 7.48888901869456, "train_stats/max_log_achievement_collect_coal": 0.027777777777777776, "train_stats/max_log_achievement_collect_drink": 2.4722222222222223, "train_stats/max_log_achievement_collect_sapling": 1.9166666666666667, "train_stats/max_log_achievement_collect_stone": 2.0277777777777777, "train_stats/max_log_achievement_collect_wood": 12.166666666666666, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.3333333333333333, "train_stats/max_log_achievement_eat_cow": 0.16666666666666666, "train_stats/max_log_achievement_make_wood_pickaxe": 2.7777777777777777, "train_stats/max_log_achievement_make_wood_sword": 1.6944444444444444, "train_stats/max_log_achievement_place_furnace": 0.0, "train_stats/max_log_achievement_place_plant": 1.75, "train_stats/max_log_achievement_place_stone": 1.3333333333333333, "train_stats/max_log_achievement_place_table": 3.5277777777777777, "train_stats/max_log_achievement_wake_up": 1.0277777777777777, "train_stats/mean_log_entropy": 0.40705980608860654, "eval_stats/sum_log_reward": 9.100000381469727, "eval_stats/max_log_achievement_collect_coal": 0.125, "eval_stats/max_log_achievement_collect_drink": 3.5, "eval_stats/max_log_achievement_collect_sapling": 1.5, "eval_stats/max_log_achievement_collect_stone": 3.75, "eval_stats/max_log_achievement_collect_wood": 15.5, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.75, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_make_wood_pickaxe": 3.75, "eval_stats/max_log_achievement_make_wood_sword": 1.75, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.5, "eval_stats/max_log_achievement_place_stone": 2.0, "eval_stats/max_log_achievement_place_table": 4.625, "eval_stats/max_log_achievement_wake_up": 1.0, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 7.753646968922112e-06, "report/cont_loss_std": 0.00019614076882135123, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 3.753584314836189e-05, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 7.548655503342161e-06, "report/cont_pred": 0.993156909942627, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 8.684168815612793, "report/dyn_loss_std": 9.951647758483887, "report/image_loss_mean": 5.07252311706543, "report/image_loss_std": 11.077834129333496, "report/model_loss_mean": 10.373148918151855, "report/model_loss_std": 15.735526084899902, "report/post_ent_mag": 61.794273376464844, "report/post_ent_max": 61.794273376464844, "report/post_ent_mean": 43.448726654052734, "report/post_ent_min": 22.522689819335938, "report/post_ent_std": 7.053955554962158, "report/prior_ent_mag": 74.87126922607422, "report/prior_ent_max": 74.87126922607422, "report/prior_ent_mean": 51.97140121459961, "report/prior_ent_min": 27.23917007446289, "report/prior_ent_std": 7.382506370544434, "report/rep_loss_mean": 8.684168815612793, "report/rep_loss_std": 9.951647758483887, "report/reward_avg": 0.020245783030986786, "report/reward_loss_mean": 0.09011706709861755, "report/reward_loss_std": 0.18495909869670868, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0024158954620361, "report/reward_neg_acc": 0.9959431886672974, "report/reward_neg_loss": 0.06594600528478622, "report/reward_pos_acc": 0.8947368264198303, "report/reward_pos_loss": 0.7172923684120178, "report/reward_pred": 0.021084927022457123, "report/reward_rate": 0.037109375, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 1.860799670794222e-06, "eval/cont_loss_std": 2.8486909286584705e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00012670454452745616, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.124981736211339e-06, "eval/cont_pred": 0.9941402673721313, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 20.442066192626953, "eval/dyn_loss_std": 11.592242240905762, "eval/image_loss_mean": 28.22195816040039, "eval/image_loss_std": 32.64667892456055, "eval/model_loss_mean": 40.58649444580078, "eval/model_loss_std": 36.60049057006836, "eval/post_ent_mag": 54.872718811035156, "eval/post_ent_max": 54.872718811035156, "eval/post_ent_mean": 41.447452545166016, "eval/post_ent_min": 20.712413787841797, "eval/post_ent_std": 6.355119705200195, "eval/prior_ent_mag": 74.87126922607422, "eval/prior_ent_max": 74.87126922607422, "eval/prior_ent_mean": 54.26927947998047, "eval/prior_ent_min": 29.17898941040039, "eval/prior_ent_std": 5.649181842803955, "eval/rep_loss_mean": 20.442066192626953, "eval/rep_loss_std": 11.592242240905762, "eval/reward_avg": 0.01572265475988388, "eval/reward_loss_mean": 0.09929395467042923, "eval/reward_loss_std": 0.557516872882843, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 1.0012645721435547, "eval/reward_neg_acc": 0.9930209517478943, "eval/reward_neg_loss": 0.0637691393494606, "eval/reward_pos_acc": 0.8095238208770752, "eval/reward_pos_loss": 1.7960269451141357, "eval/reward_pred": 0.013836052268743515, "eval/reward_rate": 0.0205078125, "replay/size": 434817.0, "replay/inserts": 7456.0, "replay/samples": 29824.0, "replay/insert_wait_avg": 1.5446364623794228e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.545631458830936e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 86176.0, "eval_replay/inserts": 2560.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1809170246124268e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.08970832824707e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1384887695312, "timer/env.step_count": 932.0, "timer/env.step_total": 79.59187293052673, "timer/env.step_frac": 0.07958085187627215, "timer/env.step_avg": 0.08539900529026473, "timer/env.step_min": 0.02339959144592285, "timer/env.step_max": 3.154067039489746, "timer/replay._sample_count": 29824.0, "timer/replay._sample_total": 14.517621517181396, "timer/replay._sample_frac": 0.014515611268037892, "timer/replay._sample_avg": 0.00048677647254497707, "timer/replay._sample_min": 0.0003523826599121094, "timer/replay._sample_max": 0.02896881103515625, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1252.0, "timer/agent.policy_total": 20.444133043289185, "timer/agent.policy_frac": 0.020441302152506467, "timer/agent.policy_avg": 0.01632917974703609, "timer/agent.policy_min": 0.009640932083129883, "timer/agent.policy_max": 0.05977892875671387, "timer/dataset_train_count": 1864.0, "timer/dataset_train_total": 0.2972414493560791, "timer/dataset_train_frac": 0.00029720029045354984, "timer/dataset_train_avg": 0.0001594642968648493, "timer/dataset_train_min": 9.34600830078125e-05, "timer/dataset_train_max": 0.0007793903350830078, "timer/agent.train_count": 1864.0, "timer/agent.train_total": 836.3538815975189, "timer/agent.train_frac": 0.8362380720158903, "timer/agent.train_avg": 0.448687704719699, "timer/agent.train_min": 0.4361541271209717, "timer/agent.train_max": 0.9847521781921387, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4736506938934326, "timer/agent.report_frac": 0.0004735851076746024, "timer/agent.report_avg": 0.2368253469467163, "timer/agent.report_min": 0.23041892051696777, "timer/agent.report_max": 0.24323177337646484, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7418136596679688e-05, "timer/dataset_eval_frac": 2.7414340018463018e-08, "timer/dataset_eval_avg": 2.7418136596679688e-05, "timer/dataset_eval_min": 2.7418136596679688e-05, "timer/dataset_eval_max": 2.7418136596679688e-05, "fps": 7.45485264021064}
{"step": 435344, "time": 58393.87465405464, "episode/length": 152.0, "episode/score": 8.276296841815565, "episode/reward_rate": 0.9738562091503268, "episode/intrinsic_return": 0.17629655825112422}
{"step": 435560, "time": 58422.32295370102, "episode/length": 227.0, "episode/score": 10.348201940758372, "episode/reward_rate": 0.9780701754385965, "episode/intrinsic_return": 0.24820172768340854}
{"step": 435680, "time": 58438.63822746277, "episode/length": 177.0, "episode/score": 8.304237598093096, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.2042374147913506}
{"step": 436152, "time": 58497.87114405632, "episode/length": 58.0, "episode/score": 6.16629192417895, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.06629166564380284}
{"step": 436168, "time": 58501.34635591507, "episode/length": 272.0, "episode/score": 10.416529674221238, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.3165294236605405}
{"step": 436232, "time": 58510.5764029026, "episode/length": 153.0, "episode/score": 10.272797100427852, "episode/reward_rate": 0.9805194805194806, "episode/intrinsic_return": 0.17279671337018954}
{"step": 436728, "time": 58572.45884680748, "episode/length": 172.0, "episode/score": 10.30610031174001, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.20609999592852546}
{"step": 436792, "time": 58581.70205259323, "episode/length": 383.0, "episode/score": 11.529253879789394, "episode/reward_rate": 0.9921875, "episode/intrinsic_return": 0.4292535477961792}
{"step": 436912, "time": 58597.76258087158, "episode/length": 168.0, "episode/score": 9.288064170948928, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.18806392859551124}
{"step": 437248, "time": 58639.96060872078, "episode/length": 394.0, "episode/score": 9.521244404702884, "episode/reward_rate": 0.9974683544303797, "episode/intrinsic_return": 0.4212441028612375}
{"step": 437696, "time": 58695.56353545189, "episode/length": 396.0, "episode/score": 9.506333209617878, "episode/reward_rate": 0.8866498740554156, "episode/intrinsic_return": 0.40633291406265926}
{"step": 437880, "time": 58719.42262363434, "episode/length": 205.0, "episode/score": 8.33922892526607, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.23922866603243165}
{"step": 438048, "time": 58741.23626995087, "episode/length": 234.0, "episode/score": 9.377827665783116, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.27782739234680776}
{"step": 438104, "time": 58749.4904088974, "episode/length": 148.0, "episode/score": 5.260124018248462, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.16012386681541102}
{"step": 438264, "time": 58770.55012464523, "episode/length": 183.0, "episode/score": 7.300275181085453, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.20027495631074999}
{"step": 438264, "time": 58770.559260845184, "episode/length": 263.0, "episode/score": 8.401766369403049, "episode/reward_rate": 0.9962121212121212, "episode/intrinsic_return": 0.30176616389508126}
{"step": 438720, "time": 58829.31378817558, "episode/length": 183.0, "episode/score": 8.306608100840094, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.20660783217681455}
{"step": 438800, "time": 58840.48784947395, "episode/length": 258.0, "episode/score": 7.397381067661627, "episode/reward_rate": 0.9961389961389961, "episode/intrinsic_return": 0.29738079244998517}
{"step": 439328, "time": 58905.91445541382, "episode/length": 180.0, "episode/score": 9.30952215058278, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.20952191276956}
{"step": 439416, "time": 58918.14390850067, "episode/length": 163.0, "episode/score": 7.276942394670186, "episode/reward_rate": 0.9634146341463414, "episode/intrinsic_return": 0.17694219576878822}
{"step": 439640, "time": 58947.25986170769, "episode/length": 171.0, "episode/score": 9.285623335130367, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.1856230378289183}
{"step": 439992, "time": 58991.56053328514, "episode/length": 148.0, "episode/score": 6.2746251944918185, "episode/reward_rate": 0.959731543624161, "episode/intrinsic_return": 0.17462499672546983}
{"step": 440024, "time": 59017.45884156227, "eval_episode/length": 157.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9683544303797469}
{"step": 440024, "time": 59019.025594472885, "eval_episode/length": 159.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.99375}
{"step": 440024, "time": 59020.89469027519, "eval_episode/length": 164.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9696969696969697}
{"step": 440024, "time": 59022.81121683121, "eval_episode/length": 173.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9942528735632183}
{"step": 440024, "time": 59024.48928785324, "eval_episode/length": 177.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9719101123595506}
{"step": 440024, "time": 59027.50381207466, "eval_episode/length": 52.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9245283018867925}
{"step": 440024, "time": 59030.91138482094, "eval_episode/length": 244.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9959183673469387}
{"step": 440024, "time": 59034.591922044754, "eval_episode/length": 295.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9966216216216216}
{"step": 440216, "time": 59057.86704492569, "episode/length": 186.0, "episode/score": 9.309461816093972, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.20946149178416817}
{"step": 440272, "time": 59066.17913222313, "episode/length": 277.0, "episode/score": 7.426619169564219, "episode/reward_rate": 0.9964028776978417, "episode/intrinsic_return": 0.3266189075366128}
{"step": 440992, "time": 59154.5883140564, "episode/length": 411.0, "episode/score": 10.570770574013295, "episode/reward_rate": 0.9878640776699029, "episode/intrinsic_return": 0.47077030034415657}
{"step": 441184, "time": 59179.529418468475, "episode/length": 148.0, "episode/score": 7.255206838413869, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.15520655682848883}
{"step": 441560, "time": 59226.637585401535, "episode/length": 411.0, "episode/score": 11.523123205088268, "episode/reward_rate": 0.9174757281553398, "episode/intrinsic_return": 0.4231228813605412}
{"step": 441816, "time": 59259.0986225605, "episode/length": 310.0, "episode/score": 9.438964052107622, "episode/reward_rate": 0.9967845659163987, "episode/intrinsic_return": 0.3389638991902757}
{"step": 441944, "time": 59275.96486234665, "episode/length": 215.0, "episode/score": 8.343511157998364, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.24351092268807406}
{"step": 442104, "time": 59297.184490442276, "episode/length": 228.0, "episode/score": 10.346004693645227, "episode/reward_rate": 0.9737991266375546, "episode/intrinsic_return": 0.24600442262453726}
{"step": 442472, "time": 59344.537583589554, "episode/length": 381.0, "episode/score": 6.5339834192936905, "episode/reward_rate": 0.9895287958115183, "episode/intrinsic_return": 0.43398323712699494}
{"step": 442568, "time": 59357.844499111176, "episode/length": 172.0, "episode/score": 9.298706045640756, "episode/reward_rate": 0.953757225433526, "episode/intrinsic_return": 0.19870572948002518}
{"step": 442821, "time": 59391.4574534893, "train_stats/sum_log_reward": 8.506250217556953, "train_stats/max_log_achievement_collect_coal": 0.21875, "train_stats/max_log_achievement_collect_drink": 4.375, "train_stats/max_log_achievement_collect_sapling": 1.875, "train_stats/max_log_achievement_collect_stone": 4.96875, "train_stats/max_log_achievement_collect_wood": 11.8125, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.46875, "train_stats/max_log_achievement_eat_cow": 0.03125, "train_stats/max_log_achievement_make_wood_pickaxe": 2.4375, "train_stats/max_log_achievement_make_wood_sword": 1.5, "train_stats/max_log_achievement_place_furnace": 0.0625, "train_stats/max_log_achievement_place_plant": 1.71875, "train_stats/max_log_achievement_place_stone": 4.03125, "train_stats/max_log_achievement_place_table": 3.5625, "train_stats/max_log_achievement_wake_up": 1.375, "train_stats/mean_log_entropy": 0.5058440137654543, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.6229633188502675, "train/action_min": 0.0, "train/action_std": 3.8023610217048525, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04337198904810105, "train/actor_opt_grad_steps": 109380.0, "train/actor_opt_loss": -8.402086270923283, "train/adv_mag": 0.470462674444372, "train/adv_max": 0.43512670496568323, "train/adv_mean": 0.002377675339119835, "train/adv_min": -0.39070130032014083, "train/adv_std": 0.053710012651860393, "train/cont_avg": 0.994558405748663, "train/cont_loss_mean": 7.665254141875889e-05, "train/cont_loss_std": 0.0022953600578029774, "train/cont_neg_acc": 0.9985676092260024, "train/cont_neg_loss": 0.008136021428429601, "train/cont_pos_acc": 0.9999894812145335, "train/cont_pos_loss": 2.1252318071107012e-05, "train/cont_pred": 0.994553192095323, "train/cont_rate": 0.994558405748663, "train/dyn_loss_mean": 6.82241215170386, "train/dyn_loss_std": 8.967934072973893, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0794558566521832, "train/extr_critic_critic_opt_grad_steps": 109380.0, "train/extr_critic_critic_opt_loss": 16142.226959391712, "train/extr_critic_mag": 8.330602380681166, "train/extr_critic_max": 8.330602380681166, "train/extr_critic_mean": 2.2144283234754347, "train/extr_critic_min": -0.5547520674486212, "train/extr_critic_std": 1.9765060942440746, "train/extr_return_normed_mag": 1.5356416829767074, "train/extr_return_normed_max": 1.5356416829767074, "train/extr_return_normed_mean": 0.3898594648761545, "train/extr_return_normed_min": -0.11695998259645732, "train/extr_return_normed_std": 0.3303413435737079, "train/extr_return_rate": 0.7202453457097956, "train/extr_return_raw_mag": 9.180096544683936, "train/extr_return_raw_max": 9.180096544683936, "train/extr_return_raw_mean": 2.2288109816331914, "train/extr_return_raw_min": -0.8456072807312012, "train/extr_return_raw_std": 2.0043218091209942, "train/extr_reward_mag": 1.0309897973575695, "train/extr_reward_max": 1.0309897973575695, "train/extr_reward_mean": 0.036611551747602576, "train/extr_reward_min": -0.6492982745808076, "train/extr_reward_std": 0.18500326430415087, "train/image_loss_mean": 3.7511904112157977, "train/image_loss_std": 9.01358284924757, "train/model_loss_mean": 7.924750514208951, "train/model_loss_std": 13.139597877461643, "train/model_opt_grad_norm": 39.88432134536498, "train/model_opt_grad_steps": 109283.1871657754, "train/model_opt_loss": 12966.081582135695, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1637.7005347593583, "train/policy_entropy_mag": 2.4835121810117506, "train/policy_entropy_max": 2.4835121810117506, "train/policy_entropy_mean": 0.4979962456353845, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.5936957063840672, "train/policy_logprob_mag": 7.4383840790406905, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.49747826342276713, "train/policy_logprob_min": -7.4383840790406905, "train/policy_logprob_std": 1.0704126715022613, "train/policy_randomness_mag": 0.876570815708548, "train/policy_randomness_max": 0.876570815708548, "train/policy_randomness_mean": 0.17577082090039942, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.2095485306519238, "train/post_ent_mag": 60.514253300141526, "train/post_ent_max": 60.514253300141526, "train/post_ent_mean": 44.26180071499258, "train/post_ent_min": 19.380936683817982, "train/post_ent_std": 7.080328082018357, "train/prior_ent_mag": 74.76405836299142, "train/prior_ent_max": 74.76405836299142, "train/prior_ent_mean": 51.071521697834854, "train/prior_ent_min": 30.83324730205026, "train/prior_ent_std": 6.794390191368878, "train/rep_loss_mean": 6.82241215170386, "train/rep_loss_std": 8.967934072973893, "train/reward_avg": 0.024507593184231437, "train/reward_loss_mean": 0.08003621815360167, "train/reward_loss_std": 0.19277247455827692, "train/reward_max_data": 1.0140842562690775, "train/reward_max_pred": 1.0148157384943834, "train/reward_neg_acc": 0.9984661834762696, "train/reward_neg_loss": 0.05462500805602992, "train/reward_pos_acc": 0.8927887977763294, "train/reward_pos_loss": 0.757881861000775, "train/reward_pred": 0.024180622731539654, "train/reward_rate": 0.0361798128342246, "eval_stats/sum_log_reward": 6.4749999940395355, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 3.375, "eval_stats/max_log_achievement_collect_sapling": 2.0, "eval_stats/max_log_achievement_collect_stone": 0.625, "eval_stats/max_log_achievement_collect_wood": 14.0, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.125, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 2.0, "eval_stats/max_log_achievement_make_wood_sword": 1.875, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.875, "eval_stats/max_log_achievement_place_stone": 0.5, "eval_stats/max_log_achievement_place_table": 4.0, "eval_stats/max_log_achievement_wake_up": 1.25, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 5.2943482842238154e-06, "report/cont_loss_std": 9.214725287165493e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 1.3006865628995001e-06, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 5.306083039613441e-06, "report/cont_pred": 0.9970650672912598, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 6.136816024780273, "report/dyn_loss_std": 8.551981925964355, "report/image_loss_mean": 3.778059959411621, "report/image_loss_std": 8.15866756439209, "report/model_loss_mean": 7.53013277053833, "report/model_loss_std": 12.026389122009277, "report/post_ent_mag": 61.782493591308594, "report/post_ent_max": 61.782493591308594, "report/post_ent_mean": 45.773807525634766, "report/post_ent_min": 19.878231048583984, "report/post_ent_std": 7.661590576171875, "report/prior_ent_mag": 74.96945190429688, "report/prior_ent_max": 74.96945190429688, "report/prior_ent_mean": 52.31596755981445, "report/prior_ent_min": 31.924001693725586, "report/prior_ent_std": 6.721193790435791, "report/rep_loss_mean": 6.136816024780273, "report/rep_loss_std": 8.551981925964355, "report/reward_avg": 0.016971347853541374, "report/reward_loss_mean": 0.06997773051261902, "report/reward_loss_std": 0.20342618227005005, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0036146640777588, "report/reward_neg_acc": 0.9939879775047302, "report/reward_neg_loss": 0.04940016195178032, "report/reward_pos_acc": 0.9230769872665405, "report/reward_pos_loss": 0.859839677810669, "report/reward_pred": 0.017141779884696007, "report/reward_rate": 0.025390625, "eval/cont_avg": 0.9931640625, "eval/cont_loss_mean": 4.5987162593519315e-06, "eval/cont_loss_std": 5.779905040981248e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00031261215917766094, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 2.478662736393744e-06, "eval/cont_pred": 0.9931637644767761, "eval/cont_rate": 0.9931640625, "eval/dyn_loss_mean": 19.169523239135742, "eval/dyn_loss_std": 12.696371078491211, "eval/image_loss_mean": 19.836111068725586, "eval/image_loss_std": 21.424388885498047, "eval/model_loss_mean": 31.54674530029297, "eval/model_loss_std": 26.70794105529785, "eval/post_ent_mag": 56.91709518432617, "eval/post_ent_max": 56.91709518432617, "eval/post_ent_mean": 40.59117889404297, "eval/post_ent_min": 18.121240615844727, "eval/post_ent_std": 6.845126152038574, "eval/prior_ent_mag": 74.96945190429688, "eval/prior_ent_max": 74.96945190429688, "eval/prior_ent_mean": 53.12267303466797, "eval/prior_ent_min": 37.212955474853516, "eval/prior_ent_std": 5.874521255493164, "eval/rep_loss_mean": 19.169523239135742, "eval/rep_loss_std": 12.696371078491211, "eval/reward_avg": 0.0419921875, "eval/reward_loss_mean": 0.20891639590263367, "eval/reward_loss_std": 1.1117825508117676, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.002415657043457, "eval/reward_neg_acc": 0.9907692074775696, "eval/reward_neg_loss": 0.05986148864030838, "eval/reward_pos_acc": 0.6530612111091614, "eval/reward_pos_loss": 3.174805164337158, "eval/reward_pred": 0.02997278980910778, "eval/reward_rate": 0.0478515625, "replay/size": 442317.0, "replay/inserts": 7500.0, "replay/samples": 30000.0, "replay/insert_wait_avg": 1.5880902608235677e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.574717203776042e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 88544.0, "eval_replay/inserts": 2368.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1661165469401592e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.387731552124023e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2343633174896, "timer/env.step_count": 937.0, "timer/env.step_total": 75.99927878379822, "timer/env.step_frac": 0.07598147151406644, "timer/env.step_avg": 0.08110915558569713, "timer/env.step_min": 0.023261547088623047, "timer/env.step_max": 3.307619333267212, "timer/replay._sample_count": 30000.0, "timer/replay._sample_total": 14.653302431106567, "timer/replay._sample_frac": 0.014649869039197752, "timer/replay._sample_avg": 0.0004884434143702189, "timer/replay._sample_min": 0.00034809112548828125, "timer/replay._sample_max": 0.010947465896606445, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1233.0, "timer/agent.policy_total": 21.238516092300415, "timer/agent.policy_frac": 0.021233539729487366, "timer/agent.policy_avg": 0.017225073878589143, "timer/agent.policy_min": 0.009532928466796875, "timer/agent.policy_max": 1.279400110244751, "timer/dataset_train_count": 1875.0, "timer/dataset_train_total": 0.2955176830291748, "timer/dataset_train_frac": 0.00029544844075245295, "timer/dataset_train_avg": 0.00015760943094889323, "timer/dataset_train_min": 9.417533874511719e-05, "timer/dataset_train_max": 0.0012421607971191406, "timer/agent.train_count": 1875.0, "timer/agent.train_total": 838.8856976032257, "timer/agent.train_frac": 0.8386891396341185, "timer/agent.train_avg": 0.44740570538838703, "timer/agent.train_min": 0.4353952407836914, "timer/agent.train_max": 0.9626643657684326, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48101019859313965, "timer/agent.report_frac": 0.0004808974938611059, "timer/agent.report_avg": 0.24050509929656982, "timer/agent.report_min": 0.23553991317749023, "timer/agent.report_max": 0.24547028541564941, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.956390380859375e-05, "timer/dataset_eval_frac": 2.9556976737470592e-08, "timer/dataset_eval_avg": 2.956390380859375e-05, "timer/dataset_eval_min": 2.956390380859375e-05, "timer/dataset_eval_max": 2.956390380859375e-05, "fps": 7.49811834110413}
{"step": 443032, "time": 59416.9162812233, "episode/length": 151.0, "episode/score": 6.250914955172448, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.15091490915347094}
{"step": 443080, "time": 59424.191153526306, "episode/length": 429.0, "episode/score": 9.500104369119981, "episode/reward_rate": 0.986046511627907, "episode/intrinsic_return": 0.400104076155003}
{"step": 443240, "time": 59445.127406835556, "episode/length": 280.0, "episode/score": 7.404719071434556, "episode/reward_rate": 0.9786476868327402, "episode/intrinsic_return": 0.3047188866776196}
{"step": 443384, "time": 59464.137221336365, "episode/length": 159.0, "episode/score": 2.278815436541663, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.17881531770490255}
{"step": 443456, "time": 59474.36079311371, "episode/length": 46.0, "episode/score": 5.154458508419339, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.054458332306239754}
{"step": 443504, "time": 59481.66699695587, "episode/length": 242.0, "episode/score": 8.37307736530056, "episode/reward_rate": 0.9958847736625515, "episode/intrinsic_return": 0.2730770711423247}
{"step": 443664, "time": 59502.61684179306, "episode/length": 214.0, "episode/score": 10.336755338640614, "episode/reward_rate": 0.9720930232558139, "episode/intrinsic_return": 0.23675501735760918}
{"step": 443824, "time": 59523.40179157257, "episode/length": 168.0, "episode/score": 8.286312934968919, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.1863126964572075}
{"step": 444224, "time": 59573.251893520355, "episode/length": 89.0, "episode/score": 6.199507761924906, "episode/reward_rate": 0.9888888888888889, "episode/intrinsic_return": 0.09950758068953292}
{"step": 444552, "time": 59614.76559829712, "episode/length": 145.0, "episode/score": 10.255340973039893, "episode/reward_rate": 0.9726027397260274, "episode/intrinsic_return": 0.1553406471002745}
{"step": 444840, "time": 59651.15126132965, "episode/length": 225.0, "episode/score": 7.355322768751648, "episode/reward_rate": 0.9778761061946902, "episode/intrinsic_return": 0.2553225600422593}
{"step": 445088, "time": 59682.60651922226, "episode/length": 157.0, "episode/score": 10.279395299174212, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.179395003386162}
{"step": 445536, "time": 59738.539008140564, "episode/length": 233.0, "episode/score": 7.368839578673942, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.26883928090683185}
{"step": 445728, "time": 59763.331674575806, "episode/length": 394.0, "episode/score": 11.531946615379638, "episode/reward_rate": 0.9898734177215189, "episode/intrinsic_return": 0.4319462872281292}
{"step": 446144, "time": 59815.1728849411, "episode/length": 335.0, "episode/score": 11.473819552548775, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.3738192382506895}
{"step": 446312, "time": 59837.03057527542, "episode/length": 219.0, "episode/score": 11.351923935459581, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.2519235820459471}
{"step": 446464, "time": 59856.90215063095, "episode/length": 279.0, "episode/score": 8.428239937791659, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.32823975850624265}
{"step": 446792, "time": 59898.16724705696, "episode/length": 443.0, "episode/score": 10.530009900752702, "episode/reward_rate": 0.7837837837837838, "episode/intrinsic_return": 0.43000954873605224}
{"step": 446944, "time": 59918.03914093971, "episode/length": 151.0, "episode/score": 7.24148428272747, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.1414841736695962}
{"step": 447040, "time": 59931.28510475159, "episode/length": 187.0, "episode/score": 7.302811320847013, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.20281119252240387}
{"step": 447400, "time": 59976.38510942459, "episode/length": 319.0, "episode/score": 10.46283418857729, "episode/reward_rate": 0.9875, "episode/intrinsic_return": 0.36283390710832464}
{"step": 447568, "time": 59998.8233089447, "episode/length": 177.0, "episode/score": 9.28923164546677, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.1892313794810434}
{"step": 447864, "time": 60036.06968045235, "episode/length": 174.0, "episode/score": 9.29301722167611, "episode/reward_rate": 0.9657142857142857, "episode/intrinsic_return": 0.193016898530459}
{"step": 447864, "time": 60036.0803630352, "episode/length": 346.0, "episode/score": 9.486121180905684, "episode/reward_rate": 0.9942363112391931, "episode/intrinsic_return": 0.3861209347105614}
{"step": 447944, "time": 60048.89386200905, "episode/length": 203.0, "episode/score": 8.341099227599898, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.2410989890881865}
{"step": 448104, "time": 60069.8435587883, "episode/length": 163.0, "episode/score": 7.272542400252405, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.1725421959376945}
{"step": 448248, "time": 60088.8275885582, "episode/length": 47.0, "episode/score": 4.155031270481686, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0550311465226514}
{"step": 448768, "time": 60153.335157871246, "episode/length": 170.0, "episode/score": 10.294790878382628, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.19479058259457815}
{"step": 448896, "time": 60170.43805170059, "episode/length": 243.0, "episode/score": 11.380704460027573, "episode/reward_rate": 0.9754098360655737, "episode/intrinsic_return": 0.28070411010639873}
{"step": 449216, "time": 60210.79370594025, "episode/length": 205.0, "episode/score": 9.340003177372637, "episode/reward_rate": 0.9805825242718447, "episode/intrinsic_return": 0.24000291022275633}
{"step": 449344, "time": 60227.687641859055, "episode/length": 184.0, "episode/score": 9.316985964163905, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.2169856464897748}
{"step": 449424, "time": 60238.89886665344, "episode/length": 164.0, "episode/score": 7.279527208268064, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.1795269983945218}
{"step": 449600, "time": 60261.600382089615, "episode/length": 206.0, "episode/score": 9.337523433059232, "episode/reward_rate": 0.961352657004831, "episode/intrinsic_return": 0.23752323389589947}
{"step": 450008, "time": 60329.88993382454, "eval_episode/length": 121.0, "eval_episode/score": 9.100000023841858, "eval_episode/reward_rate": 0.9918032786885246}
{"step": 450008, "time": 60334.68695020676, "eval_episode/length": 160.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9751552795031055}
{"step": 450008, "time": 60337.30650424957, "eval_episode/length": 185.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9946236559139785}
{"step": 450008, "time": 60339.45302295685, "eval_episode/length": 202.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9753694581280788}
{"step": 450008, "time": 60341.13636159897, "eval_episode/length": 206.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9758454106280193}
{"step": 450008, "time": 60343.107659339905, "eval_episode/length": 216.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9953917050691244}
{"step": 450008, "time": 60344.759474277496, "eval_episode/length": 220.0, "eval_episode/score": 10.099999994039536, "eval_episode/reward_rate": 0.995475113122172}
{"step": 450008, "time": 60348.00005245209, "eval_episode/length": 262.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9961977186311787}
{"step": 450280, "time": 60380.75748705864, "episode/length": 188.0, "episode/score": 9.293055148696567, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.19305485255927124}
{"step": 450349, "time": 60391.469546079636, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.6649439385596745, "train/action_min": 0.0, "train/action_std": 3.7945351955738476, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04403680107219422, "train/actor_opt_grad_steps": 111255.0, "train/actor_opt_loss": -8.298387471150528, "train/adv_mag": 0.4917928119923206, "train/adv_max": 0.4497741070833612, "train/adv_mean": 0.002725334952164632, "train/adv_min": -0.40604353291874234, "train/adv_std": 0.0538832985776219, "train/cont_avg": 0.9946964345079787, "train/cont_loss_mean": 0.0002182532725399331, "train/cont_loss_std": 0.006840613746831083, "train/cont_neg_acc": 0.9968760562069873, "train/cont_neg_loss": 0.02137495947793639, "train/cont_pos_acc": 0.9999895362143821, "train/cont_pos_loss": 7.542145588283134e-05, "train/cont_pred": 0.9947089356310824, "train/cont_rate": 0.9946964345079787, "train/dyn_loss_mean": 6.821236658603587, "train/dyn_loss_std": 8.86041995565942, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0843229807437735, "train/extr_critic_critic_opt_grad_steps": 111255.0, "train/extr_critic_critic_opt_loss": 15986.357582903924, "train/extr_critic_mag": 8.248639563296704, "train/extr_critic_max": 8.248639563296704, "train/extr_critic_mean": 2.226577041631049, "train/extr_critic_min": -0.5372460421095503, "train/extr_critic_std": 1.9745479739726859, "train/extr_return_normed_mag": 1.534872886348278, "train/extr_return_normed_max": 1.534872886348278, "train/extr_return_normed_mean": 0.39493055625798856, "train/extr_return_normed_min": -0.1117881400153992, "train/extr_return_normed_std": 0.3327567006679291, "train/extr_return_rate": 0.7108180616447266, "train/extr_return_raw_mag": 9.106608725608663, "train/extr_return_raw_max": 9.106608725608663, "train/extr_return_raw_mean": 2.242987115332421, "train/extr_return_raw_min": -0.8081367957465192, "train/extr_return_raw_std": 2.003764820859787, "train/extr_reward_mag": 1.0288260300108727, "train/extr_reward_max": 1.0288260300108727, "train/extr_reward_mean": 0.03792064845007151, "train/extr_reward_min": -0.6419211543620901, "train/extr_reward_std": 0.1872875450297873, "train/image_loss_mean": 3.677351895799028, "train/image_loss_std": 8.515638478258824, "train/model_loss_mean": 7.850042779394921, "train/model_loss_std": 12.590058118739027, "train/model_opt_grad_norm": 40.521192327458806, "train/model_opt_grad_steps": 111156.93617021276, "train/model_opt_loss": 13007.856741397938, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1648.936170212766, "train/policy_entropy_mag": 2.498786486209707, "train/policy_entropy_max": 2.498786486209707, "train/policy_entropy_mean": 0.5195073412453874, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6130919497697911, "train/policy_logprob_mag": 7.438384068773148, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5184961495564339, "train/policy_logprob_min": -7.438384068773148, "train/policy_logprob_std": 1.0837514676312183, "train/policy_randomness_mag": 0.8819619737406994, "train/policy_randomness_max": 0.8819619737406994, "train/policy_randomness_mean": 0.18336329284183522, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.21639455450659104, "train/post_ent_mag": 60.25857631196367, "train/post_ent_max": 60.25857631196367, "train/post_ent_mean": 44.29656164696876, "train/post_ent_min": 19.389656371258674, "train/post_ent_std": 6.992481343289639, "train/prior_ent_mag": 74.8473594746691, "train/prior_ent_max": 74.8473594746691, "train/prior_ent_mean": 51.13527853945468, "train/prior_ent_min": 30.92614871897596, "train/prior_ent_std": 6.751550702338523, "train/rep_loss_mean": 6.821236658603587, "train/rep_loss_std": 8.86041995565942, "train/reward_avg": 0.025189470990184457, "train/reward_loss_mean": 0.07973066313152617, "train/reward_loss_std": 0.18691007210377683, "train/reward_max_data": 1.0113564139985023, "train/reward_max_pred": 1.0119146565173536, "train/reward_neg_acc": 0.9984994277041009, "train/reward_neg_loss": 0.05406688886912579, "train/reward_pos_acc": 0.89242326293854, "train/reward_pos_loss": 0.7473510747894327, "train/reward_pred": 0.02494488368454845, "train/reward_rate": 0.037057430186170214, "train_stats/sum_log_reward": 8.335294260698205, "train_stats/max_log_achievement_collect_coal": 0.20588235294117646, "train_stats/max_log_achievement_collect_drink": 3.088235294117647, "train_stats/max_log_achievement_collect_sapling": 1.3823529411764706, "train_stats/max_log_achievement_collect_stone": 5.5588235294117645, "train_stats/max_log_achievement_collect_wood": 10.941176470588236, "train_stats/max_log_achievement_defeat_skeleton": 0.029411764705882353, "train_stats/max_log_achievement_defeat_zombie": 0.4411764705882353, "train_stats/max_log_achievement_eat_cow": 0.08823529411764706, "train_stats/max_log_achievement_make_wood_pickaxe": 2.0, "train_stats/max_log_achievement_make_wood_sword": 1.2647058823529411, "train_stats/max_log_achievement_place_furnace": 0.14705882352941177, "train_stats/max_log_achievement_place_plant": 1.3235294117647058, "train_stats/max_log_achievement_place_stone": 3.5588235294117645, "train_stats/max_log_achievement_place_table": 3.3823529411764706, "train_stats/max_log_achievement_wake_up": 1.411764705882353, "train_stats/mean_log_entropy": 0.5297915931133663, "eval_stats/sum_log_reward": 7.475000083446503, "eval_stats/max_log_achievement_collect_coal": 0.125, "eval_stats/max_log_achievement_collect_drink": 3.875, "eval_stats/max_log_achievement_collect_sapling": 1.0, "eval_stats/max_log_achievement_collect_stone": 5.75, "eval_stats/max_log_achievement_collect_wood": 13.25, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.625, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 2.625, "eval_stats/max_log_achievement_make_wood_sword": 1.625, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.0, "eval_stats/max_log_achievement_place_stone": 3.5, "eval_stats/max_log_achievement_place_table": 4.125, "eval_stats/max_log_achievement_wake_up": 1.0, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9912109375, "report/cont_loss_mean": 4.2636424041120335e-05, "report/cont_loss_std": 0.0008888619486242533, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 5.8764115237863734e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 4.2493422370171174e-05, "report/cont_pred": 0.991169810295105, "report/cont_rate": 0.9912109375, "report/dyn_loss_mean": 6.1403913497924805, "report/dyn_loss_std": 8.755128860473633, "report/image_loss_mean": 2.796844720840454, "report/image_loss_std": 6.740974426269531, "report/model_loss_mean": 6.570189476013184, "report/model_loss_std": 10.809357643127441, "report/post_ent_mag": 60.268028259277344, "report/post_ent_max": 60.268028259277344, "report/post_ent_mean": 43.68102264404297, "report/post_ent_min": 18.592906951904297, "report/post_ent_std": 7.05648136138916, "report/prior_ent_mag": 74.41270446777344, "report/prior_ent_max": 74.41270446777344, "report/prior_ent_mean": 49.708961486816406, "report/prior_ent_min": 27.313840866088867, "report/prior_ent_std": 6.956576824188232, "report/rep_loss_mean": 6.1403913497924805, "report/rep_loss_std": 8.755128860473633, "report/reward_avg": 0.022955264896154404, "report/reward_loss_mean": 0.08906736969947815, "report/reward_loss_std": 0.19929759204387665, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0055406093597412, "report/reward_neg_acc": 0.9989805817604065, "report/reward_neg_loss": 0.05904373526573181, "report/reward_pos_acc": 0.9302325248718262, "report/reward_pos_loss": 0.7740251421928406, "report/reward_pred": 0.022727996110916138, "report/reward_rate": 0.0419921875, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 3.1959364150679903e-06, "eval/cont_loss_std": 2.5043114874279127e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 3.703848415170796e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 3.02987882605521e-06, "eval/cont_pred": 0.9951143860816956, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 19.245141983032227, "eval/dyn_loss_std": 11.338237762451172, "eval/image_loss_mean": 15.860076904296875, "eval/image_loss_std": 18.077268600463867, "eval/model_loss_mean": 27.570789337158203, "eval/model_loss_std": 22.23284149169922, "eval/post_ent_mag": 61.406517028808594, "eval/post_ent_max": 61.406517028808594, "eval/post_ent_mean": 41.556182861328125, "eval/post_ent_min": 20.006633758544922, "eval/post_ent_std": 7.153046131134033, "eval/prior_ent_mag": 74.41270446777344, "eval/prior_ent_max": 74.41270446777344, "eval/prior_ent_mean": 54.3387451171875, "eval/prior_ent_min": 36.540950775146484, "eval/prior_ent_std": 6.136471748352051, "eval/rep_loss_mean": 19.245141983032227, "eval/rep_loss_std": 11.338237762451172, "eval/reward_avg": 0.04238281399011612, "eval/reward_loss_mean": 0.1636233627796173, "eval/reward_loss_std": 0.947641909122467, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0024206638336182, "eval/reward_neg_acc": 0.9897541403770447, "eval/reward_neg_loss": 0.10726310312747955, "eval/reward_pos_acc": 0.875, "eval/reward_pos_loss": 1.3096157312393188, "eval/reward_pred": 0.04064043611288071, "eval/reward_rate": 0.046875, "replay/size": 449845.0, "replay/inserts": 7528.0, "replay/samples": 30112.0, "replay/insert_wait_avg": 1.5839253424584676e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.649553062811921e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 90648.0, "eval_replay/inserts": 2104.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1961723008536567e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.450580596923828e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 999.9986515045166, "timer/env.step_count": 941.0, "timer/env.step_total": 76.13694071769714, "timer/env.step_frac": 0.07613704338815627, "timer/env.step_avg": 0.08091067026322757, "timer/env.step_min": 0.02295970916748047, "timer/env.step_max": 3.1908960342407227, "timer/replay._sample_count": 30112.0, "timer/replay._sample_total": 14.799493551254272, "timer/replay._sample_frac": 0.014799513508331395, "timer/replay._sample_avg": 0.0004914815871165739, "timer/replay._sample_min": 0.0003631114959716797, "timer/replay._sample_max": 0.024875879287719727, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1204.0, "timer/agent.policy_total": 20.696011304855347, "timer/agent.policy_frac": 0.02069603921337075, "timer/agent.policy_avg": 0.017189378160178858, "timer/agent.policy_min": 0.009613513946533203, "timer/agent.policy_max": 0.1291365623474121, "timer/dataset_train_count": 1882.0, "timer/dataset_train_total": 0.2914557456970215, "timer/dataset_train_frac": 0.0002914561387243082, "timer/dataset_train_avg": 0.00015486490207068093, "timer/dataset_train_min": 9.274482727050781e-05, "timer/dataset_train_max": 0.0008764266967773438, "timer/agent.train_count": 1882.0, "timer/agent.train_total": 840.62597823143, "timer/agent.train_frac": 0.8406271118132935, "timer/agent.train_avg": 0.44666630086685977, "timer/agent.train_min": 0.4363057613372803, "timer/agent.train_max": 0.5806515216827393, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4769613742828369, "timer/agent.report_frac": 0.0004769620174639632, "timer/agent.report_avg": 0.23848068714141846, "timer/agent.report_min": 0.23273849487304688, "timer/agent.report_max": 0.24422287940979004, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7894973754882812e-05, "timer/dataset_eval_frac": 2.7895011371179657e-08, "timer/dataset_eval_avg": 2.7894973754882812e-05, "timer/dataset_eval_min": 2.7894973754882812e-05, "timer/dataset_eval_max": 2.7894973754882812e-05, "fps": 7.5279010728885565}
{"step": 450520, "time": 60412.306931734085, "episode/length": 202.0, "episode/score": 9.335370484135638, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.23537021814991022}
{"step": 450600, "time": 60424.98926234245, "episode/length": 444.0, "episode/score": 7.511744783930226, "episode/reward_rate": 0.7078651685393258, "episode/intrinsic_return": 0.4117446275204202}
{"step": 450864, "time": 60459.25040984154, "episode/length": 189.0, "episode/score": 10.304721989172322, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.20472166323270358}
{"step": 451144, "time": 60494.891394138336, "episode/length": 361.0, "episode/score": 9.480123370880847, "episode/reward_rate": 0.9917127071823204, "episode/intrinsic_return": 0.38012308297993513}
{"step": 451240, "time": 60508.032322883606, "episode/length": 204.0, "episode/score": 9.34433802372223, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.24433772991324076}
{"step": 451800, "time": 60577.69959139824, "episode/length": 189.0, "episode/score": 8.320990659140989, "episode/reward_rate": 0.968421052631579, "episode/intrinsic_return": 0.22099041118508467}
{"step": 451856, "time": 60585.928970098495, "episode/length": 156.0, "episode/score": 4.279775801898268, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.1797756630380718}
{"step": 452040, "time": 60609.71172833443, "episode/length": 189.0, "episode/score": 10.30317853897759, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.2031781450514245}
{"step": 452336, "time": 60647.35709309578, "episode/length": 36.0, "episode/score": 3.1419584280229174, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.04195833270205185}
{"step": 452480, "time": 60666.32933497429, "episode/length": 154.0, "episode/score": 6.256975287914429, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.15697507769164076}
{"step": 452760, "time": 60701.64195775986, "episode/length": 442.0, "episode/score": 9.530750266801306, "episode/reward_rate": 0.6478555304740407, "episode/intrinsic_return": 0.4307499638682657}
{"step": 452792, "time": 60707.063376665115, "episode/length": 420.0, "episode/score": 11.549141044417183, "episode/reward_rate": 0.9928741092636579, "episode/intrinsic_return": 0.44914072691767615}
{"step": 453120, "time": 60748.41579055786, "episode/length": 246.0, "episode/score": 10.387387182628572, "episode/reward_rate": 0.97165991902834, "episode/intrinsic_return": 0.28738689731790146}
{"step": 453120, "time": 60748.428018569946, "episode/length": 164.0, "episode/score": 9.286775076947151, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.18677476474454124}
{"step": 453368, "time": 60781.864522218704, "episode/length": 188.0, "episode/score": 9.30625714828966, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.20625681812998664}
{"step": 454136, "time": 60876.70596551895, "episode/length": 224.0, "episode/score": 9.349472761828792, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.24947253385266777}
{"step": 454304, "time": 60898.81079006195, "episode/length": 192.0, "episode/score": 7.323508229412255, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.2235080223326804}
{"step": 454424, "time": 60914.88505792618, "episode/length": 162.0, "episode/score": 8.272311727214401, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.17231148986684275}
{"step": 454640, "time": 60942.82726383209, "episode/length": 189.0, "episode/score": 10.307401652513363, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.20740133670187788}
{"step": 454904, "time": 60976.44186592102, "episode/length": 504.0, "episode/score": 10.656401278492012, "episode/reward_rate": 0.9841584158415841, "episode/intrinsic_return": 0.5564010203061116}
{"step": 455032, "time": 60993.454023599625, "episode/length": 318.0, "episode/score": 11.476072455184294, "episode/reward_rate": 0.9811912225705329, "episode/intrinsic_return": 0.37607213774299453}
{"step": 455336, "time": 61031.57645344734, "episode/length": 245.0, "episode/score": 10.394263647343905, "episode/reward_rate": 0.9959349593495935, "episode/intrinsic_return": 0.2942632994017913}
{"step": 455656, "time": 61071.71107459068, "episode/length": 168.0, "episode/score": 10.30181581418583, "episode/reward_rate": 0.9822485207100592, "episode/intrinsic_return": 0.2018154721808969}
{"step": 456024, "time": 61118.13385915756, "episode/length": 235.0, "episode/score": 8.371491778183554, "episode/reward_rate": 0.9745762711864406, "episode/intrinsic_return": 0.2714915231408668}
{"step": 456144, "time": 61134.23837971687, "episode/length": 154.0, "episode/score": 8.257627356346347, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.15762698581966106}
{"step": 456248, "time": 61148.55027985573, "episode/length": 227.0, "episode/score": 9.339166370569728, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.2391660767607391}
{"step": 456336, "time": 61160.7308177948, "episode/length": 442.0, "episode/score": 9.53270013855763, "episode/reward_rate": 0.9932279909706546, "episode/intrinsic_return": 0.4326998821179586}
{"step": 456400, "time": 61170.11806297302, "episode/length": 219.0, "episode/score": 8.348854295385536, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.24885394441662356}
{"step": 456520, "time": 61186.0756790638, "episode/length": 46.0, "episode/score": 4.1538196229957975, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.05381944339023903}
{"step": 456920, "time": 61236.59013104439, "episode/length": 157.0, "episode/score": 10.253754950585972, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.15375467412286525}
{"step": 457152, "time": 61266.3270111084, "episode/length": 264.0, "episode/score": 11.398237126450113, "episode/reward_rate": 0.9849056603773585, "episode/intrinsic_return": 0.2982368163429783}
{"step": 457560, "time": 61317.538514614105, "episode/length": 152.0, "episode/score": 9.261827621081466, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.1618272520681785}
{"step": 457824, "time": 61351.2934782505, "episode/length": 224.0, "episode/score": 8.337075404020652, "episode/reward_rate": 0.9822222222222222, "episode/intrinsic_return": 0.2370751655089407}
{"step": 457856, "time": 61356.7017390728, "episode/length": 314.0, "episode/score": 8.434704103767217, "episode/reward_rate": 0.9841269841269841, "episode/intrinsic_return": 0.334703875150808}
{"step": 458125, "time": 61391.67030262947, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.6943036984174675, "train/action_min": 0.0, "train/action_std": 3.803082979642428, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04336473212983364, "train/actor_opt_grad_steps": 113170.0, "train/actor_opt_loss": -8.87174663910499, "train/adv_mag": 0.4939912036443368, "train/adv_max": 0.4507408482906146, "train/adv_mean": 0.002626382632689246, "train/adv_min": -0.4021287141702114, "train/adv_std": 0.05350432426501543, "train/cont_avg": 0.9946965144230769, "train/cont_loss_mean": 9.961567533754335e-05, "train/cont_loss_std": 0.0029994878594181546, "train/cont_neg_acc": 1.0, "train/cont_neg_loss": 0.0018610211891124588, "train/cont_pos_acc": 0.9999647119106391, "train/cont_pos_loss": 9.009282751508298e-05, "train/cont_pred": 0.9946638394624759, "train/cont_rate": 0.9946965144230769, "train/dyn_loss_mean": 6.968380563687056, "train/dyn_loss_std": 8.9739483833313, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.073879341590099, "train/extr_critic_critic_opt_grad_steps": 113170.0, "train/extr_critic_critic_opt_loss": 16097.978791065705, "train/extr_critic_mag": 8.456883454934145, "train/extr_critic_max": 8.456883454934145, "train/extr_critic_mean": 2.2666099823438204, "train/extr_critic_min": -0.5287537959905771, "train/extr_critic_std": 2.0248202262780604, "train/extr_return_normed_mag": 1.5342391435916607, "train/extr_return_normed_max": 1.5342391435916607, "train/extr_return_normed_mean": 0.39296555572595354, "train/extr_return_normed_min": -0.11066579482494257, "train/extr_return_normed_std": 0.3342906381839361, "train/extr_return_rate": 0.7154193742152972, "train/extr_return_raw_mag": 9.308144006973658, "train/extr_return_raw_max": 9.308144006973658, "train/extr_return_raw_mean": 2.2827461212109297, "train/extr_return_raw_min": -0.8171944943758157, "train/extr_return_raw_std": 2.0577944712761123, "train/extr_reward_mag": 1.0310125534351056, "train/extr_reward_max": 1.0310125534351056, "train/extr_reward_mean": 0.039009352668355673, "train/extr_reward_min": -0.6421928124550061, "train/extr_reward_std": 0.18994990594876118, "train/image_loss_mean": 3.771135335090833, "train/image_loss_std": 9.144032830458421, "train/model_loss_mean": 8.033511817149627, "train/model_loss_std": 13.292452645913148, "train/model_opt_grad_norm": 40.677204239674104, "train/model_opt_grad_steps": 113070.53846153847, "train/model_opt_loss": 11700.066558994391, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1461.5384615384614, "train/policy_entropy_mag": 2.466301058500241, "train/policy_entropy_max": 2.466301058500241, "train/policy_entropy_mean": 0.5158195289281698, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6116973745517241, "train/policy_logprob_mag": 7.438384063427264, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5155936817328135, "train/policy_logprob_min": -7.438384063427264, "train/policy_logprob_std": 1.0806729353391207, "train/policy_randomness_mag": 0.8704960428751432, "train/policy_randomness_max": 0.8704960428751432, "train/policy_randomness_mean": 0.18206165868502397, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.2159023309365297, "train/post_ent_mag": 60.14247745611729, "train/post_ent_max": 60.14247745611729, "train/post_ent_mean": 44.19285403520633, "train/post_ent_min": 19.32719586690267, "train/post_ent_std": 6.97240049411089, "train/prior_ent_mag": 74.84391933343349, "train/prior_ent_max": 74.84391933343349, "train/prior_ent_mean": 51.15243260310246, "train/prior_ent_min": 30.83755253522824, "train/prior_ent_std": 6.752712584764529, "train/rep_loss_mean": 6.968380563687056, "train/rep_loss_std": 8.9739483833313, "train/reward_avg": 0.025976140878330438, "train/reward_loss_mean": 0.08124854289568388, "train/reward_loss_std": 0.1970769505852308, "train/reward_max_data": 1.012529945984865, "train/reward_max_pred": 1.0120111575493447, "train/reward_neg_acc": 0.9983219253711212, "train/reward_neg_loss": 0.05454497839777898, "train/reward_pos_acc": 0.8903307642692174, "train/reward_pos_loss": 0.7612609600409483, "train/reward_pred": 0.02567814268076267, "train/reward_rate": 0.03773036858974359, "train_stats/sum_log_reward": 8.62941203397863, "train_stats/max_log_achievement_collect_coal": 0.2647058823529412, "train_stats/max_log_achievement_collect_drink": 3.3529411764705883, "train_stats/max_log_achievement_collect_sapling": 1.7647058823529411, "train_stats/max_log_achievement_collect_stone": 6.088235294117647, "train_stats/max_log_achievement_collect_wood": 10.441176470588236, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.38235294117647056, "train_stats/max_log_achievement_eat_cow": 0.11764705882352941, "train_stats/max_log_achievement_make_wood_pickaxe": 1.7647058823529411, "train_stats/max_log_achievement_make_wood_sword": 1.1764705882352942, "train_stats/max_log_achievement_place_furnace": 0.029411764705882353, "train_stats/max_log_achievement_place_plant": 1.7352941176470589, "train_stats/max_log_achievement_place_stone": 4.588235294117647, "train_stats/max_log_achievement_place_table": 3.323529411764706, "train_stats/max_log_achievement_wake_up": 1.4705882352941178, "train_stats/mean_log_entropy": 0.6061324319418739, "train_stats/max_log_achievement_make_stone_pickaxe": 0.25, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 2.9670916319446405e-06, "report/cont_loss_std": 7.67745659686625e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 1.6133246845129179e-06, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.973734126499039e-06, "report/cont_pred": 0.9951143264770508, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 6.760776042938232, "report/dyn_loss_std": 8.498115539550781, "report/image_loss_mean": 2.7126545906066895, "report/image_loss_std": 8.271183013916016, "report/model_loss_mean": 6.848249912261963, "report/model_loss_std": 12.514996528625488, "report/post_ent_mag": 57.98506164550781, "report/post_ent_max": 57.98506164550781, "report/post_ent_mean": 43.80899429321289, "report/post_ent_min": 18.21625328063965, "report/post_ent_std": 6.8051886558532715, "report/prior_ent_mag": 75.02496337890625, "report/prior_ent_max": 75.02496337890625, "report/prior_ent_mean": 50.789466857910156, "report/prior_ent_min": 31.633872985839844, "report/prior_ent_std": 6.404590129852295, "report/rep_loss_mean": 6.760776042938232, "report/rep_loss_std": 8.498115539550781, "report/reward_avg": 0.031274378299713135, "report/reward_loss_mean": 0.07912716269493103, "report/reward_loss_std": 0.16218046844005585, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0035946369171143, "report/reward_neg_acc": 0.9969293475151062, "report/reward_neg_loss": 0.04915058985352516, "report/reward_pos_acc": 0.8723403811454773, "report/reward_pos_loss": 0.7022571563720703, "report/reward_pred": 0.0318676121532917, "report/reward_rate": 0.0458984375, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.00028979431954212487, "eval/cont_loss_std": 0.00910886563360691, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 4.482673375605373e-06, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.00029035264742560685, "eval/cont_pred": 0.9977949261665344, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 18.490468978881836, "eval/dyn_loss_std": 12.393596649169922, "eval/image_loss_mean": 17.247812271118164, "eval/image_loss_std": 22.490161895751953, "eval/model_loss_mean": 28.459199905395508, "eval/model_loss_std": 27.181711196899414, "eval/post_ent_mag": 58.953819274902344, "eval/post_ent_max": 58.953819274902344, "eval/post_ent_mean": 41.89215850830078, "eval/post_ent_min": 21.126766204833984, "eval/post_ent_std": 7.26870584487915, "eval/prior_ent_mag": 75.02496337890625, "eval/prior_ent_max": 75.02496337890625, "eval/prior_ent_mean": 53.986934661865234, "eval/prior_ent_min": 39.36479949951172, "eval/prior_ent_std": 5.864675521850586, "eval/rep_loss_mean": 18.490468978881836, "eval/rep_loss_std": 12.393596649169922, "eval/reward_avg": 0.03652343899011612, "eval/reward_loss_mean": 0.11681614816188812, "eval/reward_loss_std": 0.785438597202301, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0058188438415527, "eval/reward_neg_acc": 0.9878172874450684, "eval/reward_neg_loss": 0.054446008056402206, "eval/reward_pos_acc": 0.8205128312110901, "eval/reward_pos_loss": 1.6920620203018188, "eval/reward_pred": 0.03612720966339111, "eval/reward_rate": 0.0380859375, "replay/size": 457621.0, "replay/inserts": 7776.0, "replay/samples": 31104.0, "replay/insert_wait_avg": 1.5991460148689678e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.628949949280225e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 90648.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 9.834766387939453e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1836090087891, "timer/env.step_count": 972.0, "timer/env.step_total": 77.48316812515259, "timer/env.step_frac": 0.07746894412910911, "timer/env.step_avg": 0.07971519354439567, "timer/env.step_min": 0.022829055786132812, "timer/env.step_max": 3.3181469440460205, "timer/replay._sample_count": 31104.0, "timer/replay._sample_total": 15.28358769416809, "timer/replay._sample_frac": 0.015280782004930644, "timer/replay._sample_avg": 0.0004913704891386346, "timer/replay._sample_min": 0.0003802776336669922, "timer/replay._sample_max": 0.018682479858398438, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 972.0, "timer/agent.policy_total": 15.801161289215088, "timer/agent.policy_frac": 0.015798260586248256, "timer/agent.policy_avg": 0.016256338774912643, "timer/agent.policy_min": 0.014899730682373047, "timer/agent.policy_max": 0.04824709892272949, "timer/dataset_train_count": 1944.0, "timer/dataset_train_total": 0.30581021308898926, "timer/dataset_train_frac": 0.00030575407388654975, "timer/dataset_train_avg": 0.0001573097803955706, "timer/dataset_train_min": 9.1552734375e-05, "timer/dataset_train_max": 0.005329132080078125, "timer/agent.train_count": 1944.0, "timer/agent.train_total": 873.1928932666779, "timer/agent.train_frac": 0.8730325966169725, "timer/agent.train_avg": 0.44917329900549274, "timer/agent.train_min": 0.43676066398620605, "timer/agent.train_max": 1.161529541015625, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48357129096984863, "timer/agent.report_frac": 0.00048348251922372714, "timer/agent.report_avg": 0.24178564548492432, "timer/agent.report_min": 0.23416566848754883, "timer/agent.report_max": 0.2494056224822998, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.4332275390625e-05, "timer/dataset_eval_frac": 3.432597283277745e-08, "timer/dataset_eval_avg": 3.4332275390625e-05, "timer/dataset_eval_min": 3.4332275390625e-05, "timer/dataset_eval_max": 3.4332275390625e-05, "fps": 7.774453377747919}
{"step": 458152, "time": 61394.84411358833, "episode/length": 153.0, "episode/score": 9.248057356056052, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.14805696946405078}
{"step": 458728, "time": 61466.47820854187, "episode/length": 290.0, "episode/score": 11.423343387691602, "episode/reward_rate": 0.9759450171821306, "episode/intrinsic_return": 0.32334299888771056}
{"step": 459032, "time": 61506.60941314697, "episode/length": 313.0, "episode/score": 8.465918929186046, "episode/reward_rate": 0.9840764331210191, "episode/intrinsic_return": 0.3659186988234069}
{"step": 459216, "time": 61530.5330953598, "episode/length": 169.0, "episode/score": 11.2967952405279, "episode/reward_rate": 0.9647058823529412, "episode/intrinsic_return": 0.19679489957070473}
{"step": 459272, "time": 61538.747129917145, "episode/length": 213.0, "episode/score": 11.345865262188454, "episode/reward_rate": 0.9719626168224299, "episode/intrinsic_return": 0.24586491226727958}
{"step": 459584, "time": 61578.529651880264, "episode/length": 219.0, "episode/score": 8.35832791240864, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.2583276738969289}
{"step": 459672, "time": 61590.78361058235, "episode/length": 427.0, "episode/score": 11.517786602565138, "episode/reward_rate": 0.9906542056074766, "episode/intrinsic_return": 0.41778624595008296}
{"step": 459736, "time": 61599.99325656891, "episode/length": 197.0, "episode/score": 5.3111986776148115, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.21119855976758117}
{"step": 460096, "time": 61665.23744010925, "eval_episode/length": 170.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9766081871345029}
{"step": 460096, "time": 61668.635931015015, "eval_episode/length": 214.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9767441860465116}
{"step": 460096, "time": 61671.907522916794, "eval_episode/length": 251.0, "eval_episode/score": 9.099999971687794, "eval_episode/reward_rate": 0.996031746031746}
{"step": 460096, "time": 61674.862802028656, "eval_episode/length": 284.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9824561403508771}
{"step": 460096, "time": 61676.902116298676, "eval_episode/length": 298.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9832775919732442}
{"step": 460096, "time": 61678.9742372036, "eval_episode/length": 307.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9772727272727273}
{"step": 460096, "time": 61678.982713222504, "eval_episode/length": 307.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9837662337662337}
{"step": 460096, "time": 61687.563568115234, "eval_episode/length": 434.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.993103448275862}
{"step": 460264, "time": 61707.78791856766, "episode/length": 191.0, "episode/score": 6.319795315830561, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.21979512830876047}
{"step": 460272, "time": 61710.29051017761, "episode/length": 389.0, "episode/score": 6.519816928632281, "episode/reward_rate": 0.9923076923076923, "episode/intrinsic_return": 0.4198167926242604}
{"step": 460800, "time": 61775.60071825981, "episode/length": 190.0, "episode/score": 10.327147100455477, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.22714680583158042}
{"step": 460808, "time": 61778.03855586052, "episode/length": 221.0, "episode/score": 9.354932263377123, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.2549320008838549}
{"step": 460840, "time": 61783.46707582474, "episode/length": 202.0, "episode/score": 8.327303387955908, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.22730313687134185}
{"step": 461088, "time": 61814.95806336403, "episode/length": 168.0, "episode/score": 5.278285635422435, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.17828548282523116}
{"step": 461136, "time": 61822.27053165436, "episode/length": 182.0, "episode/score": 3.302397880990611, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.20239773235152825}
{"step": 461280, "time": 61841.825498342514, "episode/length": 211.0, "episode/score": 8.33948511051858, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.23948473112977808}
{"step": 461320, "time": 61848.19827795029, "episode/length": 131.0, "episode/score": 9.249619010817696, "episode/reward_rate": 0.9924242424242424, "episode/intrinsic_return": 0.14961868802129175}
{"step": 461536, "time": 61875.99263358116, "episode/length": 55.0, "episode/score": 1.1574547477630404, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.057454693653198774}
{"step": 462400, "time": 61982.70153069496, "episode/length": 198.0, "episode/score": 10.332873958181153, "episode/reward_rate": 0.9798994974874372, "episode/intrinsic_return": 0.2328736933595792}
{"step": 462464, "time": 61991.940282821655, "episode/length": 202.0, "episode/score": 10.329139100587781, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.22913874798905454}
{"step": 462688, "time": 62020.731699705124, "episode/length": 193.0, "episode/score": 9.30452253005933, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.20452227839268744}
{"step": 462704, "time": 62024.16882133484, "episode/length": 237.0, "episode/score": 8.380269314116958, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.2802689991203806}
{"step": 462728, "time": 62028.61454820633, "episode/length": 306.0, "episode/score": 11.426987869914228, "episode/reward_rate": 0.9869706840390879, "episode/intrinsic_return": 0.32698754548800935}
{"step": 462744, "time": 62032.06475663185, "episode/length": 150.0, "episode/score": 9.273552050361104, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.17355178292018536}
{"step": 462792, "time": 62039.51077055931, "episode/length": 183.0, "episode/score": 8.309740500877524, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.2097402000836155}
{"step": 462856, "time": 62048.89694786072, "episode/length": 48.0, "episode/score": 4.155252850873694, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.05525272027898609}
{"step": 463248, "time": 62097.84495425224, "episode/length": 245.0, "episode/score": 11.388029456627919, "episode/reward_rate": 0.9959349593495935, "episode/intrinsic_return": 0.2880291356941598}
{"step": 463400, "time": 62118.29121661186, "episode/length": 124.0, "episode/score": 7.229511281291707, "episode/reward_rate": 0.992, "episode/intrinsic_return": 0.12951094289564935}
{"step": 464024, "time": 62195.568376779556, "episode/length": 166.0, "episode/score": 8.27993771052661, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.1799374755073586}
{"step": 464224, "time": 62221.49482393265, "episode/length": 189.0, "episode/score": 8.300339980891295, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.20033973003955907}
{"step": 464464, "time": 62252.06658434868, "episode/length": 216.0, "episode/score": 10.342729457500354, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.24272903342261998}
{"step": 464544, "time": 62263.28055906296, "episode/length": 161.0, "episode/score": 9.278986044953854, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.1789857789681264}
{"step": 464792, "time": 62294.96646118164, "episode/length": 249.0, "episode/score": 8.386052821768317, "episode/reward_rate": 0.984, "episode/intrinsic_return": 0.28605258500283526}
{"step": 465032, "time": 62325.875638246536, "episode/length": 285.0, "episode/score": 12.427570423310499, "episode/reward_rate": 0.9790209790209791, "episode/intrinsic_return": 0.32757009155011474}
{"step": 465216, "time": 62349.70917868614, "episode/length": 226.0, "episode/score": 5.36380709225341, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.26380688633798854}
{"step": 465440, "time": 62378.46810054779, "episode/length": 322.0, "episode/score": 9.44185837178793, "episode/reward_rate": 0.9907120743034056, "episode/intrinsic_return": 0.3418581344985796}
{"step": 465496, "time": 62386.68920302391, "episode/length": 158.0, "episode/score": 9.277349111809599, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.17734869681225973}
{"step": 465517, "time": 62391.75311255455, "train_stats/sum_log_reward": 8.316216481698525, "train_stats/max_log_achievement_collect_coal": 0.40540540540540543, "train_stats/max_log_achievement_collect_drink": 3.108108108108108, "train_stats/max_log_achievement_collect_sapling": 1.4864864864864864, "train_stats/max_log_achievement_collect_stone": 4.675675675675675, "train_stats/max_log_achievement_collect_wood": 9.45945945945946, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.5675675675675675, "train_stats/max_log_achievement_eat_cow": 0.13513513513513514, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.4054054054054055, "train_stats/max_log_achievement_make_wood_sword": 1.1081081081081081, "train_stats/max_log_achievement_place_furnace": 0.21621621621621623, "train_stats/max_log_achievement_place_plant": 1.4324324324324325, "train_stats/max_log_achievement_place_stone": 3.081081081081081, "train_stats/max_log_achievement_place_table": 3.054054054054054, "train_stats/max_log_achievement_wake_up": 1.1891891891891893, "train_stats/mean_log_entropy": 0.5227405275847461, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.748366237331081, "train/action_min": 0.0, "train/action_std": 3.8608741038554424, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04196539880657518, "train/actor_opt_grad_steps": 115070.0, "train/actor_opt_loss": -7.069773722802465, "train/adv_mag": 0.47987814964474856, "train/adv_max": 0.42737144038483904, "train/adv_mean": 0.003157333548404347, "train/adv_min": -0.39773838769745185, "train/adv_std": 0.05189993657373093, "train/cont_avg": 0.9947107263513514, "train/cont_loss_mean": 8.209125756846601e-05, "train/cont_loss_std": 0.002505589666274828, "train/cont_neg_acc": 0.9948434159562395, "train/cont_neg_loss": 0.01030059375999046, "train/cont_pos_acc": 0.9999946793994388, "train/cont_pos_loss": 2.2484541578485753e-05, "train/cont_pred": 0.9947235938665029, "train/cont_rate": 0.9947107263513514, "train/dyn_loss_mean": 6.805143026403479, "train/dyn_loss_std": 8.899985661377778, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0757015247602721, "train/extr_critic_critic_opt_grad_steps": 115070.0, "train/extr_critic_critic_opt_loss": 15928.85856735642, "train/extr_critic_mag": 8.664672464937777, "train/extr_critic_max": 8.664672464937777, "train/extr_critic_mean": 2.342117826358692, "train/extr_critic_min": -0.5423274446178127, "train/extr_critic_std": 2.1148518549429403, "train/extr_return_normed_mag": 1.5157479253975121, "train/extr_return_normed_max": 1.5157479253975121, "train/extr_return_normed_mean": 0.3918296148648133, "train/extr_return_normed_min": -0.11064874771479014, "train/extr_return_normed_std": 0.33762012591233126, "train/extr_return_rate": 0.7068887610693235, "train/extr_return_raw_mag": 9.495634465604216, "train/extr_return_raw_max": 9.495634465604216, "train/extr_return_raw_mean": 2.36217257976532, "train/extr_return_raw_min": -0.8271402657032013, "train/extr_return_raw_std": 2.143037287608997, "train/extr_reward_mag": 1.0309696609909471, "train/extr_reward_max": 1.0309696609909471, "train/extr_reward_mean": 0.039965715541227444, "train/extr_reward_min": -0.6408682894062352, "train/extr_reward_std": 0.1921475350856781, "train/image_loss_mean": 3.736554045934935, "train/image_loss_std": 8.715136770299964, "train/model_loss_mean": 7.900071162146491, "train/model_loss_std": 12.839022291028822, "train/model_opt_grad_norm": 41.57209878869959, "train/model_opt_grad_steps": 114968.86486486487, "train/model_opt_loss": 11416.308884079392, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1439.1891891891892, "train/policy_entropy_mag": 2.4532957540976033, "train/policy_entropy_max": 2.4532957540976033, "train/policy_entropy_mean": 0.520646892206089, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.608794288860785, "train/policy_logprob_mag": 7.438384063823803, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5201372006454983, "train/policy_logprob_min": -7.438384063823803, "train/policy_logprob_std": 1.0810583974864032, "train/policy_randomness_mag": 0.8659057410987647, "train/policy_randomness_max": 0.8659057410987647, "train/policy_randomness_mean": 0.18376550376415252, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.21487766898967126, "train/post_ent_mag": 60.2316570797482, "train/post_ent_max": 60.2316570797482, "train/post_ent_mean": 44.43223544971363, "train/post_ent_min": 19.669004832087335, "train/post_ent_std": 7.0121661856367785, "train/prior_ent_mag": 74.83526829899968, "train/prior_ent_max": 74.83526829899968, "train/prior_ent_mean": 51.26393579019083, "train/prior_ent_min": 30.79319215722986, "train/prior_ent_std": 6.741817332602836, "train/rep_loss_mean": 6.805143026403479, "train/rep_loss_std": 8.899985661377778, "train/reward_avg": 0.025643575277078796, "train/reward_loss_mean": 0.08034920434694032, "train/reward_loss_std": 0.18897989714467847, "train/reward_max_data": 1.0136824640067847, "train/reward_max_pred": 1.0128553274515513, "train/reward_neg_acc": 0.9984754855568344, "train/reward_neg_loss": 0.05435708239674568, "train/reward_pos_acc": 0.8944910171869639, "train/reward_pos_loss": 0.7496919470864374, "train/reward_pred": 0.02534894335612252, "train/reward_rate": 0.03735747466216216, "eval_stats/sum_log_reward": 8.850000083446503, "eval_stats/max_log_achievement_collect_coal": 0.25, "eval_stats/max_log_achievement_collect_drink": 4.25, "eval_stats/max_log_achievement_collect_sapling": 1.625, "eval_stats/max_log_achievement_collect_stone": 5.25, "eval_stats/max_log_achievement_collect_wood": 9.625, "eval_stats/max_log_achievement_defeat_skeleton": 0.25, "eval_stats/max_log_achievement_defeat_zombie": 0.875, "eval_stats/max_log_achievement_eat_cow": 0.25, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.875, "eval_stats/max_log_achievement_make_wood_sword": 1.0, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.625, "eval_stats/max_log_achievement_place_stone": 5.125, "eval_stats/max_log_achievement_place_table": 2.875, "eval_stats/max_log_achievement_wake_up": 1.875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 1.7801664853323018e-06, "report/cont_loss_std": 2.068675348709803e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 2.18101081372879e-06, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.777803959157609e-06, "report/cont_pred": 0.9941388368606567, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 7.542893886566162, "report/dyn_loss_std": 9.012022972106934, "report/image_loss_mean": 2.9675793647766113, "report/image_loss_std": 8.720379829406738, "report/model_loss_mean": 7.577672481536865, "report/model_loss_std": 12.821640014648438, "report/post_ent_mag": 60.03954315185547, "report/post_ent_max": 60.03954315185547, "report/post_ent_mean": 44.56455993652344, "report/post_ent_min": 21.7001895904541, "report/post_ent_std": 7.302541732788086, "report/prior_ent_mag": 74.62149047851562, "report/prior_ent_max": 74.62149047851562, "report/prior_ent_mean": 52.28782653808594, "report/prior_ent_min": 27.960556030273438, "report/prior_ent_std": 6.511168003082275, "report/rep_loss_mean": 7.542893886566162, "report/rep_loss_std": 9.012022972106934, "report/reward_avg": 0.03240537270903587, "report/reward_loss_mean": 0.08435501158237457, "report/reward_loss_std": 0.17708805203437805, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0018277168273926, "report/reward_neg_acc": 0.9989786148071289, "report/reward_neg_loss": 0.05583857372403145, "report/reward_pos_acc": 0.9333333373069763, "report/reward_pos_loss": 0.7047459483146667, "report/reward_pred": 0.032938212156295776, "report/reward_rate": 0.0439453125, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.00293187634088099, "eval/cont_loss_std": 0.09377072006464005, "eval/cont_neg_acc": 0.75, "eval/cont_neg_loss": 0.7505353689193726, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 9.816881174629088e-08, "eval/cont_pred": 0.9970217347145081, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 21.031795501708984, "eval/dyn_loss_std": 12.518473625183105, "eval/image_loss_mean": 24.728090286254883, "eval/image_loss_std": 28.13581085205078, "eval/model_loss_mean": 37.42777633666992, "eval/model_loss_std": 32.15973663330078, "eval/post_ent_mag": 56.43023681640625, "eval/post_ent_max": 56.43023681640625, "eval/post_ent_mean": 40.49250793457031, "eval/post_ent_min": 21.505781173706055, "eval/post_ent_std": 6.62479829788208, "eval/prior_ent_mag": 74.62149047851562, "eval/prior_ent_max": 74.62149047851562, "eval/prior_ent_mean": 53.80727005004883, "eval/prior_ent_min": 36.924320220947266, "eval/prior_ent_std": 5.6296892166137695, "eval/rep_loss_mean": 21.031795501708984, "eval/rep_loss_std": 12.518473625183105, "eval/reward_avg": 0.03544921800494194, "eval/reward_loss_mean": 0.07767657190561295, "eval/reward_loss_std": 0.4967731237411499, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0018317699432373, "eval/reward_neg_acc": 0.9969512820243835, "eval/reward_neg_loss": 0.02607252076268196, "eval/reward_pos_acc": 0.9000000357627869, "eval/reward_pos_loss": 1.347136378288269, "eval/reward_pred": 0.0317460373044014, "eval/reward_rate": 0.0390625, "replay/size": 465013.0, "replay/inserts": 7392.0, "replay/samples": 29568.0, "replay/insert_wait_avg": 1.633418844891833e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.627572203095341e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 94128.0, "eval_replay/inserts": 3480.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2105908887139682e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.685754776000977e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0654900074005, "timer/env.step_count": 924.0, "timer/env.step_total": 81.91026854515076, "timer/env.step_frac": 0.08190490459234287, "timer/env.step_avg": 0.08864747678046618, "timer/env.step_min": 0.02335333824157715, "timer/env.step_max": 2.1552927494049072, "timer/replay._sample_count": 29568.0, "timer/replay._sample_total": 14.494105100631714, "timer/replay._sample_frac": 0.014493155943741702, "timer/replay._sample_avg": 0.0004901956541068627, "timer/replay._sample_min": 0.00039577484130859375, "timer/replay._sample_max": 0.032436370849609375, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1359.0, "timer/agent.policy_total": 21.900644302368164, "timer/agent.policy_frac": 0.021899210122935147, "timer/agent.policy_avg": 0.016115264387320208, "timer/agent.policy_min": 0.009864568710327148, "timer/agent.policy_max": 0.08890581130981445, "timer/dataset_train_count": 1848.0, "timer/dataset_train_total": 0.29166603088378906, "timer/dataset_train_frac": 0.0002916469309241245, "timer/dataset_train_avg": 0.00015782793878992915, "timer/dataset_train_min": 9.393692016601562e-05, "timer/dataset_train_max": 0.0008168220520019531, "timer/agent.train_count": 1848.0, "timer/agent.train_total": 828.6398940086365, "timer/agent.train_frac": 0.8285856299296004, "timer/agent.train_avg": 0.4483982110436345, "timer/agent.train_min": 0.43461155891418457, "timer/agent.train_max": 1.0004911422729492, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48415470123291016, "timer/agent.report_frac": 0.0004841229960143184, "timer/agent.report_avg": 0.24207735061645508, "timer/agent.report_min": 0.2341775894165039, "timer/agent.report_max": 0.24997711181640625, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.2411346435546875e-05, "timer/dataset_eval_frac": 2.2409878812417607e-08, "timer/dataset_eval_avg": 2.2411346435546875e-05, "timer/dataset_eval_min": 2.2411346435546875e-05, "timer/dataset_eval_max": 2.2411346435546875e-05, "fps": 7.3914023953859065}
{"step": 465768, "time": 62421.929010391235, "episode/length": 162.0, "episode/score": 5.2672314285428, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.1672313178260083}
{"step": 465880, "time": 62436.989339351654, "episode/length": 231.0, "episode/score": 7.354917053641657, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.25491677228910703}
{"step": 466024, "time": 62455.8884935379, "episode/length": 184.0, "episode/score": 11.30502749966763, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.20502714625399676}
{"step": 466456, "time": 62509.85315465927, "episode/length": 177.0, "episode/score": 7.309541896160226, "episode/reward_rate": 0.9662921348314607, "episode/intrinsic_return": 0.20954166277078912}
{"step": 466560, "time": 62524.00338888168, "episode/length": 220.0, "episode/score": 8.33990624733724, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.23990604101436475}
{"step": 466616, "time": 62532.39049768448, "episode/length": 174.0, "episode/score": 6.301077532991258, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.2010773118254292}
{"step": 466928, "time": 62571.97428011894, "episode/length": 185.0, "episode/score": 6.301294652804245, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.20129447273302503}
{"step": 466928, "time": 62571.9836165905, "episode/length": 178.0, "episode/score": 9.29171931581277, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.19171914522939915}
{"step": 467040, "time": 62590.27832746506, "episode/length": 158.0, "episode/score": 11.267065552197437, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.1670653749201847}
{"step": 467424, "time": 62638.46082854271, "episode/length": 192.0, "episode/score": 11.324229880837265, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.22422952975193766}
{"step": 467560, "time": 62656.73645281792, "episode/length": 124.0, "episode/score": 7.243543997449251, "episode/reward_rate": 0.952, "episode/intrinsic_return": 0.14354377965946696}
{"step": 467584, "time": 62661.26253819466, "episode/length": 194.0, "episode/score": 8.30743561766485, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.20743542822219752}
{"step": 467792, "time": 62688.08840537071, "episode/length": 146.0, "episode/score": 9.27443726483989, "episode/reward_rate": 0.9591836734693877, "episode/intrinsic_return": 0.17443698115903317}
{"step": 467920, "time": 62705.092475652695, "episode/length": 123.0, "episode/score": 9.220834545107664, "episode/reward_rate": 0.9919354838709677, "episode/intrinsic_return": 0.12083417609437674}
{"step": 468384, "time": 62763.18619275093, "episode/length": 181.0, "episode/score": 8.296581731545302, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.19658145403445815}
{"step": 468704, "time": 62803.85389208794, "episode/length": 280.0, "episode/score": 10.406388926370255, "episode/reward_rate": 0.9893238434163701, "episode/intrinsic_return": 0.30638867476181986}
{"step": 468888, "time": 62827.92409014702, "episode/length": 182.0, "episode/score": 8.282521651040042, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.1825214515274638}
{"step": 469032, "time": 62846.771374464035, "episode/length": 183.0, "episode/score": 9.311906907427783, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.2119065884730844}
{"step": 469432, "time": 62896.81847238541, "episode/length": 230.0, "episode/score": 10.346882870849186, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.24688262648760428}
{"step": 469720, "time": 62933.26229119301, "episode/length": 334.0, "episode/score": 11.469339833894992, "episode/reward_rate": 0.9940298507462687, "episode/intrinsic_return": 0.36933954654705303}
{"step": 469768, "time": 62940.63179731369, "episode/length": 230.0, "episode/score": 9.371367677954368, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.27136738111857994}
{"step": 469824, "time": 62948.847853422165, "episode/length": 139.0, "episode/score": 4.239747876550155, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.13974772127539836}
{"step": 470080, "time": 62999.33796644211, "eval_episode/length": 113.0, "eval_episode/score": 7.100000023841858, "eval_episode/reward_rate": 0.9912280701754386}
{"step": 470080, "time": 63003.16443133354, "eval_episode/length": 167.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9821428571428571}
{"step": 470080, "time": 63004.80586147308, "eval_episode/length": 169.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9647058823529412}
{"step": 470080, "time": 63007.020874500275, "eval_episode/length": 187.0, "eval_episode/score": 8.099999964237213, "eval_episode/reward_rate": 0.973404255319149}
{"step": 470080, "time": 63009.0161280632, "eval_episode/length": 198.0, "eval_episode/score": 11.100000008940697, "eval_episode/reward_rate": 0.9698492462311558}
{"step": 470080, "time": 63010.55109524727, "eval_episode/length": 199.0, "eval_episode/score": 5.099999971687794, "eval_episode/reward_rate": 0.995}
{"step": 470080, "time": 63012.5877199173, "eval_episode/length": 213.0, "eval_episode/score": 8.099999979138374, "eval_episode/reward_rate": 0.9813084112149533}
{"step": 470080, "time": 63017.00049805641, "eval_episode/length": 164.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9939393939393939}
{"step": 470216, "time": 63033.56294512749, "episode/length": 228.0, "episode/score": 8.336462017487065, "episode/reward_rate": 0.9737991266375546, "episode/intrinsic_return": 0.23646180441210163}
{"step": 470328, "time": 63048.70044827461, "episode/length": 179.0, "episode/score": 5.295955806177517, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.19595571583340643}
{"step": 470592, "time": 63082.22553110123, "episode/length": 349.0, "episode/score": 12.476275910699314, "episode/reward_rate": 0.9857142857142858, "episode/intrinsic_return": 0.37627555667449997}
{"step": 470704, "time": 63097.60819005966, "episode/length": 158.0, "episode/score": 9.271333109645639, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.1713328436599113}
{"step": 471280, "time": 63169.14393520355, "episode/length": 280.0, "episode/score": 8.415544261618379, "episode/reward_rate": 0.99644128113879, "episode/intrinsic_return": 0.31554396978845034}
{"step": 471312, "time": 63174.531383514404, "episode/length": 198.0, "episode/score": 3.3221344623193545, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.2221343136802716}
{"step": 471360, "time": 63181.851625204086, "episode/length": 191.0, "episode/score": 8.306485711796086, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.20648550593887194}
{"step": 471416, "time": 63190.06422972679, "episode/length": 205.0, "episode/score": 10.32207463318855, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.2220743227321691}
{"step": 471800, "time": 63238.36768102646, "episode/length": 197.0, "episode/score": 8.325797527039413, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.22579730826009836}
{"step": 471896, "time": 63251.624910354614, "episode/length": 162.0, "episode/score": 9.291838155262667, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.1918378916052461}
{"step": 471984, "time": 63263.68234491348, "episode/length": 206.0, "episode/score": 10.324389511473328, "episode/reward_rate": 0.9710144927536232, "episode/intrinsic_return": 0.2243892562560177}
{"step": 472264, "time": 63299.04215526581, "episode/length": 45.0, "episode/score": 5.156666873721406, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.05666666547767818}
{"step": 472480, "time": 63326.71910190582, "episode/length": 221.0, "episode/score": 11.35753655889448, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.2575362947713984}
{"step": 472592, "time": 63341.876009225845, "episode/length": 163.0, "episode/score": 8.275554614861903, "episode/reward_rate": 0.9634146341463414, "episode/intrinsic_return": 0.17555438100680476}
{"step": 472736, "time": 63361.07155299187, "episode/length": 171.0, "episode/score": 6.285977502546302, "episode/reward_rate": 0.9651162790697675, "episode/intrinsic_return": 0.18597739728647866}
{"step": 472969, "time": 63391.80333018303, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.492481518817204, "train/action_min": 0.0, "train/action_std": 3.6199220021565757, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04207532977064451, "train/actor_opt_grad_steps": 116925.0, "train/actor_opt_loss": -7.951227997960423, "train/adv_mag": 0.4695658387355907, "train/adv_max": 0.43090981821860036, "train/adv_mean": 0.0030155412398300383, "train/adv_min": -0.38313050584126546, "train/adv_std": 0.05188842362133406, "train/cont_avg": 0.9946446572580645, "train/cont_loss_mean": 9.600767769504893e-05, "train/cont_loss_std": 0.00277237599318865, "train/cont_neg_acc": 0.9977598568444611, "train/cont_neg_loss": 0.008029138261356115, "train/cont_pos_acc": 0.9999894220982829, "train/cont_pos_loss": 3.8282757400806946e-05, "train/cont_pred": 0.9946438144612056, "train/cont_rate": 0.9946446572580645, "train/dyn_loss_mean": 6.777963992088072, "train/dyn_loss_std": 8.874483941703714, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.112280345732166, "train/extr_critic_critic_opt_grad_steps": 116925.0, "train/extr_critic_critic_opt_loss": 16061.789997059812, "train/extr_critic_mag": 8.73349868097613, "train/extr_critic_max": 8.73349868097613, "train/extr_critic_mean": 2.452187056182533, "train/extr_critic_min": -0.5254996906044662, "train/extr_critic_std": 2.096835809369241, "train/extr_return_normed_mag": 1.4959425759571854, "train/extr_return_normed_max": 1.4959425759571854, "train/extr_return_normed_mean": 0.39946622121077713, "train/extr_return_normed_min": -0.10893196782838273, "train/extr_return_normed_std": 0.3283322484743211, "train/extr_return_rate": 0.7507123360710759, "train/extr_return_raw_mag": 9.575397050508888, "train/extr_return_raw_max": 9.575397050508888, "train/extr_return_raw_mean": 2.471729682337853, "train/extr_return_raw_min": -0.8222167004821122, "train/extr_return_raw_std": 2.1273395598575635, "train/extr_reward_mag": 1.0318807055873256, "train/extr_reward_max": 1.0318807055873256, "train/extr_reward_mean": 0.03964511401230289, "train/extr_reward_min": -0.6329088909651643, "train/extr_reward_std": 0.19150073898415412, "train/image_loss_mean": 3.585487069622163, "train/image_loss_std": 8.543248166320144, "train/model_loss_mean": 7.733385765424338, "train/model_loss_std": 12.649561174454227, "train/model_opt_grad_norm": 37.480203341412285, "train/model_opt_grad_steps": 116822.62365591398, "train/model_opt_loss": 12943.593692246304, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1673.3870967741937, "train/policy_entropy_mag": 2.512607885945228, "train/policy_entropy_max": 2.512607885945228, "train/policy_entropy_mean": 0.4939318855283081, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.5928489674804032, "train/policy_logprob_mag": 7.438384091982278, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.49384153273797804, "train/policy_logprob_min": -7.438384091982278, "train/policy_logprob_std": 1.0691103710923144, "train/policy_randomness_mag": 0.8868403213639413, "train/policy_randomness_max": 0.8868403213639413, "train/policy_randomness_mean": 0.1743362783103861, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.20924967030684152, "train/post_ent_mag": 60.277662995041055, "train/post_ent_max": 60.277662995041055, "train/post_ent_mean": 44.44877169209142, "train/post_ent_min": 19.27642902763941, "train/post_ent_std": 7.019082046324207, "train/prior_ent_mag": 74.8209463140016, "train/prior_ent_max": 74.8209463140016, "train/prior_ent_mean": 51.24268609733992, "train/prior_ent_min": 30.67452359968616, "train/prior_ent_std": 6.760287131032636, "train/rep_loss_mean": 6.777963992088072, "train/rep_loss_std": 8.874483941703714, "train/reward_avg": 0.02690500637856863, "train/reward_loss_mean": 0.08102433557712263, "train/reward_loss_std": 0.19436863481357533, "train/reward_max_data": 1.0157616811413919, "train/reward_max_pred": 1.0150484602938417, "train/reward_neg_acc": 0.9984309622036514, "train/reward_neg_loss": 0.054128542802827334, "train/reward_pos_acc": 0.9029634136666533, "train/reward_pos_loss": 0.7502632185976993, "train/reward_pred": 0.02664358322057993, "train/reward_rate": 0.03863722278225806, "train_stats/sum_log_reward": 8.289189403121537, "train_stats/max_log_achievement_collect_coal": 0.2972972972972973, "train_stats/max_log_achievement_collect_drink": 3.7567567567567566, "train_stats/max_log_achievement_collect_sapling": 1.5135135135135136, "train_stats/max_log_achievement_collect_stone": 3.6486486486486487, "train_stats/max_log_achievement_collect_wood": 10.486486486486486, "train_stats/max_log_achievement_defeat_skeleton": 0.02702702702702703, "train_stats/max_log_achievement_defeat_zombie": 0.5405405405405406, "train_stats/max_log_achievement_eat_cow": 0.08108108108108109, "train_stats/max_log_achievement_make_stone_pickaxe": 0.02702702702702703, "train_stats/max_log_achievement_make_wood_pickaxe": 1.4324324324324325, "train_stats/max_log_achievement_make_wood_sword": 1.4054054054054055, "train_stats/max_log_achievement_place_furnace": 0.2972972972972973, "train_stats/max_log_achievement_place_plant": 1.4054054054054055, "train_stats/max_log_achievement_place_stone": 1.9189189189189189, "train_stats/max_log_achievement_place_table": 3.2162162162162162, "train_stats/max_log_achievement_wake_up": 1.1891891891891893, "train_stats/mean_log_entropy": 0.48351775512502, "eval_stats/sum_log_reward": 8.350000083446503, "eval_stats/max_log_achievement_collect_coal": 0.125, "eval_stats/max_log_achievement_collect_drink": 2.625, "eval_stats/max_log_achievement_collect_sapling": 1.0, "eval_stats/max_log_achievement_collect_stone": 4.25, "eval_stats/max_log_achievement_collect_wood": 9.25, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.625, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 2.25, "eval_stats/max_log_achievement_make_wood_sword": 1.0, "eval_stats/max_log_achievement_place_furnace": 0.25, "eval_stats/max_log_achievement_place_plant": 1.0, "eval_stats/max_log_achievement_place_stone": 2.0, "eval_stats/max_log_achievement_place_table": 2.625, "eval_stats/max_log_achievement_wake_up": 1.375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 2.014791334659094e-06, "report/cont_loss_std": 4.397205702844076e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0001257781550521031, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 1.529444716652506e-06, "report/cont_pred": 0.9960927963256836, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 7.170082092285156, "report/dyn_loss_std": 8.8048677444458, "report/image_loss_mean": 3.4871208667755127, "report/image_loss_std": 8.078375816345215, "report/model_loss_mean": 7.869756698608398, "report/model_loss_std": 12.021336555480957, "report/post_ent_mag": 63.113319396972656, "report/post_ent_max": 63.113319396972656, "report/post_ent_mean": 44.029747009277344, "report/post_ent_min": 19.933670043945312, "report/post_ent_std": 6.723000526428223, "report/prior_ent_mag": 75.06982421875, "report/prior_ent_max": 75.06982421875, "report/prior_ent_mean": 51.613792419433594, "report/prior_ent_min": 34.9635009765625, "report/prior_ent_std": 6.685729503631592, "report/rep_loss_mean": 7.170082092285156, "report/rep_loss_std": 8.8048677444458, "report/reward_avg": 0.028802795335650444, "report/reward_loss_mean": 0.08058463037014008, "report/reward_loss_std": 0.1762687712907791, "report/reward_max_data": 1.1012500524520874, "report/reward_max_pred": 1.107999563217163, "report/reward_neg_acc": 0.997967541217804, "report/reward_neg_loss": 0.0539402961730957, "report/reward_pos_acc": 0.875, "report/reward_pos_loss": 0.7360354661941528, "report/reward_pred": 0.028054816648364067, "report/reward_rate": 0.0390625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 9.526135545456782e-05, "eval/cont_loss_std": 0.002971705747768283, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.024331143125891685, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 2.1868476096642553e-07, "eval/cont_pred": 0.9961843490600586, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 18.123321533203125, "eval/dyn_loss_std": 12.025725364685059, "eval/image_loss_mean": 13.49317455291748, "eval/image_loss_std": 15.88979721069336, "eval/model_loss_mean": 24.511762619018555, "eval/model_loss_std": 20.605737686157227, "eval/post_ent_mag": 58.820892333984375, "eval/post_ent_max": 58.820892333984375, "eval/post_ent_mean": 41.48011779785156, "eval/post_ent_min": 21.729156494140625, "eval/post_ent_std": 6.979923725128174, "eval/prior_ent_mag": 75.06982421875, "eval/prior_ent_max": 75.06982421875, "eval/prior_ent_mean": 53.72336196899414, "eval/prior_ent_min": 34.0759162902832, "eval/prior_ent_std": 5.77548360824585, "eval/rep_loss_mean": 18.123321533203125, "eval/rep_loss_std": 12.025725364685059, "eval/reward_avg": 0.02675781212747097, "eval/reward_loss_mean": 0.1445009410381317, "eval/reward_loss_std": 0.859522819519043, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0018198490142822, "eval/reward_neg_acc": 0.9919435977935791, "eval/reward_neg_loss": 0.07117625325918198, "eval/reward_pos_acc": 0.7096773982048035, "eval/reward_pos_loss": 2.4932565689086914, "eval/reward_pred": 0.0217241533100605, "eval/reward_rate": 0.0302734375, "replay/size": 472465.0, "replay/inserts": 7452.0, "replay/samples": 29808.0, "replay/insert_wait_avg": 1.6420871675238453e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.447221236912332e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 96360.0, "eval_replay/inserts": 2232.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2080088311198792e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.301568984985352e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0409300327301, "timer/env.step_count": 932.0, "timer/env.step_total": 81.3904812335968, "timer/env.step_frac": 0.08138715005488124, "timer/env.step_avg": 0.08732884252531846, "timer/env.step_min": 0.0236513614654541, "timer/env.step_max": 3.230853319168091, "timer/replay._sample_count": 29808.0, "timer/replay._sample_total": 14.379034996032715, "timer/replay._sample_frac": 0.014378446485747445, "timer/replay._sample_avg": 0.0004823884526312639, "timer/replay._sample_min": 0.0003521442413330078, "timer/replay._sample_max": 0.009601593017578125, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1211.0, "timer/agent.policy_total": 19.498743772506714, "timer/agent.policy_frac": 0.019497945720950184, "timer/agent.policy_avg": 0.01610135736788333, "timer/agent.policy_min": 0.0094757080078125, "timer/agent.policy_max": 0.0731658935546875, "timer/dataset_train_count": 1863.0, "timer/dataset_train_total": 0.30040693283081055, "timer/dataset_train_frac": 0.00030039463766845883, "timer/dataset_train_avg": 0.00016124902460054244, "timer/dataset_train_min": 9.632110595703125e-05, "timer/dataset_train_max": 0.0010123252868652344, "timer/agent.train_count": 1863.0, "timer/agent.train_total": 835.5336003303528, "timer/agent.train_frac": 0.8354994033124292, "timer/agent.train_avg": 0.44848824494382866, "timer/agent.train_min": 0.43515515327453613, "timer/agent.train_max": 1.0044844150543213, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48354029655456543, "timer/agent.report_frac": 0.00048352050604442737, "timer/agent.report_avg": 0.24177014827728271, "timer/agent.report_min": 0.23451876640319824, "timer/agent.report_max": 0.2490215301513672, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.2411346435546875e-05, "timer/dataset_eval_frac": 2.2410429175947207e-08, "timer/dataset_eval_avg": 2.2411346435546875e-05, "timer/dataset_eval_min": 2.2411346435546875e-05, "timer/dataset_eval_max": 2.2411346435546875e-05, "fps": 7.451590178032139}
{"step": 473032, "time": 63399.305094242096, "episode/length": 153.0, "episode/score": 10.28126717221403, "episode/reward_rate": 0.9545454545454546, "episode/intrinsic_return": 0.18126683288664935}
{"step": 473184, "time": 63419.191655397415, "episode/length": 220.0, "episode/score": 11.339871862940981, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.2398715489339338}
{"step": 473232, "time": 63426.5026884079, "episode/length": 239.0, "episode/score": 11.36252079811129, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.2625204303640203}
{"step": 473296, "time": 63435.72881817818, "episode/length": 163.0, "episode/score": 7.2730883090898715, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.17308817238335905}
{"step": 473320, "time": 63440.10762214661, "episode/length": 131.0, "episode/score": 7.235307678627123, "episode/reward_rate": 0.9924242424242424, "episode/intrinsic_return": 0.13530743775800147}
{"step": 474016, "time": 63525.91956090927, "episode/length": 191.0, "episode/score": 8.319215501625877, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.2192152457391785}
{"step": 474200, "time": 63550.46128940582, "episode/length": 182.0, "episode/score": 9.312491480322024, "episode/reward_rate": 0.9672131147540983, "episode/intrinsic_return": 0.2124912075842076}
{"step": 474432, "time": 63579.986189603806, "episode/length": 174.0, "episode/score": 8.283287384304458, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.18328710663354286}
{"step": 474528, "time": 63593.0536134243, "episode/length": 161.0, "episode/score": 9.286357759775456, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.18635754606020782}
{"step": 474544, "time": 63596.41463589668, "episode/length": 169.0, "episode/score": 9.303055833559483, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.20305555150844157}
{"step": 474904, "time": 63641.59747815132, "episode/length": 288.0, "episode/score": 8.438063543327644, "episode/reward_rate": 0.9965397923875432, "episode/intrinsic_return": 0.3380633048159325}
{"step": 475008, "time": 63655.650408029556, "episode/length": 213.0, "episode/score": 9.356679307478771, "episode/reward_rate": 0.9719626168224299, "episode/intrinsic_return": 0.25667898701067315}
{"step": 475480, "time": 63715.77517962456, "episode/length": 159.0, "episode/score": 8.276172357120231, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.17617207960938686}
{"step": 475552, "time": 63726.1662209034, "episode/length": 278.0, "episode/score": 11.421049987162405, "episode/reward_rate": 0.982078853046595, "episode/intrinsic_return": 0.3210496345636784}
{"step": 475808, "time": 63759.538945674896, "episode/length": 223.0, "episode/score": 8.346795065765036, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.2467948111880105}
{"step": 476096, "time": 63796.01400876045, "episode/length": 207.0, "episode/score": 9.33500791951883, "episode/reward_rate": 0.9711538461538461, "episode/intrinsic_return": 0.2350076020193228}
{"step": 476136, "time": 63802.40216231346, "episode/length": 198.0, "episode/score": 9.327568686712766, "episode/reward_rate": 0.9798994974874372, "episode/intrinsic_return": 0.22756839173962362}
{"step": 476344, "time": 63829.064517736435, "episode/length": 107.0, "episode/score": 9.21967138306718, "episode/reward_rate": 0.9537037037037037, "episode/intrinsic_return": 0.11967105910662212}
{"step": 476776, "time": 63882.927159786224, "episode/length": 120.0, "episode/score": 8.247708594310097, "episode/reward_rate": 0.9504132231404959, "episode/intrinsic_return": 0.14770833030343056}
{"step": 476976, "time": 63908.738523721695, "episode/length": 177.0, "episode/score": 8.305796174176066, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.20579592076319386}
{"step": 477032, "time": 63917.03087186813, "episode/length": 85.0, "episode/score": 2.190459731991723, "episode/reward_rate": 0.9883720930232558, "episode/intrinsic_return": 0.09045961199080921}
{"step": 477032, "time": 63917.040949344635, "episode/length": 312.0, "episode/score": 8.460644070823037, "episode/reward_rate": 0.9968051118210862, "episode/intrinsic_return": 0.36064379028539406}
{"step": 477056, "time": 63923.09392595291, "episode/length": 34.0, "episode/score": 1.13891670294106, "episode/reward_rate": 0.8571428571428571, "episode/intrinsic_return": 0.03891666606068611}
{"step": 477272, "time": 63950.88054680824, "episode/length": 282.0, "episode/score": 9.418039256110205, "episode/reward_rate": 0.9964664310954063, "episode/intrinsic_return": 0.3180389174813172}
{"step": 477384, "time": 63966.12258386612, "episode/length": 309.0, "episode/score": 8.445166613390029, "episode/reward_rate": 0.9806451612903225, "episode/intrinsic_return": 0.3451663238884066}
{"step": 477424, "time": 63972.56621050835, "episode/length": 165.0, "episode/score": 8.286298364895629, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.18629812754807062}
{"step": 477648, "time": 64001.087599515915, "episode/length": 188.0, "episode/score": 9.327416924461431, "episode/reward_rate": 0.9682539682539683, "episode/intrinsic_return": 0.22741666196816368}
{"step": 477952, "time": 64039.21584677696, "episode/length": 121.0, "episode/score": 8.23730095909923, "episode/reward_rate": 0.9590163934426229, "episode/intrinsic_return": 0.1373007115071232}
{"step": 478216, "time": 64072.72499704361, "episode/length": 98.0, "episode/score": 8.217208295185628, "episode/reward_rate": 0.98989898989899, "episode/intrinsic_return": 0.11720799788417935}
{"step": 478304, "time": 64084.87481713295, "episode/length": 158.0, "episode/score": 8.271002491106628, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.1710022537590703}
{"step": 478456, "time": 64105.210587501526, "episode/length": 174.0, "episode/score": 10.293627674260279, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.19362735693539435}
{"step": 478600, "time": 64124.51022911072, "episode/length": 151.0, "episode/score": 6.267835718421338, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.1678355081985501}
{"step": 478784, "time": 64148.117498636246, "episode/length": 218.0, "episode/score": 9.358236395630229, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.2582360983287799}
{"step": 479104, "time": 64188.15091466904, "episode/length": 228.0, "episode/score": 9.332618894995903, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.23261858162913995}
{"step": 479160, "time": 64196.39221572876, "episode/length": 188.0, "episode/score": 10.304011184194678, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.20401084335389896}
{"step": 479312, "time": 64216.58171534538, "episode/length": 169.0, "episode/score": 6.282463131314216, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.18246290851857339}
{"step": 479480, "time": 64238.35145878792, "episode/length": 39.0, "episode/score": 3.1481250943616033, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.04812499904073775}
{"step": 479696, "time": 64265.815417051315, "episode/length": 154.0, "episode/score": 10.257620125876201, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.15761982112417172}
{"step": 479880, "time": 64289.72117948532, "episode/length": 159.0, "episode/score": 8.262289189410694, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.16228894944379135}
{"step": 480040, "time": 64310.400700092316, "episode/length": 216.0, "episode/score": 10.352544785669124, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.25254449337353435}
{"step": 480064, "time": 64329.898473501205, "eval_episode/length": 59.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9833333333333333}
{"step": 480064, "time": 64335.81364750862, "eval_episode/length": 163.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.975609756097561}
{"step": 480064, "time": 64337.784058094025, "eval_episode/length": 174.0, "eval_episode/score": 12.100000001490116, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 480064, "time": 64339.417707681656, "eval_episode/length": 177.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9719101123595506}
{"step": 480064, "time": 64342.26392745972, "eval_episode/length": 187.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.973404255319149}
{"step": 480064, "time": 64345.5487742424, "eval_episode/length": 204.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9707317073170731}
{"step": 480064, "time": 64347.29838728905, "eval_episode/length": 208.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9952153110047847}
{"step": 480064, "time": 64348.99494552612, "eval_episode/length": 209.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9761904761904762}
{"step": 480088, "time": 64351.88776731491, "episode/length": 162.0, "episode/score": 10.29101433010419, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.19101403780859982}
{"step": 480160, "time": 64361.98656487465, "episode/length": 131.0, "episode/score": 10.25183305029168, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.15183272353715438}
{"step": 480389, "time": 64391.855666399, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.484276024070946, "train/action_min": 0.0, "train/action_std": 3.640419337556169, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0411763496898316, "train/actor_opt_grad_steps": 118780.0, "train/actor_opt_loss": -8.377603700112653, "train/adv_mag": 0.48491797640516954, "train/adv_max": 0.44288178231265096, "train/adv_mean": 0.0026597550556707083, "train/adv_min": -0.3915357348081228, "train/adv_std": 0.05121831376407598, "train/cont_avg": 0.9949007601351352, "train/cont_loss_mean": 9.788719771996064e-05, "train/cont_loss_std": 0.002907271413290358, "train/cont_neg_acc": 0.9990990993138906, "train/cont_neg_loss": 0.004585333826132744, "train/cont_pos_acc": 0.9999893662091848, "train/cont_pos_loss": 7.21642833584641e-05, "train/cont_pred": 0.994883832416019, "train/cont_rate": 0.9949007601351352, "train/dyn_loss_mean": 6.7881638990866175, "train/dyn_loss_std": 8.814527003829543, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1103236485171963, "train/extr_critic_critic_opt_grad_steps": 118780.0, "train/extr_critic_critic_opt_loss": 16082.614152238175, "train/extr_critic_mag": 9.142141481347986, "train/extr_critic_max": 9.142141481347986, "train/extr_critic_mean": 2.6309203147888183, "train/extr_critic_min": -0.5124276934443294, "train/extr_critic_std": 2.210680471239863, "train/extr_return_normed_mag": 1.4883167447270573, "train/extr_return_normed_max": 1.4883167447270573, "train/extr_return_normed_mean": 0.4092295419525456, "train/extr_return_normed_min": -0.10062107947227117, "train/extr_return_normed_std": 0.33209053060492955, "train/extr_return_rate": 0.7521417904544521, "train/extr_return_raw_mag": 9.930268091768832, "train/extr_return_raw_max": 9.930268091768832, "train/extr_return_raw_mean": 2.6488618702501863, "train/extr_return_raw_min": -0.791668027639389, "train/extr_return_raw_std": 2.2409660448899142, "train/extr_reward_mag": 1.0376947274079193, "train/extr_reward_max": 1.0376947274079193, "train/extr_reward_mean": 0.041587375436682956, "train/extr_reward_min": -0.6369915826900585, "train/extr_reward_std": 0.19593114901233363, "train/image_loss_mean": 3.561415121362016, "train/image_loss_std": 8.636195922542262, "train/model_loss_mean": 7.715448052174336, "train/model_loss_std": 12.719709223669929, "train/model_opt_grad_norm": 38.686710378286, "train/model_opt_grad_steps": 118676.21621621621, "train/model_opt_loss": 12489.117625633446, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1621.6216216216217, "train/policy_entropy_mag": 2.4940196978079308, "train/policy_entropy_max": 2.4940196978079308, "train/policy_entropy_mean": 0.47420542401236454, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.5800273165509507, "train/policy_logprob_mag": 7.438384099908777, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.4743640053916622, "train/policy_logprob_min": -7.438384099908777, "train/policy_logprob_std": 1.059382057834316, "train/policy_randomness_mag": 0.8802795062194, "train/policy_randomness_max": 0.8802795062194, "train/policy_randomness_mean": 0.16737370462836446, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.20472419076674694, "train/post_ent_mag": 60.32895883096231, "train/post_ent_max": 60.32895883096231, "train/post_ent_mean": 44.44894213289828, "train/post_ent_min": 19.449427042780695, "train/post_ent_std": 6.998569027153222, "train/prior_ent_mag": 74.95919680208773, "train/prior_ent_max": 74.95919680208773, "train/prior_ent_mean": 51.243793549408785, "train/prior_ent_min": 30.83343841965134, "train/prior_ent_std": 6.727485638695794, "train/rep_loss_mean": 6.7881638990866175, "train/rep_loss_std": 8.814527003829543, "train/reward_avg": 0.026986330012614662, "train/reward_loss_mean": 0.08103666138407346, "train/reward_loss_std": 0.19050830276431263, "train/reward_max_data": 1.0136802119177741, "train/reward_max_pred": 1.0124532725359943, "train/reward_neg_acc": 0.9985284206029531, "train/reward_neg_loss": 0.05420291196252849, "train/reward_pos_acc": 0.8893090608957651, "train/reward_pos_loss": 0.7478670229782929, "train/reward_pred": 0.026661271521368542, "train/reward_rate": 0.038751055743243244, "train_stats/sum_log_reward": 8.338095503193992, "train_stats/max_log_achievement_collect_coal": 0.2857142857142857, "train_stats/max_log_achievement_collect_drink": 2.4523809523809526, "train_stats/max_log_achievement_collect_sapling": 1.3571428571428572, "train_stats/max_log_achievement_collect_stone": 5.833333333333333, "train_stats/max_log_achievement_collect_wood": 9.404761904761905, "train_stats/max_log_achievement_defeat_skeleton": 0.023809523809523808, "train_stats/max_log_achievement_defeat_zombie": 0.5, "train_stats/max_log_achievement_eat_cow": 0.19047619047619047, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.3095238095238095, "train_stats/max_log_achievement_make_wood_sword": 1.2380952380952381, "train_stats/max_log_achievement_place_furnace": 0.30952380952380953, "train_stats/max_log_achievement_place_plant": 1.2857142857142858, "train_stats/max_log_achievement_place_stone": 3.5, "train_stats/max_log_achievement_place_table": 3.0, "train_stats/max_log_achievement_wake_up": 1.1904761904761905, "train_stats/mean_log_entropy": 0.4533725728591283, "eval_stats/sum_log_reward": 8.600000321865082, "eval_stats/max_log_achievement_collect_coal": 0.375, "eval_stats/max_log_achievement_collect_drink": 4.5, "eval_stats/max_log_achievement_collect_sapling": 1.375, "eval_stats/max_log_achievement_collect_stone": 3.875, "eval_stats/max_log_achievement_collect_wood": 9.375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.875, "eval_stats/max_log_achievement_eat_cow": 0.25, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.125, "eval_stats/max_log_achievement_make_wood_sword": 1.375, "eval_stats/max_log_achievement_place_furnace": 0.125, "eval_stats/max_log_achievement_place_plant": 1.25, "eval_stats/max_log_achievement_place_stone": 3.0, "eval_stats/max_log_achievement_place_table": 2.875, "eval_stats/max_log_achievement_wake_up": 1.25, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.00010073761222884059, "report/cont_loss_std": 0.00289047509431839, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.013690872117877007, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 7.196868864411954e-06, "report/cont_pred": 0.9932464957237244, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 6.245172500610352, "report/dyn_loss_std": 8.819915771484375, "report/image_loss_mean": 2.7727890014648438, "report/image_loss_std": 9.725303649902344, "report/model_loss_mean": 6.59494686126709, "report/model_loss_std": 13.77767276763916, "report/post_ent_mag": 58.51952362060547, "report/post_ent_max": 58.51952362060547, "report/post_ent_mean": 44.6051025390625, "report/post_ent_min": 17.20876693725586, "report/post_ent_std": 6.4197096824646, "report/prior_ent_mag": 75.08518981933594, "report/prior_ent_max": 75.08518981933594, "report/prior_ent_mean": 51.12356185913086, "report/prior_ent_min": 31.346996307373047, "report/prior_ent_std": 6.449113368988037, "report/rep_loss_mean": 6.245172500610352, "report/rep_loss_std": 8.819915771484375, "report/reward_avg": 0.014443503692746162, "report/reward_loss_mean": 0.07495436072349548, "report/reward_loss_std": 0.15379519760608673, "report/reward_max_data": 1.1012500524520874, "report/reward_max_pred": 1.0050177574157715, "report/reward_neg_acc": 0.9979899525642395, "report/reward_neg_loss": 0.057274602353572845, "report/reward_pos_acc": 0.8965517282485962, "report/reward_pos_loss": 0.6815527677536011, "report/reward_pred": 0.01525413990020752, "report/reward_rate": 0.0283203125, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 1.015576344798319e-05, "eval/cont_loss_std": 0.0002115606766892597, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00334562873467803, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 3.6284200177760795e-06, "eval/cont_pred": 0.9980498552322388, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 18.995771408081055, "eval/dyn_loss_std": 12.337467193603516, "eval/image_loss_mean": 17.700782775878906, "eval/image_loss_std": 19.684106826782227, "eval/model_loss_mean": 29.205623626708984, "eval/model_loss_std": 24.8134765625, "eval/post_ent_mag": 60.94248580932617, "eval/post_ent_max": 60.94248580932617, "eval/post_ent_mean": 41.802085876464844, "eval/post_ent_min": 20.548477172851562, "eval/post_ent_std": 7.300657272338867, "eval/prior_ent_mag": 75.08518981933594, "eval/prior_ent_max": 75.08518981933594, "eval/prior_ent_mean": 54.09920120239258, "eval/prior_ent_min": 37.331661224365234, "eval/prior_ent_std": 5.9146857261657715, "eval/rep_loss_mean": 18.995771408081055, "eval/rep_loss_std": 12.337467193603516, "eval/reward_avg": 0.02626953274011612, "eval/reward_loss_mean": 0.10736820846796036, "eval/reward_loss_std": 0.7417504787445068, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0021166801452637, "eval/reward_neg_acc": 0.9969818592071533, "eval/reward_neg_loss": 0.03838425129652023, "eval/reward_pos_acc": 0.7333333492279053, "eval/reward_pos_loss": 2.3930370807647705, "eval/reward_pred": 0.020431015640497208, "eval/reward_rate": 0.029296875, "replay/size": 479885.0, "replay/inserts": 7420.0, "replay/samples": 29680.0, "replay/insert_wait_avg": 1.6718540551527492e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.335789441419741e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 98040.0, "eval_replay/inserts": 1680.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2325389044625418e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.344650268554688e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0372343063354, "timer/env.step_count": 927.0, "timer/env.step_total": 89.83288812637329, "timer/env.step_frac": 0.0898295433856369, "timer/env.step_avg": 0.09690710693244152, "timer/env.step_min": 0.023398637771606445, "timer/env.step_max": 3.167104959487915, "timer/replay._sample_count": 29680.0, "timer/replay._sample_total": 14.172709703445435, "timer/replay._sample_frac": 0.014172182012078954, "timer/replay._sample_avg": 0.00047751717329667904, "timer/replay._sample_min": 0.0003726482391357422, "timer/replay._sample_max": 0.027736186981201172, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1137.0, "timer/agent.policy_total": 18.89638662338257, "timer/agent.policy_frac": 0.018895683055731253, "timer/agent.policy_avg": 0.016619513301128028, "timer/agent.policy_min": 0.009488105773925781, "timer/agent.policy_max": 0.1257326602935791, "timer/dataset_train_count": 1855.0, "timer/dataset_train_total": 0.29820799827575684, "timer/dataset_train_frac": 0.0002981968951212156, "timer/dataset_train_avg": 0.00016075902872008453, "timer/dataset_train_min": 9.584426879882812e-05, "timer/dataset_train_max": 0.0008547306060791016, "timer/agent.train_count": 1855.0, "timer/agent.train_total": 828.7175986766815, "timer/agent.train_frac": 0.8286867431006328, "timer/agent.train_avg": 0.44674803163163423, "timer/agent.train_min": 0.4357259273529053, "timer/agent.train_max": 0.9855997562408447, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.46457386016845703, "timer/agent.report_frac": 0.0004645565627270903, "timer/agent.report_avg": 0.23228693008422852, "timer/agent.report_min": 0.2209184169769287, "timer/agent.report_max": 0.24365544319152832, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.314018249511719e-05, "timer/dataset_eval_frac": 3.313894858935378e-08, "timer/dataset_eval_avg": 3.314018249511719e-05, "timer/dataset_eval_min": 3.314018249511719e-05, "timer/dataset_eval_max": 3.314018249511719e-05, "fps": 7.419619613732152}
{"step": 480896, "time": 64452.942140340805, "episode/length": 126.0, "episode/score": 7.248468201967626, "episode/reward_rate": 0.9606299212598425, "episode/intrinsic_return": 0.14846799325823667}
{"step": 481000, "time": 64467.14525794983, "episode/length": 347.0, "episode/score": 9.473715390687175, "episode/reward_rate": 0.9913793103448276, "episode/intrinsic_return": 0.3737151276118311}
{"step": 481048, "time": 64474.61299037933, "episode/length": 216.0, "episode/score": 8.34882648938219, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.24882618963602}
{"step": 481280, "time": 64504.067140340805, "episode/length": 224.0, "episode/score": 9.349132539857237, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.24913219552399823}
{"step": 481728, "time": 64559.713480472565, "episode/length": 204.0, "episode/score": 7.328970997306897, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.22897075844593928}
{"step": 482304, "time": 64631.15085220337, "episode/length": 267.0, "episode/score": 11.404349888129218, "episode/reward_rate": 0.996268656716418, "episode/intrinsic_return": 0.30434951154893497}
{"step": 482360, "time": 64639.88775730133, "episode/length": 332.0, "episode/score": 10.480344245075685, "episode/reward_rate": 0.9819819819819819, "episode/intrinsic_return": 0.38034395685463096}
{"step": 482504, "time": 64658.77414274216, "episode/length": 187.0, "episode/score": 8.316795246717447, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.2167950116981956}
{"step": 482584, "time": 64670.00111436844, "episode/length": 317.0, "episode/score": 8.456740097321017, "episode/reward_rate": 0.9779874213836478, "episode/intrinsic_return": 0.35673985752873705}
{"step": 482616, "time": 64675.323962688446, "episode/length": 195.0, "episode/score": 8.322091018128049, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.22209084568203252}
{"step": 482760, "time": 64694.230149030685, "episode/length": 232.0, "episode/score": 9.367386883855943, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.26738650308470824}
{"step": 482896, "time": 64712.25633406639, "episode/length": 201.0, "episode/score": 10.32177609831524, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.22177582033873477}
{"step": 482984, "time": 64724.34727573395, "episode/length": 45.0, "episode/score": 4.15520851186011, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.05520833225455135}
{"step": 483552, "time": 64795.806211948395, "episode/length": 148.0, "episode/score": 9.246651522607863, "episode/reward_rate": 0.9731543624161074, "episode/intrinsic_return": 0.14665137257179595}
{"step": 483888, "time": 64838.234776735306, "episode/length": 269.0, "episode/score": 8.40210557791761, "episode/reward_rate": 0.9962962962962963, "episode/intrinsic_return": 0.30210525360780593}
{"step": 483984, "time": 64851.24921607971, "episode/length": 209.0, "episode/score": 10.33775966034409, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.23775935338017007}
{"step": 483992, "time": 64853.67153644562, "episode/length": 136.0, "episode/score": 7.247606828611424, "episode/reward_rate": 0.9927007299270073, "episode/intrinsic_return": 0.14760656541966455}
{"step": 484144, "time": 64873.39324808121, "episode/length": 194.0, "episode/score": 9.315364637624953, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.21536437047507206}
{"step": 484200, "time": 64881.76350402832, "episode/length": 179.0, "episode/score": 10.284533819324679, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.18453343308192416}
{"step": 484256, "time": 64890.202045202255, "episode/length": 218.0, "episode/score": 10.34106232085287, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.24106211755679396}
{"step": 484440, "time": 64913.79498434067, "episode/length": 181.0, "episode/score": 10.30974148796031, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.20974116947127186}
{"step": 485224, "time": 65009.79716300964, "episode/length": 153.0, "episode/score": 9.261291146158328, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.16129088017260074}
{"step": 485592, "time": 65055.70678901672, "episode/length": 166.0, "episode/score": 8.27599224745154, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.17599207890543767}
{"step": 485696, "time": 65069.83121609688, "episode/length": 193.0, "episode/score": 10.312018884239478, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.21201855946401338}
{"step": 486176, "time": 65129.34997701645, "episode/length": 246.0, "episode/score": 10.37287333495351, "episode/reward_rate": 0.9757085020242915, "episode/intrinsic_return": 0.27287310267001885}
{"step": 486408, "time": 65158.83918213844, "episode/length": 245.0, "episode/score": 11.3727464904523, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.272746177609406}
{"step": 486936, "time": 65224.01096868515, "episode/length": 422.0, "episode/score": 11.54204849796588, "episode/reward_rate": 0.9905437352245863, "episode/intrinsic_return": 0.44204820366212516}
{"step": 487104, "time": 65245.84357762337, "episode/length": 175.0, "episode/score": 4.28854104430593, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.18854097477105825}
{"step": 487128, "time": 65250.35611104965, "episode/length": 191.0, "episode/score": 7.306583496800158, "episode/reward_rate": 0.9635416666666666, "episode/intrinsic_return": 0.20658332982566208}
{"step": 487368, "time": 65280.85519361496, "episode/length": 434.0, "episode/score": 11.55623046146684, "episode/reward_rate": 0.8114942528735632, "episode/intrinsic_return": 0.45623028698355483}
{"step": 487376, "time": 65283.47432923317, "episode/length": 423.0, "episode/score": 8.556848186381103, "episode/reward_rate": 0.9858490566037735, "episode/intrinsic_return": 0.45684793715918204}
{"step": 487568, "time": 65308.0425195694, "episode/length": 173.0, "episode/score": 8.295365249592578, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.1953649468923686}
{"step": 487960, "time": 65357.63672208786, "episode/length": 193.0, "episode/score": 11.317287429458702, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.2172871573611701}
{"step": 488225, "time": 65392.04318833351, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.558364556760204, "train/action_min": 0.0, "train/action_std": 3.663685936100629, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04112524473659542, "train/actor_opt_grad_steps": 120685.0, "train/actor_opt_loss": -8.90372543702168, "train/adv_mag": 0.48326714260845766, "train/adv_max": 0.423432677832185, "train/adv_mean": 0.0021571770106378124, "train/adv_min": -0.4018244941015633, "train/adv_std": 0.05083842358875031, "train/cont_avg": 0.9946438536352041, "train/cont_loss_mean": 0.00018203902544633896, "train/cont_loss_std": 0.005523733045623716, "train/cont_neg_acc": 0.9937851049961188, "train/cont_neg_loss": 0.027808030077148244, "train/cont_pos_acc": 0.9999849574298275, "train/cont_pos_loss": 4.189660396134624e-05, "train/cont_pred": 0.9946538392378359, "train/cont_rate": 0.9946438536352041, "train/dyn_loss_mean": 7.005144209277873, "train/dyn_loss_std": 9.003510939831637, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.101385395745842, "train/extr_critic_critic_opt_grad_steps": 120685.0, "train/extr_critic_critic_opt_loss": 16089.582270408164, "train/extr_critic_mag": 9.242136629260315, "train/extr_critic_max": 9.242136629260315, "train/extr_critic_mean": 2.535805356745817, "train/extr_critic_min": -0.5153057903659587, "train/extr_critic_std": 2.2249905558264986, "train/extr_return_normed_mag": 1.4993055846009935, "train/extr_return_normed_max": 1.4993055846009935, "train/extr_return_normed_mean": 0.3935944514767248, "train/extr_return_normed_min": -0.101071139265384, "train/extr_return_normed_std": 0.33363344185814564, "train/extr_return_rate": 0.7428634933062962, "train/extr_return_raw_mag": 10.009601471375445, "train/extr_return_raw_max": 10.009601471375445, "train/extr_return_raw_mean": 2.550363869083171, "train/extr_return_raw_min": -0.7865928980160732, "train/extr_return_raw_std": 2.250893306367251, "train/extr_reward_mag": 1.0292899170700385, "train/extr_reward_max": 1.0292899170700385, "train/extr_reward_mean": 0.04104926375368116, "train/extr_reward_min": -0.639327849660601, "train/extr_reward_std": 0.19444388326029388, "train/image_loss_mean": 3.840085025344576, "train/image_loss_std": 8.87320437236708, "train/model_loss_mean": 8.126257263884252, "train/model_loss_std": 13.037121052644691, "train/model_opt_grad_norm": 39.075788175142726, "train/model_opt_grad_steps": 120579.92857142857, "train/model_opt_loss": 12397.548564054528, "train/model_opt_model_opt_grad_overflow": 0.00510204081632653, "train/model_opt_model_opt_grad_scale": 1517.857142857143, "train/policy_entropy_mag": 2.5258775608880177, "train/policy_entropy_max": 2.5258775608880177, "train/policy_entropy_mean": 0.49545998399963187, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6097327362822027, "train/policy_logprob_mag": 7.438384087718263, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.4953406144465719, "train/policy_logprob_min": -7.438384087718263, "train/policy_logprob_std": 1.074521812249203, "train/policy_randomness_mag": 0.8915239332281814, "train/policy_randomness_max": 0.8915239332281814, "train/policy_randomness_mean": 0.17487563223254923, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.21520890021810726, "train/post_ent_mag": 60.360845293317524, "train/post_ent_max": 60.360845293317524, "train/post_ent_mean": 44.4489756992885, "train/post_ent_min": 19.51529347166723, "train/post_ent_std": 7.071660375108524, "train/prior_ent_mag": 74.98664007381517, "train/prior_ent_max": 74.98664007381517, "train/prior_ent_mean": 51.45669150839046, "train/prior_ent_min": 31.13253559385027, "train/prior_ent_std": 6.785767037041333, "train/rep_loss_mean": 7.005144209277873, "train/rep_loss_std": 9.003510939831637, "train/reward_avg": 0.026969201896073564, "train/reward_loss_mean": 0.08290367345420682, "train/reward_loss_std": 0.19883273363265455, "train/reward_max_data": 1.011449861283205, "train/reward_max_pred": 1.012279390072336, "train/reward_neg_acc": 0.9982834430981655, "train/reward_neg_loss": 0.05529042460708594, "train/reward_pos_acc": 0.8952429276339862, "train/reward_pos_loss": 0.7590972668662364, "train/reward_pred": 0.026629927016946733, "train/reward_rate": 0.03919702646683673, "train_stats/sum_log_reward": 8.857576008998986, "train_stats/max_log_achievement_collect_coal": 0.30303030303030304, "train_stats/max_log_achievement_collect_drink": 3.696969696969697, "train_stats/max_log_achievement_collect_sapling": 1.5454545454545454, "train_stats/max_log_achievement_collect_stone": 5.757575757575758, "train_stats/max_log_achievement_collect_wood": 9.787878787878787, "train_stats/max_log_achievement_defeat_skeleton": 0.06060606060606061, "train_stats/max_log_achievement_defeat_zombie": 0.6666666666666666, "train_stats/max_log_achievement_eat_cow": 0.030303030303030304, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.2424242424242424, "train_stats/max_log_achievement_make_wood_sword": 1.7878787878787878, "train_stats/max_log_achievement_place_furnace": 0.30303030303030304, "train_stats/max_log_achievement_place_plant": 1.4242424242424243, "train_stats/max_log_achievement_place_stone": 3.787878787878788, "train_stats/max_log_achievement_place_table": 2.9696969696969697, "train_stats/max_log_achievement_wake_up": 1.5757575757575757, "train_stats/mean_log_entropy": 0.5627063277995947, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 2.362339000683278e-05, "report/cont_loss_std": 8.668812370160595e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 1.6129315554280765e-05, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 2.3652777599636465e-05, "report/cont_pred": 0.9960702657699585, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 9.309757232666016, "report/dyn_loss_std": 9.788067817687988, "report/image_loss_mean": 4.388768196105957, "report/image_loss_std": 9.407508850097656, "report/model_loss_mean": 10.068472862243652, "report/model_loss_std": 14.015532493591309, "report/post_ent_mag": 57.054718017578125, "report/post_ent_max": 57.054718017578125, "report/post_ent_mean": 42.38273620605469, "report/post_ent_min": 16.425798416137695, "report/post_ent_std": 6.698752403259277, "report/prior_ent_mag": 74.76848602294922, "report/prior_ent_max": 74.76848602294922, "report/prior_ent_mean": 52.04924774169922, "report/prior_ent_min": 33.556732177734375, "report/prior_ent_std": 6.445696830749512, "report/rep_loss_mean": 9.309757232666016, "report/rep_loss_std": 9.788067817687988, "report/reward_avg": 0.042570311576128006, "report/reward_loss_mean": 0.09382651746273041, "report/reward_loss_std": 0.22040119767189026, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.003019094467163, "report/reward_neg_acc": 0.9979381561279297, "report/reward_neg_loss": 0.054916493594646454, "report/reward_pos_acc": 0.8703703880310059, "report/reward_pos_loss": 0.7927660346031189, "report/reward_pred": 0.040873050689697266, "report/reward_rate": 0.052734375, "eval/cont_avg": 0.9931640625, "eval/cont_loss_mean": 0.0014502647100016475, "eval/cont_loss_std": 0.04226066172122955, "eval/cont_neg_acc": 0.8571429252624512, "eval/cont_neg_loss": 0.19328288733959198, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.0001298829010920599, "eval/cont_pred": 0.993762731552124, "eval/cont_rate": 0.9931640625, "eval/dyn_loss_mean": 18.138187408447266, "eval/dyn_loss_std": 12.658285140991211, "eval/image_loss_mean": 17.241680145263672, "eval/image_loss_std": 21.507356643676758, "eval/model_loss_mean": 28.270748138427734, "eval/model_loss_std": 26.167272567749023, "eval/post_ent_mag": 58.727821350097656, "eval/post_ent_max": 58.727821350097656, "eval/post_ent_mean": 42.15060043334961, "eval/post_ent_min": 19.59838104248047, "eval/post_ent_std": 7.137031555175781, "eval/prior_ent_mag": 74.76848602294922, "eval/prior_ent_max": 74.76848602294922, "eval/prior_ent_mean": 53.6690673828125, "eval/prior_ent_min": 32.44611358642578, "eval/prior_ent_std": 6.607685089111328, "eval/rep_loss_mean": 18.138187408447266, "eval/rep_loss_std": 12.658285140991211, "eval/reward_avg": 0.03212890774011612, "eval/reward_loss_mean": 0.14470383524894714, "eval/reward_loss_std": 0.882763147354126, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0024054050445557, "eval/reward_neg_acc": 0.992893397808075, "eval/reward_neg_loss": 0.06494230777025223, "eval/reward_pos_acc": 0.7948718070983887, "eval/reward_pos_loss": 2.159193754196167, "eval/reward_pred": 0.02487390860915184, "eval/reward_rate": 0.0380859375, "replay/size": 487721.0, "replay/inserts": 7836.0, "replay/samples": 31344.0, "replay/insert_wait_avg": 1.6119724758551278e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.32720293762612e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 98040.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 8.493661880493164e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1743543148041, "timer/env.step_count": 980.0, "timer/env.step_total": 77.38720059394836, "timer/env.step_frac": 0.07737371015373067, "timer/env.step_avg": 0.07896653121831465, "timer/env.step_min": 0.023497581481933594, "timer/env.step_max": 2.229565143585205, "timer/replay._sample_count": 31344.0, "timer/replay._sample_total": 14.968171119689941, "timer/replay._sample_frac": 0.014965561809415003, "timer/replay._sample_avg": 0.0004775450204086888, "timer/replay._sample_min": 0.00034999847412109375, "timer/replay._sample_max": 0.01684427261352539, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 980.0, "timer/agent.policy_total": 15.778922080993652, "timer/agent.policy_frac": 0.015776171437432446, "timer/agent.policy_avg": 0.016100940898973116, "timer/agent.policy_min": 0.014586925506591797, "timer/agent.policy_max": 0.10047578811645508, "timer/dataset_train_count": 1959.0, "timer/dataset_train_total": 0.31643080711364746, "timer/dataset_train_frac": 0.0003163756456547286, "timer/dataset_train_avg": 0.0001615267009258027, "timer/dataset_train_min": 9.918212890625e-05, "timer/dataset_train_max": 0.0012421607971191406, "timer/agent.train_count": 1959.0, "timer/agent.train_total": 872.8865215778351, "timer/agent.train_frac": 0.8727343565770881, "timer/agent.train_avg": 0.4455776016221721, "timer/agent.train_min": 0.43563055992126465, "timer/agent.train_max": 0.979001522064209, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47566890716552734, "timer/agent.report_frac": 0.0004755859866966864, "timer/agent.report_avg": 0.23783445358276367, "timer/agent.report_min": 0.23084592819213867, "timer/agent.report_max": 0.24482297897338867, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.86102294921875e-05, "timer/dataset_eval_frac": 2.8605242044810973e-08, "timer/dataset_eval_avg": 2.86102294921875e-05, "timer/dataset_eval_min": 2.86102294921875e-05, "timer/dataset_eval_max": 2.86102294921875e-05, "fps": 7.834511754256555}
{"step": 488472, "time": 65421.7379925251, "episode/length": 167.0, "episode/score": 8.291129619541152, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.19112937544150554}
{"step": 488688, "time": 65449.480108737946, "episode/length": 432.0, "episode/score": 10.546638003309909, "episode/reward_rate": 0.8452655889145496, "episode/intrinsic_return": 0.4466376512932584}
{"step": 488752, "time": 65459.434274196625, "episode/length": 172.0, "episode/score": 11.305031665338902, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.20503124603419565}
{"step": 489072, "time": 65499.99231982231, "episode/length": 245.0, "episode/score": 9.375079878840552, "episode/reward_rate": 0.9715447154471545, "episode/intrinsic_return": 0.2750795817719336}
{"step": 489400, "time": 65541.23921561241, "episode/length": 228.0, "episode/score": 10.37884086153963, "episode/reward_rate": 0.9694323144104804, "episode/intrinsic_return": 0.2788405739006521}
{"step": 489976, "time": 65612.77136707306, "episode/length": 251.0, "episode/score": 11.385254388607336, "episode/reward_rate": 0.996031746031746, "episode/intrinsic_return": 0.285254064937817}
{"step": 490048, "time": 65640.89222049713, "eval_episode/length": 103.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9615384615384616}
{"step": 490048, "time": 65643.69899225235, "eval_episode/length": 135.0, "eval_episode/score": 6.0999999940395355, "eval_episode/reward_rate": 0.9926470588235294}
{"step": 490048, "time": 65646.77890372276, "eval_episode/length": 172.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9653179190751445}
{"step": 490048, "time": 65648.34275150299, "eval_episode/length": 39.0, "eval_episode/score": 4.0999999940395355, "eval_episode/reward_rate": 0.975}
{"step": 490048, "time": 65652.00521969795, "eval_episode/length": 226.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9691629955947136}
{"step": 490048, "time": 65654.2154045105, "eval_episode/length": 243.0, "eval_episode/score": 12.100000038743019, "eval_episode/reward_rate": 0.9795081967213115}
{"step": 490048, "time": 65656.11816954613, "eval_episode/length": 252.0, "eval_episode/score": 8.099999971687794, "eval_episode/reward_rate": 0.9960474308300395}
{"step": 490048, "time": 65660.07422471046, "eval_episode/length": 309.0, "eval_episode/score": 10.099999979138374, "eval_episode/reward_rate": 0.9967741935483871}
{"step": 490144, "time": 65671.70426917076, "episode/length": 400.0, "episode/score": 11.494772866871699, "episode/reward_rate": 0.9950124688279302, "episode/intrinsic_return": 0.39477268389009623}
{"step": 490192, "time": 65678.99996232986, "episode/length": 351.0, "episode/score": 8.501907343069433, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.4019071220200203}
{"step": 490584, "time": 65727.88545250893, "episode/length": 263.0, "episode/score": 7.3933270980996895, "episode/reward_rate": 0.9848484848484849, "episode/intrinsic_return": 0.29332681206142297}
{"step": 490640, "time": 65736.98087143898, "episode/length": 235.0, "episode/score": 10.353511949489985, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.2535116074850521}
{"step": 490728, "time": 65749.62452840805, "episode/length": 254.0, "episode/score": 10.391728885433167, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.2917286190690902}
{"step": 490832, "time": 65763.66530609131, "episode/length": 219.0, "episode/score": 9.34888555220823, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.24888524664129363}
{"step": 491072, "time": 65794.25018000603, "episode/length": 42.0, "episode/score": 1.1525000926339999, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.05249999894294888}
{"step": 491400, "time": 65835.31340193748, "episode/length": 177.0, "episode/score": 9.307712590045412, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.20771238756424282}
{"step": 491456, "time": 65843.60047507286, "episode/length": 157.0, "episode/score": 6.283463216423115, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.18346303868020186}
{"step": 491688, "time": 65874.57008314133, "episode/length": 285.0, "episode/score": 11.432090542547485, "episode/reward_rate": 0.9825174825174825, "episode/intrinsic_return": 0.3320902216137256}
{"step": 491816, "time": 65891.52714633942, "episode/length": 153.0, "episode/score": 10.268376819036348, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.1683765103261976}
{"step": 491880, "time": 65900.76481509209, "episode/length": 154.0, "episode/score": 8.264978928880737, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.16497858850561897}
{"step": 491984, "time": 65914.81574320793, "episode/length": 229.0, "episode/score": 7.37243185123225, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.27243158804049017}
{"step": 492496, "time": 65978.0581009388, "episode/length": 207.0, "episode/score": 11.325537758588325, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.225537404010538}
{"step": 492496, "time": 65978.06616163254, "episode/length": 177.0, "episode/score": 9.309779496041301, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.20977920223231195}
{"step": 492984, "time": 66040.06624937057, "episode/length": 197.0, "episode/score": 10.301876824823921, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.2018765985940263}
{"step": 493064, "time": 66051.147077322, "episode/length": 200.0, "episode/score": 10.33578918800049, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.23578884238668252}
{"step": 493232, "time": 66073.01735186577, "episode/length": 168.0, "episode/score": 11.285654475768752, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.18565412235511758}
{"step": 493512, "time": 66108.64724802971, "episode/length": 227.0, "episode/score": 6.358602492500722, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.25860238082350406}
{"step": 493520, "time": 66111.13741350174, "episode/length": 212.0, "episode/score": 8.351450764546826, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.25145046130819537}
{"step": 493544, "time": 66115.56345248222, "episode/length": 130.0, "episode/score": 5.24976177845565, "episode/reward_rate": 0.9618320610687023, "episode/intrinsic_return": 0.149761627022599}
{"step": 494376, "time": 66217.58570098877, "episode/length": 234.0, "episode/score": 11.382458682404831, "episode/reward_rate": 0.9829787234042553, "episode/intrinsic_return": 0.28245832782704383}
{"step": 494528, "time": 66237.2618944645, "episode/length": 182.0, "episode/score": 10.313476843104581, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.2134765502269147}
{"step": 494888, "time": 66282.45966982841, "episode/length": 237.0, "episode/score": 9.385132373136003, "episode/reward_rate": 0.9789915966386554, "episode/intrinsic_return": 0.2851321094785817}
{"step": 495000, "time": 66297.46603488922, "episode/length": 220.0, "episode/score": 8.34776842793508, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.24776813377684448}
{"step": 495240, "time": 66327.95558667183, "episode/length": 406.0, "episode/score": 10.547207631661877, "episode/reward_rate": 0.7592137592137592, "episode/intrinsic_return": 0.4472073103788716}
{"step": 495432, "time": 66352.75690770149, "episode/length": 235.0, "episode/score": 7.3659917209879495, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.2659914459218271}
{"step": 495737, "time": 66392.26403141022, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.5694580078125, "train/action_min": 0.0, "train/action_std": 3.6735255680185683, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04137931023030839, "train/actor_opt_grad_steps": 122605.0, "train/actor_opt_loss": -9.103294162654338, "train/adv_mag": 0.4816060866764251, "train/adv_max": 0.43236312349425987, "train/adv_mean": 0.002213522564938722, "train/adv_min": -0.3958373933713487, "train/adv_std": 0.050979667719691354, "train/cont_avg": 0.9948211020611702, "train/cont_loss_mean": 4.892420743041665e-05, "train/cont_loss_std": 0.0012815030917302445, "train/cont_neg_acc": 0.9991087346153463, "train/cont_neg_loss": 0.0034869645923534596, "train/cont_pos_acc": 0.9999895441405316, "train/cont_pos_loss": 2.984306032954735e-05, "train/cont_pred": 0.994809866902676, "train/cont_rate": 0.9948211020611702, "train/dyn_loss_mean": 6.911470413208008, "train/dyn_loss_std": 8.961845220403468, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0725579680280481, "train/extr_critic_critic_opt_grad_steps": 122605.0, "train/extr_critic_critic_opt_loss": 15797.234707446809, "train/extr_critic_mag": 8.949972066473453, "train/extr_critic_max": 8.949972066473453, "train/extr_critic_mean": 2.5364958377594644, "train/extr_critic_min": -0.4954501555321064, "train/extr_critic_std": 2.1176812984841935, "train/extr_return_normed_mag": 1.4973932986563825, "train/extr_return_normed_max": 1.4973932986563825, "train/extr_return_normed_mean": 0.40457169473805327, "train/extr_return_normed_min": -0.10622674621086806, "train/extr_return_normed_std": 0.3283355164718121, "train/extr_return_rate": 0.7673939349169426, "train/extr_return_raw_mag": 9.685763567051989, "train/extr_return_raw_max": 9.685763567051989, "train/extr_return_raw_mean": 2.550916457429845, "train/extr_return_raw_min": -0.7841557964999625, "train/extr_return_raw_std": 2.1436307607813085, "train/extr_reward_mag": 1.0315287392190162, "train/extr_reward_max": 1.0315287392190162, "train/extr_reward_mean": 0.04169010016274579, "train/extr_reward_min": -0.6303885090858379, "train/extr_reward_std": 0.19572660984828116, "train/image_loss_mean": 3.873060253706384, "train/image_loss_std": 9.22810423374176, "train/model_loss_mean": 8.101776485747479, "train/model_loss_std": 13.366219614414458, "train/model_opt_grad_norm": 37.17889684311887, "train/model_opt_grad_steps": 122498.1755319149, "train/model_opt_loss": 11139.623716963099, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1382.9787234042553, "train/policy_entropy_mag": 2.4844928840373424, "train/policy_entropy_max": 2.4844928840373424, "train/policy_entropy_mean": 0.477002648121499, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.5874007512280282, "train/policy_logprob_mag": 7.438384091600459, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.47653571674798395, "train/policy_logprob_min": -7.438384091600459, "train/policy_logprob_std": 1.0611642034763986, "train/policy_randomness_mag": 0.8769169573454146, "train/policy_randomness_max": 0.8769169573454146, "train/policy_randomness_mean": 0.16836100313416186, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.20732668985394723, "train/post_ent_mag": 60.24804125440882, "train/post_ent_max": 60.24804125440882, "train/post_ent_mean": 44.510108582516935, "train/post_ent_min": 19.61975108308995, "train/post_ent_std": 7.008866746374902, "train/prior_ent_mag": 74.99400662361307, "train/prior_ent_max": 74.99400662361307, "train/prior_ent_mean": 51.42081313437604, "train/prior_ent_min": 30.966541290283203, "train/prior_ent_std": 6.778394808160498, "train/rep_loss_mean": 6.911470413208008, "train/rep_loss_std": 8.961845220403468, "train/reward_avg": 0.027360007776185236, "train/reward_loss_mean": 0.0817850747125897, "train/reward_loss_std": 0.1939353476813499, "train/reward_max_data": 1.0118883290189378, "train/reward_max_pred": 1.0119520755524332, "train/reward_neg_acc": 0.9984098809196594, "train/reward_neg_loss": 0.05469931626414999, "train/reward_pos_acc": 0.8995803090486121, "train/reward_pos_loss": 0.749955008004574, "train/reward_pred": 0.027126693865284324, "train/reward_rate": 0.03897419381648936, "train_stats/sum_log_reward": 8.918182026256215, "train_stats/max_log_achievement_collect_coal": 0.21212121212121213, "train_stats/max_log_achievement_collect_drink": 4.636363636363637, "train_stats/max_log_achievement_collect_sapling": 2.090909090909091, "train_stats/max_log_achievement_collect_stone": 8.545454545454545, "train_stats/max_log_achievement_collect_wood": 10.636363636363637, "train_stats/max_log_achievement_defeat_skeleton": 0.030303030303030304, "train_stats/max_log_achievement_defeat_zombie": 0.45454545454545453, "train_stats/max_log_achievement_eat_cow": 0.12121212121212122, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.3636363636363635, "train_stats/max_log_achievement_make_wood_sword": 1.7272727272727273, "train_stats/max_log_achievement_place_furnace": 0.45454545454545453, "train_stats/max_log_achievement_place_plant": 2.0, "train_stats/max_log_achievement_place_stone": 5.818181818181818, "train_stats/max_log_achievement_place_table": 3.242424242424242, "train_stats/max_log_achievement_wake_up": 1.393939393939394, "train_stats/mean_log_entropy": 0.5127506229010496, "eval_stats/sum_log_reward": 8.600000202655792, "eval_stats/max_log_achievement_collect_coal": 0.25, "eval_stats/max_log_achievement_collect_drink": 4.625, "eval_stats/max_log_achievement_collect_sapling": 1.875, "eval_stats/max_log_achievement_collect_stone": 6.5, "eval_stats/max_log_achievement_collect_wood": 8.75, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.625, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.875, "eval_stats/max_log_achievement_make_wood_sword": 1.875, "eval_stats/max_log_achievement_place_furnace": 0.125, "eval_stats/max_log_achievement_place_plant": 1.75, "eval_stats/max_log_achievement_place_stone": 5.125, "eval_stats/max_log_achievement_place_table": 2.75, "eval_stats/max_log_achievement_wake_up": 1.5, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 2.77280923910439e-05, "report/cont_loss_std": 0.0005035542417317629, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0007612701156176627, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.4128770746756345e-05, "report/cont_pred": 0.9950970411300659, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 7.162164688110352, "report/dyn_loss_std": 8.859696388244629, "report/image_loss_mean": 3.0505871772766113, "report/image_loss_std": 6.021280765533447, "report/model_loss_mean": 7.419468879699707, "report/model_loss_std": 10.170621871948242, "report/post_ent_mag": 57.58794021606445, "report/post_ent_max": 57.58794021606445, "report/post_ent_mean": 43.59895324707031, "report/post_ent_min": 20.334606170654297, "report/post_ent_std": 6.582390308380127, "report/prior_ent_mag": 74.71000671386719, "report/prior_ent_max": 74.71000671386719, "report/prior_ent_mean": 50.693931579589844, "report/prior_ent_min": 32.956016540527344, "report/prior_ent_std": 6.557175636291504, "report/rep_loss_mean": 7.162164688110352, "report/rep_loss_std": 8.859696388244629, "report/reward_avg": 0.017064956948161125, "report/reward_loss_mean": 0.07155492156744003, "report/reward_loss_std": 0.17122812569141388, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.001828908920288, "report/reward_neg_acc": 0.9969940185546875, "report/reward_neg_loss": 0.052796464413404465, "report/reward_pos_acc": 0.8076923489570618, "report/reward_pos_loss": 0.7915911078453064, "report/reward_pred": 0.017092322930693626, "report/reward_rate": 0.025390625, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 7.326579634536756e-06, "eval/cont_loss_std": 0.00013764890900347382, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.001496180659160018, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.95188624477305e-06, "eval/cont_pred": 0.9970718026161194, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 19.85204315185547, "eval/dyn_loss_std": 12.389492988586426, "eval/image_loss_mean": 20.284385681152344, "eval/image_loss_std": 23.39630889892578, "eval/model_loss_mean": 32.302452087402344, "eval/model_loss_std": 28.52104949951172, "eval/post_ent_mag": 56.9107666015625, "eval/post_ent_max": 56.9107666015625, "eval/post_ent_mean": 41.25196838378906, "eval/post_ent_min": 22.154314041137695, "eval/post_ent_std": 6.304067611694336, "eval/prior_ent_mag": 74.71000671386719, "eval/prior_ent_max": 74.71000671386719, "eval/prior_ent_mean": 53.6563720703125, "eval/prior_ent_min": 37.4327392578125, "eval/prior_ent_std": 5.323920249938965, "eval/rep_loss_mean": 19.85204315185547, "eval/rep_loss_std": 12.389492988586426, "eval/reward_avg": 0.03427734225988388, "eval/reward_loss_mean": 0.10683369636535645, "eval/reward_loss_std": 0.6558329463005066, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.001788854598999, "eval/reward_neg_acc": 0.9888437986373901, "eval/reward_neg_loss": 0.060278575867414474, "eval/reward_pos_acc": 0.8947368264198303, "eval/reward_pos_loss": 1.3148164749145508, "eval/reward_pred": 0.03702893853187561, "eval/reward_rate": 0.037109375, "replay/size": 495233.0, "replay/inserts": 7512.0, "replay/samples": 30048.0, "replay/insert_wait_avg": 1.615165267635585e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.5683299217996e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 2480.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1755574134088332e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.791685104370117e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2026407718658, "timer/env.step_count": 939.0, "timer/env.step_total": 78.7314031124115, "timer/env.step_frac": 0.07871545215242956, "timer/env.step_avg": 0.0838460097043786, "timer/env.step_min": 0.02332139015197754, "timer/env.step_max": 3.2145090103149414, "timer/replay._sample_count": 30048.0, "timer/replay._sample_total": 14.398176431655884, "timer/replay._sample_frac": 0.014395259365186912, "timer/replay._sample_avg": 0.00047917253832720593, "timer/replay._sample_min": 0.0003924369812011719, "timer/replay._sample_max": 0.017401695251464844, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1249.0, "timer/agent.policy_total": 20.38462781906128, "timer/agent.policy_frac": 0.020380497899235968, "timer/agent.policy_avg": 0.016320758862338896, "timer/agent.policy_min": 0.00970602035522461, "timer/agent.policy_max": 0.07372784614562988, "timer/dataset_train_count": 1878.0, "timer/dataset_train_total": 0.3082277774810791, "timer/dataset_train_frac": 0.00030816533062061986, "timer/dataset_train_avg": 0.0001641255471145256, "timer/dataset_train_min": 9.894371032714844e-05, "timer/dataset_train_max": 0.0008656978607177734, "timer/agent.train_count": 1878.0, "timer/agent.train_total": 836.7308142185211, "timer/agent.train_frac": 0.8365612927924365, "timer/agent.train_avg": 0.4455435645466034, "timer/agent.train_min": 0.4308030605316162, "timer/agent.train_max": 1.0546188354492188, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4763615131378174, "timer/agent.report_frac": 0.00047626500243011223, "timer/agent.report_avg": 0.2381807565689087, "timer/agent.report_min": 0.23023676872253418, "timer/agent.report_max": 0.2461247444152832, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0040740966796875e-05, "timer/dataset_eval_frac": 3.003465472118145e-08, "timer/dataset_eval_avg": 3.0040740966796875e-05, "timer/dataset_eval_min": 3.0040740966796875e-05, "timer/dataset_eval_max": 3.0040740966796875e-05, "fps": 7.510360410544033}
{"step": 495824, "time": 66402.73029494286, "episode/length": 288.0, "episode/score": 11.4344381502342, "episode/reward_rate": 0.9688581314878892, "episode/intrinsic_return": 0.33443784094197326}
{"step": 496136, "time": 66442.1741797924, "episode/length": 219.0, "episode/score": 11.348564693649678, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.24856433627792285}
{"step": 496296, "time": 66463.08700489998, "episode/length": 346.0, "episode/score": 14.48386184660194, "episode/reward_rate": 0.9913544668587896, "episode/intrinsic_return": 0.38386138177884277}
{"step": 496664, "time": 66509.52007365227, "episode/length": 153.0, "episode/score": 10.27716975489966, "episode/reward_rate": 0.961038961038961, "episode/intrinsic_return": 0.17716946376822307}
{"step": 496712, "time": 66516.81713247299, "episode/length": 183.0, "episode/score": 10.306597613829581, "episode/reward_rate": 0.967391304347826, "episode/intrinsic_return": 0.20659733058528218}
{"step": 497048, "time": 66559.2472808361, "episode/length": 255.0, "episode/score": 11.391277956279737, "episode/reward_rate": 0.99609375, "episode/intrinsic_return": 0.2912775159038574}
{"step": 497088, "time": 66565.9856557846, "episode/length": 274.0, "episode/score": 8.419235546924028, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.31923529933192185}
{"step": 497184, "time": 66579.14905142784, "episode/length": 169.0, "episode/score": 7.291256470509325, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.19125626063578238}
{"step": 497688, "time": 66641.44889903069, "episode/length": 193.0, "episode/score": 11.326087708162959, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.22608738722919952}
{"step": 497752, "time": 66650.64654183388, "episode/length": 181.0, "episode/score": 11.315191725938348, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.21519140151212923}
{"step": 498112, "time": 66695.88624382019, "episode/length": 180.0, "episode/score": 10.316450638711103, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.21645031626394484}
{"step": 498224, "time": 66710.93093824387, "episode/length": 188.0, "episode/score": 7.310051229469536, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.2100509894444258}
{"step": 498272, "time": 66718.27905011177, "episode/length": 135.0, "episode/score": 9.250073887684266, "episode/reward_rate": 0.9926470588235294, "episode/intrinsic_return": 0.15007355231500696}
{"step": 498304, "time": 66723.7747797966, "episode/length": 156.0, "episode/score": 6.267699934185657, "episode/reward_rate": 0.9617834394904459, "episode/intrinsic_return": 0.16769972745532868}
{"step": 498416, "time": 66738.81184411049, "episode/length": 485.0, "episode/score": 10.60706610195848, "episode/reward_rate": 0.9958847736625515, "episode/intrinsic_return": 0.5070658178119629}
{"step": 498472, "time": 66747.02367091179, "episode/length": 172.0, "episode/score": 10.295767494397296, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.19576714645518223}
{"step": 498656, "time": 66770.90396118164, "episode/length": 47.0, "episode/score": 3.1554420071825007, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.05544191814806254}
{"step": 499176, "time": 66835.72037220001, "episode/length": 177.0, "episode/score": 10.299043726978198, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.1990433330520318}
{"step": 499280, "time": 66849.98544287682, "episode/length": 198.0, "episode/score": 8.324394565453986, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.22439428072539158}
{"step": 499568, "time": 66886.61560082436, "episode/length": 143.0, "episode/score": 8.260001845572333, "episode/reward_rate": 0.9861111111111112, "episode/intrinsic_return": 0.16000155187975906}
{"step": 499744, "time": 66910.83291769028, "episode/length": 57.0, "episode/score": 3.1708503522968385, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.07085022368119098}
{"step": 500032, "time": 66963.41429281235, "eval_episode/length": 77.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9871794871794872}
{"step": 500032, "time": 66968.9322810173, "eval_episode/length": 168.0, "eval_episode/score": 11.099999964237213, "eval_episode/reward_rate": 0.9763313609467456}
{"step": 500032, "time": 66970.67944455147, "eval_episode/length": 175.0, "eval_episode/score": 13.100000001490116, "eval_episode/reward_rate": 0.9715909090909091}
{"step": 500032, "time": 66973.34096646309, "eval_episode/length": 200.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9751243781094527}
{"step": 500032, "time": 66976.61333036423, "eval_episode/length": 239.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.975}
{"step": 500032, "time": 66978.37501955032, "eval_episode/length": 247.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9758064516129032}
{"step": 500032, "time": 66980.4821407795, "eval_episode/length": 260.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9961685823754789}
{"step": 500032, "time": 66983.0263864994, "eval_episode/length": 205.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9757281553398058}
{"step": 500240, "time": 67008.24127030373, "episode/length": 197.0, "episode/score": 9.316243265335288, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.2162430051703268}
{"step": 500984, "time": 67100.28818202019, "episode/length": 334.0, "episode/score": 10.490271437578485, "episode/reward_rate": 0.991044776119403, "episode/intrinsic_return": 0.39027114295458887}
{"step": 501008, "time": 67104.78664040565, "episode/length": 316.0, "episode/score": 12.45420478451706, "episode/reward_rate": 0.9905362776025236, "episode/intrinsic_return": 0.3542044469359098}
{"step": 501064, "time": 67113.34037280083, "episode/length": 186.0, "episode/score": 8.310953108191825, "episode/reward_rate": 0.9679144385026738, "episode/intrinsic_return": 0.21095284418515803}
{"step": 501096, "time": 67118.76039886475, "episode/length": 168.0, "episode/score": 7.29543870071393, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.19543846185297298}
{"step": 501480, "time": 67166.86147403717, "episode/length": 154.0, "episode/score": 11.274993505629027, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.17499315361237677}
{"step": 501584, "time": 67181.07850980759, "episode/length": 300.0, "episode/score": 11.439189642580459, "episode/reward_rate": 0.9966777408637874, "episode/intrinsic_return": 0.33918944030301645}
{"step": 501672, "time": 67193.76859331131, "episode/length": 444.0, "episode/score": 12.60147771386255, "episode/reward_rate": 0.9842696629213483, "episode/intrinsic_return": 0.501477341123973}
{"step": 502600, "time": 67308.72408127785, "episode/length": 201.0, "episode/score": 11.317907333580479, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.21790700915425987}
{"step": 502640, "time": 67315.09339284897, "episode/length": 551.0, "episode/score": 12.737012306093675, "episode/reward_rate": 0.9963768115942029, "episode/intrinsic_return": 0.6370119549792435}
{"step": 502680, "time": 67321.54594779015, "episode/length": 201.0, "episode/score": 10.324563786919498, "episode/reward_rate": 0.9702970297029703, "episode/intrinsic_return": 0.22456350096854294}
{"step": 502824, "time": 67340.4912993908, "episode/length": 226.0, "episode/score": 10.362035503349944, "episode/reward_rate": 0.9823788546255506, "episode/intrinsic_return": 0.2620351940577166}
{"step": 502960, "time": 67358.63751649857, "episode/length": 184.0, "episode/score": 7.312676439648385, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.21267616062414163}
{"step": 502992, "time": 67364.00425696373, "episode/length": 236.0, "episode/score": 8.381609264873077, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.2816090184451241}
{"step": 503192, "time": 67389.90681695938, "episode/length": 189.0, "episode/score": 6.310916059404008, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.21091588166109432}
{"step": 503193, "time": 67392.50923466682, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.633355909778226, "train/action_min": 0.0, "train/action_std": 3.7426009998526624, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.041599281672989166, "train/actor_opt_grad_steps": 124475.0, "train/actor_opt_loss": -7.896806251257658, "train/adv_mag": 0.4748658513830554, "train/adv_max": 0.4236750003471169, "train/adv_mean": 0.0027093492114242204, "train/adv_min": -0.37950236911094315, "train/adv_std": 0.051458138111297805, "train/cont_avg": 0.9948914230510753, "train/cont_loss_mean": 0.00011453377387497813, "train/cont_loss_std": 0.0034567450053226557, "train/cont_neg_acc": 0.9977385225475476, "train/cont_neg_loss": 0.00790674574496399, "train/cont_pos_acc": 0.9999841281803705, "train/cont_pos_loss": 6.491313600115158e-05, "train/cont_pred": 0.994879400858315, "train/cont_rate": 0.9948914230510753, "train/dyn_loss_mean": 6.880546910788423, "train/dyn_loss_std": 8.93084785502444, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0591323420565615, "train/extr_critic_critic_opt_grad_steps": 124475.0, "train/extr_critic_critic_opt_loss": 15812.083616851478, "train/extr_critic_mag": 8.955061610027027, "train/extr_critic_max": 8.955061610027027, "train/extr_critic_mean": 2.5903887005262476, "train/extr_critic_min": -0.4918023020990433, "train/extr_critic_std": 2.1272023268925246, "train/extr_return_normed_mag": 1.4953495494781002, "train/extr_return_normed_max": 1.4953495494781002, "train/extr_return_normed_mean": 0.40905233881165903, "train/extr_return_normed_min": -0.10685455003973618, "train/extr_return_normed_std": 0.3275856242705417, "train/extr_return_rate": 0.7777830673161373, "train/extr_return_raw_mag": 9.764078560695854, "train/extr_return_raw_max": 9.764078560695854, "train/extr_return_raw_mean": 2.6082448190258396, "train/extr_return_raw_min": -0.790377063456402, "train/extr_return_raw_std": 2.158025816563637, "train/extr_reward_mag": 1.0308474084382415, "train/extr_reward_max": 1.0308474084382415, "train/extr_reward_mean": 0.04309455120074813, "train/extr_reward_min": -0.6441700682845167, "train/extr_reward_std": 0.19831515263806107, "train/image_loss_mean": 3.698474572550866, "train/image_loss_std": 8.623711621889504, "train/model_loss_mean": 7.908366457108529, "train/model_loss_std": 12.77760382621519, "train/model_opt_grad_norm": 38.9596319301154, "train/model_opt_grad_steps": 124366.45161290323, "train/model_opt_loss": 10242.107154107864, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1297.0430107526881, "train/policy_entropy_mag": 2.445227506340191, "train/policy_entropy_max": 2.445227506340191, "train/policy_entropy_mean": 0.46049309786288967, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.5609196184142944, "train/policy_logprob_mag": 7.438384115055043, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.46005884245518713, "train/policy_logprob_min": -7.438384115055043, "train/policy_logprob_std": 1.0485835661811214, "train/policy_randomness_mag": 0.8630580056098199, "train/policy_randomness_max": 0.8630580056098199, "train/policy_randomness_mean": 0.1625338546451061, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.19798001134267418, "train/post_ent_mag": 60.098945658694035, "train/post_ent_max": 60.098945658694035, "train/post_ent_mean": 44.55584987517326, "train/post_ent_min": 19.501228624774562, "train/post_ent_std": 6.985223452250163, "train/prior_ent_mag": 74.93912661972867, "train/prior_ent_max": 74.93912661972867, "train/prior_ent_mean": 51.452684853666575, "train/prior_ent_min": 31.207093884868005, "train/prior_ent_std": 6.74111004542279, "train/rep_loss_mean": 6.880546910788423, "train/rep_loss_std": 8.93084785502444, "train/reward_avg": 0.027075543589088865, "train/reward_loss_mean": 0.08144919089572404, "train/reward_loss_std": 0.19495968460555999, "train/reward_max_data": 1.0077016430516397, "train/reward_max_pred": 1.0098153583465084, "train/reward_neg_acc": 0.9982285217572284, "train/reward_neg_loss": 0.054204193995364254, "train/reward_pos_acc": 0.9008428887013467, "train/reward_pos_loss": 0.7556278394755497, "train/reward_pred": 0.026816636994881654, "train/reward_rate": 0.038836735551075266, "train_stats/sum_log_reward": 9.322222471237183, "train_stats/max_log_achievement_collect_coal": 0.6111111111111112, "train_stats/max_log_achievement_collect_drink": 5.166666666666667, "train_stats/max_log_achievement_collect_sapling": 1.4166666666666667, "train_stats/max_log_achievement_collect_stone": 7.666666666666667, "train_stats/max_log_achievement_collect_wood": 10.194444444444445, "train_stats/max_log_achievement_defeat_skeleton": 0.05555555555555555, "train_stats/max_log_achievement_defeat_zombie": 0.6944444444444444, "train_stats/max_log_achievement_eat_cow": 0.19444444444444445, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.3333333333333333, "train_stats/max_log_achievement_make_wood_sword": 1.8055555555555556, "train_stats/max_log_achievement_place_furnace": 0.4444444444444444, "train_stats/max_log_achievement_place_plant": 1.3611111111111112, "train_stats/max_log_achievement_place_stone": 5.0, "train_stats/max_log_achievement_place_table": 2.9166666666666665, "train_stats/max_log_achievement_wake_up": 1.75, "train_stats/mean_log_entropy": 0.4655688583023018, "eval_stats/sum_log_reward": 9.975000321865082, "eval_stats/max_log_achievement_collect_coal": 0.5, "eval_stats/max_log_achievement_collect_drink": 2.875, "eval_stats/max_log_achievement_collect_sapling": 1.25, "eval_stats/max_log_achievement_collect_stone": 12.25, "eval_stats/max_log_achievement_collect_wood": 8.125, "eval_stats/max_log_achievement_defeat_skeleton": 0.125, "eval_stats/max_log_achievement_defeat_zombie": 0.75, "eval_stats/max_log_achievement_eat_cow": 0.375, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.75, "eval_stats/max_log_achievement_make_wood_sword": 0.875, "eval_stats/max_log_achievement_place_furnace": 0.625, "eval_stats/max_log_achievement_place_plant": 1.25, "eval_stats/max_log_achievement_place_stone": 7.75, "eval_stats/max_log_achievement_place_table": 2.25, "eval_stats/max_log_achievement_wake_up": 1.5, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 1.6129324649227783e-06, "report/cont_loss_std": 1.2484914805099834e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 5.3231378842610866e-05, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 1.4105071386438794e-06, "report/cont_pred": 0.9960925579071045, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 6.973042964935303, "report/dyn_loss_std": 9.185855865478516, "report/image_loss_mean": 2.8675789833068848, "report/image_loss_std": 7.350879192352295, "report/model_loss_mean": 7.131429195404053, "report/model_loss_std": 11.692892074584961, "report/post_ent_mag": 58.723052978515625, "report/post_ent_max": 58.723052978515625, "report/post_ent_mean": 44.03638458251953, "report/post_ent_min": 21.110397338867188, "report/post_ent_std": 6.501465797424316, "report/prior_ent_mag": 74.81588745117188, "report/prior_ent_max": 74.81588745117188, "report/prior_ent_mean": 50.95856475830078, "report/prior_ent_min": 33.69923400878906, "report/prior_ent_std": 6.352141857147217, "report/rep_loss_mean": 6.973042964935303, "report/rep_loss_std": 9.185855865478516, "report/reward_avg": 0.028673116117715836, "report/reward_loss_mean": 0.08002251386642456, "report/reward_loss_std": 0.19518215954303741, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.002403736114502, "report/reward_neg_acc": 0.9989786148071289, "report/reward_neg_loss": 0.04626411944627762, "report/reward_pos_acc": 0.9111111164093018, "report/reward_pos_loss": 0.8144551515579224, "report/reward_pred": 0.025865808129310608, "report/reward_rate": 0.0439453125, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.00010101828229380772, "eval/cont_loss_std": 0.0031357782427221537, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.03348956257104874, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.912887794082053e-06, "eval/cont_pred": 0.997160792350769, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 17.44761085510254, "eval/dyn_loss_std": 13.117168426513672, "eval/image_loss_mean": 16.26268768310547, "eval/image_loss_std": 19.13998794555664, "eval/model_loss_mean": 26.834980010986328, "eval/model_loss_std": 24.21200180053711, "eval/post_ent_mag": 59.23540496826172, "eval/post_ent_max": 59.23540496826172, "eval/post_ent_mean": 41.192466735839844, "eval/post_ent_min": 18.80674934387207, "eval/post_ent_std": 7.03299617767334, "eval/prior_ent_mag": 74.81588745117188, "eval/prior_ent_max": 74.81588745117188, "eval/prior_ent_mean": 52.26782989501953, "eval/prior_ent_min": 31.821277618408203, "eval/prior_ent_std": 6.266012668609619, "eval/rep_loss_mean": 17.44761085510254, "eval/rep_loss_std": 13.117168426513672, "eval/reward_avg": 0.03271484375, "eval/reward_loss_mean": 0.10362473130226135, "eval/reward_loss_std": 0.6751593351364136, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0018343925476074, "eval/reward_neg_acc": 0.9919109344482422, "eval/reward_neg_loss": 0.04382690414786339, "eval/reward_pos_acc": 0.8571428656578064, "eval/reward_pos_loss": 1.7933404445648193, "eval/reward_pred": 0.029484432190656662, "eval/reward_rate": 0.0341796875, "replay/size": 502689.0, "replay/inserts": 7456.0, "replay/samples": 29824.0, "replay/insert_wait_avg": 1.6303980810959451e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.497106754728653e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 2272.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1400437690842319e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.344650268554688e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2323698997498, "timer/env.step_count": 932.0, "timer/env.step_total": 81.64789772033691, "timer/env.step_frac": 0.08162892961414579, "timer/env.step_avg": 0.0876050404724645, "timer/env.step_min": 0.02350163459777832, "timer/env.step_max": 2.010575532913208, "timer/replay._sample_count": 29824.0, "timer/replay._sample_total": 14.36904263496399, "timer/replay._sample_frac": 0.014365704477654681, "timer/replay._sample_avg": 0.00048179461624745136, "timer/replay._sample_min": 0.00035119056701660156, "timer/replay._sample_max": 0.028840065002441406, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1216.0, "timer/agent.policy_total": 19.538607120513916, "timer/agent.policy_frac": 0.01953406799109312, "timer/agent.policy_avg": 0.016067933487264735, "timer/agent.policy_min": 0.009331941604614258, "timer/agent.policy_max": 0.05442190170288086, "timer/dataset_train_count": 1864.0, "timer/dataset_train_total": 0.30465269088745117, "timer/dataset_train_frac": 0.0003045819152183463, "timer/dataset_train_avg": 0.00016344028481086437, "timer/dataset_train_min": 9.822845458984375e-05, "timer/dataset_train_max": 0.0009644031524658203, "timer/agent.train_count": 1864.0, "timer/agent.train_total": 835.5287218093872, "timer/agent.train_frac": 0.8353346151885983, "timer/agent.train_avg": 0.44824502242992875, "timer/agent.train_min": 0.4355168342590332, "timer/agent.train_max": 0.9956462383270264, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4759676456451416, "timer/agent.report_frac": 0.000475857070785308, "timer/agent.report_avg": 0.2379838228225708, "timer/agent.report_min": 0.23154854774475098, "timer/agent.report_max": 0.24441909790039062, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7179718017578125e-05, "timer/dataset_eval_frac": 2.717340373647602e-08, "timer/dataset_eval_avg": 2.7179718017578125e-05, "timer/dataset_eval_min": 2.7179718017578125e-05, "timer/dataset_eval_max": 2.7179718017578125e-05, "fps": 7.4541647200350525}
{"step": 503496, "time": 67429.21973824501, "episode/length": 238.0, "episode/score": 9.3745325930322, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.2745323043454846}
{"step": 503920, "time": 67482.32402014732, "episode/length": 164.0, "episode/score": 6.279249538278236, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.17924920555742574}
{"step": 504312, "time": 67531.59585165977, "episode/length": 164.0, "episode/score": 9.289872928793557, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.18987256327272917}
{"step": 504320, "time": 67534.10558438301, "episode/length": 204.0, "episode/score": 9.341191031876406, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.24119075669386802}
{"step": 504608, "time": 67570.54447293282, "episode/length": 205.0, "episode/score": 7.331541206898692, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.23154091821197653}
{"step": 504736, "time": 67587.67802166939, "episode/length": 261.0, "episode/score": 9.41218809397833, "episode/reward_rate": 0.9961832061068703, "episode/intrinsic_return": 0.31218781774805393}
{"step": 504792, "time": 67596.1986694336, "episode/length": 161.0, "episode/score": 8.29028594798001, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.1902857106324518}
{"step": 504808, "time": 67599.64940905571, "episode/length": 247.0, "episode/score": 10.387275397567464, "episode/reward_rate": 0.9758064516129032, "episode/intrinsic_return": 0.28727510643602727}
{"step": 504912, "time": 67613.68352508545, "episode/length": 214.0, "episode/score": 10.345626264621387, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.24562595591123682}
{"step": 505528, "time": 67689.96607804298, "episode/length": 200.0, "episode/score": 9.330666066023696, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.2306657332155737}
{"step": 505664, "time": 67708.02297449112, "episode/length": 131.0, "episode/score": 9.243700489427283, "episode/reward_rate": 0.9924242424242424, "episode/intrinsic_return": 0.1437001809499634}
{"step": 506024, "time": 67753.52267289162, "episode/length": 61.0, "episode/score": 1.16615876351716, "episode/reward_rate": 0.9193548387096774, "episode/intrinsic_return": 0.06615872896509245}
{"step": 506192, "time": 67775.43017530441, "episode/length": 172.0, "episode/score": 8.2869414266479, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.18694115740254347}
{"step": 506296, "time": 67789.62753939629, "episode/length": 194.0, "episode/score": 9.304090308702143, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.20408998939819867}
{"step": 506424, "time": 67806.84415555, "episode/length": 188.0, "episode/score": 10.31290786196223, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.21290755127301964}
{"step": 506648, "time": 67835.61912584305, "episode/length": 231.0, "episode/score": 11.366715673322688, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.26671523643926776}
{"step": 506872, "time": 67864.43413114548, "episode/length": 318.0, "episode/score": 6.469699262917857, "episode/reward_rate": 0.9811912225705329, "episode/intrinsic_return": 0.36969909332401585}
{"step": 507352, "time": 67924.44357395172, "episode/length": 59.0, "episode/score": 6.158504988226923, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.05850475134502631}
{"step": 507784, "time": 67978.75679421425, "episode/length": 141.0, "episode/score": 11.251509582572908, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.15150921775057213}
{"step": 508104, "time": 68020.84593009949, "episode/length": 238.0, "episode/score": 10.371999014962057, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.2719987089294591}
{"step": 508144, "time": 68027.19896268845, "episode/length": 230.0, "episode/score": 10.367702353883942, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.2677019444745383}
{"step": 508256, "time": 68042.48778915405, "episode/length": 323.0, "episode/score": 10.464506265838281, "episode/reward_rate": 0.9907407407407407, "episode/intrinsic_return": 0.3645059457194293}
{"step": 508392, "time": 68060.58762097359, "episode/length": 245.0, "episode/score": 9.385148622219276, "episode/reward_rate": 0.9796747967479674, "episode/intrinsic_return": 0.2851482833575574}
{"step": 508456, "time": 68069.86162424088, "episode/length": 303.0, "episode/score": 11.447724321202259, "episode/reward_rate": 0.9802631578947368, "episode/intrinsic_return": 0.34772391528531443}
{"step": 508688, "time": 68099.57569885254, "episode/length": 546.0, "episode/score": 13.68025448786284, "episode/reward_rate": 0.9981718464351006, "episode/intrinsic_return": 0.5802541143093549}
{"step": 508904, "time": 68127.10199689865, "episode/length": 193.0, "episode/score": 10.31502967576671, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.2150293529703049}
{"step": 509352, "time": 68183.0648355484, "episode/length": 155.0, "episode/score": 6.273250918402482, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.17325073833126226}
{"step": 509552, "time": 68208.95350003242, "episode/length": 161.0, "episode/score": 9.291275874711573, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.19127563742222264}
{"step": 509952, "time": 68259.268627882, "episode/length": 186.0, "episode/score": 10.317112621414708, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.21711232911911793}
{"step": 510016, "time": 68268.46974277496, "episode/length": 278.0, "episode/score": 7.414841836722189, "episode/reward_rate": 0.989247311827957, "episode/intrinsic_return": 0.314841597861232}
{"step": 510016, "time": 68284.0884988308, "eval_episode/length": 59.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9833333333333333}
{"step": 510016, "time": 68289.49007129669, "eval_episode/length": 154.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.967741935483871}
{"step": 510016, "time": 68291.37443709373, "eval_episode/length": 163.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9573170731707317}
{"step": 510016, "time": 68293.1220510006, "eval_episode/length": 168.0, "eval_episode/score": 5.0999999940395355, "eval_episode/reward_rate": 0.9940828402366864}
{"step": 510016, "time": 68295.69886803627, "eval_episode/length": 192.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9740932642487047}
{"step": 510016, "time": 68297.40869450569, "eval_episode/length": 198.0, "eval_episode/score": 11.099999994039536, "eval_episode/reward_rate": 0.9949748743718593}
{"step": 510016, "time": 68299.73264026642, "eval_episode/length": 215.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9953703703703703}
{"step": 510016, "time": 68301.6357011795, "eval_episode/length": 54.0, "eval_episode/score": 5.099999971687794, "eval_episode/reward_rate": 0.9818181818181818}
{"step": 510104, "time": 68313.8705136776, "episode/length": 213.0, "episode/score": 8.348607399966568, "episode/reward_rate": 0.9719626168224299, "episode/intrinsic_return": 0.2486071379389614}
{"step": 510152, "time": 68321.20610141754, "episode/length": 182.0, "episode/score": 11.304709724747227, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.2047093470027903}
{"step": 510480, "time": 68362.6448674202, "episode/length": 196.0, "episode/score": 11.323554343282012, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.2235540268884506}
{"step": 510709, "time": 68392.94270944595, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.469126599900266, "train/action_min": 0.0, "train/action_std": 3.666814631604134, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04227700324213885, "train/actor_opt_grad_steps": 126345.0, "train/actor_opt_loss": -7.843979774677056, "train/adv_mag": 0.48519618967746164, "train/adv_max": 0.4334653617536768, "train/adv_mean": 0.002571500820570865, "train/adv_min": -0.40025840232029875, "train/adv_std": 0.05181803873324014, "train/cont_avg": 0.9947951296542553, "train/cont_loss_mean": 7.859521888828502e-05, "train/cont_loss_std": 0.0023184727260251235, "train/cont_neg_acc": 0.9969858159410193, "train/cont_neg_loss": 0.010530574153502593, "train/cont_pos_acc": 0.9999947712776509, "train/cont_pos_loss": 2.4199528871997184e-05, "train/cont_pred": 0.99479792631687, "train/cont_rate": 0.9947951296542553, "train/dyn_loss_mean": 6.974066939759762, "train/dyn_loss_std": 8.952308573621385, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0576119816049616, "train/extr_critic_critic_opt_grad_steps": 126345.0, "train/extr_critic_critic_opt_loss": 15883.408603100066, "train/extr_critic_mag": 9.025275884790624, "train/extr_critic_max": 9.025275884790624, "train/extr_critic_mean": 2.611886264795953, "train/extr_critic_min": -0.48622312697958436, "train/extr_critic_std": 2.1380396092191654, "train/extr_return_normed_mag": 1.4935861210873786, "train/extr_return_normed_max": 1.4935861210873786, "train/extr_return_normed_mean": 0.4066561076869356, "train/extr_return_normed_min": -0.10950082835761156, "train/extr_return_normed_std": 0.32647824945284964, "train/extr_return_rate": 0.780643325536809, "train/extr_return_raw_mag": 9.846743319896941, "train/extr_return_raw_max": 9.846743319896941, "train/extr_return_raw_mean": 2.6289771865022944, "train/extr_return_raw_min": -0.7985499973626847, "train/extr_return_raw_std": 2.1680503012018, "train/extr_reward_mag": 1.037808802533657, "train/extr_reward_max": 1.037808802533657, "train/extr_reward_mean": 0.04358008480135431, "train/extr_reward_min": -0.6719966746391134, "train/extr_reward_std": 0.19998528134632618, "train/image_loss_mean": 3.742838234343427, "train/image_loss_std": 8.953475607202408, "train/model_loss_mean": 8.010299763780958, "train/model_loss_std": 13.0888290912547, "train/model_opt_grad_norm": 38.11757420478983, "train/model_opt_grad_steps": 126234.85638297872, "train/model_opt_loss": 12812.076332903924, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1595.7446808510638, "train/policy_entropy_mag": 2.4730379023450486, "train/policy_entropy_max": 2.4730379023450486, "train/policy_entropy_mean": 0.45911088474887485, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.5679366652001726, "train/policy_logprob_mag": 7.43838414993692, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.45907195213627305, "train/policy_logprob_min": -7.43838414993692, "train/policy_logprob_std": 1.0475584455627076, "train/policy_randomness_mag": 0.8728738519105506, "train/policy_randomness_max": 0.8728738519105506, "train/policy_randomness_mean": 0.1620459942583074, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.20045672047962534, "train/post_ent_mag": 60.06303456489076, "train/post_ent_max": 60.06303456489076, "train/post_ent_mean": 44.557443172373674, "train/post_ent_min": 19.348765784121575, "train/post_ent_std": 7.006091975151224, "train/prior_ent_mag": 74.96005833402593, "train/prior_ent_max": 74.96005833402593, "train/prior_ent_mean": 51.56261957452652, "train/prior_ent_min": 30.84220503746195, "train/prior_ent_std": 6.730726640275184, "train/rep_loss_mean": 6.974066939759762, "train/rep_loss_std": 8.952308573621385, "train/reward_avg": 0.028439768064925645, "train/reward_loss_mean": 0.0829427978618348, "train/reward_loss_std": 0.19892250453221036, "train/reward_max_data": 1.0140159891006795, "train/reward_max_pred": 1.0120326483503301, "train/reward_neg_acc": 0.9982225815666482, "train/reward_neg_loss": 0.05482256432321477, "train/reward_pos_acc": 0.9039020715875828, "train/reward_pos_loss": 0.7492277406631632, "train/reward_pred": 0.02819369232995396, "train/reward_rate": 0.040418259640957445, "train_stats/sum_log_reward": 8.948485128807299, "train_stats/max_log_achievement_collect_coal": 0.5757575757575758, "train_stats/max_log_achievement_collect_drink": 2.878787878787879, "train_stats/max_log_achievement_collect_sapling": 1.606060606060606, "train_stats/max_log_achievement_collect_stone": 7.787878787878788, "train_stats/max_log_achievement_collect_wood": 10.575757575757576, "train_stats/max_log_achievement_defeat_skeleton": 0.030303030303030304, "train_stats/max_log_achievement_defeat_zombie": 0.8181818181818182, "train_stats/max_log_achievement_eat_cow": 0.18181818181818182, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.2121212121212122, "train_stats/max_log_achievement_make_wood_sword": 1.7575757575757576, "train_stats/max_log_achievement_place_furnace": 0.09090909090909091, "train_stats/max_log_achievement_place_plant": 1.4242424242424243, "train_stats/max_log_achievement_place_stone": 5.7272727272727275, "train_stats/max_log_achievement_place_table": 3.090909090909091, "train_stats/max_log_achievement_wake_up": 1.303030303030303, "train_stats/mean_log_entropy": 0.4641588226412282, "eval_stats/sum_log_reward": 8.475000083446503, "eval_stats/max_log_achievement_collect_coal": 0.5, "eval_stats/max_log_achievement_collect_drink": 1.5, "eval_stats/max_log_achievement_collect_sapling": 1.5, "eval_stats/max_log_achievement_collect_stone": 8.375, "eval_stats/max_log_achievement_collect_wood": 9.625, "eval_stats/max_log_achievement_defeat_skeleton": 0.375, "eval_stats/max_log_achievement_defeat_zombie": 0.125, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.125, "eval_stats/max_log_achievement_make_wood_sword": 1.375, "eval_stats/max_log_achievement_place_furnace": 0.125, "eval_stats/max_log_achievement_place_plant": 1.375, "eval_stats/max_log_achievement_place_stone": 3.875, "eval_stats/max_log_achievement_place_table": 2.875, "eval_stats/max_log_achievement_wake_up": 1.0, "eval_stats/mean_log_entropy": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.25, "train_stats/max_log_achievement_make_stone_sword": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 1.960939152922947e-05, "report/cont_loss_std": 0.00047219087718985975, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 1.2600249874594738e-06, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.9753872038563713e-05, "report/cont_pred": 0.9921680688858032, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 6.506070137023926, "report/dyn_loss_std": 8.655633926391602, "report/image_loss_mean": 3.5885210037231445, "report/image_loss_std": 5.953279495239258, "report/model_loss_mean": 7.575583457946777, "report/model_loss_std": 9.860143661499023, "report/post_ent_mag": 64.41572570800781, "report/post_ent_max": 64.41572570800781, "report/post_ent_mean": 44.82768249511719, "report/post_ent_min": 19.205827713012695, "report/post_ent_std": 7.170177936553955, "report/prior_ent_mag": 74.724609375, "report/prior_ent_max": 74.724609375, "report/prior_ent_mean": 51.68988800048828, "report/prior_ent_min": 31.211135864257812, "report/prior_ent_std": 7.126213073730469, "report/rep_loss_mean": 6.506070137023926, "report/rep_loss_std": 8.655633926391602, "report/reward_avg": 0.02792959474027157, "report/reward_loss_mean": 0.08340094983577728, "report/reward_loss_std": 0.16785533726215363, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.001903772354126, "report/reward_neg_acc": 0.9989827275276184, "report/reward_neg_loss": 0.05865820124745369, "report/reward_pos_acc": 0.9268292188644409, "report/reward_pos_loss": 0.676623523235321, "report/reward_pred": 0.028290903195738792, "report/reward_rate": 0.0400390625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.0023346617817878723, "eval/cont_loss_std": 0.07401702553033829, "eval/cont_neg_acc": 0.75, "eval/cont_neg_loss": 0.5925641655921936, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 2.0036033674841747e-05, "eval/cont_pred": 0.9969597458839417, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 20.190353393554688, "eval/dyn_loss_std": 11.833379745483398, "eval/image_loss_mean": 23.145065307617188, "eval/image_loss_std": 23.77676773071289, "eval/model_loss_mean": 35.45640182495117, "eval/model_loss_std": 27.992145538330078, "eval/post_ent_mag": 59.243621826171875, "eval/post_ent_max": 59.243621826171875, "eval/post_ent_mean": 41.993595123291016, "eval/post_ent_min": 18.595237731933594, "eval/post_ent_std": 7.31100606918335, "eval/prior_ent_mag": 74.724609375, "eval/prior_ent_max": 74.724609375, "eval/prior_ent_mean": 55.68044662475586, "eval/prior_ent_min": 32.91484069824219, "eval/prior_ent_std": 5.943356513977051, "eval/rep_loss_mean": 20.190353393554688, "eval/rep_loss_std": 11.833379745483398, "eval/reward_avg": 0.03310546651482582, "eval/reward_loss_mean": 0.19479292631149292, "eval/reward_loss_std": 1.0770177841186523, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 1.0024077892303467, "eval/reward_neg_acc": 0.9908629655838013, "eval/reward_neg_loss": 0.08190982043743134, "eval/reward_pos_acc": 0.692307710647583, "eval/reward_pos_loss": 3.0458152294158936, "eval/reward_pred": 0.026033300906419754, "eval/reward_rate": 0.0380859375, "replay/size": 510205.0, "replay/inserts": 7516.0, "replay/samples": 30064.0, "replay/insert_wait_avg": 1.7068689335147519e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.508868800635792e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 1792.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1685437389782497e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.046627044677734e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4167585372925, "timer/env.step_count": 939.0, "timer/env.step_total": 75.538015127182, "timer/env.step_frac": 0.0755065471290445, "timer/env.step_avg": 0.0804451705294803, "timer/env.step_min": 0.023513078689575195, "timer/env.step_max": 1.7699344158172607, "timer/replay._sample_count": 30064.0, "timer/replay._sample_total": 14.462098360061646, "timer/replay._sample_frac": 0.0144560736679448, "timer/replay._sample_avg": 0.0004810437187354193, "timer/replay._sample_min": 0.00038242340087890625, "timer/replay._sample_max": 0.02842092514038086, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1163.0, "timer/agent.policy_total": 18.670486450195312, "timer/agent.policy_frac": 0.01866270860705432, "timer/agent.policy_avg": 0.01605372867600629, "timer/agent.policy_min": 0.009498834609985352, "timer/agent.policy_max": 0.08533644676208496, "timer/dataset_train_count": 1879.0, "timer/dataset_train_total": 0.30717992782592773, "timer/dataset_train_frac": 0.0003070519612996637, "timer/dataset_train_avg": 0.00016348053636292055, "timer/dataset_train_min": 9.751319885253906e-05, "timer/dataset_train_max": 0.0040209293365478516, "timer/agent.train_count": 1879.0, "timer/agent.train_total": 844.0659358501434, "timer/agent.train_frac": 0.84371431070812, "timer/agent.train_avg": 0.4492101840607469, "timer/agent.train_min": 0.43823885917663574, "timer/agent.train_max": 1.0807745456695557, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47745704650878906, "timer/agent.report_frac": 0.0004772581451023253, "timer/agent.report_avg": 0.23872852325439453, "timer/agent.report_min": 0.23108267784118652, "timer/agent.report_max": 0.24637436866760254, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0040740966796875e-05, "timer/dataset_eval_frac": 3.002822644706531e-08, "timer/dataset_eval_avg": 3.0040740966796875e-05, "timer/dataset_eval_min": 3.0040740966796875e-05, "timer/dataset_eval_max": 3.0040740966796875e-05, "fps": 7.512755167421377}
{"step": 510784, "time": 68402.13071203232, "episode/length": 329.0, "episode/score": 12.478939276456003, "episode/reward_rate": 0.9878787878787879, "episode/intrinsic_return": 0.37893902769974375}
{"step": 510872, "time": 68414.36884832382, "episode/length": 189.0, "episode/score": 10.305270845634368, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.20527051969474996}
{"step": 511560, "time": 68499.64819908142, "episode/length": 192.0, "episode/score": 10.323272777328384, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.2232723796769278}
{"step": 511568, "time": 68502.09005403519, "episode/length": 176.0, "episode/score": 8.29811245025121, "episode/reward_rate": 0.9887005649717514, "episode/intrinsic_return": 0.1981121910175716}
{"step": 512144, "time": 68573.99628782272, "episode/length": 158.0, "episode/score": 6.26096533665077, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.16096510919851426}
{"step": 512176, "time": 68579.5020480156, "episode/length": 173.0, "episode/score": 8.308028357196235, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.208028085738988}
{"step": 512288, "time": 68594.58215999603, "episode/length": 341.0, "episode/score": 8.48939245369911, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.38939215721256915}
{"step": 512424, "time": 68612.7219157219, "episode/length": 242.0, "episode/score": 10.382881132663897, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.28288085200983915}
{"step": 512488, "time": 68622.04820346832, "episode/length": 316.0, "episode/score": 11.46716697827651, "episode/reward_rate": 0.9905362776025236, "episode/intrinsic_return": 0.367166661999363}
{"step": 512808, "time": 68662.62917900085, "episode/length": 78.0, "episode/score": 7.195208560209721, "episode/reward_rate": 0.9240506329113924, "episode/intrinsic_return": 0.095208331476897}
{"step": 512936, "time": 68679.75867843628, "episode/length": 170.0, "episode/score": 10.30165190632215, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.20165157060364436}
{"step": 512976, "time": 68685.98674106598, "episode/length": 176.0, "episode/score": 8.29258340258093, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.19258316371997353}
{"step": 513552, "time": 68757.4854900837, "episode/length": 175.0, "episode/score": 8.289555358713187, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.1895551277393679}
{"step": 513664, "time": 68772.671864748, "episode/length": 444.0, "episode/score": 12.530235026117225, "episode/reward_rate": 0.9932584269662922, "episode/intrinsic_return": 0.43023462788369216}
{"step": 513664, "time": 68772.67954349518, "episode/length": 154.0, "episode/score": 10.265696143788773, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.16569574613731675}
{"step": 513784, "time": 68790.53590798378, "episode/length": 186.0, "episode/score": 8.312960368648419, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.21296016663291084}
{"step": 514000, "time": 68818.21498322487, "episode/length": 188.0, "episode/score": 10.305365528514812, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.20536528365846607}
{"step": 514152, "time": 68838.15038633347, "episode/length": 146.0, "episode/score": 7.265839066616536, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.16583879993231676}
{"step": 514512, "time": 68883.58159184456, "episode/length": 196.0, "episode/score": 11.32268998905056, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.2226897108994308}
{"step": 514960, "time": 68939.82594752312, "episode/length": 175.0, "episode/score": 8.2962831003897, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.19628284720965894}
{"step": 515008, "time": 68947.30648970604, "episode/length": 167.0, "episode/score": 8.281380621530843, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.18138038418328506}
{"step": 515072, "time": 68956.57522249222, "episode/length": 175.0, "episode/score": 6.290473772336554, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.19047362410492497}
{"step": 515304, "time": 68986.45691251755, "episode/length": 162.0, "episode/score": 7.277681327152095, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.17768111844270607}
{"step": 515376, "time": 68996.61783528328, "episode/length": 37.0, "episode/score": 1.138332653499674, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.038332664291374385}
{"step": 515560, "time": 69020.56126332283, "episode/length": 221.0, "episode/score": 9.35571134856582, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.2557110559209832}
{"step": 515616, "time": 69029.06554722786, "episode/length": 350.0, "episode/score": 12.52079713414878, "episode/reward_rate": 0.98005698005698, "episode/intrinsic_return": 0.4207967789889153}
{"step": 516200, "time": 69103.30299305916, "episode/length": 255.0, "episode/score": 9.386831739197078, "episode/reward_rate": 0.99609375, "episode/intrinsic_return": 0.2868314176812419}
{"step": 516528, "time": 69144.77525615692, "episode/length": 251.0, "episode/score": 7.3806570096840005, "episode/reward_rate": 0.9801587301587301, "episode/intrinsic_return": 0.2806567731513496}
{"step": 516560, "time": 69150.26987195015, "episode/length": 147.0, "episode/score": 11.268530996083427, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.16853073620950454}
{"step": 516640, "time": 69161.45608186722, "episode/length": 166.0, "episode/score": 9.29116123085987, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.19116101371037075}
{"step": 516640, "time": 69161.46440172195, "episode/length": 209.0, "episode/score": 9.332815424635555, "episode/reward_rate": 0.9809523809523809, "episode/intrinsic_return": 0.23281520119962806}
{"step": 516648, "time": 69165.74014353752, "episode/length": 204.0, "episode/score": 10.341479644939682, "episode/reward_rate": 0.9804878048780488, "episode/intrinsic_return": 0.2414793514799385}
{"step": 516880, "time": 69195.3390057087, "episode/length": 157.0, "episode/score": 9.269779299569564, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.1697790022681147}
{"step": 517144, "time": 69229.08766365051, "episode/length": 197.0, "episode/score": 11.316825761152359, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.2168254077387246}
{"step": 517560, "time": 69281.43571066856, "episode/length": 51.0, "episode/score": 3.1588810573221053, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.05888097538900183}
{"step": 517816, "time": 69314.53465437889, "episode/length": 160.0, "episode/score": 7.279244911723254, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.179244790499979}
{"step": 517880, "time": 69323.79501223564, "episode/length": 209.0, "episode/score": 10.34083003014166, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.24082975682176766}
{"step": 518328, "time": 69379.96358084679, "episode/length": 209.0, "episode/score": 10.322244686114573, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.22224439841738786}
{"step": 518417, "time": 69394.8524928093, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.5156952062419045, "train/action_min": 0.0, "train/action_std": 3.628364991647592, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04179063557111538, "train/actor_opt_grad_steps": 128250.0, "train/actor_opt_loss": -7.273851667583915, "train/adv_mag": 0.5024275614498811, "train/adv_max": 0.4494337320636591, "train/adv_mean": 0.0027970349397626404, "train/adv_min": -0.4150849679591124, "train/adv_std": 0.05168262268826752, "train/cont_avg": 0.9948186528497409, "train/cont_loss_mean": 7.16869909430622e-05, "train/cont_loss_std": 0.0021259949319630956, "train/cont_neg_acc": 0.9957775305956602, "train/cont_neg_loss": 0.00834370084811494, "train/cont_pos_acc": 0.9999898103852346, "train/cont_pos_loss": 2.2591987225610543e-05, "train/cont_pred": 0.9948265620463871, "train/cont_rate": 0.9948186528497409, "train/dyn_loss_mean": 6.918265977671727, "train/dyn_loss_std": 8.939946053559298, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1110271783690377, "train/extr_critic_critic_opt_grad_steps": 128250.0, "train/extr_critic_critic_opt_loss": 16010.704754290804, "train/extr_critic_mag": 9.205406238378021, "train/extr_critic_max": 9.205406238378021, "train/extr_critic_mean": 2.675194832945117, "train/extr_critic_min": -0.46223707334982916, "train/extr_critic_std": 2.1715565153971856, "train/extr_return_normed_mag": 1.4770322253667012, "train/extr_return_normed_max": 1.4770322253667012, "train/extr_return_normed_mean": 0.4040189065000554, "train/extr_return_normed_min": -0.10816571066262191, "train/extr_return_normed_std": 0.32379218812433547, "train/extr_return_rate": 0.7987198842004173, "train/extr_return_raw_mag": 9.99132877310323, "train/extr_return_raw_max": 9.99132877310323, "train/extr_return_raw_mean": 2.6942063094420754, "train/extr_return_raw_min": -0.7886991678433097, "train/extr_return_raw_std": 2.201945525376908, "train/extr_reward_mag": 1.0392287135741871, "train/extr_reward_max": 1.0392287135741871, "train/extr_reward_mean": 0.04409434504498163, "train/extr_reward_min": -0.6516677431491991, "train/extr_reward_std": 0.20036852444700626, "train/image_loss_mean": 3.804551763238067, "train/image_loss_std": 8.944313911576344, "train/model_loss_mean": 8.038899557578132, "train/model_loss_std": 13.078008780207659, "train/model_opt_grad_norm": 39.00779234930641, "train/model_opt_grad_steps": 128138.71502590674, "train/model_opt_loss": 13971.528047077396, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1729.2746113989638, "train/policy_entropy_mag": 2.453112848064442, "train/policy_entropy_max": 2.453112848064442, "train/policy_entropy_mean": 0.46128899306830967, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.5716144532119672, "train/policy_logprob_mag": 7.438384127740416, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.461797529242817, "train/policy_logprob_min": -7.438384127740416, "train/policy_logprob_std": 1.0494060676950248, "train/policy_randomness_mag": 0.8658411851818697, "train/policy_randomness_max": 0.8658411851818697, "train/policy_randomness_mean": 0.1628147712257242, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.20175481807691445, "train/post_ent_mag": 60.288107857185324, "train/post_ent_max": 60.288107857185324, "train/post_ent_mean": 44.61621228153842, "train/post_ent_min": 19.529658218739563, "train/post_ent_std": 7.006197855262559, "train/prior_ent_mag": 74.98959781468841, "train/prior_ent_max": 74.98959781468841, "train/prior_ent_mean": 51.554192933393885, "train/prior_ent_min": 31.07510565723162, "train/prior_ent_std": 6.729182675712467, "train/rep_loss_mean": 6.918265977671727, "train/rep_loss_std": 8.939946053559298, "train/reward_avg": 0.02725925348660489, "train/reward_loss_mean": 0.08331657938388963, "train/reward_loss_std": 0.1975660275841624, "train/reward_max_data": 1.0147215344127596, "train/reward_max_pred": 1.0133321841146044, "train/reward_neg_acc": 0.9982554196076072, "train/reward_neg_loss": 0.05557065684869499, "train/reward_pos_acc": 0.8846749598498171, "train/reward_pos_loss": 0.7503604221838126, "train/reward_pred": 0.027037194461942953, "train/reward_rate": 0.0399176246761658, "train_stats/sum_log_reward": 8.78421072269741, "train_stats/max_log_achievement_collect_coal": 0.13157894736842105, "train_stats/max_log_achievement_collect_drink": 2.9210526315789473, "train_stats/max_log_achievement_collect_sapling": 1.5526315789473684, "train_stats/max_log_achievement_collect_stone": 7.026315789473684, "train_stats/max_log_achievement_collect_wood": 8.657894736842104, "train_stats/max_log_achievement_defeat_skeleton": 0.05263157894736842, "train_stats/max_log_achievement_defeat_zombie": 0.6578947368421053, "train_stats/max_log_achievement_eat_cow": 0.21052631578947367, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.2105263157894737, "train_stats/max_log_achievement_make_wood_sword": 1.3157894736842106, "train_stats/max_log_achievement_place_furnace": 0.2894736842105263, "train_stats/max_log_achievement_place_plant": 1.394736842105263, "train_stats/max_log_achievement_place_stone": 4.842105263157895, "train_stats/max_log_achievement_place_table": 2.6315789473684212, "train_stats/max_log_achievement_wake_up": 1.2894736842105263, "train_stats/mean_log_entropy": 0.43203308747002955, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 5.349514140107203e-06, "report/cont_loss_std": 7.982672104844823e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00020082252740394324, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 4.197414455120452e-06, "report/cont_pred": 0.994137704372406, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 6.87473201751709, "report/dyn_loss_std": 8.534895896911621, "report/image_loss_mean": 2.8812217712402344, "report/image_loss_std": 6.29566764831543, "report/model_loss_mean": 7.096221923828125, "report/model_loss_std": 10.468807220458984, "report/post_ent_mag": 59.31642532348633, "report/post_ent_max": 59.31642532348633, "report/post_ent_mean": 43.567420959472656, "report/post_ent_min": 20.51742935180664, "report/post_ent_std": 6.1659650802612305, "report/prior_ent_mag": 74.94580078125, "report/prior_ent_max": 74.94580078125, "report/prior_ent_mean": 50.829647064208984, "report/prior_ent_min": 32.32974624633789, "report/prior_ent_std": 6.8945112228393555, "report/rep_loss_mean": 6.87473201751709, "report/rep_loss_std": 8.534895896911621, "report/reward_avg": 0.03167859464883804, "report/reward_loss_mean": 0.09015551209449768, "report/reward_loss_std": 0.1781112402677536, "report/reward_max_data": 1.1012500524520874, "report/reward_max_pred": 1.0435702800750732, "report/reward_neg_acc": 0.9979487061500549, "report/reward_neg_loss": 0.06011918932199478, "report/reward_pos_acc": 0.9387754797935486, "report/reward_pos_loss": 0.6878170967102051, "report/reward_pred": 0.03271510452032089, "report/reward_rate": 0.0478515625, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 4.2756555558298714e-06, "eval/cont_loss_std": 3.9610484236618504e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00032589887268841267, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.3800373583071632e-06, "eval/cont_pred": 0.9941402077674866, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 18.400468826293945, "eval/dyn_loss_std": 11.958452224731445, "eval/image_loss_mean": 15.706772804260254, "eval/image_loss_std": 29.199230194091797, "eval/model_loss_mean": 26.906253814697266, "eval/model_loss_std": 32.61662292480469, "eval/post_ent_mag": 59.810096740722656, "eval/post_ent_max": 59.810096740722656, "eval/post_ent_mean": 42.461158752441406, "eval/post_ent_min": 22.157201766967773, "eval/post_ent_std": 7.247757911682129, "eval/prior_ent_mag": 74.94580078125, "eval/prior_ent_max": 74.94580078125, "eval/prior_ent_mean": 53.88341522216797, "eval/prior_ent_min": 35.82911682128906, "eval/prior_ent_std": 6.416940212249756, "eval/rep_loss_mean": 18.400468826293945, "eval/rep_loss_std": 11.958452224731445, "eval/reward_avg": 0.0302734375, "eval/reward_loss_mean": 0.15919476747512817, "eval/reward_loss_std": 0.9156666994094849, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.001030683517456, "eval/reward_neg_acc": 0.991894543170929, "eval/reward_neg_loss": 0.08210338652133942, "eval/reward_pos_acc": 0.8108108043670654, "eval/reward_pos_loss": 2.2156596183776855, "eval/reward_pred": 0.027426868677139282, "eval/reward_rate": 0.0361328125, "replay/size": 517913.0, "replay/inserts": 7708.0, "replay/samples": 30832.0, "replay/insert_wait_avg": 1.6157591225387028e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.563557226421552e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 8.642673492431641e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4904232025146, "timer/env.step_count": 964.0, "timer/env.step_total": 84.48935055732727, "timer/env.step_frac": 0.08444793533043676, "timer/env.step_avg": 0.08764455452004903, "timer/env.step_min": 0.02336907386779785, "timer/env.step_max": 3.322036027908325, "timer/replay._sample_count": 30832.0, "timer/replay._sample_total": 14.808786392211914, "timer/replay._sample_frac": 0.014801527379752228, "timer/replay._sample_avg": 0.0004803057340494264, "timer/replay._sample_min": 0.00036716461181640625, "timer/replay._sample_max": 0.01076507568359375, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 964.0, "timer/agent.policy_total": 15.647908926010132, "timer/agent.policy_frac": 0.015640238590112675, "timer/agent.policy_avg": 0.016232270670134993, "timer/agent.policy_min": 0.014640331268310547, "timer/agent.policy_max": 0.05441451072692871, "timer/dataset_train_count": 1927.0, "timer/dataset_train_total": 0.3130486011505127, "timer/dataset_train_frac": 0.00031289515010894496, "timer/dataset_train_avg": 0.00016245386671017784, "timer/dataset_train_min": 9.918212890625e-05, "timer/dataset_train_max": 0.0005755424499511719, "timer/agent.train_count": 1927.0, "timer/agent.train_total": 866.9074158668518, "timer/agent.train_frac": 0.8664824727576392, "timer/agent.train_avg": 0.4498741130601203, "timer/agent.train_min": 0.436398983001709, "timer/agent.train_max": 0.9605569839477539, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4738185405731201, "timer/agent.report_frac": 0.00047358628287160723, "timer/agent.report_avg": 0.23690927028656006, "timer/agent.report_min": 0.23091530799865723, "timer/agent.report_max": 0.2429032325744629, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9802322387695312e-05, "timer/dataset_eval_frac": 2.9787713801697093e-08, "timer/dataset_eval_avg": 2.9802322387695312e-05, "timer/dataset_eval_min": 2.9802322387695312e-05, "timer/dataset_eval_max": 2.9802322387695312e-05, "fps": 7.704104127361519}
{"step": 518448, "time": 69398.48596763611, "episode/length": 225.0, "episode/score": 10.35318922465467, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.2531889672836769}
{"step": 518624, "time": 69421.49268221855, "episode/length": 100.0, "episode/score": 7.219666869554203, "episode/reward_rate": 0.9405940594059405, "episode/intrinsic_return": 0.11966666433727369}
{"step": 518656, "time": 69426.97909879684, "episode/length": 251.0, "episode/score": 11.39020909041119, "episode/reward_rate": 0.9801587301587301, "episode/intrinsic_return": 0.2902087694774309}
{"step": 518672, "time": 69430.78348183632, "episode/length": 223.0, "episode/score": 12.365534486276374, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.2655341355402925}
{"step": 518928, "time": 69464.00628447533, "episode/length": 295.0, "episode/score": 10.443595964041378, "episode/reward_rate": 0.9898648648648649, "episode/intrinsic_return": 0.34359571103595954}
{"step": 518992, "time": 69473.20309495926, "episode/length": 45.0, "episode/score": 4.153044764563674, "episode/reward_rate": 0.8913043478260869, "episode/intrinsic_return": 0.053044641768792644}
{"step": 519936, "time": 69589.2644007206, "episode/length": 185.0, "episode/score": 8.314230933268846, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.21423074469930725}
{"step": 520000, "time": 69618.54364609718, "eval_episode/length": 175.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9715909090909091}
{"step": 520000, "time": 69621.93481874466, "eval_episode/length": 176.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9943502824858758}
{"step": 520000, "time": 69624.00318646431, "eval_episode/length": 189.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 520000, "time": 69626.20911717415, "eval_episode/length": 207.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9711538461538461}
{"step": 520000, "time": 69629.68974041939, "eval_episode/length": 248.0, "eval_episode/score": 9.100000031292439, "eval_episode/reward_rate": 0.9959839357429718}
{"step": 520000, "time": 69633.13743042946, "eval_episode/length": 294.0, "eval_episode/score": 12.100000001490116, "eval_episode/reward_rate": 0.9830508474576272}
{"step": 520000, "time": 69635.57263684273, "eval_episode/length": 314.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9841269841269841}
{"step": 520000, "time": 69637.96551918983, "eval_episode/length": 159.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.96875}
{"step": 520184, "time": 69660.25592160225, "episode/length": 327.0, "episode/score": 8.479199429255459, "episode/reward_rate": 0.9878048780487805, "episode/intrinsic_return": 0.37919913742553035}
{"step": 520320, "time": 69678.29571557045, "episode/length": 205.0, "episode/score": 10.34000572415971, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.24000542557769222}
{"step": 520480, "time": 69699.2076420784, "episode/length": 227.0, "episode/score": 10.359479647995613, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.25947931734117446}
{"step": 520560, "time": 69710.33818054199, "episode/length": 278.0, "episode/score": 13.410418837564066, "episode/reward_rate": 0.982078853046595, "episode/intrinsic_return": 0.31041839870158583}
{"step": 520808, "time": 69741.97163748741, "episode/length": 40.0, "episode/score": 3.1494584832689725, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.04945833230158314}
{"step": 521256, "time": 69797.59915494919, "episode/length": 164.0, "episode/score": 7.2808180104984785, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.18081781610817416}
{"step": 521296, "time": 69803.96278595924, "episode/length": 426.0, "episode/score": 11.489674727496094, "episode/reward_rate": 0.9929742388758782, "episode/intrinsic_return": 0.38967437104111013}
{"step": 521344, "time": 69811.48410439491, "episode/length": 293.0, "episode/score": 11.437226579520939, "episode/reward_rate": 0.9863945578231292, "episode/intrinsic_return": 0.3372262620796391}
{"step": 521368, "time": 69815.95940351486, "episode/length": 304.0, "episode/score": 10.455534942422673, "episode/reward_rate": 0.980327868852459, "episode/intrinsic_return": 0.3555345807435515}
{"step": 522048, "time": 69900.39885663986, "episode/length": 215.0, "episode/score": 10.346702427310447, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.2467021964239393}
{"step": 522112, "time": 69910.31076216698, "episode/length": 240.0, "episode/score": 6.379163082632658, "episode/reward_rate": 0.995850622406639, "episode/intrinsic_return": 0.2791628401628259}
{"step": 522232, "time": 69926.49692940712, "episode/length": 121.0, "episode/score": 9.225019456378504, "episode/reward_rate": 0.9918032786885246, "episode/intrinsic_return": 0.12501910168430186}
{"step": 522248, "time": 69930.00335764885, "episode/length": 210.0, "episode/score": 4.342728230640205, "episode/reward_rate": 0.9715639810426541, "episode/intrinsic_return": 0.24272808351452113}
{"step": 522368, "time": 69946.28112483025, "episode/length": 194.0, "episode/score": 10.330807940094019, "episode/reward_rate": 0.9641025641025641, "episode/intrinsic_return": 0.23080754744842125}
{"step": 522536, "time": 69968.52824020386, "episode/length": 145.0, "episode/score": 8.268208739482361, "episode/reward_rate": 0.9657534246575342, "episode/intrinsic_return": 0.16820847431154107}
{"step": 522656, "time": 69984.85961031914, "episode/length": 163.0, "episode/score": 9.280065233608184, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.1800649676224566}
{"step": 523104, "time": 70041.3633787632, "episode/length": 123.0, "episode/score": 10.230514429140385, "episode/reward_rate": 0.9919354838709677, "episode/intrinsic_return": 0.13051404091856966}
{"step": 523416, "time": 70081.31126880646, "episode/length": 145.0, "episode/score": 9.258844376041452, "episode/reward_rate": 0.9657534246575342, "episode/intrinsic_return": 0.15884408165038622}
{"step": 523952, "time": 70148.96168279648, "episode/length": 214.0, "episode/score": 10.34183657792073, "episode/reward_rate": 0.9720930232558139, "episode/intrinsic_return": 0.2418362867892938}
{"step": 523976, "time": 70153.38567638397, "episode/length": 164.0, "episode/score": 7.281232835808623, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.1812326701146958}
{"step": 523976, "time": 70153.40198254585, "episode/length": 334.0, "episode/score": 11.500477242616398, "episode/reward_rate": 0.982089552238806, "episode/intrinsic_return": 0.4004768440336193}
{"step": 524296, "time": 70197.29733085632, "episode/length": 280.0, "episode/score": 12.411018472421347, "episode/reward_rate": 0.9750889679715302, "episode/intrinsic_return": 0.3110181020110758}
{"step": 524368, "time": 70208.47126531601, "episode/length": 157.0, "episode/score": 7.270396045008056, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.17039585501242982}
{"step": 524392, "time": 70213.33693599701, "episode/length": 231.0, "episode/score": 10.360230188523929, "episode/reward_rate": 0.9741379310344828, "episode/intrinsic_return": 0.2602299117115763}
{"step": 525080, "time": 70299.03513646126, "episode/length": 137.0, "episode/score": 4.2665103174676915, "episode/reward_rate": 0.9565217391304348, "episode/intrinsic_return": 0.16651020049357612}
{"step": 525088, "time": 70301.50621175766, "episode/length": 339.0, "episode/score": 7.5043489314439284, "episode/reward_rate": 0.9911764705882353, "episode/intrinsic_return": 0.40434878158248466}
{"step": 525472, "time": 70349.69761013985, "episode/length": 146.0, "episode/score": 8.268066205495415, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.16806592018474475}
{"step": 525520, "time": 70357.09621620178, "episode/length": 143.0, "episode/score": 6.242753028889638, "episode/reward_rate": 0.9583333333333334, "episode/intrinsic_return": 0.14275291860940342}
{"step": 525552, "time": 70362.51577234268, "episode/length": 199.0, "episode/score": 12.327117005260334, "episode/reward_rate": 0.97, "episode/intrinsic_return": 0.2271166267009903}
{"step": 525576, "time": 70366.96508789062, "episode/length": 269.0, "episode/score": 10.409995881278519, "episode/reward_rate": 0.9740740740740741, "episode/intrinsic_return": 0.30999561025782896}
{"step": 525777, "time": 70393.89054965973, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.55744336998981, "train/action_min": 0.0, "train/action_std": 3.6313807731089383, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04228575242197384, "train/actor_opt_grad_steps": 130135.0, "train/actor_opt_loss": -9.240389309722282, "train/adv_mag": 0.486662510458542, "train/adv_max": 0.4360905560138433, "train/adv_mean": 0.002628832340396121, "train/adv_min": -0.4092817993267723, "train/adv_std": 0.05214449087076861, "train/cont_avg": 0.9943953804347826, "train/cont_loss_mean": 0.00015754489731587842, "train/cont_loss_std": 0.004833889443605328, "train/cont_neg_acc": 0.9987771741074064, "train/cont_neg_loss": 0.008113467739193587, "train/cont_pos_acc": 0.9999839699138766, "train/cont_pos_loss": 8.871512164570808e-05, "train/cont_pred": 0.994385016353234, "train/cont_rate": 0.9943953804347826, "train/dyn_loss_mean": 6.865655912005383, "train/dyn_loss_std": 8.950217039688773, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0563611346094504, "train/extr_critic_critic_opt_grad_steps": 130135.0, "train/extr_critic_critic_opt_loss": 15884.54515009341, "train/extr_critic_mag": 9.304859560468923, "train/extr_critic_max": 9.304859560468923, "train/extr_critic_mean": 2.7700268321711086, "train/extr_critic_min": -0.4857288611971814, "train/extr_critic_std": 2.2543338219756666, "train/extr_return_normed_mag": 1.4756021123865377, "train/extr_return_normed_max": 1.4756021123865377, "train/extr_return_normed_mean": 0.4139258200707643, "train/extr_return_normed_min": -0.10743899777045716, "train/extr_return_normed_std": 0.3324531465768814, "train/extr_return_rate": 0.7865535558565803, "train/extr_return_raw_mag": 10.08293246186298, "train/extr_return_raw_max": 10.08293246186298, "train/extr_return_raw_mean": 2.7881077242934187, "train/extr_return_raw_min": -0.79510848612889, "train/extr_return_raw_std": 2.2848069784433944, "train/extr_reward_mag": 1.0358531410279481, "train/extr_reward_max": 1.0358531410279481, "train/extr_reward_mean": 0.046067760133629905, "train/extr_reward_min": -0.6732432310995848, "train/extr_reward_std": 0.20560094633180162, "train/image_loss_mean": 3.6713621447915616, "train/image_loss_std": 8.427812625532566, "train/model_loss_mean": 7.87464056585146, "train/model_loss_std": 12.572618246078491, "train/model_opt_grad_norm": 37.47757816314697, "train/model_opt_grad_steps": 130022.58695652174, "train/model_opt_loss": 13135.285955014437, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1677.9891304347825, "train/policy_entropy_mag": 2.475723669580791, "train/policy_entropy_max": 2.475723669580791, "train/policy_entropy_mean": 0.4756385225640691, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.5943141550473545, "train/policy_logprob_mag": 7.438384151977042, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.47600921356807585, "train/policy_logprob_min": -7.438384151977042, "train/policy_logprob_std": 1.0609991508333578, "train/policy_randomness_mag": 0.8738218111836392, "train/policy_randomness_max": 0.8738218111836392, "train/policy_randomness_mean": 0.1678795259364921, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.20976681804851346, "train/post_ent_mag": 60.16813595398612, "train/post_ent_max": 60.16813595398612, "train/post_ent_mean": 44.67162219337795, "train/post_ent_min": 19.45493168934532, "train/post_ent_std": 7.010308390078337, "train/prior_ent_mag": 74.90148548457934, "train/prior_ent_max": 74.90148548457934, "train/prior_ent_mean": 51.56469552413277, "train/prior_ent_min": 31.20786710407423, "train/prior_ent_std": 6.7753196099530095, "train/rep_loss_mean": 6.865655912005383, "train/rep_loss_std": 8.950217039688773, "train/reward_avg": 0.028591878378115918, "train/reward_loss_mean": 0.08372732895709899, "train/reward_loss_std": 0.19729846744271723, "train/reward_max_data": 1.0180978587140208, "train/reward_max_pred": 1.0167516508828038, "train/reward_neg_acc": 0.9985168919615124, "train/reward_neg_loss": 0.055259522658003414, "train/reward_pos_acc": 0.9042148447555044, "train/reward_pos_loss": 0.7493204785429913, "train/reward_pred": 0.028296776272801926, "train/reward_rate": 0.04093601392663043, "train_stats/sum_log_reward": 8.856756893364159, "train_stats/max_log_achievement_collect_coal": 0.24324324324324326, "train_stats/max_log_achievement_collect_drink": 2.8378378378378377, "train_stats/max_log_achievement_collect_sapling": 1.4594594594594594, "train_stats/max_log_achievement_collect_stone": 7.621621621621622, "train_stats/max_log_achievement_collect_wood": 8.72972972972973, "train_stats/max_log_achievement_defeat_skeleton": 0.10810810810810811, "train_stats/max_log_achievement_defeat_zombie": 0.6756756756756757, "train_stats/max_log_achievement_eat_cow": 0.1891891891891892, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.3783783783783783, "train_stats/max_log_achievement_make_wood_sword": 1.2702702702702702, "train_stats/max_log_achievement_place_furnace": 0.2702702702702703, "train_stats/max_log_achievement_place_plant": 1.4054054054054055, "train_stats/max_log_achievement_place_stone": 4.918918918918919, "train_stats/max_log_achievement_place_table": 2.5675675675675675, "train_stats/max_log_achievement_wake_up": 1.4054054054054055, "train_stats/mean_log_entropy": 0.49453537568852707, "eval_stats/sum_log_reward": 9.725000143051147, "eval_stats/max_log_achievement_collect_coal": 0.5, "eval_stats/max_log_achievement_collect_drink": 5.75, "eval_stats/max_log_achievement_collect_sapling": 2.5, "eval_stats/max_log_achievement_collect_stone": 9.0, "eval_stats/max_log_achievement_collect_wood": 11.875, "eval_stats/max_log_achievement_defeat_skeleton": 0.125, "eval_stats/max_log_achievement_defeat_zombie": 1.125, "eval_stats/max_log_achievement_eat_cow": 0.25, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.625, "eval_stats/max_log_achievement_make_wood_sword": 1.625, "eval_stats/max_log_achievement_place_furnace": 0.25, "eval_stats/max_log_achievement_place_plant": 2.25, "eval_stats/max_log_achievement_place_stone": 5.75, "eval_stats/max_log_achievement_place_table": 3.25, "eval_stats/max_log_achievement_wake_up": 1.625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 8.14757640910102e-06, "report/cont_loss_std": 0.00020895105262752622, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0013620624085888267, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.5042259065012331e-06, "report/cont_pred": 0.9951223134994507, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 8.175206184387207, "report/dyn_loss_std": 9.481780052185059, "report/image_loss_mean": 4.896160125732422, "report/image_loss_std": 9.890680313110352, "report/model_loss_mean": 9.892809867858887, "report/model_loss_std": 14.469249725341797, "report/post_ent_mag": 60.06861114501953, "report/post_ent_max": 60.06861114501953, "report/post_ent_mean": 45.012386322021484, "report/post_ent_min": 21.08730697631836, "report/post_ent_std": 7.2368903160095215, "report/prior_ent_mag": 74.85855102539062, "report/prior_ent_max": 74.85855102539062, "report/prior_ent_mean": 53.42729187011719, "report/prior_ent_min": 30.603626251220703, "report/prior_ent_std": 6.943931579589844, "report/rep_loss_mean": 8.175206184387207, "report/rep_loss_std": 9.481780052185059, "report/reward_avg": 0.031637147068977356, "report/reward_loss_mean": 0.09151788055896759, "report/reward_loss_std": 0.2355535626411438, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.004209280014038, "report/reward_neg_acc": 0.9989754557609558, "report/reward_neg_loss": 0.05617736279964447, "report/reward_pos_acc": 0.875, "report/reward_pos_loss": 0.8101086020469666, "report/reward_pred": 0.030087625607848167, "report/reward_rate": 0.046875, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.0032464780379086733, "eval/cont_loss_std": 0.10364118218421936, "eval/cont_neg_acc": 0.5, "eval/cont_neg_loss": 1.6609795093536377, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.3822767616366036e-06, "eval/cont_pred": 0.998989462852478, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 19.158321380615234, "eval/dyn_loss_std": 12.122086524963379, "eval/image_loss_mean": 19.370750427246094, "eval/image_loss_std": 21.625226974487305, "eval/model_loss_mean": 30.994054794311523, "eval/model_loss_std": 26.57503890991211, "eval/post_ent_mag": 60.015968322753906, "eval/post_ent_max": 60.015968322753906, "eval/post_ent_mean": 41.738162994384766, "eval/post_ent_min": 20.609180450439453, "eval/post_ent_std": 7.357341289520264, "eval/prior_ent_mag": 74.85855102539062, "eval/prior_ent_max": 74.85855102539062, "eval/prior_ent_mean": 54.947845458984375, "eval/prior_ent_min": 39.33834457397461, "eval/prior_ent_std": 5.688665390014648, "eval/rep_loss_mean": 19.158321380615234, "eval/rep_loss_std": 12.122086524963379, "eval/reward_avg": 0.03505859524011612, "eval/reward_loss_mean": 0.12506580352783203, "eval/reward_loss_std": 0.70490562915802, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0029900074005127, "eval/reward_neg_acc": 0.9908722043037415, "eval/reward_neg_loss": 0.03507455438375473, "eval/reward_pos_acc": 0.6315789222717285, "eval/reward_pos_loss": 2.460102081298828, "eval/reward_pred": 0.024901900440454483, "eval/reward_rate": 0.037109375, "replay/size": 525273.0, "replay/inserts": 7360.0, "replay/samples": 29440.0, "replay/insert_wait_avg": 1.6478416712387748e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.552135249842768e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 2688.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1478328988665625e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.195638656616211e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4278199672699, "timer/env.step_count": 920.0, "timer/env.step_total": 84.33038187026978, "timer/env.step_frac": 0.08429431907744103, "timer/env.step_avg": 0.09166345855464106, "timer/env.step_min": 0.023525476455688477, "timer/env.step_max": 3.2162554264068604, "timer/replay._sample_count": 29440.0, "timer/replay._sample_total": 14.29687213897705, "timer/replay._sample_frac": 0.014290758267242897, "timer/replay._sample_avg": 0.00048562745037286176, "timer/replay._sample_min": 0.0003695487976074219, "timer/replay._sample_max": 0.010035514831542969, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1256.0, "timer/agent.policy_total": 20.409971714019775, "timer/agent.policy_frac": 0.02040124365462719, "timer/agent.policy_avg": 0.016249977479315107, "timer/agent.policy_min": 0.009823083877563477, "timer/agent.policy_max": 0.07727861404418945, "timer/dataset_train_count": 1840.0, "timer/dataset_train_total": 0.3052694797515869, "timer/dataset_train_frac": 0.00030513893522230736, "timer/dataset_train_avg": 0.0001659073259519494, "timer/dataset_train_min": 0.00010013580322265625, "timer/dataset_train_max": 0.0004761219024658203, "timer/agent.train_count": 1840.0, "timer/agent.train_total": 826.9754159450531, "timer/agent.train_frac": 0.8266217706461907, "timer/agent.train_avg": 0.44944316083970276, "timer/agent.train_min": 0.43654608726501465, "timer/agent.train_max": 1.0402305126190186, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4762284755706787, "timer/agent.report_frac": 0.0004760248226466344, "timer/agent.report_avg": 0.23811423778533936, "timer/agent.report_min": 0.22990179061889648, "timer/agent.report_max": 0.24632668495178223, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.075599670410156e-05, "timer/dataset_eval_frac": 3.074284430145873e-08, "timer/dataset_eval_avg": 3.075599670410156e-05, "timer/dataset_eval_min": 3.075599670410156e-05, "timer/dataset_eval_max": 3.075599670410156e-05, "fps": 7.356744944713386}
{"step": 526376, "time": 70466.85397219658, "episode/length": 299.0, "episode/score": 10.431037438390376, "episode/reward_rate": 0.9966666666666667, "episode/intrinsic_return": 0.33103715569905034}
{"step": 526608, "time": 70496.6738049984, "episode/length": 189.0, "episode/score": 10.310440349260716, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.21044006156353134}
{"step": 526712, "time": 70510.86441802979, "episode/length": 203.0, "episode/score": 11.332600363962229, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.2326000596758604}
{"step": 526968, "time": 70543.7024769783, "episode/length": 186.0, "episode/score": 7.303902156622826, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.2039018820223646}
{"step": 526992, "time": 70548.14243865013, "episode/length": 183.0, "episode/score": 9.320300399564985, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.2203001370135098}
{"step": 527240, "time": 70579.91087841988, "episode/length": 210.0, "episode/score": 10.331374368931392, "episode/reward_rate": 0.981042654028436, "episode/intrinsic_return": 0.2313741819916686}
{"step": 527272, "time": 70585.33091568947, "episode/length": 211.0, "episode/score": 9.348587496378059, "episode/reward_rate": 0.9716981132075472, "episode/intrinsic_return": 0.24858722038061387}
{"step": 527360, "time": 70597.75044941902, "episode/length": 370.0, "episode/score": 13.53113713570201, "episode/reward_rate": 0.9865229110512129, "episode/intrinsic_return": 0.4311367802802124}
{"step": 528024, "time": 70680.26379060745, "episode/length": 205.0, "episode/score": 8.339414007721643, "episode/reward_rate": 0.970873786407767, "episode/intrinsic_return": 0.23941379432653775}
{"step": 528064, "time": 70686.70071268082, "episode/length": 181.0, "episode/score": 11.300011406453905, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.20001115475815823}
{"step": 528288, "time": 70715.47233080864, "episode/length": 196.0, "episode/score": 11.326369309293568, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.22636897113034138}
{"step": 528392, "time": 70729.59120059013, "episode/length": 177.0, "episode/score": 10.293237809297807, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.19323763120564763}
{"step": 528392, "time": 70729.59655213356, "episode/length": 45.0, "episode/score": 4.155833465862088, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.05583333212416619}
{"step": 528648, "time": 70763.70358896255, "episode/length": 44.0, "episode/score": 1.152602361908066, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.052602271709474735}
{"step": 528760, "time": 70778.9937376976, "episode/length": 189.0, "episode/score": 5.262703650699677, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.16270349926662675}
{"step": 529000, "time": 70809.61168169975, "episode/length": 204.0, "episode/score": 8.319580026551193, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.2195797493604914}
{"step": 529184, "time": 70833.45528388023, "episode/length": 238.0, "episode/score": 10.36595415603415, "episode/reward_rate": 0.9707112970711297, "episode/intrinsic_return": 0.2659539412129561}
{"step": 529288, "time": 70847.68042087555, "episode/length": 152.0, "episode/score": 8.268524166074258, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.1685238288423534}
{"step": 529640, "time": 70891.76380634308, "episode/length": 155.0, "episode/score": 9.273541713426312, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.17354140087445558}
{"step": 529848, "time": 70918.85602855682, "episode/length": 356.0, "episode/score": 11.499239664584366, "episode/reward_rate": 0.988795518207283, "episode/intrinsic_return": 0.39923943052554023}
{"step": 530088, "time": 70969.18785858154, "eval_episode/length": 162.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9570552147239264}
{"step": 530088, "time": 70971.23257660866, "eval_episode/length": 174.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9942857142857143}
{"step": 530088, "time": 70972.87075638771, "eval_episode/length": 177.0, "eval_episode/score": 3.0999999791383743, "eval_episode/reward_rate": 0.9943820224719101}
{"step": 530088, "time": 70974.62753129005, "eval_episode/length": 182.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9672131147540983}
{"step": 530088, "time": 70977.69478726387, "eval_episode/length": 217.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9770642201834863}
{"step": 530088, "time": 70982.20151662827, "eval_episode/length": 117.0, "eval_episode/score": 9.100000023841858, "eval_episode/reward_rate": 0.9915254237288136}
{"step": 530088, "time": 70984.1946208477, "eval_episode/length": 293.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9829931972789115}
{"step": 530088, "time": 70988.71209001541, "eval_episode/length": 181.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9725274725274725}
{"step": 530216, "time": 71004.16608834267, "episode/length": 227.0, "episode/score": 11.362370399079282, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.2623700491581076}
{"step": 530424, "time": 71031.22034478188, "episode/length": 221.0, "episode/score": 11.341404662247896, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.2414042838631758}
{"step": 530752, "time": 71072.83663320541, "episode/length": 248.0, "episode/score": 10.391922422849802, "episode/reward_rate": 0.9678714859437751, "episode/intrinsic_return": 0.29192209539678515}
{"step": 530848, "time": 71086.06973862648, "episode/length": 230.0, "episode/score": 7.3541960201027905, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.25419580865764146}
{"step": 531344, "time": 71148.12350797653, "episode/length": 186.0, "episode/score": 6.309972284607738, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.20997211221992984}
{"step": 531392, "time": 71155.5393652916, "episode/length": 275.0, "episode/score": 11.420208507866391, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.3202081626018298}
{"step": 531776, "time": 71203.63684344292, "episode/length": 310.0, "episode/score": 10.446378475198799, "episode/reward_rate": 0.9935691318327974, "episode/intrinsic_return": 0.34637819605814}
{"step": 531976, "time": 71229.4558455944, "episode/length": 291.0, "episode/score": 8.446406024129828, "episode/reward_rate": 0.9691780821917808, "episode/intrinsic_return": 0.34640574708464555}
{"step": 532184, "time": 71256.59107971191, "episode/length": 178.0, "episode/score": 8.291069394633723, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.19106920821786844}
{"step": 532408, "time": 71285.7245798111, "episode/length": 273.0, "episode/score": 11.39897150595425, "episode/reward_rate": 0.9963503649635036, "episode/intrinsic_return": 0.29897108632940217}
{"step": 532768, "time": 71332.43045783043, "episode/length": 171.0, "episode/score": 10.295943491713842, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.19594314342248254}
{"step": 532872, "time": 71346.72589588165, "episode/length": 252.0, "episode/score": 11.381184613922414, "episode/reward_rate": 0.9960474308300395, "episode/intrinsic_return": 0.2811844108882724}
{"step": 532896, "time": 71351.09459996223, "episode/length": 139.0, "episode/score": 8.264541911543347, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.16454166360199451}
{"step": 533229, "time": 71394.12395501137, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.47380869875672, "train/action_min": 0.0, "train/action_std": 3.5516138704874183, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04208515051712272, "train/actor_opt_grad_steps": 131985.0, "train/actor_opt_loss": -8.515451969658976, "train/adv_mag": 0.4717832827760327, "train/adv_max": 0.40887836807517597, "train/adv_mean": 0.002581938935397756, "train/adv_min": -0.39720825306189955, "train/adv_std": 0.05155332718965828, "train/cont_avg": 0.9947811659946236, "train/cont_loss_mean": 0.00016640492970910472, "train/cont_loss_std": 0.005068058482068956, "train/cont_neg_acc": 0.9960445476475582, "train/cont_neg_loss": 0.01939555468520382, "train/cont_pos_acc": 0.9999894243414684, "train/cont_pos_loss": 4.497239070129246e-05, "train/cont_pred": 0.9947901723846313, "train/cont_rate": 0.9947811659946236, "train/dyn_loss_mean": 6.920818705712596, "train/dyn_loss_std": 8.943621614927887, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.115933693224384, "train/extr_critic_critic_opt_grad_steps": 131985.0, "train/extr_critic_critic_opt_loss": 16104.574202998992, "train/extr_critic_mag": 9.494726575830931, "train/extr_critic_max": 9.494726575830931, "train/extr_critic_mean": 2.844801411192904, "train/extr_critic_min": -0.5013525960265949, "train/extr_critic_std": 2.2947713585310083, "train/extr_return_normed_mag": 1.4598090167968505, "train/extr_return_normed_max": 1.4598090167968505, "train/extr_return_normed_mean": 0.41186261689791115, "train/extr_return_normed_min": -0.10484922719338248, "train/extr_return_normed_std": 0.3280354838377686, "train/extr_return_rate": 0.7989349230643241, "train/extr_return_raw_mag": 10.291431539802142, "train/extr_return_raw_max": 10.291431539802142, "train/extr_return_raw_mean": 2.8631023072427317, "train/extr_return_raw_min": -0.7999657289956206, "train/extr_return_raw_std": 2.3254963480016237, "train/extr_reward_mag": 1.038683028631313, "train/extr_reward_max": 1.038683028631313, "train/extr_reward_mean": 0.045337413647963155, "train/extr_reward_min": -0.649264952187897, "train/extr_reward_std": 0.20348027156245324, "train/image_loss_mean": 3.653562136234776, "train/image_loss_std": 8.632624869705529, "train/model_loss_mean": 7.889004468917847, "train/model_loss_std": 12.796071995971023, "train/model_opt_grad_norm": 35.97611072499265, "train/model_opt_grad_steps": 131871.13440860214, "train/model_opt_loss": 13170.293244392642, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1666.6666666666667, "train/policy_entropy_mag": 2.4881478304504068, "train/policy_entropy_max": 2.4881478304504068, "train/policy_entropy_mean": 0.474598757361853, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.5962895609999216, "train/policy_logprob_mag": 7.43838410223684, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.4732591972876621, "train/policy_logprob_min": -7.43838410223684, "train/policy_logprob_std": 1.0576058578106664, "train/policy_randomness_mag": 0.8782069933029913, "train/policy_randomness_max": 0.8782069933029913, "train/policy_randomness_mean": 0.16751253504746705, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.2104640493309626, "train/post_ent_mag": 60.0788395174088, "train/post_ent_max": 60.0788395174088, "train/post_ent_mean": 44.59631407132713, "train/post_ent_min": 19.350619557083295, "train/post_ent_std": 6.963818268109393, "train/prior_ent_mag": 74.9690428703062, "train/prior_ent_max": 74.9690428703062, "train/prior_ent_mean": 51.539978314471504, "train/prior_ent_min": 30.823682938852617, "train/prior_ent_std": 6.706343579035933, "train/rep_loss_mean": 6.920818705712596, "train/rep_loss_std": 8.943621614927887, "train/reward_avg": 0.02777328053289043, "train/reward_loss_mean": 0.08278470478391134, "train/reward_loss_std": 0.19538838368269704, "train/reward_max_data": 1.0136133829752605, "train/reward_max_pred": 1.012516205028821, "train/reward_neg_acc": 0.9982765916214195, "train/reward_neg_loss": 0.05480459092124816, "train/reward_pos_acc": 0.8967354499524639, "train/reward_pos_loss": 0.7614760110455174, "train/reward_pred": 0.027319749962458367, "train/reward_rate": 0.03965578797043011, "train_stats/sum_log_reward": 9.100000283934854, "train_stats/max_log_achievement_collect_coal": 0.3333333333333333, "train_stats/max_log_achievement_collect_drink": 3.3333333333333335, "train_stats/max_log_achievement_collect_sapling": 1.8484848484848484, "train_stats/max_log_achievement_collect_stone": 9.454545454545455, "train_stats/max_log_achievement_collect_wood": 9.030303030303031, "train_stats/max_log_achievement_defeat_skeleton": 0.12121212121212122, "train_stats/max_log_achievement_defeat_zombie": 0.5757575757575758, "train_stats/max_log_achievement_eat_cow": 0.21212121212121213, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.4242424242424243, "train_stats/max_log_achievement_make_wood_sword": 1.303030303030303, "train_stats/max_log_achievement_place_furnace": 0.6060606060606061, "train_stats/max_log_achievement_place_plant": 1.7575757575757576, "train_stats/max_log_achievement_place_stone": 5.242424242424242, "train_stats/max_log_achievement_place_table": 2.5454545454545454, "train_stats/max_log_achievement_wake_up": 1.4848484848484849, "train_stats/mean_log_entropy": 0.4837153919718482, "eval_stats/sum_log_reward": 8.975000321865082, "eval_stats/max_log_achievement_collect_coal": 0.625, "eval_stats/max_log_achievement_collect_drink": 1.875, "eval_stats/max_log_achievement_collect_sapling": 1.375, "eval_stats/max_log_achievement_collect_stone": 5.75, "eval_stats/max_log_achievement_collect_wood": 9.375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.875, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.625, "eval_stats/max_log_achievement_make_wood_sword": 1.125, "eval_stats/max_log_achievement_place_furnace": 0.5, "eval_stats/max_log_achievement_place_plant": 1.25, "eval_stats/max_log_achievement_place_stone": 2.375, "eval_stats/max_log_achievement_place_table": 3.0, "eval_stats/max_log_achievement_wake_up": 1.25, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 2.179076000174973e-05, "report/cont_loss_std": 0.00040500485920347273, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 4.768303188029677e-05, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 2.1612542695947923e-05, "report/cont_pred": 0.9931430220603943, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 8.488155364990234, "report/dyn_loss_std": 9.436288833618164, "report/image_loss_mean": 4.203917026519775, "report/image_loss_std": 10.955657958984375, "report/model_loss_mean": 9.392677307128906, "report/model_loss_std": 15.21773910522461, "report/post_ent_mag": 59.633583068847656, "report/post_ent_max": 59.633583068847656, "report/post_ent_mean": 44.235496520996094, "report/post_ent_min": 17.476856231689453, "report/post_ent_std": 6.777216911315918, "report/prior_ent_mag": 75.12669372558594, "report/prior_ent_max": 75.12669372558594, "report/prior_ent_mean": 52.40644836425781, "report/prior_ent_min": 30.94171905517578, "report/prior_ent_std": 7.673207759857178, "report/rep_loss_mean": 8.488155364990234, "report/rep_loss_std": 9.436288833618164, "report/reward_avg": 0.02702530473470688, "report/reward_loss_mean": 0.09584467858076096, "report/reward_loss_std": 0.2442501038312912, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.002425193786621, "report/reward_neg_acc": 0.9969325065612793, "report/reward_neg_loss": 0.06391943991184235, "report/reward_pos_acc": 0.9130434989929199, "report/reward_pos_loss": 0.774603009223938, "report/reward_pred": 0.02721766009926796, "report/reward_rate": 0.044921875, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.011646985076367855, "eval/cont_loss_std": 0.3723767101764679, "eval/cont_neg_acc": 0.75, "eval/cont_neg_loss": 2.980473041534424, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 4.530362730292836e-06, "eval/cont_pred": 0.9970658421516418, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 16.97722625732422, "eval/dyn_loss_std": 11.42872142791748, "eval/image_loss_mean": 19.093791961669922, "eval/image_loss_std": 28.851940155029297, "eval/model_loss_mean": 29.423885345458984, "eval/model_loss_std": 31.878456115722656, "eval/post_ent_mag": 58.52641677856445, "eval/post_ent_max": 58.52641677856445, "eval/post_ent_mean": 41.75128936767578, "eval/post_ent_min": 21.10967254638672, "eval/post_ent_std": 6.666790962219238, "eval/prior_ent_mag": 75.12669372558594, "eval/prior_ent_max": 75.12669372558594, "eval/prior_ent_mean": 53.07532501220703, "eval/prior_ent_min": 38.96746826171875, "eval/prior_ent_std": 5.462868690490723, "eval/rep_loss_mean": 16.97722625732422, "eval/rep_loss_std": 11.42872142791748, "eval/reward_avg": 0.03496093302965164, "eval/reward_loss_mean": 0.13211211562156677, "eval/reward_loss_std": 0.882032036781311, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0024285316467285, "eval/reward_neg_acc": 0.9868020415306091, "eval/reward_neg_loss": 0.06353107839822769, "eval/reward_pos_acc": 0.8461538553237915, "eval/reward_pos_loss": 1.8642232418060303, "eval/reward_pred": 0.03581304848194122, "eval/reward_rate": 0.0380859375, "replay/size": 532725.0, "replay/inserts": 7452.0, "replay/samples": 29808.0, "replay/insert_wait_avg": 1.6297375202434906e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.512088879039066e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 2920.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1546154544778067e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.195638656616211e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2165715694427, "timer/env.step_count": 931.0, "timer/env.step_total": 76.43831896781921, "timer/env.step_frac": 0.07642176818554368, "timer/env.step_avg": 0.08210345753793685, "timer/env.step_min": 0.023491382598876953, "timer/env.step_max": 3.138737440109253, "timer/replay._sample_count": 29808.0, "timer/replay._sample_total": 14.534799814224243, "timer/replay._sample_frac": 0.0145316526713986, "timer/replay._sample_avg": 0.0004876140571062884, "timer/replay._sample_min": 0.0003795623779296875, "timer/replay._sample_max": 0.018274545669555664, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1296.0, "timer/agent.policy_total": 21.092761039733887, "timer/agent.policy_frac": 0.02108819393647635, "timer/agent.policy_avg": 0.016275278580041578, "timer/agent.policy_min": 0.009764671325683594, "timer/agent.policy_max": 0.06195497512817383, "timer/dataset_train_count": 1863.0, "timer/dataset_train_total": 0.31191396713256836, "timer/dataset_train_frac": 0.00031184643006178475, "timer/dataset_train_avg": 0.00016742563989939258, "timer/dataset_train_min": 9.894371032714844e-05, "timer/dataset_train_max": 0.0008561611175537109, "timer/agent.train_count": 1863.0, "timer/agent.train_total": 836.1009273529053, "timer/agent.train_frac": 0.8359198908702111, "timer/agent.train_avg": 0.4487927683053705, "timer/agent.train_min": 0.43589186668395996, "timer/agent.train_max": 1.0444386005401611, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4749293327331543, "timer/agent.report_frac": 0.00047482649881309334, "timer/agent.report_avg": 0.23746466636657715, "timer/agent.report_min": 0.23117923736572266, "timer/agent.report_max": 0.24375009536743164, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.266334533691406e-05, "timer/dataset_eval_frac": 3.2656272916636356e-08, "timer/dataset_eval_avg": 3.266334533691406e-05, "timer/dataset_eval_min": 3.266334533691406e-05, "timer/dataset_eval_max": 3.266334533691406e-05, "fps": 7.450278614794338}
{"step": 533728, "time": 71455.02827763557, "episode/length": 412.0, "episode/score": 11.493173001907053, "episode/reward_rate": 0.7723970944309927, "episode/intrinsic_return": 0.3931726651262579}
{"step": 533744, "time": 71458.58247494698, "episode/length": 299.0, "episode/score": 10.464195812659455, "episode/reward_rate": 0.9866666666666667, "episode/intrinsic_return": 0.36419551919971127}
{"step": 533952, "time": 71485.55134344101, "episode/length": 220.0, "episode/score": 7.348924855199584, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.24892456185625633}
{"step": 534016, "time": 71494.93755698204, "episode/length": 254.0, "episode/score": 10.391674607621098, "episode/reward_rate": 0.9725490196078431, "episode/intrinsic_return": 0.2916743011228391}
{"step": 534016, "time": 71494.94546723366, "episode/length": 155.0, "episode/score": 6.274818021647661, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.1748178462330543}
{"step": 534464, "time": 71552.98278474808, "episode/length": 198.0, "episode/score": 8.333072779008944, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.23307246878539445}
{"step": 534840, "time": 71600.02427244186, "episode/length": 303.0, "episode/score": 9.449811540096562, "episode/reward_rate": 0.9868421052631579, "episode/intrinsic_return": 0.3498112345296249}
{"step": 535088, "time": 71631.93903946877, "episode/length": 133.0, "episode/score": 7.260708592191804, "episode/reward_rate": 0.9925373134328358, "episode/intrinsic_return": 0.16070833016419783}
{"step": 535168, "time": 71643.35627794266, "episode/length": 143.0, "episode/score": 6.263328465020095, "episode/reward_rate": 0.9652777777777778, "episode/intrinsic_return": 0.16332828727718152}
{"step": 535296, "time": 71660.39780855179, "episode/length": 195.0, "episode/score": 11.323950205178335, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.22394983802769275}
{"step": 535408, "time": 71675.81552672386, "episode/length": 207.0, "episode/score": 8.331659872408636, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.23165960374535643}
{"step": 535504, "time": 71689.05967068672, "episode/length": 325.0, "episode/score": 9.46036413551883, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.36036387069725606}
{"step": 535704, "time": 71715.04198670387, "episode/length": 154.0, "episode/score": 12.278822686874264, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.1788223189087148}
{"step": 536136, "time": 71769.7692387104, "episode/length": 272.0, "episode/score": 10.422702632424262, "episode/reward_rate": 0.9963369963369964, "episode/intrinsic_return": 0.32270234245697793}
{"step": 536416, "time": 71805.7198843956, "episode/length": 125.0, "episode/score": 10.229143765343906, "episode/reward_rate": 0.9920634920634921, "episode/intrinsic_return": 0.1291434139093326}
{"step": 536688, "time": 71840.77851963043, "episode/length": 173.0, "episode/score": 11.275924805538125, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.1759244503782611}
{"step": 536704, "time": 71844.2493391037, "episode/length": 191.0, "episode/score": 8.310424298257203, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.2104240632379515}
{"step": 536848, "time": 71863.71579861641, "episode/length": 167.0, "episode/score": 10.290629853506289, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.1906296257629947}
{"step": 537168, "time": 71904.45345020294, "episode/length": 290.0, "episode/score": 11.41517317086982, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.3151728538359748}
{"step": 537184, "time": 71908.04324293137, "episode/length": 184.0, "episode/score": 8.317443441949763, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.2174432355686804}
{"step": 537640, "time": 71966.0151925087, "episode/length": 152.0, "episode/score": 9.255215509972004, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.15521519980666199}
{"step": 537792, "time": 71986.27418446541, "episode/length": 77.0, "episode/score": 6.1792541006579995, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0792539045214653}
{"step": 537920, "time": 72003.55378818512, "episode/length": 222.0, "episode/score": 9.357233679806086, "episode/reward_rate": 0.9775784753363229, "episode/intrinsic_return": 0.25723347732491675}
{"step": 538272, "time": 72048.47998404503, "episode/length": 195.0, "episode/score": 9.319039160010107, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.21903888028737128}
{"step": 538536, "time": 72082.42138719559, "episode/length": 430.0, "episode/score": 10.59449074015447, "episode/reward_rate": 0.9976798143851509, "episode/intrinsic_return": 0.49449042236392415}
{"step": 538736, "time": 72108.4672756195, "episode/length": 255.0, "episode/score": 10.395344651489722, "episode/reward_rate": 0.99609375, "episode/intrinsic_return": 0.2953444310805935}
{"step": 538816, "time": 72119.74550676346, "episode/length": 146.0, "episode/score": 8.25356568611187, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.15356542495737813}
{"step": 539072, "time": 72152.660435915, "episode/length": 143.0, "episode/score": 8.257696015319198, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.1576957466559179}
{"step": 539136, "time": 72162.51020383835, "episode/length": 285.0, "episode/score": 11.437271156034512, "episode/reward_rate": 0.986013986013986, "episode/intrinsic_return": 0.3372707782900761}
{"step": 539536, "time": 72213.06519842148, "episode/length": 57.0, "episode/score": 5.164749083435709, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.06474894835901068}
{"step": 539632, "time": 72226.31290769577, "episode/length": 305.0, "episode/score": 12.459127248108416, "episode/reward_rate": 0.9901960784313726, "episode/intrinsic_return": 0.3591268210038834}
{"step": 539832, "time": 72252.16419243813, "episode/length": 161.0, "episode/score": 10.28156865263827, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.18156836348589422}
{"step": 539968, "time": 72270.52181887627, "episode/length": 143.0, "episode/score": 10.23825013286114, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.138249769959657}
{"step": 540000, "time": 72275.89731144905, "episode/length": 275.0, "episode/score": 11.42191480529982, "episode/reward_rate": 0.9963768115942029, "episode/intrinsic_return": 0.3219143156657083}
{"step": 540072, "time": 72302.73528194427, "eval_episode/length": 94.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9473684210526315}
{"step": 540072, "time": 72306.51612305641, "eval_episode/length": 144.0, "eval_episode/score": 11.100000008940697, "eval_episode/reward_rate": 0.993103448275862}
{"step": 540072, "time": 72308.36556315422, "eval_episode/length": 154.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.967741935483871}
{"step": 540072, "time": 72310.60521674156, "eval_episode/length": 167.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9761904761904762}
{"step": 540072, "time": 72312.99915766716, "eval_episode/length": 187.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9787234042553191}
{"step": 540072, "time": 72316.17389369011, "eval_episode/length": 54.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9818181818181818}
{"step": 540072, "time": 72318.59706950188, "eval_episode/length": 242.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9958847736625515}
{"step": 540072, "time": 72322.4477815628, "eval_episode/length": 295.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9831081081081081}
{"step": 540649, "time": 72394.25102066994, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.453369140625, "train/action_min": 0.0, "train/action_std": 3.5675296539901407, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04029798122142912, "train/actor_opt_grad_steps": 133845.0, "train/actor_opt_loss": -7.765145216177228, "train/adv_mag": 0.4698636419670556, "train/adv_max": 0.4221332916008529, "train/adv_mean": 0.0028680370310359003, "train/adv_min": -0.38030848011214247, "train/adv_std": 0.05038372192892336, "train/cont_avg": 0.9949334257392473, "train/cont_loss_mean": 6.126737906987928e-05, "train/cont_loss_std": 0.0017453361230404427, "train/cont_neg_acc": 0.9983358940770549, "train/cont_neg_loss": 0.006223804296625044, "train/cont_pos_acc": 0.9999947205025662, "train/cont_pos_loss": 2.3624317779100393e-05, "train/cont_pred": 0.9949335356553396, "train/cont_rate": 0.9949334257392473, "train/dyn_loss_mean": 6.957256137683827, "train/dyn_loss_std": 9.009902572119108, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1183514973168731, "train/extr_critic_critic_opt_grad_steps": 133845.0, "train/extr_critic_critic_opt_loss": 15925.790800361223, "train/extr_critic_mag": 9.556142812134118, "train/extr_critic_max": 9.556142812134118, "train/extr_critic_mean": 2.922253929799603, "train/extr_critic_min": -0.48063741896742135, "train/extr_critic_std": 2.3385697821135163, "train/extr_return_normed_mag": 1.4429791249254698, "train/extr_return_normed_max": 1.4429791249254698, "train/extr_return_normed_mean": 0.4159432883544635, "train/extr_return_normed_min": -0.09444166249245085, "train/extr_return_normed_std": 0.32675787934692957, "train/extr_return_rate": 0.7982495798859545, "train/extr_return_raw_mag": 10.383317127022693, "train/extr_return_raw_max": 10.383317127022693, "train/extr_return_raw_mean": 2.9430043876812024, "train/extr_return_raw_min": -0.7537741013752517, "train/extr_return_raw_std": 2.3671747587060414, "train/extr_reward_mag": 1.0422155857086182, "train/extr_reward_max": 1.0422155857086182, "train/extr_reward_mean": 0.04557063468601755, "train/extr_reward_min": -0.6396092157210073, "train/extr_reward_std": 0.20361693403733674, "train/image_loss_mean": 3.783850496174187, "train/image_loss_std": 9.160664835283834, "train/model_loss_mean": 8.041510694770404, "train/model_loss_std": 13.288426850431708, "train/model_opt_grad_norm": 40.544085652119406, "train/model_opt_grad_steps": 133729.75806451612, "train/model_opt_loss": 12555.44384765625, "train/model_opt_model_opt_grad_overflow": 0.005376344086021506, "train/model_opt_model_opt_grad_scale": 1555.779569892473, "train/policy_entropy_mag": 2.4833518497405516, "train/policy_entropy_max": 2.4833518497405516, "train/policy_entropy_mean": 0.4692937249457964, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.5920234670241674, "train/policy_logprob_mag": 7.438384115055043, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.4695977778524481, "train/policy_logprob_min": -7.438384115055043, "train/policy_logprob_std": 1.0561545555309584, "train/policy_randomness_mag": 0.876514224595921, "train/policy_randomness_max": 0.876514224595921, "train/policy_randomness_mean": 0.16564009010150868, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.2089583034957609, "train/post_ent_mag": 60.272814596852946, "train/post_ent_max": 60.272814596852946, "train/post_ent_mean": 44.657271518502185, "train/post_ent_min": 19.508779982084867, "train/post_ent_std": 7.006380675941386, "train/prior_ent_mag": 74.92416652556389, "train/prior_ent_max": 74.92416652556389, "train/prior_ent_mean": 51.634352427656935, "train/prior_ent_min": 31.13635145207887, "train/prior_ent_std": 6.7435355545372095, "train/rep_loss_mean": 6.957256137683827, "train/rep_loss_std": 9.009902572119108, "train/reward_avg": 0.028611616276565097, "train/reward_loss_mean": 0.08324527235761765, "train/reward_loss_std": 0.19682733181823966, "train/reward_max_data": 1.0157639211223972, "train/reward_max_pred": 1.0148400786102458, "train/reward_neg_acc": 0.9982202056274619, "train/reward_neg_loss": 0.054712998810955274, "train/reward_pos_acc": 0.8933326435345476, "train/reward_pos_loss": 0.7543483950117583, "train/reward_pred": 0.02827847081546982, "train/reward_rate": 0.04076885920698925, "train_stats/sum_log_reward": 9.217647328096277, "train_stats/max_log_achievement_collect_coal": 0.2647058823529412, "train_stats/max_log_achievement_collect_drink": 3.323529411764706, "train_stats/max_log_achievement_collect_sapling": 1.1470588235294117, "train_stats/max_log_achievement_collect_stone": 7.382352941176471, "train_stats/max_log_achievement_collect_wood": 9.588235294117647, "train_stats/max_log_achievement_defeat_skeleton": 0.058823529411764705, "train_stats/max_log_achievement_defeat_zombie": 0.6176470588235294, "train_stats/max_log_achievement_eat_cow": 0.058823529411764705, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.6470588235294117, "train_stats/max_log_achievement_make_wood_sword": 1.1764705882352942, "train_stats/max_log_achievement_place_furnace": 0.5588235294117647, "train_stats/max_log_achievement_place_plant": 1.1470588235294117, "train_stats/max_log_achievement_place_stone": 4.088235294117647, "train_stats/max_log_achievement_place_table": 2.823529411764706, "train_stats/max_log_achievement_wake_up": 1.4705882352941178, "train_stats/mean_log_entropy": 0.46720031780355115, "eval_stats/sum_log_reward": 8.100000202655792, "eval_stats/max_log_achievement_collect_coal": 0.375, "eval_stats/max_log_achievement_collect_drink": 1.625, "eval_stats/max_log_achievement_collect_sapling": 1.0, "eval_stats/max_log_achievement_collect_stone": 3.75, "eval_stats/max_log_achievement_collect_wood": 9.5, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.375, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.375, "eval_stats/max_log_achievement_make_wood_sword": 1.25, "eval_stats/max_log_achievement_place_furnace": 0.5, "eval_stats/max_log_achievement_place_plant": 0.875, "eval_stats/max_log_achievement_place_stone": 0.875, "eval_stats/max_log_achievement_place_table": 2.625, "eval_stats/max_log_achievement_wake_up": 1.125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 5.059677278040908e-06, "report/cont_loss_std": 5.047937520430423e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00032786731026135385, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 4.1111729842668865e-06, "report/cont_pred": 0.9970672130584717, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 6.203974723815918, "report/dyn_loss_std": 8.728501319885254, "report/image_loss_mean": 3.0679075717926025, "report/image_loss_std": 6.588800430297852, "report/model_loss_mean": 6.860957145690918, "report/model_loss_std": 10.737689971923828, "report/post_ent_mag": 59.90620040893555, "report/post_ent_max": 59.90620040893555, "report/post_ent_mean": 45.379432678222656, "report/post_ent_min": 18.08718490600586, "report/post_ent_std": 7.345251083374023, "report/prior_ent_mag": 74.53192138671875, "report/prior_ent_max": 74.53192138671875, "report/prior_ent_mean": 51.57238006591797, "report/prior_ent_min": 30.079912185668945, "report/prior_ent_std": 6.41013765335083, "report/rep_loss_mean": 6.203974723815918, "report/rep_loss_std": 8.728501319885254, "report/reward_avg": 0.019232748076319695, "report/reward_loss_mean": 0.07065930962562561, "report/reward_loss_std": 0.17815999686717987, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0018315315246582, "report/reward_neg_acc": 0.9989949464797974, "report/reward_neg_loss": 0.04896298795938492, "report/reward_pos_acc": 0.8965517282485962, "report/reward_pos_loss": 0.8150672912597656, "report/reward_pred": 0.01838228851556778, "report/reward_rate": 0.0283203125, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.016100291162729263, "eval/cont_loss_std": 0.514396607875824, "eval/cont_neg_acc": 0.8333333730697632, "eval/cont_neg_loss": 2.7472167015075684, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 3.3389408145012567e-06, "eval/cont_pred": 0.9951281547546387, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 18.300790786743164, "eval/dyn_loss_std": 13.031901359558105, "eval/image_loss_mean": 18.645254135131836, "eval/image_loss_std": 33.011531829833984, "eval/model_loss_mean": 29.777729034423828, "eval/model_loss_std": 36.692291259765625, "eval/post_ent_mag": 61.542625427246094, "eval/post_ent_max": 61.542625427246094, "eval/post_ent_mean": 42.22246551513672, "eval/post_ent_min": 19.737483978271484, "eval/post_ent_std": 7.192808628082275, "eval/prior_ent_mag": 74.53192138671875, "eval/prior_ent_max": 74.53192138671875, "eval/prior_ent_mean": 54.05799102783203, "eval/prior_ent_min": 32.19102478027344, "eval/prior_ent_std": 6.851203918457031, "eval/rep_loss_mean": 18.300790786743164, "eval/rep_loss_std": 13.031901359558105, "eval/reward_avg": 0.03291015326976776, "eval/reward_loss_mean": 0.13590069115161896, "eval/reward_loss_std": 0.7858396172523499, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0012199878692627, "eval/reward_neg_acc": 0.9959391355514526, "eval/reward_neg_loss": 0.05129009857773781, "eval/reward_pos_acc": 0.7692307829856873, "eval/reward_pos_loss": 2.2728607654571533, "eval/reward_pred": 0.02465323731303215, "eval/reward_rate": 0.0380859375, "replay/size": 540145.0, "replay/inserts": 7420.0, "replay/samples": 29680.0, "replay/insert_wait_avg": 1.665267018937679e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.640640690641583e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 2368.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1845416313893086e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.791685104370117e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1127412319183, "timer/env.step_count": 928.0, "timer/env.step_total": 78.81466245651245, "timer/env.step_frac": 0.07880577779604145, "timer/env.step_avg": 0.08492959316434531, "timer/env.step_min": 0.024393320083618164, "timer/env.step_max": 3.3424429893493652, "timer/replay._sample_count": 29680.0, "timer/replay._sample_total": 14.676826477050781, "timer/replay._sample_frac": 0.014675171980083133, "timer/replay._sample_avg": 0.0004945022397928161, "timer/replay._sample_min": 0.0003402233123779297, "timer/replay._sample_max": 0.026167869567871094, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1224.0, "timer/agent.policy_total": 20.23288106918335, "timer/agent.policy_frac": 0.020230600246389126, "timer/agent.policy_avg": 0.016530131592470056, "timer/agent.policy_min": 0.009716033935546875, "timer/agent.policy_max": 0.04328513145446777, "timer/dataset_train_count": 1855.0, "timer/dataset_train_total": 0.3180060386657715, "timer/dataset_train_frac": 0.0003179701903148021, "timer/dataset_train_avg": 0.0001714318267740008, "timer/dataset_train_min": 0.00010204315185546875, "timer/dataset_train_max": 0.0005757808685302734, "timer/agent.train_count": 1855.0, "timer/agent.train_total": 834.3136358261108, "timer/agent.train_frac": 0.8342195848824208, "timer/agent.train_avg": 0.4497647632485773, "timer/agent.train_min": 0.4351503849029541, "timer/agent.train_max": 0.5898964405059814, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47598934173583984, "timer/agent.report_frac": 0.0004759356841604937, "timer/agent.report_avg": 0.23799467086791992, "timer/agent.report_min": 0.23069214820861816, "timer/agent.report_max": 0.24529719352722168, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0040740966796875e-05, "timer/dataset_eval_frac": 3.00373545184449e-08, "timer/dataset_eval_avg": 3.0040740966796875e-05, "timer/dataset_eval_min": 3.0040740966796875e-05, "timer/dataset_eval_max": 3.0040740966796875e-05, "fps": 7.419047620048849}
{"step": 540736, "time": 72406.35936141014, "episode/length": 149.0, "episode/score": 7.25687943437697, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.1568793403366726}
{"step": 540840, "time": 72420.67296671867, "episode/length": 320.0, "episode/score": 8.46514794703944, "episode/reward_rate": 0.9781931464174455, "episode/intrinsic_return": 0.3651477323346626}
{"step": 541000, "time": 72441.99851107597, "episode/length": 232.0, "episode/score": 10.37749098810309, "episode/reward_rate": 0.9699570815450643, "episode/intrinsic_return": 0.2774907004641136}
{"step": 541088, "time": 72454.52043604851, "episode/length": 156.0, "episode/score": 10.264522947617479, "episode/reward_rate": 0.9808917197452229, "episode/intrinsic_return": 0.1645226644604918}
{"step": 541216, "time": 72471.83016967773, "episode/length": 155.0, "episode/score": 11.288000332948286, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.1879999961820431}
{"step": 541312, "time": 72485.33949947357, "episode/length": 321.0, "episode/score": 9.47270409039811, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.37270381847520184}
{"step": 541376, "time": 72494.80085372925, "episode/length": 217.0, "episode/score": 8.35009375478603, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.25009359107116325}
{"step": 541720, "time": 72538.31903123856, "episode/length": 214.0, "episode/score": 11.340759344088383, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.24075896480144365}
{"step": 542016, "time": 72576.043364048, "episode/length": 159.0, "episode/score": 3.2828179994235143, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.182817820632863}
{"step": 542056, "time": 72582.59550714493, "episode/length": 151.0, "episode/score": 8.272673225222206, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.17267296459158388}
{"step": 542432, "time": 72630.09382677078, "episode/length": 151.0, "episode/score": 11.281584536016453, "episode/reward_rate": 0.9539473684210527, "episode/intrinsic_return": 0.18158418958773836}
{"step": 542496, "time": 72639.52661061287, "episode/length": 139.0, "episode/score": 7.250225509880693, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.15022528627014253}
{"step": 542520, "time": 72643.97458195686, "episode/length": 178.0, "episode/score": 12.305316602258245, "episode/reward_rate": 0.9664804469273743, "episode/intrinsic_return": 0.2053162697411608}
{"step": 543264, "time": 72737.11605906487, "episode/length": 192.0, "episode/score": 11.312338701725821, "episode/reward_rate": 0.9637305699481865, "episode/intrinsic_return": 0.21233838399348315}
{"step": 543288, "time": 72741.5119407177, "episode/length": 285.0, "episode/score": 11.435968840436544, "episode/reward_rate": 0.986013986013986, "episode/intrinsic_return": 0.3359685998875648}
{"step": 543288, "time": 72741.52320122719, "episode/length": 246.0, "episode/score": 9.395339569011412, "episode/reward_rate": 0.97165991902834, "episode/intrinsic_return": 0.29533927985903574}
{"step": 543896, "time": 72819.91968560219, "episode/length": 174.0, "episode/score": 10.300865758305008, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.20086549843108514}
{"step": 543904, "time": 72822.38702511787, "episode/length": 235.0, "episode/score": 9.3732274050235, "episode/reward_rate": 0.9788135593220338, "episode/intrinsic_return": 0.2732271413660783}
{"step": 543912, "time": 72824.81131911278, "episode/length": 173.0, "episode/score": 9.297831983363722, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.1978316570748575}
{"step": 543992, "time": 72836.08762311935, "episode/length": 241.0, "episode/score": 11.394131360295432, "episode/reward_rate": 0.9958677685950413, "episode/intrinsic_return": 0.29413097463475424}
{"step": 544520, "time": 72902.11527466774, "episode/length": 153.0, "episode/score": 5.244691330763089, "episode/reward_rate": 0.961038961038961, "episode/intrinsic_return": 0.14469115267093002}
{"step": 544992, "time": 72961.67281484604, "episode/length": 212.0, "episode/score": 8.34847849336984, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.2484781930124882}
{"step": 545144, "time": 72981.69768691063, "episode/length": 338.0, "episode/score": 10.49903502804591, "episode/reward_rate": 0.9970501474926253, "episode/intrinsic_return": 0.3990347246908641}
{"step": 545344, "time": 73008.0701019764, "episode/length": 168.0, "episode/score": 9.27482222490653, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.17482224361447152}
{"step": 545768, "time": 73061.44057178497, "episode/length": 232.0, "episode/score": 11.363525935239522, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.26352563293221465}
{"step": 545824, "time": 73069.81043624878, "episode/length": 319.0, "episode/score": 13.480815217084455, "episode/reward_rate": 0.98125, "episode/intrinsic_return": 0.38081477612649905}
{"step": 546000, "time": 73092.8527917862, "episode/length": 260.0, "episode/score": 8.38968410018606, "episode/reward_rate": 0.9846743295019157, "episode/intrinsic_return": 0.28968385981170286}
{"step": 546096, "time": 73106.01771616936, "episode/length": 274.0, "episode/score": 11.395448476037927, "episode/reward_rate": 0.9963636363636363, "episode/intrinsic_return": 0.295448068607584}
{"step": 546216, "time": 73122.37325072289, "episode/length": 48.0, "episode/score": 6.153893185011839, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0538929516224016}
{"step": 546264, "time": 73129.88133478165, "episode/length": 217.0, "episode/score": 12.349993426363653, "episode/reward_rate": 0.981651376146789, "episode/intrinsic_return": 0.24999313214721042}
{"step": 546568, "time": 73168.75819015503, "episode/length": 196.0, "episode/score": 8.322593939297803, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.2225937025323219}
{"step": 546936, "time": 73215.1972618103, "episode/length": 145.0, "episode/score": 9.264701029837852, "episode/reward_rate": 0.9726027397260274, "episode/intrinsic_return": 0.16470077700705588}
{"step": 546944, "time": 73217.61034035683, "episode/length": 224.0, "episode/score": 8.368995549943065, "episode/reward_rate": 0.9822222222222222, "episode/intrinsic_return": 0.268995283608092}
{"step": 547288, "time": 73260.89064407349, "episode/length": 242.0, "episode/score": 10.393715575279202, "episode/reward_rate": 0.9711934156378601, "episode/intrinsic_return": 0.2937152718077414}
{"step": 547704, "time": 73313.1618874073, "episode/length": 212.0, "episode/score": 12.33756553031344, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.23756511717874673}
{"step": 547768, "time": 73322.61360263824, "episode/length": 193.0, "episode/score": 8.315010729368623, "episode/reward_rate": 0.9896907216494846, "episode/intrinsic_return": 0.215010560880728}
{"step": 547776, "time": 73325.0702700615, "episode/length": 209.0, "episode/score": 4.3529306745213034, "episode/reward_rate": 0.9809523809523809, "episode/intrinsic_return": 0.25293055056226876}
{"step": 547952, "time": 73347.82909154892, "episode/length": 172.0, "episode/score": 7.29667158799748, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.19667132247741392}
{"step": 548313, "time": 73394.3750705719, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.385659422549902, "train/action_min": 0.0, "train/action_std": 3.4626344523504766, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04178997431516023, "train/actor_opt_grad_steps": 135730.0, "train/actor_opt_loss": -7.918992776755263, "train/adv_mag": 0.4738197382832073, "train/adv_max": 0.412115725079132, "train/adv_mean": 0.0029632288640412925, "train/adv_min": -0.39126482465504353, "train/adv_std": 0.0518932280506139, "train/cont_avg": 0.9946416884816754, "train/cont_loss_mean": 0.00014858994899072576, "train/cont_loss_std": 0.004058397577004136, "train/cont_neg_acc": 0.9963533840681377, "train/cont_neg_loss": 0.01400151239624967, "train/cont_pos_acc": 0.9999794176735803, "train/cont_pos_loss": 6.705168398483567e-05, "train/cont_pred": 0.9946318540273537, "train/cont_rate": 0.9946416884816754, "train/dyn_loss_mean": 6.976005531730452, "train/dyn_loss_std": 9.035084364926004, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.129639110015949, "train/extr_critic_critic_opt_grad_steps": 135730.0, "train/extr_critic_critic_opt_loss": 16280.084551906086, "train/extr_critic_mag": 9.767152192080832, "train/extr_critic_max": 9.767152192080832, "train/extr_critic_mean": 2.992930869781534, "train/extr_critic_min": -0.4684050207986882, "train/extr_critic_std": 2.388854258971689, "train/extr_return_normed_mag": 1.4516673244106832, "train/extr_return_normed_max": 1.4516673244106832, "train/extr_return_normed_mean": 0.41912736778796034, "train/extr_return_normed_min": -0.09174915059854848, "train/extr_return_normed_std": 0.32979448958841295, "train/extr_return_rate": 0.7962563827399808, "train/extr_return_raw_mag": 10.592799091838417, "train/extr_return_raw_max": 10.592799091838417, "train/extr_return_raw_mean": 3.014655918975151, "train/extr_return_raw_min": -0.7350642799706983, "train/extr_return_raw_std": 2.4207221194711654, "train/extr_reward_mag": 1.03940045147042, "train/extr_reward_max": 1.03940045147042, "train/extr_reward_mean": 0.0467141324859015, "train/extr_reward_min": -0.6461383953144413, "train/extr_reward_std": 0.2065480924869707, "train/image_loss_mean": 3.7318702892483215, "train/image_loss_std": 8.85677712125928, "train/model_loss_mean": 8.002384982183965, "train/model_loss_std": 13.062459316553246, "train/model_opt_grad_norm": 36.461014188396994, "train/model_opt_grad_steps": 135613.0, "train/model_opt_loss": 7605.820706192736, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 952.2251308900524, "train/policy_entropy_mag": 2.5358584713561374, "train/policy_entropy_max": 2.5358584713561374, "train/policy_entropy_mean": 0.4514359995644754, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.5828777209938508, "train/policy_logprob_mag": 7.438384143469845, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.45103957312893495, "train/policy_logprob_min": -7.438384143469845, "train/policy_logprob_std": 1.0447342720331323, "train/policy_randomness_mag": 0.8950467577779481, "train/policy_randomness_max": 0.8950467577779481, "train/policy_randomness_mean": 0.15933709821775946, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.20573025692195793, "train/post_ent_mag": 60.066995371074576, "train/post_ent_max": 60.066995371074576, "train/post_ent_mean": 44.54776264610091, "train/post_ent_min": 19.5361423692154, "train/post_ent_std": 6.976680111510591, "train/prior_ent_mag": 74.89505236560761, "train/prior_ent_max": 74.89505236560761, "train/prior_ent_mean": 51.543861389160156, "train/prior_ent_min": 31.06950972592019, "train/prior_ent_std": 6.746292488737256, "train/rep_loss_mean": 6.976005531730452, "train/rep_loss_std": 9.035084364926004, "train/reward_avg": 0.028821758725997352, "train/reward_loss_mean": 0.08476280370307843, "train/reward_loss_std": 0.2057138049477682, "train/reward_max_data": 1.0169546572949875, "train/reward_max_pred": 1.0159964274361495, "train/reward_neg_acc": 0.9981684818941885, "train/reward_neg_loss": 0.05563857810113443, "train/reward_pos_acc": 0.890697419331336, "train/reward_pos_loss": 0.7629357538922295, "train/reward_pred": 0.028451501957448052, "train/reward_rate": 0.04130705988219895, "train_stats/sum_log_reward": 9.152631734546862, "train_stats/max_log_achievement_collect_coal": 0.47368421052631576, "train_stats/max_log_achievement_collect_drink": 3.1842105263157894, "train_stats/max_log_achievement_collect_sapling": 1.368421052631579, "train_stats/max_log_achievement_collect_stone": 6.421052631578948, "train_stats/max_log_achievement_collect_wood": 10.342105263157896, "train_stats/max_log_achievement_defeat_skeleton": 0.10526315789473684, "train_stats/max_log_achievement_defeat_zombie": 0.5526315789473685, "train_stats/max_log_achievement_eat_cow": 0.13157894736842105, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.6578947368421053, "train_stats/max_log_achievement_make_wood_sword": 1.1578947368421053, "train_stats/max_log_achievement_place_furnace": 0.5789473684210527, "train_stats/max_log_achievement_place_plant": 1.368421052631579, "train_stats/max_log_achievement_place_stone": 3.1842105263157894, "train_stats/max_log_achievement_place_table": 3.1578947368421053, "train_stats/max_log_achievement_wake_up": 1.3157894736842106, "train_stats/mean_log_entropy": 0.48665198801379456, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 2.5921861379174516e-05, "report/cont_loss_std": 0.0005330302519723773, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00019432601402513683, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 2.4762735847616568e-05, "report/cont_pred": 0.9931409358978271, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 6.819027900695801, "report/dyn_loss_std": 9.156076431274414, "report/image_loss_mean": 3.407435655593872, "report/image_loss_std": 8.615532875061035, "report/model_loss_mean": 7.575523376464844, "report/model_loss_std": 12.964727401733398, "report/post_ent_mag": 59.30543518066406, "report/post_ent_max": 59.30543518066406, "report/post_ent_mean": 44.809478759765625, "report/post_ent_min": 20.627674102783203, "report/post_ent_std": 6.817974090576172, "report/prior_ent_mag": 75.12886047363281, "report/prior_ent_max": 75.12886047363281, "report/prior_ent_mean": 51.91632080078125, "report/prior_ent_min": 29.34054183959961, "report/prior_ent_std": 6.8030195236206055, "report/rep_loss_mean": 6.819027900695801, "report/rep_loss_std": 9.156076431274414, "report/reward_avg": 0.022651253268122673, "report/reward_loss_mean": 0.07664524763822556, "report/reward_loss_std": 0.16558967530727386, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0018258094787598, "report/reward_neg_acc": 0.9989878535270691, "report/reward_neg_loss": 0.054788652807474136, "report/reward_pos_acc": 0.7777777910232544, "report/reward_pos_loss": 0.6764875054359436, "report/reward_pred": 0.0234951451420784, "report/reward_rate": 0.03515625, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 7.014250877546147e-05, "eval/cont_loss_std": 0.001962526235729456, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.012913445010781288, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 7.123350769688841e-06, "eval/cont_pred": 0.995171308517456, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 18.17086410522461, "eval/dyn_loss_std": 12.11172103881836, "eval/image_loss_mean": 19.13787841796875, "eval/image_loss_std": 18.594539642333984, "eval/model_loss_mean": 30.164356231689453, "eval/model_loss_std": 23.211288452148438, "eval/post_ent_mag": 59.5111083984375, "eval/post_ent_max": 59.5111083984375, "eval/post_ent_mean": 41.06793212890625, "eval/post_ent_min": 20.94876480102539, "eval/post_ent_std": 6.989469528198242, "eval/prior_ent_mag": 75.12886047363281, "eval/prior_ent_max": 75.12886047363281, "eval/prior_ent_mean": 53.7552490234375, "eval/prior_ent_min": 37.649574279785156, "eval/prior_ent_std": 6.026501178741455, "eval/rep_loss_mean": 18.17086410522461, "eval/rep_loss_std": 12.11172103881836, "eval/reward_avg": 0.02031249925494194, "eval/reward_loss_mean": 0.12388892471790314, "eval/reward_loss_std": 0.7569396495819092, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0018126964569092, "eval/reward_neg_acc": 0.9959959983825684, "eval/reward_neg_loss": 0.05458013713359833, "eval/reward_pos_acc": 0.6399999856948853, "eval/reward_pos_loss": 2.893467903137207, "eval/reward_pred": 0.013634547591209412, "eval/reward_rate": 0.0244140625, "replay/size": 547809.0, "replay/inserts": 7664.0, "replay/samples": 30656.0, "replay/insert_wait_avg": 1.6814047210151816e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.512876161204997e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 8.493661880493164e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1098756790161, "timer/env.step_count": 958.0, "timer/env.step_total": 85.08900737762451, "timer/env.step_frac": 0.0850796591923003, "timer/env.step_avg": 0.08881942314992121, "timer/env.step_min": 0.023723363876342773, "timer/env.step_max": 3.3400228023529053, "timer/replay._sample_count": 30656.0, "timer/replay._sample_total": 15.08693790435791, "timer/replay._sample_frac": 0.01508528039893093, "timer/replay._sample_avg": 0.0004921365443749319, "timer/replay._sample_min": 0.00038743019104003906, "timer/replay._sample_max": 0.010649681091308594, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 958.0, "timer/agent.policy_total": 15.73802661895752, "timer/agent.policy_frac": 0.015736297582575436, "timer/agent.policy_avg": 0.016428002733776117, "timer/agent.policy_min": 0.014648914337158203, "timer/agent.policy_max": 0.06676197052001953, "timer/dataset_train_count": 1916.0, "timer/dataset_train_total": 0.32476305961608887, "timer/dataset_train_frac": 0.00032472737997471903, "timer/dataset_train_avg": 0.000169500553035537, "timer/dataset_train_min": 9.846687316894531e-05, "timer/dataset_train_max": 0.0009415149688720703, "timer/agent.train_count": 1916.0, "timer/agent.train_total": 863.2445285320282, "timer/agent.train_frac": 0.8631496893738158, "timer/agent.train_avg": 0.45054516102924225, "timer/agent.train_min": 0.43665051460266113, "timer/agent.train_max": 1.0492582321166992, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47446656227111816, "timer/agent.report_frac": 0.00047441443566286466, "timer/agent.report_avg": 0.23723328113555908, "timer/agent.report_min": 0.23041915893554688, "timer/agent.report_max": 0.2440474033355713, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0517578125e-05, "timer/dataset_eval_frac": 3.0514225353769604e-08, "timer/dataset_eval_avg": 3.0517578125e-05, "timer/dataset_eval_min": 3.0517578125e-05, "timer/dataset_eval_max": 3.0517578125e-05, "fps": 7.663041257493429}
{"step": 548376, "time": 73401.92306613922, "episode/length": 178.0, "episode/score": 10.298890832951656, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.1988904903500952}
{"step": 548816, "time": 73457.84747982025, "episode/length": 190.0, "episode/score": 5.319500313796198, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.21950019073938165}
{"step": 548912, "time": 73472.77057600021, "episode/length": 246.0, "episode/score": 8.3860123122995, "episode/reward_rate": 0.9838056680161943, "episode/intrinsic_return": 0.286012126116475}
{"step": 549088, "time": 73495.75786376, "episode/length": 164.0, "episode/score": 7.289050667604897, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.18905041267862543}
{"step": 549088, "time": 73495.76617598534, "episode/length": 172.0, "episode/score": 8.293124772547344, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.1931245351997859}
{"step": 549480, "time": 73546.86411237717, "episode/length": 82.0, "episode/score": 5.1797855576305665, "episode/reward_rate": 0.9879518072289156, "episode/intrinsic_return": 0.07978539263513085}
{"step": 549712, "time": 73577.6041135788, "episode/length": 430.0, "episode/score": 9.533545490657161, "episode/reward_rate": 0.9907192575406032, "episode/intrinsic_return": 0.43354527356586914}
{"step": 549912, "time": 73603.5143930912, "episode/length": 266.0, "episode/score": 6.401261220626111, "episode/reward_rate": 0.9812734082397003, "episode/intrinsic_return": 0.301261113721921}
{"step": 550056, "time": 73642.35315275192, "eval_episode/length": 159.0, "eval_episode/score": 8.100000023841858, "eval_episode/reward_rate": 0.99375}
{"step": 550056, "time": 73643.98000478745, "eval_episode/length": 163.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9573170731707317}
{"step": 550056, "time": 73646.94992303848, "eval_episode/length": 192.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9740932642487047}
{"step": 550056, "time": 73652.75932836533, "eval_episode/length": 237.0, "eval_episode/score": 12.100000001490116, "eval_episode/reward_rate": 0.9663865546218487}
{"step": 550056, "time": 73656.32150912285, "eval_episode/length": 281.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9787234042553191}
{"step": 550056, "time": 73659.85033130646, "eval_episode/length": 168.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9763313609467456}
{"step": 550056, "time": 73662.0043091774, "eval_episode/length": 150.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9668874172185431}
{"step": 550056, "time": 73664.04114985466, "eval_episode/length": 357.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9888268156424581}
{"step": 550160, "time": 73676.76183128357, "episode/length": 133.0, "episode/score": 7.247335248252966, "episode/reward_rate": 0.9925373134328358, "episode/intrinsic_return": 0.1473350462374583}
{"step": 550208, "time": 73684.31957268715, "episode/length": 281.0, "episode/score": 11.438760304138668, "episode/reward_rate": 0.9964539007092199, "episode/intrinsic_return": 0.3387599534025867}
{"step": 550224, "time": 73687.76328587532, "episode/length": 163.0, "episode/score": 9.263812806487294, "episode/reward_rate": 0.9817073170731707, "episode/intrinsic_return": 0.16381277903656155}
{"step": 550624, "time": 73738.41576552391, "episode/length": 191.0, "episode/score": 11.31606971893325, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.21606934281862777}
{"step": 550672, "time": 73745.85331630707, "episode/length": 148.0, "episode/score": 7.265995685258531, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.16599535384739283}
{"step": 551312, "time": 73825.57668662071, "episode/length": 143.0, "episode/score": 8.27354191656923, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.17354166315635666}
{"step": 551696, "time": 73874.03678321838, "episode/length": 183.0, "episode/score": 10.311035555943818, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.2110352774434432}
{"step": 551768, "time": 73884.74526381493, "episode/length": 231.0, "episode/score": 11.36890000137737, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.2688996052393122}
{"step": 551800, "time": 73890.28518080711, "episode/length": 427.0, "episode/score": 8.5002598688111, "episode/reward_rate": 0.9088785046728972, "episode/intrinsic_return": 0.40025960384400605}
{"step": 552064, "time": 73924.03688097, "episode/length": 179.0, "episode/score": 8.295367563749096, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.1953673599873582}
{"step": 552128, "time": 73933.45114421844, "episode/length": 181.0, "episode/score": 9.302282711989847, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.2022824816854154}
{"step": 552208, "time": 73944.91181659698, "episode/length": 311.0, "episode/score": 11.459659527260555, "episode/reward_rate": 0.9903846153846154, "episode/intrinsic_return": 0.35965920399848983}
{"step": 552824, "time": 74021.26946496964, "episode/length": 326.0, "episode/score": 12.474564014735734, "episode/reward_rate": 0.9877675840978594, "episode/intrinsic_return": 0.3745636550356721}
{"step": 553000, "time": 74044.19059062004, "episode/length": 210.0, "episode/score": 11.339483089162513, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.23948277099361803}
{"step": 553064, "time": 74053.41096234322, "episode/length": 170.0, "episode/score": 7.300311567178596, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.20031132715348576}
{"step": 553400, "time": 74096.17355203629, "episode/length": 199.0, "episode/score": 8.311579790628457, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.21157960005075438}
{"step": 553472, "time": 74106.64098906517, "episode/length": 175.0, "episode/score": 8.301922738645771, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.20192250793388666}
{"step": 553648, "time": 74129.54168343544, "episode/length": 179.0, "episode/score": 9.301411394674687, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.20141109465203044}
{"step": 553976, "time": 74171.18340396881, "episode/length": 230.0, "episode/score": 12.37608960349462, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.27608928020345047}
{"step": 554336, "time": 74216.61642408371, "episode/length": 320.0, "episode/score": 12.463823164280711, "episode/reward_rate": 0.9813084112149533, "episode/intrinsic_return": 0.3638227765245574}
{"step": 554384, "time": 74224.06651067734, "episode/length": 164.0, "episode/score": 6.288209611169805, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.1882093991862348}
{"step": 554784, "time": 74274.78415679932, "episode/length": 163.0, "episode/score": 6.274761526113252, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.17476136533787212}
{"step": 554824, "time": 74281.31357622147, "episode/length": 227.0, "episode/score": 11.367754263011193, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.26775388023179403}
{"step": 555104, "time": 74317.31670856476, "episode/length": 181.0, "episode/score": 8.305458343386363, "episode/reward_rate": 0.967032967032967, "episode/intrinsic_return": 0.20545816063759048}
{"step": 555224, "time": 74333.3620083332, "episode/length": 299.0, "episode/score": 11.442456626123658, "episode/reward_rate": 0.99, "episode/intrinsic_return": 0.34245627271002377}
{"step": 555709, "time": 74394.68416333199, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.448702425570102, "train/action_min": 0.0, "train/action_std": 3.5140197341506547, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04079605074146309, "train/actor_opt_grad_steps": 137610.0, "train/actor_opt_loss": -9.579425924056133, "train/adv_mag": 0.47305767077046473, "train/adv_max": 0.42217951827758066, "train/adv_mean": 0.0021287854142035545, "train/adv_min": -0.3860064623323647, "train/adv_std": 0.049683482663051504, "train/cont_avg": 0.9948110219594595, "train/cont_loss_mean": 0.00012540990497237126, "train/cont_loss_std": 0.0038483093458714355, "train/cont_neg_acc": 0.9959759763769201, "train/cont_neg_loss": 0.009395904489373011, "train/cont_pos_acc": 0.999989361698563, "train/cont_pos_loss": 6.480073190481242e-05, "train/cont_pred": 0.9948112207490045, "train/cont_rate": 0.9948110219594595, "train/dyn_loss_mean": 6.99130463213534, "train/dyn_loss_std": 8.975896459012418, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.081160373945494, "train/extr_critic_critic_opt_grad_steps": 137610.0, "train/extr_critic_critic_opt_loss": 15978.363835515203, "train/extr_critic_mag": 9.987973084320894, "train/extr_critic_max": 9.987973084320894, "train/extr_critic_mean": 3.0794860672306372, "train/extr_critic_min": -0.4742445301365208, "train/extr_critic_std": 2.4570506534060916, "train/extr_return_normed_mag": 1.4361807410781449, "train/extr_return_normed_max": 1.4361807410781449, "train/extr_return_normed_mean": 0.4191334490840499, "train/extr_return_normed_min": -0.09623004663232211, "train/extr_return_normed_std": 0.32929582273637925, "train/extr_return_rate": 0.7926960568170289, "train/extr_return_raw_mag": 10.771597970498576, "train/extr_return_raw_max": 10.771597970498576, "train/extr_return_raw_mean": 3.0955404951765733, "train/extr_return_raw_min": -0.7939239337637618, "train/extr_return_raw_std": 2.4853581538071503, "train/extr_reward_mag": 1.042078395791956, "train/extr_reward_max": 1.042078395791956, "train/extr_reward_mean": 0.044945567373085665, "train/extr_reward_min": -0.6625889771693462, "train/extr_reward_std": 0.2028917306178325, "train/image_loss_mean": 3.7578770431312356, "train/image_loss_std": 8.798257781363823, "train/model_loss_mean": 8.035750048869366, "train/model_loss_std": 12.96025923651618, "train/model_opt_grad_norm": 36.355546940983956, "train/model_opt_grad_steps": 137492.07027027028, "train/model_opt_loss": 13092.067491026182, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1628.3783783783783, "train/policy_entropy_mag": 2.5157559369061446, "train/policy_entropy_max": 2.5157559369061446, "train/policy_entropy_mean": 0.4672729988355894, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6014370272288452, "train/policy_logprob_mag": 7.438384128261257, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.46769646261189435, "train/policy_logprob_min": -7.438384128261257, "train/policy_logprob_std": 1.05659650531975, "train/policy_randomness_mag": 0.8879514452573415, "train/policy_randomness_max": 0.8879514452573415, "train/policy_randomness_mean": 0.16492686187093322, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.21228087834409765, "train/post_ent_mag": 60.019112684920024, "train/post_ent_max": 60.019112684920024, "train/post_ent_mean": 44.58499891951278, "train/post_ent_min": 19.601328478632748, "train/post_ent_std": 6.984688995979928, "train/prior_ent_mag": 74.94642288620408, "train/prior_ent_max": 74.94642288620408, "train/prior_ent_mean": 51.62559366999446, "train/prior_ent_min": 31.261004040692303, "train/prior_ent_std": 6.732535522048538, "train/rep_loss_mean": 6.99130463213534, "train/rep_loss_std": 8.975896459012418, "train/reward_avg": 0.02854377843842313, "train/reward_loss_mean": 0.08296480637949866, "train/reward_loss_std": 0.19149182406631676, "train/reward_max_data": 1.0196284113703546, "train/reward_max_pred": 1.0176930556426178, "train/reward_neg_acc": 0.9981877913346162, "train/reward_neg_loss": 0.0548861189871221, "train/reward_pos_acc": 0.8932938743282008, "train/reward_pos_loss": 0.7439613339063283, "train/reward_pred": 0.02828337515930872, "train/reward_rate": 0.040772804054054056, "train_stats/sum_log_reward": 8.857575951200543, "train_stats/max_log_achievement_collect_coal": 0.21212121212121213, "train_stats/max_log_achievement_collect_drink": 3.757575757575758, "train_stats/max_log_achievement_collect_sapling": 1.1818181818181819, "train_stats/max_log_achievement_collect_stone": 7.636363636363637, "train_stats/max_log_achievement_collect_wood": 9.727272727272727, "train_stats/max_log_achievement_defeat_skeleton": 0.030303030303030304, "train_stats/max_log_achievement_defeat_zombie": 0.7272727272727273, "train_stats/max_log_achievement_eat_cow": 0.15151515151515152, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 2.0606060606060606, "train_stats/max_log_achievement_make_wood_sword": 1.121212121212121, "train_stats/max_log_achievement_place_furnace": 0.6666666666666666, "train_stats/max_log_achievement_place_plant": 1.1515151515151516, "train_stats/max_log_achievement_place_stone": 4.0, "train_stats/max_log_achievement_place_table": 2.696969696969697, "train_stats/max_log_achievement_wake_up": 1.3333333333333333, "train_stats/mean_log_entropy": 0.4912435358220881, "eval_stats/sum_log_reward": 8.475000083446503, "eval_stats/max_log_achievement_collect_coal": 0.5, "eval_stats/max_log_achievement_collect_drink": 6.125, "eval_stats/max_log_achievement_collect_sapling": 0.75, "eval_stats/max_log_achievement_collect_stone": 8.125, "eval_stats/max_log_achievement_collect_wood": 8.0, "eval_stats/max_log_achievement_defeat_skeleton": 0.125, "eval_stats/max_log_achievement_defeat_zombie": 0.375, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.5, "eval_stats/max_log_achievement_make_wood_sword": 1.125, "eval_stats/max_log_achievement_place_furnace": 0.25, "eval_stats/max_log_achievement_place_plant": 0.75, "eval_stats/max_log_achievement_place_stone": 6.25, "eval_stats/max_log_achievement_place_table": 2.125, "eval_stats/max_log_achievement_wake_up": 1.625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 8.648034963698592e-07, "report/cont_loss_std": 5.515013981494121e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 1.5176765089108812e-07, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 8.683021519573231e-07, "report/cont_pred": 0.9951163530349731, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 7.874067783355713, "report/dyn_loss_std": 9.64835262298584, "report/image_loss_mean": 3.560938835144043, "report/image_loss_std": 8.81908893585205, "report/model_loss_mean": 8.367340087890625, "report/model_loss_std": 13.567083358764648, "report/post_ent_mag": 62.68427658081055, "report/post_ent_max": 62.68427658081055, "report/post_ent_mean": 44.063377380371094, "report/post_ent_min": 21.24987030029297, "report/post_ent_std": 7.443114280700684, "report/prior_ent_mag": 74.62089538574219, "report/prior_ent_max": 74.62089538574219, "report/prior_ent_mean": 51.94425964355469, "report/prior_ent_min": 29.911914825439453, "report/prior_ent_std": 6.71465539932251, "report/rep_loss_mean": 7.874067783355713, "report/rep_loss_std": 9.64835262298584, "report/reward_avg": 0.032998085021972656, "report/reward_loss_mean": 0.08195929229259491, "report/reward_loss_std": 0.22589537501335144, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0035877227783203, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.04877233877778053, "report/reward_pos_acc": 0.9523809552192688, "report/reward_pos_loss": 0.8579019904136658, "report/reward_pred": 0.030682731419801712, "report/reward_rate": 0.041015625, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 7.138532964745536e-07, "eval/cont_loss_std": 2.3130144199967617e-06, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 9.547951549393474e-07, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 7.126710670490866e-07, "eval/cont_pred": 0.9951165318489075, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 19.966449737548828, "eval/dyn_loss_std": 12.366562843322754, "eval/image_loss_mean": 20.058849334716797, "eval/image_loss_std": 24.093149185180664, "eval/model_loss_mean": 32.14699935913086, "eval/model_loss_std": 28.6417179107666, "eval/post_ent_mag": 57.07059860229492, "eval/post_ent_max": 57.07059860229492, "eval/post_ent_mean": 41.42381286621094, "eval/post_ent_min": 22.06728744506836, "eval/post_ent_std": 6.846608638763428, "eval/prior_ent_mag": 74.62089538574219, "eval/prior_ent_max": 74.62089538574219, "eval/prior_ent_mean": 54.17259216308594, "eval/prior_ent_min": 37.96528625488281, "eval/prior_ent_std": 5.307364463806152, "eval/rep_loss_mean": 19.966449737548828, "eval/rep_loss_std": 12.366562843322754, "eval/reward_avg": 0.03388671576976776, "eval/reward_loss_mean": 0.10828018933534622, "eval/reward_loss_std": 0.6408618092536926, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 1.002408504486084, "eval/reward_neg_acc": 0.992893397808075, "eval/reward_neg_loss": 0.05546139180660248, "eval/reward_pos_acc": 0.8717948794364929, "eval/reward_pos_loss": 1.4422935247421265, "eval/reward_pred": 0.03457237780094147, "eval/reward_rate": 0.0380859375, "replay/size": 555205.0, "replay/inserts": 7396.0, "replay/samples": 29584.0, "replay/insert_wait_avg": 1.6836297389557066e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.693802362651423e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 2864.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2098244448613855e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.642673492431641e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2947247028351, "timer/env.step_count": 924.0, "timer/env.step_total": 76.29440665245056, "timer/env.step_frac": 0.07627192743130372, "timer/env.step_avg": 0.08256970416931879, "timer/env.step_min": 0.023752450942993164, "timer/env.step_max": 3.2076168060302734, "timer/replay._sample_count": 29584.0, "timer/replay._sample_total": 14.692809343338013, "timer/replay._sample_frac": 0.014688480285350814, "timer/replay._sample_avg": 0.0004966471519516635, "timer/replay._sample_min": 0.0003764629364013672, "timer/replay._sample_max": 0.028680801391601562, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1282.0, "timer/agent.policy_total": 22.797448873519897, "timer/agent.policy_frac": 0.022790731881838628, "timer/agent.policy_avg": 0.01778272143020273, "timer/agent.policy_min": 0.009924888610839844, "timer/agent.policy_max": 0.12224578857421875, "timer/dataset_train_count": 1849.0, "timer/dataset_train_total": 0.3118414878845215, "timer/dataset_train_frac": 0.00031174960757407026, "timer/dataset_train_avg": 0.00016865413081910302, "timer/dataset_train_min": 9.822845458984375e-05, "timer/dataset_train_max": 0.0010395050048828125, "timer/agent.train_count": 1849.0, "timer/agent.train_total": 832.9471173286438, "timer/agent.train_frac": 0.8327016995676885, "timer/agent.train_avg": 0.45048519055091607, "timer/agent.train_min": 0.43552494049072266, "timer/agent.train_max": 1.009934902191162, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4746088981628418, "timer/agent.report_frac": 0.00047446906041000804, "timer/agent.report_avg": 0.2373044490814209, "timer/agent.report_min": 0.23062491416931152, "timer/agent.report_max": 0.24398398399353027, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.075599670410156e-05, "timer/dataset_eval_frac": 3.0746934822872804e-08, "timer/dataset_eval_avg": 3.075599670410156e-05, "timer/dataset_eval_min": 3.075599670410156e-05, "timer/dataset_eval_max": 3.075599670410156e-05, "fps": 7.393714478341912}
{"step": 555712, "time": 74394.71014904976, "episode/length": 216.0, "episode/score": 11.342154851169198, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.2421545099209652}
{"step": 555832, "time": 74411.41030073166, "episode/length": 186.0, "episode/score": 9.300853220122463, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.20085291825171225}
{"step": 556040, "time": 74438.52665281296, "episode/length": 206.0, "episode/score": 9.330889483261217, "episode/reward_rate": 0.9710144927536232, "episode/intrinsic_return": 0.23088928185688928}
{"step": 556336, "time": 74476.32838749886, "episode/length": 188.0, "episode/score": 10.289237742299065, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.18923743906043455}
{"step": 556440, "time": 74490.64989185333, "episode/length": 379.0, "episode/score": 11.49917250847875, "episode/reward_rate": 0.9894736842105263, "episode/intrinsic_return": 0.3991721678708018}
{"step": 556528, "time": 74502.87908577919, "episode/length": 177.0, "episode/score": 8.279192603455613, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.1791923996938749}
{"step": 556776, "time": 74535.07831263542, "episode/length": 193.0, "episode/score": 9.329476194755898, "episode/reward_rate": 0.9639175257731959, "episode/intrinsic_return": 0.22947593575509018}
{"step": 556896, "time": 74551.36870908737, "episode/length": 263.0, "episode/score": 12.412426995520946, "episode/reward_rate": 0.9962121212121212, "episode/intrinsic_return": 0.3124265812220983}
{"step": 557368, "time": 74612.5468826294, "episode/length": 165.0, "episode/score": 10.280144334732995, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.18014411168996958}
{"step": 557520, "time": 74632.77279615402, "episode/length": 210.0, "episode/score": 8.357796661340672, "episode/reward_rate": 0.9715639810426541, "episode/intrinsic_return": 0.2577963870894564}
{"step": 557560, "time": 74639.31778144836, "episode/length": 230.0, "episode/score": 8.355947558087337, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.25594727056477495}
{"step": 557888, "time": 74681.2106411457, "episode/length": 45.0, "episode/score": 1.1540625839843415, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.05406249890802428}
{"step": 557960, "time": 74691.46467423439, "episode/length": 189.0, "episode/score": 11.31332491607418, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.21332451993612267}
{"step": 557992, "time": 74696.96829676628, "episode/length": 206.0, "episode/score": 7.315341947109118, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.2153417616536899}
{"step": 558072, "time": 74708.4792342186, "episode/length": 192.0, "episode/score": 11.301975001949813, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.20197467868774766}
{"step": 558368, "time": 74746.91091275215, "episode/length": 198.0, "episode/score": 8.330843201892549, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.23084297886407512}
{"step": 558912, "time": 74815.4486913681, "episode/length": 168.0, "episode/score": 3.2938712902996485, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.19387119614293624}
{"step": 559128, "time": 74843.42701935768, "episode/length": 219.0, "episode/score": 8.351590257246244, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.25158999207542365}
{"step": 559168, "time": 74849.85771036148, "episode/length": 283.0, "episode/score": 10.433504160464508, "episode/reward_rate": 0.9647887323943662, "episode/intrinsic_return": 0.33350389025872573}
{"step": 559240, "time": 74860.17017364502, "episode/length": 155.0, "episode/score": 9.280053720304295, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.18005347886764866}
{"step": 559288, "time": 74867.60446715355, "episode/length": 165.0, "episode/score": 10.283166956238802, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.1831666326274899}
{"step": 559440, "time": 74888.11724066734, "episode/length": 65.0, "episode/score": 5.177026091917014, "episode/reward_rate": 0.9848484848484849, "episode/intrinsic_return": 0.07702593931981028}
{"step": 559760, "time": 74929.29812693596, "episode/length": 233.0, "episode/score": 10.366697441982069, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.2666971759090302}
{"step": 560040, "time": 74984.33360767365, "eval_episode/length": 145.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9794520547945206}
{"step": 560040, "time": 74987.53200101852, "eval_episode/length": 181.0, "eval_episode/score": 11.099999994039536, "eval_episode/reward_rate": 0.9945054945054945}
{"step": 560040, "time": 74990.24085259438, "eval_episode/length": 206.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9951690821256038}
{"step": 560040, "time": 74991.85777640343, "eval_episode/length": 207.0, "eval_episode/score": 7.0999999940395355, "eval_episode/reward_rate": 0.9951923076923077}
{"step": 560040, "time": 74994.26767516136, "eval_episode/length": 225.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9778761061946902}
{"step": 560040, "time": 74996.25391888618, "eval_episode/length": 236.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9957805907172996}
{"step": 560040, "time": 74999.20657086372, "eval_episode/length": 263.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9772727272727273}
{"step": 560040, "time": 75000.95513391495, "eval_episode/length": 64.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9846153846153847}
{"step": 560512, "time": 75058.11135673523, "episode/length": 304.0, "episode/score": 12.456471924798734, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.3564716205996774}
{"step": 560640, "time": 75075.3342909813, "episode/length": 188.0, "episode/score": 2.312093349959696, "episode/reward_rate": 0.9682539682539683, "episode/intrinsic_return": 0.2120932902619188}
{"step": 560840, "time": 75101.23607707024, "episode/length": 193.0, "episode/score": 11.304015967819169, "episode/reward_rate": 0.9845360824742269, "episode/intrinsic_return": 0.20401564417875306}
{"step": 560896, "time": 75109.52312111855, "episode/length": 206.0, "episode/score": 8.3385960183125, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.23859574720449928}
{"step": 560976, "time": 75120.87764191628, "episode/length": 151.0, "episode/score": 9.256179222286619, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.15617898693267307}
{"step": 561024, "time": 75128.19512367249, "episode/length": 331.0, "episode/score": 11.465162922831041, "episode/reward_rate": 0.9849397590361446, "episode/intrinsic_return": 0.36516257347739156}
{"step": 561712, "time": 75213.54120182991, "episode/length": 317.0, "episode/score": 11.447156686954713, "episode/reward_rate": 0.9874213836477987, "episode/intrinsic_return": 0.3471565032164108}
{"step": 561968, "time": 75246.15028333664, "episode/length": 181.0, "episode/score": 8.304029601727962, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.20402930093405303}
{"step": 562144, "time": 75269.28409934044, "episode/length": 139.0, "episode/score": 10.25155835557598, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.1515580968662107}
{"step": 562168, "time": 75273.80621886253, "episode/length": 190.0, "episode/score": 10.325855426955968, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.22585513233207166}
{"step": 562560, "time": 75323.5855948925, "episode/length": 207.0, "episode/score": 10.33716292938334, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.2371626126987394}
{"step": 562800, "time": 75354.4271914959, "episode/length": 419.0, "episode/score": 10.564986549735977, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.46498626505103857}
{"step": 563000, "time": 75380.39020204544, "episode/length": 160.0, "episode/score": 12.290421243218589, "episode/reward_rate": 0.9627329192546584, "episode/intrinsic_return": 0.19042086465924513}
{"step": 563097, "time": 75394.72702360153, "train_stats/sum_log_reward": 9.044444706704882, "train_stats/max_log_achievement_collect_coal": 0.3333333333333333, "train_stats/max_log_achievement_collect_drink": 3.888888888888889, "train_stats/max_log_achievement_collect_sapling": 1.5, "train_stats/max_log_achievement_collect_stone": 7.527777777777778, "train_stats/max_log_achievement_collect_wood": 9.166666666666666, "train_stats/max_log_achievement_defeat_skeleton": 0.027777777777777776, "train_stats/max_log_achievement_defeat_zombie": 0.6944444444444444, "train_stats/max_log_achievement_eat_cow": 0.1388888888888889, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.8888888888888888, "train_stats/max_log_achievement_make_wood_sword": 1.0555555555555556, "train_stats/max_log_achievement_place_furnace": 0.6944444444444444, "train_stats/max_log_achievement_place_plant": 1.4722222222222223, "train_stats/max_log_achievement_place_stone": 3.8333333333333335, "train_stats/max_log_achievement_place_table": 2.5, "train_stats/max_log_achievement_wake_up": 1.3055555555555556, "train_stats/mean_log_entropy": 0.4732077001697487, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.456638645481419, "train/action_min": 0.0, "train/action_std": 3.5457870070998734, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03955537083785276, "train/actor_opt_grad_steps": 139460.0, "train/actor_opt_loss": -6.985061223281396, "train/adv_mag": 0.4428820005945257, "train/adv_max": 0.40911464207881204, "train/adv_mean": 0.002993399329382039, "train/adv_min": -0.3604822675924043, "train/adv_std": 0.049488812242005326, "train/cont_avg": 0.9947001689189189, "train/cont_loss_mean": 0.0001512974578338037, "train/cont_loss_std": 0.004530715396430964, "train/cont_neg_acc": 0.9945881605148316, "train/cont_neg_loss": 0.018858889631021336, "train/cont_pos_acc": 0.9999893671757466, "train/cont_pos_loss": 3.899761097282076e-05, "train/cont_pred": 0.9947057630564715, "train/cont_rate": 0.9947001689189189, "train/dyn_loss_mean": 6.90479076488598, "train/dyn_loss_std": 8.981284832310033, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.092221579036197, "train/extr_critic_critic_opt_grad_steps": 139460.0, "train/extr_critic_critic_opt_loss": 15967.311380912162, "train/extr_critic_mag": 9.93368198807175, "train/extr_critic_max": 9.93368198807175, "train/extr_critic_mean": 3.009215755076022, "train/extr_critic_min": -0.44796177825412237, "train/extr_critic_std": 2.4313272327990147, "train/extr_return_normed_mag": 1.4495173235197325, "train/extr_return_normed_max": 1.4495173235197325, "train/extr_return_normed_mean": 0.4129991435521358, "train/extr_return_normed_min": -0.09551945985169025, "train/extr_return_normed_std": 0.32929305555047217, "train/extr_return_rate": 0.7921336973035658, "train/extr_return_raw_mag": 10.777901432965253, "train/extr_return_raw_max": 10.777901432965253, "train/extr_return_raw_mean": 3.0315852764490487, "train/extr_return_raw_min": -0.7691429397544345, "train/extr_return_raw_std": 2.461190602586076, "train/extr_reward_mag": 1.0400915751586088, "train/extr_reward_max": 1.0400915751586088, "train/extr_reward_mean": 0.04633468878833023, "train/extr_reward_min": -0.6354994735202274, "train/extr_reward_std": 0.20596907090496372, "train/image_loss_mean": 3.841461368509241, "train/image_loss_std": 8.951466501081311, "train/model_loss_mean": 8.068731052811081, "train/model_loss_std": 13.085841008779164, "train/model_opt_grad_norm": 35.876565757957664, "train/model_opt_grad_steps": 139340.41621621622, "train/model_opt_loss": 10912.912811444257, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1344.5945945945946, "train/policy_entropy_mag": 2.526850157815057, "train/policy_entropy_max": 2.526850157815057, "train/policy_entropy_mean": 0.47782561940115853, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.617329229213096, "train/policy_logprob_mag": 7.438384141148748, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.4780031391092249, "train/policy_logprob_min": -7.438384141148748, "train/policy_logprob_std": 1.0644092308508384, "train/policy_randomness_mag": 0.8918672162133294, "train/policy_randomness_max": 0.8918672162133294, "train/policy_randomness_mean": 0.16865147469011513, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.2178901288154963, "train/post_ent_mag": 60.06137730366475, "train/post_ent_max": 60.06137730366475, "train/post_ent_mean": 44.73236020062421, "train/post_ent_min": 19.437994761080354, "train/post_ent_std": 7.017896770786595, "train/prior_ent_mag": 74.83759909964897, "train/prior_ent_max": 74.83759909964897, "train/prior_ent_mean": 51.67178732382285, "train/prior_ent_min": 31.037348865818334, "train/prior_ent_std": 6.776931747230323, "train/rep_loss_mean": 6.90479076488598, "train/rep_loss_std": 8.981284832310033, "train/reward_avg": 0.0285537680057255, "train/reward_loss_mean": 0.08424395278498933, "train/reward_loss_std": 0.20045328297325082, "train/reward_max_data": 1.010977508570697, "train/reward_max_pred": 1.0125180669732996, "train/reward_neg_acc": 0.9981447319726686, "train/reward_neg_loss": 0.055746875965111964, "train/reward_pos_acc": 0.8985667502557909, "train/reward_pos_loss": 0.7505488057394285, "train/reward_pred": 0.0283377341473022, "train/reward_rate": 0.041105363175675674, "eval_stats/sum_log_reward": 8.600000321865082, "eval_stats/max_log_achievement_collect_coal": 0.125, "eval_stats/max_log_achievement_collect_drink": 5.25, "eval_stats/max_log_achievement_collect_sapling": 1.125, "eval_stats/max_log_achievement_collect_stone": 4.875, "eval_stats/max_log_achievement_collect_wood": 10.625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 1.0, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.625, "eval_stats/max_log_achievement_make_wood_sword": 1.375, "eval_stats/max_log_achievement_place_furnace": 0.375, "eval_stats/max_log_achievement_place_plant": 1.125, "eval_stats/max_log_achievement_place_stone": 2.875, "eval_stats/max_log_achievement_place_table": 3.125, "eval_stats/max_log_achievement_wake_up": 1.0, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 1.0832262887561228e-05, "report/cont_loss_std": 0.00021061980805825442, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 9.006850450532511e-05, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 1.0521532203711104e-05, "report/cont_pred": 0.996083676815033, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 6.260059356689453, "report/dyn_loss_std": 8.686817169189453, "report/image_loss_mean": 3.497346878051758, "report/image_loss_std": 7.3233795166015625, "report/model_loss_mean": 7.322211742401123, "report/model_loss_std": 11.437309265136719, "report/post_ent_mag": 60.314964294433594, "report/post_ent_max": 60.314964294433594, "report/post_ent_mean": 45.20355987548828, "report/post_ent_min": 17.49069595336914, "report/post_ent_std": 6.8920369148254395, "report/prior_ent_mag": 75.33529663085938, "report/prior_ent_max": 75.33529663085938, "report/prior_ent_mean": 51.39226150512695, "report/prior_ent_min": 32.53144073486328, "report/prior_ent_std": 6.418396472930908, "report/rep_loss_mean": 6.260059356689453, "report/rep_loss_std": 8.686817169189453, "report/reward_avg": 0.022321727126836777, "report/reward_loss_mean": 0.06881829351186752, "report/reward_loss_std": 0.12988978624343872, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0449626445770264, "report/reward_neg_acc": 0.9979838132858276, "report/reward_neg_loss": 0.04893045872449875, "report/reward_pos_acc": 0.875, "report/reward_pos_loss": 0.6853410601615906, "report/reward_pred": 0.022811196744441986, "report/reward_rate": 0.03125, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 3.7652975152013823e-05, "eval/cont_loss_std": 0.0011306778760626912, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 5.808399509987794e-05, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 3.7572852306766436e-05, "eval/cont_pred": 0.9960572719573975, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 17.55052947998047, "eval/dyn_loss_std": 11.882939338684082, "eval/image_loss_mean": 17.274526596069336, "eval/image_loss_std": 19.67034149169922, "eval/model_loss_mean": 27.970895767211914, "eval/model_loss_std": 24.639860153198242, "eval/post_ent_mag": 58.8602294921875, "eval/post_ent_max": 58.8602294921875, "eval/post_ent_mean": 43.25266647338867, "eval/post_ent_min": 19.410781860351562, "eval/post_ent_std": 7.524064064025879, "eval/prior_ent_mag": 75.33529663085938, "eval/prior_ent_max": 75.33529663085938, "eval/prior_ent_mean": 55.12763214111328, "eval/prior_ent_min": 40.900482177734375, "eval/prior_ent_std": 5.487014293670654, "eval/rep_loss_mean": 17.55052947998047, "eval/rep_loss_std": 11.882939338684082, "eval/reward_avg": 0.0322265625, "eval/reward_loss_mean": 0.16601324081420898, "eval/reward_loss_std": 0.9355016946792603, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 1.0049428939819336, "eval/reward_neg_acc": 0.9888550639152527, "eval/reward_neg_loss": 0.0869523286819458, "eval/reward_pos_acc": 0.7567567229270935, "eval/reward_pos_loss": 2.2750163078308105, "eval/reward_pred": 0.027110936120152473, "eval/reward_rate": 0.0361328125, "replay/size": 562593.0, "replay/inserts": 7388.0, "replay/samples": 29552.0, "replay/insert_wait_avg": 1.7126573377773449e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.48761163638228e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 2176.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.177958705846001e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.642673492431641e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0241034030914, "timer/env.step_count": 924.0, "timer/env.step_total": 80.74969124794006, "timer/env.step_frac": 0.08074774495249475, "timer/env.step_avg": 0.08739144074452387, "timer/env.step_min": 0.024130582809448242, "timer/env.step_max": 2.055210590362549, "timer/replay._sample_count": 29552.0, "timer/replay._sample_total": 14.607541799545288, "timer/replay._sample_frac": 0.014607189716563516, "timer/replay._sample_avg": 0.0004942996006884572, "timer/replay._sample_min": 0.0004055500030517578, "timer/replay._sample_max": 0.025673866271972656, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1196.0, "timer/agent.policy_total": 19.936458110809326, "timer/agent.policy_frac": 0.01993597758590555, "timer/agent.policy_avg": 0.016669279356863985, "timer/agent.policy_min": 0.010092735290527344, "timer/agent.policy_max": 0.05542564392089844, "timer/dataset_train_count": 1847.0, "timer/dataset_train_total": 0.31428098678588867, "timer/dataset_train_frac": 0.0003142734117271649, "timer/dataset_train_avg": 0.0001701575456339408, "timer/dataset_train_min": 9.989738464355469e-05, "timer/dataset_train_max": 0.004373788833618164, "timer/agent.train_count": 1847.0, "timer/agent.train_total": 833.7652056217194, "timer/agent.train_frac": 0.8337451095272689, "timer/agent.train_avg": 0.45141592074808845, "timer/agent.train_min": 0.4365253448486328, "timer/agent.train_max": 1.1316940784454346, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47528600692749023, "timer/agent.report_frac": 0.0004752745511934037, "timer/agent.report_avg": 0.23764300346374512, "timer/agent.report_min": 0.22884654998779297, "timer/agent.report_max": 0.24643945693969727, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0517578125e-05, "timer/dataset_eval_frac": 3.051684256524257e-08, "timer/dataset_eval_avg": 3.0517578125e-05, "timer/dataset_eval_min": 3.0517578125e-05, "timer/dataset_eval_max": 3.0517578125e-05, "fps": 7.387697240855448}
{"step": 563552, "time": 75450.07666540146, "episode/length": 172.0, "episode/score": 7.291928810191166, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.19192857016605558}
{"step": 563680, "time": 75467.11313486099, "episode/length": 84.0, "episode/score": 7.1965326978461235, "episode/reward_rate": 0.9882352941176471, "episode/intrinsic_return": 0.09653239890030818}
{"step": 563968, "time": 75503.97584247589, "episode/length": 373.0, "episode/score": 10.525175072765705, "episode/reward_rate": 0.9919786096256684, "episode/intrinsic_return": 0.4251747971175064}
{"step": 564064, "time": 75517.26839661598, "episode/length": 157.0, "episode/score": 10.267553935260366, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.16755361944888136}
{"step": 564192, "time": 75534.45017647743, "episode/length": 255.0, "episode/score": 10.404609035693284, "episode/reward_rate": 0.98046875, "episode/intrinsic_return": 0.30460868973023025}
{"step": 564320, "time": 75551.59423303604, "episode/length": 219.0, "episode/score": 11.35313602280803, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.2531355859246105}
{"step": 564328, "time": 75554.0787987709, "episode/length": 435.0, "episode/score": 7.578450797980622, "episode/reward_rate": 0.9977064220183486, "episode/intrinsic_return": 0.4784505116222135}
{"step": 564552, "time": 75583.06088232994, "episode/length": 322.0, "episode/score": 12.435943651857087, "episode/reward_rate": 0.9907120743034056, "episode/intrinsic_return": 0.33594319941767026}
{"step": 564992, "time": 75638.4343957901, "episode/length": 179.0, "episode/score": 12.311999703058973, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.211999322171323}
{"step": 565288, "time": 75677.66865158081, "episode/length": 200.0, "episode/score": 9.317121644704457, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.21712130133164464}
{"step": 565480, "time": 75702.64228367805, "episode/length": 188.0, "episode/score": 9.325956397251502, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.2259561238151946}
{"step": 565504, "time": 75707.10454010963, "episode/length": 179.0, "episode/score": 11.300717758744213, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.20071747023212083}
{"step": 565896, "time": 75756.65420603752, "episode/length": 195.0, "episode/score": 7.317930242294096, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.21793013041315135}
{"step": 566040, "time": 75775.83205842972, "episode/length": 214.0, "episode/score": 11.336851699117688, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.23685132457467262}
{"step": 566208, "time": 75797.93682742119, "episode/length": 206.0, "episode/score": 11.343831598975157, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.24383130382739182}
{"step": 566296, "time": 75810.32931900024, "episode/length": 162.0, "episode/score": 10.297916904761223, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.1979166624660138}
{"step": 566696, "time": 75860.8952639103, "episode/length": 49.0, "episode/score": 5.155673766890686, "episode/reward_rate": 0.92, "episode/intrinsic_return": 0.05567361429348239}
{"step": 566728, "time": 75866.35301089287, "episode/length": 316.0, "episode/score": 11.457990101645919, "episode/reward_rate": 0.9873817034700315, "episode/intrinsic_return": 0.3579897923536919}
{"step": 566968, "time": 75897.15809392929, "episode/length": 209.0, "episode/score": 10.34412513528332, "episode/reward_rate": 0.9809523809523809, "episode/intrinsic_return": 0.2441248441227799}
{"step": 567040, "time": 75907.54147696495, "episode/length": 194.0, "episode/score": 11.323615025214167, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.2236146629529685}
{"step": 567288, "time": 75939.27954554558, "episode/length": 155.0, "episode/score": 12.26197857405623, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.16197827748237614}
{"step": 567680, "time": 75988.86678910255, "episode/length": 48.0, "episode/score": 3.151213485525659, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.05121350400077063}
{"step": 567808, "time": 76005.9984741211, "episode/length": 134.0, "episode/score": 9.24282801935351, "episode/reward_rate": 0.9925925925925926, "episode/intrinsic_return": 0.14282759003708634}
{"step": 567984, "time": 76029.0217769146, "episode/length": 221.0, "episode/score": 10.341248370566063, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.24124799945730047}
{"step": 568232, "time": 76060.87920212746, "episode/length": 291.0, "episode/score": 11.415862439882403, "episode/reward_rate": 0.9863013698630136, "episode/intrinsic_return": 0.3158621645252424}
{"step": 568320, "time": 76073.08358502388, "episode/length": 159.0, "episode/score": 10.280596507562223, "episode/reward_rate": 0.9625, "episode/intrinsic_return": 0.18059629751405737}
{"step": 568744, "time": 76126.62935996056, "episode/length": 404.0, "episode/score": 12.511526469921591, "episode/reward_rate": 0.9827160493827161, "episode/intrinsic_return": 0.4115260673370358}
{"step": 568800, "time": 76135.05416202545, "episode/length": 101.0, "episode/score": 7.200722548291196, "episode/reward_rate": 0.9509803921568627, "episode/intrinsic_return": 0.10072230023342854}
{"step": 568912, "time": 76150.37471294403, "episode/length": 153.0, "episode/score": 9.278279261736316, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.178279043364455}
{"step": 568928, "time": 76153.8002038002, "episode/length": 278.0, "episode/score": 11.410702450394638, "episode/reward_rate": 0.985663082437276, "episode/intrinsic_return": 0.3107021300429551}
{"step": 569104, "time": 76176.72249126434, "episode/length": 161.0, "episode/score": 7.295500201289542, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.1954999960726127}
{"step": 569504, "time": 76226.95960998535, "episode/length": 49.0, "episode/score": 5.159100166310964, "episode/reward_rate": 0.92, "episode/intrinsic_return": 0.05909999881259864}
{"step": 569864, "time": 76272.44448876381, "episode/length": 192.0, "episode/score": 8.315153228109011, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.21515303983051126}
{"step": 570024, "time": 76312.54985952377, "eval_episode/length": 154.0, "eval_episode/score": 8.099999994039536, "eval_episode/reward_rate": 0.9935483870967742}
{"step": 570024, "time": 76314.75882148743, "eval_episode/length": 170.0, "eval_episode/score": 9.099999994039536, "eval_episode/reward_rate": 0.9941520467836257}
{"step": 570024, "time": 76317.06830644608, "eval_episode/length": 185.0, "eval_episode/score": 11.100000008940697, "eval_episode/reward_rate": 0.9946236559139785}
{"step": 570024, "time": 76319.46331763268, "eval_episode/length": 201.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.995049504950495}
{"step": 570024, "time": 76321.51688432693, "eval_episode/length": 212.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9953051643192489}
{"step": 570024, "time": 76323.19061374664, "eval_episode/length": 214.0, "eval_episode/score": 7.099999979138374, "eval_episode/reward_rate": 0.9953488372093023}
{"step": 570024, "time": 76325.32493591309, "eval_episode/length": 42.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9767441860465116}
{"step": 570024, "time": 76327.2492609024, "eval_episode/length": 237.0, "eval_episode/score": 10.100000016391277, "eval_episode/reward_rate": 0.9957983193277311}
{"step": 570064, "time": 76332.0964319706, "episode/length": 164.0, "episode/score": 7.279179613206907, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.1791794693990596}
{"step": 570104, "time": 76338.60576915741, "episode/length": 391.0, "episode/score": 9.46806688378183, "episode/reward_rate": 0.8112244897959183, "episode/intrinsic_return": 0.3680665874844635}
{"step": 570304, "time": 76364.34188485146, "episode/length": 173.0, "episode/score": 11.29411298280138, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.1941126466172136}
{"step": 570537, "time": 76395.12226939201, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.43193858156922, "train/action_min": 0.0, "train/action_std": 3.5366407338009087, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0387238103555896, "train/actor_opt_grad_steps": 141315.0, "train/actor_opt_loss": -11.214414977648806, "train/adv_mag": 0.4382311653706335, "train/adv_max": 0.3975050990940422, "train/adv_mean": 0.001815961927038814, "train/adv_min": -0.36064482288014504, "train/adv_std": 0.048491832149285145, "train/cont_avg": 0.9948441700268817, "train/cont_loss_mean": 0.00017659926208374012, "train/cont_loss_std": 0.005332880463062258, "train/cont_neg_acc": 0.9957373276833565, "train/cont_neg_loss": 0.021954256119721502, "train/cont_pos_acc": 0.9999841249758198, "train/cont_pos_loss": 4.835974737105175e-05, "train/cont_pred": 0.9948368482692267, "train/cont_rate": 0.9948441700268817, "train/dyn_loss_mean": 7.156084224741946, "train/dyn_loss_std": 8.97139608988198, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0586702317319892, "train/extr_critic_critic_opt_grad_steps": 141315.0, "train/extr_critic_critic_opt_loss": 15873.944220430107, "train/extr_critic_mag": 10.083940193217288, "train/extr_critic_max": 10.083940193217288, "train/extr_critic_mean": 3.0329994117060015, "train/extr_critic_min": -0.4406043726910827, "train/extr_critic_std": 2.456319106522427, "train/extr_return_normed_mag": 1.4422072229846832, "train/extr_return_normed_max": 1.4422072229846832, "train/extr_return_normed_mean": 0.4063387339313825, "train/extr_return_normed_min": -0.08927880576060664, "train/extr_return_normed_std": 0.32441063842145346, "train/extr_return_rate": 0.79326281207864, "train/extr_return_raw_mag": 10.9810805525831, "train/extr_return_raw_max": 10.9810805525831, "train/extr_return_raw_mean": 3.0469045844129337, "train/extr_return_raw_min": -0.7496557631479797, "train/extr_return_raw_std": 2.485235196928824, "train/extr_reward_mag": 1.040067494556468, "train/extr_reward_max": 1.040067494556468, "train/extr_reward_mean": 0.04613610511265134, "train/extr_reward_min": -0.6409843589669915, "train/extr_reward_std": 0.2048135999069419, "train/image_loss_mean": 3.8167768146402095, "train/image_loss_std": 8.941979428773285, "train/model_loss_mean": 8.194026929076, "train/model_loss_std": 13.073253277809389, "train/model_opt_grad_norm": 37.525881105853664, "train/model_opt_grad_steps": 141193.36559139786, "train/model_opt_loss": 8018.8333136445735, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 981.1827956989247, "train/policy_entropy_mag": 2.52703159598894, "train/policy_entropy_max": 2.52703159598894, "train/policy_entropy_mean": 0.4730457519331286, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6079078391995482, "train/policy_logprob_mag": 7.438384163764216, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.47338776306439473, "train/policy_logprob_min": -7.438384163764216, "train/policy_logprob_std": 1.0624512395551127, "train/policy_randomness_mag": 0.891931256940288, "train/policy_randomness_max": 0.891931256940288, "train/policy_randomness_mean": 0.1669643922678886, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.21456479056868502, "train/post_ent_mag": 60.01176760273595, "train/post_ent_max": 60.01176760273595, "train/post_ent_mean": 44.58788037043746, "train/post_ent_min": 19.485584212887673, "train/post_ent_std": 6.9693076610565186, "train/prior_ent_mag": 74.89745355421498, "train/prior_ent_max": 74.89745355421498, "train/prior_ent_mean": 51.77127304897513, "train/prior_ent_min": 31.605862689274613, "train/prior_ent_std": 6.71681458206587, "train/rep_loss_mean": 7.156084224741946, "train/rep_loss_std": 8.97139608988198, "train/reward_avg": 0.02883844730013641, "train/reward_loss_mean": 0.08342299470177261, "train/reward_loss_std": 0.19263509176270935, "train/reward_max_data": 1.0168414301769708, "train/reward_max_pred": 1.0150678516716085, "train/reward_neg_acc": 0.9981964624697163, "train/reward_neg_loss": 0.054875325631871016, "train/reward_pos_acc": 0.8994320054208079, "train/reward_pos_loss": 0.7484288199614453, "train/reward_pred": 0.028602705527377384, "train/reward_rate": 0.041167884744623656, "train_stats/sum_log_reward": 9.322222352027893, "train_stats/max_log_achievement_collect_coal": 0.3611111111111111, "train_stats/max_log_achievement_collect_drink": 2.0555555555555554, "train_stats/max_log_achievement_collect_sapling": 1.5, "train_stats/max_log_achievement_collect_stone": 8.805555555555555, "train_stats/max_log_achievement_collect_wood": 10.277777777777779, "train_stats/max_log_achievement_defeat_skeleton": 0.08333333333333333, "train_stats/max_log_achievement_defeat_zombie": 0.5555555555555556, "train_stats/max_log_achievement_eat_cow": 0.1111111111111111, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.027777777777777776, "train_stats/max_log_achievement_make_wood_pickaxe": 1.6111111111111112, "train_stats/max_log_achievement_make_wood_sword": 1.3888888888888888, "train_stats/max_log_achievement_place_furnace": 0.9444444444444444, "train_stats/max_log_achievement_place_plant": 1.4722222222222223, "train_stats/max_log_achievement_place_stone": 4.25, "train_stats/max_log_achievement_place_table": 2.7222222222222223, "train_stats/max_log_achievement_wake_up": 1.25, "train_stats/mean_log_entropy": 0.46706626812616986, "eval_stats/sum_log_reward": 8.725000262260437, "eval_stats/max_log_achievement_collect_coal": 0.125, "eval_stats/max_log_achievement_collect_drink": 2.75, "eval_stats/max_log_achievement_collect_sapling": 1.25, "eval_stats/max_log_achievement_collect_stone": 4.25, "eval_stats/max_log_achievement_collect_wood": 11.125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.625, "eval_stats/max_log_achievement_eat_cow": 0.25, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.5, "eval_stats/max_log_achievement_make_wood_sword": 1.125, "eval_stats/max_log_achievement_place_furnace": 0.5, "eval_stats/max_log_achievement_place_plant": 1.125, "eval_stats/max_log_achievement_place_stone": 1.625, "eval_stats/max_log_achievement_place_table": 3.125, "eval_stats/max_log_achievement_wake_up": 1.125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 3.9495425880886614e-06, "report/cont_loss_std": 5.4064028518041596e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.000552945479284972, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 1.7966174254979705e-06, "report/cont_pred": 0.9960941672325134, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 7.803474426269531, "report/dyn_loss_std": 9.376697540283203, "report/image_loss_mean": 3.9537713527679443, "report/image_loss_std": 7.832311153411865, "report/model_loss_mean": 8.714134216308594, "report/model_loss_std": 12.227143287658691, "report/post_ent_mag": 60.77922821044922, "report/post_ent_max": 60.77922821044922, "report/post_ent_mean": 44.272117614746094, "report/post_ent_min": 18.721410751342773, "report/post_ent_std": 7.4482574462890625, "report/prior_ent_mag": 75.00054931640625, "report/prior_ent_max": 75.00054931640625, "report/prior_ent_mean": 52.59028625488281, "report/prior_ent_min": 29.15027618408203, "report/prior_ent_std": 6.829769134521484, "report/rep_loss_mean": 7.803474426269531, "report/rep_loss_std": 9.376697540283203, "report/reward_avg": 0.028489133343100548, "report/reward_loss_mean": 0.07827378809452057, "report/reward_loss_std": 0.1552373468875885, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0032339096069336, "report/reward_neg_acc": 0.9959267377853394, "report/reward_neg_loss": 0.05242474377155304, "report/reward_pos_acc": 0.8809524178504944, "report/reward_pos_loss": 0.6826490163803101, "report/reward_pred": 0.03005356900393963, "report/reward_rate": 0.041015625, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 6.959209713386372e-05, "eval/cont_loss_std": 0.0014181496808305383, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.008145090192556381, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.996747753059026e-05, "eval/cont_pred": 0.9951268434524536, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 17.814912796020508, "eval/dyn_loss_std": 12.908658981323242, "eval/image_loss_mean": 16.371131896972656, "eval/image_loss_std": 19.61070442199707, "eval/model_loss_mean": 27.159626007080078, "eval/model_loss_std": 23.98408317565918, "eval/post_ent_mag": 59.905643463134766, "eval/post_ent_max": 59.905643463134766, "eval/post_ent_mean": 42.487640380859375, "eval/post_ent_min": 18.943166732788086, "eval/post_ent_std": 7.299742698669434, "eval/prior_ent_mag": 75.00054931640625, "eval/prior_ent_max": 75.00054931640625, "eval/prior_ent_mean": 54.80870819091797, "eval/prior_ent_min": 36.99131774902344, "eval/prior_ent_std": 5.644808292388916, "eval/rep_loss_mean": 17.814912796020508, "eval/rep_loss_std": 12.908658981323242, "eval/reward_avg": 0.03037109225988388, "eval/reward_loss_mean": 0.0994769036769867, "eval/reward_loss_std": 0.6630303263664246, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0030238628387451, "eval/reward_neg_acc": 0.9908907413482666, "eval/reward_neg_loss": 0.03669947385787964, "eval/reward_pos_acc": 0.8055555820465088, "eval/reward_pos_loss": 1.8223686218261719, "eval/reward_pred": 0.02973450906574726, "eval/reward_rate": 0.03515625, "replay/size": 570033.0, "replay/inserts": 7440.0, "replay/samples": 29760.0, "replay/insert_wait_avg": 1.6836068963491788e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.547358030913978e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 1904.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.219766480582101e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.08970832824707e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3783676624298, "timer/env.step_count": 930.0, "timer/env.step_total": 80.06980419158936, "timer/env.step_frac": 0.08003951982557095, "timer/env.step_avg": 0.08609656364687028, "timer/env.step_min": 0.023787736892700195, "timer/env.step_max": 1.720259189605713, "timer/replay._sample_count": 29760.0, "timer/replay._sample_total": 14.626095533370972, "timer/replay._sample_frac": 0.014620563584903944, "timer/replay._sample_avg": 0.0004914682638901537, "timer/replay._sample_min": 0.0003879070281982422, "timer/replay._sample_max": 0.02556586265563965, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1168.0, "timer/agent.policy_total": 19.32902956008911, "timer/agent.policy_frac": 0.019321718846495035, "timer/agent.policy_avg": 0.016548826678158487, "timer/agent.policy_min": 0.00987100601196289, "timer/agent.policy_max": 0.05719494819641113, "timer/dataset_train_count": 1860.0, "timer/dataset_train_total": 0.3189859390258789, "timer/dataset_train_frac": 0.0003188652907112025, "timer/dataset_train_avg": 0.00017149781668058007, "timer/dataset_train_min": 0.00010085105895996094, "timer/dataset_train_max": 0.0063893795013427734, "timer/agent.train_count": 1860.0, "timer/agent.train_total": 836.8859617710114, "timer/agent.train_frac": 0.8365694309509623, "timer/agent.train_avg": 0.44993868912419965, "timer/agent.train_min": 0.4335508346557617, "timer/agent.train_max": 1.0895171165466309, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4745216369628906, "timer/agent.report_frac": 0.00047434216122815484, "timer/agent.report_avg": 0.2372608184814453, "timer/agent.report_min": 0.23052477836608887, "timer/agent.report_max": 0.24399685859680176, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.075599670410156e-05, "timer/dataset_eval_frac": 3.0744364030950284e-08, "timer/dataset_eval_avg": 3.075599670410156e-05, "timer/dataset_eval_min": 3.075599670410156e-05, "timer/dataset_eval_max": 3.075599670410156e-05, "fps": 7.437067209891295}
{"step": 570560, "time": 76397.83185887337, "episode/length": 290.0, "episode/score": 12.432878315340531, "episode/reward_rate": 0.9965635738831615, "episode/intrinsic_return": 0.3328779001103612}
{"step": 570640, "time": 76409.13404560089, "episode/length": 213.0, "episode/score": 11.335254395396987, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.23525401433471416}
{"step": 570848, "time": 76435.83043813705, "episode/length": 167.0, "episode/score": 9.285548351276702, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.18554811887679534}
{"step": 570944, "time": 76449.05327224731, "episode/length": 267.0, "episode/score": 10.409737984180538, "episode/reward_rate": 0.9888059701492538, "episode/intrinsic_return": 0.30973770102355047}
{"step": 571552, "time": 76524.93569326401, "episode/length": 210.0, "episode/score": 9.345389617271394, "episode/reward_rate": 0.9715639810426541, "episode/intrinsic_return": 0.2453893547781263}
{"step": 571576, "time": 76529.56480932236, "episode/length": 183.0, "episode/score": 8.315429821801445, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.21542968000176188}
{"step": 571664, "time": 76541.83508682251, "episode/length": 169.0, "episode/score": 7.29221283856441, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.19221258387096896}
{"step": 571720, "time": 76550.25813293457, "episode/length": 206.0, "episode/score": 9.335258608145978, "episode/reward_rate": 0.966183574879227, "episode/intrinsic_return": 0.23525829547770627}
{"step": 571864, "time": 76569.46651864052, "episode/length": 38.0, "episode/score": 4.141458407888422, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.041458332765614614}
{"step": 572232, "time": 76615.77646255493, "episode/length": 198.0, "episode/score": 10.305196500923103, "episode/reward_rate": 0.9798994974874372, "episode/intrinsic_return": 0.20519623252175734}
{"step": 572328, "time": 76629.246540308, "episode/length": 184.0, "episode/score": 10.312285247529871, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.21228493590933795}
{"step": 572696, "time": 76675.69237160683, "episode/length": 218.0, "episode/score": 10.355004234468197, "episode/reward_rate": 0.9726027397260274, "episode/intrinsic_return": 0.2550039901066157}
{"step": 572872, "time": 76698.74864649773, "episode/length": 288.0, "episode/score": 12.408568408623069, "episode/reward_rate": 0.9757785467128027, "episode/intrinsic_return": 0.3085681599977761}
{"step": 573376, "time": 76762.05836391449, "episode/length": 188.0, "episode/score": 11.30383679526767, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.20383648955521494}
{"step": 573680, "time": 76803.16698074341, "episode/length": 244.0, "episode/score": 9.381252552860133, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.28125238734082814}
{"step": 573944, "time": 76837.0403790474, "episode/length": 295.0, "episode/score": 11.440402132560848, "episode/reward_rate": 0.9797297297297297, "episode/intrinsic_return": 0.340401842535357}
{"step": 574792, "time": 76941.71386122704, "episode/length": 307.0, "episode/score": 9.452932345743193, "episode/reward_rate": 0.9805194805194806, "episode/intrinsic_return": 0.3529320720449505}
{"step": 574816, "time": 76946.10934567451, "episode/length": 242.0, "episode/score": 12.383510928395935, "episode/reward_rate": 0.9958847736625515, "episode/intrinsic_return": 0.28351060658906135}
{"step": 574904, "time": 76958.58670330048, "episode/length": 275.0, "episode/score": 9.426428539590688, "episode/reward_rate": 0.9818840579710145, "episode/intrinsic_return": 0.3264283290768617}
{"step": 575040, "time": 76976.60611820221, "episode/length": 421.0, "episode/score": 10.541403758278193, "episode/reward_rate": 0.8175355450236966, "episode/intrinsic_return": 0.44140352200747657}
{"step": 575048, "time": 76979.09943842888, "episode/length": 208.0, "episode/score": 12.33905988116885, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.23905950144535382}
{"step": 575296, "time": 77010.7904176712, "episode/length": 48.0, "episode/score": 3.1578055475256406, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.05780539655825123}
{"step": 575472, "time": 77033.56077361107, "episode/length": 404.0, "episode/score": 12.471869146165773, "episode/reward_rate": 0.9876543209876543, "episode/intrinsic_return": 0.37186882741480076}
{"step": 575912, "time": 77088.79516458511, "episode/length": 278.0, "episode/score": 12.435076614674472, "episode/reward_rate": 0.982078853046595, "episode/intrinsic_return": 0.3350762548579951}
{"step": 575952, "time": 77095.13683843613, "episode/length": 250.0, "episode/score": 10.403572284594702, "episode/reward_rate": 0.9840637450199203, "episode/intrinsic_return": 0.30357196366094286}
{"step": 576344, "time": 77144.57609844208, "episode/length": 193.0, "episode/score": 11.32630809847251, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.22630778382517747}
{"step": 576544, "time": 77170.48577666283, "episode/length": 186.0, "episode/score": 10.30801748948943, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.20801716704227147}
{"step": 576704, "time": 77191.47627902031, "episode/length": 235.0, "episode/score": 11.36742237868566, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.26742193830978067}
{"step": 577056, "time": 77235.87223100662, "episode/length": 219.0, "episode/score": 12.348058076817324, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.24805774686137738}
{"step": 577384, "time": 77277.35423970222, "episode/length": 238.0, "episode/score": 11.376882644217403, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.27688224179291865}
{"step": 577552, "time": 77299.63467764854, "episode/length": 199.0, "episode/score": 11.336965251131915, "episode/reward_rate": 0.965, "episode/intrinsic_return": 0.23696490755537525}
{"step": 577832, "time": 77335.09140300751, "episode/length": 160.0, "episode/score": 6.28951894772581, "episode/reward_rate": 0.9627329192546584, "episode/intrinsic_return": 0.18951877347535628}
{"step": 578032, "time": 77360.97741746902, "episode/length": 210.0, "episode/score": 9.329462728093858, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.2294624239239056}
{"step": 578272, "time": 77391.6309595108, "episode/length": 403.0, "episode/score": 7.575614141616825, "episode/reward_rate": 0.9381188118811881, "episode/intrinsic_return": 0.47561390589908115}
{"step": 578281, "time": 77395.14396238327, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.388250606576192, "train/action_min": 0.0, "train/action_std": 3.47827438103784, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03877916389634622, "train/actor_opt_grad_steps": 143215.0, "train/actor_opt_loss": -9.019016615825599, "train/adv_mag": 0.43785138443573235, "train/adv_max": 0.38784052170429034, "train/adv_mean": 0.002248189140048162, "train/adv_min": -0.37497577516688513, "train/adv_std": 0.048686206532815066, "train/cont_avg": 0.9946691768685567, "train/cont_loss_mean": 4.558302892791701e-05, "train/cont_loss_std": 0.001354206449713164, "train/cont_neg_acc": 0.9993556701030928, "train/cont_neg_loss": 0.0027280461709190394, "train/cont_pos_acc": 0.9999949176286914, "train/cont_pos_loss": 2.941034100243882e-05, "train/cont_pred": 0.994667970642601, "train/cont_rate": 0.9946691768685567, "train/dyn_loss_mean": 6.929316768941191, "train/dyn_loss_std": 9.002060025008683, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0500555001583296, "train/extr_critic_critic_opt_grad_steps": 143215.0, "train/extr_critic_critic_opt_loss": 15794.297272672358, "train/extr_critic_mag": 9.874926827617527, "train/extr_critic_max": 9.874926827617527, "train/extr_critic_mean": 2.97003783393152, "train/extr_critic_min": -0.48022167338538413, "train/extr_critic_std": 2.4447672920128736, "train/extr_return_normed_mag": 1.448548070548736, "train/extr_return_normed_max": 1.448548070548736, "train/extr_return_normed_mean": 0.4107880788980071, "train/extr_return_normed_min": -0.09259824427900855, "train/extr_return_normed_std": 0.3294307260783677, "train/extr_return_rate": 0.7740402571933785, "train/extr_return_raw_mag": 10.771875351974645, "train/extr_return_raw_max": 10.771875351974645, "train/extr_return_raw_mean": 2.9868998103535054, "train/extr_return_raw_min": -0.7895983090412986, "train/extr_return_raw_std": 2.4713712445239433, "train/extr_reward_mag": 1.0434926613089965, "train/extr_reward_max": 1.0434926613089965, "train/extr_reward_mean": 0.04628760249536369, "train/extr_reward_min": -0.6535977880979321, "train/extr_reward_std": 0.20584779647514992, "train/image_loss_mean": 3.759766077257923, "train/image_loss_std": 9.012846531327238, "train/model_loss_mean": 8.001252388216786, "train/model_loss_std": 13.176362170386561, "train/model_opt_grad_norm": 36.83500618295571, "train/model_opt_grad_steps": 143092.8144329897, "train/model_opt_loss": 15577.309479703608, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1952.319587628866, "train/policy_entropy_mag": 2.529980202311093, "train/policy_entropy_max": 2.529980202311093, "train/policy_entropy_mean": 0.47322083471976606, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6138636829312315, "train/policy_logprob_mag": 7.438384159324095, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.4739323521090537, "train/policy_logprob_min": -7.438384159324095, "train/policy_logprob_std": 1.063339974155131, "train/policy_randomness_mag": 0.8929719857333862, "train/policy_randomness_max": 0.8929719857333862, "train/policy_randomness_mean": 0.16702618784050352, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.21666694225109728, "train/post_ent_mag": 60.25235522162054, "train/post_ent_max": 60.25235522162054, "train/post_ent_mean": 44.77047296897652, "train/post_ent_min": 19.384343496302968, "train/post_ent_std": 6.973824041405904, "train/prior_ent_mag": 74.92282497759948, "train/prior_ent_max": 74.92282497759948, "train/prior_ent_mean": 51.72023275709644, "train/prior_ent_min": 31.19076588227577, "train/prior_ent_std": 6.693968111706763, "train/rep_loss_mean": 6.929316768941191, "train/rep_loss_std": 9.002060025008683, "train/reward_avg": 0.02855909134731772, "train/reward_loss_mean": 0.0838507389476926, "train/reward_loss_std": 0.19451972135563486, "train/reward_max_data": 1.0203179028845324, "train/reward_max_pred": 1.0200184706560116, "train/reward_neg_acc": 0.9981791370922757, "train/reward_neg_loss": 0.055192600724469756, "train/reward_pos_acc": 0.8879860747106296, "train/reward_pos_loss": 0.7557125604644264, "train/reward_pred": 0.02815940591612274, "train/reward_rate": 0.0408948131443299, "train_stats/sum_log_reward": 9.776470829458798, "train_stats/max_log_achievement_collect_coal": 0.4117647058823529, "train_stats/max_log_achievement_collect_drink": 3.735294117647059, "train_stats/max_log_achievement_collect_sapling": 1.3235294117647058, "train_stats/max_log_achievement_collect_stone": 10.911764705882353, "train_stats/max_log_achievement_collect_wood": 9.147058823529411, "train_stats/max_log_achievement_defeat_skeleton": 0.029411764705882353, "train_stats/max_log_achievement_defeat_zombie": 0.9117647058823529, "train_stats/max_log_achievement_eat_cow": 0.14705882352941177, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.3529411764705883, "train_stats/max_log_achievement_make_wood_sword": 1.2941176470588236, "train_stats/max_log_achievement_place_furnace": 1.1176470588235294, "train_stats/max_log_achievement_place_plant": 1.2352941176470589, "train_stats/max_log_achievement_place_stone": 4.764705882352941, "train_stats/max_log_achievement_place_table": 2.3529411764705883, "train_stats/max_log_achievement_wake_up": 1.3823529411764706, "train_stats/mean_log_entropy": 0.5164924027288661, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.00011577171244425699, "report/cont_loss_std": 0.003643222851678729, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 1.1772173138524522e-06, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.00011622109013842419, "report/cont_pred": 0.9959844350814819, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 7.418929576873779, "report/dyn_loss_std": 8.35105037689209, "report/image_loss_mean": 3.5853323936462402, "report/image_loss_std": 8.067615509033203, "report/model_loss_mean": 8.121160507202148, "report/model_loss_std": 12.000471115112305, "report/post_ent_mag": 62.54664611816406, "report/post_ent_max": 62.54664611816406, "report/post_ent_mean": 44.46507263183594, "report/post_ent_min": 21.950801849365234, "report/post_ent_std": 6.772597789764404, "report/prior_ent_mag": 74.95860290527344, "report/prior_ent_max": 74.95860290527344, "report/prior_ent_mean": 52.288387298583984, "report/prior_ent_min": 35.95051193237305, "report/prior_ent_std": 6.210942268371582, "report/rep_loss_mean": 7.418929576873779, "report/rep_loss_std": 8.35105037689209, "report/reward_avg": 0.03620762377977371, "report/reward_loss_mean": 0.08435457944869995, "report/reward_loss_std": 0.15310153365135193, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0029728412628174, "report/reward_neg_acc": 0.9969136714935303, "report/reward_neg_loss": 0.0527612566947937, "report/reward_pos_acc": 0.9038462042808533, "report/reward_pos_loss": 0.6749069690704346, "report/reward_pred": 0.03739205002784729, "report/reward_rate": 0.05078125, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.00014236800780054182, "eval/cont_loss_std": 0.004259695298969746, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.03622666001319885, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 8.61008061292523e-07, "eval/cont_pred": 0.9962257742881775, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 18.284643173217773, "eval/dyn_loss_std": 12.309189796447754, "eval/image_loss_mean": 16.915639877319336, "eval/image_loss_std": 18.901182174682617, "eval/model_loss_mean": 28.027484893798828, "eval/model_loss_std": 23.73395538330078, "eval/post_ent_mag": 61.86301040649414, "eval/post_ent_max": 61.86301040649414, "eval/post_ent_mean": 42.52642059326172, "eval/post_ent_min": 18.774335861206055, "eval/post_ent_std": 7.5652899742126465, "eval/prior_ent_mag": 74.95860290527344, "eval/prior_ent_max": 74.95860290527344, "eval/prior_ent_mean": 55.29179382324219, "eval/prior_ent_min": 32.70055389404297, "eval/prior_ent_std": 6.212552070617676, "eval/rep_loss_mean": 18.284643173217773, "eval/rep_loss_std": 12.309189796447754, "eval/reward_avg": 0.03046875074505806, "eval/reward_loss_mean": 0.1409148871898651, "eval/reward_loss_std": 0.7844834923744202, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0075442790985107, "eval/reward_neg_acc": 0.9878543019294739, "eval/reward_neg_loss": 0.07472352683544159, "eval/reward_pos_acc": 0.7777777910232544, "eval/reward_pos_loss": 1.9575001001358032, "eval/reward_pred": 0.02813190221786499, "eval/reward_rate": 0.03515625, "replay/size": 577777.0, "replay/inserts": 7744.0, "replay/samples": 30976.0, "replay/insert_wait_avg": 1.656553469413568e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.476365147543348e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 7.748603820800781e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0119543075562, "timer/env.step_count": 968.0, "timer/env.step_total": 78.2005968093872, "timer/env.step_frac": 0.07819966198657703, "timer/env.step_avg": 0.08078574050556529, "timer/env.step_min": 0.023912668228149414, "timer/env.step_max": 1.842036485671997, "timer/replay._sample_count": 30976.0, "timer/replay._sample_total": 15.232094287872314, "timer/replay._sample_frac": 0.015231912200909196, "timer/replay._sample_avg": 0.0004917385810909192, "timer/replay._sample_min": 0.000385284423828125, "timer/replay._sample_max": 0.018965482711791992, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 968.0, "timer/agent.policy_total": 15.80473256111145, "timer/agent.policy_frac": 0.015804543628736126, "timer/agent.policy_avg": 0.016327203058999432, "timer/agent.policy_min": 0.014683246612548828, "timer/agent.policy_max": 0.06267094612121582, "timer/dataset_train_count": 1936.0, "timer/dataset_train_total": 0.32310056686401367, "timer/dataset_train_frac": 0.0003230967044666381, "timer/dataset_train_avg": 0.00016689078866942856, "timer/dataset_train_min": 9.846687316894531e-05, "timer/dataset_train_max": 0.0012569427490234375, "timer/agent.train_count": 1936.0, "timer/agent.train_total": 871.0820615291595, "timer/agent.train_frac": 0.8710716484707702, "timer/agent.train_avg": 0.4499390813683675, "timer/agent.train_min": 0.43877625465393066, "timer/agent.train_max": 1.1738801002502441, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47979140281677246, "timer/agent.report_frac": 0.0004797856673113444, "timer/agent.report_avg": 0.23989570140838623, "timer/agent.report_min": 0.2337336540222168, "timer/agent.report_max": 0.24605774879455566, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.384185791015625e-05, "timer/dataset_eval_frac": 2.3841572900661173e-08, "timer/dataset_eval_avg": 2.384185791015625e-05, "timer/dataset_eval_min": 2.384185791015625e-05, "timer/dataset_eval_max": 2.384185791015625e-05, "fps": 7.7437898952269375}
{"step": 578512, "time": 77423.24249982834, "episode/length": 119.0, "episode/score": 6.23301023284148, "episode/reward_rate": 0.9916666666666667, "episode/intrinsic_return": 0.13301001831132453}
{"step": 578856, "time": 77466.70357298851, "episode/length": 42.0, "episode/score": 4.1487084773834795, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.04870833252789453}
{"step": 579064, "time": 77493.75150942802, "episode/length": 393.0, "episode/score": 11.533863484579342, "episode/reward_rate": 0.9923857868020305, "episode/intrinsic_return": 0.4338631706305023}
{"step": 579264, "time": 77519.75841760635, "episode/length": 153.0, "episode/score": 7.2784222330883495, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.1784220243789605}
{"step": 579448, "time": 77543.62296485901, "episode/length": 298.0, "episode/score": 11.446063158215111, "episode/reward_rate": 0.9732441471571907, "episode/intrinsic_return": 0.34606286440612166}
{"step": 579456, "time": 77546.01782751083, "episode/length": 258.0, "episode/score": 12.40531922657101, "episode/reward_rate": 0.9961389961389961, "episode/intrinsic_return": 0.3053187900368357}
{"step": 579464, "time": 77548.8178524971, "episode/length": 203.0, "episode/score": 10.327451840406866, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.2274515082826838}
{"step": 579856, "time": 77598.1185760498, "episode/length": 393.0, "episode/score": 12.543745098730142, "episode/reward_rate": 0.9923857868020305, "episode/intrinsic_return": 0.4437447704622173}
{"step": 580008, "time": 77638.16712474823, "eval_episode/length": 158.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9559748427672956}
{"step": 580008, "time": 77640.06148529053, "eval_episode/length": 165.0, "eval_episode/score": 7.099999971687794, "eval_episode/reward_rate": 0.9939759036144579}
{"step": 580008, "time": 77642.25531744957, "eval_episode/length": 179.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9666666666666667}
{"step": 580008, "time": 77644.4724650383, "eval_episode/length": 188.0, "eval_episode/score": 7.0999999940395355, "eval_episode/reward_rate": 0.9947089947089947}
{"step": 580008, "time": 77646.96171450615, "eval_episode/length": 196.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9695431472081218}
{"step": 580008, "time": 77649.42511367798, "eval_episode/length": 59.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9333333333333333}
{"step": 580008, "time": 77651.64676404, "eval_episode/length": 233.0, "eval_episode/score": 8.099999994039536, "eval_episode/reward_rate": 0.9957264957264957}
{"step": 580008, "time": 77655.21587657928, "eval_episode/length": 44.0, "eval_episode/score": 6.0999999940395355, "eval_episode/reward_rate": 0.9777777777777777}
{"step": 580336, "time": 77695.06035661697, "episode/length": 158.0, "episode/score": 11.274447279552987, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.17444686932867626}
{"step": 581184, "time": 77800.21328997612, "episode/length": 214.0, "episode/score": 12.338932256549015, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.23893187449721154}
{"step": 581216, "time": 77805.7444972992, "episode/length": 220.0, "episode/score": 10.353909688788917, "episode/reward_rate": 0.9819004524886877, "episode/intrinsic_return": 0.25390933211565425}
{"step": 581408, "time": 77830.76002812386, "episode/length": 318.0, "episode/score": 12.460331908143417, "episode/reward_rate": 0.987460815047022, "episode/intrinsic_return": 0.36033158632199047}
{"step": 582064, "time": 77913.9561123848, "episode/length": 349.0, "episode/score": 6.481265889076894, "episode/reward_rate": 0.9914285714285714, "episode/intrinsic_return": 0.38126572972760187}
{"step": 582256, "time": 77938.84993672371, "episode/length": 349.0, "episode/score": 10.49873610175564, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.3987358082958963}
{"step": 582320, "time": 77948.150400877, "episode/length": 307.0, "episode/score": 11.452865726765594, "episode/reward_rate": 0.987012987012987, "episode/intrinsic_return": 0.3528654480323894}
{"step": 582608, "time": 77985.40282440186, "episode/length": 541.0, "episode/score": 12.684135294261068, "episode/reward_rate": 0.992619926199262, "episode/intrinsic_return": 0.5841348392168584}
{"step": 582848, "time": 78016.20652294159, "episode/length": 313.0, "episode/score": 8.44130918555129, "episode/reward_rate": 0.9968152866242038, "episode/intrinsic_return": 0.34130896188253246}
{"step": 582880, "time": 78021.73454022408, "episode/length": 183.0, "episode/score": 12.308521338367427, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.20852095631562406}
{"step": 582904, "time": 78026.17922735214, "episode/length": 214.0, "episode/score": 10.324255104875192, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.22425480908714235}
{"step": 583496, "time": 78099.80781698227, "episode/length": 178.0, "episode/score": 9.312292008602526, "episode/reward_rate": 0.9664804469273743, "episode/intrinsic_return": 0.2122917696251534}
{"step": 583568, "time": 78110.02247023582, "episode/length": 155.0, "episode/score": 9.265486447304284, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.165486156289262}
{"step": 583768, "time": 78135.78008127213, "episode/length": 188.0, "episode/score": 8.31275626020215, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.21275599386717658}
{"step": 583880, "time": 78150.87723588943, "episode/length": 158.0, "episode/score": 4.216960116971677, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.11696007339742209}
{"step": 583992, "time": 78165.98640155792, "episode/length": 346.0, "episode/score": 8.49859699409717, "episode/reward_rate": 0.9855907780979827, "episode/intrinsic_return": 0.39859673823957564}
{"step": 584160, "time": 78188.06540870667, "episode/length": 156.0, "episode/score": 10.27793515043777, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.17793482251909154}
{"step": 584280, "time": 78204.13316726685, "episode/length": 174.0, "episode/score": 9.292224343917042, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.19222400156286312}
{"step": 584880, "time": 78278.81136250496, "episode/length": 163.0, "episode/score": 8.276618500132827, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.17661824695278483}
{"step": 585064, "time": 78302.72651982307, "episode/length": 147.0, "episode/score": 9.26716481987387, "episode/reward_rate": 0.9594594594594594, "episode/intrinsic_return": 0.16716453441767953}
{"step": 585128, "time": 78312.17958498001, "episode/length": 284.0, "episode/score": 7.419541586221385, "episode/reward_rate": 0.9754385964912281, "episode/intrinsic_return": 0.31954138915352814}
{"step": 585240, "time": 78327.36562561989, "episode/length": 134.0, "episode/score": 9.264875286899041, "episode/reward_rate": 0.9555555555555556, "episode/intrinsic_return": 0.1648749965825118}
{"step": 585408, "time": 78349.41760468483, "episode/length": 204.0, "episode/score": 9.335752183216755, "episode/reward_rate": 0.9804878048780488, "episode/intrinsic_return": 0.23575187101414485}
{"step": 585552, "time": 78368.34867429733, "episode/length": 194.0, "episode/score": 7.328019225906246, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.22801899746445997}
{"step": 585753, "time": 78395.35346245766, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.507785263881888, "train/action_min": 0.0, "train/action_std": 3.576218963951193, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.039636165504494024, "train/actor_opt_grad_steps": 145115.0, "train/actor_opt_loss": -7.669685149575353, "train/adv_mag": 0.41058823546414736, "train/adv_max": 0.3724822092761276, "train/adv_mean": 0.0025138896303164935, "train/adv_min": -0.35073031789513043, "train/adv_std": 0.04936964255106706, "train/cont_avg": 0.9949439264112904, "train/cont_loss_mean": 0.00010818652911989839, "train/cont_loss_std": 0.0032026038531624778, "train/cont_neg_acc": 0.9951996931465723, "train/cont_neg_loss": 0.016021017714873943, "train/cont_pos_acc": 0.999984133948562, "train/cont_pos_loss": 2.8936683236052874e-05, "train/cont_pred": 0.9949542229534477, "train/cont_rate": 0.9949439264112904, "train/dyn_loss_mean": 6.8573682897834365, "train/dyn_loss_std": 8.963347335015573, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0666873150615281, "train/extr_critic_critic_opt_grad_steps": 145115.0, "train/extr_critic_critic_opt_loss": 15932.525821152554, "train/extr_critic_mag": 9.97954878755795, "train/extr_critic_max": 9.97954878755795, "train/extr_critic_mean": 3.0214643363029725, "train/extr_critic_min": -0.472257464162765, "train/extr_critic_std": 2.4219634654701396, "train/extr_return_normed_mag": 1.4453454523958185, "train/extr_return_normed_max": 1.4453454523958185, "train/extr_return_normed_mean": 0.41065226302992913, "train/extr_return_normed_min": -0.09043133334927661, "train/extr_return_normed_std": 0.323801845151891, "train/extr_return_rate": 0.7945928948540841, "train/extr_return_raw_mag": 10.870724770330614, "train/extr_return_raw_max": 10.870724770330614, "train/extr_return_raw_mean": 3.040481241800452, "train/extr_return_raw_min": -0.7519400328077296, "train/extr_return_raw_std": 2.4506821004293298, "train/extr_reward_mag": 1.03309335888073, "train/extr_reward_max": 1.03309335888073, "train/extr_reward_mean": 0.047735571721067994, "train/extr_reward_min": -0.6423865684898951, "train/extr_reward_std": 0.2079054884692674, "train/image_loss_mean": 3.7574057258585447, "train/image_loss_std": 8.77934967830617, "train/model_loss_mean": 7.954739065580471, "train/model_loss_std": 12.922226249530752, "train/model_opt_grad_norm": 37.17455387628207, "train/model_opt_grad_steps": 144990.47311827957, "train/model_opt_loss": 10229.2440749958, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1283.6021505376343, "train/policy_entropy_mag": 2.519541600699066, "train/policy_entropy_max": 2.519541600699066, "train/policy_entropy_mean": 0.4792603097295248, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6153456724138671, "train/policy_logprob_mag": 7.438384150946012, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.47877548570914935, "train/policy_logprob_min": -7.438384150946012, "train/policy_logprob_std": 1.0631005715939306, "train/policy_randomness_mag": 0.8892876166169361, "train/policy_randomness_max": 0.8892876166169361, "train/policy_randomness_mean": 0.16915785653456564, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.21719001954601658, "train/post_ent_mag": 60.15113922857469, "train/post_ent_max": 60.15113922857469, "train/post_ent_mean": 44.831339928411666, "train/post_ent_min": 19.19580325259957, "train/post_ent_std": 7.003164939982916, "train/prior_ent_mag": 74.86630917620916, "train/prior_ent_max": 74.86630917620916, "train/prior_ent_mean": 51.72404564067882, "train/prior_ent_min": 31.309584525323682, "train/prior_ent_std": 6.71146959386846, "train/rep_loss_mean": 6.8573682897834365, "train/rep_loss_std": 8.963347335015573, "train/reward_avg": 0.02911509863872041, "train/reward_loss_mean": 0.0828042579914934, "train/reward_loss_std": 0.19302473417533342, "train/reward_max_data": 1.0152285265666183, "train/reward_max_pred": 1.0140401278772662, "train/reward_neg_acc": 0.9983724506311519, "train/reward_neg_loss": 0.054493744687367514, "train/reward_pos_acc": 0.9084712715559108, "train/reward_pos_loss": 0.7426263183675786, "train/reward_pred": 0.028868341277683934, "train/reward_rate": 0.04113113239247312, "train_stats/sum_log_reward": 9.256250262260437, "train_stats/max_log_achievement_collect_coal": 0.28125, "train_stats/max_log_achievement_collect_drink": 3.84375, "train_stats/max_log_achievement_collect_sapling": 1.34375, "train_stats/max_log_achievement_collect_stone": 9.09375, "train_stats/max_log_achievement_collect_wood": 10.0625, "train_stats/max_log_achievement_defeat_skeleton": 0.09375, "train_stats/max_log_achievement_defeat_zombie": 0.78125, "train_stats/max_log_achievement_eat_cow": 0.125, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.03125, "train_stats/max_log_achievement_make_wood_pickaxe": 1.75, "train_stats/max_log_achievement_make_wood_sword": 1.15625, "train_stats/max_log_achievement_place_furnace": 0.875, "train_stats/max_log_achievement_place_plant": 1.28125, "train_stats/max_log_achievement_place_stone": 4.15625, "train_stats/max_log_achievement_place_table": 2.8125, "train_stats/max_log_achievement_wake_up": 1.625, "train_stats/mean_log_entropy": 0.5075732371769845, "eval_stats/sum_log_reward": 7.599999964237213, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 1.625, "eval_stats/max_log_achievement_collect_sapling": 0.625, "eval_stats/max_log_achievement_collect_stone": 5.625, "eval_stats/max_log_achievement_collect_wood": 10.125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.5, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.875, "eval_stats/max_log_achievement_make_wood_sword": 1.125, "eval_stats/max_log_achievement_place_furnace": 0.75, "eval_stats/max_log_achievement_place_plant": 0.625, "eval_stats/max_log_achievement_place_stone": 2.375, "eval_stats/max_log_achievement_place_table": 3.25, "eval_stats/max_log_achievement_wake_up": 0.875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 2.628093625389738e-06, "report/cont_loss_std": 3.914049011655152e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00032357143936678767, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 7.364830025835545e-07, "report/cont_pred": 0.9941418170928955, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 6.882623672485352, "report/dyn_loss_std": 9.679069519042969, "report/image_loss_mean": 3.8682031631469727, "report/image_loss_std": 9.023273468017578, "report/model_loss_mean": 8.078446388244629, "report/model_loss_std": 13.565715789794922, "report/post_ent_mag": 58.60697937011719, "report/post_ent_max": 58.60697937011719, "report/post_ent_mean": 44.78873825073242, "report/post_ent_min": 17.129013061523438, "report/post_ent_std": 6.975663661956787, "report/prior_ent_mag": 74.85569763183594, "report/prior_ent_max": 74.85569763183594, "report/prior_ent_mean": 51.7215576171875, "report/prior_ent_min": 33.2735481262207, "report/prior_ent_std": 6.6186842918396, "report/rep_loss_mean": 6.882623672485352, "report/rep_loss_std": 9.679069519042969, "report/reward_avg": 0.02700323797762394, "report/reward_loss_mean": 0.08066579699516296, "report/reward_loss_std": 0.19456051290035248, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0024158954620361, "report/reward_neg_acc": 0.9979715943336487, "report/reward_neg_loss": 0.05712975934147835, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6913639903068542, "report/reward_pred": 0.027888724580407143, "report/reward_rate": 0.037109375, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.014535821042954922, "eval/cont_loss_std": 0.4636407494544983, "eval/cont_neg_acc": 0.75, "eval/cont_neg_loss": 3.721142053604126, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 1.1129780119745192e-07, "eval/cont_pred": 0.9971094727516174, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 18.16870880126953, "eval/dyn_loss_std": 13.103643417358398, "eval/image_loss_mean": 20.122509002685547, "eval/image_loss_std": 25.132064819335938, "eval/model_loss_mean": 31.155336380004883, "eval/model_loss_std": 30.075681686401367, "eval/post_ent_mag": 59.759151458740234, "eval/post_ent_max": 59.759151458740234, "eval/post_ent_mean": 41.77067565917969, "eval/post_ent_min": 18.805099487304688, "eval/post_ent_std": 7.506300449371338, "eval/prior_ent_mag": 74.85569763183594, "eval/prior_ent_max": 74.85569763183594, "eval/prior_ent_mean": 53.888458251953125, "eval/prior_ent_min": 34.62400817871094, "eval/prior_ent_std": 5.965163230895996, "eval/rep_loss_mean": 18.16870880126953, "eval/rep_loss_std": 13.103643417358398, "eval/reward_avg": 0.04179687798023224, "eval/reward_loss_mean": 0.11706632375717163, "eval/reward_loss_std": 0.6885189414024353, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0024089813232422, "eval/reward_neg_acc": 0.9948875308036804, "eval/reward_neg_loss": 0.04837799072265625, "eval/reward_pos_acc": 0.8478261232376099, "eval/reward_pos_loss": 1.5774403810501099, "eval/reward_pred": 0.03620961308479309, "eval/reward_rate": 0.044921875, "replay/size": 585249.0, "replay/inserts": 7472.0, "replay/samples": 29888.0, "replay/insert_wait_avg": 1.67419491794431e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.465497712251716e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 2232.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1672042176714934e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.301568984985352e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1915135383606, "timer/env.step_count": 934.0, "timer/env.step_total": 74.15085577964783, "timer/env.step_frac": 0.07413665760602747, "timer/env.step_avg": 0.0793906378797086, "timer/env.step_min": 0.02358412742614746, "timer/env.step_max": 1.9816277027130127, "timer/replay._sample_count": 29888.0, "timer/replay._sample_total": 14.520127773284912, "timer/replay._sample_frac": 0.014517347504696677, "timer/replay._sample_avg": 0.0004858179795665455, "timer/replay._sample_min": 0.00040602684020996094, "timer/replay._sample_max": 0.009613752365112305, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1213.0, "timer/agent.policy_total": 19.94769597053528, "timer/agent.policy_frac": 0.01994387644818806, "timer/agent.policy_avg": 0.016444926603903773, "timer/agent.policy_min": 0.009844303131103516, "timer/agent.policy_max": 0.10494375228881836, "timer/dataset_train_count": 1868.0, "timer/dataset_train_total": 0.3110942840576172, "timer/dataset_train_frac": 0.00031103471669846925, "timer/dataset_train_avg": 0.00016653869596232183, "timer/dataset_train_min": 9.894371032714844e-05, "timer/dataset_train_max": 0.001239776611328125, "timer/agent.train_count": 1868.0, "timer/agent.train_total": 840.3725473880768, "timer/agent.train_frac": 0.8402116354847934, "timer/agent.train_avg": 0.44987823735978416, "timer/agent.train_min": 0.43821215629577637, "timer/agent.train_max": 1.030090570449829, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48044490814208984, "timer/agent.report_frac": 0.0004803529140558572, "timer/agent.report_avg": 0.24022245407104492, "timer/agent.report_min": 0.23414897918701172, "timer/agent.report_max": 0.24629592895507812, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 8.082389831542969e-05, "timer/dataset_eval_frac": 8.080842240852489e-08, "timer/dataset_eval_avg": 8.082389831542969e-05, "timer/dataset_eval_min": 8.082389831542969e-05, "timer/dataset_eval_max": 8.082389831542969e-05, "fps": 7.470461561582572}
{"step": 585984, "time": 78423.44066023827, "episode/length": 137.0, "episode/score": 11.253749490048904, "episode/reward_rate": 0.9927536231884058, "episode/intrinsic_return": 0.1537491578810659}
{"step": 586064, "time": 78434.70604085922, "episode/length": 320.0, "episode/score": 4.448503895342583, "episode/reward_rate": 0.9906542056074766, "episode/intrinsic_return": 0.34850374472443946}
{"step": 586296, "time": 78464.64889621735, "episode/length": 251.0, "episode/score": 9.386427781062594, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.2864274919102172}
{"step": 586520, "time": 78493.51329994202, "episode/length": 66.0, "episode/score": 4.172954282219507, "episode/reward_rate": 0.9850746268656716, "episode/intrinsic_return": 0.07295407246238028}
{"step": 586816, "time": 78531.18702054024, "episode/length": 210.0, "episode/score": 10.346300010008235, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.24629960176298482}
{"step": 587352, "time": 78598.11227607727, "episode/length": 224.0, "episode/score": 12.366292906591298, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.2662925535269096}
{"step": 587424, "time": 78608.48705220222, "episode/length": 169.0, "episode/score": 7.292572792347528, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.19257255348657054}
{"step": 588040, "time": 78684.91082644463, "episode/length": 217.0, "episode/score": 9.351290363186308, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.25129007027953776}
{"step": 588072, "time": 78690.31296658516, "episode/length": 353.0, "episode/score": 8.492370085106813, "episode/reward_rate": 0.9915254237288136, "episode/intrinsic_return": 0.39236984857416246}
{"step": 588208, "time": 78708.24616122246, "episode/length": 349.0, "episode/score": 11.465189522159562, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.3651892000616499}
{"step": 588552, "time": 78752.37355566025, "episode/length": 149.0, "episode/score": 8.263238628427644, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.1632383899159322}
{"step": 588608, "time": 78760.58546686172, "episode/length": 260.0, "episode/score": 11.395259421668015, "episode/reward_rate": 0.9961685823754789, "episode/intrinsic_return": 0.29525907209608704}
{"step": 588936, "time": 78802.00326347351, "episode/length": 188.0, "episode/score": 9.304935243406362, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.20493497974894126}
{"step": 588992, "time": 78810.28632116318, "episode/length": 271.0, "episode/score": 12.418295921030222, "episode/reward_rate": 0.9779411764705882, "episode/intrinsic_return": 0.31829552989802323}
{"step": 589072, "time": 78821.9793586731, "episode/length": 500.0, "episode/score": 11.642650315001447, "episode/reward_rate": 0.9820359281437125, "episode/intrinsic_return": 0.5426500126941391}
{"step": 589520, "time": 78878.08360505104, "episode/length": 163.0, "episode/score": 10.293333640205674, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.19333332974929363}
{"step": 589664, "time": 78897.01901459694, "episode/length": 131.0, "episode/score": 9.258151304467901, "episode/reward_rate": 0.9621212121212122, "episode/intrinsic_return": 0.15815103848217404}
{"step": 590024, "time": 78944.75113391876, "episode/length": 243.0, "episode/score": 10.39111376269284, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.2911133912348305}
{"step": 590096, "time": 78971.66302800179, "eval_episode/length": 72.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9315068493150684}
{"step": 590096, "time": 78979.11927342415, "eval_episode/length": 167.0, "eval_episode/score": 10.099999979138374, "eval_episode/reward_rate": 0.9940476190476191}
{"step": 590096, "time": 78980.84408259392, "eval_episode/length": 171.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9767441860465116}
{"step": 590096, "time": 78982.73760294914, "eval_episode/length": 178.0, "eval_episode/score": 7.099999979138374, "eval_episode/reward_rate": 0.9832402234636871}
{"step": 590096, "time": 78984.33712434769, "eval_episode/length": 179.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9944444444444445}
{"step": 590096, "time": 78986.3499379158, "eval_episode/length": 190.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9947643979057592}
{"step": 590096, "time": 78991.23596310616, "eval_episode/length": 264.0, "eval_episode/score": 11.100000008940697, "eval_episode/reward_rate": 0.9811320754716981}
{"step": 590096, "time": 78993.8488547802, "eval_episode/length": 287.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9895833333333334}
{"step": 590176, "time": 79003.53025841713, "episode/length": 147.0, "episode/score": 7.276898826332399, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.17689858141784498}
{"step": 590360, "time": 79027.54549384117, "episode/length": 177.0, "episode/score": 8.29779145664179, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.19779115899109456}
{"step": 590520, "time": 79048.56353759766, "episode/length": 180.0, "episode/score": 8.291792291880483, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.19179213433562836}
{"step": 590624, "time": 79062.80362868309, "episode/length": 322.0, "episode/score": 9.464180433053116, "episode/reward_rate": 0.978328173374613, "episode/intrinsic_return": 0.3641801532721729}
{"step": 590848, "time": 79091.89812755585, "episode/length": 286.0, "episode/score": 10.425480167938076, "episode/reward_rate": 0.9895470383275261, "episode/intrinsic_return": 0.32547990736566135}
{"step": 591160, "time": 79131.50210738182, "episode/length": 186.0, "episode/score": 12.307909959989047, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.20790953858886496}
{"step": 591640, "time": 79191.48092079163, "episode/length": 264.0, "episode/score": 11.396901673160755, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.29690131375173223}
{"step": 591800, "time": 79212.50528097153, "episode/length": 159.0, "episode/score": 10.278110799869864, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.17811044494283124}
{"step": 591824, "time": 79216.95564198494, "episode/length": 224.0, "episode/score": 11.349914410704514, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.24991403680178337}
{"step": 592016, "time": 79241.8877093792, "episode/length": 173.0, "episode/score": 11.308562980492752, "episode/reward_rate": 0.9597701149425287, "episode/intrinsic_return": 0.208562651642751}
{"step": 592168, "time": 79262.02734065056, "episode/length": 225.0, "episode/score": 10.355506392349525, "episode/reward_rate": 0.9734513274336283, "episode/intrinsic_return": 0.2555061526154532}
{"step": 592296, "time": 79279.09564638138, "episode/length": 264.0, "episode/score": 9.402617562231171, "episode/reward_rate": 0.9735849056603774, "episode/intrinsic_return": 0.3026172158024565}
{"step": 592824, "time": 79344.68807148933, "episode/length": 147.0, "episode/score": 8.259240416068678, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.15924019304020476}
{"step": 593221, "time": 79395.68967962265, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.435021058760863, "train/action_min": 0.0, "train/action_std": 3.5374131495939856, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03907140959950692, "train/actor_opt_grad_steps": 146980.0, "train/actor_opt_loss": -9.231839028152233, "train/adv_mag": 0.43418554666845555, "train/adv_max": 0.37465391630794914, "train/adv_mean": 0.002314508589301171, "train/adv_min": -0.375539377172363, "train/adv_std": 0.04882502043868769, "train/cont_avg": 0.9949866310160428, "train/cont_loss_mean": 0.00011851484875228774, "train/cont_loss_std": 0.003686017841512835, "train/cont_neg_acc": 0.9924560740669781, "train/cont_neg_loss": 0.01946465083624219, "train/cont_pos_acc": 0.999994751922587, "train/cont_pos_loss": 2.3087865792827576e-05, "train/cont_pred": 0.9950002645426256, "train/cont_rate": 0.9949866310160428, "train/dyn_loss_mean": 7.100223426512856, "train/dyn_loss_std": 8.985562344923377, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0452900726527454, "train/extr_critic_critic_opt_grad_steps": 146980.0, "train/extr_critic_critic_opt_loss": 15884.241257937834, "train/extr_critic_mag": 10.03054139958346, "train/extr_critic_max": 10.03054139958346, "train/extr_critic_mean": 3.058603606122063, "train/extr_critic_min": -0.43012737144123425, "train/extr_critic_std": 2.4105702122265007, "train/extr_return_normed_mag": 1.4404643372418409, "train/extr_return_normed_max": 1.4404643372418409, "train/extr_return_normed_mean": 0.4112190424121, "train/extr_return_normed_min": -0.09261699092579398, "train/extr_return_normed_std": 0.3217233479979204, "train/extr_return_rate": 0.8091515293095839, "train/extr_return_raw_mag": 10.882427934656807, "train/extr_return_raw_max": 10.882427934656807, "train/extr_return_raw_mean": 3.0761514602497937, "train/extr_return_raw_min": -0.7449756204125716, "train/extr_return_raw_std": 2.440141182532285, "train/extr_reward_mag": 1.0426401875235818, "train/extr_reward_max": 1.0426401875235818, "train/extr_reward_mean": 0.04835325934710031, "train/extr_reward_min": -0.6428767933565027, "train/extr_reward_std": 0.2095858608497018, "train/image_loss_mean": 3.824470627116647, "train/image_loss_std": 9.293841726639691, "train/model_loss_mean": 8.169297225972548, "train/model_loss_std": 13.396001188512791, "train/model_opt_grad_norm": 36.45813442169026, "train/model_opt_grad_steps": 146854.06951871657, "train/model_opt_loss": 14804.19457616143, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1818.1818181818182, "train/policy_entropy_mag": 2.5327687199740487, "train/policy_entropy_max": 2.5327687199740487, "train/policy_entropy_mean": 0.4498379574739997, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.5864183027795292, "train/policy_logprob_mag": 7.438384117289661, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.44874837500526304, "train/policy_logprob_min": -7.438384117289661, "train/policy_logprob_std": 1.0431588872231263, "train/policy_randomness_mag": 0.8939562108427446, "train/policy_randomness_max": 0.8939562108427446, "train/policy_randomness_mean": 0.1587730573221324, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.20697992848839988, "train/post_ent_mag": 60.029591932653744, "train/post_ent_max": 60.029591932653744, "train/post_ent_mean": 44.5541991779511, "train/post_ent_min": 19.62655396894975, "train/post_ent_std": 6.935887790618733, "train/prior_ent_mag": 74.80685975589854, "train/prior_ent_max": 74.80685975589854, "train/prior_ent_mean": 51.683853027017356, "train/prior_ent_min": 31.590202902727587, "train/prior_ent_std": 6.641031561050823, "train/rep_loss_mean": 7.100223426512856, "train/rep_loss_std": 8.985562344923377, "train/reward_avg": 0.030399174558964962, "train/reward_loss_mean": 0.08457404012507934, "train/reward_loss_std": 0.19882487836368581, "train/reward_max_data": 1.0167535976930098, "train/reward_max_pred": 1.0161292807941131, "train/reward_neg_acc": 0.9982204628500709, "train/reward_neg_loss": 0.05520507737117655, "train/reward_pos_acc": 0.8960697670033909, "train/reward_pos_loss": 0.7448030789905691, "train/reward_pred": 0.030024685929305253, "train/reward_rate": 0.04254574699197861, "train_stats/sum_log_reward": 9.42258087281258, "train_stats/max_log_achievement_collect_coal": 0.41935483870967744, "train_stats/max_log_achievement_collect_drink": 4.903225806451613, "train_stats/max_log_achievement_collect_sapling": 1.064516129032258, "train_stats/max_log_achievement_collect_stone": 9.612903225806452, "train_stats/max_log_achievement_collect_wood": 8.935483870967742, "train_stats/max_log_achievement_defeat_skeleton": 0.03225806451612903, "train_stats/max_log_achievement_defeat_zombie": 0.7741935483870968, "train_stats/max_log_achievement_eat_cow": 0.16129032258064516, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.5161290322580645, "train_stats/max_log_achievement_make_wood_sword": 1.1935483870967742, "train_stats/max_log_achievement_place_furnace": 0.9354838709677419, "train_stats/max_log_achievement_place_plant": 1.064516129032258, "train_stats/max_log_achievement_place_stone": 4.967741935483871, "train_stats/max_log_achievement_place_table": 2.5483870967741935, "train_stats/max_log_achievement_wake_up": 1.2903225806451613, "train_stats/mean_log_entropy": 0.4837555072961315, "eval_stats/sum_log_reward": 8.975000202655792, "eval_stats/max_log_achievement_collect_coal": 0.375, "eval_stats/max_log_achievement_collect_drink": 2.25, "eval_stats/max_log_achievement_collect_sapling": 1.25, "eval_stats/max_log_achievement_collect_stone": 7.25, "eval_stats/max_log_achievement_collect_wood": 8.875, "eval_stats/max_log_achievement_defeat_skeleton": 0.25, "eval_stats/max_log_achievement_defeat_zombie": 0.5, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.375, "eval_stats/max_log_achievement_make_wood_sword": 0.75, "eval_stats/max_log_achievement_place_furnace": 1.0, "eval_stats/max_log_achievement_place_plant": 1.0, "eval_stats/max_log_achievement_place_stone": 2.5, "eval_stats/max_log_achievement_place_table": 2.5, "eval_stats/max_log_achievement_wake_up": 1.375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.00037160603096708655, "report/cont_loss_std": 0.011841148138046265, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 5.847976717632264e-05, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.00037283397978171706, "report/cont_pred": 0.9957847595214844, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 7.114556789398193, "report/dyn_loss_std": 8.20775318145752, "report/image_loss_mean": 3.8198680877685547, "report/image_loss_std": 7.388324737548828, "report/model_loss_mean": 8.172988891601562, "report/model_loss_std": 10.991376876831055, "report/post_ent_mag": 59.98057556152344, "report/post_ent_max": 59.98057556152344, "report/post_ent_mean": 44.54591751098633, "report/post_ent_min": 20.283573150634766, "report/post_ent_std": 6.557257652282715, "report/prior_ent_mag": 74.72418212890625, "report/prior_ent_max": 74.72418212890625, "report/prior_ent_mean": 51.81268310546875, "report/prior_ent_min": 27.00977325439453, "report/prior_ent_std": 6.344610214233398, "report/rep_loss_mean": 7.114556789398193, "report/rep_loss_std": 8.20775318145752, "report/reward_avg": 0.03493309020996094, "report/reward_loss_mean": 0.08401502668857574, "report/reward_loss_std": 0.1600775122642517, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.001725435256958, "report/reward_neg_acc": 0.9979424476623535, "report/reward_neg_loss": 0.050868622958660126, "report/reward_pos_acc": 0.9615384936332703, "report/reward_pos_loss": 0.703597903251648, "report/reward_pred": 0.034118346869945526, "report/reward_rate": 0.05078125, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 1.4552869060935336e-06, "eval/cont_loss_std": 1.69829490914708e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00042729920824058354, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.0390170928076259e-06, "eval/cont_pred": 0.999022901058197, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 19.883773803710938, "eval/dyn_loss_std": 12.50128173828125, "eval/image_loss_mean": 19.887950897216797, "eval/image_loss_std": 20.193275451660156, "eval/model_loss_mean": 31.981685638427734, "eval/model_loss_std": 25.558273315429688, "eval/post_ent_mag": 58.70087432861328, "eval/post_ent_max": 58.70087432861328, "eval/post_ent_mean": 41.220733642578125, "eval/post_ent_min": 18.54486846923828, "eval/post_ent_std": 7.223133563995361, "eval/prior_ent_mag": 74.72418212890625, "eval/prior_ent_max": 74.72418212890625, "eval/prior_ent_mean": 54.5433349609375, "eval/prior_ent_min": 35.980682373046875, "eval/prior_ent_std": 5.456264972686768, "eval/rep_loss_mean": 19.883773803710938, "eval/rep_loss_std": 12.50128173828125, "eval/reward_avg": 0.03427734225988388, "eval/reward_loss_mean": 0.16347116231918335, "eval/reward_loss_std": 1.0113091468811035, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.001816987991333, "eval/reward_neg_acc": 0.9888664484024048, "eval/reward_neg_loss": 0.044995490461587906, "eval/reward_pos_acc": 0.6111111044883728, "eval/reward_pos_loss": 3.4149703979492188, "eval/reward_pred": 0.02607399970293045, "eval/reward_rate": 0.03515625, "replay/size": 592717.0, "replay/inserts": 7468.0, "replay/samples": 29872.0, "replay/insert_wait_avg": 1.6864570756614943e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.374598243112671e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 2304.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.212581992149353e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.599592208862305e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3218286037445, "timer/env.step_count": 933.0, "timer/env.step_total": 74.65989947319031, "timer/env.step_frac": 0.07463587951229762, "timer/env.step_avg": 0.08002132848144727, "timer/env.step_min": 0.023548603057861328, "timer/env.step_max": 2.092520236968994, "timer/replay._sample_count": 29872.0, "timer/replay._sample_total": 14.487353563308716, "timer/replay._sample_frac": 0.014482692618564823, "timer/replay._sample_avg": 0.0004849810378718772, "timer/replay._sample_min": 0.00037217140197753906, "timer/replay._sample_max": 0.010901212692260742, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1221.0, "timer/agent.policy_total": 21.567644834518433, "timer/agent.policy_frac": 0.0215607059826163, "timer/agent.policy_avg": 0.01766391878338938, "timer/agent.policy_min": 0.009813785552978516, "timer/agent.policy_max": 0.1500082015991211, "timer/dataset_train_count": 1867.0, "timer/dataset_train_total": 0.3144216537475586, "timer/dataset_train_frac": 0.0003143204964210671, "timer/dataset_train_avg": 0.00016841009841861735, "timer/dataset_train_min": 9.918212890625e-05, "timer/dataset_train_max": 0.00529932975769043, "timer/agent.train_count": 1867.0, "timer/agent.train_total": 838.7938394546509, "timer/agent.train_frac": 0.8385239784534589, "timer/agent.train_avg": 0.44927361513371766, "timer/agent.train_min": 0.43593430519104004, "timer/agent.train_max": 1.093043327331543, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47963380813598633, "timer/agent.report_frac": 0.00047947949791864706, "timer/agent.report_avg": 0.23981690406799316, "timer/agent.report_min": 0.2326810359954834, "timer/agent.report_max": 0.24695277214050293, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8848648071289062e-05, "timer/dataset_eval_frac": 2.8839366738158845e-08, "timer/dataset_eval_avg": 2.8848648071289062e-05, "timer/dataset_eval_min": 2.8848648071289062e-05, "timer/dataset_eval_max": 2.8848648071289062e-05, "fps": 7.465489698332066}
{"step": 593224, "time": 79395.71321153641, "episode/length": 174.0, "episode/score": 9.297687749127363, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.19768742633095826}
{"step": 593312, "time": 79408.50447463989, "episode/length": 161.0, "episode/score": 11.280860348687384, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.18086011439572758}
{"step": 593456, "time": 79427.59109091759, "episode/length": 160.0, "episode/score": 13.29496559035033, "episode/reward_rate": 0.9813664596273292, "episode/intrinsic_return": 0.1949652736657299}
{"step": 593728, "time": 79462.26970124245, "episode/length": 178.0, "episode/score": 7.299281311072264, "episode/reward_rate": 0.9664804469273743, "episode/intrinsic_return": 0.19928102704216144}
{"step": 594200, "time": 79521.52853894234, "episode/length": 171.0, "episode/score": 12.29592334136305, "episode/reward_rate": 0.9883720930232558, "episode/intrinsic_return": 0.19592292601646477}
{"step": 594232, "time": 79526.96870470047, "episode/length": 422.0, "episode/score": 11.567942621391921, "episode/reward_rate": 0.9905437352245863, "episode/intrinsic_return": 0.4679423117504484}
{"step": 594368, "time": 79545.2360188961, "episode/length": 400.0, "episode/score": 9.473011294482603, "episode/reward_rate": 0.85785536159601, "episode/intrinsic_return": 0.3730110310434611}
{"step": 594448, "time": 79556.52985715866, "episode/length": 141.0, "episode/score": 9.265749505786516, "episode/reward_rate": 0.9577464788732394, "episode/intrinsic_return": 0.16574924562155502}
{"step": 594920, "time": 79615.64963841438, "episode/length": 211.0, "episode/score": 11.343228740224731, "episode/reward_rate": 0.9858490566037735, "episode/intrinsic_return": 0.2432284020615043}
{"step": 595128, "time": 79642.65090632439, "episode/length": 415.0, "episode/score": 8.53713316052017, "episode/reward_rate": 0.9927884615384616, "episode/intrinsic_return": 0.4371330516951275}
{"step": 595288, "time": 79664.42042446136, "episode/length": 228.0, "episode/score": 11.368816164991586, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.2688159008685034}
{"step": 595352, "time": 79673.78664112091, "episode/length": 143.0, "episode/score": 9.260177766789639, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.16017742792791978}
{"step": 595680, "time": 79715.55681061745, "episode/length": 180.0, "episode/score": 10.293620052267215, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.19361975019273814}
{"step": 595880, "time": 79741.49470043182, "episode/length": 268.0, "episode/score": 11.402170612098416, "episode/reward_rate": 0.9776951672862454, "episode/intrinsic_return": 0.30217021083808504}
{"step": 595920, "time": 79747.86545443535, "episode/length": 183.0, "episode/score": 11.321773934969315, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.2217735803915275}
{"step": 596488, "time": 79818.57083821297, "episode/length": 169.0, "episode/score": 11.28941148157719, "episode/reward_rate": 0.9647058823529412, "episode/intrinsic_return": 0.1894112267091259}
{"step": 596648, "time": 79839.68946862221, "episode/length": 284.0, "episode/score": 11.429298910479702, "episode/reward_rate": 0.9964912280701754, "episode/intrinsic_return": 0.32929858558782144}
{"step": 596928, "time": 79875.39144301414, "episode/length": 204.0, "episode/score": 10.332628440832195, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.23262797193456208}
{"step": 597048, "time": 79891.74398779869, "episode/length": 170.0, "episode/score": 10.300485325209593, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.20048504094665986}
{"step": 597072, "time": 79896.32580852509, "episode/length": 268.0, "episode/score": 12.406134140052018, "episode/reward_rate": 0.9739776951672863, "episode/intrinsic_return": 0.30613382953742985}
{"step": 597328, "time": 79929.02025198936, "episode/length": 175.0, "episode/score": 10.293794403664833, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.19379407970427565}
{"step": 597384, "time": 79937.26665592194, "episode/length": 187.0, "episode/score": 10.303427937848937, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.2034276058557225}
{"step": 597528, "time": 79956.34541273117, "episode/length": 271.0, "episode/score": 11.39938637600062, "episode/reward_rate": 0.9742647058823529, "episode/intrinsic_return": 0.29938608018346713}
{"step": 598176, "time": 80038.17178368568, "episode/length": 190.0, "episode/score": 10.307717512056115, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.20771725276426878}
{"step": 598496, "time": 80078.81285762787, "episode/length": 195.0, "episode/score": 11.320547523316236, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.22054721757467632}
{"step": 598512, "time": 80082.35059022903, "episode/length": 179.0, "episode/score": 5.312823642161675, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.21282343624625355}
{"step": 598664, "time": 80102.38247084618, "episode/length": 271.0, "episode/score": 10.420439727144185, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.32043943240387307}
{"step": 598928, "time": 80136.18079781532, "episode/length": 192.0, "episode/score": 7.330227473270497, "episode/reward_rate": 0.9689119170984456, "episode/intrinsic_return": 0.23022726805356797}
{"step": 599168, "time": 80167.02361392975, "episode/length": 264.0, "episode/score": 11.428333640214987, "episode/reward_rate": 0.9735849056603774, "episode/intrinsic_return": 0.3283333262661472}
{"step": 599696, "time": 80232.83057904243, "episode/length": 295.0, "episode/score": 11.443532216668245, "episode/reward_rate": 0.9763513513513513, "episode/intrinsic_return": 0.343531829843414}
{"step": 599736, "time": 80239.73870182037, "episode/length": 275.0, "episode/score": 11.436765586782712, "episode/reward_rate": 0.9963768115942029, "episode/intrinsic_return": 0.33676521718734875}
{"step": 599776, "time": 80246.80190587044, "episode/length": 138.0, "episode/score": 8.257683537238336, "episode/reward_rate": 0.9784172661870504, "episode/intrinsic_return": 0.1576832873179228}
{"step": 599984, "time": 80274.55089759827, "episode/length": 185.0, "episode/score": 11.303801501879207, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.20380122139977175}
{"step": 600080, "time": 80304.43665027618, "eval_episode/length": 87.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9886363636363636}
{"step": 600080, "time": 80308.12454652786, "eval_episode/length": 137.0, "eval_episode/score": 7.100000023841858, "eval_episode/reward_rate": 0.9710144927536232}
{"step": 600080, "time": 80310.11724162102, "eval_episode/length": 55.0, "eval_episode/score": 6.0999999940395355, "eval_episode/reward_rate": 0.9821428571428571}
{"step": 600080, "time": 80313.00541090965, "eval_episode/length": 174.0, "eval_episode/score": 8.100000023841858, "eval_episode/reward_rate": 0.9657142857142857}
{"step": 600080, "time": 80315.01678943634, "eval_episode/length": 184.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9783783783783784}
{"step": 600080, "time": 80317.31366038322, "eval_episode/length": 201.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.995049504950495}
{"step": 600080, "time": 80319.4508728981, "eval_episode/length": 214.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9953488372093023}
{"step": 600080, "time": 80321.97362279892, "eval_episode/length": 90.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.945054945054945}
{"step": 600472, "time": 80369.83473682404, "episode/length": 244.0, "episode/score": 10.389863951611915, "episode/reward_rate": 0.9918367346938776, "episode/intrinsic_return": 0.28986355978122447}
{"step": 600669, "time": 80396.13083720207, "train_stats/sum_log_reward": 10.158823728561401, "train_stats/max_log_achievement_collect_coal": 0.47058823529411764, "train_stats/max_log_achievement_collect_drink": 4.088235294117647, "train_stats/max_log_achievement_collect_sapling": 1.3823529411764706, "train_stats/max_log_achievement_collect_stone": 10.147058823529411, "train_stats/max_log_achievement_collect_wood": 9.382352941176471, "train_stats/max_log_achievement_defeat_skeleton": 0.08823529411764706, "train_stats/max_log_achievement_defeat_zombie": 0.9411764705882353, "train_stats/max_log_achievement_eat_cow": 0.08823529411764706, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.4411764705882353, "train_stats/max_log_achievement_make_wood_sword": 1.4705882352941178, "train_stats/max_log_achievement_place_furnace": 1.2647058823529411, "train_stats/max_log_achievement_place_plant": 1.3529411764705883, "train_stats/max_log_achievement_place_stone": 3.8529411764705883, "train_stats/max_log_achievement_place_table": 2.6470588235294117, "train_stats/max_log_achievement_wake_up": 1.5, "train_stats/mean_log_entropy": 0.4876827382866074, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.434793451780914, "train/action_min": 0.0, "train/action_std": 3.4821370301708097, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.038930429606347954, "train/actor_opt_grad_steps": 148845.0, "train/actor_opt_loss": -9.14319607395158, "train/adv_mag": 0.4469677043217485, "train/adv_max": 0.40147937802217337, "train/adv_mean": 0.002272874111421056, "train/adv_min": -0.3573418004858878, "train/adv_std": 0.048690800344751727, "train/cont_avg": 0.9946866599462365, "train/cont_loss_mean": 0.0001571187046671314, "train/cont_loss_std": 0.0048869850243625146, "train/cont_neg_acc": 0.996216216602841, "train/cont_neg_loss": 0.020842439281419944, "train/cont_pos_acc": 0.9999893781959369, "train/cont_pos_loss": 4.305689533837462e-05, "train/cont_pred": 0.9946888034702629, "train/cont_rate": 0.9946866599462365, "train/dyn_loss_mean": 6.992520888646443, "train/dyn_loss_std": 9.021684920915993, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0301264681482827, "train/extr_critic_critic_opt_grad_steps": 148845.0, "train/extr_critic_critic_opt_loss": 15814.595330351143, "train/extr_critic_mag": 10.048913376305693, "train/extr_critic_max": 10.048913376305693, "train/extr_critic_mean": 3.0296771007199443, "train/extr_critic_min": -0.46035177733308524, "train/extr_critic_std": 2.4579905694530857, "train/extr_return_normed_mag": 1.4412665655536037, "train/extr_return_normed_max": 1.4412665655536037, "train/extr_return_normed_mean": 0.4079905955060836, "train/extr_return_normed_min": -0.09010207909409718, "train/extr_return_normed_std": 0.325828696290652, "train/extr_return_rate": 0.7972537660470573, "train/extr_return_raw_mag": 10.934132704170802, "train/extr_return_raw_max": 10.934132704170802, "train/extr_return_raw_mean": 3.04701554582965, "train/extr_return_raw_min": -0.7547328896740432, "train/extr_return_raw_std": 2.4871626169450822, "train/extr_reward_mag": 1.0403867037065568, "train/extr_reward_max": 1.0403867037065568, "train/extr_reward_mean": 0.04813289525167596, "train/extr_reward_min": -0.655295685414345, "train/extr_reward_std": 0.20987818590415422, "train/image_loss_mean": 3.772470571661508, "train/image_loss_std": 8.838267513500746, "train/model_loss_mean": 8.051830066147671, "train/model_loss_std": 13.038162108390562, "train/model_opt_grad_norm": 35.19794649691195, "train/model_opt_grad_steps": 148717.70430107528, "train/model_opt_loss": 19366.021145728326, "train/model_opt_model_opt_grad_overflow": 0.005376344086021506, "train/model_opt_model_opt_grad_scale": 2392.47311827957, "train/policy_entropy_mag": 2.5580527756803777, "train/policy_entropy_max": 2.5580527756803777, "train/policy_entropy_mean": 0.47212986103309096, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6208547876086287, "train/policy_logprob_mag": 7.438384174018778, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.47276543817853417, "train/policy_logprob_min": -7.438384174018778, "train/policy_logprob_std": 1.065868402681043, "train/policy_randomness_mag": 0.9028803718987332, "train/policy_randomness_max": 0.9028803718987332, "train/policy_randomness_mean": 0.16664112138972487, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.21913449362080584, "train/post_ent_mag": 60.10496022624354, "train/post_ent_max": 60.10496022624354, "train/post_ent_mean": 44.546975638276784, "train/post_ent_min": 19.524661382039387, "train/post_ent_std": 7.002295206951839, "train/prior_ent_mag": 74.86006812639134, "train/prior_ent_max": 74.86006812639134, "train/prior_ent_mean": 51.58888546113045, "train/prior_ent_min": 31.247618408613306, "train/prior_ent_std": 6.792838970820109, "train/rep_loss_mean": 6.992520888646443, "train/rep_loss_std": 9.021684920915993, "train/reward_avg": 0.028969293024631276, "train/reward_loss_mean": 0.08368984061062977, "train/reward_loss_std": 0.19216271862387657, "train/reward_max_data": 1.0141510175120445, "train/reward_max_pred": 1.0142288977100002, "train/reward_neg_acc": 0.9981966944791938, "train/reward_neg_loss": 0.0554220421660331, "train/reward_pos_acc": 0.9001290186118054, "train/reward_pos_loss": 0.7410864663380449, "train/reward_pred": 0.02873431855652441, "train/reward_rate": 0.04123088877688172, "eval_stats/sum_log_reward": 7.2250001430511475, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 2.375, "eval_stats/max_log_achievement_collect_sapling": 1.625, "eval_stats/max_log_achievement_collect_stone": 4.875, "eval_stats/max_log_achievement_collect_wood": 6.875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.375, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.125, "eval_stats/max_log_achievement_make_wood_sword": 0.875, "eval_stats/max_log_achievement_place_furnace": 0.125, "eval_stats/max_log_achievement_place_plant": 1.5, "eval_stats/max_log_achievement_place_stone": 3.75, "eval_stats/max_log_achievement_place_table": 1.875, "eval_stats/max_log_achievement_wake_up": 1.0, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 6.046835915185511e-05, "report/cont_loss_std": 0.0012394094374030828, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.000745478319004178, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 5.643097756546922e-05, "report/cont_pred": 0.9940897226333618, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 6.685732841491699, "report/dyn_loss_std": 8.863367080688477, "report/image_loss_mean": 4.453516006469727, "report/image_loss_std": 7.936053276062012, "report/model_loss_mean": 8.565505981445312, "report/model_loss_std": 11.903412818908691, "report/post_ent_mag": 60.547698974609375, "report/post_ent_max": 60.547698974609375, "report/post_ent_mean": 44.878482818603516, "report/post_ent_min": 19.75670051574707, "report/post_ent_std": 7.254133224487305, "report/prior_ent_mag": 74.96430969238281, "report/prior_ent_max": 74.96430969238281, "report/prior_ent_mean": 52.047950744628906, "report/prior_ent_min": 30.58915901184082, "report/prior_ent_std": 6.987650394439697, "report/rep_loss_mean": 6.685732841491699, "report/rep_loss_std": 8.863367080688477, "report/reward_avg": 0.026627743616700172, "report/reward_loss_mean": 0.1004895269870758, "report/reward_loss_std": 0.2434273511171341, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0018081665039062, "report/reward_neg_acc": 0.9989701509475708, "report/reward_neg_loss": 0.06411048769950867, "report/reward_pos_acc": 0.6603773832321167, "report/reward_pos_loss": 0.7669810056686401, "report/reward_pred": 0.026391610503196716, "report/reward_rate": 0.0517578125, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 3.883842509821989e-06, "eval/cont_loss_std": 9.264993423130363e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0018521144520491362, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.669524690190883e-07, "eval/cont_pred": 0.9980502724647522, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 17.421432495117188, "eval/dyn_loss_std": 11.120944023132324, "eval/image_loss_mean": 13.577667236328125, "eval/image_loss_std": 13.291244506835938, "eval/model_loss_mean": 24.164878845214844, "eval/model_loss_std": 17.817230224609375, "eval/post_ent_mag": 58.101295471191406, "eval/post_ent_max": 58.101295471191406, "eval/post_ent_mean": 42.992774963378906, "eval/post_ent_min": 21.557218551635742, "eval/post_ent_std": 6.64207649230957, "eval/prior_ent_mag": 74.96430969238281, "eval/prior_ent_max": 74.96430969238281, "eval/prior_ent_mean": 55.30108642578125, "eval/prior_ent_min": 40.352569580078125, "eval/prior_ent_std": 5.231447219848633, "eval/rep_loss_mean": 17.421432495117188, "eval/rep_loss_std": 11.120944023132324, "eval/reward_avg": 0.03798827901482582, "eval/reward_loss_mean": 0.1343477964401245, "eval/reward_loss_std": 0.7879809737205505, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0040388107299805, "eval/reward_neg_acc": 0.9928717613220215, "eval/reward_neg_loss": 0.05946076288819313, "eval/reward_pos_acc": 0.8333333730697632, "eval/reward_pos_loss": 1.8852782249450684, "eval/reward_pred": 0.03436701372265816, "eval/reward_rate": 0.041015625, "replay/size": 600165.0, "replay/inserts": 7448.0, "replay/samples": 29792.0, "replay/insert_wait_avg": 1.6563817074424343e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.312932921019328e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 1880.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.178776964228204e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.344650268554688e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4263565540314, "timer/env.step_count": 931.0, "timer/env.step_total": 79.80401277542114, "timer/env.step_frac": 0.07977000231212027, "timer/env.step_avg": 0.08571859589196686, "timer/env.step_min": 0.0237579345703125, "timer/env.step_max": 2.2325339317321777, "timer/replay._sample_count": 29792.0, "timer/replay._sample_total": 14.392658233642578, "timer/replay._sample_frac": 0.014386524444655867, "timer/replay._sample_avg": 0.000483104801075543, "timer/replay._sample_min": 0.0003628730773925781, "timer/replay._sample_max": 0.010985851287841797, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1166.0, "timer/agent.policy_total": 19.04670000076294, "timer/agent.policy_frac": 0.019038582776216832, "timer/agent.policy_avg": 0.016335077187618303, "timer/agent.policy_min": 0.009592771530151367, "timer/agent.policy_max": 0.05582857131958008, "timer/dataset_train_count": 1862.0, "timer/dataset_train_total": 0.3086819648742676, "timer/dataset_train_frac": 0.0003085504123836987, "timer/dataset_train_avg": 0.00016577978779498795, "timer/dataset_train_min": 9.942054748535156e-05, "timer/dataset_train_max": 0.0006334781646728516, "timer/agent.train_count": 1862.0, "timer/agent.train_total": 837.2036552429199, "timer/agent.train_frac": 0.836846860099396, "timer/agent.train_avg": 0.4496260232239097, "timer/agent.train_min": 0.4378681182861328, "timer/agent.train_max": 0.9907596111297607, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47571372985839844, "timer/agent.report_frac": 0.0004755109926301766, "timer/agent.report_avg": 0.23785686492919922, "timer/agent.report_min": 0.23096537590026855, "timer/agent.report_max": 0.24474835395812988, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8133392333984375e-05, "timer/dataset_eval_frac": 2.812140258968171e-08, "timer/dataset_eval_avg": 2.8133392333984375e-05, "timer/dataset_eval_min": 2.8133392333984375e-05, "timer/dataset_eval_max": 2.8133392333984375e-05, "fps": 7.444713870967558}
{"step": 601080, "time": 80446.25945329666, "episode/length": 172.0, "episode/score": 11.307823651281069, "episode/reward_rate": 0.9653179190751445, "episode/intrinsic_return": 0.20782330799556803}
{"step": 601200, "time": 80462.44816088676, "episode/length": 283.0, "episode/score": 9.435403529809264, "episode/reward_rate": 0.9788732394366197, "episode/intrinsic_return": 0.3354032265706337}
{"step": 601264, "time": 80471.8724796772, "episode/length": 159.0, "episode/score": 9.275401259121281, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.17540096298398566}
{"step": 601576, "time": 80511.51437568665, "episode/length": 229.0, "episode/score": 12.369715596079914, "episode/reward_rate": 0.9695652173913043, "episode/intrinsic_return": 0.2697152859145717}
{"step": 601592, "time": 80514.96426510811, "episode/length": 302.0, "episode/score": 5.456611658199108, "episode/reward_rate": 0.9966996699669967, "episode/intrinsic_return": 0.35661145111953374}
{"step": 601672, "time": 80526.34094834328, "episode/length": 436.0, "episode/score": 9.569150941753833, "episode/reward_rate": 0.9954233409610984, "episode/intrinsic_return": 0.46915065609391604}
{"step": 601904, "time": 80556.41649627686, "episode/length": 178.0, "episode/score": 11.296009652402063, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.19600923481448262}
{"step": 602192, "time": 80593.38217139244, "episode/length": 301.0, "episode/score": 11.449604133809771, "episode/reward_rate": 0.9768211920529801, "episode/intrinsic_return": 0.34960381986093125}
{"step": 602616, "time": 80647.22913455963, "episode/length": 191.0, "episode/score": 8.321939208104595, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.22193892337600118}
{"step": 602704, "time": 80659.61623740196, "episode/length": 63.0, "episode/score": 7.177291875355877, "episode/reward_rate": 0.984375, "episode/intrinsic_return": 0.07729166513308883}
{"step": 602728, "time": 80664.10055780411, "episode/length": 190.0, "episode/score": 7.328894248303186, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.22889405961723241}
{"step": 603088, "time": 80709.75007104874, "episode/length": 227.0, "episode/score": 11.363916601840174, "episode/reward_rate": 0.9649122807017544, "episode/intrinsic_return": 0.26391624435200356}
{"step": 603128, "time": 80716.1662466526, "episode/length": 181.0, "episode/score": 9.31592154790087, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.21592121136745845}
{"step": 603224, "time": 80729.59341573715, "episode/length": 205.0, "episode/score": 10.32974515485148, "episode/reward_rate": 0.9805825242718447, "episode/intrinsic_return": 0.22974486366183555}
{"step": 603304, "time": 80741.01976680756, "episode/length": 174.0, "episode/score": 9.30223557755562, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.20223531389819982}
{"step": 603536, "time": 80771.1136879921, "episode/length": 242.0, "episode/score": 11.379803698382602, "episode/reward_rate": 0.9794238683127572, "episode/intrinsic_return": 0.2798033592880529}
{"step": 603984, "time": 80827.86623048782, "episode/length": 159.0, "episode/score": 11.28188275622324, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.18188244041175494}
{"step": 604096, "time": 80843.10930347443, "episode/length": 120.0, "episode/score": 9.229733678304001, "episode/reward_rate": 0.9917355371900827, "episode/intrinsic_return": 0.1297332585336335}
{"step": 604256, "time": 80865.7890560627, "episode/length": 190.0, "episode/score": 9.31425764292635, "episode/reward_rate": 0.9685863874345549, "episode/intrinsic_return": 0.21425732478655846}
{"step": 604528, "time": 80900.86319994926, "episode/length": 238.0, "episode/score": 12.369482301332027, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.269481840699882}
{"step": 605120, "time": 80975.15599751472, "episode/length": 253.0, "episode/score": 12.377017382767917, "episode/reward_rate": 0.984251968503937, "episode/intrinsic_return": 0.27701716014689737}
{"step": 605352, "time": 81005.20297980309, "episode/length": 255.0, "episode/score": 13.376992518943553, "episode/reward_rate": 0.99609375, "episode/intrinsic_return": 0.2769921711760617}
{"step": 605496, "time": 81024.42125415802, "episode/length": 188.0, "episode/score": 7.3250865636218805, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.22508630508673377}
{"step": 605552, "time": 81032.78930783272, "episode/length": 161.0, "episode/score": 9.272158006977406, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.1721576806885423}
{"step": 606024, "time": 81092.1779448986, "episode/length": 310.0, "episode/score": 9.458768164934554, "episode/reward_rate": 0.9871382636655949, "episode/intrinsic_return": 0.3587679612892316}
{"step": 606152, "time": 81109.34069466591, "episode/length": 365.0, "episode/score": 8.506742257070982, "episode/reward_rate": 0.9863387978142076, "episode/intrinsic_return": 0.4067420801429762}
{"step": 606664, "time": 81175.14795684814, "episode/length": 145.0, "episode/score": 10.257889602263276, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.15788936837907386}
{"step": 606792, "time": 81192.3582201004, "episode/length": 208.0, "episode/score": 11.328524202324843, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.22852401954696688}
{"step": 606808, "time": 81196.15986919403, "episode/length": 81.0, "episode/score": 8.197883223730969, "episode/reward_rate": 0.9512195121951219, "episode/intrinsic_return": 0.09788298521925753}
{"step": 607240, "time": 81250.66007590294, "episode/length": 210.0, "episode/score": 11.340533793734721, "episode/reward_rate": 0.981042654028436, "episode/intrinsic_return": 0.2405335257990373}
{"step": 607720, "time": 81310.75307226181, "episode/length": 59.0, "episode/score": 6.168710763673971, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.06871058243859807}
{"step": 607776, "time": 81319.10410666466, "episode/length": 302.0, "episode/score": 11.44130567276261, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.34130531259688723}
{"step": 607928, "time": 81339.13284087181, "episode/length": 157.0, "episode/score": 8.27258793738065, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.17258772983541348}
{"step": 608136, "time": 81365.83669114113, "episode/length": 450.0, "episode/score": 13.569970963528704, "episode/reward_rate": 0.70509977827051, "episode/intrinsic_return": 0.46997058648275924}
{"step": 608336, "time": 81391.90551757812, "episode/length": 190.0, "episode/score": 11.310406468915971, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.21040612504839373}
{"step": 608353, "time": 81396.2982621193, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.459145545959473, "train/action_min": 0.0, "train/action_std": 3.5189547079304853, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03919727460015565, "train/actor_opt_grad_steps": 150735.0, "train/actor_opt_loss": -9.491313000607382, "train/adv_mag": 0.43802537815645337, "train/adv_max": 0.39585550238067907, "train/adv_mean": 0.002198247338391468, "train/adv_min": -0.365272421312208, "train/adv_std": 0.04897801975797241, "train/cont_avg": 0.9947916666666666, "train/cont_loss_mean": 0.0001652552331275666, "train/cont_loss_std": 0.005049830814507199, "train/cont_neg_acc": 0.9970858140538136, "train/cont_neg_loss": 0.020146533395974348, "train/cont_pos_acc": 0.9999846446638306, "train/cont_pos_loss": 6.260372091534035e-05, "train/cont_pred": 0.9947866074120005, "train/cont_rate": 0.9947916666666666, "train/dyn_loss_mean": 6.929684961835544, "train/dyn_loss_std": 8.946258053183556, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0641336900492508, "train/extr_critic_critic_opt_grad_steps": 150735.0, "train/extr_critic_critic_opt_loss": 15934.284474690756, "train/extr_critic_mag": 10.041114057103792, "train/extr_critic_max": 10.041114057103792, "train/extr_critic_mean": 3.008438858514031, "train/extr_critic_min": -0.45817139372229576, "train/extr_critic_std": 2.466822157924374, "train/extr_return_normed_mag": 1.4479196804265182, "train/extr_return_normed_max": 1.4479196804265182, "train/extr_return_normed_mean": 0.4063609049189836, "train/extr_return_normed_min": -0.09064526528042431, "train/extr_return_normed_std": 0.32720618167271215, "train/extr_return_rate": 0.7859334725265702, "train/extr_return_raw_mag": 10.961185619235039, "train/extr_return_raw_max": 10.961185619235039, "train/extr_return_raw_mean": 3.0251906625926495, "train/extr_return_raw_min": -0.7624506008190414, "train/extr_return_raw_std": 2.4936489009608827, "train/extr_reward_mag": 1.048695046454668, "train/extr_reward_max": 1.048695046454668, "train/extr_reward_mean": 0.04700562130892649, "train/extr_reward_min": -0.6615309702853361, "train/extr_reward_std": 0.2074309641805788, "train/image_loss_mean": 3.7707864679396152, "train/image_loss_std": 8.670071800549826, "train/model_loss_mean": 8.014290638267994, "train/model_loss_std": 12.806314498186111, "train/model_opt_grad_norm": 37.397031704584755, "train/model_opt_grad_steps": 150605.421875, "train/model_opt_loss": 10981.828315734863, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1360.6770833333333, "train/policy_entropy_mag": 2.5745660650233426, "train/policy_entropy_max": 2.5745660650233426, "train/policy_entropy_mean": 0.4822572413831949, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6311838820887109, "train/policy_logprob_mag": 7.438384113212426, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.4813607571025689, "train/policy_logprob_min": -7.438384113212426, "train/policy_logprob_std": 1.0682368036359549, "train/policy_randomness_mag": 0.9087088396772742, "train/policy_randomness_max": 0.9087088396772742, "train/policy_randomness_mean": 0.17021564320505908, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.2227802121390899, "train/post_ent_mag": 60.12066141764323, "train/post_ent_max": 60.12066141764323, "train/post_ent_mean": 44.694384137789406, "train/post_ent_min": 19.543670137723286, "train/post_ent_std": 6.982761636376381, "train/prior_ent_mag": 74.84513179461162, "train/prior_ent_max": 74.84513179461162, "train/prior_ent_mean": 51.68435784180959, "train/prior_ent_min": 31.175492574771244, "train/prior_ent_std": 6.741396255791187, "train/rep_loss_mean": 6.929684961835544, "train/rep_loss_std": 8.946258053183556, "train/reward_avg": 0.029759231343632564, "train/reward_loss_mean": 0.08552796331544717, "train/reward_loss_std": 0.20141414258008203, "train/reward_max_data": 1.019997863098979, "train/reward_max_pred": 1.020786923666795, "train/reward_neg_acc": 0.9982816536600391, "train/reward_neg_loss": 0.05582792148925364, "train/reward_pos_acc": 0.8952988047773639, "train/reward_pos_loss": 0.7516970649982492, "train/reward_pred": 0.029386526706124034, "train/reward_rate": 0.042689005533854164, "train_stats/sum_log_reward": 9.728571673801968, "train_stats/max_log_achievement_collect_coal": 0.6285714285714286, "train_stats/max_log_achievement_collect_drink": 3.0, "train_stats/max_log_achievement_collect_sapling": 1.4, "train_stats/max_log_achievement_collect_stone": 7.771428571428571, "train_stats/max_log_achievement_collect_wood": 10.0, "train_stats/max_log_achievement_defeat_skeleton": 0.05714285714285714, "train_stats/max_log_achievement_defeat_zombie": 0.6857142857142857, "train_stats/max_log_achievement_eat_cow": 0.2571428571428571, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.02857142857142857, "train_stats/max_log_achievement_make_wood_pickaxe": 1.457142857142857, "train_stats/max_log_achievement_make_wood_sword": 1.6285714285714286, "train_stats/max_log_achievement_place_furnace": 0.8857142857142857, "train_stats/max_log_achievement_place_plant": 1.3714285714285714, "train_stats/max_log_achievement_place_stone": 3.5142857142857142, "train_stats/max_log_achievement_place_table": 2.8, "train_stats/max_log_achievement_wake_up": 1.2571428571428571, "train_stats/mean_log_entropy": 0.4475268717323031, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 6.340580512187444e-06, "report/cont_loss_std": 0.00011621524754446, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 6.235072305571521e-06, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 6.3409938775293995e-06, "report/cont_pred": 0.9960875511169434, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 6.814250946044922, "report/dyn_loss_std": 8.766725540161133, "report/image_loss_mean": 3.378586530685425, "report/image_loss_std": 7.7807793617248535, "report/model_loss_mean": 7.55232572555542, "report/model_loss_std": 11.81171989440918, "report/post_ent_mag": 61.39813995361328, "report/post_ent_max": 61.39813995361328, "report/post_ent_mean": 43.881675720214844, "report/post_ent_min": 20.80979347229004, "report/post_ent_std": 6.7976202964782715, "report/prior_ent_mag": 74.89584350585938, "report/prior_ent_max": 74.89584350585938, "report/prior_ent_mean": 51.11725997924805, "report/prior_ent_min": 30.199979782104492, "report/prior_ent_std": 6.493752956390381, "report/rep_loss_mean": 6.814250946044922, "report/rep_loss_std": 8.766725540161133, "report/reward_avg": 0.03909255936741829, "report/reward_loss_mean": 0.08518187701702118, "report/reward_loss_std": 0.16107013821601868, "report/reward_max_data": 1.1012500524520874, "report/reward_max_pred": 1.0767464637756348, "report/reward_neg_acc": 0.9989712834358215, "report/reward_neg_loss": 0.052899692207574844, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6886105537414551, "report/reward_pred": 0.039466533809900284, "report/reward_rate": 0.05078125, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.00017877982463687658, "eval/cont_loss_std": 0.005634374916553497, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.03624430671334267, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.8145260582969058e-06, "eval/cont_pred": 0.9952774047851562, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 18.51244354248047, "eval/dyn_loss_std": 12.353638648986816, "eval/image_loss_mean": 13.839094161987305, "eval/image_loss_std": 17.803316116333008, "eval/model_loss_mean": 25.092147827148438, "eval/model_loss_std": 22.809404373168945, "eval/post_ent_mag": 58.98419189453125, "eval/post_ent_max": 58.98419189453125, "eval/post_ent_mean": 41.66871643066406, "eval/post_ent_min": 21.632646560668945, "eval/post_ent_std": 7.1281352043151855, "eval/prior_ent_mag": 74.89584350585938, "eval/prior_ent_max": 74.89584350585938, "eval/prior_ent_mean": 54.598812103271484, "eval/prior_ent_min": 37.47386169433594, "eval/prior_ent_std": 5.737692356109619, "eval/rep_loss_mean": 18.51244354248047, "eval/rep_loss_std": 12.353638648986816, "eval/reward_avg": 0.04755859449505806, "eval/reward_loss_mean": 0.14541006088256836, "eval/reward_loss_std": 0.8739638924598694, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0018064975738525, "eval/reward_neg_acc": 0.9958763122558594, "eval/reward_neg_loss": 0.049575746059417725, "eval/reward_pos_acc": 0.8518518805503845, "eval/reward_pos_loss": 1.8668785095214844, "eval/reward_pred": 0.04004357382655144, "eval/reward_rate": 0.052734375, "replay/size": 607849.0, "replay/inserts": 7684.0, "replay/samples": 30736.0, "replay/insert_wait_avg": 1.6709158409392692e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.373398632385159e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 1.1324882507324219e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1535527706146, "timer/env.step_count": 961.0, "timer/env.step_total": 79.71040725708008, "timer/env.step_frac": 0.0796981693823585, "timer/env.step_avg": 0.08294527290018738, "timer/env.step_min": 0.023861169815063477, "timer/env.step_max": 1.8639130592346191, "timer/replay._sample_count": 30736.0, "timer/replay._sample_total": 15.011996507644653, "timer/replay._sample_frac": 0.015009691727893763, "timer/replay._sample_avg": 0.0004884173772658984, "timer/replay._sample_min": 0.00037097930908203125, "timer/replay._sample_max": 0.02878260612487793, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 961.0, "timer/agent.policy_total": 15.871030807495117, "timer/agent.policy_frac": 0.015868594140899025, "timer/agent.policy_avg": 0.016515120507278998, "timer/agent.policy_min": 0.014737606048583984, "timer/agent.policy_max": 0.0920257568359375, "timer/dataset_train_count": 1921.0, "timer/dataset_train_total": 0.3228580951690674, "timer/dataset_train_frac": 0.0003228085270253646, "timer/dataset_train_avg": 0.00016806772262835366, "timer/dataset_train_min": 9.942054748535156e-05, "timer/dataset_train_max": 0.0012431144714355469, "timer/agent.train_count": 1921.0, "timer/agent.train_total": 868.8180727958679, "timer/agent.train_frac": 0.8686846838558714, "timer/agent.train_avg": 0.45227385361575634, "timer/agent.train_min": 0.43807482719421387, "timer/agent.train_max": 2.0490927696228027, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47998499870300293, "timer/agent.report_frac": 0.000479911306992165, "timer/agent.report_avg": 0.23999249935150146, "timer/agent.report_min": 0.23307180404663086, "timer/agent.report_max": 0.24691319465637207, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.218650817871094e-05, "timer/dataset_eval_frac": 3.2181566609995254e-08, "timer/dataset_eval_avg": 3.218650817871094e-05, "timer/dataset_eval_min": 3.218650817871094e-05, "timer/dataset_eval_max": 3.218650817871094e-05, "fps": 7.682697778198638}
{"step": 608608, "time": 81427.42850756645, "episode/length": 563.0, "episode/score": 10.6933393299405, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.5933390223653987}
{"step": 608632, "time": 81431.88708782196, "episode/length": 325.0, "episode/score": 7.4581502274604645, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.35814999458034436}
{"step": 608728, "time": 81445.14931035042, "episode/length": 241.0, "episode/score": 12.378974869476679, "episode/reward_rate": 0.9710743801652892, "episode/intrinsic_return": 0.2789744944097947}
{"step": 609464, "time": 81536.69118452072, "episode/length": 210.0, "episode/score": 11.332813480250024, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.2328131960744031}
{"step": 609704, "time": 81567.7802746296, "episode/length": 221.0, "episode/score": 11.339014841189055, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.2390145595454669}
{"step": 609840, "time": 81586.06935763359, "episode/length": 187.0, "episode/score": 8.3131327064375, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.21313253631979023}
{"step": 609960, "time": 81602.33054065704, "episode/length": 227.0, "episode/score": 10.355957972134547, "episode/reward_rate": 0.9692982456140351, "episode/intrinsic_return": 0.25595765434400164}
{"step": 610064, "time": 81639.40385007858, "eval_episode/length": 117.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9661016949152542}
{"step": 610064, "time": 81643.19793629646, "eval_episode/length": 151.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9605263157894737}
{"step": 610064, "time": 81645.085958004, "eval_episode/length": 154.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.967741935483871}
{"step": 610064, "time": 81649.18747401237, "eval_episode/length": 210.0, "eval_episode/score": 12.100000008940697, "eval_episode/reward_rate": 0.995260663507109}
{"step": 610064, "time": 81651.15958952904, "eval_episode/length": 221.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9684684684684685}
{"step": 610064, "time": 81654.67920899391, "eval_episode/length": 265.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9962406015037594}
{"step": 610064, "time": 81656.51137781143, "eval_episode/length": 271.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9816176470588235}
{"step": 610064, "time": 81658.8534913063, "eval_episode/length": 62.0, "eval_episode/score": 6.099999971687794, "eval_episode/reward_rate": 0.9841269841269841}
{"step": 610088, "time": 81661.80452656746, "episode/length": 169.0, "episode/score": 9.309166981605813, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.2091666623018682}
{"step": 610112, "time": 81666.25164675713, "episode/length": 184.0, "episode/score": 8.325833559036255, "episode/reward_rate": 0.9621621621621622, "episode/intrinsic_return": 0.22583332867361605}
{"step": 610152, "time": 81672.7499654293, "episode/length": 192.0, "episode/score": 12.314627725392256, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.2146274610945511}
{"step": 610240, "time": 81684.96465659142, "episode/length": 314.0, "episode/score": 12.462393817121665, "episode/reward_rate": 0.9873015873015873, "episode/intrinsic_return": 0.36239352638312994}
{"step": 610496, "time": 81717.73385953903, "episode/length": 42.0, "episode/score": 2.1450030422129203, "episode/reward_rate": 0.9069767441860465, "episode/intrinsic_return": 0.04500297553022392}
{"step": 611272, "time": 81814.62531924248, "episode/length": 178.0, "episode/score": 9.287738628577245, "episode/reward_rate": 0.9664804469273743, "episode/intrinsic_return": 0.1877382750326433}
{"step": 611400, "time": 81831.79298090935, "episode/length": 160.0, "episode/score": 10.291218243521143, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.19121791874567862}
{"step": 611520, "time": 81848.57041072845, "episode/length": 226.0, "episode/score": 8.32003467933555, "episode/reward_rate": 0.9779735682819384, "episode/intrinsic_return": 0.22003450770444033}
{"step": 611664, "time": 81867.6468539238, "episode/length": 177.0, "episode/score": 11.297340278988486, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.19733995689057338}
{"step": 611840, "time": 81890.70882463455, "episode/length": 167.0, "episode/score": 11.278928114500559, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.1789276882109334}
{"step": 611944, "time": 81904.91472887993, "episode/length": 247.0, "episode/score": 10.38488567966806, "episode/reward_rate": 0.9798387096774194, "episode/intrinsic_return": 0.28488542212244283}
{"step": 612736, "time": 82003.55182528496, "episode/length": 166.0, "episode/score": 9.28542742854097, "episode/reward_rate": 0.9640718562874252, "episode/intrinsic_return": 0.1854272150876568}
{"step": 612768, "time": 82009.06128525734, "episode/length": 334.0, "episode/score": 11.489797794040442, "episode/reward_rate": 0.9880597014925373, "episode/intrinsic_return": 0.38979753311878085}
{"step": 612840, "time": 82019.4169242382, "episode/length": 421.0, "episode/score": 12.547459561787491, "episode/reward_rate": 0.990521327014218, "episode/intrinsic_return": 0.4474592537758326}
{"step": 613352, "time": 82083.75283956528, "episode/length": 210.0, "episode/score": 10.339865617976557, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.23986525420195903}
{"step": 613352, "time": 82083.76100850105, "episode/length": 228.0, "episode/score": 11.368706289369584, "episode/reward_rate": 0.9781659388646288, "episode/intrinsic_return": 0.2687059359559498}
{"step": 613360, "time": 82088.10171484947, "episode/length": 189.0, "episode/score": 8.32392814664081, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.22392789901959986}
{"step": 613928, "time": 82159.24934768677, "episode/length": 148.0, "episode/score": 8.261102216306881, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.16110194880775452}
{"step": 614024, "time": 82172.55344247818, "episode/length": 343.0, "episode/score": 10.472773601468361, "episode/reward_rate": 0.9912790697674418, "episode/intrinsic_return": 0.37277330684446497}
{"step": 614264, "time": 82203.65837073326, "episode/length": 289.0, "episode/score": 10.447548510918296, "episode/reward_rate": 0.9724137931034482, "episode/intrinsic_return": 0.3475482801773069}
{"step": 614288, "time": 82208.1055932045, "episode/length": 189.0, "episode/score": 10.315518661569513, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.21551836694561644}
{"step": 614384, "time": 82221.3396692276, "episode/length": 192.0, "episode/score": 12.319279793120131, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.2192794638626765}
{"step": 615200, "time": 82324.50506901741, "episode/length": 230.0, "episode/score": 8.3547974625385, "episode/reward_rate": 0.9783549783549783, "episode/intrinsic_return": 0.2547972659217521}
{"step": 615232, "time": 82330.04359340668, "episode/length": 162.0, "episode/score": 10.27803652150942, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.17803614300828485}
{"step": 615232, "time": 82330.05179977417, "episode/length": 234.0, "episode/score": 11.357084438646325, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.2570840141465851}
{"step": 615488, "time": 82364.38739275932, "episode/length": 149.0, "episode/score": 11.266774684787379, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.16677426513342652}
{"step": 615488, "time": 82364.39870405197, "episode/length": 265.0, "episode/score": 8.396444248961416, "episode/reward_rate": 0.9774436090225563, "episode/intrinsic_return": 0.2964441546882881}
{"step": 615704, "time": 82394.08175706863, "episode/length": 164.0, "episode/score": 9.273968264168161, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.1739679821171194}
{"step": 615705, "time": 82396.6495141983, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.480528126592222, "train/action_min": 0.0, "train/action_std": 3.5286507995232292, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.038440750010878495, "train/actor_opt_grad_steps": 152615.0, "train/actor_opt_loss": -9.906985651971215, "train/adv_mag": 0.42714166665530723, "train/adv_max": 0.39094496526471945, "train/adv_mean": 0.002156466091867554, "train/adv_min": -0.34454122461054637, "train/adv_std": 0.048672535456717014, "train/cont_avg": 0.9946925951086957, "train/cont_loss_mean": 0.0001754745813964205, "train/cont_loss_std": 0.005386332204716506, "train/cont_neg_acc": 0.994105849577033, "train/cont_neg_loss": 0.016880369130860436, "train/cont_pos_acc": 0.9999893029098925, "train/cont_pos_loss": 7.67235546927635e-05, "train/cont_pred": 0.9947021995549616, "train/cont_rate": 0.9946925951086957, "train/dyn_loss_mean": 6.955959954987401, "train/dyn_loss_std": 9.015753849692967, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.051951744310234, "train/extr_critic_critic_opt_grad_steps": 152615.0, "train/extr_critic_critic_opt_loss": 15924.585231615149, "train/extr_critic_mag": 10.126200463460838, "train/extr_critic_max": 10.126200463460838, "train/extr_critic_mean": 3.010234007368917, "train/extr_critic_min": -0.4705572018156881, "train/extr_critic_std": 2.515386158357496, "train/extr_return_normed_mag": 1.4475908227588818, "train/extr_return_normed_max": 1.4475908227588818, "train/extr_return_normed_mean": 0.4049889375658139, "train/extr_return_normed_min": -0.09271248867330344, "train/extr_return_normed_std": 0.3320044648388158, "train/extr_return_rate": 0.7778147352130517, "train/extr_return_raw_mag": 11.014678789221723, "train/extr_return_raw_max": 11.014678789221723, "train/extr_return_raw_mean": 3.0267599244480548, "train/extr_return_raw_min": -0.7856981232762337, "train/extr_return_raw_std": 2.543635843888573, "train/extr_reward_mag": 1.0420387905576955, "train/extr_reward_max": 1.0420387905576955, "train/extr_reward_mean": 0.04805860330310205, "train/extr_reward_min": -0.6724887665199197, "train/extr_reward_std": 0.20932804533968802, "train/image_loss_mean": 3.762851243433745, "train/image_loss_std": 8.878882374452507, "train/model_loss_mean": 8.021307908970376, "train/model_loss_std": 13.047067968741707, "train/model_opt_grad_norm": 35.439590661422066, "train/model_opt_grad_steps": 152484.10326086957, "train/model_opt_loss": 13300.46037226138, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1650.8152173913043, "train/policy_entropy_mag": 2.56546616035959, "train/policy_entropy_max": 2.56546616035959, "train/policy_entropy_mean": 0.4746364413396172, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6191715015017468, "train/policy_logprob_mag": 7.438384162343067, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.4741782732307911, "train/policy_logprob_min": -7.438384162343067, "train/policy_logprob_std": 1.0634638650909713, "train/policy_randomness_mag": 0.9054969701430072, "train/policy_randomness_max": 0.9054969701430072, "train/policy_randomness_mean": 0.16752583371556323, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.21854036900660265, "train/post_ent_mag": 60.35091006237528, "train/post_ent_max": 60.35091006237528, "train/post_ent_mean": 44.64127254486084, "train/post_ent_min": 19.342054392980494, "train/post_ent_std": 6.9850453112436375, "train/prior_ent_mag": 74.8693909852401, "train/prior_ent_max": 74.8693909852401, "train/prior_ent_mean": 51.620596823485, "train/prior_ent_min": 31.153009642725404, "train/prior_ent_std": 6.756480815617935, "train/rep_loss_mean": 6.955959954987401, "train/rep_loss_std": 9.015753849692967, "train/reward_avg": 0.030118933595393017, "train/reward_loss_mean": 0.08470522916025441, "train/reward_loss_std": 0.20308980426710585, "train/reward_max_data": 1.0186413371044656, "train/reward_max_pred": 1.0175594687461853, "train/reward_neg_acc": 0.9983488778057306, "train/reward_neg_loss": 0.05528709820836135, "train/reward_pos_acc": 0.9048160797227984, "train/reward_pos_loss": 0.7579249357399733, "train/reward_pred": 0.02960782542662776, "train/reward_rate": 0.041917883831521736, "train_stats/sum_log_reward": 9.785714558192662, "train_stats/max_log_achievement_collect_coal": 0.5428571428571428, "train_stats/max_log_achievement_collect_drink": 5.4, "train_stats/max_log_achievement_collect_sapling": 1.1428571428571428, "train_stats/max_log_achievement_collect_stone": 12.028571428571428, "train_stats/max_log_achievement_collect_wood": 8.971428571428572, "train_stats/max_log_achievement_defeat_skeleton": 0.05714285714285714, "train_stats/max_log_achievement_defeat_zombie": 0.6571428571428571, "train_stats/max_log_achievement_eat_cow": 0.14285714285714285, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.4, "train_stats/max_log_achievement_make_wood_sword": 1.6571428571428573, "train_stats/max_log_achievement_place_furnace": 1.5142857142857142, "train_stats/max_log_achievement_place_plant": 1.1142857142857143, "train_stats/max_log_achievement_place_stone": 4.9714285714285715, "train_stats/max_log_achievement_place_table": 2.4857142857142858, "train_stats/max_log_achievement_wake_up": 1.3142857142857143, "train_stats/mean_log_entropy": 0.492523883496012, "eval_stats/sum_log_reward": 8.975000083446503, "eval_stats/max_log_achievement_collect_coal": 0.5, "eval_stats/max_log_achievement_collect_drink": 2.0, "eval_stats/max_log_achievement_collect_sapling": 1.375, "eval_stats/max_log_achievement_collect_stone": 7.375, "eval_stats/max_log_achievement_collect_wood": 8.5, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.25, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.25, "eval_stats/max_log_achievement_make_wood_sword": 1.875, "eval_stats/max_log_achievement_place_furnace": 0.75, "eval_stats/max_log_achievement_place_plant": 1.375, "eval_stats/max_log_achievement_place_stone": 3.5, "eval_stats/max_log_achievement_place_table": 2.125, "eval_stats/max_log_achievement_wake_up": 1.0, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 9.672869509813609e-07, "report/cont_loss_std": 6.31957163932384e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 6.898069955241226e-07, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 9.69196889855084e-07, "report/cont_pred": 0.9931631088256836, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 6.506271839141846, "report/dyn_loss_std": 8.951909065246582, "report/image_loss_mean": 3.6724345684051514, "report/image_loss_std": 7.709924221038818, "report/model_loss_mean": 7.666380882263184, "report/model_loss_std": 11.94172191619873, "report/post_ent_mag": 59.458988189697266, "report/post_ent_max": 59.458988189697266, "report/post_ent_mean": 44.58197021484375, "report/post_ent_min": 19.194290161132812, "report/post_ent_std": 7.321358680725098, "report/prior_ent_mag": 75.2508773803711, "report/prior_ent_max": 75.2508773803711, "report/prior_ent_mean": 51.589378356933594, "report/prior_ent_min": 27.779788970947266, "report/prior_ent_std": 6.891995906829834, "report/rep_loss_mean": 6.506271839141846, "report/rep_loss_std": 8.951909065246582, "report/reward_avg": 0.026295913383364677, "report/reward_loss_mean": 0.09018180519342422, "report/reward_loss_std": 0.2045694887638092, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0028626918792725, "report/reward_neg_acc": 0.9989786148071289, "report/reward_neg_loss": 0.059859998524188995, "report/reward_pos_acc": 0.9555555582046509, "report/reward_pos_loss": 0.7498497366905212, "report/reward_pred": 0.02617853879928589, "report/reward_rate": 0.0439453125, "eval/cont_avg": 0.9921875, "eval/cont_loss_mean": 0.0004616767982952297, "eval/cont_loss_std": 0.014482984319329262, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.05802815407514572, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 8.397445526497904e-06, "eval/cont_pred": 0.9925420880317688, "eval/cont_rate": 0.9921875, "eval/dyn_loss_mean": 19.73169708251953, "eval/dyn_loss_std": 13.302308082580566, "eval/image_loss_mean": 16.436843872070312, "eval/image_loss_std": 19.57796287536621, "eval/model_loss_mean": 28.415939331054688, "eval/model_loss_std": 24.9476375579834, "eval/post_ent_mag": 58.40264892578125, "eval/post_ent_max": 58.40264892578125, "eval/post_ent_mean": 40.94988250732422, "eval/post_ent_min": 18.695865631103516, "eval/post_ent_std": 7.311561584472656, "eval/prior_ent_mag": 75.2508773803711, "eval/prior_ent_max": 75.2508773803711, "eval/prior_ent_mean": 53.992042541503906, "eval/prior_ent_min": 34.71205520629883, "eval/prior_ent_std": 6.345944881439209, "eval/rep_loss_mean": 19.73169708251953, "eval/rep_loss_std": 13.302308082580566, "eval/reward_avg": 0.04677734151482582, "eval/reward_loss_mean": 0.13961541652679443, "eval/reward_loss_std": 0.7982499003410339, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.002943515777588, "eval/reward_neg_acc": 0.9886715412139893, "eval/reward_neg_loss": 0.04876568168401718, "eval/reward_pos_acc": 0.849056601524353, "eval/reward_pos_loss": 1.804051160812378, "eval/reward_pred": 0.04276096075773239, "eval/reward_rate": 0.0517578125, "replay/size": 615201.0, "replay/inserts": 7352.0, "replay/samples": 29408.0, "replay/insert_wait_avg": 1.6985053725548745e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.330349791426135e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 2280.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.30680569431238e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.301568984985352e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3313143253326, "timer/env.step_count": 919.0, "timer/env.step_total": 79.29090523719788, "timer/env.step_frac": 0.07926464372523932, "timer/env.step_avg": 0.08627954868030237, "timer/env.step_min": 0.023630380630493164, "timer/env.step_max": 3.348435401916504, "timer/replay._sample_count": 29408.0, "timer/replay._sample_total": 14.339104413986206, "timer/replay._sample_frac": 0.014334355236751863, "timer/replay._sample_avg": 0.00048759196184664736, "timer/replay._sample_min": 0.0003707408905029297, "timer/replay._sample_max": 0.020128488540649414, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1204.0, "timer/agent.policy_total": 20.288077116012573, "timer/agent.policy_frac": 0.020281357611698622, "timer/agent.policy_avg": 0.01685056238871476, "timer/agent.policy_min": 0.010022878646850586, "timer/agent.policy_max": 0.08448600769042969, "timer/dataset_train_count": 1838.0, "timer/dataset_train_total": 0.3072068691253662, "timer/dataset_train_frac": 0.00030710512079946235, "timer/dataset_train_avg": 0.00016714193097136355, "timer/dataset_train_min": 9.918212890625e-05, "timer/dataset_train_max": 0.0012519359588623047, "timer/agent.train_count": 1838.0, "timer/agent.train_total": 829.3876945972443, "timer/agent.train_frac": 0.8291129975838253, "timer/agent.train_avg": 0.4512446651780437, "timer/agent.train_min": 0.4381144046783447, "timer/agent.train_max": 1.0551879405975342, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47415614128112793, "timer/agent.report_frac": 0.00047399909858957044, "timer/agent.report_avg": 0.23707807064056396, "timer/agent.report_min": 0.23042535781860352, "timer/agent.report_max": 0.24373078346252441, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8848648071289062e-05, "timer/dataset_eval_frac": 2.8839093266560247e-08, "timer/dataset_eval_avg": 2.8848648071289062e-05, "timer/dataset_eval_min": 2.8848648071289062e-05, "timer/dataset_eval_max": 2.8848648071289062e-05, "fps": 7.349444190859501}
{"step": 615880, "time": 82417.9809744358, "episode/length": 231.0, "episode/score": 8.366415862273243, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.2664155810371085}
{"step": 616424, "time": 82486.2128636837, "episode/length": 269.0, "episode/score": 12.407544367069931, "episode/reward_rate": 0.9962962962962963, "episode/intrinsic_return": 0.307544090985175}
{"step": 616480, "time": 82494.50377440453, "episode/length": 159.0, "episode/score": 12.27864523590597, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.1786448624689001}
{"step": 616536, "time": 82503.1435508728, "episode/length": 162.0, "episode/score": 10.2780062667523, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.178005905058626}
{"step": 616848, "time": 82542.89832520485, "episode/length": 201.0, "episode/score": 8.331635654250022, "episode/reward_rate": 0.9702970297029703, "episode/intrinsic_return": 0.23163539024335478}
{"step": 616880, "time": 82548.23917365074, "episode/length": 173.0, "episode/score": 11.29406673774588, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.19406639678868487}
{"step": 616944, "time": 82557.76368331909, "episode/length": 181.0, "episode/score": 9.303862441018282, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.20386214636528166}
{"step": 617152, "time": 82585.4061756134, "episode/length": 180.0, "episode/score": 10.305882891149395, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.20588258278849025}
{"step": 617264, "time": 82600.705016613, "episode/length": 97.0, "episode/score": 3.2137766515879775, "episode/reward_rate": 0.9489795918367347, "episode/intrinsic_return": 0.11377658542915015}
{"step": 617528, "time": 82634.57925915718, "episode/length": 123.0, "episode/score": 7.22613949289007, "episode/reward_rate": 0.9919354838709677, "episode/intrinsic_return": 0.12613933754255413}
{"step": 617624, "time": 82647.74767875671, "episode/length": 217.0, "episode/score": 11.346818488050076, "episode/reward_rate": 0.9678899082568807, "episode/intrinsic_return": 0.24681816702900505}
{"step": 617752, "time": 82665.47550010681, "episode/length": 165.0, "episode/score": 3.276103581718644, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.17610345741036326}
{"step": 618672, "time": 82780.51369428635, "episode/length": 189.0, "episode/score": 11.303307690935299, "episode/reward_rate": 0.9631578947368421, "episode/intrinsic_return": 0.20330736671280647}
{"step": 618904, "time": 82810.37080192566, "episode/length": 204.0, "episode/score": 9.329615994358392, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.22961567709171504}
{"step": 619056, "time": 82830.78517270088, "episode/length": 263.0, "episode/score": 11.401219632351967, "episode/reward_rate": 0.9962121212121212, "episode/intrinsic_return": 0.3012192053201943}
{"step": 619120, "time": 82840.07104706764, "episode/length": 283.0, "episode/score": 11.403642892280686, "episode/reward_rate": 0.9753521126760564, "episode/intrinsic_return": 0.3036425300704195}
{"step": 619256, "time": 82858.0442495346, "episode/length": 203.0, "episode/score": 11.32176191170447, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.22176151854955606}
{"step": 619344, "time": 82870.41228246689, "episode/length": 307.0, "episode/score": 10.433483504625656, "episode/reward_rate": 0.9967532467532467, "episode/intrinsic_return": 0.33348321195171593}
{"step": 619952, "time": 82946.20622515678, "episode/length": 159.0, "episode/score": 13.276856973863005, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.176856664032357}
{"step": 620040, "time": 82958.54569506645, "episode/length": 285.0, "episode/score": 10.417289165199008, "episode/reward_rate": 0.9755244755244755, "episode/intrinsic_return": 0.31728887988833776}
{"step": 620048, "time": 82981.22395014763, "eval_episode/length": 166.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9940119760479041}
{"step": 620048, "time": 82982.88337159157, "eval_episode/length": 170.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9707602339181286}
{"step": 620048, "time": 82985.08651614189, "eval_episode/length": 184.0, "eval_episode/score": 12.100000001490116, "eval_episode/reward_rate": 0.9945945945945946}
{"step": 620048, "time": 82987.04598402977, "eval_episode/length": 192.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9792746113989638}
{"step": 620048, "time": 82990.52686309814, "eval_episode/length": 236.0, "eval_episode/score": 10.099999994039536, "eval_episode/reward_rate": 0.9915611814345991}
{"step": 620048, "time": 82992.24227118492, "eval_episode/length": 240.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.979253112033195}
{"step": 620048, "time": 82996.59867215157, "eval_episode/length": 296.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9932659932659933}
{"step": 620048, "time": 83002.59811377525, "eval_episode/length": 157.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9936708860759493}
{"step": 620440, "time": 83050.46642065048, "episode/length": 191.0, "episode/score": 12.309651636332546, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.2096513762403447}
{"step": 620800, "time": 83096.32619595528, "episode/length": 209.0, "episode/score": 8.326987359006125, "episode/reward_rate": 0.9809523809523809, "episode/intrinsic_return": 0.22698709406813578}
{"step": 620968, "time": 83118.38749408722, "episode/length": 429.0, "episode/score": 9.56629648146668, "episode/reward_rate": 0.8395348837209302, "episode/intrinsic_return": 0.46629620279168194}
{"step": 621360, "time": 83167.98919796944, "episode/length": 48.0, "episode/score": 6.157708574552089, "episode/reward_rate": 0.9387755102040817, "episode/intrinsic_return": 0.057708332198672}
{"step": 621608, "time": 83199.91327047348, "episode/length": 206.0, "episode/score": 10.332865018690654, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.2328647036649727}
{"step": 621624, "time": 83203.39298892021, "episode/length": 295.0, "episode/score": 10.446334768055067, "episode/reward_rate": 0.9797297297297297, "episode/intrinsic_return": 0.3463344083550055}
{"step": 621752, "time": 83220.6122136116, "episode/length": 213.0, "episode/score": 11.346964185215029, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.24696383339482963}
{"step": 621776, "time": 83225.07734799385, "episode/length": 303.0, "episode/score": 12.43876206273876, "episode/reward_rate": 0.9802631578947368, "episode/intrinsic_return": 0.33876168883602986}
{"step": 622144, "time": 83271.37938976288, "episode/length": 167.0, "episode/score": 10.280575242453779, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.18057496214896673}
{"step": 622192, "time": 83278.85314035416, "episode/length": 391.0, "episode/score": 13.530054491465535, "episode/reward_rate": 0.9872448979591837, "episode/intrinsic_return": 0.4300539967091481}
{"step": 622408, "time": 83306.69832921028, "episode/length": 245.0, "episode/score": 11.394666018546559, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.29466566862538457}
{"step": 622656, "time": 83339.9856710434, "episode/length": 57.0, "episode/score": 6.167375210148748, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.06737499876180664}
{"step": 623101, "time": 83396.73270344734, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.312854993665541, "train/action_min": 0.0, "train/action_std": 3.3550260801573057, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03942515922559274, "train/actor_opt_grad_steps": 154460.0, "train/actor_opt_loss": -7.871349994002564, "train/adv_mag": 0.4638568992550309, "train/adv_max": 0.41662584688212423, "train/adv_mean": 0.0026649249076129036, "train/adv_min": -0.38335279749857415, "train/adv_std": 0.049657506153390214, "train/cont_avg": 0.9950432854729729, "train/cont_loss_mean": 7.520565873629476e-05, "train/cont_loss_std": 0.0022631626361894757, "train/cont_neg_acc": 0.9962033471545657, "train/cont_neg_loss": 0.008987780304814683, "train/cont_pos_acc": 0.9999893787744883, "train/cont_pos_loss": 2.2175550102015545e-05, "train/cont_pred": 0.9950557695852743, "train/cont_rate": 0.9950432854729729, "train/dyn_loss_mean": 7.121057345416094, "train/dyn_loss_std": 8.99770816081279, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.058077437168843, "train/extr_critic_critic_opt_grad_steps": 154460.0, "train/extr_critic_critic_opt_loss": 16016.369188133445, "train/extr_critic_mag": 10.315112459337389, "train/extr_critic_max": 10.315112459337389, "train/extr_critic_mean": 3.048522034206906, "train/extr_critic_min": -0.4495291716343648, "train/extr_critic_std": 2.482621714875505, "train/extr_return_normed_mag": 1.4862305241662104, "train/extr_return_normed_max": 1.4862305241662104, "train/extr_return_normed_mean": 0.41055171288348535, "train/extr_return_normed_min": -0.08643786166668743, "train/extr_return_normed_std": 0.3291063339323611, "train/extr_return_rate": 0.7917933960218687, "train/extr_return_raw_mag": 11.285688405423551, "train/extr_return_raw_max": 11.285688405423551, "train/extr_return_raw_mean": 3.068859418662819, "train/extr_return_raw_min": -0.7268850065566398, "train/extr_return_raw_std": 2.5137009285591745, "train/extr_reward_mag": 1.0450587401518951, "train/extr_reward_max": 1.0450587401518951, "train/extr_reward_mean": 0.04813858957306759, "train/extr_reward_min": -0.6381680308161555, "train/extr_reward_std": 0.20897201573526536, "train/image_loss_mean": 3.7960571018425195, "train/image_loss_std": 8.885904821189675, "train/model_loss_mean": 8.154321348344958, "train/model_loss_std": 13.065017125413224, "train/model_opt_grad_norm": 36.809806792800494, "train/model_opt_grad_steps": 154327.4054054054, "train/model_opt_loss": 10694.548550992398, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1317.5675675675675, "train/policy_entropy_mag": 2.6101837158203125, "train/policy_entropy_max": 2.6101837158203125, "train/policy_entropy_mean": 0.45808975841547994, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6170526825092935, "train/policy_logprob_mag": 7.438384156613736, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.45818398707621805, "train/policy_logprob_min": -7.438384156613736, "train/policy_logprob_std": 1.0553422219044453, "train/policy_randomness_mag": 0.9212803060944016, "train/policy_randomness_max": 0.9212803060944016, "train/policy_randomness_mean": 0.16168558295514132, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.2177925192826503, "train/post_ent_mag": 59.95270235216295, "train/post_ent_max": 59.95270235216295, "train/post_ent_mean": 44.64597646352407, "train/post_ent_min": 19.655510959109744, "train/post_ent_std": 6.988095162365887, "train/prior_ent_mag": 74.7799965110985, "train/prior_ent_max": 74.7799965110985, "train/prior_ent_mean": 51.79943645580395, "train/prior_ent_min": 31.172189083614864, "train/prior_ent_std": 6.698962814743455, "train/rep_loss_mean": 7.121057345416094, "train/rep_loss_std": 8.99770816081279, "train/reward_avg": 0.030902850124481563, "train/reward_loss_mean": 0.08555465038563755, "train/reward_loss_std": 0.20750069175217603, "train/reward_max_data": 1.0201666999507595, "train/reward_max_pred": 1.0181423999167778, "train/reward_neg_acc": 0.9982338699134621, "train/reward_neg_loss": 0.05502309734756882, "train/reward_pos_acc": 0.8984319126283801, "train/reward_pos_loss": 0.7652310719361176, "train/reward_pred": 0.03032602419623652, "train/reward_rate": 0.04300570101351351, "train_stats/sum_log_reward": 9.72500029206276, "train_stats/max_log_achievement_collect_coal": 0.65625, "train_stats/max_log_achievement_collect_drink": 3.4375, "train_stats/max_log_achievement_collect_sapling": 1.09375, "train_stats/max_log_achievement_collect_stone": 11.0625, "train_stats/max_log_achievement_collect_wood": 8.34375, "train_stats/max_log_achievement_defeat_skeleton": 0.125, "train_stats/max_log_achievement_defeat_zombie": 0.5625, "train_stats/max_log_achievement_eat_cow": 0.21875, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.40625, "train_stats/max_log_achievement_make_wood_sword": 1.15625, "train_stats/max_log_achievement_place_furnace": 1.4375, "train_stats/max_log_achievement_place_plant": 1.0625, "train_stats/max_log_achievement_place_stone": 4.40625, "train_stats/max_log_achievement_place_table": 2.4375, "train_stats/max_log_achievement_wake_up": 1.34375, "train_stats/mean_log_entropy": 0.49828575318679214, "eval_stats/sum_log_reward": 9.100000202655792, "eval_stats/max_log_achievement_collect_coal": 0.625, "eval_stats/max_log_achievement_collect_drink": 2.875, "eval_stats/max_log_achievement_collect_sapling": 1.25, "eval_stats/max_log_achievement_collect_stone": 5.125, "eval_stats/max_log_achievement_collect_wood": 8.0, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.75, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.375, "eval_stats/max_log_achievement_make_wood_sword": 1.0, "eval_stats/max_log_achievement_place_furnace": 0.625, "eval_stats/max_log_achievement_place_plant": 1.25, "eval_stats/max_log_achievement_place_stone": 1.75, "eval_stats/max_log_achievement_place_table": 2.125, "eval_stats/max_log_achievement_wake_up": 1.5, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 5.834522198711056e-06, "report/cont_loss_std": 0.00013891997514292598, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.001483964966610074, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.4913383665771107e-06, "report/cont_pred": 0.9970731735229492, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 7.638131618499756, "report/dyn_loss_std": 9.633634567260742, "report/image_loss_mean": 5.381350517272949, "report/image_loss_std": 10.997305870056152, "report/model_loss_mean": 10.043838500976562, "report/model_loss_std": 15.329960823059082, "report/post_ent_mag": 59.64067077636719, "report/post_ent_max": 59.64067077636719, "report/post_ent_mean": 45.061912536621094, "report/post_ent_min": 19.800434112548828, "report/post_ent_std": 7.507026672363281, "report/prior_ent_mag": 74.77192687988281, "report/prior_ent_max": 74.77192687988281, "report/prior_ent_mean": 52.56599426269531, "report/prior_ent_min": 29.09575080871582, "report/prior_ent_std": 6.708988666534424, "report/rep_loss_mean": 7.638131618499756, "report/rep_loss_std": 9.633634567260742, "report/reward_avg": 0.021905574947595596, "report/reward_loss_mean": 0.0796029269695282, "report/reward_loss_std": 0.14415143430233002, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0042014122009277, "report/reward_neg_acc": 0.9969512820243835, "report/reward_neg_loss": 0.05457222834229469, "report/reward_pos_acc": 0.824999988079071, "report/reward_pos_loss": 0.6953580975532532, "report/reward_pred": 0.022635169327259064, "report/reward_rate": 0.0390625, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.000640111684333533, "eval/cont_loss_std": 0.01780397817492485, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.108963243663311, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.6649336203045095e-06, "eval/cont_pred": 0.9946442246437073, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 18.390426635742188, "eval/dyn_loss_std": 12.405126571655273, "eval/image_loss_mean": 17.181869506835938, "eval/image_loss_std": 20.54307746887207, "eval/model_loss_mean": 28.35205841064453, "eval/model_loss_std": 25.16623878479004, "eval/post_ent_mag": 58.43171691894531, "eval/post_ent_max": 58.43171691894531, "eval/post_ent_mean": 42.143272399902344, "eval/post_ent_min": 21.382305145263672, "eval/post_ent_std": 7.389840602874756, "eval/prior_ent_mag": 74.77192687988281, "eval/prior_ent_max": 74.77192687988281, "eval/prior_ent_mean": 53.983001708984375, "eval/prior_ent_min": 38.358489990234375, "eval/prior_ent_std": 5.587848663330078, "eval/rep_loss_mean": 18.390426635742188, "eval/rep_loss_std": 12.405126571655273, "eval/reward_avg": 0.03125, "eval/reward_loss_mean": 0.1352948546409607, "eval/reward_loss_std": 0.7862377166748047, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0013949871063232, "eval/reward_neg_acc": 0.986842155456543, "eval/reward_neg_loss": 0.07027983665466309, "eval/reward_pos_acc": 0.8055555820465088, "eval/reward_pos_loss": 1.9195961952209473, "eval/reward_pred": 0.030377177521586418, "eval/reward_rate": 0.03515625, "replay/size": 622597.0, "replay/inserts": 7396.0, "replay/samples": 29584.0, "replay/insert_wait_avg": 1.6934617652707387e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.451950633377563e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 2744.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2725504772308617e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.344650268554688e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0674033164978, "timer/env.step_count": 924.0, "timer/env.step_total": 75.6077470779419, "timer/env.step_frac": 0.07560265120851442, "timer/env.step_avg": 0.08182656610166872, "timer/env.step_min": 0.023673057556152344, "timer/env.step_max": 2.1482419967651367, "timer/replay._sample_count": 29584.0, "timer/replay._sample_total": 14.456498384475708, "timer/replay._sample_frac": 0.014455524034214089, "timer/replay._sample_avg": 0.0004886593558841167, "timer/replay._sample_min": 0.00037360191345214844, "timer/replay._sample_max": 0.010473012924194336, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1267.0, "timer/agent.policy_total": 21.123774528503418, "timer/agent.policy_frac": 0.02112235081200646, "timer/agent.policy_avg": 0.01667227666022369, "timer/agent.policy_min": 0.01003265380859375, "timer/agent.policy_max": 0.13979029655456543, "timer/dataset_train_count": 1849.0, "timer/dataset_train_total": 0.3380088806152344, "timer/dataset_train_frac": 0.00033798609923121604, "timer/dataset_train_avg": 0.0001828063172608082, "timer/dataset_train_min": 9.751319885253906e-05, "timer/dataset_train_max": 0.02394247055053711, "timer/agent.train_count": 1849.0, "timer/agent.train_total": 833.343909740448, "timer/agent.train_frac": 0.833287743382947, "timer/agent.train_avg": 0.4506997889348015, "timer/agent.train_min": 0.4371330738067627, "timer/agent.train_max": 1.0150587558746338, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47722482681274414, "timer/agent.report_frac": 0.000477192662444687, "timer/agent.report_avg": 0.23861241340637207, "timer/agent.report_min": 0.2328939437866211, "timer/agent.report_max": 0.24433088302612305, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8133392333984375e-05, "timer/dataset_eval_frac": 2.8131496177843942e-08, "timer/dataset_eval_avg": 2.8133392333984375e-05, "timer/dataset_eval_min": 2.8133392333984375e-05, "timer/dataset_eval_max": 2.8133392333984375e-05, "fps": 7.3953965659785394}
{"step": 623208, "time": 83409.88339233398, "episode/length": 230.0, "episode/score": 12.362909982191923, "episode/reward_rate": 0.9783549783549783, "episode/intrinsic_return": 0.2629096446107724}
{"step": 623296, "time": 83422.06248903275, "episode/length": 208.0, "episode/score": 11.334484566988976, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.2344841947160603}
{"step": 623384, "time": 83434.39157366753, "episode/length": 203.0, "episode/score": 10.318474475036055, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.21847415771117085}
{"step": 623440, "time": 83442.69153690338, "episode/length": 207.0, "episode/score": 12.326663377607474, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.2266631276870612}
{"step": 623768, "time": 83484.19154286385, "episode/length": 202.0, "episode/score": 11.324272795302022, "episode/reward_rate": 0.9802955665024631, "episode/intrinsic_return": 0.22427241057266656}
{"step": 623896, "time": 83501.30006217957, "episode/length": 185.0, "episode/score": 12.30535661513386, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.20535632787323266}
{"step": 624600, "time": 83589.04022312164, "episode/length": 162.0, "episode/score": 12.280870045040501, "episode/reward_rate": 0.9815950920245399, "episode/intrinsic_return": 0.18086961560766213}
{"step": 624704, "time": 83603.16049075127, "episode/length": 255.0, "episode/score": 12.397028939587472, "episode/reward_rate": 0.97265625, "episode/intrinsic_return": 0.2970285645205877}
{"step": 624712, "time": 83605.59792470932, "episode/length": 158.0, "episode/score": 12.28350734390915, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.1835069920089154}
{"step": 624936, "time": 83634.55310463905, "episode/length": 145.0, "episode/score": 9.262735625728965, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.16273529652971774}
{"step": 624992, "time": 83642.97060918808, "episode/length": 422.0, "episode/score": 11.53882571109716, "episode/reward_rate": 0.8817966903073287, "episode/intrinsic_return": 0.43882532887073467}
{"step": 624992, "time": 83642.98030757904, "episode/length": 222.0, "episode/score": 8.354346475207421, "episode/reward_rate": 0.9641255605381166, "episode/intrinsic_return": 0.2543462483372423}
{"step": 625264, "time": 83679.50521302223, "episode/length": 170.0, "episode/score": 10.30487534974236, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.20487499597948045}
{"step": 625480, "time": 83707.55956435204, "episode/length": 261.0, "episode/score": 10.393064326191961, "episode/reward_rate": 0.9809160305343512, "episode/intrinsic_return": 0.2930640037448029}
{"step": 625904, "time": 83760.90939927101, "episode/length": 120.0, "episode/score": 9.231251396689913, "episode/reward_rate": 0.9917355371900827, "episode/intrinsic_return": 0.1312510057905456}
{"step": 625992, "time": 83773.21859669685, "episode/length": 173.0, "episode/score": 11.31049279771105, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.21049241996661294}
{"step": 626424, "time": 83827.78022265434, "episode/length": 144.0, "episode/score": 7.264663777783426, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.16466359465630376}
{"step": 626816, "time": 83877.8175444603, "episode/length": 263.0, "episode/score": 9.407392855751823, "episode/reward_rate": 0.9810606060606061, "episode/intrinsic_return": 0.30739255961452727}
{"step": 626960, "time": 83897.11297082901, "episode/length": 184.0, "episode/score": 12.310793145439675, "episode/reward_rate": 0.9675675675675676, "episode/intrinsic_return": 0.21079276688033133}
{"step": 626976, "time": 83900.6181435585, "episode/length": 247.0, "episode/score": 10.385411817460408, "episode/reward_rate": 0.9717741935483871, "episode/intrinsic_return": 0.28541144565315335}
{"step": 627136, "time": 83921.63372969627, "episode/length": 302.0, "episode/score": 11.452530097329145, "episode/reward_rate": 0.976897689768977, "episode/intrinsic_return": 0.35252972936359583}
{"step": 627304, "time": 83943.94327902794, "episode/length": 288.0, "episode/score": 12.443369557953702, "episode/reward_rate": 0.9792387543252595, "episode/intrinsic_return": 0.34336918405097094}
{"step": 627440, "time": 83962.10281538963, "episode/length": 191.0, "episode/score": 8.319948005777405, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.21994765387717052}
{"step": 627784, "time": 84005.78922557831, "episode/length": 80.0, "episode/score": 8.18568104892256, "episode/reward_rate": 0.9876543209876543, "episode/intrinsic_return": 0.08568075301809586}
{"step": 628176, "time": 84055.11228251457, "episode/length": 169.0, "episode/score": 11.288882119664777, "episode/reward_rate": 0.9823529411764705, "episode/intrinsic_return": 0.18888178377164877}
{"step": 628384, "time": 84082.1137201786, "episode/length": 244.0, "episode/score": 12.383071605843725, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.28307120062527247}
{"step": 628384, "time": 84082.12188100815, "episode/length": 175.0, "episode/score": 10.285379423768973, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.1853792803685792}
{"step": 628408, "time": 84088.47406721115, "episode/length": 301.0, "episode/score": 11.454277061518951, "episode/reward_rate": 0.9966887417218543, "episode/intrinsic_return": 0.35427668400734547}
{"step": 628520, "time": 84103.79497671127, "episode/length": 151.0, "episode/score": 10.266096283410661, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.16609602094649745}
{"step": 628528, "time": 84106.2286965847, "episode/length": 195.0, "episode/score": 12.318987225398814, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.2189867973629589}
{"step": 628696, "time": 84128.10351061821, "episode/length": 38.0, "episode/score": 5.147291803965345, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.04729166568722576}
{"step": 628864, "time": 84150.26172232628, "episode/length": 177.0, "episode/score": 9.295188773883638, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.19518852914370655}
{"step": 629136, "time": 84184.88934469223, "episode/length": 75.0, "episode/score": 6.191471187551542, "episode/reward_rate": 0.9342105263157895, "episode/intrinsic_return": 0.09147102179940703}
{"step": 629168, "time": 84190.3432905674, "episode/length": 58.0, "episode/score": 6.169666858389974, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.06966666533844545}
{"step": 629560, "time": 84239.8213737011, "episode/length": 172.0, "episode/score": 9.28805375409138, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.18805352518393192}
{"step": 630032, "time": 84318.39105129242, "eval_episode/length": 152.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9607843137254902}
{"step": 630032, "time": 84320.13273334503, "eval_episode/length": 157.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9620253164556962}
{"step": 630032, "time": 84323.37646198273, "eval_episode/length": 195.0, "eval_episode/score": 11.100000008940697, "eval_episode/reward_rate": 0.9948979591836735}
{"step": 630032, "time": 84325.26780152321, "eval_episode/length": 203.0, "eval_episode/score": 10.099999979138374, "eval_episode/reward_rate": 0.9950980392156863}
{"step": 630032, "time": 84327.44007563591, "eval_episode/length": 60.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9836065573770492}
{"step": 630032, "time": 84330.36991167068, "eval_episode/length": 247.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9879032258064516}
{"step": 630032, "time": 84333.59126996994, "eval_episode/length": 284.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9754385964912281}
{"step": 630032, "time": 84336.78345775604, "eval_episode/length": 321.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.984472049689441}
{"step": 630080, "time": 84342.65553498268, "episode/length": 151.0, "episode/score": 10.260901269436545, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.16090098913173279}
{"step": 630312, "time": 84372.56177210808, "episode/length": 240.0, "episode/score": 11.369854472739462, "episode/reward_rate": 0.995850622406639, "episode/intrinsic_return": 0.2698542566377}
{"step": 630493, "time": 84397.00743937492, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.389737845755912, "train/action_min": 0.0, "train/action_std": 3.385262833414851, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03845470531566723, "train/actor_opt_grad_steps": 156310.0, "train/actor_opt_loss": -9.706461204628686, "train/adv_mag": 0.43092231460519737, "train/adv_max": 0.38834120389577503, "train/adv_mean": 0.0019635694001955335, "train/adv_min": -0.34989687268798414, "train/adv_std": 0.04781639495411435, "train/cont_avg": 0.9948638091216216, "train/cont_loss_mean": 0.00018035606721935905, "train/cont_loss_std": 0.005545821054348946, "train/cont_neg_acc": 0.9924301252416943, "train/cont_neg_loss": 0.03491080692660237, "train/cont_pos_acc": 0.9999893729751175, "train/cont_pos_loss": 3.855906415931197e-05, "train/cont_pred": 0.9948733423207258, "train/cont_rate": 0.9948638091216216, "train/dyn_loss_mean": 7.003746800809293, "train/dyn_loss_std": 8.934461098748285, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.012299587597718, "train/extr_critic_critic_opt_grad_steps": 156310.0, "train/extr_critic_critic_opt_loss": 15870.755099239865, "train/extr_critic_mag": 10.15033659548373, "train/extr_critic_max": 10.15033659548373, "train/extr_critic_mean": 2.987649423367268, "train/extr_critic_min": -0.41784498820433746, "train/extr_critic_std": 2.4698104819735964, "train/extr_return_normed_mag": 1.4461091125333632, "train/extr_return_normed_max": 1.4461091125333632, "train/extr_return_normed_mean": 0.4012618097099098, "train/extr_return_normed_min": -0.08627154398206117, "train/extr_return_normed_std": 0.32546368418513116, "train/extr_return_rate": 0.7841688172237293, "train/extr_return_raw_mag": 11.012580088022593, "train/extr_return_raw_max": 11.012580088022593, "train/extr_return_raw_mean": 3.002710611111409, "train/extr_return_raw_min": -0.7355866685106948, "train/extr_return_raw_std": 2.4953064319249747, "train/extr_reward_mag": 1.038395154798353, "train/extr_reward_max": 1.038395154798353, "train/extr_reward_mean": 0.04889739287664761, "train/extr_reward_min": -0.6490577169366785, "train/extr_reward_std": 0.21121850070115683, "train/image_loss_mean": 3.7883091050225337, "train/image_loss_std": 8.925012142593797, "train/model_loss_mean": 8.074788647728997, "train/model_loss_std": 13.031237679558831, "train/model_opt_grad_norm": 36.32591506854908, "train/model_opt_grad_steps": 156176.47567567567, "train/model_opt_loss": 14810.317958192567, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1844.5945945945946, "train/policy_entropy_mag": 2.6011096297083673, "train/policy_entropy_max": 2.6011096297083673, "train/policy_entropy_mean": 0.45670412472776467, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6137675401326772, "train/policy_logprob_mag": 7.438384133416253, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.45690607235238356, "train/policy_logprob_min": -7.438384133416253, "train/policy_logprob_std": 1.0547493705878386, "train/policy_randomness_mag": 0.9180775503854494, "train/policy_randomness_max": 0.9180775503854494, "train/policy_randomness_mean": 0.16119651436000257, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.21663300781636624, "train/post_ent_mag": 59.874228462013036, "train/post_ent_max": 59.874228462013036, "train/post_ent_mean": 44.52221118823902, "train/post_ent_min": 19.420883570490656, "train/post_ent_std": 6.999377766171017, "train/prior_ent_mag": 74.84987759976774, "train/prior_ent_max": 74.84987759976774, "train/prior_ent_mean": 51.57955132561761, "train/prior_ent_min": 31.270739993533574, "train/prior_ent_std": 6.755062698673558, "train/rep_loss_mean": 7.003746800809293, "train/rep_loss_std": 8.934461098748285, "train/reward_avg": 0.030496824462268802, "train/reward_loss_mean": 0.08405113288679639, "train/reward_loss_std": 0.19095946485931808, "train/reward_max_data": 1.0152995818370096, "train/reward_max_pred": 1.0138174662718902, "train/reward_neg_acc": 0.9983881347888225, "train/reward_neg_loss": 0.054922504098834216, "train/reward_pos_acc": 0.9068766439283217, "train/reward_pos_loss": 0.7387978666537517, "train/reward_pred": 0.030237302073353046, "train/reward_rate": 0.042810388513513514, "train_stats/sum_log_reward": 10.127027215184393, "train_stats/max_log_achievement_collect_coal": 0.7567567567567568, "train_stats/max_log_achievement_collect_drink": 2.891891891891892, "train_stats/max_log_achievement_collect_sapling": 1.162162162162162, "train_stats/max_log_achievement_collect_stone": 11.864864864864865, "train_stats/max_log_achievement_collect_wood": 9.432432432432432, "train_stats/max_log_achievement_defeat_skeleton": 0.16216216216216217, "train_stats/max_log_achievement_defeat_zombie": 0.5675675675675675, "train_stats/max_log_achievement_eat_cow": 0.16216216216216217, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.5675675675675675, "train_stats/max_log_achievement_make_wood_sword": 1.5405405405405406, "train_stats/max_log_achievement_place_furnace": 1.5135135135135136, "train_stats/max_log_achievement_place_plant": 1.1081081081081081, "train_stats/max_log_achievement_place_stone": 4.405405405405405, "train_stats/max_log_achievement_place_table": 2.5405405405405403, "train_stats/max_log_achievement_wake_up": 1.3513513513513513, "train_stats/mean_log_entropy": 0.4427157660593858, "eval_stats/sum_log_reward": 9.224999964237213, "eval_stats/max_log_achievement_collect_coal": 0.5, "eval_stats/max_log_achievement_collect_drink": 5.375, "eval_stats/max_log_achievement_collect_sapling": 1.375, "eval_stats/max_log_achievement_collect_stone": 6.0, "eval_stats/max_log_achievement_collect_wood": 9.375, "eval_stats/max_log_achievement_defeat_skeleton": 0.375, "eval_stats/max_log_achievement_defeat_zombie": 0.875, "eval_stats/max_log_achievement_eat_cow": 0.25, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.375, "eval_stats/max_log_achievement_make_wood_sword": 1.25, "eval_stats/max_log_achievement_place_furnace": 0.875, "eval_stats/max_log_achievement_place_plant": 1.375, "eval_stats/max_log_achievement_place_stone": 2.125, "eval_stats/max_log_achievement_place_table": 2.625, "eval_stats/max_log_achievement_wake_up": 1.25, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 4.463839104573708e-06, "report/cont_loss_std": 5.3006053349236026e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 5.7032748372876085e-06, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 4.456534043129068e-06, "report/cont_pred": 0.9941362738609314, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 7.064321517944336, "report/dyn_loss_std": 9.497489929199219, "report/image_loss_mean": 4.139131546020508, "report/image_loss_std": 9.654594421386719, "report/model_loss_mean": 8.469890594482422, "report/model_loss_std": 14.169322967529297, "report/post_ent_mag": 61.321712493896484, "report/post_ent_max": 61.321712493896484, "report/post_ent_mean": 46.063392639160156, "report/post_ent_min": 19.185787200927734, "report/post_ent_std": 7.651777744293213, "report/prior_ent_mag": 74.54129791259766, "report/prior_ent_max": 74.54129791259766, "report/prior_ent_mean": 53.319244384765625, "report/prior_ent_min": 34.35203170776367, "report/prior_ent_std": 6.922383785247803, "report/rep_loss_mean": 7.064321517944336, "report/rep_loss_std": 9.497489929199219, "report/reward_avg": 0.029647160321474075, "report/reward_loss_mean": 0.09216263145208359, "report/reward_loss_std": 0.21027763187885284, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.013904333114624, "report/reward_neg_acc": 0.9959099888801575, "report/reward_neg_loss": 0.05908132717013359, "report/reward_pos_acc": 0.739130437374115, "report/reward_pos_loss": 0.7954999208450317, "report/reward_pred": 0.029085515066981316, "report/reward_rate": 0.044921875, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.0019220529356971383, "eval/cont_loss_std": 0.06024457886815071, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.007617938332259655, "eval/cont_pos_acc": 0.9990195631980896, "eval/cont_pos_loss": 0.0018997160950675607, "eval/cont_pred": 0.9952795505523682, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 18.75432014465332, "eval/dyn_loss_std": 12.988792419433594, "eval/image_loss_mean": 15.526902198791504, "eval/image_loss_std": 22.832643508911133, "eval/model_loss_mean": 26.8803653717041, "eval/model_loss_std": 28.186260223388672, "eval/post_ent_mag": 60.894012451171875, "eval/post_ent_max": 60.894012451171875, "eval/post_ent_mean": 41.51729202270508, "eval/post_ent_min": 20.91004753112793, "eval/post_ent_std": 8.05296802520752, "eval/prior_ent_mag": 74.54129791259766, "eval/prior_ent_max": 74.54129791259766, "eval/prior_ent_mean": 54.409461975097656, "eval/prior_ent_min": 38.9041748046875, "eval/prior_ent_std": 5.410967826843262, "eval/rep_loss_mean": 18.75432014465332, "eval/rep_loss_std": 12.988792419433594, "eval/reward_avg": 0.02021484449505806, "eval/reward_loss_mean": 0.09894931316375732, "eval/reward_loss_std": 0.692348301410675, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0024113655090332, "eval/reward_neg_acc": 0.9870129823684692, "eval/reward_neg_loss": 0.058968085795640945, "eval/reward_pos_acc": 0.8260869979858398, "eval/reward_pos_loss": 1.8390018939971924, "eval/reward_pred": 0.02578446827828884, "eval/reward_rate": 0.0224609375, "replay/size": 629989.0, "replay/inserts": 7392.0, "replay/samples": 29568.0, "replay/insert_wait_avg": 1.6647048326797815e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.573547430368729e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 2576.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1864471139374727e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.642673492431641e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2611684799194, "timer/env.step_count": 924.0, "timer/env.step_total": 82.99226069450378, "timer/env.step_frac": 0.08297059139127211, "timer/env.step_avg": 0.08981846395509067, "timer/env.step_min": 0.023381948471069336, "timer/env.step_max": 3.400514841079712, "timer/replay._sample_count": 29568.0, "timer/replay._sample_total": 14.467926502227783, "timer/replay._sample_frac": 0.01446414892244038, "timer/replay._sample_avg": 0.0004893102848426604, "timer/replay._sample_min": 0.00035691261291503906, "timer/replay._sample_max": 0.02564692497253418, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1246.0, "timer/agent.policy_total": 20.645726680755615, "timer/agent.policy_frac": 0.020640336075557736, "timer/agent.policy_avg": 0.016569604077652983, "timer/agent.policy_min": 0.009836435317993164, "timer/agent.policy_max": 0.052907705307006836, "timer/dataset_train_count": 1848.0, "timer/dataset_train_total": 0.31328916549682617, "timer/dataset_train_frac": 0.0003132073656052515, "timer/dataset_train_avg": 0.00016952876920823927, "timer/dataset_train_min": 9.965896606445312e-05, "timer/dataset_train_max": 0.0007927417755126953, "timer/agent.train_count": 1848.0, "timer/agent.train_total": 830.612783908844, "timer/agent.train_frac": 0.8303959106711227, "timer/agent.train_avg": 0.4494657921584654, "timer/agent.train_min": 0.43751978874206543, "timer/agent.train_max": 0.5954599380493164, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4823741912841797, "timer/agent.report_frac": 0.000482248243243548, "timer/agent.report_avg": 0.24118709564208984, "timer/agent.report_min": 0.23201251029968262, "timer/agent.report_max": 0.25036168098449707, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.075599670410156e-05, "timer/dataset_eval_frac": 3.074796630448121e-08, "timer/dataset_eval_avg": 3.075599670410156e-05, "timer/dataset_eval_min": 3.075599670410156e-05, "timer/dataset_eval_max": 3.075599670410156e-05, "fps": 7.389955907338769}
{"step": 630552, "time": 84404.11150741577, "episode/length": 172.0, "episode/score": 9.3044650634547, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.2044647825678112}
{"step": 630832, "time": 84441.4807317257, "episode/length": 158.0, "episode/score": 10.276702762834248, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.17670239507242513}
{"step": 630848, "time": 84444.92961382866, "episode/length": 290.0, "episode/score": 12.422065886146811, "episode/reward_rate": 0.993127147766323, "episode/intrinsic_return": 0.3220655633649585}
{"step": 631312, "time": 84503.29815268517, "episode/length": 59.0, "episode/score": 1.156577709094563, "episode/reward_rate": 0.9166666666666666, "episode/intrinsic_return": 0.05657767681259429}
{"step": 631408, "time": 84516.78269457817, "episode/length": 452.0, "episode/score": 11.639676138716823, "episode/reward_rate": 0.9823399558498896, "episode/intrinsic_return": 0.5396758805891295}
{"step": 631536, "time": 84534.0294213295, "episode/length": 181.0, "episode/score": 10.304434157585092, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.20443388257717743}
{"step": 631688, "time": 84554.1532599926, "episode/length": 171.0, "episode/score": 7.292386991172862, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.19238677955308958}
{"step": 631720, "time": 84559.7590265274, "episode/length": 322.0, "episode/score": 13.462894587960363, "episode/reward_rate": 0.9814241486068112, "episode/intrinsic_return": 0.3628942178993384}
{"step": 631936, "time": 84587.60252666473, "episode/length": 440.0, "episode/score": 5.519739308096177, "episode/reward_rate": 0.8684807256235828, "episode/intrinsic_return": 0.41973912776302313}
{"step": 632232, "time": 84625.16114926338, "episode/length": 209.0, "episode/score": 8.343957966939342, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.24395777959216502}
{"step": 632320, "time": 84637.45100688934, "episode/length": 183.0, "episode/score": 11.308766248533175, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.2087659275994156}
{"step": 632560, "time": 84668.47729372978, "episode/length": 155.0, "episode/score": 10.287036667716166, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.18703636505961185}
{"step": 633232, "time": 84752.32920575142, "episode/length": 227.0, "episode/score": 12.355081192227772, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.25508095930399577}
{"step": 633248, "time": 84755.85301041603, "episode/length": 194.0, "episode/score": 7.31696800541431, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.21696785029962484}
{"step": 633376, "time": 84773.02197623253, "episode/length": 179.0, "episode/score": 12.299659779293506, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.19965946733827877}
{"step": 633592, "time": 84800.9367582798, "episode/length": 169.0, "episode/score": 10.30051219004963, "episode/reward_rate": 0.9647058823529412, "episode/intrinsic_return": 0.20051190089725424}
{"step": 633960, "time": 84847.48576879501, "episode/length": 302.0, "episode/score": 12.435889199322446, "episode/reward_rate": 0.9966996699669967, "episode/intrinsic_return": 0.3358888654083785}
{"step": 633968, "time": 84850.0008957386, "episode/length": 280.0, "episode/score": 11.426524748258089, "episode/reward_rate": 0.9750889679715302, "episode/intrinsic_return": 0.3265243791283865}
{"step": 634064, "time": 84863.20161676407, "episode/length": 187.0, "episode/score": 12.300525595528143, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.20052521894785968}
{"step": 634072, "time": 84865.59368038177, "episode/length": 218.0, "episode/score": 10.345239599197612, "episode/reward_rate": 0.9726027397260274, "episode/intrinsic_return": 0.2452392653417519}
{"step": 635152, "time": 84998.70642638206, "episode/length": 221.0, "episode/score": 11.338475606283737, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.23847513924874875}
{"step": 635168, "time": 85002.26163291931, "episode/length": 239.0, "episode/score": 12.377625036419886, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.2776246437742884}
{"step": 635232, "time": 85011.48367738724, "episode/length": 204.0, "episode/score": 12.332733245258623, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.23273289335838854}
{"step": 635336, "time": 85025.64787745476, "episode/length": 171.0, "episode/score": 10.29963586400072, "episode/reward_rate": 0.9651162790697675, "episode/intrinsic_return": 0.19963561556460263}
{"step": 635584, "time": 85057.3975391388, "episode/length": 43.0, "episode/score": 0.14299379258591216, "episode/reward_rate": 0.8863636363636364, "episode/intrinsic_return": 0.042993784343707375}
{"step": 635656, "time": 85067.86129593849, "episode/length": 198.0, "episode/score": 9.314760147323796, "episode/reward_rate": 0.9798994974874372, "episode/intrinsic_return": 0.2147598417568588}
{"step": 635744, "time": 85080.31318569183, "episode/length": 313.0, "episode/score": 10.420774618126416, "episode/reward_rate": 0.9808917197452229, "episode/intrinsic_return": 0.32077434783332137}
{"step": 636096, "time": 85124.91492366791, "episode/length": 265.0, "episode/score": 11.414899009697365, "episode/reward_rate": 0.9962406015037594, "episode/intrinsic_return": 0.31489862403668667}
{"step": 636520, "time": 85178.30888986588, "episode/length": 168.0, "episode/score": 6.284696350733611, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.18469617066239152}
{"step": 636584, "time": 85187.60932087898, "episode/length": 313.0, "episode/score": 11.457770154442187, "episode/reward_rate": 0.9808917197452229, "episode/intrinsic_return": 0.35776991854982043}
{"step": 636760, "time": 85210.64233064651, "episode/length": 146.0, "episode/score": 10.254555459034236, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.15455512986409303}
{"step": 636848, "time": 85222.88528442383, "episode/length": 188.0, "episode/score": 13.311762692480443, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.21176228192143753}
{"step": 636872, "time": 85227.27177500725, "episode/length": 151.0, "episode/score": 7.280163458985498, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.18016323346864738}
{"step": 637464, "time": 85301.0229754448, "episode/length": 214.0, "episode/score": 8.337377484913759, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.23737719389873746}
{"step": 637752, "time": 85337.75473833084, "episode/length": 145.0, "episode/score": 10.262109053895074, "episode/reward_rate": 0.958904109589041, "episode/intrinsic_return": 0.16210879343907436}
{"step": 638144, "time": 85387.07668089867, "episode/length": 255.0, "episode/score": 12.396643276569193, "episode/reward_rate": 0.984375, "episode/intrinsic_return": 0.29664292350480537}
{"step": 638200, "time": 85395.36253857613, "episode/length": 209.0, "episode/score": 10.340066599725105, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.24006639022991294}
{"step": 638201, "time": 85398.05312371254, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.414911299789508, "train/action_min": 0.0, "train/action_std": 3.4490130738273184, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0392707744758055, "train/actor_opt_grad_steps": 158200.0, "train/actor_opt_loss": -9.7568453056593, "train/adv_mag": 0.44726030127063315, "train/adv_max": 0.4041033126992883, "train/adv_mean": 0.0019997048154856327, "train/adv_min": -0.36885647861759896, "train/adv_std": 0.04881473842988978, "train/cont_avg": 0.9948237127590673, "train/cont_loss_mean": 6.555960555427454e-05, "train/cont_loss_std": 0.0019729495672730544, "train/cont_neg_acc": 0.9982728846950234, "train/cont_neg_loss": 0.00816560055271995, "train/cont_pos_acc": 0.999994915384085, "train/cont_pos_loss": 1.7772969619104302e-05, "train/cont_pred": 0.9948331624115069, "train/cont_rate": 0.9948237127590673, "train/dyn_loss_mean": 6.894469747889227, "train/dyn_loss_std": 8.94841428371291, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0252586884202117, "train/extr_critic_critic_opt_grad_steps": 158200.0, "train/extr_critic_critic_opt_loss": 15951.066219033355, "train/extr_critic_mag": 10.012545798108986, "train/extr_critic_max": 10.012545798108986, "train/extr_critic_mean": 2.9080312925299214, "train/extr_critic_min": -0.4470511316635448, "train/extr_critic_std": 2.446671254894276, "train/extr_return_normed_mag": 1.4470004374499148, "train/extr_return_normed_max": 1.4470004374499148, "train/extr_return_normed_mean": 0.3979256641833893, "train/extr_return_normed_min": -0.09160547964081862, "train/extr_return_normed_std": 0.3278373235865578, "train/extr_return_rate": 0.7735464971300234, "train/extr_return_raw_mag": 10.839677894671347, "train/extr_return_raw_max": 10.839677894671347, "train/extr_return_raw_mean": 2.9231183714199562, "train/extr_return_raw_min": -0.7707478811703815, "train/extr_return_raw_std": 2.473980014188302, "train/extr_reward_mag": 1.046767725228028, "train/extr_reward_max": 1.046767725228028, "train/extr_reward_mean": 0.046723352166114694, "train/extr_reward_min": -0.6416326125051074, "train/extr_reward_std": 0.20679782717030282, "train/image_loss_mean": 3.70459106919679, "train/image_loss_std": 8.538601853069245, "train/model_loss_mean": 7.927132065432059, "train/model_loss_std": 12.676315292793234, "train/model_opt_grad_norm": 35.29117516532463, "train/model_opt_grad_steps": 158064.66321243523, "train/model_opt_loss": 10641.231827335654, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1340.6735751295337, "train/policy_entropy_mag": 2.614552271798485, "train/policy_entropy_max": 2.614552271798485, "train/policy_entropy_mean": 0.4802860901763402, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6466056869746489, "train/policy_logprob_mag": 7.438384147505686, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.4805158409121123, "train/policy_logprob_min": -7.438384147505686, "train/policy_logprob_std": 1.0741000947556965, "train/policy_randomness_mag": 0.922822216631835, "train/policy_randomness_max": 0.922822216631835, "train/policy_randomness_mean": 0.16951991401496946, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.22822343376634036, "train/post_ent_mag": 60.144750091078365, "train/post_ent_max": 60.144750091078365, "train/post_ent_mean": 44.80326382730909, "train/post_ent_min": 19.4013343326786, "train/post_ent_std": 7.067730078425432, "train/prior_ent_mag": 74.82579072151778, "train/prior_ent_max": 74.82579072151778, "train/prior_ent_mean": 51.765260903946476, "train/prior_ent_min": 31.08981011939172, "train/prior_ent_std": 6.7632946103348015, "train/rep_loss_mean": 6.894469747889227, "train/rep_loss_std": 8.94841428371291, "train/reward_avg": 0.031114279111567403, "train/reward_loss_mean": 0.08579364698862782, "train/reward_loss_std": 0.20043134322592632, "train/reward_max_data": 1.0188644543830594, "train/reward_max_pred": 1.0181756204891699, "train/reward_neg_acc": 0.9980952921926667, "train/reward_neg_loss": 0.05557077845143531, "train/reward_pos_acc": 0.9055000475651241, "train/reward_pos_loss": 0.7521979083051336, "train/reward_pred": 0.030720381066203117, "train/reward_rate": 0.04343932156735751, "train_stats/sum_log_reward": 9.694594763017989, "train_stats/max_log_achievement_collect_coal": 0.7297297297297297, "train_stats/max_log_achievement_collect_drink": 3.891891891891892, "train_stats/max_log_achievement_collect_sapling": 1.2702702702702702, "train_stats/max_log_achievement_collect_stone": 10.567567567567568, "train_stats/max_log_achievement_collect_wood": 9.0, "train_stats/max_log_achievement_defeat_skeleton": 0.16216216216216217, "train_stats/max_log_achievement_defeat_zombie": 0.7567567567567568, "train_stats/max_log_achievement_eat_cow": 0.10810810810810811, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.2972972972972974, "train_stats/max_log_achievement_make_wood_sword": 1.0810810810810811, "train_stats/max_log_achievement_place_furnace": 1.3513513513513513, "train_stats/max_log_achievement_place_plant": 1.2162162162162162, "train_stats/max_log_achievement_place_stone": 3.7567567567567566, "train_stats/max_log_achievement_place_table": 2.5675675675675675, "train_stats/max_log_achievement_wake_up": 1.3243243243243243, "train_stats/mean_log_entropy": 0.4652360399832597, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 5.111750397190917e-06, "report/cont_loss_std": 3.564981307135895e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 6.122407398834184e-07, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 5.133828381076455e-06, "report/cont_pred": 0.9951120615005493, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 7.179484844207764, "report/dyn_loss_std": 8.877581596374512, "report/image_loss_mean": 3.9211580753326416, "report/image_loss_std": 9.61378288269043, "report/model_loss_mean": 8.320611000061035, "report/model_loss_std": 13.607614517211914, "report/post_ent_mag": 60.68517303466797, "report/post_ent_max": 60.68517303466797, "report/post_ent_mean": 44.825782775878906, "report/post_ent_min": 18.854286193847656, "report/post_ent_std": 6.9159111976623535, "report/prior_ent_mag": 74.89225006103516, "report/prior_ent_max": 74.89225006103516, "report/prior_ent_mean": 52.36412048339844, "report/prior_ent_min": 33.651634216308594, "report/prior_ent_std": 6.319733619689941, "report/rep_loss_mean": 7.179484844207764, "report/rep_loss_std": 8.877581596374512, "report/reward_avg": 0.03864218294620514, "report/reward_loss_mean": 0.09175745397806168, "report/reward_loss_std": 0.21395942568778992, "report/reward_max_data": 1.1012500524520874, "report/reward_max_pred": 1.0677804946899414, "report/reward_neg_acc": 0.9969104528427124, "report/reward_neg_loss": 0.055716436356306076, "report/reward_pos_acc": 0.8301886916160583, "report/reward_pos_loss": 0.7520561814308167, "report/reward_pred": 0.03790785372257233, "report/reward_rate": 0.0517578125, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.00036041493876837194, "eval/cont_loss_std": 0.009082208387553692, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.07094849646091461, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 8.359891216969118e-05, "eval/cont_pred": 0.9962537288665771, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 18.44506072998047, "eval/dyn_loss_std": 11.981315612792969, "eval/image_loss_mean": 17.33708953857422, "eval/image_loss_std": 23.76161766052246, "eval/model_loss_mean": 28.541038513183594, "eval/model_loss_std": 28.253864288330078, "eval/post_ent_mag": 57.00420379638672, "eval/post_ent_max": 57.00420379638672, "eval/post_ent_mean": 41.729034423828125, "eval/post_ent_min": 20.71605682373047, "eval/post_ent_std": 6.785599708557129, "eval/prior_ent_mag": 74.89225006103516, "eval/prior_ent_max": 74.89225006103516, "eval/prior_ent_mean": 54.53192901611328, "eval/prior_ent_min": 37.709747314453125, "eval/prior_ent_std": 5.790622711181641, "eval/rep_loss_mean": 18.44506072998047, "eval/rep_loss_std": 11.981315612792969, "eval/reward_avg": 0.03505859151482582, "eval/reward_loss_mean": 0.1365521252155304, "eval/reward_loss_std": 0.7732676267623901, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0022079944610596, "eval/reward_neg_acc": 0.9918616414070129, "eval/reward_neg_loss": 0.04793848097324371, "eval/reward_pos_acc": 0.7560975551605225, "eval/reward_pos_loss": 2.261117935180664, "eval/reward_pred": 0.02692783996462822, "eval/reward_rate": 0.0400390625, "replay/size": 637697.0, "replay/inserts": 7708.0, "replay/samples": 30832.0, "replay/insert_wait_avg": 1.668868191080138e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.599746865439304e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 7.450580596923828e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1001.0351514816284, "timer/env.step_count": 964.0, "timer/env.step_total": 83.37155079841614, "timer/env.step_frac": 0.08328533785753499, "timer/env.step_avg": 0.0864850112016765, "timer/env.step_min": 0.02358722686767578, "timer/env.step_max": 1.9146811962127686, "timer/replay._sample_count": 30832.0, "timer/replay._sample_total": 15.106683015823364, "timer/replay._sample_frac": 0.015091061481171784, "timer/replay._sample_avg": 0.0004899676639797407, "timer/replay._sample_min": 0.0003581047058105469, "timer/replay._sample_max": 0.020012378692626953, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 964.0, "timer/agent.policy_total": 15.911398649215698, "timer/agent.policy_frac": 0.015894944973376107, "timer/agent.policy_avg": 0.016505600258522508, "timer/agent.policy_min": 0.014830350875854492, "timer/agent.policy_max": 0.061846256256103516, "timer/dataset_train_count": 1927.0, "timer/dataset_train_total": 0.32661867141723633, "timer/dataset_train_frac": 0.00032628092123818955, "timer/dataset_train_avg": 0.00016949593742461667, "timer/dataset_train_min": 0.00010156631469726562, "timer/dataset_train_max": 0.0012159347534179688, "timer/agent.train_count": 1927.0, "timer/agent.train_total": 866.551833152771, "timer/agent.train_frac": 0.865655748322315, "timer/agent.train_avg": 0.44968958648301555, "timer/agent.train_min": 0.43750524520874023, "timer/agent.train_max": 1.068244218826294, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47466397285461426, "timer/agent.report_frac": 0.00047417313183464725, "timer/agent.report_avg": 0.23733198642730713, "timer/agent.report_min": 0.23068737983703613, "timer/agent.report_max": 0.24397659301757812, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.1948089599609375e-05, "timer/dataset_eval_frac": 3.1915052685535695e-08, "timer/dataset_eval_avg": 3.1948089599609375e-05, "timer/dataset_eval_min": 3.1948089599609375e-05, "timer/dataset_eval_max": 3.1948089599609375e-05, "fps": 7.699917049938434}
{"step": 638296, "time": 85409.63857984543, "episode/length": 191.0, "episode/score": 12.307134329607834, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.20713391775370837}
{"step": 638600, "time": 85448.33331084251, "episode/length": 430.0, "episode/score": 11.51325390653983, "episode/reward_rate": 0.9953596287703016, "episode/intrinsic_return": 0.4132537104032963}
{"step": 638648, "time": 85455.72698307037, "episode/length": 221.0, "episode/score": 11.361346169901935, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.2613458957380317}
{"step": 638760, "time": 85471.0054473877, "episode/length": 238.0, "episode/score": 12.387292149593122, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.28729166090488434}
{"step": 639464, "time": 85559.86114406586, "episode/length": 164.0, "episode/score": 9.288516987124694, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.18851668507932118}
{"step": 639488, "time": 85564.2768881321, "episode/length": 252.0, "episode/score": 7.3745420090858715, "episode/reward_rate": 0.9960474308300395, "episode/intrinsic_return": 0.27454175055072483}
{"step": 639616, "time": 85581.44294929504, "episode/length": 176.0, "episode/score": 5.313886979405652, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.21388690038293134}
{"step": 639792, "time": 85604.40604376793, "episode/length": 186.0, "episode/score": 10.3126275714053, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.21262727678140436}
{"step": 639952, "time": 85625.59023976326, "episode/length": 60.0, "episode/score": 4.163678910901126, "episode/reward_rate": 0.9344262295081968, "episode/intrinsic_return": 0.06367879659001119}
{"step": 640016, "time": 85652.57565975189, "eval_episode/length": 107.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.9629629629629629}
{"step": 640016, "time": 85655.46012425423, "eval_episode/length": 139.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 640016, "time": 85658.57494974136, "eval_episode/length": 174.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9942857142857143}
{"step": 640016, "time": 85660.41783499718, "eval_episode/length": 181.0, "eval_episode/score": 13.099999986588955, "eval_episode/reward_rate": 0.9945054945054945}
{"step": 640016, "time": 85662.47302293777, "eval_episode/length": 190.0, "eval_episode/score": 11.100000023841858, "eval_episode/reward_rate": 0.9947643979057592}
{"step": 640016, "time": 85664.98521471024, "eval_episode/length": 214.0, "eval_episode/score": 12.100000008940697, "eval_episode/reward_rate": 0.9953488372093023}
{"step": 640016, "time": 85669.65159845352, "eval_episode/length": 285.0, "eval_episode/score": 13.099999986588955, "eval_episode/reward_rate": 0.9685314685314685}
{"step": 640016, "time": 85671.85726976395, "eval_episode/length": 190.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9685863874345549}
{"step": 640184, "time": 85692.475440979, "episode/length": 177.0, "episode/score": 11.291444647237313, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.19144436285068878}
{"step": 640352, "time": 85714.50949645042, "episode/length": 212.0, "episode/score": 11.341149925608988, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.2411495716569334}
{"step": 640816, "time": 85772.8377726078, "episode/length": 57.0, "episode/score": 6.1672022164129885, "episode/reward_rate": 0.9137931034482759, "episode/intrinsic_return": 0.06720211695937905}
{"step": 640960, "time": 85792.02157473564, "episode/length": 183.0, "episode/score": 10.304199262520342, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.20419897624924488}
{"step": 641184, "time": 85820.97148537636, "episode/length": 428.0, "episode/score": 12.550612828253634, "episode/reward_rate": 0.9953379953379954, "episode/intrinsic_return": 0.45061245667920957}
{"step": 641216, "time": 85826.35448741913, "episode/length": 49.0, "episode/score": 5.1608335403725505, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.060833332128822803}
{"step": 641496, "time": 85862.20185160637, "episode/length": 163.0, "episode/score": 9.27967812220436, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.17967782046457614}
{"step": 641776, "time": 85897.86614847183, "episode/length": 396.0, "episode/score": 10.483012793391481, "episode/reward_rate": 0.9924433249370277, "episode/intrinsic_return": 0.38301256362547065}
{"step": 641928, "time": 85917.86909389496, "episode/length": 246.0, "episode/score": 11.373170043334994, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.2731696400956025}
{"step": 642096, "time": 85939.87937116623, "episode/length": 113.0, "episode/score": 8.241250246879645, "episode/reward_rate": 0.956140350877193, "episode/intrinsic_return": 0.1412499969592318}
{"step": 642288, "time": 85964.83935260773, "episode/length": 44.0, "episode/score": 3.1442808900610544, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.04428075341274962}
{"step": 642408, "time": 85981.08002901077, "episode/length": 348.0, "episode/score": 11.468557585949156, "episode/reward_rate": 0.994269340974212, "episode/intrinsic_return": 0.36855725434884334}
{"step": 642768, "time": 86026.38793087006, "episode/length": 123.0, "episode/score": 11.229911484981812, "episode/reward_rate": 0.9919354838709677, "episode/intrinsic_return": 0.12991110930374816}
{"step": 642920, "time": 86047.02832174301, "episode/length": 212.0, "episode/score": 8.339648133368428, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.23964788025386952}
{"step": 643200, "time": 86082.8889760971, "episode/length": 425.0, "episode/score": 10.50508173447247, "episode/reward_rate": 0.8356807511737089, "episode/intrinsic_return": 0.4050814684285342}
{"step": 643272, "time": 86093.20469117165, "episode/length": 221.0, "episode/score": 8.350164306365514, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.2501640023847358}
{"step": 643344, "time": 86103.47645235062, "episode/length": 297.0, "episode/score": 8.449708406726131, "episode/reward_rate": 0.9765100671140939, "episode/intrinsic_return": 0.34970817918656394}
{"step": 643400, "time": 86111.79131817818, "episode/length": 162.0, "episode/score": 10.29172667446619, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.19172635201903176}
{"step": 644128, "time": 86202.1755104065, "episode/length": 214.0, "episode/score": 8.34568354620069, "episode/reward_rate": 0.9720930232558139, "episode/intrinsic_return": 0.24568337322352818}
{"step": 644656, "time": 86268.03155970573, "episode/length": 216.0, "episode/score": 10.350456085142241, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.25045576537263514}
{"step": 644752, "time": 86281.28891897202, "episode/length": 168.0, "episode/score": 11.287456339133769, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.18745600725696931}
{"step": 645064, "time": 86320.97670221329, "episode/length": 346.0, "episode/score": 8.493769153614721, "episode/reward_rate": 0.9942363112391931, "episode/intrinsic_return": 0.3937689279960068}
{"step": 645192, "time": 86337.95737075806, "episode/length": 302.0, "episode/score": 9.447911945392661, "episode/reward_rate": 0.9966996699669967, "episode/intrinsic_return": 0.34791165068145347}
