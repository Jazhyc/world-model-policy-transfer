{"step": 1560, "time": 178.00940656661987, "eval_episode/length": 93.0, "eval_episode/score": 0.7093750238418579, "eval_episode/reward_rate": 0.010638297872340425}
{"step": 1560, "time": 183.2742829322815, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 183.283940076828, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 183.29390215873718, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 183.30315256118774, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 183.31258296966553, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 183.32063746452332, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 183.33103466033936, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1561, "time": 303.28953862190247, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.87225341796875, "train/action_min": 0.0, "train/action_std": 2.0147409439086914, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00013791168748866767, "train/actor_opt_grad_steps": 1.0, "train/actor_opt_loss": -0.5766173005104065, "train/adv_mag": 0.0, "train/adv_max": 0.0, "train/adv_mean": 0.0, "train/adv_min": 0.0, "train/adv_std": 0.0, "train/cont_avg": 1.0, "train/cont_loss_mean": 0.9403895139694214, "train/cont_loss_std": 0.3367415964603424, "train/cont_neg_acc": NaN, "train/cont_neg_loss": NaN, "train/cont_pos_acc": 0.2421875, "train/cont_pos_loss": 0.9403895139694214, "train/cont_pred": 0.41158339381217957, "train/cont_rate": 1.0, "train/dyn_loss_mean": 9.792753219604492, "train/dyn_loss_std": 0.36431068181991577, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 2.944597005844116, "train/extr_critic_critic_opt_grad_steps": 1.0, "train/extr_critic_critic_opt_loss": 11965.8740234375, "train/extr_critic_mag": 0.0, "train/extr_critic_max": 0.0, "train/extr_critic_mean": 0.0, "train/extr_critic_min": 0.0, "train/extr_critic_std": 0.0, "train/extr_return_normed_mag": 0.0, "train/extr_return_normed_max": 0.0, "train/extr_return_normed_mean": 0.0, "train/extr_return_normed_min": 0.0, "train/extr_return_normed_std": 0.0, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.0, "train/extr_return_raw_max": 0.0, "train/extr_return_raw_mean": 0.0, "train/extr_return_raw_min": 0.0, "train/extr_return_raw_std": 0.0, "train/extr_reward_mag": 0.0, "train/extr_reward_max": 0.0, "train/extr_reward_mean": 0.0, "train/extr_reward_min": 0.0, "train/extr_reward_std": 0.0, "train/image_loss_mean": 5225.42626953125, "train/image_loss_std": 41.318153381347656, "train/model_loss_mean": 5237.78369140625, "train/model_loss_std": 41.331565856933594, "train/model_opt_grad_norm": NaN, "train/model_opt_grad_steps": 0.0, "train/model_opt_loss": 52377836.0, "train/model_opt_model_opt_grad_overflow": 1.0, "train/model_opt_model_opt_grad_scale": 5000.0, "train/policy_entropy_mag": 1.9401166439056396, "train/policy_entropy_max": 1.9401166439056396, "train/policy_entropy_mean": 1.7783297300338745, "train/policy_entropy_min": 1.0240278244018555, "train/policy_entropy_std": 0.09150445461273193, "train/policy_logprob_mag": 4.369824409484863, "train/policy_logprob_max": -0.3315334618091583, "train/policy_logprob_mean": -1.7853456735610962, "train/policy_logprob_min": -4.369824409484863, "train/policy_logprob_std": 0.5577027201652527, "train/policy_randomness_mag": 0.997022807598114, "train/policy_randomness_max": 0.997022807598114, "train/policy_randomness_mean": 0.9138807058334351, "train/policy_randomness_min": 0.5262462496757507, "train/policy_randomness_std": 0.047023989260196686, "train/post_ent_mag": 106.59553527832031, "train/post_ent_max": 106.59553527832031, "train/post_ent_mean": 106.26959228515625, "train/post_ent_min": 105.95700073242188, "train/post_ent_std": 0.1108068972826004, "train/prior_ent_mag": 106.47528076171875, "train/prior_ent_max": 106.47528076171875, "train/prior_ent_mean": 105.6922378540039, "train/prior_ent_min": 104.7059555053711, "train/prior_ent_std": 0.2766479551792145, "train/rep_loss_mean": 9.792753219604492, "train/rep_loss_std": 0.36431068181991577, "train/reward_avg": 0.0, "train/reward_loss_mean": 5.541262626647949, "train/reward_loss_std": 9.5367431640625e-07, "train/reward_max_data": 0.0, "train/reward_max_pred": 0.0, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 5.541262626647949, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0, "train/reward_rate": 0.0, "train/params_agent/wm/model_opt": 181559683.0, "train/params_agent/task_behavior/critic/critic_opt": 9708799.0, "train/params_agent/task_behavior/ac/actor_opt": 9454599.0, "report/cont_avg": 1.0, "report/cont_loss_mean": 0.9185498952865601, "report/cont_loss_std": 0.33563530445098877, "report/cont_neg_acc": NaN, "report/cont_neg_loss": NaN, "report/cont_pos_acc": 0.27734375, "report/cont_pos_loss": 0.9185498952865601, "report/cont_pred": 0.4205755591392517, "report/cont_rate": 1.0, "report/dyn_loss_mean": 9.849010467529297, "report/dyn_loss_std": 0.3398287892341614, "report/image_loss_mean": 5218.9453125, "report/image_loss_std": 41.26558303833008, "report/model_loss_mean": 5231.314453125, "report/model_loss_std": 41.243160247802734, "report/post_ent_mag": 106.53895568847656, "report/post_ent_max": 106.53895568847656, "report/post_ent_mean": 106.25239562988281, "report/post_ent_min": 105.90631103515625, "report/post_ent_std": 0.11825431883335114, "report/prior_ent_mag": 106.62886047363281, "report/prior_ent_max": 106.62886047363281, "report/prior_ent_mean": 105.63520812988281, "report/prior_ent_min": 104.83836364746094, "report/prior_ent_std": 0.2643789052963257, "report/rep_loss_mean": 9.849010467529297, "report/rep_loss_std": 0.3398287892341614, "report/reward_avg": 0.0, "report/reward_loss_mean": 5.541262626647949, "report/reward_loss_std": 9.5367431640625e-07, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.0, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 5.541262626647949, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.9320032596588135, "eval/cont_loss_std": 0.30467745661735535, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 0.2314453125, "eval/cont_pos_loss": 0.9320032596588135, "eval/cont_pred": 0.4116564393043518, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 9.845252990722656, "eval/dyn_loss_std": 0.3722545802593231, "eval/image_loss_mean": 5224.546875, "eval/image_loss_std": 41.242862701416016, "eval/model_loss_mean": 5236.927734375, "eval/model_loss_std": 41.210350036621094, "eval/post_ent_mag": 106.53988647460938, "eval/post_ent_max": 106.53988647460938, "eval/post_ent_mean": 106.25654602050781, "eval/post_ent_min": 105.77177429199219, "eval/post_ent_std": 0.11613649874925613, "eval/prior_ent_mag": 106.51078796386719, "eval/prior_ent_max": 106.51078796386719, "eval/prior_ent_mean": 105.65116882324219, "eval/prior_ent_min": 104.63737487792969, "eval/prior_ent_std": 0.2788970470428467, "eval/rep_loss_mean": 9.845252990722656, "eval/rep_loss_std": 0.3722545802593231, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 5.541262626647949, "eval/reward_loss_std": 9.5367431640625e-07, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 5.541262626647949, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0, "eval/reward_rate": 0.0, "replay/size": 1057.0, "replay/inserts": 1057.0, "replay/samples": 112.0, "replay/insert_wait_avg": 1.8193796206558213e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.557523999895369e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 3368.0, "eval_replay/inserts": 3368.0, "eval_replay/samples": 112.0, "eval_replay/insert_wait_avg": 1.6052196258037505e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0111502238682339e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 152.7148277759552, "timer/env.step_count": 196.0, "timer/env.step_total": 1.579742431640625, "timer/env.step_frac": 0.010344394546665978, "timer/env.step_avg": 0.008059910365513392, "timer/env.step_min": 0.0062940120697021484, "timer/env.step_max": 0.019226789474487305, "timer/replay._sample_count": 112.0, "timer/replay._sample_total": 0.10733842849731445, "timer/replay._sample_frac": 0.0007028684120627007, "timer/replay._sample_avg": 0.000958378825868879, "timer/replay._sample_min": 0.0005047321319580078, "timer/replay._sample_max": 0.0022475719451904297, "timer/agent.save_count": 1.0, "timer/agent.save_total": 2.6683878898620605, "timer/agent.save_frac": 0.017473011158921633, "timer/agent.save_avg": 2.6683878898620605, "timer/agent.save_min": 2.6683878898620605, "timer/agent.save_max": 2.6683878898620605, "timer/agent.policy_count": 290.0, "timer/agent.policy_total": 27.734663724899292, "timer/agent.policy_frac": 0.18161081100512552, "timer/agent.policy_avg": 0.09563677146516997, "timer/agent.policy_min": 0.010178327560424805, "timer/agent.policy_max": 21.42552876472473, "timer/dataset_train_count": 1.0, "timer/dataset_train_total": 4.220008850097656e-05, "timer/dataset_train_frac": 2.7633262018857427e-07, "timer/dataset_train_avg": 4.220008850097656e-05, "timer/dataset_train_min": 4.220008850097656e-05, "timer/dataset_train_max": 4.220008850097656e-05, "timer/agent.train_count": 1.0, "timer/agent.train_total": 93.50061845779419, "timer/agent.train_frac": 0.6122563199623748, "timer/agent.train_avg": 93.50061845779419, "timer/agent.train_min": 93.50061845779419, "timer/agent.train_max": 93.50061845779419, "timer/agent.report_count": 2.0, "timer/agent.report_total": 23.869209051132202, "timer/agent.report_frac": 0.15629922384583525, "timer/agent.report_avg": 11.934604525566101, "timer/agent.report_min": 0.25397324562072754, "timer/agent.report_max": 23.615235805511475, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.600120544433594e-05, "timer/dataset_eval_frac": 2.3574138784448994e-07, "timer/dataset_eval_avg": 3.600120544433594e-05, "timer/dataset_eval_min": 3.600120544433594e-05, "timer/dataset_eval_max": 3.600120544433594e-05}
{"step": 2312, "time": 326.1597878932953, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 2312, "time": 326.17556715011597, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 2312, "time": 326.1866524219513, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 2312, "time": 326.1965298652649, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 2312, "time": 326.2052597999573, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 2312, "time": 326.21413564682007, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 2312, "time": 326.22361516952515, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 2312, "time": 326.2334370613098, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 4624, "time": 397.43619775772095, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 4624, "time": 397.45556116104126, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 4624, "time": 397.46737480163574, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 4624, "time": 397.47849702835083, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 4624, "time": 397.4884421825409, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 4624, "time": 397.4991316795349, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 4624, "time": 397.5103282928467, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 4624, "time": 397.5224595069885, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 6368, "time": 450.89562797546387, "episode/length": 217.0, "episode/score": 0.3218750059604645, "episode/reward_rate": 0.0045871559633027525, "episode/intrinsic_return": 0.0}
{"step": 6936, "time": 468.0468096733093, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 6936, "time": 468.06060314178467, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 6936, "time": 468.0709502696991, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 6936, "time": 468.07945370674133, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 6936, "time": 468.08835911750793, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 6936, "time": 468.0970220565796, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 6936, "time": 468.10621333122253, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 8680, "time": 522.1808483600616, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 9248, "time": 539.763683795929, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 9248, "time": 539.7849185466766, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 9248, "time": 539.7943065166473, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 9248, "time": 539.8068628311157, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 9248, "time": 539.8176529407501, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 9248, "time": 539.8298652172089, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 9248, "time": 539.8419766426086, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 10088, "time": 568.2673666477203, "eval_episode/length": 147.0, "eval_episode/score": 0.5406249761581421, "eval_episode/reward_rate": 0.006756756756756757}
{"step": 10088, "time": 570.8926022052765, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 570.9026553630829, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 570.9125578403473, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 570.9201126098633, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 570.9307947158813, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 570.9397692680359, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 570.9494757652283, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10992, "time": 598.9152307510376, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 10992, "time": 598.9233613014221, "episode/length": 217.0, "episode/score": 0.3218750059604645, "episode/reward_rate": 0.0045871559633027525, "episode/intrinsic_return": 0.0}
{"step": 11560, "time": 616.1694326400757, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 11560, "time": 616.1817042827606, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 11560, "time": 616.1913907527924, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 11560, "time": 616.1991758346558, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 11560, "time": 616.2060549259186, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 11560, "time": 616.2142267227173, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 13304, "time": 669.4673516750336, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 13304, "time": 669.4751062393188, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 13872, "time": 686.9937446117401, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 13872, "time": 687.0108733177185, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 13872, "time": 687.0231273174286, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 13872, "time": 687.0347828865051, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 13872, "time": 687.0461983680725, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 13872, "time": 687.0580871105194, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 15616, "time": 740.4925172328949, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 15616, "time": 740.5013160705566, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 16184, "time": 757.6047699451447, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 16184, "time": 757.6260657310486, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 16184, "time": 757.6411600112915, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 16184, "time": 757.653434753418, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 16184, "time": 757.6661643981934, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 16184, "time": 757.6776928901672, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 17928, "time": 811.6825408935547, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 17928, "time": 811.6925420761108, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 18496, "time": 829.4406268596649, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 18496, "time": 829.4569215774536, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 18496, "time": 829.4660449028015, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 18496, "time": 829.4775061607361, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 18496, "time": 829.4889228343964, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 18496, "time": 829.5003678798676, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 20072, "time": 883.7157065868378, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 883.7242152690887, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 883.7335138320923, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 883.7437074184418, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 883.7534077167511, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 883.7628426551819, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 883.7705585956573, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 883.7793045043945, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20240, "time": 889.155476808548, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 20240, "time": 889.1650614738464, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 20808, "time": 906.2947790622711, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 20808, "time": 906.3158662319183, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 20808, "time": 906.3283581733704, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 20808, "time": 906.3398513793945, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 20808, "time": 906.35293841362, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 20808, "time": 906.3655819892883, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 22552, "time": 959.8620483875275, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 22552, "time": 959.8702490329742, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 23120, "time": 977.5390923023224, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 23120, "time": 977.5579957962036, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 23120, "time": 977.5697536468506, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 23120, "time": 977.5791418552399, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 23120, "time": 977.5880517959595, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 23120, "time": 977.5968241691589, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 24864, "time": 1031.708372592926, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 24864, "time": 1031.7163090705872, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 25432, "time": 1048.9737272262573, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 25432, "time": 1048.9860754013062, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 25432, "time": 1048.9951224327087, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 25432, "time": 1049.0033111572266, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 25432, "time": 1049.0116147994995, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 25432, "time": 1049.0218257904053, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 27176, "time": 1102.5809271335602, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 27176, "time": 1102.5885326862335, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 27744, "time": 1120.1625134944916, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 27744, "time": 1120.1745433807373, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 27744, "time": 1120.1849756240845, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 27744, "time": 1120.1932094097137, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 27744, "time": 1120.201807975769, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 27744, "time": 1120.2108697891235, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 29488, "time": 1173.8721351623535, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 29488, "time": 1173.8792474269867, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 30056, "time": 1191.1664283275604, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 30056, "time": 1191.1814315319061, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 30056, "time": 1191.1930484771729, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 30056, "time": 1191.2023808956146, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 30056, "time": 1191.210913181305, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 30056, "time": 1191.2203996181488, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 30056, "time": 1196.6337888240814, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1196.6429290771484, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1196.6511421203613, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1196.659265756607, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1196.668140888214, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1196.677150964737, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1196.6873104572296, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1196.6957468986511, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 31800, "time": 1250.4225478172302, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 31800, "time": 1250.4312081336975, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 32232, "time": 1263.5997722148895, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 32368, "time": 1267.9608471393585, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 32368, "time": 1267.9704945087433, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 32368, "time": 1267.9796996116638, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 32368, "time": 1267.990885734558, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 32368, "time": 1268.0027494430542, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 32368, "time": 1268.0136983394623, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 32737, "time": 1279.9489619731903, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.9994985049532863, "train/action_min": 0.0, "train/action_std": 1.9992457511498756, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 7.895074872742287e-05, "train/actor_opt_grad_steps": 975.0, "train/actor_opt_loss": -3.7865363282641185, "train/adv_mag": 0.00016478723783197705, "train/adv_max": 0.00016473713978924103, "train/adv_mean": 9.832420361572442e-05, "train/adv_min": 1.4551942156764508e-05, "train/adv_std": 4.567175552850487e-05, "train/cont_avg": 0.9968639255798969, "train/cont_loss_mean": 0.02590554768725499, "train/cont_loss_std": 0.30592217575991615, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.792554368086852, "train/cont_pos_acc": 0.9962799880922455, "train/cont_pos_loss": 0.0077857277919986595, "train/cont_pred": 0.9939493770451889, "train/cont_rate": 0.9968639255798969, "train/dyn_loss_mean": 1.0590195698836415, "train/dyn_loss_std": 0.004791020810000998, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 4.3883543688151025, "train/extr_critic_critic_opt_grad_steps": 975.0, "train/extr_critic_critic_opt_loss": 5289.868359752537, "train/extr_critic_mag": 0.0004186667117875876, "train/extr_critic_max": 0.0004186617959405958, "train/extr_critic_mean": 0.00041736823808508744, "train/extr_critic_min": 0.00041641525386535013, "train/extr_critic_std": 2.193105889206042e-07, "train/extr_return_normed_mag": 0.00021290481765004905, "train/extr_return_normed_max": 0.00021289412283245882, "train/extr_return_normed_mean": 0.00014697398341871113, "train/extr_return_normed_min": 6.35801663852905e-05, "train/extr_return_normed_std": 4.566318699859836e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.0005816300651531711, "train/extr_return_raw_max": 0.000581612718545122, "train/extr_return_raw_mean": 0.000515692592469571, "train/extr_return_raw_min": 0.0004322987621732294, "train/extr_return_raw_std": 4.566318697165274e-05, "train/extr_reward_mag": 1.6838004908610865e-05, "train/extr_reward_max": 1.683554698511497e-05, "train/extr_reward_mean": 1.67932616290418e-05, "train/extr_reward_min": 1.66886860562354e-05, "train/extr_reward_std": 2.0131007236905784e-08, "train/image_loss_mean": 28.027419893243877, "train/image_loss_std": 0.3785891588969329, "train/model_loss_mean": 28.796553996113158, "train/model_loss_std": 0.6332624261603528, "train/model_opt_grad_norm": 101.42592113870413, "train/model_opt_grad_steps": 965.0, "train/model_opt_loss": 549.08012792253, "train/model_opt_model_opt_grad_overflow": 0.005154639175257732, "train/model_opt_model_opt_grad_scale": 14.447084407216495, "train/policy_entropy_mag": 1.945812844124037, "train/policy_entropy_max": 1.945812844124037, "train/policy_entropy_mean": 1.9417284002009125, "train/policy_entropy_min": 1.8847310082199646, "train/policy_entropy_std": 0.0026929151073587848, "train/policy_logprob_mag": 2.401680124174688, "train/policy_logprob_max": -1.5350998414238703, "train/policy_logprob_mean": -1.941739349021125, "train/policy_logprob_min": -2.401680124174688, "train/policy_logprob_std": 0.08070817130819424, "train/policy_randomness_mag": 0.9999500556090444, "train/policy_randomness_max": 0.9999500556090444, "train/policy_randomness_mean": 0.9978510675971041, "train/policy_randomness_min": 0.968560197611445, "train/policy_randomness_std": 0.0013838846694927702, "train/post_ent_mag": 81.56257019829505, "train/post_ent_max": 81.56257019829505, "train/post_ent_mean": 81.42663888832958, "train/post_ent_min": 81.38357205735039, "train/post_ent_std": 0.02529283926927859, "train/prior_ent_mag": 87.31127709457554, "train/prior_ent_max": 87.31127709457554, "train/prior_ent_mean": 87.19030258336018, "train/prior_ent_min": 86.95771616512967, "train/prior_ent_std": 0.054287402698597345, "train/rep_loss_mean": 1.0590195698836415, "train/rep_loss_std": 0.004791020810000998, "train/reward_avg": 2.7544474374435687e-05, "train/reward_loss_mean": 0.10781498882708322, "train/reward_loss_std": 0.02637716437020828, "train/reward_max_data": 0.02654639224416202, "train/reward_max_pred": 1.684292075560265e-05, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.10696300099794057, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 9.970017492771149, "train/reward_pred": 1.678000787541885e-05, "train/reward_rate": 8.557506443298968e-05, "train_stats/mean_log_entropy": 1.9308787742547229, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.014293269254267216, "report/cont_loss_std": 0.25843876600265503, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.856381416320801, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0028606129344552755, "report/cont_pred": 0.9971432685852051, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.2654404938220978, "report/image_loss_std": 0.09269342571496964, "report/model_loss_mean": 0.8802067041397095, "report/model_loss_std": 0.2725297808647156, "report/post_ent_mag": 70.18083190917969, "report/post_ent_max": 70.18083190917969, "report/post_ent_mean": 69.90617370605469, "report/post_ent_min": 69.87824249267578, "report/post_ent_std": 0.042530860751867294, "report/prior_ent_mag": 77.3603286743164, "report/prior_ent_max": 77.3603286743164, "report/prior_ent_mean": 77.11318969726562, "report/prior_ent_min": 77.05119323730469, "report/prior_ent_std": 0.05205109715461731, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.0004729791544377804, "report/reward_loss_std": 9.325499945589399e-07, "report/reward_max_data": 0.0, "report/reward_max_pred": 1.7523765563964844e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0004729791544377804, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 1.751701347529888e-05, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.0028605794068425894, "eval/cont_loss_std": 2.2668368728773203e-06, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0028605794068425894, "eval/cont_pred": 0.9971433281898499, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.26259124279022217, "eval/image_loss_std": 0.10291493684053421, "eval/model_loss_mean": 0.8659248352050781, "eval/model_loss_std": 0.10291508585214615, "eval/post_ent_mag": 70.17919158935547, "eval/post_ent_max": 70.17919158935547, "eval/post_ent_mean": 69.90443420410156, "eval/post_ent_min": 69.88008117675781, "eval/post_ent_std": 0.03992866352200508, "eval/prior_ent_mag": 77.3603286743164, "eval/prior_ent_max": 77.3603286743164, "eval/prior_ent_mean": 77.11034393310547, "eval/prior_ent_min": 77.05049133300781, "eval/prior_ent_std": 0.04971585050225258, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00047300709411501884, "eval/reward_loss_std": 9.615505405236036e-07, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 1.7523765563964844e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00047300709411501884, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 1.751701347529888e-05, "eval/reward_rate": 0.0, "replay/size": 32233.0, "replay/inserts": 31176.0, "replay/samples": 31168.0, "replay/insert_wait_avg": 1.276483100164784e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.538258271540459e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 10304.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.126919650701503e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0579824447631836e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 976.6469035148621, "timer/env.step_count": 3897.0, "timer/env.step_total": 38.50451183319092, "timer/env.step_frac": 0.039425212627631066, "timer/env.step_avg": 0.009880552176851659, "timer/env.step_min": 0.00832366943359375, "timer/env.step_max": 0.0572354793548584, "timer/replay._sample_count": 31168.0, "timer/replay._sample_total": 16.41907501220703, "timer/replay._sample_frac": 0.016811679792478013, "timer/replay._sample_avg": 0.0005267927044470942, "timer/replay._sample_min": 0.0003440380096435547, "timer/replay._sample_max": 0.011312007904052734, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4764.0, "timer/agent.policy_total": 51.18627381324768, "timer/agent.policy_frac": 0.05241021461188584, "timer/agent.policy_avg": 0.010744389969195568, "timer/agent.policy_min": 0.009175539016723633, "timer/agent.policy_max": 0.0921328067779541, "timer/dataset_train_count": 1948.0, "timer/dataset_train_total": 0.21021699905395508, "timer/dataset_train_frac": 0.00021524360369894535, "timer/dataset_train_avg": 0.00010791427056157858, "timer/dataset_train_min": 8.535385131835938e-05, "timer/dataset_train_max": 0.001088857650756836, "timer/agent.train_count": 1948.0, "timer/agent.train_total": 872.607435464859, "timer/agent.train_frac": 0.8934727917780985, "timer/agent.train_avg": 0.44795042888339787, "timer/agent.train_min": 0.4359169006347656, "timer/agent.train_max": 0.6956901550292969, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.49103212356567383, "timer/agent.report_frac": 0.0005027734402254228, "timer/agent.report_avg": 0.24551606178283691, "timer/agent.report_min": 0.23743605613708496, "timer/agent.report_max": 0.25359606742858887, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 8.654594421386719e-05, "timer/dataset_eval_frac": 8.861538791798379e-08, "timer/dataset_eval_avg": 8.654594421386719e-05, "timer/dataset_eval_min": 8.654594421386719e-05, "timer/dataset_eval_max": 8.654594421386719e-05, "fps": 31.92101148062682}
{"step": 34112, "time": 1323.1827793121338, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 34544, "time": 1336.5285811424255, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 34680, "time": 1340.4987788200378, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 34680, "time": 1340.5082919597626, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 34680, "time": 1340.5194582939148, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 34680, "time": 1340.530201435089, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 34680, "time": 1340.5407881736755, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 34680, "time": 1340.55087184906, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 36424, "time": 1394.1138787269592, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 36856, "time": 1407.2985181808472, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 36992, "time": 1411.6667845249176, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 36992, "time": 1411.6744339466095, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 36992, "time": 1411.6833937168121, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 36992, "time": 1411.6927137374878, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 36992, "time": 1411.7050242424011, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 36992, "time": 1411.7171039581299, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 38736, "time": 1465.110425710678, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 39168, "time": 1478.2001752853394, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 39304, "time": 1482.1918976306915, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 39304, "time": 1482.2010924816132, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 39304, "time": 1482.2120325565338, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 39304, "time": 1482.2214744091034, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 39304, "time": 1482.231377363205, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 39304, "time": 1482.2426042556763, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 39736, "time": 1495.3655729293823, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 40040, "time": 1509.8951680660248, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1509.9038951396942, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1509.913554906845, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1509.9243576526642, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1509.9307091236115, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1509.9376430511475, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1509.944988489151, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1509.954222202301, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 41048, "time": 1541.7027614116669, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 41480, "time": 1554.839789390564, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 41616, "time": 1559.1873679161072, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 41616, "time": 1559.1965794563293, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 41616, "time": 1559.2066566944122, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 41616, "time": 1559.2168719768524, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 41616, "time": 1559.2244536876678, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 42048, "time": 1572.5289611816406, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 43360, "time": 1612.5447988510132, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 43792, "time": 1625.6525495052338, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 43928, "time": 1629.5479228496552, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 43928, "time": 1629.5553076267242, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 43928, "time": 1629.56125497818, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 43928, "time": 1629.5684533119202, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 43928, "time": 1629.5751185417175, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 44360, "time": 1642.8149707317352, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 45672, "time": 1682.8357586860657, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 46104, "time": 1696.0264670848846, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 46240, "time": 1700.3824045658112, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 46240, "time": 1700.3899247646332, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 46240, "time": 1700.3997476100922, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 46240, "time": 1700.4095718860626, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 46240, "time": 1700.419130563736, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 46672, "time": 1713.548084974289, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 47984, "time": 1753.631203174591, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 48416, "time": 1766.6987798213959, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 48552, "time": 1770.6044385433197, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 48552, "time": 1770.6145539283752, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 48552, "time": 1770.6260452270508, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 48552, "time": 1770.6397070884705, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 48552, "time": 1770.6535139083862, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 48984, "time": 1783.8298878669739, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 50024, "time": 1821.0906474590302, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1821.106386423111, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1821.115862607956, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1821.1252536773682, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1821.1348571777344, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1821.1446521282196, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1821.1539018154144, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1821.1606085300446, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50296, "time": 1829.4369537830353, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 50312, "time": 1829.9240744113922, "episode/length": 219.0, "episode/score": 0.31562501192092896, "episode/reward_rate": 0.004545454545454545, "episode/intrinsic_return": 0.0}
{"step": 50728, "time": 1842.8407649993896, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 50864, "time": 1847.240422487259, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 50864, "time": 1847.2502174377441, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 50864, "time": 1847.2600405216217, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 50864, "time": 1847.2707891464233, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 51296, "time": 1860.378497838974, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 52608, "time": 1900.4662585258484, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 52624, "time": 1901.0497798919678, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 53040, "time": 1913.64821267128, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 53176, "time": 1917.5856745243073, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 53176, "time": 1917.5956404209137, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 53176, "time": 1917.6047983169556, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 53176, "time": 1917.6161057949066, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 53352, "time": 1923.032445192337, "episode/length": 21.0, "episode/score": 0.934374988079071, "episode/reward_rate": 0.045454545454545456, "episode/intrinsic_return": 0.0}
{"step": 53608, "time": 1931.045226573944, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 54920, "time": 1971.0757675170898, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 54936, "time": 1971.5701792240143, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 55352, "time": 1984.2509596347809, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 55488, "time": 1988.635202884674, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 55488, "time": 1988.6440987586975, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 55488, "time": 1988.653476715088, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 55664, "time": 1994.1456923484802, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 55920, "time": 2001.939035654068, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 57232, "time": 2042.2046647071838, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 57248, "time": 2042.6986093521118, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 57664, "time": 2055.9406950473785, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 57800, "time": 2059.8784403800964, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 57800, "time": 2059.8858358860016, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 57800, "time": 2059.8936684131622, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 57976, "time": 2065.2395219802856, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 58232, "time": 2072.9831438064575, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 59544, "time": 2113.0026242733, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 59560, "time": 2113.497166156769, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 59976, "time": 2126.1957354545593, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 60008, "time": 2131.2713272571564, "eval_episode/length": 186.0, "eval_episode/score": 0.41874998807907104, "eval_episode/reward_rate": 0.0053475935828877}
{"step": 60008, "time": 2133.1758563518524, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2133.1848759651184, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2133.195588350296, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2133.2024052143097, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2133.2099463939667, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2133.2158632278442, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2133.222565174103, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60112, "time": 2136.6432564258575, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 60112, "time": 2136.652551174164, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 60112, "time": 2136.662750005722, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 60288, "time": 2142.2249262332916, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 60544, "time": 2150.1150193214417, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 61856, "time": 2190.144325733185, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 61872, "time": 2190.653175830841, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 62288, "time": 2203.3501160144806, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 62424, "time": 2207.2496984004974, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 62424, "time": 2207.257654428482, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 62424, "time": 2207.267797231674, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 62600, "time": 2212.616003036499, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 62856, "time": 2220.4192967414856, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 64168, "time": 2260.297219514847, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 64184, "time": 2260.8358883857727, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 64600, "time": 2273.467721939087, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 64736, "time": 2277.759355068207, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 64736, "time": 2277.7673411369324, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 64736, "time": 2277.777349472046, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 64793, "time": 2280.2605855464935, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.0014763827347637, "train/action_min": 0.0, "train/action_std": 2.0007435225728734, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 6.428044790522814e-05, "train/actor_opt_grad_steps": 2950.0, "train/actor_opt_loss": -3.0478560384299227, "train/adv_mag": 0.00024177918711037777, "train/adv_max": 0.00024177918711037777, "train/adv_mean": 0.0001385403002901304, "train/adv_min": 1.147780880165189e-05, "train/adv_std": 6.448257362766282e-05, "train/cont_avg": 0.9964484219527363, "train/cont_loss_mean": 0.023673408961303495, "train/cont_loss_std": 0.32732540810070193, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.687641711690318, "train/cont_pos_acc": 0.9999999860625955, "train/cont_pos_loss": 0.003460695215301653, "train/cont_pred": 0.9965455220706427, "train/cont_rate": 0.9964484219527363, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.08258786719681611, "train/extr_critic_critic_opt_grad_steps": 2950.0, "train/extr_critic_critic_opt_loss": 2218.582474589941, "train/extr_critic_mag": 0.0038390533247990395, "train/extr_critic_max": 0.0038390533247990395, "train/extr_critic_mean": 0.0038293786422205875, "train/extr_critic_min": 0.0038189573667535733, "train/extr_critic_std": 2.5599095375125685e-06, "train/extr_return_normed_mag": 0.0004641740526123649, "train/extr_return_normed_max": 0.0004641740526123649, "train/extr_return_normed_mean": 0.00036837772911632274, "train/extr_return_normed_min": 0.00024552244359432764, "train/extr_return_normed_std": 6.435634664984406e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.004063716182596425, "train/extr_return_raw_max": 0.004063716182596425, "train/extr_return_raw_mean": 0.003967920041976691, "train/extr_return_raw_min": 0.0038450645735783884, "train/extr_return_raw_std": 6.435634655029738e-05, "train/extr_reward_mag": 3.345332928557894e-05, "train/extr_reward_max": 3.345332928557894e-05, "train/extr_reward_mean": 3.3390825388887064e-05, "train/extr_reward_min": 3.3232110056711076e-05, "train/extr_reward_std": 3.009137778312449e-08, "train/image_loss_mean": 0.27381343472359787, "train/image_loss_std": 0.08453738589340182, "train/model_loss_mean": 0.8986878531489206, "train/model_loss_std": 0.36013731115789555, "train/model_opt_grad_norm": 80.51129941797969, "train/model_opt_grad_steps": 2940.0, "train/model_opt_loss": 50.80673404712582, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 56.650342039801, "train/policy_entropy_mag": 1.9458882784962062, "train/policy_entropy_max": 1.9458882784962062, "train/policy_entropy_mean": 1.9448070881971673, "train/policy_entropy_min": 1.9269747651038478, "train/policy_entropy_std": 0.0007661633686954851, "train/policy_logprob_mag": 2.207484664015509, "train/policy_logprob_max": -1.6944597390160632, "train/policy_logprob_mean": -1.9448333041584906, "train/policy_logprob_min": -2.207484664015509, "train/policy_logprob_std": 0.04675064562120248, "train/policy_randomness_mag": 0.999988820422348, "train/policy_randomness_max": 0.999988820422348, "train/policy_randomness_mean": 0.9994331936338055, "train/policy_randomness_min": 0.9902691956776292, "train/policy_randomness_std": 0.00039373012447836274, "train/post_ent_mag": 61.72135879744345, "train/post_ent_max": 61.72135879744345, "train/post_ent_mean": 61.328592746411985, "train/post_ent_min": 61.295551679620694, "train/post_ent_std": 0.06351640796409318, "train/prior_ent_mag": 67.60623163251735, "train/prior_ent_max": 67.60623163251735, "train/prior_ent_mean": 67.39808622521548, "train/prior_ent_min": 67.24247578483316, "train/prior_ent_std": 0.05873600362026276, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 4.6550694433740566e-05, "train/reward_loss_mean": 0.0012009857495811152, "train/reward_loss_std": 0.02910434015610491, "train/reward_max_data": 0.04606654305956257, "train/reward_max_pred": 3.351204430879052e-05, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.0002608777741891151, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 10.759585436652689, "train/reward_pred": 3.341486647410031e-05, "train/reward_rate": 8.745335820895522e-05, "train_stats/mean_log_entropy": 1.937095352581569, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.020056473091244698, "report/cont_loss_std": 0.3061269223690033, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.667525291442871, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.003462542314082384, "report/cont_pred": 0.9965435862541199, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.25818806886672974, "report/image_loss_std": 0.08337552100419998, "report/model_loss_mean": 0.8784055709838867, "report/model_loss_std": 0.3249555826187134, "report/post_ent_mag": 53.48029708862305, "report/post_ent_max": 53.48029708862305, "report/post_ent_mean": 53.123924255371094, "report/post_ent_min": 53.09635543823242, "report/post_ent_std": 0.054537441581487656, "report/prior_ent_mag": 62.653587341308594, "report/prior_ent_max": 62.653587341308594, "report/prior_ent_mean": 62.36073303222656, "report/prior_ent_min": 62.303375244140625, "report/prior_ent_std": 0.06051049754023552, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.00016100844368338585, "report/reward_loss_std": 2.260136824361325e-07, "report/reward_max_data": 0.0, "report/reward_max_pred": 3.695487976074219e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00016100844368338585, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 3.6849407479166985e-05, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.0034624759573489428, "eval/cont_loss_std": 1.0324779395887163e-06, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0034624759573489428, "eval/cont_pred": 0.9965436458587646, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2556360363960266, "eval/image_loss_std": 0.09229172766208649, "eval/model_loss_mean": 0.8592594861984253, "eval/model_loss_std": 0.09229182451963425, "eval/post_ent_mag": 53.479061126708984, "eval/post_ent_max": 53.479061126708984, "eval/post_ent_mean": 53.122047424316406, "eval/post_ent_min": 53.093788146972656, "eval/post_ent_std": 0.05036625638604164, "eval/prior_ent_mag": 62.653587341308594, "eval/prior_ent_max": 62.653587341308594, "eval/prior_ent_mean": 62.35755920410156, "eval/prior_ent_min": 62.29962158203125, "eval/prior_ent_std": 0.05406752601265907, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00016102660447359085, "eval/reward_loss_std": 2.190786574374215e-07, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 3.695487976074219e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00016102660447359085, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 3.684742841869593e-05, "eval/reward_rate": 0.0, "replay/size": 64289.0, "replay/inserts": 32056.0, "replay/samples": 32064.0, "replay/insert_wait_avg": 1.2620952559552766e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.116253810014554e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 17240.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1087701394896194e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.685754776000977e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2963349819183, "timer/env.step_count": 4007.0, "timer/env.step_total": 39.151121616363525, "timer/env.step_frac": 0.03913952320646184, "timer/env.step_avg": 0.009770681711096463, "timer/env.step_min": 0.007891654968261719, "timer/env.step_max": 0.0365293025970459, "timer/replay._sample_count": 32064.0, "timer/replay._sample_total": 16.91368007659912, "timer/replay._sample_frac": 0.016908669446344476, "timer/replay._sample_avg": 0.0005274975073789646, "timer/replay._sample_min": 0.0003819465637207031, "timer/replay._sample_max": 0.025612592697143555, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4874.0, "timer/agent.policy_total": 51.29530644416809, "timer/agent.policy_frac": 0.051280110353593686, "timer/agent.policy_avg": 0.010524272967617581, "timer/agent.policy_min": 0.008588075637817383, "timer/agent.policy_max": 0.08593869209289551, "timer/dataset_train_count": 2004.0, "timer/dataset_train_total": 0.21594643592834473, "timer/dataset_train_frac": 0.00021588246240275213, "timer/dataset_train_avg": 0.00010775770255905426, "timer/dataset_train_min": 9.131431579589844e-05, "timer/dataset_train_max": 0.0004374980926513672, "timer/agent.train_count": 2004.0, "timer/agent.train_total": 895.995447397232, "timer/agent.train_frac": 0.8957300112605414, "timer/agent.train_avg": 0.44710351666528547, "timer/agent.train_min": 0.4345550537109375, "timer/agent.train_max": 0.8435463905334473, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48208141326904297, "timer/agent.report_frac": 0.00048193859800331793, "timer/agent.report_avg": 0.24104070663452148, "timer/agent.report_min": 0.23355698585510254, "timer/agent.report_max": 0.24852442741394043, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 7.414817810058594e-05, "timer/dataset_eval_frac": 7.412621191091964e-08, "timer/dataset_eval_avg": 7.414817810058594e-05, "timer/dataset_eval_min": 7.414817810058594e-05, "timer/dataset_eval_max": 7.414817810058594e-05, "fps": 32.04600467860301}
{"step": 64912, "time": 2283.8829538822174, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 65168, "time": 2291.747653245926, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
