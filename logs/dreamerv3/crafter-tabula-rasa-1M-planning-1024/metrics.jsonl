{"step": 688, "time": 113.77617335319519, "episode/length": 85.0, "episode/score": 2.1879678903133026, "episode/reward_rate": 0.9534883720930233, "episode/intrinsic_return": 0.08796782363060629}
{"step": 1024, "time": 117.45444059371948, "episode/length": 127.0, "episode/score": 0.22829660004026664, "episode/reward_rate": 0.9609375, "episode/intrinsic_return": 0.12829659179806185}
{"step": 1160, "time": 119.69430327415466, "episode/length": 144.0, "episode/score": 2.241707389404837, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.14170726707561698}
{"step": 1176, "time": 121.0845775604248, "episode/length": 146.0, "episode/score": 0.21897126578187454, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.1189712007289927}
{"step": 1200, "time": 122.50305604934692, "episode/length": 149.0, "episode/score": 0.2345765910231421, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.13457657183789706}
{"step": 1464, "time": 125.71896886825562, "episode/length": 182.0, "episode/score": 1.2496918731667392, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.1496918362863653}
{"step": 1504, "time": 127.37976098060608, "episode/length": 187.0, "episode/score": 0.29438921915243554, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.19438915642786014}
{"step": 1560, "time": 143.7451868057251, "eval_episode/length": 145.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9931506849315068}
{"step": 1560, "time": 145.16566467285156, "eval_episode/length": 148.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9664429530201343}
{"step": 1560, "time": 146.66454553604126, "eval_episode/length": 152.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9934640522875817}
{"step": 1560, "time": 148.51603031158447, "eval_episode/length": 174.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 1560, "time": 150.0323235988617, "eval_episode/length": 180.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9779005524861878}
{"step": 1560, "time": 151.71889114379883, "train_stats/sum_log_reward": 0.8142857040677752, "train_stats/max_log_achievement_collect_sapling": 0.42857142857142855, "train_stats/max_log_achievement_place_plant": 0.2857142857142857, "train_stats/max_log_achievement_wake_up": 1.4285714285714286, "train_stats/max_log_achievement_collect_drink": 0.6666666666666666, "eval_stats/sum_log_reward": 1.299999937415123, "eval_stats/max_log_achievement_collect_drink": 0.0, "eval_stats/max_log_achievement_collect_sapling": 0.6, "eval_stats/max_log_achievement_place_plant": 0.6, "eval_stats/max_log_achievement_wake_up": 2.0}
{"step": 1560, "time": 188.0672698020935, "eval_episode/length": 34.0, "eval_episode/score": -0.9000000283122063, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 1560, "time": 195.14083170890808, "eval_episode/length": 151.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.993421052631579}
{"step": 1560, "time": 196.96944189071655, "eval_episode/length": 152.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9934640522875817}
{"step": 1560, "time": 198.68846225738525, "eval_episode/length": 156.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9936305732484076}
{"step": 1560, "time": 200.48294734954834, "eval_episode/length": 161.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9938271604938271}
{"step": 1560, "time": 202.22529244422913, "eval_episode/length": 164.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9696969696969697}
{"step": 1560, "time": 206.54885077476501, "eval_episode/length": 226.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9779735682819384}
{"step": 1560, "time": 208.18739485740662, "eval_episode/length": 192.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9948186528497409}
{"step": 1561, "time": 335.4320261478424, "eval_stats/sum_log_reward": 2.599999912083149, "eval_stats/max_log_achievement_collect_drink": 4.125, "eval_stats/max_log_achievement_collect_sapling": 0.875, "eval_stats/max_log_achievement_place_plant": 0.625, "eval_stats/max_log_achievement_wake_up": 1.875, "eval_stats/max_log_achievement_collect_wood": 1.1428571428571428, "eval_stats/max_log_achievement_place_table": 0.2857142857142857, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 7.336181640625, "train/action_min": 0.0, "train/action_std": 4.849708557128906, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00031206963467411697, "train/actor_opt_grad_steps": 1.0, "train/actor_opt_loss": -2.08318829536438, "train/adv_mag": 0.0, "train/adv_max": 0.0, "train/adv_mean": 0.0, "train/adv_min": 0.0, "train/adv_std": 0.0, "train/cont_avg": 0.9921875, "train/cont_loss_mean": 0.6689414978027344, "train/cont_loss_std": 0.2890952527523041, "train/cont_neg_acc": 0.375, "train/cont_neg_loss": 0.7757543325424194, "train/cont_pos_acc": 0.5925197005271912, "train/cont_pos_loss": 0.6681004166603088, "train/cont_pred": 0.5331352353096008, "train/cont_rate": 0.9921875, "train/dyn_loss_mean": 10.854202270507812, "train/dyn_loss_std": 0.48769065737724304, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 7.249999523162842, "train/extr_critic_critic_opt_grad_steps": 1.0, "train/extr_critic_critic_opt_loss": 29892.517578125, "train/extr_critic_mag": 0.0, "train/extr_critic_max": 0.0, "train/extr_critic_mean": 0.0, "train/extr_critic_min": 0.0, "train/extr_critic_std": 0.0, "train/extr_return_normed_mag": 0.0, "train/extr_return_normed_max": 0.0, "train/extr_return_normed_mean": 0.0, "train/extr_return_normed_min": 0.0, "train/extr_return_normed_std": 0.0, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.0, "train/extr_return_raw_max": 0.0, "train/extr_return_raw_mean": 0.0, "train/extr_return_raw_min": 0.0, "train/extr_return_raw_std": 0.0, "train/extr_reward_mag": 0.0, "train/extr_reward_max": 0.0, "train/extr_reward_mean": 0.0, "train/extr_reward_min": 0.0, "train/extr_reward_std": 0.0, "train/image_loss_mean": 3713.924072265625, "train/image_loss_std": 158.46490478515625, "train/model_loss_mean": 3726.646728515625, "train/model_loss_std": 158.40673828125, "train/model_opt_grad_norm": NaN, "train/model_opt_grad_steps": 0.0, "train/model_opt_loss": 37266468.0, "train/model_opt_model_opt_grad_overflow": 1.0, "train/model_opt_model_opt_grad_scale": 5000.0, "train/policy_entropy_mag": 2.7660982608795166, "train/policy_entropy_max": 2.7660982608795166, "train/policy_entropy_mean": 2.5736894607543945, "train/policy_entropy_min": 1.9398810863494873, "train/policy_entropy_std": 0.08389019221067429, "train/policy_logprob_mag": 5.499567031860352, "train/policy_logprob_max": -0.6370119452476501, "train/policy_logprob_mean": -2.5740957260131836, "train/policy_logprob_min": -5.499567031860352, "train/policy_logprob_std": 0.6748619079589844, "train/policy_randomness_mag": 0.9763113260269165, "train/policy_randomness_max": 0.9763113260269165, "train/policy_randomness_mean": 0.9083995223045349, "train/policy_randomness_min": 0.684692919254303, "train/policy_randomness_std": 0.02960955537855625, "train/post_ent_mag": 106.15617370605469, "train/post_ent_max": 106.15617370605469, "train/post_ent_mean": 105.65431213378906, "train/post_ent_min": 104.98454284667969, "train/post_ent_std": 0.20890861749649048, "train/prior_ent_mag": 106.34642028808594, "train/prior_ent_max": 106.34642028808594, "train/prior_ent_mean": 105.51731872558594, "train/prior_ent_min": 104.46488189697266, "train/prior_ent_std": 0.2916885018348694, "train/rep_loss_mean": 10.854202270507812, "train/rep_loss_std": 0.48769065737724304, "train/reward_avg": 0.006501795258373022, "train/reward_loss_mean": 5.541262626647949, "train/reward_loss_std": 9.804239198274445e-07, "train/reward_max_data": 1.0012500286102295, "train/reward_max_pred": 0.0, "train/reward_neg_acc": 0.9999999403953552, "train/reward_neg_loss": 5.541262626647949, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 5.541263580322266, "train/reward_pred": 0.0, "train/reward_rate": 0.0126953125, "train/params_agent/wm/model_opt": 181569923.0, "train/params_agent/task_behavior/critic/critic_opt": 9708799.0, "train/params_agent/task_behavior/ac/actor_opt": 9464849.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 0.7018011212348938, "report/cont_loss_std": 0.3191901743412018, "report/cont_neg_acc": 0.75, "report/cont_neg_loss": 0.6280895471572876, "report/cont_pos_acc": 0.5482283234596252, "report/cont_pos_loss": 0.7023815512657166, "report/cont_pred": 0.5184104442596436, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 10.797883033752441, "report/dyn_loss_std": 0.5416149497032166, "report/image_loss_mean": 3715.5849609375, "report/image_loss_std": 155.23777770996094, "report/model_loss_mean": 3728.306640625, "report/model_loss_std": 155.10772705078125, "report/post_ent_mag": 106.24181365966797, "report/post_ent_max": 106.24181365966797, "report/post_ent_mean": 105.66691589355469, "report/post_ent_min": 104.99224853515625, "report/post_ent_std": 0.22824019193649292, "report/prior_ent_mag": 106.3882064819336, "report/prior_ent_max": 106.3882064819336, "report/prior_ent_mean": 105.58715057373047, "report/prior_ent_min": 104.39857482910156, "report/prior_ent_std": 0.3030639886856079, "report/rep_loss_mean": 10.797883033752441, "report/rep_loss_std": 0.5416149497032166, "report/reward_avg": 0.006501795258373022, "report/reward_loss_mean": 5.541262626647949, "report/reward_loss_std": 9.804239198274445e-07, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 0.0, "report/reward_neg_acc": 0.9999999403953552, "report/reward_neg_loss": 5.541262626647949, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 5.541263580322266, "report/reward_pred": 0.0, "report/reward_rate": 0.0126953125, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.6602650880813599, "eval/cont_loss_std": 0.25810670852661133, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.5355985164642334, "eval/cont_pos_acc": 0.6023505926132202, "eval/cont_pos_loss": 0.6606314182281494, "eval/cont_pred": 0.5326665639877319, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 10.862504005432129, "eval/dyn_loss_std": 0.5451362133026123, "eval/image_loss_mean": 3597.4228515625, "eval/image_loss_std": 197.41885375976562, "eval/model_loss_mean": 3610.141845703125, "eval/model_loss_std": 197.3439483642578, "eval/post_ent_mag": 106.3672866821289, "eval/post_ent_max": 106.3672866821289, "eval/post_ent_mean": 105.63914489746094, "eval/post_ent_min": 104.86788940429688, "eval/post_ent_std": 0.28164562582969666, "eval/prior_ent_mag": 106.44273376464844, "eval/prior_ent_max": 106.44273376464844, "eval/prior_ent_mean": 105.58651733398438, "eval/prior_ent_min": 104.73049926757812, "eval/prior_ent_std": 0.26217448711395264, "eval/rep_loss_mean": 10.862504005432129, "eval/rep_loss_std": 0.5451362133026123, "eval/reward_avg": 0.01025390625, "eval/reward_loss_mean": 5.541262626647949, "eval/reward_loss_std": 9.542561656417092e-07, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 5.541262626647949, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.541264057159424, "eval/reward_pred": 0.0, "eval/reward_rate": 0.013671875, "replay/size": 1057.0, "replay/inserts": 1057.0, "replay/samples": 112.0, "replay/insert_wait_avg": 2.4938087138570244e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.302075522286551e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 2880.0, "eval_replay/inserts": 2880.0, "eval_replay/samples": 112.0, "eval_replay/insert_wait_avg": 1.5112260977427165e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.047133581978934e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 237.81831550598145, "timer/env.step_count": 196.0, "timer/env.step_total": 25.328965663909912, "timer/env.step_frac": 0.10650552969404434, "timer/env.step_avg": 0.1292294166526016, "timer/env.step_min": 0.02261495590209961, "timer/env.step_max": 11.287426710128784, "timer/replay._sample_count": 112.0, "timer/replay._sample_total": 0.10973334312438965, "timer/replay._sample_frac": 0.00046141670329689016, "timer/replay._sample_avg": 0.0009797619921820505, "timer/replay._sample_min": 0.000354766845703125, "timer/replay._sample_max": 0.009387493133544922, "timer/agent.save_count": 1.0, "timer/agent.save_total": 9.28034234046936, "timer/agent.save_frac": 0.0390228242964573, "timer/agent.save_avg": 9.28034234046936, "timer/agent.save_min": 9.28034234046936, "timer/agent.save_max": 9.28034234046936, "timer/agent.policy_count": 229.0, "timer/agent.policy_total": 25.341060161590576, "timer/agent.policy_frac": 0.10655638573368507, "timer/agent.policy_avg": 0.11065965136065754, "timer/agent.policy_min": 0.009793996810913086, "timer/agent.policy_max": 19.02913236618042, "timer/dataset_train_count": 1.0, "timer/dataset_train_total": 3.266334533691406e-05, "timer/dataset_train_frac": 1.3734579385704436e-07, "timer/dataset_train_avg": 3.266334533691406e-05, "timer/dataset_train_min": 3.266334533691406e-05, "timer/dataset_train_max": 3.266334533691406e-05, "timer/agent.train_count": 1.0, "timer/agent.train_total": 93.56342673301697, "timer/agent.train_frac": 0.39342397381779337, "timer/agent.train_avg": 93.56342673301697, "timer/agent.train_min": 93.56342673301697, "timer/agent.train_max": 93.56342673301697, "timer/agent.report_count": 2.0, "timer/agent.report_total": 31.258487939834595, "timer/agent.report_frac": 0.13143852219005564, "timer/agent.report_avg": 15.629243969917297, "timer/agent.report_min": 7.648159027099609, "timer/agent.report_max": 23.610328912734985, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 4.0531158447265625e-05, "timer/dataset_eval_frac": 1.7042908726786524e-07, "timer/dataset_eval_avg": 4.0531158447265625e-05, "timer/dataset_eval_min": 4.0531158447265625e-05, "timer/dataset_eval_max": 4.0531158447265625e-05}
{"step": 1648, "time": 375.4016840457916, "episode/length": 205.0, "episode/score": 0.3077831087211962, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.20778309931483818}
{"step": 2072, "time": 570.8685574531555, "episode/length": 130.0, "episode/score": 1.2121475774220016, "episode/reward_rate": 0.9618320610687023, "episode/intrinsic_return": 0.1121476054431696}
{"step": 2128, "time": 598.0407271385193, "episode/length": 179.0, "episode/score": 0.268042251082079, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.16804224283987423}
{"step": 2784, "time": 900.4176752567291, "episode/length": 197.0, "episode/score": 2.290206382403994, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.19020631572129787}
{"step": 2832, "time": 923.9719631671906, "episode/length": 170.0, "episode/score": 1.28453159689343, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.18453156117720937}
{"step": 3024, "time": 1013.2754533290863, "episode/length": 189.0, "episode/score": 1.3067780558722006, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.20677801899182668}
{"step": 3152, "time": 1073.3214859962463, "episode/length": 127.0, "episode/score": 0.2330219702762406, "episode/reward_rate": 0.9609375, "episode/intrinsic_return": 0.13302196203403582}
{"step": 3168, "time": 1082.1337068080902, "episode/length": 41.0, "episode/score": -0.8542916878650431, "episode/reward_rate": 0.8809523809523809, "episode/intrinsic_return": 0.045708332530921325}
{"step": 3200, "time": 1098.4594433307648, "episode/length": 193.0, "episode/score": 2.2752888262766646, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.17528872944239993}
{"step": 3224, "time": 1110.850405216217, "episode/length": 257.0, "episode/score": 0.4071588340084418, "episode/reward_rate": 0.9961240310077519, "episode/intrinsic_return": 0.307158835545124}
{"step": 3240, "time": 1119.6519782543182, "episode/length": 145.0, "episode/score": 2.2442097273669788, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.14420962899021106}
{"step": 3312, "time": 1154.1137926578522, "episode/length": 266.0, "episode/score": 2.364845797743328, "episode/reward_rate": 0.9850187265917603, "episode/intrinsic_return": 0.2648457310606318}
{"step": 3408, "time": 1199.7572989463806, "episode/length": 77.0, "episode/score": 1.1710259634892282, "episode/reward_rate": 0.9358974358974359, "episode/intrinsic_return": 0.0710259266088542}
{"step": 3632, "time": 1305.0679264068604, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.7478505010190215, "train/action_min": 0.0, "train/action_std": 3.64681596485313, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04020251630403884, "train/actor_opt_grad_steps": 1040.0, "train/actor_opt_loss": 176.6031678961095, "train/adv_mag": 1.441944792461784, "train/adv_max": 1.4320385868836571, "train/adv_mean": 0.052663875828212026, "train/adv_min": -0.5509165734656949, "train/adv_std": 0.15475908165750932, "train/cont_avg": 0.9953908137077294, "train/cont_loss_mean": 0.012226381102251157, "train/cont_loss_std": 0.1231480806319106, "train/cont_neg_acc": 0.6494702624826176, "train/cont_neg_loss": 1.4117331068313062, "train/cont_pos_acc": 0.9976035932411894, "train/cont_pos_loss": 0.005413097794464131, "train/cont_pred": 0.9930899252638149, "train/cont_rate": 0.9953908137077294, "train/dyn_loss_mean": 3.959541426188704, "train/dyn_loss_std": 6.753556817338087, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 4.4200311139010005, "train/extr_critic_critic_opt_grad_steps": 1040.0, "train/extr_critic_critic_opt_loss": 22001.32643606582, "train/extr_critic_mag": 1.40862362511492, "train/extr_critic_max": 1.4086236239631396, "train/extr_critic_mean": 0.6170129493780149, "train/extr_critic_min": -0.06601896032619016, "train/extr_critic_std": 0.4661563778127732, "train/extr_return_normed_mag": 1.9534021348994761, "train/extr_return_normed_max": 1.949253067182622, "train/extr_return_normed_mean": 0.3306304913726664, "train/extr_return_normed_min": -0.35394905131917037, "train/extr_return_normed_std": 0.2865227881395932, "train/extr_return_rate": 0.4115659177118709, "train/extr_return_raw_mag": 3.9440378541371204, "train/extr_return_raw_max": 3.9381932383448173, "train/extr_return_raw_mean": 0.7148342489092752, "train/extr_return_raw_min": -0.6816728702207839, "train/extr_return_raw_std": 0.6557618717118434, "train/extr_reward_mag": 0.8315754552970186, "train/extr_reward_max": 0.83128613665484, "train/extr_reward_mean": 0.01875501506704798, "train/extr_reward_min": -0.3646998445768863, "train/extr_reward_std": 0.11066910773213338, "train/image_loss_mean": 48.39370180673645, "train/image_loss_std": 25.57123860299299, "train/model_loss_mean": 50.991639621015906, "train/model_loss_std": 27.425279730184066, "train/model_opt_grad_norm": 176.35745446658828, "train/model_opt_grad_steps": 1030.0, "train/model_opt_loss": 750.8107978710229, "train/model_opt_model_opt_grad_overflow": 0.004830917874396135, "train/model_opt_model_opt_grad_scale": 15.33250301932367, "train/policy_entropy_mag": 2.2171086881327744, "train/policy_entropy_max": 2.2171086881327744, "train/policy_entropy_mean": 0.8433818342029185, "train/policy_entropy_min": 0.3533786147976843, "train/policy_entropy_std": 0.4052795208045754, "train/policy_logprob_mag": 7.137398236039756, "train/policy_logprob_max": -0.1512862588211462, "train/policy_logprob_mean": -0.8431124487792813, "train/policy_logprob_min": -7.137398236039756, "train/policy_logprob_std": 1.0646375610632597, "train/policy_randomness_mag": 0.7825420703289013, "train/policy_randomness_max": 0.7825420703289013, "train/policy_randomness_mean": 0.29767677617137844, "train/policy_randomness_min": 0.1247271438565663, "train/policy_randomness_std": 0.14304588611152222, "train/post_ent_mag": 45.52345449106705, "train/post_ent_max": 45.52345449106705, "train/post_ent_mean": 25.578425255374633, "train/post_ent_min": 11.964871881088772, "train/post_ent_std": 6.679764961202939, "train/prior_ent_mag": 58.83616485227133, "train/prior_ent_max": 58.83616485227133, "train/prior_ent_mean": 30.51920594109429, "train/prior_ent_min": 14.518842006075209, "train/prior_ent_std": 8.24050639897297, "train/rep_loss_mean": 3.959541426188704, "train/rep_loss_std": 6.753556817338087, "train/reward_avg": 0.007528549780369543, "train/reward_loss_mean": 0.20998540824810089, "train/reward_loss_std": 0.3804406238347864, "train/reward_max_data": 1.0012500286102295, "train/reward_max_pred": 0.8508333595478592, "train/reward_neg_acc": 0.9977624122647272, "train/reward_neg_loss": 0.1895088999743623, "train/reward_pos_acc": 0.6384806565328497, "train/reward_pos_loss": 1.6879121033465805, "train/reward_pred": 0.007044712650130732, "train/reward_rate": 0.014374811292270532, "train_stats/sum_log_reward": 0.9461538172685183, "train_stats/max_log_achievement_collect_drink": 5.615384615384615, "train_stats/max_log_achievement_collect_sapling": 2.1538461538461537, "train_stats/max_log_achievement_collect_wood": 0.46153846153846156, "train_stats/max_log_achievement_place_plant": 0.07692307692307693, "train_stats/max_log_achievement_place_table": 0.0, "train_stats/max_log_achievement_wake_up": 1.9230769230769231, "train_stats/mean_log_entropy": 1.0148148192809179, "report/cont_avg": 0.990234375, "report/cont_loss_mean": 0.0005092963692732155, "report/cont_loss_std": 0.0032061149831861258, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0013312972150743008, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0005011898465454578, "report/cont_pred": 0.9897562265396118, "report/cont_rate": 0.990234375, "report/dyn_loss_mean": 3.3346409797668457, "report/dyn_loss_std": 6.54296350479126, "report/image_loss_mean": 9.36528491973877, "report/image_loss_std": 10.564964294433594, "report/model_loss_mean": 11.447449684143066, "report/model_loss_std": 12.666694641113281, "report/post_ent_mag": 40.1535758972168, "report/post_ent_max": 40.1535758972168, "report/post_ent_mean": 21.735652923583984, "report/post_ent_min": 8.406549453735352, "report/post_ent_std": 5.063119411468506, "report/prior_ent_mag": 59.48855972290039, "report/prior_ent_max": 59.48855972290039, "report/prior_ent_mean": 25.830345153808594, "report/prior_ent_min": 10.432748794555664, "report/prior_ent_std": 8.2693510055542, "report/rep_loss_mean": 3.3346409797668457, "report/rep_loss_std": 6.54296350479126, "report/reward_avg": 0.004859170876443386, "report/reward_loss_mean": 0.08087015151977539, "report/reward_loss_std": 0.15417642891407013, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0003159046173096, "report/reward_neg_acc": 0.9990050196647644, "report/reward_neg_loss": 0.06926702708005905, "report/reward_pos_acc": 0.6842105388641357, "report/reward_pos_loss": 0.694614589214325, "report/reward_pred": 0.004899747669696808, "report/reward_rate": 0.0185546875, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.00011585313768591732, "eval/cont_loss_std": 0.0011768260737881064, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.00011585313768591732, "eval/cont_pred": 0.999884843826294, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 18.91851806640625, "eval/dyn_loss_std": 12.471628189086914, "eval/image_loss_mean": 70.42414855957031, "eval/image_loss_std": 77.4468002319336, "eval/model_loss_mean": 81.89694213867188, "eval/model_loss_std": 80.94237518310547, "eval/post_ent_mag": 51.19615173339844, "eval/post_ent_max": 51.19615173339844, "eval/post_ent_mean": 27.62738037109375, "eval/post_ent_min": 8.320330619812012, "eval/post_ent_std": 9.210400581359863, "eval/prior_ent_mag": 59.48855972290039, "eval/prior_ent_max": 59.48855972290039, "eval/prior_ent_mean": 31.807538986206055, "eval/prior_ent_min": 9.230722427368164, "eval/prior_ent_std": 10.850235939025879, "eval/rep_loss_mean": 18.91851806640625, "eval/rep_loss_std": 12.471628189086914, "eval/reward_avg": 0.008496093563735485, "eval/reward_loss_mean": 0.1215580403804779, "eval/reward_loss_std": 0.9621858596801758, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0002803802490234, "eval/reward_neg_acc": 0.9990128874778748, "eval/reward_neg_loss": 0.07749604433774948, "eval/reward_pos_acc": 0.3636363744735718, "eval/reward_pos_loss": 4.1792683601379395, "eval/reward_pred": 0.004696694668382406, "eval/reward_rate": 0.0107421875, "replay/size": 3128.0, "replay/inserts": 2071.0, "replay/samples": 33136.0, "replay/insert_wait_avg": 2.7251784666789894e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.85592013680952e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 2880.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 1.3709068298339844e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 969.6271352767944, "timer/env.step_count": 258.0, "timer/env.step_total": 26.907611846923828, "timer/env.step_frac": 0.027750473215915776, "timer/env.step_avg": 0.10429306917412337, "timer/env.step_min": 0.02416253089904785, "timer/env.step_max": 1.6659715175628662, "timer/replay._sample_count": 33136.0, "timer/replay._sample_total": 16.46942949295044, "timer/replay._sample_frac": 0.016985322392250292, "timer/replay._sample_avg": 0.0004970252744130384, "timer/replay._sample_min": 0.00031447410583496094, "timer/replay._sample_max": 0.04055666923522949, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 258.0, "timer/agent.policy_total": 4.248175144195557, "timer/agent.policy_frac": 0.004381246140541284, "timer/agent.policy_avg": 0.016465795132540918, "timer/agent.policy_min": 0.015294551849365234, "timer/agent.policy_max": 0.01983475685119629, "timer/dataset_train_count": 2071.0, "timer/dataset_train_total": 0.38613128662109375, "timer/dataset_train_frac": 0.00039822656830954597, "timer/dataset_train_avg": 0.0001864467825307068, "timer/dataset_train_min": 9.34600830078125e-05, "timer/dataset_train_max": 0.0007002353668212891, "timer/agent.train_count": 2071.0, "timer/agent.train_total": 927.5234749317169, "timer/agent.train_frac": 0.9565774731200583, "timer/agent.train_avg": 0.447862614645928, "timer/agent.train_min": 0.4343678951263428, "timer/agent.train_max": 0.5795340538024902, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48596978187561035, "timer/agent.report_frac": 0.0005011924318071844, "timer/agent.report_avg": 0.24298489093780518, "timer/agent.report_min": 0.2384934425354004, "timer/agent.report_max": 0.24747633934020996, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.337860107421875e-05, "timer/dataset_eval_frac": 3.442416147387453e-08, "timer/dataset_eval_avg": 3.337860107421875e-05, "timer/dataset_eval_min": 3.337860107421875e-05, "timer/dataset_eval_max": 3.337860107421875e-05, "fps": 2.1358474772176748}
{"step": 3888, "time": 1422.6602466106415, "episode/length": 89.0, "episode/score": 1.182269620241641, "episode/reward_rate": 0.9888888888888889, "episode/intrinsic_return": 0.08226960454885557}
{"step": 4208, "time": 1569.9745223522186, "episode/length": 147.0, "episode/score": 2.234968009232034, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.13496794254933775}
{"step": 4576, "time": 1738.3685262203217, "episode/length": 157.0, "episode/score": 2.2637458624731153, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.16374574480050796}
{"step": 4960, "time": 1914.4642362594604, "episode/length": 216.0, "episode/score": 1.3245771293586586, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.22457710179151036}
{"step": 5056, "time": 1959.4794957637787, "episode/length": 231.0, "episode/score": 4.347491665376765, "episode/reward_rate": 0.978448275862069, "episode/intrinsic_return": 0.24749154258188355}
{"step": 5056, "time": 1959.488261938095, "episode/length": 226.0, "episode/score": 2.33607876262613, "episode/reward_rate": 0.9779735682819384, "episode/intrinsic_return": 0.23607869710758678}
{"step": 5144, "time": 2002.7140934467316, "episode/length": 248.0, "episode/score": 4.3158634417332, "episode/reward_rate": 0.9839357429718876, "episode/intrinsic_return": 0.21586333156938053}
{"step": 5200, "time": 2029.8116536140442, "episode/length": 223.0, "episode/score": 4.3246711689371296, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.2246710211129539}
{"step": 5216, "time": 2038.713815689087, "episode/length": 165.0, "episode/score": 3.230806351222782, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.13080625706606952}
{"step": 5464, "time": 2153.01643037796, "episode/length": 156.0, "episode/score": 2.2646775453913506, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.16467744855708588}
{"step": 5464, "time": 2153.0236139297485, "episode/length": 32.0, "episode/score": -0.8638749640667811, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.03612499951850623}
{"step": 5791, "time": 2305.146652698517, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.431243896484375, "train/action_min": 0.0, "train/action_std": 3.2177022242987596, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03434544130814848, "train/actor_opt_grad_steps": 3155.0, "train/actor_opt_loss": 65.04998008216972, "train/adv_mag": 0.8262974067970559, "train/adv_max": 0.7905978767408265, "train/adv_mean": 0.01903088638122157, "train/adv_min": -0.5577759028032974, "train/adv_std": 0.07830711041956588, "train/cont_avg": 0.9944073712384259, "train/cont_loss_mean": 0.000518874035210333, "train/cont_loss_std": 0.013850269170259506, "train/cont_neg_acc": 0.982842815970933, "train/cont_neg_loss": 0.06263710400215329, "train/cont_pos_acc": 0.9999726883791111, "train/cont_pos_loss": 0.00013483635384956314, "train/cont_pred": 0.9944129842850897, "train/cont_rate": 0.9944073712384259, "train/dyn_loss_mean": 2.915698728075734, "train/dyn_loss_std": 6.230616379667212, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.2369928986386016, "train/extr_critic_critic_opt_grad_steps": 3155.0, "train/extr_critic_critic_opt_loss": 16328.071872287326, "train/extr_critic_mag": 5.514959635557951, "train/extr_critic_max": 5.514959635557951, "train/extr_critic_mean": 2.4648272411690817, "train/extr_critic_min": -0.156426590901834, "train/extr_critic_std": 1.869558423757553, "train/extr_return_normed_mag": 1.6009094682004716, "train/extr_return_normed_max": 1.6009094682004716, "train/extr_return_normed_mean": 0.4856023522162879, "train/extr_return_normed_min": -0.15526840759924165, "train/extr_return_normed_std": 0.3674945752653811, "train/extr_return_rate": 0.77962183152084, "train/extr_return_raw_mag": 8.550260113345253, "train/extr_return_raw_max": 8.550260113345253, "train/extr_return_raw_mean": 2.5674882608431355, "train/extr_return_raw_min": -0.8918038250671493, "train/extr_return_raw_std": 1.9931603929510824, "train/extr_reward_mag": 1.0024817718399897, "train/extr_reward_max": 1.0024817718399897, "train/extr_reward_mean": 0.03212568338494748, "train/extr_reward_min": -0.5950568114165906, "train/extr_reward_std": 0.16384819481107923, "train/image_loss_mean": 6.518342779742347, "train/image_loss_std": 8.467077171361005, "train/model_loss_mean": 8.340236794065547, "train/model_loss_std": 10.995486561898831, "train/model_opt_grad_norm": 95.90264844894409, "train/model_opt_grad_steps": 3145.0, "train/model_opt_loss": 544.7239016780147, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 69.08275462962963, "train/policy_entropy_mag": 2.412619906443137, "train/policy_entropy_max": 2.412619906443137, "train/policy_entropy_mean": 0.5558131491696393, "train/policy_entropy_min": 0.07944646432857823, "train/policy_entropy_std": 0.5108549458285173, "train/policy_logprob_mag": 7.438120042836225, "train/policy_logprob_max": -0.009465954594176125, "train/policy_logprob_mean": -0.5553286067313619, "train/policy_logprob_min": -7.438120042836225, "train/policy_logprob_std": 1.1241320297122002, "train/policy_randomness_mag": 0.851548952360948, "train/policy_randomness_max": 0.851548952360948, "train/policy_randomness_mean": 0.19617765007057675, "train/policy_randomness_min": 0.028041115444567468, "train/policy_randomness_std": 0.1803093781625783, "train/post_ent_mag": 34.94020281897651, "train/post_ent_max": 34.94020281897651, "train/post_ent_mean": 19.534500740192556, "train/post_ent_min": 8.325725036638755, "train/post_ent_std": 4.8172997512199265, "train/prior_ent_mag": 59.99599191877577, "train/prior_ent_max": 59.99599191877577, "train/prior_ent_mean": 22.87037024674592, "train/prior_ent_min": 10.021004809273613, "train/prior_ent_std": 8.061739042953208, "train/rep_loss_mean": 2.915698728075734, "train/rep_loss_std": 6.230616379667212, "train/reward_avg": 0.00979883059281511, "train/reward_loss_mean": 0.07195586145476059, "train/reward_loss_std": 0.19600707351195593, "train/reward_max_data": 1.0012500286102295, "train/reward_max_pred": 1.0019038932191, "train/reward_neg_acc": 0.999150517086188, "train/reward_neg_loss": 0.057039372571226626, "train/reward_pos_acc": 0.8232909864573567, "train/reward_pos_loss": 0.812654964349888, "train/reward_pred": 0.009672993863070453, "train/reward_rate": 0.019657841435185185, "train_stats/sum_log_reward": 2.2818181297995825, "train_stats/max_log_achievement_collect_drink": 2.6363636363636362, "train_stats/max_log_achievement_collect_sapling": 1.1818181818181819, "train_stats/max_log_achievement_collect_wood": 0.8181818181818182, "train_stats/max_log_achievement_place_plant": 0.8181818181818182, "train_stats/max_log_achievement_place_table": 0.0, "train_stats/max_log_achievement_wake_up": 2.0, "train_stats/mean_log_entropy": 0.8200292912396517, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 1.4745919543202035e-06, "report/cont_loss_std": 2.15335312532261e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 1.570507447468117e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.4467436812992673e-06, "report/cont_pred": 0.9980455636978149, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 2.787266731262207, "report/dyn_loss_std": 7.100895404815674, "report/image_loss_mean": 6.509896755218506, "report/image_loss_std": 7.539267063140869, "report/model_loss_mean": 8.24609375, "report/model_loss_std": 10.257351875305176, "report/post_ent_mag": 34.16302490234375, "report/post_ent_max": 34.16302490234375, "report/post_ent_mean": 18.3890323638916, "report/post_ent_min": 7.672830581665039, "report/post_ent_std": 5.559691429138184, "report/prior_ent_mag": 62.354339599609375, "report/prior_ent_max": 62.354339599609375, "report/prior_ent_mean": 21.70183753967285, "report/prior_ent_min": 9.790748596191406, "report/prior_ent_std": 8.803464889526367, "report/rep_loss_mean": 2.787266731262207, "report/rep_loss_std": 7.100895404815674, "report/reward_avg": 0.014080526307225227, "report/reward_loss_mean": 0.0638350173830986, "report/reward_loss_std": 0.19113284349441528, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0044348239898682, "report/reward_neg_acc": 0.9990040063858032, "report/reward_neg_loss": 0.04555338993668556, "report/reward_pos_acc": 0.8500000238418579, "report/reward_pos_loss": 0.9815727472305298, "report/reward_pred": 0.012805081903934479, "report/reward_rate": 0.01953125, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.045021526515483856, "eval/cont_loss_std": 0.6169044375419617, "eval/cont_neg_acc": 0.6666666865348816, "eval/cont_neg_loss": 3.8360166549682617, "eval/cont_pos_acc": 0.994106113910675, "eval/cont_pos_loss": 0.022677745670080185, "eval/cont_pred": 0.9907158613204956, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 21.501022338867188, "eval/dyn_loss_std": 13.103231430053711, "eval/image_loss_mean": 63.5760498046875, "eval/image_loss_std": 80.0657958984375, "eval/model_loss_mean": 76.69071197509766, "eval/model_loss_std": 83.9356918334961, "eval/post_ent_mag": 41.505340576171875, "eval/post_ent_max": 41.505340576171875, "eval/post_ent_mean": 25.12679672241211, "eval/post_ent_min": 9.030097007751465, "eval/post_ent_std": 6.904738903045654, "eval/prior_ent_mag": 62.354339599609375, "eval/prior_ent_max": 62.354339599609375, "eval/prior_ent_mean": 29.776493072509766, "eval/prior_ent_min": 9.825865745544434, "eval/prior_ent_std": 9.25448226928711, "eval/rep_loss_mean": 21.501022338867188, "eval/rep_loss_std": 13.103231430053711, "eval/reward_avg": 0.006152343936264515, "eval/reward_loss_mean": 0.16902630031108856, "eval/reward_loss_std": 1.0860669612884521, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.002509593963623, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.11618281900882721, "eval/reward_pos_acc": 0.5, "eval/reward_pos_loss": 4.625494003295898, "eval/reward_pred": 0.004022413864731789, "eval/reward_rate": 0.01171875, "replay/size": 5287.0, "replay/inserts": 2159.0, "replay/samples": 34544.0, "replay/insert_wait_avg": 2.7309362951281337e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.957067720202067e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 2880.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 7.301568984985352e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0651240348816, "timer/env.step_count": 270.0, "timer/env.step_total": 24.671552658081055, "timer/env.step_frac": 0.02466994605165386, "timer/env.step_avg": 0.09137612095585576, "timer/env.step_min": 0.02413177490234375, "timer/env.step_max": 3.329056978225708, "timer/replay._sample_count": 34544.0, "timer/replay._sample_total": 16.90502619743347, "timer/replay._sample_frac": 0.016903925345609628, "timer/replay._sample_avg": 0.0004893766268363094, "timer/replay._sample_min": 0.0003216266632080078, "timer/replay._sample_max": 0.017546653747558594, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 270.0, "timer/agent.policy_total": 4.307507038116455, "timer/agent.policy_frac": 0.004307226534145402, "timer/agent.policy_avg": 0.015953729770801686, "timer/agent.policy_min": 0.01451253890991211, "timer/agent.policy_max": 0.028275489807128906, "timer/dataset_train_count": 2159.0, "timer/dataset_train_total": 0.3921236991882324, "timer/dataset_train_frac": 0.00039209816417371175, "timer/dataset_train_avg": 0.0001816228342696769, "timer/dataset_train_min": 9.512901306152344e-05, "timer/dataset_train_max": 0.0004971027374267578, "timer/agent.train_count": 2159.0, "timer/agent.train_total": 960.4620742797852, "timer/agent.train_frac": 0.9603995291873461, "timer/agent.train_avg": 0.4448643234274132, "timer/agent.train_min": 0.4327073097229004, "timer/agent.train_max": 0.586505651473999, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47077512741088867, "timer/agent.report_frac": 0.00047074447063156295, "timer/agent.report_avg": 0.23538756370544434, "timer/agent.report_min": 0.22828102111816406, "timer/agent.report_max": 0.2424941062927246, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8848648071289062e-05, "timer/dataset_eval_frac": 2.8846769453268965e-08, "timer/dataset_eval_avg": 2.8848648071289062e-05, "timer/dataset_eval_min": 2.8848648071289062e-05, "timer/dataset_eval_max": 2.8848648071289062e-05, "fps": 2.1588345337749923}
{"step": 6136, "time": 2462.021353006363, "episode/length": 146.0, "episode/score": 3.248974621452362, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.14897444033340435}
{"step": 6272, "time": 2525.333365917206, "episode/length": 151.0, "episode/score": 3.217026403336604, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.11702629078627069}
{"step": 6448, "time": 2606.7423417568207, "episode/length": 162.0, "episode/score": 0.2711692237912757, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.17116927556116934}
{"step": 6552, "time": 2655.5523858070374, "episode/length": 186.0, "episode/score": 2.257515396645431, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.1575153009753194}
{"step": 6664, "time": 2707.9173300266266, "episode/length": 260.0, "episode/score": 2.358621014806886, "episode/reward_rate": 0.9846743295019157, "episode/intrinsic_return": 0.25862094812418945}
{"step": 6704, "time": 2727.649093389511, "episode/length": 185.0, "episode/score": 4.296297077127292, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.19629695316825746}
{"step": 6792, "time": 2769.0879628658295, "episode/length": 165.0, "episode/score": 1.2293399817203863, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.12933994484001232}
{"step": 7760, "time": 3212.4745666980743, "episode/length": 185.0, "episode/score": 0.30568189700716175, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.20568188760080375}
{"step": 7959, "time": 3305.580351114273, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.277566980432581, "train/action_min": 0.0, "train/action_std": 3.2793774836593204, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.030052816038261407, "train/actor_opt_grad_steps": 5315.0, "train/actor_opt_loss": 15.293884373235482, "train/adv_mag": 0.6179651761496509, "train/adv_max": 0.5702957388151575, "train/adv_mean": 0.007371035059223787, "train/adv_min": -0.5012518759402964, "train/adv_std": 0.05555664900586837, "train/cont_avg": 0.9943124276620371, "train/cont_loss_mean": 0.00030327191251709485, "train/cont_loss_std": 0.008816706825153288, "train/cont_neg_acc": 0.991926911542582, "train/cont_neg_loss": 0.032445162863757294, "train/cont_pos_acc": 0.9999635876328857, "train/cont_pos_loss": 0.00012105949950647066, "train/cont_pred": 0.994313163889779, "train/cont_rate": 0.9943124276620371, "train/dyn_loss_mean": 2.723040853385572, "train/dyn_loss_std": 6.792203463889934, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.2042059454101104, "train/extr_critic_critic_opt_grad_steps": 5315.0, "train/extr_critic_critic_opt_loss": 15463.94517686632, "train/extr_critic_mag": 9.74377010486744, "train/extr_critic_max": 9.74377010486744, "train/extr_critic_mean": 4.090658091836506, "train/extr_critic_min": -0.3225431729246069, "train/extr_critic_std": 2.8390458126862845, "train/extr_return_normed_mag": 1.403976747835124, "train/extr_return_normed_max": 1.403976747835124, "train/extr_return_normed_mean": 0.48526627887730245, "train/extr_return_normed_min": -0.11047787746173088, "train/extr_return_normed_std": 0.346969673892966, "train/extr_return_rate": 0.8834479136599435, "train/extr_return_raw_mag": 11.946543207875004, "train/extr_return_raw_max": 11.946543207875004, "train/extr_return_raw_mean": 4.149265313590014, "train/extr_return_raw_min": -0.8768180731545996, "train/extr_return_raw_std": 2.9423268293892897, "train/extr_reward_mag": 1.00549621824865, "train/extr_reward_max": 1.00549621824865, "train/extr_reward_mean": 0.030912738061656623, "train/extr_reward_min": -0.6003488683038287, "train/extr_reward_std": 0.16657953461011252, "train/image_loss_mean": 5.050534514365373, "train/image_loss_std": 7.36140869723426, "train/model_loss_mean": 6.752314454979366, "train/model_loss_std": 10.226810461945004, "train/model_opt_grad_norm": 82.2906134305177, "train/model_opt_grad_steps": 5305.0, "train/model_opt_loss": 2047.3460727267795, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 311.05324074074076, "train/policy_entropy_mag": 2.436944133705563, "train/policy_entropy_max": 2.436944133705563, "train/policy_entropy_mean": 0.49696600809693336, "train/policy_entropy_min": 0.07938076317724255, "train/policy_entropy_std": 0.5082611592003593, "train/policy_logprob_mag": 7.438356693144198, "train/policy_logprob_max": -0.009456890975815003, "train/policy_logprob_mean": -0.4966380383681368, "train/policy_logprob_min": -7.438356693144198, "train/policy_logprob_std": 1.0891057887562998, "train/policy_randomness_mag": 0.8601343369594326, "train/policy_randomness_max": 0.8601343369594326, "train/policy_randomness_mean": 0.17540719222139428, "train/policy_randomness_min": 0.0280179258229004, "train/policy_randomness_std": 0.17939388634705986, "train/post_ent_mag": 32.386252014725294, "train/post_ent_max": 32.386252014725294, "train/post_ent_mean": 18.16139308611552, "train/post_ent_min": 8.204386157018167, "train/post_ent_std": 4.28082220311518, "train/prior_ent_mag": 63.632351363146746, "train/prior_ent_max": 63.632351363146746, "train/prior_ent_mean": 21.094984937597204, "train/prior_ent_min": 9.543566156316686, "train/prior_ent_std": 8.156680895222557, "train/rep_loss_mean": 2.723040853385572, "train/rep_loss_std": 6.792203463889934, "train/reward_avg": 0.011012989388459741, "train/reward_loss_mean": 0.06765214752198921, "train/reward_loss_std": 0.1707650579650093, "train/reward_max_data": 1.0012500286102295, "train/reward_max_pred": 1.0036148108817913, "train/reward_neg_acc": 0.9993447854563042, "train/reward_neg_loss": 0.052946158374349274, "train/reward_pos_acc": 0.8613724137345949, "train/reward_pos_loss": 0.7676645387653951, "train/reward_pred": 0.010837209981723895, "train/reward_rate": 0.020421911168981483, "train_stats/sum_log_reward": 1.9749999344348907, "train_stats/max_log_achievement_collect_drink": 2.5, "train_stats/max_log_achievement_collect_sapling": 0.75, "train_stats/max_log_achievement_collect_wood": 1.0, "train_stats/max_log_achievement_eat_cow": 0.125, "train_stats/max_log_achievement_place_plant": 0.625, "train_stats/max_log_achievement_place_table": 0.25, "train_stats/max_log_achievement_wake_up": 2.0, "train_stats/mean_log_entropy": 0.5927881449460983, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 8.41397741169203e-06, "report/cont_loss_std": 0.00010715207463363186, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0005931074847467244, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 5.545020030695014e-06, "report/cont_pred": 0.9951145648956299, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 2.7178702354431152, "report/dyn_loss_std": 7.059601306915283, "report/image_loss_mean": 6.254061698913574, "report/image_loss_std": 12.948031425476074, "report/model_loss_mean": 7.950394153594971, "report/model_loss_std": 15.566174507141113, "report/post_ent_mag": 34.92848205566406, "report/post_ent_max": 34.92848205566406, "report/post_ent_mean": 17.1501407623291, "report/post_ent_min": 8.118288040161133, "report/post_ent_std": 4.2223968505859375, "report/prior_ent_mag": 65.28933715820312, "report/prior_ent_max": 65.28933715820312, "report/prior_ent_mean": 20.077333450317383, "report/prior_ent_min": 9.669086456298828, "report/prior_ent_std": 8.277457237243652, "report/rep_loss_mean": 2.7178702354431152, "report/rep_loss_std": 7.059601306915283, "report/reward_avg": 0.010634446516633034, "report/reward_loss_mean": 0.06560182571411133, "report/reward_loss_std": 0.18547135591506958, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0045390129089355, "report/reward_neg_acc": 0.999002993106842, "report/reward_neg_loss": 0.04767906665802002, "report/reward_pos_acc": 0.8571428656578064, "report/reward_pos_loss": 0.9216268062591553, "report/reward_pred": 0.009167766198515892, "report/reward_rate": 0.0205078125, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 7.819033635314554e-05, "eval/cont_loss_std": 0.0020364271476864815, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.003461073152720928, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 6.825041782576591e-05, "eval/cont_pred": 0.9970143437385559, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 22.56448745727539, "eval/dyn_loss_std": 13.631492614746094, "eval/image_loss_mean": 71.12095642089844, "eval/image_loss_std": 78.78475952148438, "eval/model_loss_mean": 84.84359741210938, "eval/model_loss_std": 83.50054168701172, "eval/post_ent_mag": 38.32764434814453, "eval/post_ent_max": 38.32764434814453, "eval/post_ent_mean": 24.526119232177734, "eval/post_ent_min": 7.629732131958008, "eval/post_ent_std": 7.088700771331787, "eval/prior_ent_mag": 65.28933715820312, "eval/prior_ent_max": 65.28933715820312, "eval/prior_ent_mean": 28.338712692260742, "eval/prior_ent_min": 9.001708984375, "eval/prior_ent_std": 10.024590492248535, "eval/rep_loss_mean": 22.56448745727539, "eval/rep_loss_std": 13.631492614746094, "eval/reward_avg": 0.01005859300494194, "eval/reward_loss_mean": 0.18387499451637268, "eval/reward_loss_std": 1.1704473495483398, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0022926330566406, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.10415314137935638, "eval/reward_pos_acc": 0.4285714626312256, "eval/reward_pos_loss": 5.935237407684326, "eval/reward_pred": 0.004946082830429077, "eval/reward_rate": 0.013671875, "replay/size": 7455.0, "replay/inserts": 2168.0, "replay/samples": 34688.0, "replay/insert_wait_avg": 2.753030769939352e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.62485796411099e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 2880.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 8.791685104370117e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4240663051605, "timer/env.step_count": 271.0, "timer/env.step_total": 19.743143320083618, "timer/env.step_frac": 0.01973477446719214, "timer/env.step_avg": 0.07285292738038235, "timer/env.step_min": 0.024362802505493164, "timer/env.step_max": 1.697310209274292, "timer/replay._sample_count": 34688.0, "timer/replay._sample_total": 16.94516134262085, "timer/replay._sample_frac": 0.016937978516654403, "timer/replay._sample_avg": 0.0004885021143513852, "timer/replay._sample_min": 0.0003139972686767578, "timer/replay._sample_max": 0.010571002960205078, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 271.0, "timer/agent.policy_total": 4.344658374786377, "timer/agent.policy_frac": 0.0043428167325406195, "timer/agent.policy_avg": 0.016031949722458954, "timer/agent.policy_min": 0.014641046524047852, "timer/agent.policy_max": 0.05992531776428223, "timer/dataset_train_count": 2168.0, "timer/dataset_train_total": 0.40769529342651367, "timer/dataset_train_frac": 0.0004075224768754752, "timer/dataset_train_avg": 0.00018805133460632548, "timer/dataset_train_min": 9.679794311523438e-05, "timer/dataset_train_max": 0.003809213638305664, "timer/agent.train_count": 2168.0, "timer/agent.train_total": 965.4021377563477, "timer/agent.train_frac": 0.9649929167756245, "timer/agent.train_avg": 0.44529618900200535, "timer/agent.train_min": 0.4347720146179199, "timer/agent.train_max": 0.5932164192199707, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47915172576904297, "timer/agent.report_frac": 0.0004789486197974837, "timer/agent.report_avg": 0.23957586288452148, "timer/agent.report_min": 0.23233509063720703, "timer/agent.report_max": 0.24681663513183594, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.24249267578125e-05, "timer/dataset_eval_frac": 3.241118226750244e-08, "timer/dataset_eval_avg": 3.24249267578125e-05, "timer/dataset_eval_min": 3.24249267578125e-05, "timer/dataset_eval_max": 3.24249267578125e-05, "fps": 2.167054114305327}
{"step": 8016, "time": 3331.791799068451, "episode/length": 152.0, "episode/score": 1.2674058821103245, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.16740578841927345}
{"step": 8096, "time": 3369.712822198868, "episode/length": 244.0, "episode/score": 1.378934580439818, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.27893451853014994}
{"step": 8112, "time": 3378.645465373993, "episode/length": 207.0, "episode/score": 0.33107354937965283, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.23107354230160126}
{"step": 8296, "time": 3464.4782478809357, "episode/length": 203.0, "episode/score": 3.3260900231907726, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.22608992903406033}
{"step": 8304, "time": 3469.638373851776, "episode/length": 218.0, "episode/score": 2.3112761231423065, "episode/reward_rate": 0.9908675799086758, "episode/intrinsic_return": 0.2112760757554497}
{"step": 8608, "time": 3608.6449036598206, "episode/length": 73.0, "episode/score": 0.16465627872457844, "episode/reward_rate": 0.918918918918919, "episode/intrinsic_return": 0.06465627397483331}
{"step": 8920, "time": 3751.271048784256, "episode/length": 431.0, "episode/score": 1.5610319233660448, "episode/reward_rate": 0.7152777777777778, "episode/intrinsic_return": 0.4610318899781305}
{"step": 8976, "time": 3778.1744894981384, "episode/length": 283.0, "episode/score": 1.4211423016131448, "episode/reward_rate": 0.9964788732394366, "episode/intrinsic_return": 0.32114225611803704}
{"step": 9000, "time": 3790.4380826950073, "episode/length": 154.0, "episode/score": 4.258143863720761, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.15814372486056527}
{"step": 9248, "time": 3904.4237270355225, "episode/length": 141.0, "episode/score": 1.271666697692126, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.17166666314005852}
{"step": 9344, "time": 3949.559141635895, "episode/length": 155.0, "episode/score": 1.270985841498259, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.17098579437333683}
{"step": 9648, "time": 4088.9352519512177, "episode/length": 90.0, "episode/score": 2.2089783966293908, "episode/reward_rate": 0.945054945054945, "episode/intrinsic_return": 0.10897833111084765}
{"step": 9664, "time": 4097.814191102982, "episode/length": 169.0, "episode/score": 1.289204239146784, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.18920420110225677}
{"step": 10088, "time": 4306.156038045883, "eval_episode/length": 84.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9411764705882353}
{"step": 10088, "time": 4309.384306669235, "eval_episode/length": 126.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9448818897637795}
{"step": 10088, "time": 4311.605352163315, "eval_episode/length": 144.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.993103448275862}
{"step": 10088, "time": 4313.088807106018, "eval_episode/length": 145.0, "eval_episode/score": 0.09999999403953552, "eval_episode/reward_rate": 0.9931506849315068}
{"step": 10088, "time": 4314.903450250626, "eval_episode/length": 151.0, "eval_episode/score": 2.100000001490116, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 10088, "time": 4317.530230760574, "eval_episode/length": 32.0, "eval_episode/score": -0.9000000283122063, "eval_episode/reward_rate": 0.9696969696969697}
{"step": 10088, "time": 4319.712817430496, "eval_episode/length": 194.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9641025641025641}
{"step": 10088, "time": 4321.953236818314, "eval_episode/length": 209.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9761904761904762}
{"step": 10089, "time": 4322.976366043091, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.45152920288659, "train/action_min": 0.0, "train/action_std": 3.6231277850871915, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.026327957132472678, "train/actor_opt_grad_steps": 7460.0, "train/actor_opt_loss": -6.722188961477906, "train/adv_mag": 0.589161175237575, "train/adv_max": 0.5247945171986388, "train/adv_mean": 0.0033203372714725133, "train/adv_min": -0.4589944835140112, "train/adv_std": 0.04436790665935183, "train/cont_avg": 0.9946449530516432, "train/cont_loss_mean": 0.0004155491442626917, "train/cont_loss_std": 0.010465846410678464, "train/cont_neg_acc": 0.993160817824619, "train/cont_neg_loss": 0.03741242429544532, "train/cont_pos_acc": 0.9999538525729113, "train/cont_pos_loss": 0.00018621199891248404, "train/cont_pred": 0.9946582110275125, "train/cont_rate": 0.9946449530516432, "train/dyn_loss_mean": 2.6463931580664406, "train/dyn_loss_std": 7.069193179618584, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0741749710879975, "train/extr_critic_critic_opt_grad_steps": 7460.0, "train/extr_critic_critic_opt_loss": 14022.35273620892, "train/extr_critic_mag": 11.691311679535628, "train/extr_critic_max": 11.691311679535628, "train/extr_critic_mean": 3.7015523820975575, "train/extr_critic_min": -0.31228332844138706, "train/extr_critic_std": 2.870344063485732, "train/extr_return_normed_mag": 1.4275272885958354, "train/extr_return_normed_max": 1.4275272885958354, "train/extr_return_normed_mean": 0.4144747538465849, "train/extr_return_normed_min": -0.08766062877757448, "train/extr_return_normed_std": 0.33095561506602683, "train/extr_return_rate": 0.8340259877169076, "train/extr_return_raw_mag": 12.672784236675136, "train/extr_return_raw_max": 12.672784236675136, "train/extr_return_raw_mean": 3.730420793166183, "train/extr_return_raw_min": -0.7108966426950105, "train/extr_return_raw_std": 2.930270750198006, "train/extr_reward_mag": 1.0049694440734218, "train/extr_reward_max": 1.0049694440734218, "train/extr_reward_mean": 0.024610022738785813, "train/extr_reward_min": -0.5805498994012394, "train/extr_reward_std": 0.14943591407347173, "train/image_loss_mean": 4.10289535835875, "train/image_loss_std": 6.714738827915818, "train/model_loss_mean": 5.757666016968203, "train/model_loss_std": 9.786111260803652, "train/model_opt_grad_norm": 72.38530096313764, "train/model_opt_grad_steps": 7449.455399061033, "train/model_opt_loss": 4442.975935528536, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 774.6478873239437, "train/policy_entropy_mag": 2.4502118182294246, "train/policy_entropy_max": 2.4502118182294246, "train/policy_entropy_mean": 0.525878134187958, "train/policy_entropy_min": 0.07937766734003461, "train/policy_entropy_std": 0.5157239375539788, "train/policy_logprob_mag": 7.438358752380514, "train/policy_logprob_max": -0.00945630451410729, "train/policy_logprob_mean": -0.5258267401529589, "train/policy_logprob_min": -7.438358752380514, "train/policy_logprob_std": 1.1077283329806977, "train/policy_randomness_mag": 0.8648172479839952, "train/policy_randomness_max": 0.8648172479839952, "train/policy_randomness_mean": 0.18561190359749144, "train/policy_randomness_min": 0.02801683317747474, "train/policy_randomness_std": 0.18202791842216617, "train/post_ent_mag": 31.544567672299667, "train/post_ent_max": 31.544567672299667, "train/post_ent_mean": 17.675444522374114, "train/post_ent_min": 8.535181426106485, "train/post_ent_std": 3.8943030890164803, "train/prior_ent_mag": 66.07439064419886, "train/prior_ent_max": 66.07439064419886, "train/prior_ent_mean": 20.497803898484495, "train/prior_ent_min": 9.76626548185035, "train/prior_ent_std": 8.166726042966888, "train/rep_loss_mean": 2.6463931580664406, "train/rep_loss_std": 7.069193179618584, "train/reward_avg": 0.010089631515944228, "train/reward_loss_mean": 0.06651919674425617, "train/reward_loss_std": 0.16130341316612673, "train/reward_max_data": 1.0012500286102295, "train/reward_max_pred": 1.0034756201533643, "train/reward_neg_acc": 0.9994951648891252, "train/reward_neg_loss": 0.053061802972090635, "train/reward_pos_acc": 0.8563781803202741, "train/reward_pos_loss": 0.7605283019688208, "train/reward_pred": 0.009978014436340563, "train/reward_rate": 0.019072769953051644, "train_stats/sum_log_reward": 1.4846153614612727, "train_stats/max_log_achievement_collect_drink": 2.8461538461538463, "train_stats/max_log_achievement_collect_sapling": 0.23076923076923078, "train_stats/max_log_achievement_collect_wood": 1.0769230769230769, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_place_plant": 0.23076923076923078, "train_stats/max_log_achievement_place_table": 0.0, "train_stats/max_log_achievement_wake_up": 2.076923076923077, "train_stats/mean_log_entropy": 0.6796539471699641, "eval_stats/sum_log_reward": 0.3499999810010195, "eval_stats/max_log_achievement_collect_drink": 0.875, "eval_stats/max_log_achievement_collect_sapling": 0.0, "eval_stats/max_log_achievement_collect_wood": 0.125, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_place_plant": 0.0, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 1.875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 2.2811072994954884e-06, "report/cont_loss_std": 2.9699280275963247e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0004934414173476398, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 8.379329301533289e-07, "report/cont_pred": 0.9970709681510925, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 2.4997315406799316, "report/dyn_loss_std": 7.033146381378174, "report/image_loss_mean": 5.119478702545166, "report/image_loss_std": 5.784170627593994, "report/model_loss_mean": 6.687098026275635, "report/model_loss_std": 8.749519348144531, "report/post_ent_mag": 35.191375732421875, "report/post_ent_max": 35.191375732421875, "report/post_ent_mean": 17.713336944580078, "report/post_ent_min": 8.076543807983398, "report/post_ent_std": 4.384049415588379, "report/prior_ent_mag": 66.29115295410156, "report/prior_ent_max": 66.29115295410156, "report/prior_ent_mean": 20.524864196777344, "report/prior_ent_min": 10.034854888916016, "report/prior_ent_std": 8.166366577148438, "report/rep_loss_mean": 2.4997315406799316, "report/rep_loss_std": 7.033146381378174, "report/reward_avg": 0.004894318990409374, "report/reward_loss_mean": 0.06777824461460114, "report/reward_loss_std": 0.1465977132320404, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0034523010253906, "report/reward_neg_acc": 1.0000001192092896, "report/reward_neg_loss": 0.05491592362523079, "report/reward_pos_acc": 0.5, "report/reward_pos_loss": 0.7866396903991699, "report/reward_pred": 0.004949793219566345, "report/reward_rate": 0.017578125, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.033456891775131226, "eval/cont_loss_std": 0.5353351831436157, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 8.357280731201172, "eval/cont_pos_acc": 0.9990195631980896, "eval/cont_pos_loss": 0.0008144430466927588, "eval/cont_pred": 0.9994455575942993, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 21.021242141723633, "eval/dyn_loss_std": 11.972407341003418, "eval/image_loss_mean": 64.2007064819336, "eval/image_loss_std": 72.91146850585938, "eval/model_loss_mean": 77.07135009765625, "eval/model_loss_std": 76.0185317993164, "eval/post_ent_mag": 39.774925231933594, "eval/post_ent_max": 39.774925231933594, "eval/post_ent_mean": 23.806148529052734, "eval/post_ent_min": 8.159574508666992, "eval/post_ent_std": 6.646739482879639, "eval/prior_ent_mag": 66.29115295410156, "eval/prior_ent_max": 66.29115295410156, "eval/prior_ent_mean": 28.803184509277344, "eval/prior_ent_min": 8.727678298950195, "eval/prior_ent_std": 10.092506408691406, "eval/rep_loss_mean": 21.021242141723633, "eval/rep_loss_std": 11.972407341003418, "eval/reward_avg": 0.01630859263241291, "eval/reward_loss_mean": 0.224446639418602, "eval/reward_loss_std": 1.3214466571807861, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0058417320251465, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.09216032177209854, "eval/reward_pos_acc": 0.3333333432674408, "eval/reward_pos_loss": 6.542693614959717, "eval/reward_pred": 0.0047875759191811085, "eval/reward_rate": 0.0205078125, "replay/size": 9585.0, "replay/inserts": 2130.0, "replay/samples": 34080.0, "replay/insert_wait_avg": 2.578054795242811e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.951063729227988e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 4560.0, "eval_replay/inserts": 1680.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.119715826851981e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.301568984985352e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1017.3850572109222, "timer/env.step_count": 267.0, "timer/env.step_total": 27.539528846740723, "timer/env.step_frac": 0.027068933882553853, "timer/env.step_avg": 0.10314430279678173, "timer/env.step_min": 0.02427530288696289, "timer/env.step_max": 1.7372350692749023, "timer/replay._sample_count": 34080.0, "timer/replay._sample_total": 15.77033257484436, "timer/replay._sample_frac": 0.015500849420845078, "timer/replay._sample_avg": 0.00046274450043557396, "timer/replay._sample_min": 0.0003192424774169922, "timer/replay._sample_max": 0.02581191062927246, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 477.0, "timer/agent.policy_total": 7.392245292663574, "timer/agent.policy_frac": 0.00726592674058808, "timer/agent.policy_avg": 0.015497369586296801, "timer/agent.policy_min": 0.009212017059326172, "timer/agent.policy_max": 0.041925907135009766, "timer/dataset_train_count": 2130.0, "timer/dataset_train_total": 0.3812673091888428, "timer/dataset_train_frac": 0.0003747522203973153, "timer/dataset_train_avg": 0.00017899873670837688, "timer/dataset_train_min": 8.58306884765625e-05, "timer/dataset_train_max": 0.0009748935699462891, "timer/agent.train_count": 2130.0, "timer/agent.train_total": 942.6467535495758, "timer/agent.train_frac": 0.9265388231018102, "timer/agent.train_avg": 0.4425571612908807, "timer/agent.train_min": 0.43067479133605957, "timer/agent.train_max": 0.6035187244415283, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4685952663421631, "timer/agent.report_frac": 0.00046058791901935203, "timer/agent.report_avg": 0.23429763317108154, "timer/agent.report_min": 0.22690033912658691, "timer/agent.report_max": 0.24169492721557617, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.5272369384765625e-05, "timer/dataset_eval_frac": 2.4840515599912344e-08, "timer/dataset_eval_avg": 2.5272369384765625e-05, "timer/dataset_eval_min": 2.5272369384765625e-05, "timer/dataset_eval_max": 2.5272369384765625e-05, "fps": 2.093578899703785}
{"step": 10112, "time": 4333.585218429565, "episode/length": 226.0, "episode/score": 3.361338533590242, "episode/reward_rate": 0.9691629955947136, "episode/intrinsic_return": 0.2613384487467556}
{"step": 10256, "time": 4399.593393325806, "episode/length": 75.0, "episode/score": 3.1766812707064673, "episode/reward_rate": 0.9868421052631579, "episode/intrinsic_return": 0.07668113894760609}
{"step": 10272, "time": 4408.350177049637, "episode/length": 75.0, "episode/score": 0.16423091848264448, "episode/reward_rate": 0.9342105263157895, "episode/intrinsic_return": 0.0642309102404397}
{"step": 10448, "time": 4489.087432384491, "episode/length": 183.0, "episode/score": 2.2912640889753675, "episode/reward_rate": 0.9891304347826086, "episode/intrinsic_return": 0.19126402112851792}
{"step": 10504, "time": 4515.8255088329315, "episode/length": 236.0, "episode/score": 4.3433753287063155, "episode/reward_rate": 0.9789029535864979, "episode/intrinsic_return": 0.24337527081297594}
{"step": 10832, "time": 4665.035980939865, "episode/length": 185.0, "episode/score": 2.2681263327613124, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.16812632833170937}
{"step": 10904, "time": 4698.971389055252, "episode/length": 206.0, "episode/score": 2.311974973887118, "episode/reward_rate": 0.9855072463768116, "episode/intrinsic_return": 0.2119749083685747}
{"step": 11272, "time": 4865.780154943466, "episode/length": 144.0, "episode/score": 1.2344837620912585, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.13448366840020753}
{"step": 11384, "time": 4917.841209888458, "episode/length": 297.0, "episode/score": 1.3834513848360075, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.28345134911978676}
{"step": 11504, "time": 4973.4376266002655, "episode/length": 153.0, "episode/score": 2.255651833707816, "episode/reward_rate": 0.9545454545454546, "episode/intrinsic_return": 0.15565177517419215}
{"step": 11640, "time": 5036.177891254425, "episode/length": 172.0, "episode/score": 0.29985713693895377, "episode/reward_rate": 0.953757225433526, "episode/intrinsic_return": 0.19985713917412795}
{"step": 11656, "time": 5044.806045532227, "episode/length": 33.0, "episode/score": -0.8630416308296844, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.036958332755602896}
{"step": 11712, "time": 5071.533760309219, "episode/length": 150.0, "episode/score": 2.2593386949738488, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.15933858696371317}
{"step": 11952, "time": 5180.986290931702, "episode/length": 139.0, "episode/score": 0.24826703516737325, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.14826697011449141}
{"step": 12264, "time": 5323.195935487747, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.584618244696101, "train/action_min": 0.0, "train/action_std": 3.9696108813679545, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.027542501713636272, "train/actor_opt_grad_steps": 9615.0, "train/actor_opt_loss": -5.792460551861366, "train/adv_mag": 0.5846467368099668, "train/adv_max": 0.5451672376569258, "train/adv_mean": 0.0034692658939610562, "train/adv_min": -0.4563883039929451, "train/adv_std": 0.04294469891919182, "train/cont_avg": 0.9946333858944955, "train/cont_loss_mean": 0.00027780943946911237, "train/cont_loss_std": 0.007507549220815273, "train/cont_neg_acc": 0.9882372229471119, "train/cont_neg_loss": 0.04141920236561585, "train/cont_pos_acc": 0.9999819734227766, "train/cont_pos_loss": 6.812155128405917e-05, "train/cont_pred": 0.9946548184123608, "train/cont_rate": 0.9946333858944955, "train/dyn_loss_mean": 2.678272403708292, "train/dyn_loss_std": 7.100675847552238, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1433618683880622, "train/extr_critic_critic_opt_grad_steps": 9615.0, "train/extr_critic_critic_opt_loss": 14683.431147864105, "train/extr_critic_mag": 13.833624345446946, "train/extr_critic_max": 13.833624345446946, "train/extr_critic_mean": 4.218837176441053, "train/extr_critic_min": -0.44100130807369126, "train/extr_critic_std": 3.509206090498408, "train/extr_return_normed_mag": 1.3632660439801871, "train/extr_return_normed_max": 1.3632660439801871, "train/extr_return_normed_mean": 0.3972331150819402, "train/extr_return_normed_min": -0.06955405989439663, "train/extr_return_normed_std": 0.32904681850463974, "train/extr_return_rate": 0.8352148289527368, "train/extr_return_raw_mag": 14.807878813612351, "train/extr_return_raw_max": 14.807878813612351, "train/extr_return_raw_mean": 4.255096642249221, "train/extr_return_raw_min": -0.8166364440950779, "train/extr_return_raw_std": 3.5896427762617757, "train/extr_reward_mag": 1.0038455145074687, "train/extr_reward_max": 1.0038455145074687, "train/extr_reward_mean": 0.025170551523258654, "train/extr_reward_min": -0.581118646018002, "train/extr_reward_std": 0.1525182440671899, "train/image_loss_mean": 3.753847821043172, "train/image_loss_std": 6.17337505204962, "train/model_loss_mean": 5.427864557012506, "train/model_loss_std": 9.282050113065527, "train/model_opt_grad_norm": 62.53904286837248, "train/model_opt_grad_steps": 9601.848623853211, "train/model_opt_loss": 2369.437084512973, "train/model_opt_model_opt_grad_overflow": 0.0045871559633027525, "train/model_opt_model_opt_grad_scale": 432.91284403669727, "train/policy_entropy_mag": 2.472745243562471, "train/policy_entropy_max": 2.472745243562471, "train/policy_entropy_mean": 0.502792052992987, "train/policy_entropy_min": 0.07937576666200927, "train/policy_entropy_std": 0.5087242758055346, "train/policy_logprob_mag": 7.438376529501118, "train/policy_logprob_max": -0.009455861361406812, "train/policy_logprob_mean": -0.5032699864118471, "train/policy_logprob_min": -7.438376529501118, "train/policy_logprob_std": 1.0929867923259735, "train/policy_randomness_mag": 0.8727705555224637, "train/policy_randomness_max": 0.8727705555224637, "train/policy_randomness_mean": 0.1774635291701063, "train/policy_randomness_min": 0.02801616230142226, "train/policy_randomness_std": 0.17955734539742862, "train/post_ent_mag": 31.01258530748, "train/post_ent_max": 31.01258530748, "train/post_ent_mean": 17.772329496681145, "train/post_ent_min": 8.807232360227392, "train/post_ent_std": 3.8927596435634366, "train/prior_ent_mag": 67.40282541677493, "train/prior_ent_max": 67.40282541677493, "train/prior_ent_mean": 20.60409935242539, "train/prior_ent_min": 10.10749847517101, "train/prior_ent_std": 8.29947408404919, "train/rep_loss_mean": 2.678272403708292, "train/rep_loss_std": 7.100675847552238, "train/reward_avg": 0.010716648194020392, "train/reward_loss_mean": 0.06677547748277493, "train/reward_loss_std": 0.15689741994399542, "train/reward_max_data": 1.0012500286102295, "train/reward_max_pred": 1.0028157868516554, "train/reward_neg_acc": 0.9996474390729851, "train/reward_neg_loss": 0.05255304907508399, "train/reward_pos_acc": 0.8557212325411105, "train/reward_pos_loss": 0.7392884952212693, "train/reward_pred": 0.010592017157767994, "train/reward_rate": 0.020655640768348624, "train_stats/sum_log_reward": 1.5999999631728445, "train_stats/max_log_achievement_collect_drink": 0.7857142857142857, "train_stats/max_log_achievement_collect_sapling": 0.6428571428571429, "train_stats/max_log_achievement_collect_wood": 0.6428571428571429, "train_stats/max_log_achievement_eat_cow": 0.07142857142857142, "train_stats/max_log_achievement_place_plant": 0.5714285714285714, "train_stats/max_log_achievement_place_table": 0.0, "train_stats/max_log_achievement_wake_up": 1.8571428571428572, "train_stats/mean_log_entropy": 0.6472225572381701, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 4.3812997319037095e-06, "report/cont_loss_std": 5.690920079359785e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0003022410674020648, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.625740535222576e-06, "report/cont_pred": 0.9941398501396179, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 2.3483381271362305, "report/dyn_loss_std": 6.6037702560424805, "report/image_loss_mean": 2.80021333694458, "report/image_loss_std": 6.178022861480713, "report/model_loss_mean": 4.273775100708008, "report/model_loss_std": 8.7337646484375, "report/post_ent_mag": 29.23073959350586, "report/post_ent_max": 29.23073959350586, "report/post_ent_mean": 17.580923080444336, "report/post_ent_min": 8.918872833251953, "report/post_ent_std": 3.8056983947753906, "report/prior_ent_mag": 68.33311462402344, "report/prior_ent_max": 68.33311462402344, "report/prior_ent_mean": 20.560150146484375, "report/prior_ent_min": 10.628376007080078, "report/prior_ent_std": 8.418111801147461, "report/rep_loss_mean": 2.3483381271362305, "report/rep_loss_std": 6.6037702560424805, "report/reward_avg": 0.011356617324054241, "report/reward_loss_mean": 0.06455450505018234, "report/reward_loss_std": 0.1170055940747261, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.001188039779663, "report/reward_neg_acc": 0.9990009665489197, "report/reward_neg_loss": 0.050555188208818436, "report/reward_pos_acc": 0.95652174949646, "report/reward_pos_loss": 0.6738294959068298, "report/reward_pred": 0.011603807099163532, "report/reward_rate": 0.0224609375, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.011381838470697403, "eval/cont_loss_std": 0.3565870225429535, "eval/cont_neg_acc": 0.6666666865348816, "eval/cont_neg_loss": 3.884777545928955, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 6.581958587048575e-07, "eval/cont_pred": 0.9982548952102661, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 21.698383331298828, "eval/dyn_loss_std": 12.958769798278809, "eval/image_loss_mean": 72.82752990722656, "eval/image_loss_std": 85.00277709960938, "eval/model_loss_mean": 86.08137512207031, "eval/model_loss_std": 89.23070526123047, "eval/post_ent_mag": 35.328041076660156, "eval/post_ent_max": 35.328041076660156, "eval/post_ent_mean": 23.264331817626953, "eval/post_ent_min": 9.466073989868164, "eval/post_ent_std": 6.13068962097168, "eval/prior_ent_mag": 68.33311462402344, "eval/prior_ent_max": 68.33311462402344, "eval/prior_ent_mean": 28.092012405395508, "eval/prior_ent_min": 9.11935806274414, "eval/prior_ent_std": 10.106574058532715, "eval/rep_loss_mean": 21.698383331298828, "eval/rep_loss_std": 12.958769798278809, "eval/reward_avg": 0.01201171800494194, "eval/reward_loss_mean": 0.2234276384115219, "eval/reward_loss_std": 1.3720247745513916, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0011823177337646, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.1267409771680832, "eval/reward_pos_acc": 0.375, "eval/reward_pos_loss": 6.314687728881836, "eval/reward_pred": 0.004371186718344688, "eval/reward_rate": 0.015625, "replay/size": 11760.0, "replay/inserts": 2175.0, "replay/samples": 34800.0, "replay/insert_wait_avg": 2.4485314029386672e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.648714657487541e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 4560.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 6.705522537231445e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2070367336273, "timer/env.step_count": 271.0, "timer/env.step_total": 28.366886615753174, "timer/env.step_frac": 0.02836101484387754, "timer/env.step_avg": 0.10467485836071282, "timer/env.step_min": 0.02363300323486328, "timer/env.step_max": 1.6187317371368408, "timer/replay._sample_count": 34800.0, "timer/replay._sample_total": 16.088513135910034, "timer/replay._sample_frac": 0.0160851829121801, "timer/replay._sample_avg": 0.0004623135958594837, "timer/replay._sample_min": 0.0002987384796142578, "timer/replay._sample_max": 0.010681867599487305, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 271.0, "timer/agent.policy_total": 4.141568660736084, "timer/agent.policy_frac": 0.0041407113813767904, "timer/agent.policy_avg": 0.015282541183527985, "timer/agent.policy_min": 0.014319658279418945, "timer/agent.policy_max": 0.03168821334838867, "timer/dataset_train_count": 2175.0, "timer/dataset_train_total": 0.3691744804382324, "timer/dataset_train_frac": 0.0003690980635807605, "timer/dataset_train_avg": 0.00016973539330493445, "timer/dataset_train_min": 8.463859558105469e-05, "timer/dataset_train_max": 0.0014643669128417969, "timer/agent.train_count": 2175.0, "timer/agent.train_total": 957.290765285492, "timer/agent.train_frac": 0.9570926119573334, "timer/agent.train_avg": 0.4401336851887319, "timer/agent.train_min": 0.42985010147094727, "timer/agent.train_max": 0.5822970867156982, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47457408905029297, "timer/agent.report_frac": 0.00047447585511906407, "timer/agent.report_avg": 0.23728704452514648, "timer/agent.report_min": 0.23134994506835938, "timer/agent.report_max": 0.2432241439819336, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.4557113647460938e-05, "timer/dataset_eval_frac": 2.455203047526742e-08, "timer/dataset_eval_avg": 2.4557113647460938e-05, "timer/dataset_eval_min": 2.4557113647460938e-05, "timer/dataset_eval_max": 2.4557113647460938e-05, "fps": 2.1745232415610056}
{"step": 12744, "time": 5539.271058082581, "episode/length": 128.0, "episode/score": 3.2337056947635574, "episode/reward_rate": 0.9922480620155039, "episode/intrinsic_return": 0.1337055472886277}
{"step": 12760, "time": 5548.01384472847, "episode/length": 185.0, "episode/score": 3.298410633018648, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.1984105388619355}
{"step": 12776, "time": 5556.794570207596, "episode/length": 139.0, "episode/score": 4.237428850221477, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.1374287098478817}
{"step": 12840, "time": 5587.037386417389, "episode/length": 166.0, "episode/score": 0.24822750289968099, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.14822749349332298}
{"step": 12928, "time": 5628.159213781357, "episode/length": 252.0, "episode/score": 3.323028051694564, "episode/reward_rate": 0.9802371541501976, "episode/intrinsic_return": 0.22302795753785176}
{"step": 13216, "time": 5759.210118293762, "episode/length": 54.0, "episode/score": 0.16045685634890106, "episode/reward_rate": 0.9272727272727272, "episode/intrinsic_return": 0.06045683204138186}
{"step": 13288, "time": 5792.9615523815155, "episode/length": 354.0, "episode/score": 1.481208015291486, "episode/reward_rate": 0.9943661971830986, "episode/intrinsic_return": 0.3812079795752652}
{"step": 14040, "time": 6132.713310480118, "episode/length": 161.0, "episode/score": 3.2245502506348203, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.12455018401033158}
{"step": 14112, "time": 6166.878041028976, "episode/length": 269.0, "episode/score": 2.373033759329701, "episode/reward_rate": 0.9851851851851852, "episode/intrinsic_return": 0.27303377373027615}
{"step": 14200, "time": 6207.903885602951, "episode/length": 179.0, "episode/score": 4.288714216749213, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.18871411572399666}
{"step": 14408, "time": 6303.092910766602, "episode/length": 184.0, "episode/score": 3.283823157829829, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.18382308413310966}
{"step": 14416, "time": 6308.151247262955, "episode/length": 196.0, "episode/score": 2.2500978320322247, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.1500978385165581}
{"step": 14445, "time": 6323.272567987442, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.653408785478784, "train/action_min": 0.0, "train/action_std": 4.0169940410404035, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.02711427392045019, "train/actor_opt_grad_steps": 11795.0, "train/actor_opt_loss": -0.13809733762653595, "train/adv_mag": 0.6589250226223141, "train/adv_max": 0.6007108356837833, "train/adv_mean": 0.004296294923658416, "train/adv_min": -0.4865513940880058, "train/adv_std": 0.04186529875519352, "train/cont_avg": 0.994422842603211, "train/cont_loss_mean": 0.0001451630069088503, "train/cont_loss_std": 0.00413450983736768, "train/cont_neg_acc": 0.9948339891543082, "train/cont_neg_loss": 0.013403725314451173, "train/cont_pos_acc": 0.999981931590159, "train/cont_pos_loss": 6.171683574963682e-05, "train/cont_pred": 0.9944144342470607, "train/cont_rate": 0.994422842603211, "train/dyn_loss_mean": 2.684799187773958, "train/dyn_loss_std": 7.238015452656177, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.2404424189974408, "train/extr_critic_critic_opt_grad_steps": 11795.0, "train/extr_critic_critic_opt_loss": 15121.555780533257, "train/extr_critic_mag": 16.945524981262487, "train/extr_critic_max": 16.945524981262487, "train/extr_critic_mean": 4.081008871760937, "train/extr_critic_min": -0.5046580794754378, "train/extr_critic_std": 3.9223043940482882, "train/extr_return_normed_mag": 1.3847464793319002, "train/extr_return_normed_max": 1.3847464793319002, "train/extr_return_normed_mean": 0.3345815342500669, "train/extr_return_normed_min": -0.052250304250815595, "train/extr_return_normed_std": 0.3128316803672992, "train/extr_return_rate": 0.8246703421303986, "train/extr_return_raw_mag": 17.656225550065347, "train/extr_return_raw_max": 17.656225550065347, "train/extr_return_raw_mean": 4.137614280805675, "train/extr_return_raw_min": -0.8329558872848476, "train/extr_return_raw_std": 4.022890214526325, "train/extr_reward_mag": 1.004491031716723, "train/extr_reward_max": 1.004491031716723, "train/extr_reward_mean": 0.022691785840642287, "train/extr_reward_min": -0.5946946663594027, "train/extr_reward_std": 0.14617641543576476, "train/image_loss_mean": 3.5394295284507473, "train/image_loss_std": 6.290547762442072, "train/model_loss_mean": 5.217237986555887, "train/model_loss_std": 9.471683812797616, "train/model_opt_grad_norm": 59.35230902482837, "train/model_opt_grad_steps": 11780.784403669724, "train/model_opt_loss": 3020.66573676713, "train/model_opt_model_opt_grad_overflow": 0.0045871559633027525, "train/model_opt_model_opt_grad_scale": 583.4288990825688, "train/policy_entropy_mag": 2.475583131160211, "train/policy_entropy_max": 2.475583131160211, "train/policy_entropy_mean": 0.6019639301737514, "train/policy_entropy_min": 0.07937533121316805, "train/policy_entropy_std": 0.5911373642333057, "train/policy_logprob_mag": 7.4383811250739145, "train/policy_logprob_max": -0.009455808938198954, "train/policy_logprob_mean": -0.6022470246214385, "train/policy_logprob_min": -7.4383811250739145, "train/policy_logprob_std": 1.148333558795649, "train/policy_randomness_mag": 0.8737722080235087, "train/policy_randomness_max": 0.8737722080235087, "train/policy_randomness_mean": 0.21246685101351606, "train/policy_randomness_min": 0.028016008641741693, "train/policy_randomness_std": 0.20864554870566096, "train/post_ent_mag": 31.49351413971787, "train/post_ent_max": 31.49351413971787, "train/post_ent_mean": 18.021555008144553, "train/post_ent_min": 9.308273317617013, "train/post_ent_std": 3.816679544405106, "train/prior_ent_mag": 68.38989229814722, "train/prior_ent_max": 68.38989229814722, "train/prior_ent_mean": 20.926555773533813, "train/prior_ent_min": 10.721019587385545, "train/prior_ent_std": 8.363760313856492, "train/rep_loss_mean": 2.684799187773958, "train/rep_loss_std": 7.238015452656177, "train/reward_avg": 0.01074627876802937, "train/reward_loss_mean": 0.06678377373844659, "train/reward_loss_std": 0.1537124597288053, "train/reward_max_data": 1.0012500286102295, "train/reward_max_pred": 1.003053263786736, "train/reward_neg_acc": 0.9995968038335853, "train/reward_neg_loss": 0.0524076184924316, "train/reward_pos_acc": 0.8708881320209678, "train/reward_pos_loss": 0.7342721417956396, "train/reward_pred": 0.010629902451743431, "train/reward_rate": 0.02104089019495413, "train_stats/sum_log_reward": 2.4333332615594068, "train_stats/max_log_achievement_collect_drink": 5.5, "train_stats/max_log_achievement_collect_sapling": 0.8333333333333334, "train_stats/max_log_achievement_collect_wood": 1.0, "train_stats/max_log_achievement_eat_cow": 0.08333333333333333, "train_stats/max_log_achievement_place_plant": 0.8333333333333334, "train_stats/max_log_achievement_place_table": 0.16666666666666666, "train_stats/max_log_achievement_wake_up": 2.0833333333333335, "train_stats/mean_log_entropy": 0.6740359837810198, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 4.997279575036373e-06, "report/cont_loss_std": 8.864180017553736e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 6.950261740712449e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 4.680766323872376e-06, "report/cont_pred": 0.9951128363609314, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 2.3546547889709473, "report/dyn_loss_std": 7.260964393615723, "report/image_loss_mean": 3.159931182861328, "report/image_loss_std": 4.9883832931518555, "report/model_loss_mean": 4.642061233520508, "report/model_loss_std": 8.256474494934082, "report/post_ent_mag": 29.919553756713867, "report/post_ent_max": 29.919553756713867, "report/post_ent_mean": 17.266935348510742, "report/post_ent_min": 10.27238941192627, "report/post_ent_std": 3.4853625297546387, "report/prior_ent_mag": 69.01544952392578, "report/prior_ent_max": 69.01544952392578, "report/prior_ent_mean": 19.944255828857422, "report/prior_ent_min": 10.986066818237305, "report/prior_ent_std": 8.186038970947266, "report/rep_loss_mean": 2.3546547889709473, "report/rep_loss_std": 7.260964393615723, "report/reward_avg": 0.01743646338582039, "report/reward_loss_mean": 0.06933201849460602, "report/reward_loss_std": 0.126853346824646, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.002265214920044, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.050673142075538635, "report/reward_pos_acc": 0.9677419066429138, "report/reward_pos_loss": 0.6670179963111877, "report/reward_pred": 0.017378129065036774, "report/reward_rate": 0.0302734375, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.012599058449268341, "eval/cont_loss_std": 0.3237619698047638, "eval/cont_neg_acc": 0.6000000238418579, "eval/cont_neg_loss": 2.5793004035949707, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 4.842410362471128e-06, "eval/cont_pred": 0.9971179962158203, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 23.840877532958984, "eval/dyn_loss_std": 14.244609832763672, "eval/image_loss_mean": 70.55274963378906, "eval/image_loss_std": 65.60905456542969, "eval/model_loss_mean": 85.05613708496094, "eval/model_loss_std": 71.4945068359375, "eval/post_ent_mag": 37.9835319519043, "eval/post_ent_max": 37.9835319519043, "eval/post_ent_mean": 24.80318832397461, "eval/post_ent_min": 11.138477325439453, "eval/post_ent_std": 5.89925479888916, "eval/prior_ent_mag": 69.01544952392578, "eval/prior_ent_max": 69.01544952392578, "eval/prior_ent_mean": 29.843334197998047, "eval/prior_ent_min": 11.152931213378906, "eval/prior_ent_std": 10.430485725402832, "eval/rep_loss_mean": 23.840877532958984, "eval/rep_loss_std": 14.244609832763672, "eval/reward_avg": 0.01806640625, "eval/reward_loss_mean": 0.18625542521476746, "eval/reward_loss_std": 1.218010425567627, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0017690658569336, "eval/reward_neg_acc": 0.9990019798278809, "eval/reward_neg_loss": 0.05416131392121315, "eval/reward_pos_acc": 0.40909093618392944, "eval/reward_pos_loss": 6.202541828155518, "eval/reward_pred": 0.005068838596343994, "eval/reward_rate": 0.021484375, "replay/size": 13941.0, "replay/inserts": 2181.0, "replay/samples": 34896.0, "replay/insert_wait_avg": 2.4443096876253726e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.788299257085171e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 4560.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 1.1175870895385742e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.065299987793, "timer/env.step_count": 273.0, "timer/env.step_total": 25.276186227798462, "timer/env.step_frac": 0.02527453580091919, "timer/env.step_avg": 0.0925867627391885, "timer/env.step_min": 0.023282289505004883, "timer/env.step_max": 1.747431755065918, "timer/replay._sample_count": 34896.0, "timer/replay._sample_total": 16.40709161758423, "timer/replay._sample_frac": 0.016406020304658604, "timer/replay._sample_avg": 0.0004701711261343486, "timer/replay._sample_min": 0.0002932548522949219, "timer/replay._sample_max": 0.03220105171203613, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 273.0, "timer/agent.policy_total": 4.183518171310425, "timer/agent.policy_frac": 0.004183245005462633, "timer/agent.policy_avg": 0.015324242385752472, "timer/agent.policy_min": 0.014288187026977539, "timer/agent.policy_max": 0.03951001167297363, "timer/dataset_train_count": 2181.0, "timer/dataset_train_total": 0.3679945468902588, "timer/dataset_train_frac": 0.0003679705184198978, "timer/dataset_train_avg": 0.00016872744011474497, "timer/dataset_train_min": 8.511543273925781e-05, "timer/dataset_train_max": 0.0006685256958007812, "timer/agent.train_count": 2181.0, "timer/agent.train_total": 960.1578741073608, "timer/agent.train_frac": 0.9600951799038331, "timer/agent.train_avg": 0.44023744800887704, "timer/agent.train_min": 0.4309999942779541, "timer/agent.train_max": 0.5485939979553223, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4702422618865967, "timer/agent.report_frac": 0.0004702115570776594, "timer/agent.report_avg": 0.23512113094329834, "timer/agent.report_min": 0.2281324863433838, "timer/agent.report_max": 0.2421097755432129, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9325485229492188e-05, "timer/dataset_eval_frac": 2.9323570400702975e-08, "timer/dataset_eval_avg": 2.9325485229492188e-05, "timer/dataset_eval_min": 2.9325485229492188e-05, "timer/dataset_eval_max": 2.9325485229492188e-05, "fps": 2.1808302273408553}
{"step": 14520, "time": 6357.485156297684, "episode/length": 162.0, "episode/score": 3.2766310439328663, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.176630949776154}
{"step": 14712, "time": 6446.286353111267, "episode/length": 177.0, "episode/score": 3.301062587124761, "episode/reward_rate": 0.9662921348314607, "episode/intrinsic_return": 0.20106249646050856}
{"step": 14752, "time": 6465.945948839188, "episode/length": 88.0, "episode/score": 0.18193236237129895, "episode/reward_rate": 0.9438202247191011, "episode/intrinsic_return": 0.08193240089894971}
{"step": 14872, "time": 6521.790654182434, "episode/length": 43.0, "episode/score": 0.13783545800833963, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.037835407274542376}
{"step": 15088, "time": 6621.078754901886, "episode/length": 430.0, "episode/score": 5.4828520009596105, "episode/reward_rate": 0.7099767981438515, "episode/intrinsic_return": 0.38285185243694286}
{"step": 15264, "time": 6702.240919589996, "episode/length": 143.0, "episode/score": 1.2145902831944113, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.11459016168009839}
{"step": 15944, "time": 7011.916669845581, "episode/length": 190.0, "episode/score": 1.2657708406841266, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.16577071684150724}
{"step": 16024, "time": 7049.532430648804, "episode/length": 158.0, "episode/score": 4.256681189639494, "episode/reward_rate": 0.9559748427672956, "episode/intrinsic_return": 0.1566810761578381}
{"step": 16064, "time": 7069.152822971344, "episode/length": 232.0, "episode/score": -0.6262090225427528, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.27379100413963897}
{"step": 16136, "time": 7102.998463630676, "episode/length": 157.0, "episode/score": 0.2594239466543513, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.15942388160146947}
{"step": 16240, "time": 7151.087436676025, "episode/length": 228.0, "episode/score": 1.3076473714518215, "episode/reward_rate": 0.982532751091703, "episode/intrinsic_return": 0.20764733340729435}
{"step": 16352, "time": 7202.812557220459, "episode/length": 135.0, "episode/score": 3.255016660452384, "episode/reward_rate": 0.9632352941176471, "episode/intrinsic_return": 0.15501655372281675}
{"step": 16512, "time": 7277.040820837021, "episode/length": 177.0, "episode/score": 2.2588446025129088, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.15884450567864405}
{"step": 16611, "time": 7323.459639072418, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.133702431955645, "train/action_min": 0.0, "train/action_std": 3.819699324770457, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.026138169493543386, "train/actor_opt_grad_steps": 13970.0, "train/actor_opt_loss": -10.315621895998854, "train/adv_mag": 0.6334692627740895, "train/adv_max": 0.5634363612958363, "train/adv_mean": 0.0013333529633548541, "train/adv_min": -0.5083464615493326, "train/adv_std": 0.04270035194121473, "train/cont_avg": 0.9946131552419355, "train/cont_loss_mean": 0.00018104329271217097, "train/cont_loss_std": 0.005485435276886367, "train/cont_neg_acc": 0.996162184410625, "train/cont_neg_loss": 0.01814408171159172, "train/cont_pos_acc": 0.9999818744197968, "train/cont_pos_loss": 6.815496947884793e-05, "train/cont_pred": 0.994612755863348, "train/cont_rate": 0.9946131552419355, "train/dyn_loss_mean": 2.6501783632463023, "train/dyn_loss_std": 7.356405431773806, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.3068483304318195, "train/extr_critic_critic_opt_grad_steps": 13970.0, "train/extr_critic_critic_opt_loss": 15342.258532546082, "train/extr_critic_mag": 17.55359735357047, "train/extr_critic_max": 17.55359735357047, "train/extr_critic_mean": 4.253875501144866, "train/extr_critic_min": -0.5288996625056465, "train/extr_critic_std": 4.181893351989957, "train/extr_return_normed_mag": 1.3057511641133217, "train/extr_return_normed_max": 1.3057511641133217, "train/extr_return_normed_mean": 0.32049918813364847, "train/extr_return_normed_min": -0.04840472695087233, "train/extr_return_normed_std": 0.305916742863743, "train/extr_return_rate": 0.8301711725199827, "train/extr_return_raw_mag": 17.909863023713985, "train/extr_return_raw_max": 17.909863023713985, "train/extr_return_raw_mean": 4.272408394220238, "train/extr_return_raw_min": -0.8379182579330585, "train/extr_return_raw_std": 4.23593029228773, "train/extr_reward_mag": 1.0042075841657576, "train/extr_reward_max": 1.0042075841657576, "train/extr_reward_mean": 0.021119499991085672, "train/extr_reward_min": -0.6170034738180274, "train/extr_reward_std": 0.14252696244672697, "train/image_loss_mean": 3.3861307707799746, "train/image_loss_std": 6.662469628769132, "train/model_loss_mean": 5.042665584845477, "train/model_loss_std": 9.90607107619536, "train/model_opt_grad_norm": 54.692545157891736, "train/model_opt_grad_steps": 13954.612903225807, "train/model_opt_loss": 4354.403028356315, "train/model_opt_model_opt_grad_overflow": 0.004608294930875576, "train/model_opt_model_opt_grad_scale": 852.5345622119816, "train/policy_entropy_mag": 2.5019128509380852, "train/policy_entropy_max": 2.5019128509380852, "train/policy_entropy_mean": 0.5413712988251366, "train/policy_entropy_min": 0.07937523763849988, "train/policy_entropy_std": 0.5900618791030848, "train/policy_logprob_mag": 7.43838199931905, "train/policy_logprob_max": -0.00945576439581571, "train/policy_logprob_mean": -0.5416757012567213, "train/policy_logprob_min": -7.43838199931905, "train/policy_logprob_std": 1.1256460962207635, "train/policy_randomness_mag": 0.8830654423357704, "train/policy_randomness_max": 0.8830654423357704, "train/policy_randomness_mean": 0.1910803114420258, "train/policy_randomness_min": 0.028015975621507466, "train/policy_randomness_std": 0.208265950396863, "train/post_ent_mag": 31.43164071289625, "train/post_ent_max": 31.43164071289625, "train/post_ent_mean": 18.113232045679048, "train/post_ent_min": 9.926337813452092, "train/post_ent_std": 3.6042247455790295, "train/prior_ent_mag": 69.37732214861751, "train/prior_ent_max": 69.37732214861751, "train/prior_ent_mean": 20.891488193916285, "train/prior_ent_min": 11.125083193800966, "train/prior_ent_std": 8.361430772438577, "train/rep_loss_mean": 2.6501783632463023, "train/rep_loss_std": 7.356405431773806, "train/reward_avg": 0.011325930021510111, "train/reward_loss_mean": 0.06624670548167097, "train/reward_loss_std": 0.15172317888467543, "train/reward_max_data": 1.0012500286102295, "train/reward_max_pred": 1.002641110376279, "train/reward_neg_acc": 0.9995676377951275, "train/reward_neg_loss": 0.051537819017875026, "train/reward_pos_acc": 0.86520388900959, "train/reward_pos_loss": 0.7403045546623969, "train/reward_pred": 0.011227590807666358, "train/reward_rate": 0.021380868375576036, "train_stats/sum_log_reward": 1.792307654252419, "train_stats/max_log_achievement_collect_drink": 4.3076923076923075, "train_stats/max_log_achievement_collect_sapling": 0.6923076923076923, "train_stats/max_log_achievement_collect_wood": 0.9230769230769231, "train_stats/max_log_achievement_eat_cow": 0.07692307692307693, "train_stats/max_log_achievement_place_plant": 0.6153846153846154, "train_stats/max_log_achievement_place_table": 0.0, "train_stats/max_log_achievement_wake_up": 1.8461538461538463, "train_stats/mean_log_entropy": 0.6015737125506768, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 4.690655828198942e-07, "report/cont_loss_std": 4.767012796946801e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 5.3778734582010657e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 3.1242601039593865e-07, "report/cont_pred": 0.9970701932907104, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 2.3340468406677246, "report/dyn_loss_std": 7.044177532196045, "report/image_loss_mean": 2.2617135047912598, "report/image_loss_std": 3.6655080318450928, "report/model_loss_mean": 3.7177767753601074, "report/model_loss_std": 7.245816707611084, "report/post_ent_mag": 33.25651931762695, "report/post_ent_max": 33.25651931762695, "report/post_ent_mean": 18.587169647216797, "report/post_ent_min": 9.973623275756836, "report/post_ent_std": 3.7120327949523926, "report/prior_ent_mag": 70.03353118896484, "report/prior_ent_max": 70.03353118896484, "report/prior_ent_mean": 21.132678985595703, "report/prior_ent_min": 10.846402168273926, "report/prior_ent_std": 8.135823249816895, "report/rep_loss_mean": 2.3340468406677246, "report/rep_loss_std": 7.044177532196045, "report/reward_avg": 0.010238083079457283, "report/reward_loss_mean": 0.055634692311286926, "report/reward_loss_std": 0.10392772406339645, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0017805099487305, "report/reward_neg_acc": 0.9990069270133972, "report/reward_neg_loss": 0.045288942754268646, "report/reward_pos_acc": 0.7058823704719543, "report/reward_pos_loss": 0.6684680581092834, "report/reward_pred": 0.010447869077324867, "report/reward_rate": 0.0166015625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.005935562774538994, "eval/cont_loss_std": 0.14019805192947388, "eval/cont_neg_acc": 0.5, "eval/cont_neg_loss": 1.5192351341247559, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 1.0564140211499762e-06, "eval/cont_pred": 0.9981088042259216, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 24.59197235107422, "eval/dyn_loss_std": 13.43844985961914, "eval/image_loss_mean": 63.6754150390625, "eval/image_loss_std": 62.93036651611328, "eval/model_loss_mean": 78.62359619140625, "eval/model_loss_std": 67.01045989990234, "eval/post_ent_mag": 39.051090240478516, "eval/post_ent_max": 39.051090240478516, "eval/post_ent_mean": 24.95012664794922, "eval/post_ent_min": 10.620773315429688, "eval/post_ent_std": 5.691082000732422, "eval/prior_ent_mag": 70.03353118896484, "eval/prior_ent_max": 70.03353118896484, "eval/prior_ent_mean": 30.35663604736328, "eval/prior_ent_min": 11.14676284790039, "eval/prior_ent_std": 9.982902526855469, "eval/rep_loss_mean": 24.59197235107422, "eval/rep_loss_std": 13.43844985961914, "eval/reward_avg": 0.01767578162252903, "eval/reward_loss_mean": 0.1870667189359665, "eval/reward_loss_std": 1.2864817380905151, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0018084049224854, "eval/reward_neg_acc": 0.9970059990882874, "eval/reward_neg_loss": 0.06945706903934479, "eval/reward_pos_acc": 0.4545454680919647, "eval/reward_pos_loss": 5.543652057647705, "eval/reward_pred": 0.010404596105217934, "eval/reward_rate": 0.021484375, "replay/size": 16107.0, "replay/inserts": 2166.0, "replay/samples": 34656.0, "replay/insert_wait_avg": 2.4882049771887443e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.01415544687766e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 4560.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 7.897615432739258e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1728048324585, "timer/env.step_count": 271.0, "timer/env.step_total": 26.981277465820312, "timer/env.step_frac": 0.0269766157762508, "timer/env.step_avg": 0.09956190946797164, "timer/env.step_min": 0.02315378189086914, "timer/env.step_max": 1.6723732948303223, "timer/replay._sample_count": 34656.0, "timer/replay._sample_total": 16.77523970603943, "timer/replay._sample_frac": 0.016772341364400017, "timer/replay._sample_avg": 0.00048405008385386165, "timer/replay._sample_min": 0.0003173351287841797, "timer/replay._sample_max": 0.022722959518432617, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 271.0, "timer/agent.policy_total": 4.2641096115112305, "timer/agent.policy_frac": 0.004263372880074981, "timer/agent.policy_avg": 0.015734721813694577, "timer/agent.policy_min": 0.014385461807250977, "timer/agent.policy_max": 0.04692983627319336, "timer/dataset_train_count": 2166.0, "timer/dataset_train_total": 0.3855924606323242, "timer/dataset_train_frac": 0.00038552583990415117, "timer/dataset_train_avg": 0.00017802052660772125, "timer/dataset_train_min": 9.107589721679688e-05, "timer/dataset_train_max": 0.0011584758758544922, "timer/agent.train_count": 2166.0, "timer/agent.train_total": 958.2364454269409, "timer/agent.train_frac": 0.9580708861479768, "timer/agent.train_avg": 0.44239909761169943, "timer/agent.train_min": 0.4316403865814209, "timer/agent.train_max": 0.5676784515380859, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4741098880767822, "timer/agent.report_frac": 0.00047402797375219733, "timer/agent.report_avg": 0.2370549440383911, "timer/agent.report_min": 0.22963714599609375, "timer/agent.report_max": 0.24447274208068848, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8848648071289062e-05, "timer/dataset_eval_frac": 2.8843663746807805e-08, "timer/dataset_eval_avg": 2.8848648071289062e-05, "timer/dataset_eval_min": 2.8848648071289062e-05, "timer/dataset_eval_max": 2.8848648071289062e-05, "fps": 2.165598077296807}
{"step": 16624, "time": 7329.515398979187, "episode/length": 238.0, "episode/score": 2.3723268734756857, "episode/reward_rate": 0.9707112970711297, "episode/intrinsic_return": 0.27232681727036834}
{"step": 16920, "time": 7465.365562915802, "episode/length": 84.0, "episode/score": 1.1907435154207633, "episode/reward_rate": 0.9411764705882353, "episode/intrinsic_return": 0.09074347854038933}
{"step": 17176, "time": 7582.824253797531, "episode/length": 138.0, "episode/score": 3.2385578613138932, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.13855781482925522}
{"step": 17368, "time": 7671.577333688736, "episode/length": 177.0, "episode/score": 2.2830152344467933, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.18301511211757315}
{"step": 17464, "time": 7716.6836812496185, "episode/length": 165.0, "episode/score": 2.255712562993722, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.15571255515897064}
{"step": 17488, "time": 7729.10079574585, "episode/length": 141.0, "episode/score": 1.2243308863253333, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.1243307949625887}
{"step": 17576, "time": 7770.117132902145, "episode/length": 193.0, "episode/score": 4.30370440448678, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.20370428169189836}
{"step": 17912, "time": 7923.6109075546265, "episode/length": 174.0, "episode/score": 2.2888557643673266, "episode/reward_rate": 0.9657142857142857, "episode/intrinsic_return": 0.18885570234124316}
{"step": 18296, "time": 8099.2776708602905, "episode/length": 139.0, "episode/score": 1.2079455147322733, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.1079454749415163}
{"step": 18416, "time": 8155.102043628693, "episode/length": 223.0, "episode/score": 1.3452325224898232, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.245232484445296}
{"step": 18592, "time": 8236.537879228592, "episode/length": 152.0, "episode/score": 2.264545019977959, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.16454501447151415}
{"step": 18780, "time": 8323.674090147018, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.448713873937932, "train/action_min": 0.0, "train/action_std": 3.6898811819366597, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.02811526755205772, "train/actor_opt_grad_steps": 16140.0, "train/actor_opt_loss": -6.822060491958384, "train/adv_mag": 0.6521973004264217, "train/adv_max": 0.6089845823664819, "train/adv_mean": 0.0031478397645703237, "train/adv_min": -0.454118831297769, "train/adv_std": 0.04303779046175667, "train/cont_avg": 0.9943971414170507, "train/cont_loss_mean": 6.745327991490765e-05, "train/cont_loss_std": 0.0019494580362711563, "train/cont_neg_acc": 0.9971527325392868, "train/cont_neg_loss": 0.008693816152129556, "train/cont_pos_acc": 0.9999954618067236, "train/cont_pos_loss": 2.1205458922175297e-05, "train/cont_pred": 0.9944009896247618, "train/cont_rate": 0.9943971414170507, "train/dyn_loss_mean": 2.757445891331967, "train/dyn_loss_std": 7.470607500471827, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.2518484100768095, "train/extr_critic_critic_opt_grad_steps": 16140.0, "train/extr_critic_critic_opt_loss": 15107.09249891993, "train/extr_critic_mag": 17.256853222297632, "train/extr_critic_max": 17.256853222297632, "train/extr_critic_mean": 4.173286249011343, "train/extr_critic_min": -0.48419626956711165, "train/extr_critic_std": 4.073451973875547, "train/extr_return_normed_mag": 1.389076206815957, "train/extr_return_normed_max": 1.389076206815957, "train/extr_return_normed_mean": 0.3333650929724566, "train/extr_return_normed_min": -0.05645381397468978, "train/extr_return_normed_std": 0.31960661592571415, "train/extr_return_rate": 0.8171437379951301, "train/extr_return_raw_mag": 17.919581299003916, "train/extr_return_raw_max": 17.919581299003916, "train/extr_return_raw_mean": 4.214172469855454, "train/extr_return_raw_min": -0.842440004584976, "train/extr_return_raw_std": 4.14760064968865, "train/extr_reward_mag": 1.0032001145973732, "train/extr_reward_max": 1.0032001145973732, "train/extr_reward_mean": 0.024001769047693997, "train/extr_reward_min": -0.6218476130665722, "train/extr_reward_std": 0.14983131564844587, "train/image_loss_mean": 3.20707433454452, "train/image_loss_std": 6.510685090095766, "train/model_loss_mean": 4.927865460171677, "train/model_loss_std": 9.811760695848596, "train/model_opt_grad_norm": 53.02521043768676, "train/model_opt_grad_steps": 16123.350230414746, "train/model_opt_loss": 4521.56210172451, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 913.0184331797235, "train/policy_entropy_mag": 2.4725704116206013, "train/policy_entropy_max": 2.4725704116206013, "train/policy_entropy_mean": 0.5345604886657082, "train/policy_entropy_min": 0.07937514342470653, "train/policy_entropy_std": 0.5685803055213893, "train/policy_logprob_mag": 7.438382317942958, "train/policy_logprob_max": -0.009455691357808453, "train/policy_logprob_mean": -0.5339493071703317, "train/policy_logprob_min": -7.438382317942958, "train/policy_logprob_std": 1.1140461102608712, "train/policy_randomness_mag": 0.8727088496432326, "train/policy_randomness_max": 0.8727088496432326, "train/policy_randomness_mean": 0.18867639421317983, "train/policy_randomness_min": 0.028015942385737798, "train/policy_randomness_std": 0.20068389836544265, "train/post_ent_mag": 31.55870487722933, "train/post_ent_max": 31.55870487722933, "train/post_ent_mean": 18.225106076710784, "train/post_ent_min": 10.525166283005394, "train/post_ent_std": 3.505957875932966, "train/prior_ent_mag": 69.99165850520683, "train/prior_ent_max": 69.99165850520683, "train/prior_ent_mean": 21.101499188330866, "train/prior_ent_min": 11.68431898196172, "train/prior_ent_std": 8.435992126640636, "train/rep_loss_mean": 2.757445891331967, "train/rep_loss_std": 7.470607500471827, "train/reward_avg": 0.010990505720207613, "train/reward_loss_mean": 0.06625614334155337, "train/reward_loss_std": 0.15140074553302907, "train/reward_max_data": 1.0012500286102295, "train/reward_max_pred": 1.0022931241769395, "train/reward_neg_acc": 0.9994991567277689, "train/reward_neg_loss": 0.05173701214419532, "train/reward_pos_acc": 0.8704838777467403, "train/reward_pos_loss": 0.7416142777363826, "train/reward_pred": 0.010857879355858822, "train/reward_rate": 0.021079349078341015, "train_stats/sum_log_reward": 2.0090908353978936, "train_stats/max_log_achievement_collect_drink": 3.1818181818181817, "train_stats/max_log_achievement_collect_sapling": 0.5454545454545454, "train_stats/max_log_achievement_collect_wood": 1.3636363636363635, "train_stats/max_log_achievement_defeat_skeleton": 0.09090909090909091, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_place_plant": 0.5454545454545454, "train_stats/max_log_achievement_place_table": 0.0, "train_stats/max_log_achievement_wake_up": 2.1818181818181817, "train_stats/mean_log_entropy": 0.5478674633936449, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 1.5309028640331235e-06, "report/cont_loss_std": 1.6416144717368297e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0001546347775729373, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 3.2536055982745893e-07, "report/cont_pred": 0.9921884536743164, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 2.5700929164886475, "report/dyn_loss_std": 7.137864112854004, "report/image_loss_mean": 2.6733155250549316, "report/image_loss_std": 8.877214431762695, "report/model_loss_mean": 4.289194107055664, "report/model_loss_std": 11.329543113708496, "report/post_ent_mag": 32.327301025390625, "report/post_ent_max": 32.327301025390625, "report/post_ent_mean": 17.941150665283203, "report/post_ent_min": 9.853996276855469, "report/post_ent_std": 3.8992183208465576, "report/prior_ent_mag": 70.88512420654297, "report/prior_ent_max": 70.88512420654297, "report/prior_ent_mean": 20.859346389770508, "report/prior_ent_min": 10.975374221801758, "report/prior_ent_std": 9.032967567443848, "report/rep_loss_mean": 2.5700929164886475, "report/rep_loss_std": 7.137864112854004, "report/reward_avg": 0.015031727030873299, "report/reward_loss_mean": 0.07382167875766754, "report/reward_loss_std": 0.16939792037010193, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0023903846740723, "report/reward_neg_acc": 0.9979920387268066, "report/reward_neg_loss": 0.05489407852292061, "report/reward_pos_acc": 0.7500000596046448, "report/reward_pos_loss": 0.747103750705719, "report/reward_pred": 0.01603301428258419, "report/reward_rate": 0.02734375, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.008096663281321526, "eval/cont_loss_std": 0.2579389810562134, "eval/cont_neg_acc": 0.75, "eval/cont_neg_loss": 2.072707176208496, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 1.526651374206267e-07, "eval/cont_pred": 0.9971016049385071, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 22.005069732666016, "eval/dyn_loss_std": 13.992960929870605, "eval/image_loss_mean": 39.425445556640625, "eval/image_loss_std": 42.664066314697266, "eval/model_loss_mean": 52.834075927734375, "eval/model_loss_std": 48.680667877197266, "eval/post_ent_mag": 37.668418884277344, "eval/post_ent_max": 37.668418884277344, "eval/post_ent_mean": 23.09278678894043, "eval/post_ent_min": 10.481565475463867, "eval/post_ent_std": 5.576476573944092, "eval/prior_ent_mag": 70.88512420654297, "eval/prior_ent_max": 70.88512420654297, "eval/prior_ent_mean": 27.50493621826172, "eval/prior_ent_min": 11.877386093139648, "eval/prior_ent_std": 9.440099716186523, "eval/rep_loss_mean": 22.005069732666016, "eval/rep_loss_std": 13.992960929870605, "eval/reward_avg": 0.01582031138241291, "eval/reward_loss_mean": 0.19748981297016144, "eval/reward_loss_std": 1.3168325424194336, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0016348361968994, "eval/reward_neg_acc": 0.9980059862136841, "eval/reward_neg_loss": 0.04697905853390694, "eval/reward_pos_acc": 0.3333333432674408, "eval/reward_pos_loss": 7.386170387268066, "eval/reward_pred": 0.004487532190978527, "eval/reward_rate": 0.0205078125, "replay/size": 18276.0, "replay/inserts": 2169.0, "replay/samples": 34704.0, "replay/insert_wait_avg": 2.5546732120329247e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.889714863180509e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 4560.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 6.854534149169922e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2004442214966, "timer/env.step_count": 271.0, "timer/env.step_total": 23.449440717697144, "timer/env.step_frac": 0.0234447413547681, "timer/env.step_avg": 0.08652930154131787, "timer/env.step_min": 0.023594141006469727, "timer/env.step_max": 1.617332935333252, "timer/replay._sample_count": 34704.0, "timer/replay._sample_total": 16.633689880371094, "timer/replay._sample_frac": 0.01663035642152497, "timer/replay._sample_avg": 0.0004793018061425511, "timer/replay._sample_min": 0.0003409385681152344, "timer/replay._sample_max": 0.011061906814575195, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 271.0, "timer/agent.policy_total": 4.176396131515503, "timer/agent.policy_frac": 0.0041755591648094, "timer/agent.policy_avg": 0.015411055835850564, "timer/agent.policy_min": 0.01441192626953125, "timer/agent.policy_max": 0.04197430610656738, "timer/dataset_train_count": 2169.0, "timer/dataset_train_total": 0.38191962242126465, "timer/dataset_train_frac": 0.00038184308418152203, "timer/dataset_train_avg": 0.0001760809693044097, "timer/dataset_train_min": 8.940696716308594e-05, "timer/dataset_train_max": 0.0006303787231445312, "timer/agent.train_count": 2169.0, "timer/agent.train_total": 962.2340404987335, "timer/agent.train_frac": 0.9620412048983701, "timer/agent.train_avg": 0.44363026302385133, "timer/agent.train_min": 0.43303894996643066, "timer/agent.train_max": 0.5641908645629883, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4706583023071289, "timer/agent.report_frac": 0.000470563980476398, "timer/agent.report_avg": 0.23532915115356445, "timer/agent.report_min": 0.22830986976623535, "timer/agent.report_max": 0.24234843254089355, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0517578125e-05, "timer/dataset_eval_frac": 3.0511462278696825e-08, "timer/dataset_eval_avg": 3.0517578125e-05, "timer/dataset_eval_min": 3.0517578125e-05, "timer/dataset_eval_max": 3.0517578125e-05, "fps": 2.168537335713259}
{"step": 18872, "time": 8365.438036203384, "episode/length": 175.0, "episode/score": 4.271343914859244, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.17134376074864122}
{"step": 18904, "time": 8381.413236618042, "episode/length": 123.0, "episode/score": 3.225991548550155, "episode/reward_rate": 0.9516129032258065, "episode/intrinsic_return": 0.1259914578859025}
{"step": 19040, "time": 8444.643275022507, "episode/length": 182.0, "episode/score": 4.274747274530455, "episode/reward_rate": 0.9672131147540983, "episode/intrinsic_return": 0.1747471393955493}
{"step": 19680, "time": 8736.213124752045, "episode/length": 273.0, "episode/score": 4.378527163229592, "episode/reward_rate": 0.9817518248175182, "episode/intrinsic_return": 0.27852704008546425}
{"step": 19744, "time": 8766.799428224564, "episode/length": 165.0, "episode/score": 0.2616446947795339, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.1616446865373291}
{"step": 20056, "time": 8909.64099240303, "episode/length": 219.0, "episode/score": 0.34804415176040493, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.24804414235404693}
{"step": 20072, "time": 8938.530299901962, "eval_episode/length": 184.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9675675675675676}
{"step": 20072, "time": 8940.294236660004, "eval_episode/length": 189.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9789473684210527}
{"step": 20072, "time": 8942.409554243088, "eval_episode/length": 202.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9753694581280788}
{"step": 20072, "time": 8943.990968465805, "eval_episode/length": 203.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9754901960784313}
{"step": 20072, "time": 8945.524413108826, "eval_episode/length": 204.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9951219512195122}
{"step": 20072, "time": 8947.69557762146, "eval_episode/length": 221.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9774774774774775}
{"step": 20072, "time": 8950.15664768219, "eval_episode/length": 245.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9796747967479674}
{"step": 20072, "time": 8952.651653528214, "eval_episode/length": 270.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.996309963099631}
{"step": 20240, "time": 9028.563794851303, "episode/length": 414.0, "episode/score": 1.515127037797356, "episode/reward_rate": 0.7493975903614458, "episode/intrinsic_return": 0.4151270689617377}
{"step": 20392, "time": 9098.977368354797, "episode/length": 189.0, "episode/score": 2.279687856327655, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.17968778111753636}
{"step": 20592, "time": 9191.256674051285, "episode/length": 249.0, "episode/score": 4.346900683376589, "episode/reward_rate": 0.984, "episode/intrinsic_return": 0.2469006630271906}
{"step": 20624, "time": 9207.328379869461, "episode/length": 214.0, "episode/score": 3.3321851418695587, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.23218504771284643}
{"step": 20752, "time": 9267.091174840927, "episode/length": 133.0, "episode/score": 3.215807737537034, "episode/reward_rate": 0.9925373134328358, "episode/intrinsic_return": 0.11580755991053593}
{"step": 20824, "time": 9301.282678365707, "episode/length": 222.0, "episode/score": 4.31581292507326, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.21581278504891088}
{"step": 20869, "time": 9323.808629751205, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.413600628192608, "train/action_min": 0.0, "train/action_std": 3.421272384432646, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.02907780055493976, "train/actor_opt_grad_steps": 18265.0, "train/actor_opt_loss": -7.924162480841355, "train/adv_mag": 0.7146681237679261, "train/adv_max": 0.6701633034703823, "train/adv_mean": 0.0024706360743756216, "train/adv_min": -0.4993850260686416, "train/adv_std": 0.045373665750958025, "train/cont_avg": 0.9946570763221154, "train/cont_loss_mean": 0.00016869320102866133, "train/cont_loss_std": 0.0044425805301780375, "train/cont_neg_acc": 0.9962225284140843, "train/cont_neg_loss": 0.018895013993985597, "train/cont_pos_acc": 0.999985854786176, "train/cont_pos_loss": 5.281508131945637e-05, "train/cont_pred": 0.994660499290778, "train/cont_rate": 0.9946570763221154, "train/dyn_loss_mean": 2.611187707919341, "train/dyn_loss_std": 7.416266883795078, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.3079188494728162, "train/extr_critic_critic_opt_grad_steps": 18265.0, "train/extr_critic_critic_opt_loss": 15152.782221867488, "train/extr_critic_mag": 18.722397332008068, "train/extr_critic_max": 18.722397332008068, "train/extr_critic_mean": 4.101636948493811, "train/extr_critic_min": -0.5510588775460536, "train/extr_critic_std": 4.197110585295237, "train/extr_return_normed_mag": 1.4423712245546854, "train/extr_return_normed_max": 1.4423712245546854, "train/extr_return_normed_mean": 0.32097477487360054, "train/extr_return_normed_min": -0.047166074675400384, "train/extr_return_normed_std": 0.3157861096641192, "train/extr_return_rate": 0.8014529903347676, "train/extr_return_raw_mag": 19.270996960309837, "train/extr_return_raw_max": 19.270996960309837, "train/extr_return_raw_mean": 4.135070322797849, "train/extr_return_raw_min": -0.8353417243521947, "train/extr_return_raw_std": 4.2678917577633495, "train/extr_reward_mag": 1.0028535792460809, "train/extr_reward_max": 1.0028535792460809, "train/extr_reward_mean": 0.025337166777507473, "train/extr_reward_min": -0.6151161904518421, "train/extr_reward_std": 0.15443059329230052, "train/image_loss_mean": 2.703509282607299, "train/image_loss_std": 5.315591394901276, "train/model_loss_mean": 4.335810080170631, "train/model_loss_std": 8.710201472043991, "train/model_opt_grad_norm": 49.50698359196003, "train/model_opt_grad_steps": 18247.0625, "train/model_opt_loss": 5472.116030179537, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1268.0288461538462, "train/policy_entropy_mag": 2.510311558842659, "train/policy_entropy_max": 2.510311558842659, "train/policy_entropy_mean": 0.5354456911579921, "train/policy_entropy_min": 0.07937510060862853, "train/policy_entropy_std": 0.5913084155091872, "train/policy_logprob_mag": 7.438383111586938, "train/policy_logprob_max": -0.009455674054781692, "train/policy_logprob_mean": -0.5347632974959337, "train/policy_logprob_min": -7.438383111586938, "train/policy_logprob_std": 1.118319164388455, "train/policy_randomness_mag": 0.8860298180236266, "train/policy_randomness_max": 0.8860298180236266, "train/policy_randomness_mean": 0.18898883211211517, "train/policy_randomness_min": 0.02801592722356033, "train/policy_randomness_std": 0.20870592251706582, "train/post_ent_mag": 31.7901659653737, "train/post_ent_max": 31.7901659653737, "train/post_ent_mean": 18.07066940344297, "train/post_ent_min": 10.39906423825484, "train/post_ent_std": 3.450907356463946, "train/prior_ent_mag": 70.50586080551147, "train/prior_ent_max": 70.50586080551147, "train/prior_ent_mean": 20.81519469848046, "train/prior_ent_min": 11.53009257866786, "train/prior_ent_std": 8.402267843484879, "train/rep_loss_mean": 2.611187707919341, "train/rep_loss_std": 7.416266883795078, "train/reward_avg": 0.011098511410706963, "train/reward_loss_mean": 0.06541946333331558, "train/reward_loss_std": 0.14762886223168328, "train/reward_max_data": 1.0012500286102295, "train/reward_max_pred": 1.0019008207779665, "train/reward_neg_acc": 0.9996116470832092, "train/reward_neg_loss": 0.051015360083860845, "train/reward_pos_acc": 0.8753330607253772, "train/reward_pos_loss": 0.729377490396683, "train/reward_pred": 0.010995550618435327, "train/reward_rate": 0.021071213942307692, "train_stats/sum_log_reward": 2.766666665673256, "train_stats/max_log_achievement_collect_drink": 3.1666666666666665, "train_stats/max_log_achievement_collect_sapling": 1.5, "train_stats/max_log_achievement_collect_wood": 1.0, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_eat_cow": 0.08333333333333333, "train_stats/max_log_achievement_place_plant": 1.1666666666666667, "train_stats/max_log_achievement_place_table": 0.25, "train_stats/max_log_achievement_wake_up": 2.4166666666666665, "train_stats/mean_log_entropy": 0.5811261087656021, "eval_stats/sum_log_reward": 3.3499999195337296, "eval_stats/max_log_achievement_collect_drink": 2.25, "eval_stats/max_log_achievement_collect_sapling": 2.5, "eval_stats/max_log_achievement_collect_wood": 1.625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_place_plant": 2.375, "eval_stats/max_log_achievement_place_table": 0.375, "eval_stats/max_log_achievement_wake_up": 1.875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 1.0901633231696906e-06, "report/cont_loss_std": 1.251316825801041e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 5.740510823670775e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 9.246933245776745e-07, "report/cont_pred": 0.9970695972442627, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 2.458312749862671, "report/dyn_loss_std": 7.086429119110107, "report/image_loss_mean": 2.787675380706787, "report/image_loss_std": 4.271244049072266, "report/model_loss_mean": 4.326192855834961, "report/model_loss_std": 7.614804744720459, "report/post_ent_mag": 31.138290405273438, "report/post_ent_max": 31.138290405273438, "report/post_ent_mean": 17.928876876831055, "report/post_ent_min": 10.212234497070312, "report/post_ent_std": 3.457282543182373, "report/prior_ent_mag": 70.58897399902344, "report/prior_ent_max": 70.58897399902344, "report/prior_ent_mean": 20.682191848754883, "report/prior_ent_min": 11.877471923828125, "report/prior_ent_std": 8.043750762939453, "report/rep_loss_mean": 2.458312749862671, "report/rep_loss_std": 7.086429119110107, "report/reward_avg": 0.010218117386102676, "report/reward_loss_mean": 0.0635286271572113, "report/reward_loss_std": 0.11666207760572433, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0012710094451904, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.051333557814359665, "report/reward_pos_acc": 0.8500000238418579, "report/reward_pos_loss": 0.6757211089134216, "report/reward_pred": 0.010189400054514408, "report/reward_rate": 0.01953125, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.0007920943317003548, "eval/cont_loss_std": 0.02497505210340023, "eval/cont_neg_acc": 0.8333333730697632, "eval/cont_neg_loss": 0.13447751104831696, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 4.164616711932467e-06, "eval/cont_pred": 0.9946812391281128, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 22.189043045043945, "eval/dyn_loss_std": 12.68129825592041, "eval/image_loss_mean": 48.28446960449219, "eval/image_loss_std": 65.23619842529297, "eval/model_loss_mean": 61.77928161621094, "eval/model_loss_std": 69.12335205078125, "eval/post_ent_mag": 34.15995407104492, "eval/post_ent_max": 34.15995407104492, "eval/post_ent_mean": 23.209692001342773, "eval/post_ent_min": 11.382085800170898, "eval/post_ent_std": 4.653260231018066, "eval/prior_ent_mag": 70.58897399902344, "eval/prior_ent_max": 70.58897399902344, "eval/prior_ent_mean": 29.08428192138672, "eval/prior_ent_min": 11.14403247833252, "eval/prior_ent_std": 9.290450096130371, "eval/rep_loss_mean": 22.189043045043945, "eval/rep_loss_std": 12.68129825592041, "eval/reward_avg": 0.01289062388241291, "eval/reward_loss_mean": 0.1805925816297531, "eval/reward_loss_std": 1.134982705116272, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0001561641693115, "eval/reward_neg_acc": 1.0000001192092896, "eval/reward_neg_loss": 0.0756646990776062, "eval/reward_pos_acc": 0.2222222238779068, "eval/reward_pos_loss": 6.044896125793457, "eval/reward_pred": 0.0018086753552779555, "eval/reward_rate": 0.017578125, "replay/size": 20365.0, "replay/inserts": 2089.0, "replay/samples": 33424.0, "replay/insert_wait_avg": 2.518973891503392e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.028152172733232e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 6728.0, "eval_replay/inserts": 2168.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2000108556993774e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.344650268554688e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1215088367462, "timer/env.step_count": 261.0, "timer/env.step_total": 24.985249280929565, "timer/env.step_frac": 0.024982213721200956, "timer/env.step_avg": 0.095728924448006, "timer/env.step_min": 0.023395061492919922, "timer/env.step_max": 1.6402409076690674, "timer/replay._sample_count": 33424.0, "timer/replay._sample_total": 16.16794753074646, "timer/replay._sample_frac": 0.016165983220930425, "timer/replay._sample_avg": 0.00048372270017790986, "timer/replay._sample_min": 0.00032210350036621094, "timer/replay._sample_max": 0.02878594398498535, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 532.0, "timer/agent.policy_total": 8.471433162689209, "timer/agent.policy_frac": 0.008470403933760447, "timer/agent.policy_avg": 0.01592374654640829, "timer/agent.policy_min": 0.009508848190307617, "timer/agent.policy_max": 0.3330988883972168, "timer/dataset_train_count": 2089.0, "timer/dataset_train_total": 0.36225223541259766, "timer/dataset_train_frac": 0.0003622082239126501, "timer/dataset_train_avg": 0.00017340939943159294, "timer/dataset_train_min": 8.726119995117188e-05, "timer/dataset_train_max": 0.0006968975067138672, "timer/agent.train_count": 2089.0, "timer/agent.train_total": 926.7619957923889, "timer/agent.train_frac": 0.9266493997017595, "timer/agent.train_avg": 0.4436390597378597, "timer/agent.train_min": 0.43363499641418457, "timer/agent.train_max": 0.555884838104248, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4792907238006592, "timer/agent.report_frac": 0.0004792324928179259, "timer/agent.report_avg": 0.2396453619003296, "timer/agent.report_min": 0.23318076133728027, "timer/agent.report_max": 0.2461099624633789, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0517578125e-05, "timer/dataset_eval_frac": 3.051387042010063e-08, "timer/dataset_eval_avg": 3.0517578125e-05, "timer/dataset_eval_min": 3.0517578125e-05, "timer/dataset_eval_max": 3.0517578125e-05, "fps": 2.0887198161053333}
{"step": 21536, "time": 9626.365933656693, "episode/length": 223.0, "episode/score": 3.3293452041871205, "episode/reward_rate": 0.9776785714285714, "episode/intrinsic_return": 0.22934516887835343}
{"step": 21624, "time": 9667.663317918777, "episode/length": 172.0, "episode/score": 2.300145413457358, "episode/reward_rate": 0.9653179190751445, "episode/intrinsic_return": 0.2001453560878872}
{"step": 21760, "time": 9730.689642906189, "episode/length": 212.0, "episode/score": 2.2988454667265614, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.19884538147562125}
{"step": 21992, "time": 9837.088454723358, "episode/length": 199.0, "episode/score": 2.309522778792598, "episode/reward_rate": 0.97, "episode/intrinsic_return": 0.20952273108559893}
{"step": 22000, "time": 9842.13581442833, "episode/length": 155.0, "episode/score": 1.2393756669589493, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.13937569498011726}
{"step": 22360, "time": 10006.1307990551, "episode/length": 216.0, "episode/score": 3.324672396582173, "episode/reward_rate": 0.9815668202764977, "episode/intrinsic_return": 0.22467230126130744}
{"step": 22688, "time": 10156.198219299316, "episode/length": 261.0, "episode/score": 2.381220578956345, "episode/reward_rate": 0.9961832061068703, "episode/intrinsic_return": 0.2812205742648075}
{"step": 22904, "time": 10255.529011964798, "episode/length": 170.0, "episode/score": 3.2929456057008792, "episode/reward_rate": 0.9590643274853801, "episode/intrinsic_return": 0.19294549070582434}
{"step": 23051, "time": 10323.870027303696, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.460113664740297, "train/action_min": 0.0, "train/action_std": 3.56710454426944, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.029634674619798247, "train/actor_opt_grad_steps": 20400.0, "train/actor_opt_loss": -5.734610614473144, "train/adv_mag": 0.715918067179314, "train/adv_max": 0.6882328540086746, "train/adv_mean": 0.0039537361658632236, "train/adv_min": -0.49829965407989885, "train/adv_std": 0.04946607885431481, "train/cont_avg": 0.9947336972031964, "train/cont_loss_mean": 7.402191453986693e-05, "train/cont_loss_std": 0.002239756689912859, "train/cont_neg_acc": 0.9962328767667622, "train/cont_neg_loss": 0.010786935854568924, "train/cont_pos_acc": 0.9999954948142239, "train/cont_pos_loss": 2.5842784436579286e-05, "train/cont_pred": 0.9947345379280718, "train/cont_rate": 0.9947336972031964, "train/dyn_loss_mean": 2.698522622182489, "train/dyn_loss_std": 7.459016758557324, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.3157692987080578, "train/extr_critic_critic_opt_grad_steps": 20400.0, "train/extr_critic_critic_opt_loss": 15448.35350670662, "train/extr_critic_mag": 19.37018737183314, "train/extr_critic_max": 19.37018737183314, "train/extr_critic_mean": 4.372688667959274, "train/extr_critic_min": -0.514983385120897, "train/extr_critic_std": 4.108328591743017, "train/extr_return_normed_mag": 1.4997134782952262, "train/extr_return_normed_max": 1.4997134782952262, "train/extr_return_normed_mean": 0.34365604212294976, "train/extr_return_normed_min": -0.053676096535368596, "train/extr_return_normed_std": 0.3185208002998404, "train/extr_return_rate": 0.8358977077758476, "train/extr_return_raw_mag": 19.679993320273482, "train/extr_return_raw_max": 19.679993320273482, "train/extr_return_raw_mean": 4.42423277685087, "train/extr_return_raw_min": -0.8096089324994719, "train/extr_return_raw_std": 4.200455242096017, "train/extr_reward_mag": 1.0029386320070588, "train/extr_reward_max": 1.0029386320070588, "train/extr_reward_mean": 0.02522391261167178, "train/extr_reward_min": -0.6249101385133996, "train/extr_reward_std": 0.15353874998277725, "train/image_loss_mean": 2.8018688867081245, "train/image_loss_std": 5.906470067969196, "train/model_loss_mean": 4.487292255985138, "train/model_loss_std": 9.295467720728487, "train/model_opt_grad_norm": 50.007649735228654, "train/model_opt_grad_steps": 20379.99086757991, "train/model_opt_loss": 5772.3087955283245, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1289.9543378995434, "train/policy_entropy_mag": 2.4905139714071196, "train/policy_entropy_max": 2.4905139714071196, "train/policy_entropy_mean": 0.5199753258326282, "train/policy_entropy_min": 0.07937506736005277, "train/policy_entropy_std": 0.5782293718155116, "train/policy_logprob_mag": 7.438383228702632, "train/policy_logprob_max": -0.009455667285580342, "train/policy_logprob_mean": -0.520710063171169, "train/policy_logprob_min": -7.438383228702632, "train/policy_logprob_std": 1.1129172811769459, "train/policy_randomness_mag": 0.8790421390642315, "train/policy_randomness_max": 0.8790421390642315, "train/policy_randomness_mean": 0.1835284708705667, "train/policy_randomness_min": 0.02801591547452696, "train/policy_randomness_std": 0.20408959285309325, "train/post_ent_mag": 32.41679263876998, "train/post_ent_max": 32.41679263876998, "train/post_ent_mean": 18.141954874883503, "train/post_ent_min": 10.375190225366044, "train/post_ent_std": 3.4924467676850757, "train/prior_ent_mag": 71.0470205507322, "train/prior_ent_max": 71.0470205507322, "train/prior_ent_mean": 20.93429814517226, "train/prior_ent_min": 11.558737946427575, "train/prior_ent_std": 8.512546358587535, "train/rep_loss_mean": 2.698522622182489, "train/rep_loss_std": 7.459016758557324, "train/reward_avg": 0.01196799674773053, "train/reward_loss_mean": 0.06623580282953777, "train/reward_loss_std": 0.14818339202910252, "train/reward_max_data": 1.0012500286102295, "train/reward_max_pred": 1.0019001906320928, "train/reward_neg_acc": 0.9995483745178676, "train/reward_neg_loss": 0.051114452075740516, "train/reward_pos_acc": 0.8682350108068283, "train/reward_pos_loss": 0.7284509531439167, "train/reward_pred": 0.011923859839978283, "train/reward_rate": 0.02236283533105023, "train_stats/sum_log_reward": 2.349999949336052, "train_stats/max_log_achievement_collect_drink": 3.125, "train_stats/max_log_achievement_collect_sapling": 0.5, "train_stats/max_log_achievement_collect_wood": 1.125, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_eat_cow": 0.125, "train_stats/max_log_achievement_place_plant": 0.5, "train_stats/max_log_achievement_place_table": 0.25, "train_stats/max_log_achievement_wake_up": 2.625, "train_stats/mean_log_entropy": 0.4832790084183216, "report/cont_avg": 0.9912109375, "report/cont_loss_mean": 1.7379008454554423e-07, "report/cont_loss_std": 1.0097814993059728e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 2.8404301701812074e-06, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.501449986562875e-07, "report/cont_pred": 0.9912108778953552, "report/cont_rate": 0.9912109375, "report/dyn_loss_mean": 2.8749375343322754, "report/dyn_loss_std": 7.744390964508057, "report/image_loss_mean": 2.923994541168213, "report/image_loss_std": 4.380229949951172, "report/model_loss_mean": 4.719292640686035, "report/model_loss_std": 8.047231674194336, "report/post_ent_mag": 33.21729278564453, "report/post_ent_max": 33.21729278564453, "report/post_ent_mean": 18.59531021118164, "report/post_ent_min": 10.747188568115234, "report/post_ent_std": 3.809356212615967, "report/prior_ent_mag": 71.60545349121094, "report/prior_ent_max": 71.60545349121094, "report/prior_ent_mean": 21.56633758544922, "report/prior_ent_min": 12.017520904541016, "report/prior_ent_std": 9.0967378616333, "report/rep_loss_mean": 2.8749375343322754, "report/rep_loss_std": 7.744390964508057, "report/reward_avg": 0.006174227222800255, "report/reward_loss_mean": 0.07033513486385345, "report/reward_loss_std": 0.12706230580806732, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0031318664550781, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.05648170784115791, "report/reward_pos_acc": 0.695652186870575, "report/reward_pos_loss": 0.6732602119445801, "report/reward_pred": 0.006269955541938543, "report/reward_rate": 0.0224609375, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.030948041006922722, "eval/cont_loss_std": 0.69172203540802, "eval/cont_neg_acc": 0.5, "eval/cont_neg_loss": 7.922671318054199, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 1.0866289557043274e-07, "eval/cont_pred": 0.9983542561531067, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 25.212181091308594, "eval/dyn_loss_std": 13.857527732849121, "eval/image_loss_mean": 70.67033386230469, "eval/image_loss_std": 67.1805191040039, "eval/model_loss_mean": 86.05123901367188, "eval/model_loss_std": 71.01701354980469, "eval/post_ent_mag": 37.35313415527344, "eval/post_ent_max": 37.35313415527344, "eval/post_ent_mean": 24.723430633544922, "eval/post_ent_min": 9.975543975830078, "eval/post_ent_std": 5.333957195281982, "eval/prior_ent_mag": 71.60545349121094, "eval/prior_ent_max": 71.60545349121094, "eval/prior_ent_mean": 31.580509185791016, "eval/prior_ent_min": 12.214113235473633, "eval/prior_ent_std": 10.086080551147461, "eval/rep_loss_mean": 25.212181091308594, "eval/rep_loss_std": 13.857527732849121, "eval/reward_avg": 0.015039063058793545, "eval/reward_loss_mean": 0.2226385474205017, "eval/reward_loss_std": 1.2689087390899658, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0014030933380127, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.13808420300483704, "eval/reward_pos_acc": 0.5, "eval/reward_pos_loss": 4.4672675132751465, "eval/reward_pred": 0.008879238739609718, "eval/reward_rate": 0.01953125, "replay/size": 22547.0, "replay/inserts": 2182.0, "replay/samples": 34912.0, "replay/insert_wait_avg": 2.4545531443343265e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.069094881674874e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 6728.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 6.854534149169922e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0482840538025, "timer/env.step_count": 273.0, "timer/env.step_total": 19.151133060455322, "timer/env.step_frac": 0.01915020841076209, "timer/env.step_avg": 0.0701506705511184, "timer/env.step_min": 0.02331686019897461, "timer/env.step_max": 1.6786904335021973, "timer/replay._sample_count": 34912.0, "timer/replay._sample_total": 16.879950284957886, "timer/replay._sample_frac": 0.016879135291881314, "timer/replay._sample_avg": 0.00048349995087528316, "timer/replay._sample_min": 0.0003325939178466797, "timer/replay._sample_max": 0.009902238845825195, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 273.0, "timer/agent.policy_total": 4.166116714477539, "timer/agent.policy_frac": 0.004165915567186157, "timer/agent.policy_avg": 0.01526050078563201, "timer/agent.policy_min": 0.014270544052124023, "timer/agent.policy_max": 0.03188037872314453, "timer/dataset_train_count": 2182.0, "timer/dataset_train_total": 0.37474822998046875, "timer/dataset_train_frac": 0.00037473013649039704, "timer/dataset_train_avg": 0.00017174529329993984, "timer/dataset_train_min": 8.726119995117188e-05, "timer/dataset_train_max": 0.0006835460662841797, "timer/agent.train_count": 2182.0, "timer/agent.train_total": 966.3136613368988, "timer/agent.train_frac": 0.9662670060487911, "timer/agent.train_avg": 0.4428568567080196, "timer/agent.train_min": 0.43127894401550293, "timer/agent.train_max": 0.5902681350708008, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47545647621154785, "timer/agent.report_frac": 0.0004754335203538716, "timer/agent.report_avg": 0.23772823810577393, "timer/agent.report_min": 0.2323591709136963, "timer/agent.report_max": 0.24309730529785156, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9325485229492188e-05, "timer/dataset_eval_frac": 2.9324069344550246e-08, "timer/dataset_eval_avg": 2.9325485229492188e-05, "timer/dataset_eval_min": 2.9325485229492188e-05, "timer/dataset_eval_max": 2.9325485229492188e-05, "fps": 2.181866653080944}
{"step": 23120, "time": 10355.38096833229, "episode/length": 169.0, "episode/score": 3.2902591706815656, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.19025914142639522}
{"step": 23216, "time": 10400.402300834656, "episode/length": 298.0, "episode/score": 2.4263766062958894, "episode/reward_rate": 0.9832775919732442, "episode/intrinsic_return": 0.32637656208135013}
{"step": 23296, "time": 10438.234394788742, "episode/length": 162.0, "episode/score": 2.267076349097806, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.16707628241510974}
{"step": 23456, "time": 10512.51080274582, "episode/length": 181.0, "episode/score": 3.2393364305980867, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.13933626993912185}
{"step": 23776, "time": 10660.145061969757, "episode/length": 135.0, "episode/score": 2.232496476113738, "episode/reward_rate": 0.9926470588235294, "episode/intrinsic_return": 0.13249642730079358}
{"step": 23800, "time": 10672.627392292023, "episode/length": 271.0, "episode/score": 3.370817803027421, "episode/reward_rate": 0.9963235294117647, "episode/intrinsic_return": 0.2708177336089648}
{"step": 23832, "time": 10688.741778612137, "episode/length": 183.0, "episode/score": 4.276681174172154, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.17668099456659547}
{"step": 24176, "time": 10847.403716564178, "episode/length": 158.0, "episode/score": 2.2723695739687173, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.17236957568002254}
{"step": 24384, "time": 10943.254331588745, "episode/length": 157.0, "episode/score": 4.265305467743019, "episode/reward_rate": 0.9620253164556962, "episode/intrinsic_return": 0.16530535967467586}
{"step": 24424, "time": 10963.0125041008, "episode/length": 140.0, "episode/score": 2.2056957984950714, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.10569567616585118}
{"step": 24664, "time": 11074.707003593445, "episode/length": 180.0, "episode/score": 3.2530599512574554, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.1530598026183725}
{"step": 24696, "time": 11090.860213279724, "episode/length": 38.0, "episode/score": 1.1439583867322654, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.04395833262242377}
{"step": 24944, "time": 11205.47754573822, "episode/length": 185.0, "episode/score": 3.2769980534476417, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.17699796132819756}
{"step": 24968, "time": 11217.89651632309, "episode/length": 141.0, "episode/score": 3.206651735939886, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.10665164501369873}
{"step": 25056, "time": 11259.568197250366, "episode/length": 156.0, "episode/score": 4.250020496988327, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.1500204330413908}
{"step": 25160, "time": 11308.664133548737, "episode/length": 172.0, "episode/score": 2.253461229628556, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.15346118340585235}
{"step": 25189, "time": 11324.067714691162, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.647856376540493, "train/action_min": 0.0, "train/action_std": 3.710005461330145, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.028178225100879938, "train/actor_opt_grad_steps": 22560.0, "train/actor_opt_loss": -14.734122821055527, "train/adv_mag": 0.6381419834116815, "train/adv_max": 0.5951346103014521, "train/adv_mean": 0.0007986934139953177, "train/adv_min": -0.47979241224801594, "train/adv_std": 0.043827329067067364, "train/cont_avg": 0.9947504034624414, "train/cont_loss_mean": 0.00010584851989879557, "train/cont_loss_std": 0.0030752370257777356, "train/cont_neg_acc": 0.9993293095082744, "train/cont_neg_loss": 0.01281129643602703, "train/cont_pos_acc": 0.9999953760227687, "train/cont_pos_loss": 2.203080658871023e-05, "train/cont_pred": 0.9947457590573271, "train/cont_rate": 0.9947504034624414, "train/dyn_loss_mean": 2.6376971750751905, "train/dyn_loss_std": 7.462932947096131, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.239256522185366, "train/extr_critic_critic_opt_grad_steps": 22560.0, "train/extr_critic_critic_opt_loss": 14943.16668959067, "train/extr_critic_mag": 18.04991291386421, "train/extr_critic_max": 18.04991291386421, "train/extr_critic_mean": 4.139594301931175, "train/extr_critic_min": -0.5384996267551547, "train/extr_critic_std": 4.156037019452019, "train/extr_return_normed_mag": 1.4237618572275403, "train/extr_return_normed_max": 1.4237618572275403, "train/extr_return_normed_mean": 0.3280726605457879, "train/extr_return_normed_min": -0.05653231709915708, "train/extr_return_normed_std": 0.32162245653324845, "train/extr_return_rate": 0.796851504856432, "train/extr_return_raw_mag": 18.434889224773283, "train/extr_return_raw_max": 18.434889224773283, "train/extr_return_raw_mean": 4.150151338935458, "train/extr_return_raw_min": -0.8835251099067115, "train/extr_return_raw_std": 4.213861127414614, "train/extr_reward_mag": 1.0036528020957267, "train/extr_reward_max": 1.0036528020957267, "train/extr_reward_mean": 0.023499379835218333, "train/extr_reward_min": -0.6298293093560448, "train/extr_reward_std": 0.14917834725738133, "train/image_loss_mean": 2.5702197092799515, "train/image_loss_std": 5.308167995981208, "train/model_loss_mean": 4.219393443613545, "train/model_loss_std": 8.721268651630957, "train/model_opt_grad_norm": 43.65167834501311, "train/model_opt_grad_steps": 22538.17370892019, "train/model_opt_loss": 4023.2748691039465, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 956.5727699530516, "train/policy_entropy_mag": 2.496316717264238, "train/policy_entropy_max": 2.496316717264238, "train/policy_entropy_mean": 0.5507726097050967, "train/policy_entropy_min": 0.07937507859558007, "train/policy_entropy_std": 0.6016143135061847, "train/policy_logprob_mag": 7.438383364341628, "train/policy_logprob_max": -0.009455674778267812, "train/policy_logprob_mean": -0.5505153573174991, "train/policy_logprob_min": -7.438383364341628, "train/policy_logprob_std": 1.1266037259303348, "train/policy_randomness_mag": 0.8810902528919524, "train/policy_randomness_max": 0.8810902528919524, "train/policy_randomness_mean": 0.1943985619035685, "train/policy_randomness_min": 0.02801591943197407, "train/policy_randomness_std": 0.21234345289183335, "train/post_ent_mag": 33.03609851604336, "train/post_ent_max": 33.03609851604336, "train/post_ent_mean": 18.185469721404598, "train/post_ent_min": 10.589425888419711, "train/post_ent_std": 3.4969203293043685, "train/prior_ent_mag": 71.29850615022328, "train/prior_ent_max": 71.29850615022328, "train/prior_ent_mean": 20.95040840722026, "train/prior_ent_min": 11.785174320561225, "train/prior_ent_std": 8.55011522490094, "train/rep_loss_mean": 2.6376971750751905, "train/rep_loss_std": 7.462932947096131, "train/reward_avg": 0.011461505404030773, "train/reward_loss_mean": 0.06644958957260204, "train/reward_loss_std": 0.14758884130229413, "train/reward_max_data": 1.0026584796502556, "train/reward_max_pred": 1.0021425121826746, "train/reward_neg_acc": 0.9994607693712476, "train/reward_neg_loss": 0.05146057928252108, "train/reward_pos_acc": 0.8745451337294959, "train/reward_pos_loss": 0.7304505115383667, "train/reward_pred": 0.011362919563147734, "train/reward_rate": 0.02205289025821596, "train_stats/sum_log_reward": 2.78749992698431, "train_stats/max_log_achievement_collect_drink": 3.1875, "train_stats/max_log_achievement_collect_sapling": 1.75, "train_stats/max_log_achievement_collect_wood": 0.875, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_place_plant": 1.4375, "train_stats/max_log_achievement_place_table": 0.1875, "train_stats/max_log_achievement_wake_up": 2.5625, "train_stats/mean_log_entropy": 0.4975590296089649, "train_stats/max_log_achievement_make_wood_pickaxe": 0.1, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 2.0154642697889358e-05, "report/cont_loss_std": 0.0004872606659773737, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0006642592488788068, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.8262073353980668e-05, "report/cont_pred": 0.9970542192459106, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 2.6107616424560547, "report/dyn_loss_std": 7.244967937469482, "report/image_loss_mean": 2.781599283218384, "report/image_loss_std": 4.202470302581787, "report/model_loss_mean": 4.412912845611572, "report/model_loss_std": 7.637608051300049, "report/post_ent_mag": 35.766937255859375, "report/post_ent_max": 35.766937255859375, "report/post_ent_mean": 18.20547866821289, "report/post_ent_min": 11.003458023071289, "report/post_ent_std": 3.5975139141082764, "report/prior_ent_mag": 70.87715911865234, "report/prior_ent_max": 70.87715911865234, "report/prior_ent_mean": 20.86933135986328, "report/prior_ent_min": 11.727200508117676, "report/prior_ent_std": 8.26884937286377, "report/rep_loss_mean": 2.6107616424560547, "report/rep_loss_std": 7.244967937469482, "report/reward_avg": 0.01304909959435463, "report/reward_loss_mean": 0.0648365244269371, "report/reward_loss_std": 0.16442669928073883, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0017900466918945, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.04863360896706581, "report/reward_pos_acc": 0.9473684430122375, "report/reward_pos_loss": 0.9218858480453491, "report/reward_pred": 0.011072340421378613, "report/reward_rate": 0.0185546875, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.011036932468414307, "eval/cont_loss_std": 0.3528551757335663, "eval/cont_neg_acc": 0.5, "eval/cont_neg_loss": 5.649396896362305, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.9597331376862712e-06, "eval/cont_pred": 0.999022364616394, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 24.72852325439453, "eval/dyn_loss_std": 15.282514572143555, "eval/image_loss_mean": 62.20070266723633, "eval/image_loss_std": 63.80174255371094, "eval/model_loss_mean": 77.23628234863281, "eval/model_loss_std": 69.2896499633789, "eval/post_ent_mag": 38.18097686767578, "eval/post_ent_max": 38.18097686767578, "eval/post_ent_mean": 24.94971466064453, "eval/post_ent_min": 13.091008186340332, "eval/post_ent_std": 5.326848983764648, "eval/prior_ent_mag": 70.87715911865234, "eval/prior_ent_max": 70.87715911865234, "eval/prior_ent_mean": 30.263269424438477, "eval/prior_ent_min": 12.63774299621582, "eval/prior_ent_std": 9.320270538330078, "eval/rep_loss_mean": 24.72852325439453, "eval/rep_loss_std": 15.282514572143555, "eval/reward_avg": 0.00917968712747097, "eval/reward_loss_mean": 0.1874375343322754, "eval/reward_loss_std": 1.1702990531921387, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0012092590332031, "eval/reward_neg_acc": 0.9980217218399048, "eval/reward_neg_loss": 0.12771236896514893, "eval/reward_pos_acc": 0.46153849363327026, "eval/reward_pos_loss": 4.832217216491699, "eval/reward_pred": 0.005275427363812923, "eval/reward_rate": 0.0126953125, "replay/size": 24685.0, "replay/inserts": 2138.0, "replay/samples": 34208.0, "replay/insert_wait_avg": 2.6096686567515274e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.012684736439176e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 6728.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 6.258487701416016e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.184160232544, "timer/env.step_count": 267.0, "timer/env.step_total": 31.758439779281616, "timer/env.step_frac": 0.03175259221451552, "timer/env.step_avg": 0.1189454673381334, "timer/env.step_min": 0.0239565372467041, "timer/env.step_max": 1.7243335247039795, "timer/replay._sample_count": 34208.0, "timer/replay._sample_total": 16.660207986831665, "timer/replay._sample_frac": 0.01665714040398135, "timer/replay._sample_avg": 0.0004870266600453597, "timer/replay._sample_min": 0.0003437995910644531, "timer/replay._sample_max": 0.009723424911499023, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 267.0, "timer/agent.policy_total": 4.202671766281128, "timer/agent.policy_frac": 0.0042018979437786754, "timer/agent.policy_avg": 0.015740343693936808, "timer/agent.policy_min": 0.014425516128540039, "timer/agent.policy_max": 0.0401616096496582, "timer/dataset_train_count": 2138.0, "timer/dataset_train_total": 0.3930478096008301, "timer/dataset_train_frac": 0.00039297543915257167, "timer/dataset_train_avg": 0.00018383901290964925, "timer/dataset_train_min": 8.869171142578125e-05, "timer/dataset_train_max": 0.0011758804321289062, "timer/agent.train_count": 2138.0, "timer/agent.train_total": 952.6778080463409, "timer/agent.train_frac": 0.9525023949837821, "timer/agent.train_avg": 0.4455929878607769, "timer/agent.train_min": 0.43358778953552246, "timer/agent.train_max": 0.5859053134918213, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47548699378967285, "timer/agent.report_frac": 0.00047539944411749294, "timer/agent.report_avg": 0.23774349689483643, "timer/agent.report_min": 0.2290668487548828, "timer/agent.report_max": 0.24642014503479004, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.6226043701171875e-05, "timer/dataset_eval_frac": 2.622121479615743e-08, "timer/dataset_eval_avg": 2.6226043701171875e-05, "timer/dataset_eval_min": 2.6226043701171875e-05, "timer/dataset_eval_max": 2.6226043701171875e-05, "fps": 2.137574621374214}
{"step": 25528, "time": 11479.175525188446, "episode/length": 168.0, "episode/score": 3.2729684119335616, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.17296828762528094}
{"step": 25768, "time": 11590.181486606598, "episode/length": 167.0, "episode/score": 1.224261121076779, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.12426116865572112}
{"step": 26176, "time": 11777.879756450653, "episode/length": 188.0, "episode/score": 4.2772904106655005, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.17729022136836647}
{"step": 26304, "time": 11838.339631319046, "episode/length": 142.0, "episode/score": 2.2472169689426664, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.1472168694017455}
{"step": 26496, "time": 11928.779727935791, "episode/length": 224.0, "episode/score": 1.2984914925086741, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.19849151482549132}
{"step": 26528, "time": 11945.0340321064, "episode/length": 194.0, "episode/score": 1.2831967446154522, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.18319672717643698}
{"step": 26744, "time": 12046.59975194931, "episode/length": 210.0, "episode/score": 5.318544273633961, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.21854419999544916}
{"step": 26744, "time": 12046.60829257965, "episode/length": 151.0, "episode/score": 4.252545268494941, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.1525450888893829}
{"step": 26760, "time": 12057.216957092285, "episode/length": 226.0, "episode/score": 4.33499386756921, "episode/reward_rate": 0.9823788546255506, "episode/intrinsic_return": 0.23499375792926003}
{"step": 27088, "time": 12210.238111257553, "episode/length": 164.0, "episode/score": 4.2801453012352795, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.180145178440398}
{"step": 27330, "time": 12324.07916855812, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.4055700967478195, "train/action_min": 0.0, "train/action_std": 3.521566672657811, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.030815664141677145, "train/actor_opt_grad_steps": 24700.0, "train/actor_opt_loss": -8.461094139273776, "train/adv_mag": 0.7400818083175393, "train/adv_max": 0.6918183679497519, "train/adv_mean": 0.0033208199035661256, "train/adv_min": -0.55324550735396, "train/adv_std": 0.04727754235960716, "train/cont_avg": 0.9945039970930233, "train/cont_loss_mean": 8.349007499487544e-05, "train/cont_loss_std": 0.0023761818111969935, "train/cont_neg_acc": 0.9987080105515413, "train/cont_neg_loss": 0.006199402858370842, "train/cont_pos_acc": 0.9999862989713979, "train/cont_pos_loss": 4.871192718303783e-05, "train/cont_pred": 0.9945049277571745, "train/cont_rate": 0.9945039970930233, "train/dyn_loss_mean": 2.720959938404172, "train/dyn_loss_std": 7.559601060734239, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.2655381055765373, "train/extr_critic_critic_opt_grad_steps": 24700.0, "train/extr_critic_critic_opt_loss": 15209.99906431686, "train/extr_critic_mag": 18.136215254317882, "train/extr_critic_max": 18.136215254317882, "train/extr_critic_mean": 3.715530243585276, "train/extr_critic_min": -0.5704698457274326, "train/extr_critic_std": 3.6293556224468144, "train/extr_return_normed_mag": 1.5721975262774976, "train/extr_return_normed_max": 1.5721975262774976, "train/extr_return_normed_mean": 0.3327854903631432, "train/extr_return_normed_min": -0.06310153869522173, "train/extr_return_normed_std": 0.31276432636172274, "train/extr_return_rate": 0.7970521832621374, "train/extr_return_raw_mag": 18.42365676525027, "train/extr_return_raw_max": 18.42365676525027, "train/extr_return_raw_mean": 3.7548932108768196, "train/extr_return_raw_min": -0.9321698962255965, "train/extr_return_raw_std": 3.705432111163472, "train/extr_reward_mag": 1.0076596836711085, "train/extr_reward_max": 1.0076596836711085, "train/extr_reward_mean": 0.02694145153861406, "train/extr_reward_min": -0.6451669975768688, "train/extr_reward_std": 0.16016936305650445, "train/image_loss_mean": 2.4287489125894948, "train/image_loss_std": 5.3909019159716225, "train/model_loss_mean": 4.1276925353116765, "train/model_loss_std": 8.908416064949924, "train/model_opt_grad_norm": 46.181974238018654, "train/model_opt_grad_steps": 24676.562790697673, "train/model_opt_loss": 4686.290384833757, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1139.5348837209303, "train/policy_entropy_mag": 2.487790732051051, "train/policy_entropy_max": 2.487790732051051, "train/policy_entropy_mean": 0.5335500864095466, "train/policy_entropy_min": 0.07937505238277967, "train/policy_entropy_std": 0.6008524606394213, "train/policy_logprob_mag": 7.438383353033731, "train/policy_logprob_max": -0.009455666366184867, "train/policy_logprob_mean": -0.5338614110336747, "train/policy_logprob_min": -7.438383353033731, "train/policy_logprob_std": 1.117173887130826, "train/policy_randomness_mag": 0.8780809538308965, "train/policy_randomness_max": 0.8780809538308965, "train/policy_randomness_mean": 0.1883197656204534, "train/policy_randomness_min": 0.02801591014966022, "train/policy_randomness_std": 0.21207455119421315, "train/post_ent_mag": 33.80054224590923, "train/post_ent_max": 33.80054224590923, "train/post_ent_mean": 18.278874854154363, "train/post_ent_min": 10.5766753041467, "train/post_ent_std": 3.556038416263669, "train/prior_ent_mag": 71.62818085426508, "train/prior_ent_max": 71.62818085426508, "train/prior_ent_mean": 21.07636454382608, "train/prior_ent_min": 11.748405416621718, "train/prior_ent_std": 8.665088063617086, "train/rep_loss_mean": 2.720959938404172, "train/rep_loss_std": 7.559601060734239, "train/reward_avg": 0.012668981569342663, "train/reward_loss_mean": 0.06628415542979572, "train/reward_loss_std": 0.15002514484316803, "train/reward_max_data": 1.006366308899813, "train/reward_max_pred": 1.0041757616885874, "train/reward_neg_acc": 0.9995069789332013, "train/reward_neg_loss": 0.050876854793276895, "train/reward_pos_acc": 0.9026161216026128, "train/reward_pos_loss": 0.7249351324037064, "train/reward_pred": 0.012598237978446102, "train/reward_rate": 0.022847020348837208, "train_stats/sum_log_reward": 2.999999928474426, "train_stats/max_log_achievement_collect_drink": 4.7, "train_stats/max_log_achievement_collect_sapling": 1.3, "train_stats/max_log_achievement_collect_wood": 2.0, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_place_plant": 1.2, "train_stats/max_log_achievement_place_table": 0.7, "train_stats/max_log_achievement_wake_up": 2.7, "train_stats/mean_log_entropy": 0.5186077177524566, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 1.3910220104662585e-06, "report/cont_loss_std": 2.4610211767139845e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0002000657405005768, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 4.1617056467657676e-07, "report/cont_pred": 0.9951178431510925, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 2.4788875579833984, "report/dyn_loss_std": 7.0633416175842285, "report/image_loss_mean": 2.3413503170013428, "report/image_loss_std": 3.670323610305786, "report/model_loss_mean": 3.8984181880950928, "report/model_loss_std": 7.024310111999512, "report/post_ent_mag": 35.656471252441406, "report/post_ent_max": 35.656471252441406, "report/post_ent_mean": 18.215160369873047, "report/post_ent_min": 11.488578796386719, "report/post_ent_std": 3.289708375930786, "report/prior_ent_mag": 71.46810913085938, "report/prior_ent_max": 71.46810913085938, "report/prior_ent_mean": 20.989501953125, "report/prior_ent_min": 12.158491134643555, "report/prior_ent_std": 8.366848945617676, "report/rep_loss_mean": 2.4788875579833984, "report/rep_loss_std": 7.0633416175842285, "report/reward_avg": 0.016239089891314507, "report/reward_loss_mean": 0.06973405182361603, "report/reward_loss_std": 0.17691396176815033, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0016896724700928, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.04993815720081329, "report/reward_pos_acc": 0.8888888955116272, "report/reward_pos_loss": 0.8007156848907471, "report/reward_pred": 0.015588996931910515, "report/reward_rate": 0.0263671875, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.00981157273054123, "eval/cont_loss_std": 0.2560563087463379, "eval/cont_neg_acc": 0.6666666865348816, "eval/cont_neg_loss": 1.6744269132614136, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 4.824524353352899e-07, "eval/cont_pred": 0.9962799549102783, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 25.68858528137207, "eval/dyn_loss_std": 14.569918632507324, "eval/image_loss_mean": 58.13321304321289, "eval/image_loss_std": 55.7747802734375, "eval/model_loss_mean": 73.84243774414062, "eval/model_loss_std": 61.03154754638672, "eval/post_ent_mag": 35.72454833984375, "eval/post_ent_max": 35.72454833984375, "eval/post_ent_mean": 24.74791717529297, "eval/post_ent_min": 11.505661010742188, "eval/post_ent_std": 5.021687030792236, "eval/prior_ent_mag": 71.46810913085938, "eval/prior_ent_max": 71.46810913085938, "eval/prior_ent_mean": 31.864625930786133, "eval/prior_ent_min": 15.039322853088379, "eval/prior_ent_std": 9.371174812316895, "eval/rep_loss_mean": 25.68858528137207, "eval/rep_loss_std": 14.569918632507324, "eval/reward_avg": 0.01025390625, "eval/reward_loss_mean": 0.2862666845321655, "eval/reward_loss_std": 1.5203802585601807, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 1.0005302429199219, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.17687420547008514, "eval/reward_pos_acc": 0.1875, "eval/reward_pos_loss": 7.177993297576904, "eval/reward_pred": 0.0011939331889152527, "eval/reward_rate": 0.015625, "replay/size": 26826.0, "replay/inserts": 2141.0, "replay/samples": 34256.0, "replay/insert_wait_avg": 2.6792858538923837e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.82759876687746e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 6728.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 9.834766387939453e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 999.9953339099884, "timer/env.step_count": 268.0, "timer/env.step_total": 22.75293803215027, "timer/env.step_frac": 0.022753044199902542, "timer/env.step_avg": 0.08489902250802339, "timer/env.step_min": 0.023891448974609375, "timer/env.step_max": 3.2534379959106445, "timer/replay._sample_count": 34256.0, "timer/replay._sample_total": 16.609002590179443, "timer/replay._sample_frac": 0.016609080089642153, "timer/replay._sample_avg": 0.0004848494450659576, "timer/replay._sample_min": 0.0003256797790527344, "timer/replay._sample_max": 0.010805606842041016, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 268.0, "timer/agent.policy_total": 4.343197345733643, "timer/agent.policy_frac": 0.004343217611577958, "timer/agent.policy_avg": 0.016205960245274785, "timer/agent.policy_min": 0.014597654342651367, "timer/agent.policy_max": 0.04279613494873047, "timer/dataset_train_count": 2141.0, "timer/dataset_train_total": 0.4043285846710205, "timer/dataset_train_frac": 0.0004043304713133941, "timer/dataset_train_avg": 0.00018885034314386758, "timer/dataset_train_min": 8.535385131835938e-05, "timer/dataset_train_max": 0.0007839202880859375, "timer/agent.train_count": 2141.0, "timer/agent.train_total": 960.7874784469604, "timer/agent.train_frac": 0.9607919615887356, "timer/agent.train_avg": 0.4487564121657919, "timer/agent.train_min": 0.43442726135253906, "timer/agent.train_max": 0.611647367477417, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48313117027282715, "timer/agent.report_frac": 0.000483133424616874, "timer/agent.report_avg": 0.24156558513641357, "timer/agent.report_min": 0.23642396926879883, "timer/agent.report_max": 0.24670720100402832, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.86102294921875e-05, "timer/dataset_eval_frac": 2.861036299071648e-08, "timer/dataset_eval_avg": 2.86102294921875e-05, "timer/dataset_eval_min": 2.86102294921875e-05, "timer/dataset_eval_max": 2.86102294921875e-05, "fps": 2.140976572961851}
{"step": 27640, "time": 12467.886646032333, "episode/length": 182.0, "episode/score": 4.2848609512066105, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.18486087977998977}
{"step": 27656, "time": 12476.757399082184, "episode/length": 168.0, "episode/score": 2.279906630836649, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.17990656415395279}
{"step": 27848, "time": 12567.409950494766, "episode/length": 137.0, "episode/score": 3.25222549049613, "episode/reward_rate": 0.9565217391304348, "episode/intrinsic_return": 0.1522254044884903}
{"step": 27968, "time": 12624.281836986542, "episode/length": 179.0, "episode/score": 3.2537914469962743, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.15379139844526435}
{"step": 28104, "time": 12688.212672472, "episode/length": 167.0, "episode/score": 3.272487867143809, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.17248779079864107}
{"step": 28160, "time": 12715.261136293411, "episode/length": 176.0, "episode/score": 1.2641080597431937, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.16410809506942314}
{"step": 28696, "time": 12963.241443157196, "episode/length": 274.0, "episode/score": 1.3351632709682235, "episode/reward_rate": 0.9963636363636363, "episode/intrinsic_return": 0.23516316758559697}
{"step": 29056, "time": 13129.975146532059, "episode/length": 174.0, "episode/score": 1.257686167637985, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.15768614507669554}
{"step": 29104, "time": 13153.632174015045, "episode/length": 182.0, "episode/score": 2.2640157576252022, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.16401569942627248}
{"step": 29288, "time": 13239.50330233574, "episode/length": 164.0, "episode/score": 4.248774142965885, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.14877402017100394}
{"step": 29468, "time": 13324.29676270485, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.394261606422388, "train/action_min": 0.0, "train/action_std": 3.4927789459765797, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.029484765219366608, "train/actor_opt_grad_steps": 26840.0, "train/actor_opt_loss": -13.58473628857326, "train/adv_mag": 0.6782662812532954, "train/adv_max": 0.6268663840114791, "train/adv_mean": 0.001840050270825294, "train/adv_min": -0.48565713606529953, "train/adv_std": 0.043907757612391254, "train/cont_avg": 0.994576181044601, "train/cont_loss_mean": 4.2195265398800184e-05, "train/cont_loss_std": 0.0012431879895676318, "train/cont_neg_acc": 0.9981220658396331, "train/cont_neg_loss": 0.0032740721996300285, "train/cont_pos_acc": 0.9999907559632135, "train/cont_pos_loss": 2.451004236807959e-05, "train/cont_pred": 0.9945762845831858, "train/cont_rate": 0.994576181044601, "train/dyn_loss_mean": 2.6891245920333504, "train/dyn_loss_std": 7.524056770432163, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.2391647411064364, "train/extr_critic_critic_opt_grad_steps": 26840.0, "train/extr_critic_critic_opt_loss": 15170.99405351379, "train/extr_critic_mag": 18.187934145681176, "train/extr_critic_max": 18.187934145681176, "train/extr_critic_mean": 4.018622710671224, "train/extr_critic_min": -0.5613209915832734, "train/extr_critic_std": 3.882167395291754, "train/extr_return_normed_mag": 1.5287119609089526, "train/extr_return_normed_max": 1.5287119609089526, "train/extr_return_normed_mean": 0.3455038396685336, "train/extr_return_normed_min": -0.06410549419271834, "train/extr_return_normed_std": 0.3251793901545341, "train/extr_return_rate": 0.7836038764093963, "train/extr_return_raw_mag": 18.4138605314801, "train/extr_return_raw_max": 18.4138605314801, "train/extr_return_raw_mean": 4.040714897460221, "train/extr_return_raw_min": -0.9341211369339849, "train/extr_return_raw_std": 3.955710639416332, "train/extr_reward_mag": 1.0122989287398791, "train/extr_reward_max": 1.0122989287398791, "train/extr_reward_mean": 0.025833855923090322, "train/extr_reward_min": -0.6672395294261091, "train/extr_reward_std": 0.15696277315487883, "train/image_loss_mean": 2.3676645610254137, "train/image_loss_std": 5.67656617545186, "train/model_loss_mean": 4.047823637304171, "train/model_loss_std": 9.163791193089015, "train/model_opt_grad_norm": 40.0556629828687, "train/model_opt_grad_steps": 26815.25352112676, "train/model_opt_loss": 5924.148421453198, "train/model_opt_model_opt_grad_overflow": 0.004694835680751174, "train/model_opt_model_opt_grad_scale": 1467.1361502347418, "train/policy_entropy_mag": 2.4580560379744694, "train/policy_entropy_max": 2.4580560379744694, "train/policy_entropy_mean": 0.5288936697261434, "train/policy_entropy_min": 0.07937503203819615, "train/policy_entropy_std": 0.5777336879515312, "train/policy_logprob_mag": 7.438383431501792, "train/policy_logprob_max": -0.009455660895877321, "train/policy_logprob_mean": -0.5284927502764223, "train/policy_logprob_min": -7.438383431501792, "train/policy_logprob_std": 1.104912279357373, "train/policy_randomness_mag": 0.8675859128365494, "train/policy_randomness_max": 0.8675859128365494, "train/policy_randomness_mean": 0.18667625509937044, "train/policy_randomness_min": 0.028015902939256928, "train/policy_randomness_std": 0.2039146390459347, "train/post_ent_mag": 34.21293903404558, "train/post_ent_max": 34.21293903404558, "train/post_ent_mean": 18.32728770976895, "train/post_ent_min": 10.688166031815078, "train/post_ent_std": 3.559181635368598, "train/prior_ent_mag": 71.93578736211212, "train/prior_ent_max": 71.93578736211212, "train/prior_ent_mean": 21.127317133084148, "train/prior_ent_min": 11.857992239401375, "train/prior_ent_std": 8.677645839995622, "train/rep_loss_mean": 2.6891245920333504, "train/rep_loss_std": 7.524056770432163, "train/reward_avg": 0.013005319923739617, "train/reward_loss_mean": 0.0666421124702888, "train/reward_loss_std": 0.15322103837566198, "train/reward_max_data": 1.0059448654103167, "train/reward_max_pred": 1.0051980259272975, "train/reward_neg_acc": 0.9995019836045207, "train/reward_neg_loss": 0.05121616741091433, "train/reward_pos_acc": 0.9026344376550594, "train/reward_pos_loss": 0.7182209701605247, "train/reward_pred": 0.01300774767837474, "train/reward_rate": 0.02314407276995305, "train_stats/sum_log_reward": 2.499999928474426, "train_stats/max_log_achievement_collect_drink": 9.4, "train_stats/max_log_achievement_collect_sapling": 1.0, "train_stats/max_log_achievement_collect_wood": 1.0, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_place_plant": 1.0, "train_stats/max_log_achievement_place_table": 0.1, "train_stats/max_log_achievement_wake_up": 3.0, "train_stats/mean_log_entropy": 0.45238941013813017, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 4.83276744489558e-06, "report/cont_loss_std": 0.00010182688856730238, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00048095383681356907, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.0837831041499157e-06, "report/cont_pred": 0.9921901226043701, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 2.5413970947265625, "report/dyn_loss_std": 7.661367416381836, "report/image_loss_mean": 1.611366868019104, "report/image_loss_std": 3.0468380451202393, "report/model_loss_mean": 3.1977663040161133, "report/model_loss_std": 6.963549613952637, "report/post_ent_mag": 37.55536651611328, "report/post_ent_max": 37.55536651611328, "report/post_ent_mean": 18.118452072143555, "report/post_ent_min": 10.73359489440918, "report/post_ent_std": 3.4522175788879395, "report/prior_ent_mag": 72.20977783203125, "report/prior_ent_max": 72.20977783203125, "report/prior_ent_mean": 20.83831214904785, "report/prior_ent_min": 12.624246597290039, "report/prior_ent_std": 8.902008056640625, "report/rep_loss_mean": 2.5413970947265625, "report/rep_loss_std": 7.661367416381836, "report/reward_avg": 0.008341881446540356, "report/reward_loss_mean": 0.06155628710985184, "report/reward_loss_std": 0.11170435696840286, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0024263858795166, "report/reward_neg_acc": 1.0000001192092896, "report/reward_neg_loss": 0.05060464143753052, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6736319065093994, "report/reward_pred": 0.008449685759842396, "report/reward_rate": 0.017578125, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.003929437603801489, "eval/cont_loss_std": 0.1256256103515625, "eval/cont_neg_acc": 0.6666666865348816, "eval/cont_neg_loss": 1.340712547302246, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.5734393628008547e-06, "eval/cont_pred": 0.9980279207229614, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 26.13717269897461, "eval/dyn_loss_std": 15.126810073852539, "eval/image_loss_mean": 57.338157653808594, "eval/image_loss_std": 55.987064361572266, "eval/model_loss_mean": 73.15325927734375, "eval/model_loss_std": 61.968177795410156, "eval/post_ent_mag": 37.56873321533203, "eval/post_ent_max": 37.56873321533203, "eval/post_ent_mean": 23.974388122558594, "eval/post_ent_min": 12.015491485595703, "eval/post_ent_std": 5.070093154907227, "eval/prior_ent_mag": 72.20977783203125, "eval/prior_ent_max": 72.20977783203125, "eval/prior_ent_mean": 29.704662322998047, "eval/prior_ent_min": 12.704743385314941, "eval/prior_ent_std": 9.94408130645752, "eval/rep_loss_mean": 26.13717269897461, "eval/rep_loss_std": 15.126810073852539, "eval/reward_avg": 0.01249999925494194, "eval/reward_loss_mean": 0.12887683510780334, "eval/reward_loss_std": 0.9730185866355896, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.00123929977417, "eval/reward_neg_acc": 0.9990089535713196, "eval/reward_neg_loss": 0.04106362909078598, "eval/reward_pos_acc": 0.46666669845581055, "eval/reward_pos_loss": 6.035778522491455, "eval/reward_pred": 0.00769771309569478, "eval/reward_rate": 0.0146484375, "replay/size": 28964.0, "replay/inserts": 2138.0, "replay/samples": 34208.0, "replay/insert_wait_avg": 2.578890580122888e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.951281915991188e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 6728.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 7.599592208862305e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2054541110992, "timer/env.step_count": 267.0, "timer/env.step_total": 22.62380290031433, "timer/env.step_frac": 0.022619155701785805, "timer/env.step_avg": 0.08473334419593383, "timer/env.step_min": 0.024121999740600586, "timer/env.step_max": 1.69150972366333, "timer/replay._sample_count": 34208.0, "timer/replay._sample_total": 16.99451494216919, "timer/replay._sample_frac": 0.016991024066422958, "timer/replay._sample_avg": 0.0004967994311906335, "timer/replay._sample_min": 0.00033283233642578125, "timer/replay._sample_max": 0.009034156799316406, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 267.0, "timer/agent.policy_total": 4.360774040222168, "timer/agent.policy_frac": 0.00435987828530456, "timer/agent.policy_avg": 0.01633248704203059, "timer/agent.policy_min": 0.01497197151184082, "timer/agent.policy_max": 0.04777979850769043, "timer/dataset_train_count": 2138.0, "timer/dataset_train_total": 0.4558429718017578, "timer/dataset_train_frac": 0.00045574933622699924, "timer/dataset_train_avg": 0.00021320999616546203, "timer/dataset_train_min": 9.441375732421875e-05, "timer/dataset_train_max": 0.04556083679199219, "timer/agent.train_count": 2138.0, "timer/agent.train_total": 961.1256115436554, "timer/agent.train_frac": 0.960928184897597, "timer/agent.train_avg": 0.44954425235905304, "timer/agent.train_min": 0.434497594833374, "timer/agent.train_max": 0.6060655117034912, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47916078567504883, "timer/agent.report_frac": 0.0004790623603436433, "timer/agent.report_avg": 0.23958039283752441, "timer/agent.report_min": 0.23072075843811035, "timer/agent.report_max": 0.24844002723693848, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.765655517578125e-05, "timer/dataset_eval_frac": 2.7650874190003427e-08, "timer/dataset_eval_avg": 2.765655517578125e-05, "timer/dataset_eval_min": 2.765655517578125e-05, "timer/dataset_eval_max": 2.765655517578125e-05, "fps": 2.1375325263682723}
{"step": 29592, "time": 13381.19765329361, "episode/length": 185.0, "episode/score": 4.315025084122681, "episode/reward_rate": 0.956989247311828, "episode/intrinsic_return": 0.2150249413043639}
{"step": 29600, "time": 13386.350962162018, "episode/length": 179.0, "episode/score": 3.282592302375633, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.18259221683365467}
{"step": 29648, "time": 13409.962219238281, "episode/length": 118.0, "episode/score": 2.2374068873996293, "episode/reward_rate": 0.957983193277311, "episode/intrinsic_return": 0.1374067940578243}
{"step": 29936, "time": 13543.179807662964, "episode/length": 80.0, "episode/score": 3.1806547380647316, "episode/reward_rate": 0.9382716049382716, "episode/intrinsic_return": 0.0806546926860392}
{"step": 30056, "time": 13614.1461353302, "eval_episode/length": 54.0, "eval_episode/score": 1.100000023841858, "eval_episode/reward_rate": 0.9818181818181818}
{"step": 30056, "time": 13617.49850988388, "eval_episode/length": 41.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9761904761904762}
{"step": 30056, "time": 13622.195237636566, "eval_episode/length": 136.0, "eval_episode/score": 3.100000001490116, "eval_episode/reward_rate": 0.9927007299270073}
{"step": 30056, "time": 13624.99699831009, "eval_episode/length": 164.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9696969696969697}
{"step": 30056, "time": 13626.798067331314, "eval_episode/length": 170.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9707602339181286}
{"step": 30056, "time": 13628.28980255127, "eval_episode/length": 171.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9941860465116279}
{"step": 30056, "time": 13630.28516459465, "eval_episode/length": 182.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.994535519125683}
{"step": 30056, "time": 13632.87286734581, "eval_episode/length": 204.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9951219512195122}
{"step": 30080, "time": 13643.841383934021, "episode/length": 278.0, "episode/score": 5.4067138745517695, "episode/reward_rate": 0.982078853046595, "episode/intrinsic_return": 0.30671387003485506}
{"step": 30136, "time": 13670.887713432312, "episode/length": 380.0, "episode/score": 4.449129796239504, "episode/reward_rate": 0.9921259842519685, "episode/intrinsic_return": 0.34912966840965964}
{"step": 30320, "time": 13756.328869104385, "episode/length": 157.0, "episode/score": 2.2451081766425887, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.1451080950296273}
{"step": 30552, "time": 13863.668212890625, "episode/length": 180.0, "episode/score": 2.2841354121010227, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.18413534541832632}
{"step": 30712, "time": 13938.62597322464, "episode/length": 132.0, "episode/score": 3.1998558945654167, "episode/reward_rate": 0.9924812030075187, "episode/intrinsic_return": 0.09985572497157591}
{"step": 30744, "time": 13954.739940166473, "episode/length": 143.0, "episode/score": 3.23776928061784, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.13776915514540633}
{"step": 31080, "time": 14109.792563676834, "episode/length": 184.0, "episode/score": 3.263641463417798, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.16364143416262777}
{"step": 31288, "time": 14206.313621759415, "episode/length": 143.0, "episode/score": 2.233266514570232, "episode/reward_rate": 0.9652777777777778, "episode/intrinsic_return": 0.13326646337077364}
{"step": 31448, "time": 14280.930168390274, "episode/length": 170.0, "episode/score": 3.2437303706533385, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.14373033534457136}
{"step": 31539, "time": 14324.638694047928, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.116456257548309, "train/action_min": 0.0, "train/action_std": 3.936881468491854, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.028181573322069817, "train/actor_opt_grad_steps": 28940.0, "train/actor_opt_loss": -14.29600839416726, "train/adv_mag": 0.7149408160200441, "train/adv_max": 0.629518074977801, "train/adv_mean": 0.0008752431919206635, "train/adv_min": -0.5439679526908386, "train/adv_std": 0.04225326484240196, "train/cont_avg": 0.9946407004830918, "train/cont_loss_mean": 0.0001597238404699148, "train/cont_loss_std": 0.004965352715431625, "train/cont_neg_acc": 0.9972222222798113, "train/cont_neg_loss": 0.01519468662934891, "train/cont_pos_acc": 0.9999857395167512, "train/cont_pos_loss": 6.533815415182751e-05, "train/cont_pred": 0.9946416213316618, "train/cont_rate": 0.9946407004830918, "train/dyn_loss_mean": 2.706064747151545, "train/dyn_loss_std": 7.531154609532748, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.2538927842453482, "train/extr_critic_critic_opt_grad_steps": 28940.0, "train/extr_critic_critic_opt_loss": 14882.494102883455, "train/extr_critic_mag": 16.477007534192957, "train/extr_critic_max": 16.477007534192957, "train/extr_critic_mean": 3.0800934419539816, "train/extr_critic_min": -0.5833965522655542, "train/extr_critic_std": 3.698947759066227, "train/extr_return_normed_mag": 1.5055118851039722, "train/extr_return_normed_max": 1.5055118851039722, "train/extr_return_normed_mean": 0.2872351012080188, "train/extr_return_normed_min": -0.06268656786513213, "train/extr_return_normed_std": 0.3275141281206251, "train/extr_return_rate": 0.7079694793708082, "train/extr_return_raw_mag": 17.019148845027612, "train/extr_return_raw_max": 17.019148845027612, "train/extr_return_raw_mean": 3.090028426497455, "train/extr_return_raw_min": -0.9130787709772875, "train/extr_return_raw_std": 3.747455537031238, "train/extr_reward_mag": 1.0132858269456504, "train/extr_reward_max": 1.0132858269456504, "train/extr_reward_mean": 0.02779863930446802, "train/extr_reward_min": -0.657587466608499, "train/extr_reward_std": 0.16178784893762663, "train/image_loss_mean": 2.2540280957152876, "train/image_loss_std": 5.120171861372132, "train/model_loss_mean": 3.9446760237504894, "train/model_loss_std": 8.618160346855865, "train/model_opt_grad_norm": 42.5223465799128, "train/model_opt_grad_steps": 28913.299516908213, "train/model_opt_loss": 5169.156073086504, "train/model_opt_model_opt_grad_overflow": 0.004830917874396135, "train/model_opt_model_opt_grad_scale": 1304.3478260869565, "train/policy_entropy_mag": 2.4902652622996895, "train/policy_entropy_max": 2.4902652622996895, "train/policy_entropy_mean": 0.6744914005919931, "train/policy_entropy_min": 0.07937506147196903, "train/policy_entropy_std": 0.7009825049967006, "train/policy_logprob_mag": 7.43838345946897, "train/policy_logprob_max": -0.009455671848882224, "train/policy_logprob_mean": -0.6743627256817288, "train/policy_logprob_min": -7.43838345946897, "train/policy_logprob_std": 1.1929093651149585, "train/policy_randomness_mag": 0.8789543558434012, "train/policy_randomness_max": 0.8789543558434012, "train/policy_randomness_mean": 0.23806586552069384, "train/policy_randomness_min": 0.028015913333797802, "train/policy_randomness_std": 0.24741606241550998, "train/post_ent_mag": 35.158691479963956, "train/post_ent_max": 35.158691479963956, "train/post_ent_mean": 18.43960832052185, "train/post_ent_min": 10.658050891857792, "train/post_ent_std": 3.588884737180627, "train/prior_ent_mag": 72.22843166480318, "train/prior_ent_max": 72.22843166480318, "train/prior_ent_mean": 21.235861110226544, "train/prior_ent_min": 11.86838147720853, "train/prior_ent_std": 8.696343454185891, "train/rep_loss_mean": 2.706064747151545, "train/rep_loss_std": 7.531154609532748, "train/reward_avg": 0.013306155341906824, "train/reward_loss_mean": 0.0668493380797082, "train/reward_loss_std": 0.14522101384574088, "train/reward_max_data": 1.0075302233442591, "train/reward_max_pred": 1.008060587777032, "train/reward_neg_acc": 0.9995793645508624, "train/reward_neg_loss": 0.050762279166115656, "train/reward_pos_acc": 0.8932853643445001, "train/reward_pos_loss": 0.7208520349673027, "train/reward_pred": 0.013203860085079636, "train/reward_rate": 0.023984752415458936, "train_stats/sum_log_reward": 3.0999999046325684, "train_stats/max_log_achievement_collect_drink": 3.076923076923077, "train_stats/max_log_achievement_collect_sapling": 1.6923076923076923, "train_stats/max_log_achievement_collect_wood": 0.8461538461538461, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_eat_cow": 0.07692307692307693, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_place_plant": 1.6923076923076923, "train_stats/max_log_achievement_place_table": 0.15384615384615385, "train_stats/max_log_achievement_wake_up": 2.6923076923076925, "train_stats/mean_log_entropy": 0.5123154727312235, "eval_stats/sum_log_reward": 2.5999999195337296, "eval_stats/max_log_achievement_collect_drink": 0.75, "eval_stats/max_log_achievement_collect_sapling": 2.0, "eval_stats/max_log_achievement_collect_wood": 0.625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_place_plant": 2.0, "eval_stats/max_log_achievement_place_table": 0.125, "eval_stats/max_log_achievement_wake_up": 2.0, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9912109375, "report/cont_loss_mean": 9.1483968844841e-07, "report/cont_loss_std": 1.940307811310049e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 1.9150174921378493e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 7.531471055699512e-07, "report/cont_pred": 0.9912102222442627, "report/cont_rate": 0.9912109375, "report/dyn_loss_mean": 2.6098296642303467, "report/dyn_loss_std": 7.273514747619629, "report/image_loss_mean": 1.493391990661621, "report/image_loss_std": 3.5888166427612305, "report/model_loss_mean": 3.128197193145752, "report/model_loss_std": 6.840260982513428, "report/post_ent_mag": 37.3657341003418, "report/post_ent_max": 37.3657341003418, "report/post_ent_mean": 18.9301700592041, "report/post_ent_min": 11.353635787963867, "report/post_ent_std": 3.2460618019104004, "report/prior_ent_mag": 71.78936767578125, "report/prior_ent_max": 71.78936767578125, "report/prior_ent_mean": 21.59107208251953, "report/prior_ent_min": 12.794682502746582, "report/prior_ent_std": 8.874267578125, "report/rep_loss_mean": 2.6098296642303467, "report/rep_loss_std": 7.273514747619629, "report/reward_avg": 0.019310276955366135, "report/reward_loss_mean": 0.06890616565942764, "report/reward_loss_std": 0.1362602263689041, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0018246173858643, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.04935614392161369, "report/reward_pos_acc": 0.9032257795333862, "report/reward_pos_loss": 0.6951373815536499, "report/reward_pred": 0.019118331372737885, "report/reward_rate": 0.0302734375, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 7.01819226378575e-05, "eval/cont_loss_std": 0.0018465168541297317, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.017711853608489037, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 9.988901865654043e-07, "eval/cont_pred": 0.9961601495742798, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 25.96013832092285, "eval/dyn_loss_std": 13.23254108428955, "eval/image_loss_mean": 72.3658447265625, "eval/image_loss_std": 56.929622650146484, "eval/model_loss_mean": 88.09657287597656, "eval/model_loss_std": 61.03874588012695, "eval/post_ent_mag": 37.98196029663086, "eval/post_ent_max": 37.98196029663086, "eval/post_ent_mean": 25.769939422607422, "eval/post_ent_min": 13.299247741699219, "eval/post_ent_std": 4.565630912780762, "eval/prior_ent_mag": 71.78936767578125, "eval/prior_ent_max": 71.78936767578125, "eval/prior_ent_mean": 31.50131607055664, "eval/prior_ent_min": 14.75958251953125, "eval/prior_ent_std": 8.975646018981934, "eval/rep_loss_mean": 25.96013832092285, "eval/rep_loss_std": 13.23254108428955, "eval/reward_avg": 0.012988281436264515, "eval/reward_loss_mean": 0.1545809507369995, "eval/reward_loss_std": 1.0515433549880981, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0018112659454346, "eval/reward_neg_acc": 0.9990079998970032, "eval/reward_neg_loss": 0.0627991333603859, "eval/reward_pos_acc": 0.4375, "eval/reward_pos_loss": 5.936835289001465, "eval/reward_pred": 0.005851798225194216, "eval/reward_rate": 0.015625, "replay/size": 31035.0, "replay/inserts": 2071.0, "replay/samples": 33136.0, "replay/insert_wait_avg": 2.5676909648871317e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.12714080313218e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 8368.0, "eval_replay/inserts": 1640.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.237741330774819e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.791685104370117e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3252465724945, "timer/env.step_count": 259.0, "timer/env.step_total": 27.127121686935425, "timer/env.step_frac": 0.027118301552303666, "timer/env.step_avg": 0.10473792157117924, "timer/env.step_min": 0.024231910705566406, "timer/env.step_max": 1.6663260459899902, "timer/replay._sample_count": 33136.0, "timer/replay._sample_total": 16.545599222183228, "timer/replay._sample_frac": 0.016540219572458978, "timer/replay._sample_avg": 0.0004993239745950998, "timer/replay._sample_min": 0.0003573894500732422, "timer/replay._sample_max": 0.011493444442749023, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 464.0, "timer/agent.policy_total": 8.748240947723389, "timer/agent.policy_frac": 0.00874539653747447, "timer/agent.policy_avg": 0.018853967559748684, "timer/agent.policy_min": 0.010145902633666992, "timer/agent.policy_max": 0.1529374122619629, "timer/dataset_train_count": 2071.0, "timer/dataset_train_total": 0.3940587043762207, "timer/dataset_train_frac": 0.00039393057980533825, "timer/dataset_train_avg": 0.00019027460375481444, "timer/dataset_train_min": 9.489059448242188e-05, "timer/dataset_train_max": 0.007490873336791992, "timer/agent.train_count": 2071.0, "timer/agent.train_total": 924.2724757194519, "timer/agent.train_frac": 0.9239719570073542, "timer/agent.train_avg": 0.4462928419697981, "timer/agent.train_min": 0.43549346923828125, "timer/agent.train_max": 0.6061198711395264, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4687159061431885, "timer/agent.report_frac": 0.0004685635074683884, "timer/agent.report_avg": 0.23435795307159424, "timer/agent.report_min": 0.22427630424499512, "timer/agent.report_max": 0.24443960189819336, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.170967102050781e-05, "timer/dataset_eval_frac": 3.169936091202091e-08, "timer/dataset_eval_avg": 3.170967102050781e-05, "timer/dataset_eval_min": 3.170967102050781e-05, "timer/dataset_eval_max": 3.170967102050781e-05, "fps": 2.0703001189866512}
{"step": 31976, "time": 14524.870628595352, "episode/length": 206.0, "episode/score": 3.3267332009158963, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.22673312064171114}
{"step": 32032, "time": 14551.988700389862, "episode/length": 164.0, "episode/score": 4.228050642723247, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.1280504578644468}
{"step": 32040, "time": 14557.26088643074, "episode/length": 185.0, "episode/score": 3.267991337891999, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.1679913009243137}
{"step": 32048, "time": 14562.403813838959, "episode/length": 263.0, "episode/score": 4.367566844322482, "episode/reward_rate": 0.9962121212121212, "episode/intrinsic_return": 0.26756671148677924}
{"step": 32160, "time": 14615.19984459877, "episode/length": 134.0, "episode/score": 5.222136180052985, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.1221361401167087}
{"step": 32176, "time": 14624.16778087616, "episode/length": 178.0, "episode/score": 1.2385177330859278, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.13851769940697523}
{"step": 32512, "time": 14779.343230009079, "episode/length": 58.0, "episode/score": 2.161582407017704, "episode/reward_rate": 0.9322033898305084, "episode/intrinsic_return": 0.06158234033500776}
{"step": 32680, "time": 14857.752696275711, "episode/length": 153.0, "episode/score": 3.2369086880612485, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.13690853761772814}
{"step": 33224, "time": 15108.953204870224, "episode/length": 241.0, "episode/score": 4.360081310843043, "episode/reward_rate": 0.9752066115702479, "episode/intrinsic_return": 0.2600811938689276}
{"step": 33264, "time": 15128.605169534683, "episode/length": 151.0, "episode/score": 4.241890539942688, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.14189033018556074}
{"step": 33392, "time": 15188.579826831818, "episode/length": 176.0, "episode/score": 4.265464987684709, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.16546486372567415}
{"step": 33432, "time": 15208.377203941345, "episode/length": 158.0, "episode/score": 2.267661595298705, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.16766150195689988}
{"step": 33472, "time": 15228.278512954712, "episode/length": 179.0, "episode/score": 4.310079010894697, "episode/reward_rate": 0.9611111111111111, "episode/intrinsic_return": 0.2100788649331662}
{"step": 33640, "time": 15306.288700580597, "episode/length": 182.0, "episode/score": 1.2781198949996906, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.17811980130863958}
{"step": 33676, "time": 15324.670868396759, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.849675258743429, "train/action_min": 0.0, "train/action_std": 3.955813026873865, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.030391508643733006, "train/actor_opt_grad_steps": 31045.0, "train/actor_opt_loss": -7.343753277628778, "train/adv_mag": 0.6652855235978822, "train/adv_max": 0.6178832756024655, "train/adv_mean": 0.002996424769526554, "train/adv_min": -0.5013164250510875, "train/adv_std": 0.04580877728272821, "train/cont_avg": 0.9943916106892523, "train/cont_loss_mean": 4.344455985749625e-05, "train/cont_loss_std": 0.0012328778500588953, "train/cont_neg_acc": 0.9976078700011884, "train/cont_neg_loss": 0.006000995612903097, "train/cont_pos_acc": 0.9999999844025229, "train/cont_pos_loss": 1.2025525122186787e-05, "train/cont_pred": 0.9943966851613232, "train/cont_rate": 0.9943916106892523, "train/dyn_loss_mean": 2.756948165804426, "train/dyn_loss_std": 7.558611611339534, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.3169954187959154, "train/extr_critic_critic_opt_grad_steps": 31045.0, "train/extr_critic_critic_opt_loss": 15340.7747015552, "train/extr_critic_mag": 15.445476010581043, "train/extr_critic_max": 15.445476010581043, "train/extr_critic_mean": 3.137992585930869, "train/extr_critic_min": -0.4788612177438825, "train/extr_critic_std": 3.400617049119183, "train/extr_return_normed_mag": 1.4304378954606636, "train/extr_return_normed_max": 1.4304378954606636, "train/extr_return_normed_mean": 0.2873773433476965, "train/extr_return_normed_min": -0.07927917550692212, "train/extr_return_normed_std": 0.31525147859459723, "train/extr_return_rate": 0.8047057966762614, "train/extr_return_raw_mag": 15.690814120747218, "train/extr_return_raw_max": 15.690814120747218, "train/extr_return_raw_mean": 3.1701998688350215, "train/extr_return_raw_min": -0.8039672490313788, "train/extr_return_raw_std": 3.4422002117210457, "train/extr_reward_mag": 1.0108000162605928, "train/extr_reward_max": 1.0108000162605928, "train/extr_reward_mean": 0.025215204620176804, "train/extr_reward_min": -0.6381238331304533, "train/extr_reward_std": 0.15463186180758698, "train/image_loss_mean": 2.1295746314191373, "train/image_loss_std": 5.0035008988647816, "train/model_loss_mean": 3.8510563072757185, "train/model_loss_std": 8.55975518939651, "train/model_opt_grad_norm": 39.316531912188665, "train/model_opt_grad_steps": 31016.21495327103, "train/model_opt_loss": 3678.9247094270227, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 957.9439252336449, "train/policy_entropy_mag": 2.498690785648667, "train/policy_entropy_max": 2.498690785648667, "train/policy_entropy_mean": 0.6214211123568989, "train/policy_entropy_min": 0.07937504730631258, "train/policy_entropy_std": 0.6649138852257594, "train/policy_logprob_mag": 7.438383461158966, "train/policy_logprob_max": -0.009455660880308286, "train/policy_logprob_mean": -0.6215047018828793, "train/policy_logprob_min": -7.438383461158966, "train/policy_logprob_std": 1.1733420067858473, "train/policy_randomness_mag": 0.8819281960202154, "train/policy_randomness_max": 0.8819281960202154, "train/policy_randomness_mean": 0.21933438176306608, "train/policy_randomness_min": 0.028015908332558993, "train/policy_randomness_std": 0.2346854253767807, "train/post_ent_mag": 35.16428319984507, "train/post_ent_max": 35.16428319984507, "train/post_ent_mean": 18.725375050696258, "train/post_ent_min": 10.652698735210382, "train/post_ent_std": 3.608273980773498, "train/prior_ent_mag": 72.33677987071955, "train/prior_ent_max": 72.33677987071955, "train/prior_ent_mean": 21.567497574280356, "train/prior_ent_min": 11.955623020635587, "train/prior_ent_std": 8.728111258177, "train/rep_loss_mean": 2.756948165804426, "train/rep_loss_std": 7.558611611339534, "train/reward_avg": 0.013727286331155381, "train/reward_loss_mean": 0.06726934642435234, "train/reward_loss_std": 0.1513294351992206, "train/reward_max_data": 1.003586477765413, "train/reward_max_pred": 1.0046815571383896, "train/reward_neg_acc": 0.9994899329738082, "train/reward_neg_loss": 0.050927920580328065, "train/reward_pos_acc": 0.9058490724207084, "train/reward_pos_loss": 0.7246079205352569, "train/reward_pred": 0.01361069841110191, "train/reward_rate": 0.024226964077102803, "train_stats/sum_log_reward": 3.242857107094356, "train_stats/max_log_achievement_collect_drink": 3.0, "train_stats/max_log_achievement_collect_sapling": 2.142857142857143, "train_stats/max_log_achievement_collect_wood": 1.1428571428571428, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_place_plant": 1.9285714285714286, "train_stats/max_log_achievement_place_table": 0.42857142857142855, "train_stats/max_log_achievement_wake_up": 2.357142857142857, "train_stats/mean_log_entropy": 0.6040095133440835, "train_stats/max_log_achievement_make_wood_sword": 0.1, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 5.753525329055265e-06, "report/cont_loss_std": 0.00011492982594063506, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0006829429185017943, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 1.0924387652266887e-06, "report/cont_pred": 0.993167519569397, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 2.5873444080352783, "report/dyn_loss_std": 7.569784164428711, "report/image_loss_mean": 1.3013880252838135, "report/image_loss_std": 3.500854015350342, "report/model_loss_mean": 2.920461654663086, "report/model_loss_std": 7.444010257720947, "report/post_ent_mag": 37.075096130371094, "report/post_ent_max": 37.075096130371094, "report/post_ent_mean": 18.40328598022461, "report/post_ent_min": 9.82529067993164, "report/post_ent_std": 3.3951945304870605, "report/prior_ent_mag": 72.31733703613281, "report/prior_ent_max": 72.31733703613281, "report/prior_ent_mean": 21.185720443725586, "report/prior_ent_min": 10.806020736694336, "report/prior_ent_std": 8.894683837890625, "report/rep_loss_mean": 2.5873444080352783, "report/rep_loss_std": 7.569784164428711, "report/reward_avg": 0.01814364641904831, "report/reward_loss_mean": 0.06666138768196106, "report/reward_loss_std": 0.14841768145561218, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0018279552459717, "report/reward_neg_acc": 0.9999999403953552, "report/reward_neg_loss": 0.0484279990196228, "report/reward_pos_acc": 0.9000000357627869, "report/reward_pos_loss": 0.6707942485809326, "report/reward_pred": 0.01833951659500599, "report/reward_rate": 0.029296875, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.00967054907232523, "eval/cont_loss_std": 0.22819261252880096, "eval/cont_neg_acc": 0.5, "eval/cont_neg_loss": 2.4670073986053467, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 3.3933920349227265e-05, "eval/cont_pred": 0.9982739686965942, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 25.357824325561523, "eval/dyn_loss_std": 14.738632202148438, "eval/image_loss_mean": 45.35657501220703, "eval/image_loss_std": 49.967586517333984, "eval/model_loss_mean": 60.75248718261719, "eval/model_loss_std": 55.4437141418457, "eval/post_ent_mag": 37.075096130371094, "eval/post_ent_max": 37.075096130371094, "eval/post_ent_mean": 23.579696655273438, "eval/post_ent_min": 12.315555572509766, "eval/post_ent_std": 4.364636421203613, "eval/prior_ent_mag": 72.31733703613281, "eval/prior_ent_max": 72.31733703613281, "eval/prior_ent_mean": 30.103025436401367, "eval/prior_ent_min": 13.440418243408203, "eval/prior_ent_std": 9.707905769348145, "eval/rep_loss_mean": 25.357824325561523, "eval/rep_loss_std": 14.738632202148438, "eval/reward_avg": 0.01699218712747097, "eval/reward_loss_mean": 0.17154625058174133, "eval/reward_loss_std": 1.1568899154663086, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 1.0024282932281494, "eval/reward_neg_acc": 0.9980059862136841, "eval/reward_neg_loss": 0.08205652981996536, "eval/reward_pos_acc": 0.5714285969734192, "eval/reward_pos_loss": 4.445746421813965, "eval/reward_pred": 0.011473581194877625, "eval/reward_rate": 0.0205078125, "replay/size": 33172.0, "replay/inserts": 2137.0, "replay/samples": 34192.0, "replay/insert_wait_avg": 2.539040722130725e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.060782101871703e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 8368.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 8.344650268554688e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0206868648529, "timer/env.step_count": 267.0, "timer/env.step_total": 28.92370295524597, "timer/env.step_frac": 0.028923104626889427, "timer/env.step_avg": 0.10832847548781263, "timer/env.step_min": 0.0242156982421875, "timer/env.step_max": 1.7434113025665283, "timer/replay._sample_count": 34192.0, "timer/replay._sample_total": 17.115387439727783, "timer/replay._sample_frac": 0.01711503338334523, "timer/replay._sample_avg": 0.0005005670168380845, "timer/replay._sample_min": 0.0003376007080078125, "timer/replay._sample_max": 0.029598712921142578, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 267.0, "timer/agent.policy_total": 4.3773369789123535, "timer/agent.policy_frac": 0.0043772464274070815, "timer/agent.policy_avg": 0.016394520520270985, "timer/agent.policy_min": 0.01482081413269043, "timer/agent.policy_max": 0.04067111015319824, "timer/dataset_train_count": 2137.0, "timer/dataset_train_total": 0.4021449089050293, "timer/dataset_train_frac": 0.0004021365899597404, "timer/dataset_train_avg": 0.0001881819882569159, "timer/dataset_train_min": 9.441375732421875e-05, "timer/dataset_train_max": 0.0012290477752685547, "timer/agent.train_count": 2137.0, "timer/agent.train_total": 954.665757894516, "timer/agent.train_frac": 0.9546460092615401, "timer/agent.train_avg": 0.4467317538111914, "timer/agent.train_min": 0.4364025592803955, "timer/agent.train_max": 0.6031584739685059, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47644495964050293, "timer/agent.report_frac": 0.0004764351036919017, "timer/agent.report_avg": 0.23822247982025146, "timer/agent.report_min": 0.2311408519744873, "timer/agent.report_max": 0.24530410766601562, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0517578125e-05, "timer/dataset_eval_frac": 3.0516946825045306e-08, "timer/dataset_eval_avg": 3.0517578125e-05, "timer/dataset_eval_min": 3.0517578125e-05, "timer/dataset_eval_max": 3.0517578125e-05, "fps": 2.136928109349997}
{"step": 33784, "time": 15374.180398464203, "episode/length": 158.0, "episode/score": 3.253849352542602, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.15384922823432134}
{"step": 34280, "time": 15603.620378017426, "episode/length": 199.0, "episode/score": 3.3128172938850184, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.21281721637569717}
{"step": 34456, "time": 15685.683293104172, "episode/length": 148.0, "episode/score": 3.2400875110615743, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.140087360094185}
{"step": 34664, "time": 15782.643643379211, "episode/length": 153.0, "episode/score": 3.240566238655447, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.1405661649587273}
{"step": 34680, "time": 15791.490223884583, "episode/length": 129.0, "episode/score": 3.214223492106612, "episode/reward_rate": 0.9923076923076923, "episode/intrinsic_return": 0.114223401325944}
{"step": 34712, "time": 15807.864228010178, "episode/length": 164.0, "episode/score": 3.2444210331905197, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.14442090946431563}
{"step": 34832, "time": 15864.58170080185, "episode/length": 169.0, "episode/score": 5.264218782005628, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.16421869174882886}
{"step": 34840, "time": 15869.771458148956, "episode/length": 201.0, "episode/score": 4.319085664277736, "episode/reward_rate": 0.9603960396039604, "episode/intrinsic_return": 0.21908555196023372}
{"step": 35088, "time": 15984.595758914948, "episode/length": 162.0, "episode/score": 2.251440077965526, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.15144006122500286}
{"step": 35584, "time": 16212.226746320724, "episode/length": 162.0, "episode/score": 4.255079576270873, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.15507951546715049}
{"step": 35826, "time": 16324.764613389969, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.683266715116279, "train/action_min": 0.0, "train/action_std": 3.7631230808967766, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.032570966748997225, "train/actor_opt_grad_steps": 33190.0, "train/actor_opt_loss": -14.361299217578976, "train/adv_mag": 0.6599287368530451, "train/adv_max": 0.5950470369915629, "train/adv_mean": 0.0012989985688342807, "train/adv_min": -0.5014239570429159, "train/adv_std": 0.04666660814437755, "train/cont_avg": 0.9943450218023255, "train/cont_loss_mean": 3.48869750820181e-05, "train/cont_loss_std": 0.0010509012190015635, "train/cont_neg_acc": 0.9983720931895944, "train/cont_neg_loss": 0.00372764891901043, "train/cont_pos_acc": 0.9999954101651214, "train/cont_pos_loss": 1.6445674910877388e-05, "train/cont_pred": 0.9943464947301288, "train/cont_rate": 0.9943450218023255, "train/dyn_loss_mean": 2.7045371976009633, "train/dyn_loss_std": 7.549676815299101, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.2301871319149815, "train/extr_critic_critic_opt_grad_steps": 33190.0, "train/extr_critic_critic_opt_loss": 14751.929978197675, "train/extr_critic_mag": 14.178656374022019, "train/extr_critic_max": 14.178656374022019, "train/extr_critic_mean": 3.355100066162819, "train/extr_critic_min": -0.43681102963381035, "train/extr_critic_std": 3.119204930372016, "train/extr_return_normed_mag": 1.443763977982277, "train/extr_return_normed_max": 1.443763977982277, "train/extr_return_normed_mean": 0.3203041983898296, "train/extr_return_normed_min": -0.09354355657516523, "train/extr_return_normed_std": 0.3181704191274421, "train/extr_return_rate": 0.88258997950443, "train/extr_return_raw_mag": 14.48969994034878, "train/extr_return_raw_max": 14.48969994034878, "train/extr_return_raw_mean": 3.368575269122456, "train/extr_return_raw_min": -0.7307870529418767, "train/extr_return_raw_std": 3.1585180376851283, "train/extr_reward_mag": 1.0130604289298835, "train/extr_reward_max": 1.0130604289298835, "train/extr_reward_mean": 0.027235446177249732, "train/extr_reward_min": -0.6253694129544635, "train/extr_reward_std": 0.15965772721656532, "train/image_loss_mean": 2.050117319683696, "train/image_loss_std": 4.9220699609712115, "train/model_loss_mean": 3.7411291765612225, "train/model_loss_std": 8.514202550400135, "train/model_opt_grad_norm": 37.52079527655313, "train/model_opt_grad_steps": 33160.02790697674, "train/model_opt_loss": 5869.133951444404, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1563.953488372093, "train/policy_entropy_mag": 2.466203018676403, "train/policy_entropy_max": 2.466203018676403, "train/policy_entropy_mean": 0.5330105403134989, "train/policy_entropy_min": 0.07937503519446351, "train/policy_entropy_std": 0.5969230290069136, "train/policy_logprob_mag": 7.438383568164914, "train/policy_logprob_max": -0.009455661965144234, "train/policy_logprob_mean": -0.5327915721161421, "train/policy_logprob_min": -7.438383568164914, "train/policy_logprob_std": 1.1172914981842041, "train/policy_randomness_mag": 0.8704614389774411, "train/policy_randomness_max": 0.8704614389774411, "train/policy_randomness_mean": 0.1881293307903201, "train/policy_randomness_min": 0.028015904102561086, "train/policy_randomness_std": 0.2106876363587934, "train/post_ent_mag": 35.738828845356785, "train/post_ent_max": 35.738828845356785, "train/post_ent_mean": 18.76520451390466, "train/post_ent_min": 10.815941420266794, "train/post_ent_std": 3.545544309394304, "train/prior_ent_mag": 72.58166244861691, "train/prior_ent_max": 72.58166244861691, "train/prior_ent_mean": 21.569730669953103, "train/prior_ent_min": 12.043227661487668, "train/prior_ent_std": 8.729421085535094, "train/rep_loss_mean": 2.7045371976009633, "train/rep_loss_std": 7.549676815299101, "train/reward_avg": 0.01403282702532272, "train/reward_loss_mean": 0.06825465002032213, "train/reward_loss_std": 0.15198293785716213, "train/reward_max_data": 1.0049709597299266, "train/reward_max_pred": 1.0058149138162302, "train/reward_neg_acc": 0.9994262723035591, "train/reward_neg_loss": 0.051523914326762045, "train/reward_pos_acc": 0.9044047646744307, "train/reward_pos_loss": 0.7133196575697078, "train/reward_pred": 0.014050465920766772, "train/reward_rate": 0.025236191860465117, "train_stats/sum_log_reward": 3.399999904632568, "train_stats/max_log_achievement_collect_drink": 6.3, "train_stats/max_log_achievement_collect_sapling": 1.5, "train_stats/max_log_achievement_collect_wood": 1.3, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.4, "train_stats/max_log_achievement_place_table": 0.4, "train_stats/max_log_achievement_wake_up": 2.3, "train_stats/mean_log_entropy": 0.44692654311656954, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 1.8026366888079792e-06, "report/cont_loss_std": 5.568873802985763e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 6.617655890295282e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.486768496761215e-06, "report/cont_pred": 0.995116114616394, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 3.044497013092041, "report/dyn_loss_std": 7.885108470916748, "report/image_loss_mean": 2.55596923828125, "report/image_loss_std": 7.598718166351318, "report/model_loss_mean": 4.448534965515137, "report/model_loss_std": 11.324437141418457, "report/post_ent_mag": 31.337173461914062, "report/post_ent_max": 31.337173461914062, "report/post_ent_mean": 18.96182632446289, "report/post_ent_min": 11.286598205566406, "report/post_ent_std": 3.598151683807373, "report/prior_ent_mag": 72.84349822998047, "report/prior_ent_max": 72.84349822998047, "report/prior_ent_mean": 22.033096313476562, "report/prior_ent_min": 12.406373977661133, "report/prior_ent_std": 8.965972900390625, "report/rep_loss_mean": 3.044497013092041, "report/rep_loss_std": 7.885108470916748, "report/reward_avg": 0.018946245312690735, "report/reward_loss_mean": 0.06586597114801407, "report/reward_loss_std": 0.22324778139591217, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0018279552459717, "report/reward_neg_acc": 0.9979960322380066, "report/reward_neg_loss": 0.045758891850709915, "report/reward_pos_acc": 0.8461538553237915, "report/reward_pos_loss": 0.8376685380935669, "report/reward_pred": 0.01814928650856018, "report/reward_rate": 0.025390625, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.020405780524015427, "eval/cont_loss_std": 0.4664691984653473, "eval/cont_neg_acc": 0.3333333432674408, "eval/cont_neg_loss": 6.964688301086426, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.4237234609026928e-06, "eval/cont_pred": 0.9990251660346985, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 28.000680923461914, "eval/dyn_loss_std": 15.283082962036133, "eval/image_loss_mean": 69.50274658203125, "eval/image_loss_std": 66.92096710205078, "eval/model_loss_mean": 86.62422180175781, "eval/model_loss_std": 72.41177368164062, "eval/post_ent_mag": 37.99524688720703, "eval/post_ent_max": 37.99524688720703, "eval/post_ent_mean": 24.54348373413086, "eval/post_ent_min": 13.621874809265137, "eval/post_ent_std": 4.695071220397949, "eval/prior_ent_mag": 72.84349822998047, "eval/prior_ent_max": 72.84349822998047, "eval/prior_ent_mean": 31.981510162353516, "eval/prior_ent_min": 13.948567390441895, "eval/prior_ent_std": 10.153058052062988, "eval/rep_loss_mean": 28.000680923461914, "eval/rep_loss_std": 15.283082962036133, "eval/reward_avg": 0.02080078050494194, "eval/reward_loss_mean": 0.30066943168640137, "eval/reward_loss_std": 1.6308919191360474, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0006413459777832, "eval/reward_neg_acc": 0.9969969987869263, "eval/reward_neg_loss": 0.17858533561229706, "eval/reward_pos_acc": 0.4399999976158142, "eval/reward_pos_loss": 5.179149150848389, "eval/reward_pred": 0.010191809386014938, "eval/reward_rate": 0.0244140625, "replay/size": 35322.0, "replay/inserts": 2150.0, "replay/samples": 34400.0, "replay/insert_wait_avg": 2.6248222173646437e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.836832556613656e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 8368.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 8.940696716308594e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0825464725494, "timer/env.step_count": 269.0, "timer/env.step_total": 23.09651255607605, "timer/env.step_frac": 0.023094606177801152, "timer/env.step_avg": 0.08586064147240167, "timer/env.step_min": 0.023726463317871094, "timer/env.step_max": 1.77445387840271, "timer/replay._sample_count": 34400.0, "timer/replay._sample_total": 16.680800914764404, "timer/replay._sample_frac": 0.016679424087141854, "timer/replay._sample_avg": 0.00048490700333617457, "timer/replay._sample_min": 0.0003249645233154297, "timer/replay._sample_max": 0.02576422691345215, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 269.0, "timer/agent.policy_total": 4.295237064361572, "timer/agent.policy_frac": 0.004294882536958132, "timer/agent.policy_avg": 0.01596742403108391, "timer/agent.policy_min": 0.01447439193725586, "timer/agent.policy_max": 0.04683113098144531, "timer/dataset_train_count": 2150.0, "timer/dataset_train_total": 0.4027271270751953, "timer/dataset_train_frac": 0.0004026938861153793, "timer/dataset_train_avg": 0.00018731494282567225, "timer/dataset_train_min": 9.274482727050781e-05, "timer/dataset_train_max": 0.0022895336151123047, "timer/agent.train_count": 2150.0, "timer/agent.train_total": 961.0569176673889, "timer/agent.train_frac": 0.9609775923569408, "timer/agent.train_avg": 0.4470032175197158, "timer/agent.train_min": 0.43470048904418945, "timer/agent.train_max": 0.580646276473999, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4737875461578369, "timer/agent.report_frac": 0.00047374843989524774, "timer/agent.report_avg": 0.23689377307891846, "timer/agent.report_min": 0.2297070026397705, "timer/agent.report_max": 0.2440805435180664, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.765655517578125e-05, "timer/dataset_eval_frac": 2.7654272413142624e-08, "timer/dataset_eval_avg": 2.765655517578125e-05, "timer/dataset_eval_min": 2.765655517578125e-05, "timer/dataset_eval_max": 2.765655517578125e-05, "fps": 2.1497942133837458}
{"step": 35904, "time": 16360.545118808746, "episode/length": 154.0, "episode/score": 1.2384896915100398, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.13848969624814345}
{"step": 35984, "time": 16398.85703253746, "episode/length": 190.0, "episode/score": 2.2983911067112786, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.19839104119273543}
{"step": 36008, "time": 16411.42994236946, "episode/length": 165.0, "episode/score": 3.287579960975563, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.1875799238041509}
{"step": 36008, "time": 16411.43724298477, "episode/length": 114.0, "episode/score": 2.2256977571205425, "episode/reward_rate": 0.9478260869565217, "episode/intrinsic_return": 0.12569767926197528}
{"step": 36056, "time": 16436.701520204544, "episode/length": 151.0, "episode/score": 5.226699581108733, "episode/reward_rate": 0.9605263157894737, "episode/intrinsic_return": 0.1266994702464217}
{"step": 36120, "time": 16467.571236371994, "episode/length": 175.0, "episode/score": 2.268200013751084, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.16819987556027627}
{"step": 36248, "time": 16527.724629163742, "episode/length": 176.0, "episode/score": 3.2646006249196944, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.16460054141498404}
{"step": 36304, "time": 16554.988221645355, "episode/length": 36.0, "episode/score": -0.8619504005473573, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.03804960261913948}
{"step": 37120, "time": 16930.19636654854, "episode/length": 191.0, "episode/score": 3.2816274025972234, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.18162739225954283}
{"step": 37256, "time": 16993.673900842667, "episode/length": 168.0, "episode/score": 1.2997341421578312, "episode/reward_rate": 0.9644970414201184, "episode/intrinsic_return": 0.19973412308900151}
{"step": 37344, "time": 17035.19499897957, "episode/length": 160.0, "episode/score": 5.250025706180168, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.15002559473578003}
{"step": 37376, "time": 17051.188714027405, "episode/length": 170.0, "episode/score": 2.238002874578342, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.1380028809171563}
{"step": 37624, "time": 17165.916580200195, "episode/length": 171.0, "episode/score": 5.260152217644645, "episode/reward_rate": 0.9593023255813954, "episode/intrinsic_return": 0.1601521006123221}
{"step": 37680, "time": 17193.178314447403, "episode/length": 171.0, "episode/score": 5.300986102501156, "episode/reward_rate": 0.9651162790697675, "episode/intrinsic_return": 0.200985954560565}
{"step": 37704, "time": 17205.627339601517, "episode/length": 197.0, "episode/score": 2.2956904786587984, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.195690371812816}
{"step": 37768, "time": 17236.376021146774, "episode/length": 222.0, "episode/score": 4.307463781829938, "episode/reward_rate": 0.9820627802690582, "episode/intrinsic_return": 0.20746373717884126}
{"step": 37957, "time": 17325.143614292145, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.658592546489877, "train/action_min": 0.0, "train/action_std": 3.7937325782059506, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03513922382303527, "train/actor_opt_grad_steps": 35330.0, "train/actor_opt_loss": -12.609767645955996, "train/adv_mag": 0.8061394134597599, "train/adv_max": 0.7423273049329928, "train/adv_mean": 0.0022424334785422265, "train/adv_min": -0.6205527638325669, "train/adv_std": 0.052152938423722005, "train/cont_avg": 0.9942689994131455, "train/cont_loss_mean": 0.00011097559920210589, "train/cont_loss_std": 0.00339396813954573, "train/cont_neg_acc": 0.9964472024653439, "train/cont_neg_loss": 0.009406921570752928, "train/cont_pos_acc": 0.9999815192021114, "train/cont_pos_loss": 3.9092385348958104e-05, "train/cont_pred": 0.9942725407125804, "train/cont_rate": 0.9942689994131455, "train/dyn_loss_mean": 2.7757910394892447, "train/dyn_loss_std": 7.563289902019949, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.2902852461931291, "train/extr_critic_critic_opt_grad_steps": 35330.0, "train/extr_critic_critic_opt_loss": 15528.921893339202, "train/extr_critic_mag": 15.310213505382269, "train/extr_critic_max": 15.310213505382269, "train/extr_critic_mean": 3.0564803858877907, "train/extr_critic_min": -0.5231056151815423, "train/extr_critic_std": 3.2080740413755318, "train/extr_return_normed_mag": 1.5404206007858956, "train/extr_return_normed_max": 1.5404206007858956, "train/extr_return_normed_mean": 0.3011277134709515, "train/extr_return_normed_min": -0.09115832582326003, "train/extr_return_normed_std": 0.32007937126316377, "train/extr_return_rate": 0.824318741408872, "train/extr_return_raw_mag": 15.76200531793872, "train/extr_return_raw_max": 15.76200531793872, "train/extr_return_raw_mean": 3.0796104524057237, "train/extr_return_raw_min": -0.9197626586811084, "train/extr_return_raw_std": 3.2791632839211835, "train/extr_reward_mag": 1.0156469121225562, "train/extr_reward_max": 1.0156469121225562, "train/extr_reward_mean": 0.02459933026365831, "train/extr_reward_min": -0.6519765557257782, "train/extr_reward_std": 0.15362128860234095, "train/image_loss_mean": 2.068404922462965, "train/image_loss_std": 5.078563770777743, "train/model_loss_mean": 3.8028343283514463, "train/model_loss_std": 8.660571510243305, "train/model_opt_grad_norm": 39.223353721726106, "train/model_opt_grad_steps": 35298.413145539904, "train/model_opt_loss": 5667.885219520246, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1496.4788732394366, "train/policy_entropy_mag": 2.441541481465801, "train/policy_entropy_max": 2.441541481465801, "train/policy_entropy_mean": 0.5143769327463679, "train/policy_entropy_min": 0.07937501643744993, "train/policy_entropy_std": 0.5794625865741515, "train/policy_logprob_mag": 7.438383606118216, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5134397925625385, "train/policy_logprob_min": -7.438383606118216, "train/policy_logprob_std": 1.0998945731512257, "train/policy_randomness_mag": 0.86175700140671, "train/policy_randomness_max": 0.86175700140671, "train/policy_randomness_mean": 0.18155248337228533, "train/policy_randomness_min": 0.02801589759617624, "train/policy_randomness_std": 0.20452486643209145, "train/post_ent_mag": 36.76832938753943, "train/post_ent_max": 36.76832938753943, "train/post_ent_mean": 18.85790609082146, "train/post_ent_min": 10.644921660982947, "train/post_ent_std": 3.6285233575973153, "train/prior_ent_mag": 72.71913748727718, "train/prior_ent_max": 72.71913748727718, "train/prior_ent_mean": 21.73398373384431, "train/prior_ent_min": 11.939929089076083, "train/prior_ent_std": 8.841337889013156, "train/rep_loss_mean": 2.7757910394892447, "train/rep_loss_std": 7.563289902019949, "train/reward_avg": 0.014373507954075302, "train/reward_loss_mean": 0.06884379739142919, "train/reward_loss_std": 0.15555986366781271, "train/reward_max_data": 1.0082922838103603, "train/reward_max_pred": 1.0078357340584339, "train/reward_neg_acc": 0.9994533602060847, "train/reward_neg_loss": 0.0514558710402726, "train/reward_pos_acc": 0.8935611536245391, "train/reward_pos_loss": 0.7239614305361896, "train/reward_pred": 0.01428009331786017, "train/reward_rate": 0.02591787705399061, "train_stats/sum_log_reward": 2.8499999456107616, "train_stats/max_log_achievement_collect_drink": 3.0625, "train_stats/max_log_achievement_collect_sapling": 1.1875, "train_stats/max_log_achievement_collect_wood": 1.0625, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.125, "train_stats/max_log_achievement_place_table": 0.3125, "train_stats/max_log_achievement_wake_up": 1.6875, "train_stats/mean_log_entropy": 0.49724653363227844, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 1.6488825167471077e-06, "report/cont_loss_std": 2.8341542929410934e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 6.988681707298383e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.448379407520406e-06, "report/cont_pred": 0.9970691204071045, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 2.3236165046691895, "report/dyn_loss_std": 7.200270175933838, "report/image_loss_mean": 1.5805567502975464, "report/image_loss_std": 5.147421360015869, "report/model_loss_mean": 3.037285327911377, "report/model_loss_std": 8.672286987304688, "report/post_ent_mag": 34.37196731567383, "report/post_ent_max": 34.37196731567383, "report/post_ent_mean": 17.736618041992188, "report/post_ent_min": 10.413408279418945, "report/post_ent_std": 3.2383170127868652, "report/prior_ent_mag": 72.80229187011719, "report/prior_ent_max": 72.80229187011719, "report/prior_ent_mean": 20.26957893371582, "report/prior_ent_min": 11.779192924499512, "report/prior_ent_std": 8.215353012084961, "report/rep_loss_mean": 2.3236165046691895, "report/rep_loss_std": 7.200270175933838, "report/reward_avg": 0.018242856487631798, "report/reward_loss_mean": 0.06255706399679184, "report/reward_loss_std": 0.12276512384414673, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0033869743347168, "report/reward_neg_acc": 0.9989979863166809, "report/reward_neg_loss": 0.046591997146606445, "report/reward_pos_acc": 0.9615384936332703, "report/reward_pos_loss": 0.6753700375556946, "report/reward_pred": 0.018511954694986343, "report/reward_rate": 0.025390625, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.01612991839647293, "eval/cont_loss_std": 0.42884474992752075, "eval/cont_neg_acc": 0.6000000238418579, "eval/cont_neg_loss": 3.3032047748565674, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 9.979021342587657e-07, "eval/cont_pred": 0.9970288276672363, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 25.006309509277344, "eval/dyn_loss_std": 14.549697875976562, "eval/image_loss_mean": 55.287933349609375, "eval/image_loss_std": 64.29740905761719, "eval/model_loss_mean": 70.49923706054688, "eval/model_loss_std": 69.68626403808594, "eval/post_ent_mag": 39.862945556640625, "eval/post_ent_max": 39.862945556640625, "eval/post_ent_mean": 23.775907516479492, "eval/post_ent_min": 11.888566017150879, "eval/post_ent_std": 4.85963249206543, "eval/prior_ent_mag": 72.80229187011719, "eval/prior_ent_max": 72.80229187011719, "eval/prior_ent_mean": 30.679603576660156, "eval/prior_ent_min": 13.294342041015625, "eval/prior_ent_std": 9.914875984191895, "eval/rep_loss_mean": 25.006309509277344, "eval/rep_loss_std": 14.549697875976562, "eval/reward_avg": 0.006542968563735485, "eval/reward_loss_mean": 0.19139039516448975, "eval/reward_loss_std": 1.1343761682510376, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0016283988952637, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.14400219917297363, "eval/reward_pos_acc": 0.6666666865348816, "eval/reward_pos_loss": 4.187797546386719, "eval/reward_pred": 0.005868083797395229, "eval/reward_rate": 0.01171875, "replay/size": 37453.0, "replay/inserts": 2131.0, "replay/samples": 34096.0, "replay/insert_wait_avg": 2.602018251602552e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.959080100451093e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 8368.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 7.748603820800781e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3649318218231, "timer/env.step_count": 266.0, "timer/env.step_total": 31.02184295654297, "timer/env.step_frac": 0.03101052622871063, "timer/env.step_avg": 0.11662346976143974, "timer/env.step_min": 0.023189783096313477, "timer/env.step_max": 3.177337646484375, "timer/replay._sample_count": 34096.0, "timer/replay._sample_total": 16.432616710662842, "timer/replay._sample_frac": 0.016426622113528553, "timer/replay._sample_avg": 0.00048195145209593035, "timer/replay._sample_min": 0.00033974647521972656, "timer/replay._sample_max": 0.03636288642883301, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 266.0, "timer/agent.policy_total": 4.094457387924194, "timer/agent.policy_frac": 0.0040929637352116474, "timer/agent.policy_avg": 0.015392696947083437, "timer/agent.policy_min": 0.014329671859741211, "timer/agent.policy_max": 0.04627656936645508, "timer/dataset_train_count": 2131.0, "timer/dataset_train_total": 0.38406944274902344, "timer/dataset_train_frac": 0.00038392933471745365, "timer/dataset_train_avg": 0.0001802296774983686, "timer/dataset_train_min": 8.869171142578125e-05, "timer/dataset_train_max": 0.0024690628051757812, "timer/agent.train_count": 2131.0, "timer/agent.train_total": 954.4221522808075, "timer/agent.train_frac": 0.9540739803250134, "timer/agent.train_avg": 0.4478752474335089, "timer/agent.train_min": 0.43625974655151367, "timer/agent.train_max": 0.5902714729309082, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4794487953186035, "timer/agent.report_frac": 0.00047927389302367015, "timer/agent.report_avg": 0.23972439765930176, "timer/agent.report_min": 0.23317289352416992, "timer/agent.report_max": 0.2462759017944336, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9325485229492188e-05, "timer/dataset_eval_frac": 2.9314787330745223e-08, "timer/dataset_eval_avg": 2.9325485229492188e-05, "timer/dataset_eval_min": 2.9325485229492188e-05, "timer/dataset_eval_max": 2.9325485229492188e-05, "fps": 2.13019423548679}
{"step": 38272, "time": 17469.695447444916, "episode/length": 126.0, "episode/score": 2.2240430098236175, "episode/reward_rate": 0.968503937007874, "episode/intrinsic_return": 0.12404302655249921}
{"step": 38352, "time": 17508.044424533844, "episode/length": 153.0, "episode/score": 3.2577384192018144, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.15773837382312195}
{"step": 38792, "time": 17710.379608869553, "episode/length": 176.0, "episode/score": 4.269695398919339, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.16969530698906965}
{"step": 38960, "time": 17788.778606176376, "episode/length": 166.0, "episode/score": 2.212527653338384, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.11252755590749075}
{"step": 38984, "time": 17801.349544763565, "episode/length": 159.0, "episode/score": 2.2332553042183463, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.133255287477823}
{"step": 39064, "time": 17839.6025121212, "episode/length": 33.0, "episode/score": 0.1282285078705172, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.02822848239884479}
{"step": 39072, "time": 17844.752188444138, "episode/length": 162.0, "episode/score": 3.2262517758381364, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.1262517759196271}
{"step": 39192, "time": 17901.26562857628, "episode/length": 188.0, "episode/score": 3.244621747390738, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.14462163737243827}
{"step": 39864, "time": 18209.509127140045, "episode/length": 314.0, "episode/score": 3.432340874090187, "episode/reward_rate": 0.9904761904761905, "episode/intrinsic_return": 0.3323408267033301}
{"step": 39928, "time": 18240.15961098671, "episode/length": 196.0, "episode/score": 1.303634505656646, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.20363446877627212}
{"step": 40040, "time": 18309.915078401566, "eval_episode/length": 125.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9523809523809523}
{"step": 40040, "time": 18313.347735643387, "eval_episode/length": 169.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9705882352941176}
{"step": 40040, "time": 18313.355629205704, "eval_episode/length": 169.0, "eval_episode/score": 2.0999999716877937, "eval_episode/reward_rate": 0.9941176470588236}
{"step": 40040, "time": 18316.933118104935, "eval_episode/length": 179.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 40040, "time": 18318.542444705963, "eval_episode/length": 181.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.967032967032967}
{"step": 40040, "time": 18320.739403486252, "eval_episode/length": 196.0, "eval_episode/score": 5.099999971687794, "eval_episode/reward_rate": 0.9949238578680203}
{"step": 40040, "time": 18320.748122930527, "eval_episode/length": 196.0, "eval_episode/score": 3.0999999716877937, "eval_episode/reward_rate": 0.9949238578680203}
{"step": 40040, "time": 18324.093423128128, "eval_episode/length": 202.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9950738916256158}
{"step": 40041, "time": 18325.141632795334, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.650064714787679, "train/action_min": 0.0, "train/action_std": 3.68295729901802, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04087694915252154, "train/actor_opt_grad_steps": 37440.0, "train/actor_opt_loss": -13.024589843572336, "train/adv_mag": 0.8685223430252531, "train/adv_max": 0.8105534849839918, "train/adv_mean": 0.0031750449588146055, "train/adv_min": -0.6376142238030593, "train/adv_std": 0.058032553357798514, "train/cont_avg": 0.994392942583732, "train/cont_loss_mean": 6.467971853580233e-05, "train/cont_loss_std": 0.0019802891552871097, "train/cont_neg_acc": 0.9986709199453655, "train/cont_neg_loss": 0.003299119912224942, "train/cont_pos_acc": 0.9999905773327111, "train/cont_pos_loss": 4.196683361333347e-05, "train/cont_pred": 0.994389757870487, "train/cont_rate": 0.994392942583732, "train/dyn_loss_mean": 2.810875406675932, "train/dyn_loss_std": 7.584066432058526, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.3154995980445279, "train/extr_critic_critic_opt_grad_steps": 37440.0, "train/extr_critic_critic_opt_loss": 15938.155539772728, "train/extr_critic_mag": 18.032884419819954, "train/extr_critic_max": 18.032884419819954, "train/extr_critic_mean": 3.0733629516437295, "train/extr_critic_min": -0.5486169009687798, "train/extr_critic_std": 3.336276017878044, "train/extr_return_normed_mag": 1.6972518303747952, "train/extr_return_normed_max": 1.6972518303747952, "train/extr_return_normed_mean": 0.29196668419826544, "train/extr_return_normed_min": -0.07848169743729551, "train/extr_return_normed_std": 0.31382393672991027, "train/extr_return_rate": 0.8033458969809792, "train/extr_return_raw_mag": 18.515494666031103, "train/extr_return_raw_max": 18.515494666031103, "train/extr_return_raw_mean": 3.1080691945609864, "train/extr_return_raw_min": -0.9540572510096446, "train/extr_return_raw_std": 3.439546887954456, "train/extr_reward_mag": 1.0208149583716142, "train/extr_reward_max": 1.0208149583716142, "train/extr_reward_mean": 0.02449142195409137, "train/extr_reward_min": -0.6506074222081015, "train/extr_reward_std": 0.1543113484836081, "train/image_loss_mean": 2.0700871955835076, "train/image_loss_std": 5.211380356236508, "train/model_loss_mean": 3.8248559595865497, "train/model_loss_std": 8.779731125352486, "train/model_opt_grad_norm": 40.30750133660421, "train/model_opt_grad_steps": 37406.746411483255, "train/model_opt_loss": 5559.1535118869615, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1471.2918660287082, "train/policy_entropy_mag": 2.4678775294545736, "train/policy_entropy_max": 2.4678775294545736, "train/policy_entropy_mean": 0.5165627692875109, "train/policy_entropy_min": 0.07937501427944768, "train/policy_entropy_std": 0.590306438327406, "train/policy_logprob_mag": 7.438383629447536, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5164900805676382, "train/policy_logprob_min": -7.438383629447536, "train/policy_logprob_std": 1.104192093513799, "train/policy_randomness_mag": 0.8710524662259663, "train/policy_randomness_max": 0.8710524662259663, "train/policy_randomness_mean": 0.18232398932915556, "train/policy_randomness_min": 0.028015896874038798, "train/policy_randomness_std": 0.20835226859772604, "train/post_ent_mag": 37.17709725667415, "train/post_ent_max": 37.17709725667415, "train/post_ent_mean": 19.026009363420844, "train/post_ent_min": 10.728364561163067, "train/post_ent_std": 3.590524903895182, "train/prior_ent_mag": 72.87243572034333, "train/prior_ent_max": 72.87243572034333, "train/prior_ent_mean": 21.903384441393985, "train/prior_ent_min": 12.019246502926475, "train/prior_ent_std": 8.766924020776338, "train/rep_loss_mean": 2.810875406675932, "train/rep_loss_std": 7.584066432058526, "train/reward_avg": 0.015128660208487696, "train/reward_loss_mean": 0.06817883928640607, "train/reward_loss_std": 0.15429773859002374, "train/reward_max_data": 1.0069916567733983, "train/reward_max_pred": 1.0076183542680512, "train/reward_neg_acc": 0.9994716447506224, "train/reward_neg_loss": 0.050621464509855614, "train/reward_pos_acc": 0.9014268209489339, "train/reward_pos_loss": 0.7205210205470546, "train/reward_pred": 0.01505395156358097, "train/reward_rate": 0.026133560107655503, "train_stats/sum_log_reward": 2.3999999344348906, "train_stats/max_log_achievement_collect_drink": 3.5, "train_stats/max_log_achievement_collect_sapling": 1.2, "train_stats/max_log_achievement_collect_wood": 0.4, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.0, "train_stats/max_log_achievement_place_table": 0.1, "train_stats/max_log_achievement_wake_up": 1.9, "train_stats/mean_log_entropy": 0.4594371736049652, "eval_stats/sum_log_reward": 3.2249999344348907, "eval_stats/max_log_achievement_collect_drink": 4.75, "eval_stats/max_log_achievement_collect_sapling": 1.75, "eval_stats/max_log_achievement_collect_wood": 1.0, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 1.625, "eval_stats/max_log_achievement_place_table": 0.25, "eval_stats/max_log_achievement_wake_up": 1.5, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 6.382062110787956e-06, "report/cont_loss_std": 7.850093970773742e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 7.5564777944237e-05, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 6.110757112764986e-06, "report/cont_pred": 0.996087908744812, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 2.4707486629486084, "report/dyn_loss_std": 7.527296543121338, "report/image_loss_mean": 1.6241304874420166, "report/image_loss_std": 3.823880195617676, "report/model_loss_mean": 3.168642044067383, "report/model_loss_std": 7.319621562957764, "report/post_ent_mag": 39.96921157836914, "report/post_ent_max": 39.96921157836914, "report/post_ent_mean": 18.558923721313477, "report/post_ent_min": 10.329734802246094, "report/post_ent_std": 3.3318026065826416, "report/prior_ent_mag": 72.52298736572266, "report/prior_ent_max": 72.52298736572266, "report/prior_ent_mean": 21.087940216064453, "report/prior_ent_min": 10.460348129272461, "report/prior_ent_std": 8.327046394348145, "report/rep_loss_mean": 2.4707486629486084, "report/rep_loss_std": 7.527296543121338, "report/reward_avg": 0.017558500170707703, "report/reward_loss_mean": 0.062056027352809906, "report/reward_loss_std": 0.12641558051109314, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0030221939086914, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.04456266388297081, "report/reward_pos_acc": 0.8888888955116272, "report/reward_pos_loss": 0.708014726638794, "report/reward_pred": 0.017471441999077797, "report/reward_rate": 0.0263671875, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 8.519316907040775e-05, "eval/cont_loss_std": 0.0018220009515061975, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.014479072764515877, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 2.8746580937877297e-05, "eval/cont_pred": 0.9961201548576355, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 24.308929443359375, "eval/dyn_loss_std": 13.5061616897583, "eval/image_loss_mean": 66.31216430664062, "eval/image_loss_std": 62.887325286865234, "eval/model_loss_mean": 81.1443099975586, "eval/model_loss_std": 68.37809753417969, "eval/post_ent_mag": 39.96921157836914, "eval/post_ent_max": 39.96921157836914, "eval/post_ent_mean": 24.738203048706055, "eval/post_ent_min": 14.757791519165039, "eval/post_ent_std": 4.027039051055908, "eval/prior_ent_mag": 72.52298736572266, "eval/prior_ent_max": 72.52298736572266, "eval/prior_ent_mean": 30.961029052734375, "eval/prior_ent_min": 15.42027759552002, "eval/prior_ent_std": 9.286665916442871, "eval/rep_loss_mean": 24.308929443359375, "eval/rep_loss_std": 13.5061616897583, "eval/reward_avg": 0.010937499813735485, "eval/reward_loss_mean": 0.24670001864433289, "eval/reward_loss_std": 1.4673339128494263, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0052947998046875, "eval/reward_neg_acc": 0.9970208406448364, "eval/reward_neg_loss": 0.14634869992733002, "eval/reward_pos_acc": 0.3529411852359772, "eval/reward_pos_loss": 6.1910400390625, "eval/reward_pred": 0.0041864048689603806, "eval/reward_rate": 0.0166015625, "replay/size": 39537.0, "replay/inserts": 2084.0, "replay/samples": 33344.0, "replay/insert_wait_avg": 2.5021366331719163e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.951742971240902e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 9992.0, "eval_replay/inserts": 1624.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1048880703930785e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.599592208862305e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 999.9823446273804, "timer/env.step_count": 261.0, "timer/env.step_total": 21.97208070755005, "timer/env.step_frac": 0.021972468639671255, "timer/env.step_avg": 0.0841842172703067, "timer/env.step_min": 0.023316144943237305, "timer/env.step_max": 1.658790111541748, "timer/replay._sample_count": 33344.0, "timer/replay._sample_total": 15.913394212722778, "timer/replay._sample_frac": 0.015913675174587732, "timer/replay._sample_avg": 0.00047724910666754975, "timer/replay._sample_min": 0.0003440380096435547, "timer/replay._sample_max": 0.013553380966186523, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 464.0, "timer/agent.policy_total": 7.158572435379028, "timer/agent.policy_frac": 0.007158698824874253, "timer/agent.policy_avg": 0.015427957834868595, "timer/agent.policy_min": 0.009307622909545898, "timer/agent.policy_max": 0.05541229248046875, "timer/dataset_train_count": 2084.0, "timer/dataset_train_total": 0.3635697364807129, "timer/dataset_train_frac": 0.0003635761555532148, "timer/dataset_train_avg": 0.0001744576470636818, "timer/dataset_train_min": 8.535385131835938e-05, "timer/dataset_train_max": 0.0008068084716796875, "timer/agent.train_count": 2084.0, "timer/agent.train_total": 932.2353899478912, "timer/agent.train_frac": 0.9322518492016643, "timer/agent.train_avg": 0.4473298416256676, "timer/agent.train_min": 0.4381840229034424, "timer/agent.train_max": 0.5850925445556641, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4720759391784668, "timer/agent.report_frac": 0.00047208427400223215, "timer/agent.report_avg": 0.2360379695892334, "timer/agent.report_min": 0.22922897338867188, "timer/agent.report_max": 0.24284696578979492, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8848648071289062e-05, "timer/dataset_eval_frac": 2.8849157413912966e-08, "timer/dataset_eval_avg": 2.8848648071289062e-05, "timer/dataset_eval_min": 2.8848648071289062e-05, "timer/dataset_eval_max": 2.8848648071289062e-05, "fps": 2.0840090414792365}
{"step": 40344, "time": 18463.265189647675, "episode/length": 159.0, "episode/score": 5.268785544988532, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.16878550723504304}
{"step": 40352, "time": 18468.36540389061, "episode/length": 173.0, "episode/score": 4.2738299678744625, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.1738298131672309}
{"step": 40368, "time": 18477.178988933563, "episode/length": 172.0, "episode/score": 3.278837946279964, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.1788378850396839}
{"step": 40504, "time": 18540.64613389969, "episode/length": 178.0, "episode/score": 3.2832862501531963, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.18328620361035064}
{"step": 40632, "time": 18600.567234039307, "episode/length": 179.0, "episode/score": 2.2719671607505916, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.17196717515116688}
{"step": 41288, "time": 18901.41218972206, "episode/length": 169.0, "episode/score": 4.249477803686659, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.14947766366231008}
{"step": 41296, "time": 18906.441369771957, "episode/length": 377.0, "episode/score": 5.450454527988995, "episode/reward_rate": 0.9973544973544973, "episode/intrinsic_return": 0.35045443077638083}
{"step": 41496, "time": 18998.98966240883, "episode/length": 203.0, "episode/score": 3.3357501139398664, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.23574999580159783}
{"step": 41712, "time": 19098.608456373215, "episode/length": 170.0, "episode/score": 1.2521538291275647, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.15215379457549716}
{"step": 41816, "time": 19147.271622419357, "episode/length": 163.0, "episode/score": 4.234951819771595, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.13495184227758728}
{"step": 41968, "time": 19217.85813307762, "episode/length": 201.0, "episode/score": 2.2936931683789226, "episode/reward_rate": 0.9653465346534653, "episode/intrinsic_return": 0.19369311182435922}
{"step": 42104, "time": 19281.095810174942, "episode/length": 183.0, "episode/score": 1.2815140598875132, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.1815140253354457}
{"step": 42197, "time": 19325.430656671524, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.060302166606105, "train/action_min": 0.0, "train/action_std": 3.9616167722746383, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03594378849794699, "train/actor_opt_grad_steps": 39560.0, "train/actor_opt_loss": -12.297901798316905, "train/adv_mag": 0.8045963507752086, "train/adv_max": 0.7311938916527948, "train/adv_mean": 0.002499626420999342, "train/adv_min": -0.5896971236827762, "train/adv_std": 0.05230902286982814, "train/cont_avg": 0.9944131540697675, "train/cont_loss_mean": 2.914303701144554e-05, "train/cont_loss_std": 0.0008407005995988669, "train/cont_neg_acc": 0.998552971662477, "train/cont_neg_loss": 0.002859345444897393, "train/cont_pos_acc": 0.9999999830889147, "train/cont_pos_loss": 1.2800401207134074e-05, "train/cont_pred": 0.9944107890129089, "train/cont_rate": 0.9944131540697675, "train/dyn_loss_mean": 2.7567985312883243, "train/dyn_loss_std": 7.619192207691281, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.2381129519883975, "train/extr_critic_critic_opt_grad_steps": 39560.0, "train/extr_critic_critic_opt_loss": 15461.801199127907, "train/extr_critic_mag": 17.326573447294013, "train/extr_critic_max": 17.326573447294013, "train/extr_critic_mean": 2.9671562704929086, "train/extr_critic_min": -0.5850333274796952, "train/extr_critic_std": 3.3842688155728715, "train/extr_return_normed_mag": 1.6628593336704165, "train/extr_return_normed_max": 1.6628593336704165, "train/extr_return_normed_mean": 0.2902692525885826, "train/extr_return_normed_min": -0.07984071847397921, "train/extr_return_normed_std": 0.3224638038596442, "train/extr_return_rate": 0.7605983910172485, "train/extr_return_raw_mag": 17.716681005788406, "train/extr_return_raw_max": 17.716681005788406, "train/extr_return_raw_mean": 2.9940553127333174, "train/extr_return_raw_min": -0.971280865683112, "train/extr_return_raw_std": 3.4557413916255153, "train/extr_reward_mag": 1.0257284585819688, "train/extr_reward_max": 1.0257284585819688, "train/extr_reward_mean": 0.02474361344045678, "train/extr_reward_min": -0.6492148687673169, "train/extr_reward_std": 0.15523911215538203, "train/image_loss_mean": 1.9026736334312795, "train/image_loss_std": 4.790700548748637, "train/model_loss_mean": 3.624587881842325, "train/model_loss_std": 8.441678047180176, "train/model_opt_grad_norm": 37.063587419376816, "train/model_opt_grad_steps": 39525.12558139535, "train/model_opt_loss": 6078.621912472747, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1691.860465116279, "train/policy_entropy_mag": 2.4897343180900395, "train/policy_entropy_max": 2.4897343180900395, "train/policy_entropy_mean": 0.5876869636912678, "train/policy_entropy_min": 0.07937501454076101, "train/policy_entropy_std": 0.6509635496971219, "train/policy_logprob_mag": 7.438383630264637, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5879197555919026, "train/policy_logprob_min": -7.438383630264637, "train/policy_logprob_std": 1.1475435564684313, "train/policy_randomness_mag": 0.8787669547768526, "train/policy_randomness_max": 0.8787669547768526, "train/policy_randomness_mean": 0.2074277091857999, "train/policy_randomness_min": 0.02801589695520179, "train/policy_randomness_std": 0.22976156736529152, "train/post_ent_mag": 37.14921902501306, "train/post_ent_max": 37.14921902501306, "train/post_ent_mean": 19.119513134623684, "train/post_ent_min": 10.790524788789972, "train/post_ent_std": 3.625361023392788, "train/prior_ent_mag": 73.07867126464843, "train/prior_ent_max": 73.07867126464843, "train/prior_ent_mean": 21.955869435155115, "train/prior_ent_min": 12.070706531613371, "train/prior_ent_std": 8.819216175966485, "train/rep_loss_mean": 2.7567985312883243, "train/rep_loss_std": 7.619192207691281, "train/reward_avg": 0.0148318080415646, "train/reward_loss_mean": 0.06780596323484599, "train/reward_loss_std": 0.15118419188399648, "train/reward_max_data": 1.0114825891893964, "train/reward_max_pred": 1.012116952275121, "train/reward_neg_acc": 0.9994821504104969, "train/reward_neg_loss": 0.05044524997126224, "train/reward_pos_acc": 0.8987994130267654, "train/reward_pos_loss": 0.7219767237818518, "train/reward_pred": 0.014730430455055349, "train/reward_rate": 0.02578579215116279, "train_stats/sum_log_reward": 3.183333287636439, "train_stats/max_log_achievement_collect_drink": 3.75, "train_stats/max_log_achievement_collect_sapling": 1.4166666666666667, "train_stats/max_log_achievement_collect_wood": 1.5, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.3333333333333333, "train_stats/max_log_achievement_place_table": 0.5833333333333334, "train_stats/max_log_achievement_wake_up": 2.4166666666666665, "train_stats/mean_log_entropy": 0.5039556498328844, "train_stats/max_log_achievement_defeat_zombie": 0.25, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 1.1614350114541594e-05, "report/cont_loss_std": 0.0003032817621715367, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 1.9790899386862293e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.1566159628273454e-05, "report/cont_pred": 0.9941294193267822, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 3.1758289337158203, "report/dyn_loss_std": 7.803728103637695, "report/image_loss_mean": 2.0559167861938477, "report/image_loss_std": 6.3609442710876465, "report/model_loss_mean": 4.0303053855896, "report/model_loss_std": 9.926835060119629, "report/post_ent_mag": 40.412879943847656, "report/post_ent_max": 40.412879943847656, "report/post_ent_mean": 20.217191696166992, "report/post_ent_min": 11.390144348144531, "report/post_ent_std": 3.824028253555298, "report/prior_ent_mag": 73.30435180664062, "report/prior_ent_max": 73.30435180664062, "report/prior_ent_mean": 23.38416290283203, "report/prior_ent_min": 12.611410140991211, "report/prior_ent_std": 9.103923797607422, "report/rep_loss_mean": 3.1758289337158203, "report/rep_loss_std": 7.803728103637695, "report/reward_avg": 0.008335565216839314, "report/reward_loss_mean": 0.06887954473495483, "report/reward_loss_std": 0.16882875561714172, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0068929195404053, "report/reward_neg_acc": 0.999002993106842, "report/reward_neg_loss": 0.05416833236813545, "report/reward_pos_acc": 0.9523809552192688, "report/reward_pos_loss": 0.7715152502059937, "report/reward_pred": 0.007845861837267876, "report/reward_rate": 0.0205078125, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 1.795996467990335e-05, "eval/cont_loss_std": 0.0004885471425950527, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.003557023359462619, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 5.945905172666244e-07, "eval/cont_pred": 0.9951339960098267, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 25.561790466308594, "eval/dyn_loss_std": 14.812713623046875, "eval/image_loss_mean": 63.27273941040039, "eval/image_loss_std": 61.87558364868164, "eval/model_loss_mean": 78.74021911621094, "eval/model_loss_std": 68.02391052246094, "eval/post_ent_mag": 40.412879943847656, "eval/post_ent_max": 40.412879943847656, "eval/post_ent_mean": 24.607330322265625, "eval/post_ent_min": 14.753280639648438, "eval/post_ent_std": 4.173354625701904, "eval/prior_ent_mag": 73.30435180664062, "eval/prior_ent_max": 73.30435180664062, "eval/prior_ent_mean": 31.214136123657227, "eval/prior_ent_min": 15.307394981384277, "eval/prior_ent_std": 9.59127140045166, "eval/rep_loss_mean": 25.561790466308594, "eval/rep_loss_std": 14.812713623046875, "eval/reward_avg": 0.014843749813735485, "eval/reward_loss_mean": 0.13038858771324158, "eval/reward_loss_std": 0.9428246021270752, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.009329080581665, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.05126919224858284, "eval/reward_pos_acc": 0.5789473652839661, "eval/reward_pos_loss": 4.3153886795043945, "eval/reward_pred": 0.008521365001797676, "eval/reward_rate": 0.0185546875, "replay/size": 41693.0, "replay/inserts": 2156.0, "replay/samples": 34496.0, "replay/insert_wait_avg": 2.522636654204473e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.03563778387151e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 9992.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 7.897615432739258e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2794961929321, "timer/env.step_count": 269.0, "timer/env.step_total": 25.111589908599854, "timer/env.step_frac": 0.02510457327594404, "timer/env.step_avg": 0.09335163534795485, "timer/env.step_min": 0.02343463897705078, "timer/env.step_max": 1.6148459911346436, "timer/replay._sample_count": 34496.0, "timer/replay._sample_total": 16.98094654083252, "timer/replay._sample_frac": 0.01697620175707097, "timer/replay._sample_avg": 0.0004922584224499223, "timer/replay._sample_min": 0.0003147125244140625, "timer/replay._sample_max": 0.02885293960571289, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 269.0, "timer/agent.policy_total": 4.159349203109741, "timer/agent.policy_frac": 0.004158187005672156, "timer/agent.policy_avg": 0.015462264695575247, "timer/agent.policy_min": 0.014423370361328125, "timer/agent.policy_max": 0.01986861228942871, "timer/dataset_train_count": 2156.0, "timer/dataset_train_total": 0.37433791160583496, "timer/dataset_train_frac": 0.00037423331481907464, "timer/dataset_train_avg": 0.00017362611855558207, "timer/dataset_train_min": 8.559226989746094e-05, "timer/dataset_train_max": 0.0009982585906982422, "timer/agent.train_count": 2156.0, "timer/agent.train_total": 960.3962428569794, "timer/agent.train_frac": 0.9601278907667821, "timer/agent.train_avg": 0.4454528028093596, "timer/agent.train_min": 0.4321610927581787, "timer/agent.train_max": 0.5876049995422363, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47722721099853516, "timer/agent.report_frac": 0.00047709386507957416, "timer/agent.report_avg": 0.23861360549926758, "timer/agent.report_min": 0.23018145561218262, "timer/agent.report_max": 0.24704575538635254, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 6.580352783203125e-05, "timer/dataset_eval_frac": 6.578514113553236e-08, "timer/dataset_eval_avg": 6.580352783203125e-05, "timer/dataset_eval_min": 6.580352783203125e-05, "timer/dataset_eval_max": 6.580352783203125e-05, "fps": 2.155369053477721}
{"step": 42232, "time": 19341.58695626259, "episode/length": 232.0, "episode/score": 4.347063823296594, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.2470637902870294}
{"step": 42312, "time": 19379.41351222992, "episode/length": 74.0, "episode/score": 1.1861718468360323, "episode/reward_rate": 0.9866666666666667, "episode/intrinsic_return": 0.0861717554732877}
{"step": 42432, "time": 19435.36684679985, "episode/length": 141.0, "episode/score": 2.239773237120062, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.13977314028579713}
{"step": 42768, "time": 19588.961347341537, "episode/length": 184.0, "episode/score": 4.289665671524062, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.18966555309475552}
{"step": 43320, "time": 19840.606184005737, "episode/length": 168.0, "episode/score": 2.2606905026880213, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.160690435656079}
{"step": 43392, "time": 19874.731816768646, "episode/length": 144.0, "episode/score": 3.2440278466740438, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.1440276957066544}
{"step": 43568, "time": 19955.95796585083, "episode/length": 182.0, "episode/score": 3.28177676678888, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.18177664037057184}
{"step": 43632, "time": 19986.541534900665, "episode/length": 164.0, "episode/score": 3.2737573194501692, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.17375722529345694}
{"step": 43656, "time": 19998.99388575554, "episode/length": 269.0, "episode/score": 4.404689749968384, "episode/reward_rate": 0.9740740740740741, "episode/intrinsic_return": 0.304689636486728}
{"step": 43744, "time": 20040.35931134224, "episode/length": 163.0, "episode/score": 3.2637951420067566, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.16379506729140303}
{"step": 43912, "time": 20117.79590201378, "episode/length": 142.0, "episode/score": 3.253579531441119, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.15357938047372954}
{"step": 44367, "time": 20325.644970417023, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.267369705411146, "train/action_min": 0.0, "train/action_std": 4.120113734276064, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03562279376051118, "train/actor_opt_grad_steps": 41720.0, "train/actor_opt_loss": -11.281968651931681, "train/adv_mag": 0.6870327578162267, "train/adv_max": 0.6326358663046965, "train/adv_mean": 0.0027568154594179513, "train/adv_min": -0.5547615727795984, "train/adv_std": 0.05078818513432406, "train/cont_avg": 0.9944691460253456, "train/cont_loss_mean": 1.5872264745631952e-05, "train/cont_loss_std": 0.0004615099811493919, "train/cont_neg_acc": 1.0, "train/cont_neg_loss": 0.0013994799843111303, "train/cont_pos_acc": 0.9999954387339579, "train/cont_pos_loss": 8.867741478701235e-06, "train/cont_pred": 0.994468014635798, "train/cont_rate": 0.9944691460253456, "train/dyn_loss_mean": 2.839986285855693, "train/dyn_loss_std": 7.668995549601894, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.2120312968706755, "train/extr_critic_critic_opt_grad_steps": 41720.0, "train/extr_critic_critic_opt_loss": 15300.003919750865, "train/extr_critic_mag": 14.595693649784211, "train/extr_critic_max": 14.595693649784211, "train/extr_critic_mean": 3.0340855099638486, "train/extr_critic_min": -0.5319121109175792, "train/extr_critic_std": 3.1089517960350634, "train/extr_return_normed_mag": 1.5247964622787615, "train/extr_return_normed_max": 1.5247964622787615, "train/extr_return_normed_mean": 0.3141669783449393, "train/extr_return_normed_min": -0.08550037266815314, "train/extr_return_normed_std": 0.32141840677656885, "train/extr_return_rate": 0.7906715463383407, "train/extr_return_raw_mag": 14.961019142432146, "train/extr_return_raw_max": 14.961019142432146, "train/extr_return_raw_mean": 3.0611709532100484, "train/extr_return_raw_min": -0.8735333183943401, "train/extr_return_raw_std": 3.168360397013651, "train/extr_reward_mag": 1.0297902849962086, "train/extr_reward_max": 1.0297902849962086, "train/extr_reward_mean": 0.025805270436653344, "train/extr_reward_min": -0.6299251164159467, "train/extr_reward_std": 0.1565686530575225, "train/image_loss_mean": 2.0499823148349465, "train/image_loss_std": 5.413172498826058, "train/model_loss_mean": 3.8229669085296067, "train/model_loss_std": 9.0392759208855, "train/model_opt_grad_norm": 37.050895967791156, "train/model_opt_grad_steps": 41683.410138248844, "train/model_opt_loss": 5365.743463331653, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1411.2903225806451, "train/policy_entropy_mag": 2.441051367790468, "train/policy_entropy_max": 2.441051367790468, "train/policy_entropy_mean": 0.5780546619870146, "train/policy_entropy_min": 0.0793750142240854, "train/policy_entropy_std": 0.6253488772475775, "train/policy_logprob_mag": 7.43838362100487, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5791658847013377, "train/policy_logprob_min": -7.43838362100487, "train/policy_logprob_std": 1.1341561639363864, "train/policy_randomness_mag": 0.8615840121348333, "train/policy_randomness_max": 0.8615840121348333, "train/policy_randomness_mean": 0.20402792789694352, "train/policy_randomness_min": 0.02801589685822687, "train/policy_randomness_std": 0.22072071125430445, "train/post_ent_mag": 37.72169208966093, "train/post_ent_max": 37.72169208966093, "train/post_ent_mean": 19.28510205317203, "train/post_ent_min": 10.82848574818554, "train/post_ent_std": 3.630206015802199, "train/prior_ent_mag": 73.31951735536074, "train/prior_ent_max": 73.31951735536074, "train/prior_ent_mean": 22.18412702534056, "train/prior_ent_min": 12.059807566453784, "train/prior_ent_std": 8.832860392908897, "train/rep_loss_mean": 2.839986285855693, "train/rep_loss_std": 7.668995549601894, "train/reward_avg": 0.014704283959906085, "train/reward_loss_mean": 0.0689769509819246, "train/reward_loss_std": 0.15908959981757925, "train/reward_max_data": 1.0127707686841763, "train/reward_max_pred": 1.0143324213643228, "train/reward_neg_acc": 0.9994965258831253, "train/reward_neg_loss": 0.05104538393185435, "train/reward_pos_acc": 0.9041340375825557, "train/reward_pos_loss": 0.7365316072916654, "train/reward_pred": 0.014551810176682568, "train/reward_rate": 0.02624117943548387, "train_stats/sum_log_reward": 3.0090908245606856, "train_stats/max_log_achievement_collect_drink": 3.0, "train_stats/max_log_achievement_collect_sapling": 1.1818181818181819, "train_stats/max_log_achievement_collect_wood": 1.3636363636363635, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.0909090909090908, "train_stats/max_log_achievement_place_table": 0.2727272727272727, "train_stats/max_log_achievement_wake_up": 1.6363636363636365, "train_stats/mean_log_entropy": 0.5807818391106345, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 9.456146585762326e-07, "report/cont_loss_std": 6.544906227645697e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 1.6843352568685077e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 8.204356163332704e-07, "report/cont_pred": 0.9921869039535522, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 2.8809964656829834, "report/dyn_loss_std": 7.740938663482666, "report/image_loss_mean": 1.9188690185546875, "report/image_loss_std": 5.067769527435303, "report/model_loss_mean": 3.7282638549804688, "report/model_loss_std": 8.800039291381836, "report/post_ent_mag": 40.869606018066406, "report/post_ent_max": 40.869606018066406, "report/post_ent_mean": 19.29819107055664, "report/post_ent_min": 10.349002838134766, "report/post_ent_std": 3.8311305046081543, "report/prior_ent_mag": 73.65032958984375, "report/prior_ent_max": 73.65032958984375, "report/prior_ent_mean": 22.254596710205078, "report/prior_ent_min": 12.709617614746094, "report/prior_ent_std": 9.323546409606934, "report/rep_loss_mean": 2.8809964656829834, "report/rep_loss_std": 7.740938663482666, "report/reward_avg": 0.011230221018195152, "report/reward_loss_mean": 0.0807957798242569, "report/reward_loss_std": 0.21634569764137268, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.003596544265747, "report/reward_neg_acc": 0.9989939332008362, "report/reward_neg_loss": 0.058806970715522766, "report/reward_pos_acc": 0.9000000357627869, "report/reward_pos_loss": 0.8093582987785339, "report/reward_pred": 0.011812016367912292, "report/reward_rate": 0.029296875, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.005598634947091341, "eval/cont_loss_std": 0.12492189556360245, "eval/cont_neg_acc": 0.5, "eval/cont_neg_loss": 0.954971194267273, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 3.1194281291391235e-06, "eval/cont_pred": 0.9963057637214661, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 26.738840103149414, "eval/dyn_loss_std": 14.567499160766602, "eval/image_loss_mean": 52.65333557128906, "eval/image_loss_std": 49.435813903808594, "eval/model_loss_mean": 68.86277770996094, "eval/model_loss_std": 54.37323760986328, "eval/post_ent_mag": 40.869606018066406, "eval/post_ent_max": 40.869606018066406, "eval/post_ent_mean": 25.096363067626953, "eval/post_ent_min": 14.693069458007812, "eval/post_ent_std": 3.993360996246338, "eval/prior_ent_mag": 73.65032958984375, "eval/prior_ent_max": 73.65032958984375, "eval/prior_ent_mean": 33.35724639892578, "eval/prior_ent_min": 17.22924041748047, "eval/prior_ent_std": 9.362357139587402, "eval/rep_loss_mean": 26.738840103149414, "eval/rep_loss_std": 14.567499160766602, "eval/reward_avg": 0.0027343747206032276, "eval/reward_loss_mean": 0.16054126620292664, "eval/reward_loss_std": 1.1348707675933838, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0023667812347412, "eval/reward_neg_acc": 0.9990147948265076, "eval/reward_neg_loss": 0.14577864110469818, "eval/reward_pos_acc": 0.8888888955116272, "eval/reward_pos_loss": 1.8254377841949463, "eval/reward_pred": 0.005428125150501728, "eval/reward_rate": 0.0087890625, "replay/size": 43863.0, "replay/inserts": 2170.0, "replay/samples": 34720.0, "replay/insert_wait_avg": 2.4668082663540466e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.849615839769214e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 9992.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 7.003545761108398e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1962237358093, "timer/env.step_count": 271.0, "timer/env.step_total": 23.252490520477295, "timer/env.step_frac": 0.023247928725053036, "timer/env.step_avg": 0.08580254804604168, "timer/env.step_min": 0.02323627471923828, "timer/env.step_max": 1.5865280628204346, "timer/replay._sample_count": 34720.0, "timer/replay._sample_total": 16.6000554561615, "timer/replay._sample_frac": 0.016596798770304313, "timer/replay._sample_avg": 0.00047811219631801555, "timer/replay._sample_min": 0.000335693359375, "timer/replay._sample_max": 0.03301239013671875, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 271.0, "timer/agent.policy_total": 4.146444320678711, "timer/agent.policy_frac": 0.004145630849506135, "timer/agent.policy_avg": 0.01530053254862993, "timer/agent.policy_min": 0.014411687850952148, "timer/agent.policy_max": 0.02693462371826172, "timer/dataset_train_count": 2170.0, "timer/dataset_train_total": 0.37026095390319824, "timer/dataset_train_frac": 0.000370188314169239, "timer/dataset_train_avg": 0.00017062716769732637, "timer/dataset_train_min": 8.630752563476562e-05, "timer/dataset_train_max": 0.0006327629089355469, "timer/agent.train_count": 2170.0, "timer/agent.train_total": 962.4426085948944, "timer/agent.train_frac": 0.9622537915611176, "timer/agent.train_avg": 0.4435219394446518, "timer/agent.train_min": 0.4327535629272461, "timer/agent.train_max": 0.5705299377441406, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4743156433105469, "timer/agent.report_frac": 0.0004742225895824138, "timer/agent.report_avg": 0.23715782165527344, "timer/agent.report_min": 0.22962594032287598, "timer/agent.report_max": 0.2446897029876709, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9325485229492188e-05, "timer/dataset_eval_frac": 2.9319732002145797e-08, "timer/dataset_eval_avg": 2.9325485229492188e-05, "timer/dataset_eval_min": 2.9325485229492188e-05, "timer/dataset_eval_max": 2.9325485229492188e-05, "fps": 2.169542998769968}
{"step": 44784, "time": 20514.739952087402, "episode/length": 151.0, "episode/score": 3.251489059740152, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.15148893543187114}
{"step": 44832, "time": 20538.06788635254, "episode/length": 146.0, "episode/score": 2.2219640617015557, "episode/reward_rate": 0.9659863945578231, "episode/intrinsic_return": 0.12196404522296689}
{"step": 44848, "time": 20546.7930188179, "episode/length": 181.0, "episode/score": 5.293342965071588, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.19334280383054647}
{"step": 44944, "time": 20591.73505973816, "episode/length": 202.0, "episode/score": 4.318863364037043, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.21886316066820655}
{"step": 45048, "time": 20640.45534181595, "episode/length": 141.0, "episode/score": 3.2093327769737243, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.10933259585476662}
{"step": 45112, "time": 20670.998855113983, "episode/length": 411.0, "episode/score": 5.485483435363449, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.38548336350027057}
{"step": 45272, "time": 20745.01158428192, "episode/length": 190.0, "episode/score": 2.2747810119851692, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.17478088856455543}
{"step": 45464, "time": 20833.572291851044, "episode/length": 228.0, "episode/score": 4.359928172604441, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.25992796983223343}
{"step": 45944, "time": 21051.957704544067, "episode/length": 136.0, "episode/score": 3.24177769633593, "episode/reward_rate": 0.9635036496350365, "episode/intrinsic_return": 0.14177760217921787}
{"step": 46072, "time": 21111.535090208054, "episode/length": 160.0, "episode/score": 4.263593627867294, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.16359349946992552}
{"step": 46376, "time": 21250.202298641205, "episode/length": 192.0, "episode/score": 4.308050699032492, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.2080506806912581}
{"step": 46384, "time": 21255.386496067047, "episode/length": 166.0, "episode/score": 3.249106471366076, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.14910644094675263}
{"step": 46384, "time": 21255.393800258636, "episode/length": 158.0, "episode/score": 3.2833468419810288, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.18334679776648954}
{"step": 46480, "time": 21301.867101192474, "episode/length": 191.0, "episode/score": 3.311802201355704, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.2118020509121834}
{"step": 46529, "time": 21326.054170370102, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.356988412362558, "train/action_min": 0.0, "train/action_std": 4.085481981436412, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03818358388660407, "train/actor_opt_grad_steps": 43885.0, "train/actor_opt_loss": -13.197081236375702, "train/adv_mag": 0.7437957293457456, "train/adv_max": 0.6793432424741762, "train/adv_mean": 0.002698982293153491, "train/adv_min": -0.5829558547724176, "train/adv_std": 0.0536737257907926, "train/cont_avg": 0.9944435402199074, "train/cont_loss_mean": 6.676537750933605e-05, "train/cont_loss_std": 0.0020712404643170013, "train/cont_neg_acc": 0.9973508232721576, "train/cont_neg_loss": 0.006316523451836794, "train/cont_pos_acc": 0.9999954267232506, "train/cont_pos_loss": 1.919361105475172e-05, "train/cont_pred": 0.994447076762164, "train/cont_rate": 0.9944435402199074, "train/dyn_loss_mean": 2.806104119177218, "train/dyn_loss_std": 7.666149223292315, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1994728247324626, "train/extr_critic_critic_opt_grad_steps": 43885.0, "train/extr_critic_critic_opt_loss": 15378.249990957755, "train/extr_critic_mag": 16.852276771156877, "train/extr_critic_max": 16.852276771156877, "train/extr_critic_mean": 3.0802392380105124, "train/extr_critic_min": -0.5827135785862252, "train/extr_critic_std": 3.3359747197892933, "train/extr_return_normed_mag": 1.612426043384605, "train/extr_return_normed_max": 1.612426043384605, "train/extr_return_normed_mean": 0.30107859032297574, "train/extr_return_normed_min": -0.08078926950003262, "train/extr_return_normed_std": 0.3206551866260944, "train/extr_return_rate": 0.7437774654891756, "train/extr_return_raw_mag": 17.09275045659807, "train/extr_return_raw_max": 17.09275045659807, "train/extr_return_raw_mean": 3.1087323979095176, "train/extr_return_raw_min": -0.96586230121277, "train/extr_return_raw_std": 3.4232857050719083, "train/extr_reward_mag": 1.0239363886691906, "train/extr_reward_max": 1.0239363886691906, "train/extr_reward_mean": 0.02547248220933532, "train/extr_reward_min": -0.6463825559174573, "train/extr_reward_std": 0.1571450024774229, "train/image_loss_mean": 1.9130488325048376, "train/image_loss_std": 4.939885675907135, "train/model_loss_mean": 3.6660645891118935, "train/model_loss_std": 8.614794826066053, "train/model_opt_grad_norm": 35.9424516139207, "train/model_opt_grad_steps": 43846.93981481482, "train/model_opt_loss": 5709.837291576244, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1556.712962962963, "train/policy_entropy_mag": 2.472298659660198, "train/policy_entropy_max": 2.472298659660198, "train/policy_entropy_mean": 0.6083711304322437, "train/policy_entropy_min": 0.07937501450241716, "train/policy_entropy_std": 0.6579744862737479, "train/policy_logprob_mag": 7.438383678595225, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.6084534781122649, "train/policy_logprob_min": -7.438383678595225, "train/policy_logprob_std": 1.1519414203034506, "train/policy_randomness_mag": 0.8726129311102407, "train/policy_randomness_max": 0.8726129311102407, "train/policy_randomness_mean": 0.21472831139409984, "train/policy_randomness_min": 0.028015896953918314, "train/policy_randomness_std": 0.23223612029795293, "train/post_ent_mag": 37.8759930840245, "train/post_ent_max": 37.8759930840245, "train/post_ent_mean": 19.36206746984411, "train/post_ent_min": 10.937338497903612, "train/post_ent_std": 3.623522342355163, "train/prior_ent_mag": 73.50464347556785, "train/prior_ent_max": 73.50464347556785, "train/prior_ent_mean": 22.247338621704667, "train/prior_ent_min": 12.19690799271619, "train/prior_ent_std": 8.853402905993992, "train/rep_loss_mean": 2.806104119177218, "train/rep_loss_std": 7.666149223292315, "train/reward_avg": 0.0148883379833596, "train/reward_loss_mean": 0.0692865401506424, "train/reward_loss_std": 0.1593653732496831, "train/reward_max_data": 1.0105092900770682, "train/reward_max_pred": 1.0127505030896928, "train/reward_neg_acc": 0.9994428720739152, "train/reward_neg_loss": 0.05143076891976374, "train/reward_pos_acc": 0.9021224989383309, "train/reward_pos_loss": 0.7298406776454713, "train/reward_pred": 0.014760814843207805, "train/reward_rate": 0.02638527199074074, "train_stats/sum_log_reward": 3.528571367263794, "train_stats/max_log_achievement_collect_drink": 3.5, "train_stats/max_log_achievement_collect_sapling": 2.357142857142857, "train_stats/max_log_achievement_collect_wood": 1.1428571428571428, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 2.2142857142857144, "train_stats/max_log_achievement_place_table": 0.35714285714285715, "train_stats/max_log_achievement_wake_up": 2.0, "train_stats/mean_log_entropy": 0.5619838897671018, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 3.892492372870038e-07, "report/cont_loss_std": 1.0111047004102147e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 7.593078407808207e-06, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 3.4679052873798355e-07, "report/cont_pred": 0.9941403865814209, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 2.672994613647461, "report/dyn_loss_std": 7.5216264724731445, "report/image_loss_mean": 1.9496629238128662, "report/image_loss_std": 5.60019588470459, "report/model_loss_mean": 3.619358777999878, "report/model_loss_std": 8.97103214263916, "report/post_ent_mag": 35.58473205566406, "report/post_ent_max": 35.58473205566406, "report/post_ent_mean": 20.05002212524414, "report/post_ent_min": 11.637733459472656, "report/post_ent_std": 3.150729179382324, "report/prior_ent_mag": 73.72846984863281, "report/prior_ent_max": 73.72846984863281, "report/prior_ent_mean": 22.783519744873047, "report/prior_ent_min": 12.192985534667969, "report/prior_ent_std": 8.593542098999023, "report/rep_loss_mean": 2.672994613647461, "report/rep_loss_std": 7.5216264724731445, "report/reward_avg": 0.013994250446557999, "report/reward_loss_mean": 0.06589902937412262, "report/reward_loss_std": 0.12013904005289078, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.007385015487671, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.049466490745544434, "report/reward_pos_acc": 0.9259259104728699, "report/reward_pos_loss": 0.6726855635643005, "report/reward_pred": 0.014135736040771008, "report/reward_rate": 0.0263671875, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.002698330208659172, "eval/cont_loss_std": 0.08148670941591263, "eval/cont_neg_acc": 0.75, "eval/cont_neg_loss": 0.6510517597198486, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.00015576767327729613, "eval/cont_pred": 0.9968546628952026, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 25.30706024169922, "eval/dyn_loss_std": 14.55234432220459, "eval/image_loss_mean": 36.23823928833008, "eval/image_loss_std": 33.97074890136719, "eval/model_loss_mean": 51.665992736816406, "eval/model_loss_std": 39.841190338134766, "eval/post_ent_mag": 41.64820098876953, "eval/post_ent_max": 41.64820098876953, "eval/post_ent_mean": 23.98244285583496, "eval/post_ent_min": 14.488754272460938, "eval/post_ent_std": 4.147375583648682, "eval/prior_ent_mag": 73.72846984863281, "eval/prior_ent_max": 73.72846984863281, "eval/prior_ent_mean": 30.750076293945312, "eval/prior_ent_min": 14.367595672607422, "eval/prior_ent_std": 9.303496360778809, "eval/rep_loss_mean": 25.30706024169922, "eval/rep_loss_std": 14.55234432220459, "eval/reward_avg": 0.01767577975988388, "eval/reward_loss_mean": 0.24082151055335999, "eval/reward_loss_std": 1.4157264232635498, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.001051425933838, "eval/reward_neg_acc": 0.9960039854049683, "eval/reward_neg_loss": 0.10440520197153091, "eval/reward_pos_acc": 0.3913043439388275, "eval/reward_pos_loss": 6.177896499633789, "eval/reward_pred": 0.009828433394432068, "eval/reward_rate": 0.0224609375, "replay/size": 46025.0, "replay/inserts": 2162.0, "replay/samples": 34592.0, "replay/insert_wait_avg": 2.463695409670679e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.757081354689973e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 9992.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 7.599592208862305e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3988285064697, "timer/env.step_count": 271.0, "timer/env.step_total": 28.303208351135254, "timer/env.step_frac": 0.028291924725052008, "timer/env.step_avg": 0.10443988321452123, "timer/env.step_min": 0.023394346237182617, "timer/env.step_max": 3.11366605758667, "timer/replay._sample_count": 34592.0, "timer/replay._sample_total": 16.288411855697632, "timer/replay._sample_frac": 0.016281918162594382, "timer/replay._sample_avg": 0.0004708722206203062, "timer/replay._sample_min": 0.0003261566162109375, "timer/replay._sample_max": 0.022463560104370117, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 271.0, "timer/agent.policy_total": 4.172168731689453, "timer/agent.policy_frac": 0.004170505415243468, "timer/agent.policy_avg": 0.015395456574499826, "timer/agent.policy_min": 0.014396905899047852, "timer/agent.policy_max": 0.037416696548461914, "timer/dataset_train_count": 2162.0, "timer/dataset_train_total": 0.3657693862915039, "timer/dataset_train_frac": 0.0003656235651910686, "timer/dataset_train_avg": 0.00016918102973705084, "timer/dataset_train_min": 8.368492126464844e-05, "timer/dataset_train_max": 0.0006239414215087891, "timer/agent.train_count": 2162.0, "timer/agent.train_total": 957.5089404582977, "timer/agent.train_frac": 0.957127210842296, "timer/agent.train_avg": 0.44288110104454104, "timer/agent.train_min": 0.4301888942718506, "timer/agent.train_max": 0.5636169910430908, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47267746925354004, "timer/agent.report_frac": 0.00047248902716051427, "timer/agent.report_avg": 0.23633873462677002, "timer/agent.report_min": 0.23072004318237305, "timer/agent.report_max": 0.241957426071167, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0279159545898438e-05, "timer/dataset_eval_frac": 3.0267088168329075e-08, "timer/dataset_eval_avg": 3.0279159545898438e-05, "timer/dataset_eval_min": 3.0279159545898438e-05, "timer/dataset_eval_max": 3.0279159545898438e-05, "fps": 2.161109216599406}
{"step": 46816, "time": 21455.85658764839, "episode/length": 168.0, "episode/score": 4.239673242146182, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.13967311760507073}
{"step": 47128, "time": 21597.688869714737, "episode/length": 231.0, "episode/score": 2.376830243800441, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.27683014056333377}
{"step": 47184, "time": 21624.35007596016, "episode/length": 154.0, "episode/score": 1.2571211416482129, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.1571209959049611}
{"step": 47520, "time": 21777.30409860611, "episode/length": 141.0, "episode/score": 4.2529104815548635, "episode/reward_rate": 0.9647887323943662, "episode/intrinsic_return": 0.15291036108828848}
{"step": 47592, "time": 21811.215979337692, "episode/length": 189.0, "episode/score": 4.290762430860923, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.19076225358367083}
{"step": 47640, "time": 21834.365870952606, "episode/length": 156.0, "episode/score": 3.2403001784005028, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.14030014798117918}
{"step": 48088, "time": 22037.269046783447, "episode/length": 213.0, "episode/score": 3.3266164096348803, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.22661631431401474}
{"step": 48368, "time": 22164.92757153511, "episode/length": 193.0, "episode/score": 1.2952176646977023, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.19521762985459645}
{"step": 48648, "time": 22292.513737678528, "episode/length": 182.0, "episode/score": 3.2875524330083863, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.1875523167909705}
{"step": 48688, "time": 22312.13897037506, "episode/length": 194.0, "episode/score": 3.300203251912535, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.20020314541579864}
{"step": 48715, "time": 22326.462577342987, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.285383947363727, "train/action_min": 0.0, "train/action_std": 4.05315541241267, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0369990480783051, "train/actor_opt_grad_steps": 46060.0, "train/actor_opt_loss": -15.017165778434439, "train/adv_mag": 0.6628174056473388, "train/adv_max": 0.6160956461952157, "train/adv_mean": 0.0012346550445469706, "train/adv_min": -0.5214836080324704, "train/adv_std": 0.05241234792762151, "train/cont_avg": 0.9944661458333334, "train/cont_loss_mean": 6.0187442306116624e-05, "train/cont_loss_std": 0.0018524942830154666, "train/cont_neg_acc": 1.0, "train/cont_neg_loss": 0.0011989161785469114, "train/cont_pos_acc": 0.9999954972637298, "train/cont_pos_loss": 5.508473149123214e-05, "train/cont_pred": 0.9944580937629421, "train/cont_rate": 0.9944661458333334, "train/dyn_loss_mean": 2.845003018096157, "train/dyn_loss_std": 7.6591217332779005, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.2118752193233193, "train/extr_critic_critic_opt_grad_steps": 46060.0, "train/extr_critic_critic_opt_loss": 15305.069282427226, "train/extr_critic_mag": 13.948616794255226, "train/extr_critic_max": 13.948616794255226, "train/extr_critic_mean": 2.825907339788463, "train/extr_critic_min": -0.5986699344905, "train/extr_critic_std": 3.0047608635741283, "train/extr_return_normed_mag": 1.5034190514316297, "train/extr_return_normed_max": 1.5034190514316297, "train/extr_return_normed_mean": 0.3146106060509268, "train/extr_return_normed_min": -0.08531795743189446, "train/extr_return_normed_std": 0.31903296641018836, "train/extr_return_rate": 0.7379197974999746, "train/extr_return_raw_mag": 14.190957652923723, "train/extr_return_raw_max": 14.190957652923723, "train/extr_return_raw_mean": 2.8373806068342025, "train/extr_return_raw_min": -0.9836851716313733, "train/extr_return_raw_std": 3.0519061464152926, "train/extr_reward_mag": 1.024317041379676, "train/extr_reward_max": 1.024317041379676, "train/extr_reward_mean": 0.02599896290488371, "train/extr_reward_min": -0.6563482148462234, "train/extr_reward_std": 0.15748864024469297, "train/image_loss_mean": 1.9192743704199247, "train/image_loss_std": 5.164181896540672, "train/model_loss_mean": 3.694239878763347, "train/model_loss_std": 8.827891040610396, "train/model_opt_grad_norm": 36.54884998919228, "train/model_opt_grad_steps": 46019.99086757991, "train/model_opt_loss": 5444.009551583904, "train/model_opt_model_opt_grad_overflow": 0.0091324200913242, "train/model_opt_model_opt_grad_scale": 1472.6027397260275, "train/policy_entropy_mag": 2.5010235189847205, "train/policy_entropy_max": 2.5010235189847205, "train/policy_entropy_mean": 0.5783435355310571, "train/policy_entropy_min": 0.07937501384515196, "train/policy_entropy_std": 0.6444266797745064, "train/policy_logprob_mag": 7.43838369029842, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5791543198230604, "train/policy_logprob_min": -7.43838369029842, "train/policy_logprob_std": 1.1432964937871994, "train/policy_randomness_mag": 0.8827515481269523, "train/policy_randomness_max": 0.8827515481269523, "train/policy_randomness_mean": 0.20412988634142157, "train/policy_randomness_min": 0.0280158967119918, "train/policy_randomness_std": 0.22745433694695774, "train/post_ent_mag": 38.66720088976159, "train/post_ent_max": 38.66720088976159, "train/post_ent_mean": 19.510540583362317, "train/post_ent_min": 10.982555672458318, "train/post_ent_std": 3.6177229053897944, "train/prior_ent_mag": 73.5580338778561, "train/prior_ent_max": 73.5580338778561, "train/prior_ent_mean": 22.38772768517063, "train/prior_ent_min": 12.301487252048162, "train/prior_ent_std": 8.846606744478827, "train/rep_loss_mean": 2.845003018096157, "train/rep_loss_std": 7.6591217332779005, "train/reward_avg": 0.015136631284351354, "train/reward_loss_mean": 0.06790349845132326, "train/reward_loss_std": 0.15514248439438266, "train/reward_max_data": 1.0112956931057586, "train/reward_max_pred": 1.0117181457885325, "train/reward_neg_acc": 0.9994826956426717, "train/reward_neg_loss": 0.05036931309729951, "train/reward_pos_acc": 0.9059306306926083, "train/reward_pos_loss": 0.7236567520659808, "train/reward_pred": 0.014989491275694544, "train/reward_rate": 0.02609517694063927, "train_stats/sum_log_reward": 2.8999999284744264, "train_stats/max_log_achievement_collect_drink": 4.5, "train_stats/max_log_achievement_collect_sapling": 1.3, "train_stats/max_log_achievement_collect_wood": 1.6, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.3, "train_stats/max_log_achievement_place_table": 0.6, "train_stats/max_log_achievement_wake_up": 1.8, "train_stats/mean_log_entropy": 0.5228019833564759, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 2.194321950810263e-06, "report/cont_loss_std": 1.0756522897281684e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00010419133468531072, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.3911960650148103e-06, "report/cont_pred": 0.992186963558197, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 2.541292428970337, "report/dyn_loss_std": 7.5228424072265625, "report/image_loss_mean": 1.8095006942749023, "report/image_loss_std": 3.511793613433838, "report/model_loss_mean": 3.4099669456481934, "report/model_loss_std": 7.396623611450195, "report/post_ent_mag": 41.16822052001953, "report/post_ent_max": 41.16822052001953, "report/post_ent_mean": 19.827617645263672, "report/post_ent_min": 11.28758716583252, "report/post_ent_std": 3.5436739921569824, "report/prior_ent_mag": 74.16954803466797, "report/prior_ent_max": 74.16954803466797, "report/prior_ent_mean": 22.54673957824707, "report/prior_ent_min": 12.444899559020996, "report/prior_ent_std": 8.903251647949219, "report/rep_loss_mean": 2.541292428970337, "report/rep_loss_std": 7.5228424072265625, "report/reward_avg": 0.01651952788233757, "report/reward_loss_mean": 0.07568874955177307, "report/reward_loss_std": 0.17169451713562012, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0036146640777588, "report/reward_neg_acc": 0.9989919066429138, "report/reward_neg_loss": 0.05280556157231331, "report/reward_pos_acc": 0.90625, "report/reward_pos_loss": 0.7850674986839294, "report/reward_pred": 0.016545766964554787, "report/reward_rate": 0.03125, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 2.2391970560420305e-05, "eval/cont_loss_std": 0.0006417914992198348, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.005296492017805576, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 1.709224875412474e-06, "eval/cont_pred": 0.996112585067749, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 25.462427139282227, "eval/dyn_loss_std": 15.795001983642578, "eval/image_loss_mean": 41.51850891113281, "eval/image_loss_std": 54.828983306884766, "eval/model_loss_mean": 57.02315139770508, "eval/model_loss_std": 60.74262619018555, "eval/post_ent_mag": 41.16822052001953, "eval/post_ent_max": 41.16822052001953, "eval/post_ent_mean": 24.47386932373047, "eval/post_ent_min": 15.174596786499023, "eval/post_ent_std": 4.331303596496582, "eval/prior_ent_mag": 74.16954803466797, "eval/prior_ent_max": 74.16954803466797, "eval/prior_ent_mean": 31.609683990478516, "eval/prior_ent_min": 15.182745933532715, "eval/prior_ent_std": 9.946632385253906, "eval/rep_loss_mean": 25.462427139282227, "eval/rep_loss_std": 15.795001983642578, "eval/reward_avg": 0.01601562462747097, "eval/reward_loss_mean": 0.22716575860977173, "eval/reward_loss_std": 1.3239816427230835, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0023484230041504, "eval/reward_neg_acc": 0.9920159578323364, "eval/reward_neg_loss": 0.11400870233774185, "eval/reward_pos_acc": 0.5, "eval/reward_pos_loss": 5.380956172943115, "eval/reward_pred": 0.009250921197235584, "eval/reward_rate": 0.021484375, "replay/size": 48211.0, "replay/inserts": 2186.0, "replay/samples": 34976.0, "replay/insert_wait_avg": 2.4339199502426663e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.751330474267176e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 9992.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 8.940696716308594e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3962194919586, "timer/env.step_count": 273.0, "timer/env.step_total": 22.04771137237549, "timer/env.step_frac": 0.02203897909927349, "timer/env.step_avg": 0.08076084751785893, "timer/env.step_min": 0.023471593856811523, "timer/env.step_max": 1.5963561534881592, "timer/replay._sample_count": 34976.0, "timer/replay._sample_total": 16.305094480514526, "timer/replay._sample_frac": 0.016298636642984227, "timer/replay._sample_avg": 0.0004661795082489286, "timer/replay._sample_min": 0.00033473968505859375, "timer/replay._sample_max": 0.028961181640625, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 273.0, "timer/agent.policy_total": 4.25735330581665, "timer/agent.policy_frac": 0.004255667127549428, "timer/agent.policy_avg": 0.015594700753907145, "timer/agent.policy_min": 0.014333963394165039, "timer/agent.policy_max": 0.050962209701538086, "timer/dataset_train_count": 2186.0, "timer/dataset_train_total": 0.367722749710083, "timer/dataset_train_frac": 0.00036757710849489954, "timer/dataset_train_avg": 0.00016821717736051372, "timer/dataset_train_min": 8.320808410644531e-05, "timer/dataset_train_max": 0.00107574462890625, "timer/agent.train_count": 2186.0, "timer/agent.train_total": 963.5936071872711, "timer/agent.train_frac": 0.963211963832313, "timer/agent.train_avg": 0.440802199079264, "timer/agent.train_min": 0.43123388290405273, "timer/agent.train_max": 0.585970401763916, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4755887985229492, "timer/agent.report_frac": 0.00047540043560387736, "timer/agent.report_avg": 0.2377943992614746, "timer/agent.report_min": 0.231919527053833, "timer/agent.report_max": 0.2436692714691162, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.504753112792969e-05, "timer/dataset_eval_frac": 3.50336501128805e-08, "timer/dataset_eval_avg": 3.504753112792969e-05, "timer/dataset_eval_min": 3.504753112792969e-05, "timer/dataset_eval_max": 3.504753112792969e-05, "fps": 2.185105418913444}
{"step": 48744, "time": 22339.84584212303, "episode/length": 282.0, "episode/score": 3.4059658573096385, "episode/reward_rate": 0.9858657243816255, "episode/intrinsic_return": 0.305965761988773}
{"step": 48912, "time": 22416.88132095337, "episode/length": 158.0, "episode/score": 3.2697391867259284, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.16973912126559298}
{"step": 49160, "time": 22530.611894607544, "episode/length": 133.0, "episode/score": 2.224207078495965, "episode/reward_rate": 0.9626865671641791, "episode/intrinsic_return": 0.12420701297742198}
{"step": 49176, "time": 22539.21237039566, "episode/length": 197.0, "episode/score": 3.326902582666662, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.22690250282903435}
{"step": 49272, "time": 22583.915964126587, "episode/length": 218.0, "episode/score": 4.332986103123403, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.23298593050276395}
{"step": 49640, "time": 22750.926676034927, "episode/length": 158.0, "episode/score": 5.257874739527324, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.15787455677855178}
{"step": 49960, "time": 22896.479687213898, "episode/length": 163.0, "episode/score": 1.2637001941839117, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.16370015439315466}
{"step": 50024, "time": 22944.48100733757, "eval_episode/length": 129.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9538461538461539}
{"step": 50024, "time": 22947.187576770782, "eval_episode/length": 158.0, "eval_episode/score": 4.099999971687794, "eval_episode/reward_rate": 0.9937106918238994}
{"step": 50024, "time": 22948.983340740204, "eval_episode/length": 165.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9939759036144579}
{"step": 50024, "time": 22950.62703680992, "eval_episode/length": 168.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9704142011834319}
{"step": 50024, "time": 22952.37074112892, "eval_episode/length": 175.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9943181818181818}
{"step": 50024, "time": 22955.345714330673, "eval_episode/length": 211.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9952830188679245}
{"step": 50024, "time": 22957.650614261627, "eval_episode/length": 230.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9783549783549783}
{"step": 50024, "time": 22962.345803022385, "eval_episode/length": 141.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9647887323943662}
{"step": 50168, "time": 23026.969215869904, "episode/length": 177.0, "episode/score": 5.281640551627788, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.1816403921620804}
{"step": 50184, "time": 23035.6398127079, "episode/length": 158.0, "episode/score": 3.2769945563377405, "episode/reward_rate": 0.9559748427672956, "episode/intrinsic_return": 0.17699450624422752}
{"step": 50408, "time": 23138.012434244156, "episode/length": 153.0, "episode/score": 5.253790261505856, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.1537900799212366}
{"step": 50456, "time": 23161.062919139862, "episode/length": 161.0, "episode/score": 4.250711497155862, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.1507114844316675}
{"step": 50584, "time": 23220.217108011246, "episode/length": 236.0, "episode/score": 5.35769749226165, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.25769729263265617}
{"step": 50776, "time": 23308.043753385544, "episode/length": 45.0, "episode/score": 3.1436428859342413, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.043642798973451136}
{"step": 50808, "time": 23324.04171514511, "episode/length": 191.0, "episode/score": 4.274727441848881, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.17472737790194515}
{"step": 50809, "time": 23326.76011943817, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.1327876770895635, "train/action_min": 0.0, "train/action_std": 3.9677832674181635, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03483371750304574, "train/actor_opt_grad_steps": 48200.0, "train/actor_opt_loss": -13.796644370949439, "train/adv_mag": 0.7121406987523348, "train/adv_max": 0.6585948333215486, "train/adv_mean": 0.0019733155850233603, "train/adv_min": -0.5505395749111495, "train/adv_std": 0.05110951061204575, "train/cont_avg": 0.9944490131578947, "train/cont_loss_mean": 1.6212812628679425e-05, "train/cont_loss_std": 0.0003889137463975464, "train/cont_neg_acc": 1.0, "train/cont_neg_loss": 0.0016195197776181032, "train/cont_pos_acc": 0.999999978040394, "train/cont_pos_loss": 7.517725661143828e-06, "train/cont_pred": 0.9944494577686182, "train/cont_rate": 0.9944490131578947, "train/dyn_loss_mean": 2.8175909393712093, "train/dyn_loss_std": 7.642072871541292, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1261692115564665, "train/extr_critic_critic_opt_grad_steps": 48200.0, "train/extr_critic_critic_opt_loss": 14702.07091993122, "train/extr_critic_mag": 12.928373085825067, "train/extr_critic_max": 12.928373085825067, "train/extr_critic_mean": 2.6145719204222755, "train/extr_critic_min": -0.6187175883060437, "train/extr_critic_std": 2.7745350593585147, "train/extr_return_normed_mag": 1.5892762670106295, "train/extr_return_normed_max": 1.5892762670106295, "train/extr_return_normed_mean": 0.3344199993964017, "train/extr_return_normed_min": -0.09538196193045406, "train/extr_return_normed_std": 0.33662051625514144, "train/extr_return_rate": 0.6938877231196353, "train/extr_return_raw_mag": 13.144359862405148, "train/extr_return_raw_max": 13.144359862405148, "train/extr_return_raw_mean": 2.6309719593331002, "train/extr_return_raw_min": -0.9720884005418805, "train/extr_return_raw_std": 2.8237727794920997, "train/extr_reward_mag": 1.0209202492636356, "train/extr_reward_max": 1.0209202492636356, "train/extr_reward_mean": 0.027454902092663293, "train/extr_reward_min": -0.661817036747362, "train/extr_reward_std": 0.1619085357947783, "train/image_loss_mean": 1.8438025621706218, "train/image_loss_std": 4.842302997716876, "train/model_loss_mean": 3.6029344118382944, "train/model_loss_std": 8.517146151601983, "train/model_opt_grad_norm": 36.098721403824655, "train/model_opt_grad_steps": 48158.45933014354, "train/model_opt_loss": 5545.640463797099, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1549.043062200957, "train/policy_entropy_mag": 2.5302400497728557, "train/policy_entropy_max": 2.5302400497728557, "train/policy_entropy_mean": 0.5906447739692396, "train/policy_entropy_min": 0.07937501399425799, "train/policy_entropy_std": 0.648949941237007, "train/policy_logprob_mag": 7.438383709300648, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.590077638340909, "train/policy_logprob_min": -7.438383709300648, "train/policy_logprob_std": 1.147394569296586, "train/policy_randomness_mag": 0.8930637017961894, "train/policy_randomness_max": 0.8930637017961894, "train/policy_randomness_mean": 0.2084716843646109, "train/policy_randomness_min": 0.028015896776004842, "train/policy_randomness_std": 0.22905085175231313, "train/post_ent_mag": 39.18594721743935, "train/post_ent_max": 39.18594721743935, "train/post_ent_mean": 19.718272113343744, "train/post_ent_min": 11.126885122089295, "train/post_ent_std": 3.6465310502850836, "train/prior_ent_mag": 73.7637185639742, "train/prior_ent_max": 73.7637185639742, "train/prior_ent_mean": 22.58130484220514, "train/prior_ent_min": 12.3437665410019, "train/prior_ent_std": 8.862209096479644, "train/rep_loss_mean": 2.8175909393712093, "train/rep_loss_std": 7.642072871541292, "train/reward_avg": 0.014902835810984793, "train/reward_loss_mean": 0.06856106546079142, "train/reward_loss_std": 0.15841834229287918, "train/reward_max_data": 1.0117763469093723, "train/reward_max_pred": 1.0123638667558368, "train/reward_neg_acc": 0.9994532882311697, "train/reward_neg_loss": 0.05095097354867242, "train/reward_pos_acc": 0.9067999674943075, "train/reward_pos_loss": 0.7227802943955198, "train/reward_pred": 0.014829979914253907, "train/reward_rate": 0.02620832087320574, "train_stats/sum_log_reward": 3.6714284930910384, "train_stats/max_log_achievement_collect_drink": 3.357142857142857, "train_stats/max_log_achievement_collect_sapling": 2.357142857142857, "train_stats/max_log_achievement_collect_wood": 2.5714285714285716, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.7857142857142858, "train_stats/max_log_achievement_place_table": 1.0, "train_stats/max_log_achievement_wake_up": 1.6428571428571428, "train_stats/mean_log_entropy": 0.5022813869374139, "eval_stats/sum_log_reward": 3.5999999344348907, "eval_stats/max_log_achievement_collect_drink": 2.75, "eval_stats/max_log_achievement_collect_sapling": 3.375, "eval_stats/max_log_achievement_collect_wood": 1.25, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.125, "eval_stats/max_log_achievement_place_plant": 2.75, "eval_stats/max_log_achievement_place_table": 0.375, "eval_stats/max_log_achievement_wake_up": 1.875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 1.627372512302827e-06, "report/cont_loss_std": 4.220491518935887e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 1.5600719052599743e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.5450149248863454e-06, "report/cont_pred": 0.9941391944885254, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 2.974916696548462, "report/dyn_loss_std": 7.996729850769043, "report/image_loss_mean": 2.523662805557251, "report/image_loss_std": 4.938746929168701, "report/model_loss_mean": 4.379383563995361, "report/model_loss_std": 8.825470924377441, "report/post_ent_mag": 42.014625549316406, "report/post_ent_max": 42.014625549316406, "report/post_ent_mean": 19.355438232421875, "report/post_ent_min": 10.399072647094727, "report/post_ent_std": 3.7382190227508545, "report/prior_ent_mag": 73.94957733154297, "report/prior_ent_max": 73.94957733154297, "report/prior_ent_mean": 22.399959564208984, "report/prior_ent_min": 11.581897735595703, "report/prior_ent_std": 9.086393356323242, "report/rep_loss_mean": 2.974916696548462, "report/rep_loss_std": 7.996729850769043, "report/reward_avg": 0.0110156936571002, "report/reward_loss_mean": 0.0707692801952362, "report/reward_loss_std": 0.12694670259952545, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0021851062774658, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.05629061535000801, "report/reward_pos_acc": 0.9166666865348816, "report/reward_pos_loss": 0.6740473508834839, "report/reward_pred": 0.01101817935705185, "report/reward_rate": 0.0234375, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.004436946008354425, "eval/cont_loss_std": 0.14174605906009674, "eval/cont_neg_acc": 0.8333333730697632, "eval/cont_neg_loss": 0.7569419741630554, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.7492675397079438e-06, "eval/cont_pred": 0.9951084852218628, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 24.80999755859375, "eval/dyn_loss_std": 15.312224388122559, "eval/image_loss_mean": 39.702239990234375, "eval/image_loss_std": 46.26087951660156, "eval/model_loss_mean": 54.73516082763672, "eval/model_loss_std": 52.555850982666016, "eval/post_ent_mag": 42.014625549316406, "eval/post_ent_max": 42.014625549316406, "eval/post_ent_mean": 24.16074562072754, "eval/post_ent_min": 13.632516860961914, "eval/post_ent_std": 4.159989833831787, "eval/prior_ent_mag": 73.94957733154297, "eval/prior_ent_max": 73.94957733154297, "eval/prior_ent_mean": 31.339876174926758, "eval/prior_ent_min": 15.971635818481445, "eval/prior_ent_std": 9.733969688415527, "eval/rep_loss_mean": 24.80999755859375, "eval/rep_loss_std": 15.312224388122559, "eval/reward_avg": 0.01572265662252903, "eval/reward_loss_mean": 0.14248840510845184, "eval/reward_loss_std": 0.995688796043396, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0066051483154297, "eval/reward_neg_acc": 0.9950199723243713, "eval/reward_neg_loss": 0.0801706537604332, "eval/reward_pos_acc": 0.699999988079071, "eval/reward_pos_loss": 3.2708396911621094, "eval/reward_pred": 0.01395244151353836, "eval/reward_rate": 0.01953125, "replay/size": 50305.0, "replay/inserts": 2094.0, "replay/samples": 33504.0, "replay/insert_wait_avg": 2.556680608273919e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.616172775042661e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 12456.0, "eval_replay/inserts": 2464.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1921896562947856e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.301568984985352e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2832448482513, "timer/env.step_count": 262.0, "timer/env.step_total": 27.72253441810608, "timer/env.step_frac": 0.027714684376535514, "timer/env.step_avg": 0.10581120006910717, "timer/env.step_min": 0.023604631423950195, "timer/env.step_max": 1.7146475315093994, "timer/replay._sample_count": 33504.0, "timer/replay._sample_total": 15.659311056137085, "timer/replay._sample_frac": 0.01565487689290716, "timer/replay._sample_avg": 0.00046738631375767324, "timer/replay._sample_min": 0.0003371238708496094, "timer/replay._sample_max": 0.029848098754882812, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 570.0, "timer/agent.policy_total": 8.728408813476562, "timer/agent.policy_frac": 0.0087259372367081, "timer/agent.policy_avg": 0.015312997918379935, "timer/agent.policy_min": 0.009268760681152344, "timer/agent.policy_max": 0.021990060806274414, "timer/dataset_train_count": 2094.0, "timer/dataset_train_total": 0.42812538146972656, "timer/dataset_train_frac": 0.00042800415149878433, "timer/dataset_train_avg": 0.00020445338179070038, "timer/dataset_train_min": 8.535385131835938e-05, "timer/dataset_train_max": 0.042565107345581055, "timer/agent.train_count": 2094.0, "timer/agent.train_total": 922.6170220375061, "timer/agent.train_frac": 0.9223557695175354, "timer/agent.train_avg": 0.4406002970570707, "timer/agent.train_min": 0.4200413227081299, "timer/agent.train_max": 0.5595963001251221, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47309136390686035, "timer/agent.report_frac": 0.0004729574011595396, "timer/agent.report_avg": 0.23654568195343018, "timer/agent.report_min": 0.22949814796447754, "timer/agent.report_max": 0.2435932159423828, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.6702880859375e-05, "timer/dataset_eval_frac": 2.6695319547640706e-08, "timer/dataset_eval_avg": 2.6702880859375e-05, "timer/dataset_eval_min": 2.6702880859375e-05, "timer/dataset_eval_max": 2.6702880859375e-05, "fps": 2.0933804631878763}
{"step": 51176, "time": 23492.50512266159, "episode/length": 191.0, "episode/score": 3.2893725362464465, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.18937244092558103}
{"step": 51664, "time": 23715.235684156418, "episode/length": 212.0, "episode/score": 5.333056828660119, "episode/reward_rate": 0.971830985915493, "episode/intrinsic_return": 0.23305669503861282}
{"step": 51808, "time": 23781.892401456833, "episode/length": 168.0, "episode/score": 3.2603714873675926, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.16037139321088034}
{"step": 51880, "time": 23816.01489329338, "episode/length": 211.0, "episode/score": 3.3075924480508547, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.20759235272998922}
{"step": 51976, "time": 23860.895675182343, "episode/length": 145.0, "episode/score": 3.2318020573666217, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.13180211614690052}
{"step": 52240, "time": 23982.128721237183, "episode/length": 182.0, "episode/score": 0.3098135180562167, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.20981351842874574}
{"step": 52272, "time": 23998.053428411484, "episode/length": 262.0, "episode/score": 1.3652750566106988, "episode/reward_rate": 0.9961977186311787, "episode/intrinsic_return": 0.2652749350963859}
{"step": 52376, "time": 24046.51115131378, "episode/length": 223.0, "episode/score": 3.3055576672159077, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.2055576066741196}
{"step": 52624, "time": 24159.969950914383, "episode/length": 180.0, "episode/score": 5.292419494560818, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.1924193583199667}
{"step": 52928, "time": 24298.662558555603, "episode/length": 157.0, "episode/score": 4.235223288968882, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.13522315662794426}
{"step": 52986, "time": 24326.898718595505, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.127500761539564, "train/action_min": 0.0, "train/action_std": 3.933034511881137, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03703480782072752, "train/actor_opt_grad_steps": 50335.0, "train/actor_opt_loss": -14.647685071060417, "train/adv_mag": 0.6708903177342284, "train/adv_max": 0.5993740976950445, "train/adv_mean": 0.00238257061827334, "train/adv_min": -0.5619479237346474, "train/adv_std": 0.05372352156480518, "train/cont_avg": 0.994498996559633, "train/cont_loss_mean": 0.00011943361942750275, "train/cont_loss_std": 0.003649370245598387, "train/cont_neg_acc": 0.9966251645066323, "train/cont_neg_loss": 0.011354543908476719, "train/cont_pos_acc": 0.9999909712633955, "train/cont_pos_loss": 3.80761421376661e-05, "train/cont_pred": 0.9945000180410682, "train/cont_rate": 0.994498996559633, "train/dyn_loss_mean": 2.815000951836962, "train/dyn_loss_std": 7.663064081734474, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.09395462821383, "train/extr_critic_critic_opt_grad_steps": 50335.0, "train/extr_critic_critic_opt_loss": 14907.129148150803, "train/extr_critic_mag": 12.804556724128373, "train/extr_critic_max": 12.804556724128373, "train/extr_critic_mean": 2.520113891964659, "train/extr_critic_min": -0.6398600979682503, "train/extr_critic_std": 2.68522646503711, "train/extr_return_normed_mag": 1.6247646283665929, "train/extr_return_normed_max": 1.6247646283665929, "train/extr_return_normed_mean": 0.33115534108439715, "train/extr_return_normed_min": -0.09772599997733711, "train/extr_return_normed_std": 0.33143185106439327, "train/extr_return_rate": 0.6730528814256738, "train/extr_return_raw_mag": 13.253812908032618, "train/extr_return_raw_max": 13.253812908032618, "train/extr_return_raw_mean": 2.5397961664637294, "train/extr_return_raw_min": -1.0041024600147108, "train/extr_return_raw_std": 2.7471216058512344, "train/extr_reward_mag": 1.0234132556740296, "train/extr_reward_max": 1.0234132556740296, "train/extr_reward_mean": 0.02780572883784771, "train/extr_reward_min": -0.6569038044422044, "train/extr_reward_std": 0.16338484129364336, "train/image_loss_mean": 1.798229469618666, "train/image_loss_std": 4.817828575952338, "train/model_loss_mean": 3.555396144543219, "train/model_loss_std": 8.522936162598636, "train/model_opt_grad_norm": 36.51674348936169, "train/model_opt_grad_steps": 50292.266055045875, "train/model_opt_loss": 6321.962459459217, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1766.0550458715597, "train/policy_entropy_mag": 2.513402103284083, "train/policy_entropy_max": 2.513402103284083, "train/policy_entropy_mean": 0.6048016107957298, "train/policy_entropy_min": 0.07937501381159923, "train/policy_entropy_std": 0.6548247903312018, "train/policy_logprob_mag": 7.438383712681062, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.6048675957349462, "train/policy_logprob_min": -7.438383712681062, "train/policy_logprob_std": 1.150922070402618, "train/policy_randomness_mag": 0.8871206452540301, "train/policy_randomness_max": 0.8871206452540301, "train/policy_randomness_mean": 0.21346842757332216, "train/policy_randomness_min": 0.02801589671214786, "train/policy_randomness_std": 0.23112441462661149, "train/post_ent_mag": 39.68887377222744, "train/post_ent_max": 39.68887377222744, "train/post_ent_mean": 19.868021886283106, "train/post_ent_min": 11.086807005996004, "train/post_ent_std": 3.6315761782707425, "train/prior_ent_mag": 73.83948331360423, "train/prior_ent_max": 73.83948331360423, "train/prior_ent_mean": 22.716963907994263, "train/prior_ent_min": 12.325310147136722, "train/prior_ent_std": 8.82984414669352, "train/rep_loss_mean": 2.815000951836962, "train/rep_loss_std": 7.663064081734474, "train/reward_avg": 0.014688941003934164, "train/reward_loss_mean": 0.06804666413558186, "train/reward_loss_std": 0.14876914311439618, "train/reward_max_data": 1.010883058429858, "train/reward_max_pred": 1.011670423210214, "train/reward_neg_acc": 0.9994800265775908, "train/reward_neg_loss": 0.050826577127936784, "train/reward_pos_acc": 0.9090265289905968, "train/reward_pos_loss": 0.7170221947748726, "train/reward_pred": 0.014622932902340768, "train/reward_rate": 0.02581619122706422, "train_stats/sum_log_reward": 3.099999928474426, "train_stats/max_log_achievement_collect_drink": 3.1, "train_stats/max_log_achievement_collect_sapling": 1.8, "train_stats/max_log_achievement_collect_wood": 1.6, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.7, "train_stats/max_log_achievement_place_table": 0.7, "train_stats/max_log_achievement_wake_up": 2.2, "train_stats/mean_log_entropy": 0.6118525356054306, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 1.2704347227554535e-06, "report/cont_loss_std": 2.5734732389537385e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 2.8922484489157796e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.1891847861988936e-06, "report/cont_pred": 0.9970691204071045, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 2.7404327392578125, "report/dyn_loss_std": 7.864288806915283, "report/image_loss_mean": 2.344386577606201, "report/image_loss_std": 5.04274845123291, "report/model_loss_mean": 4.059467315673828, "report/model_loss_std": 8.642645835876465, "report/post_ent_mag": 35.333290100097656, "report/post_ent_max": 35.333290100097656, "report/post_ent_mean": 19.52361297607422, "report/post_ent_min": 10.428647994995117, "report/post_ent_std": 3.5996241569519043, "report/prior_ent_mag": 73.9181900024414, "report/prior_ent_max": 73.9181900024414, "report/prior_ent_mean": 22.23479461669922, "report/prior_ent_min": 11.173205375671387, "report/prior_ent_std": 8.436474800109863, "report/rep_loss_mean": 2.7404327392578125, "report/rep_loss_std": 7.864288806915283, "report/reward_avg": 0.015194686129689217, "report/reward_loss_mean": 0.07082024216651917, "report/reward_loss_std": 0.16701248288154602, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0065348148345947, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.049429282546043396, "report/reward_pos_acc": 0.9677419066429138, "report/reward_pos_loss": 0.7560207843780518, "report/reward_pred": 0.014585262164473534, "report/reward_rate": 0.0302734375, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 3.317854134365916e-05, "eval/cont_loss_std": 0.0007715699612163007, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.008243988268077374, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 9.79287165137066e-07, "eval/cont_pred": 0.9961246252059937, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 25.955961227416992, "eval/dyn_loss_std": 14.758394241333008, "eval/image_loss_mean": 49.89340591430664, "eval/image_loss_std": 50.176300048828125, "eval/model_loss_mean": 65.6527099609375, "eval/model_loss_std": 55.94451141357422, "eval/post_ent_mag": 43.680030822753906, "eval/post_ent_max": 43.680030822753906, "eval/post_ent_mean": 25.38995361328125, "eval/post_ent_min": 15.125045776367188, "eval/post_ent_std": 4.014182090759277, "eval/prior_ent_mag": 73.9181900024414, "eval/prior_ent_max": 73.9181900024414, "eval/prior_ent_mean": 33.656776428222656, "eval/prior_ent_min": 18.357791900634766, "eval/prior_ent_std": 8.855955123901367, "eval/rep_loss_mean": 25.955961227416992, "eval/rep_loss_std": 14.758394241333008, "eval/reward_avg": 0.02167968824505806, "eval/reward_loss_mean": 0.18569231033325195, "eval/reward_loss_std": 1.2327879667282104, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0012376308441162, "eval/reward_neg_acc": 0.9939879775047302, "eval/reward_neg_loss": 0.07764488458633423, "eval/reward_pos_acc": 0.6538462042808533, "eval/reward_pos_loss": 4.333052158355713, "eval/reward_pred": 0.01775255613029003, "eval/reward_rate": 0.025390625, "replay/size": 52482.0, "replay/inserts": 2177.0, "replay/samples": 34832.0, "replay/insert_wait_avg": 2.6071624685768472e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.727247999521587e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 12456.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 8.046627044677734e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1254713535309, "timer/env.step_count": 272.0, "timer/env.step_total": 22.175145387649536, "timer/env.step_frac": 0.02217236339120386, "timer/env.step_avg": 0.08152626980753507, "timer/env.step_min": 0.023615121841430664, "timer/env.step_max": 1.6442592144012451, "timer/replay._sample_count": 34832.0, "timer/replay._sample_total": 16.268616914749146, "timer/replay._sample_frac": 0.016266575925450465, "timer/replay._sample_avg": 0.0004670595117922929, "timer/replay._sample_min": 0.0003445148468017578, "timer/replay._sample_max": 0.010406494140625, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 272.0, "timer/agent.policy_total": 4.163153886795044, "timer/agent.policy_frac": 0.004162631595774471, "timer/agent.policy_avg": 0.015305712819099426, "timer/agent.policy_min": 0.01432037353515625, "timer/agent.policy_max": 0.03531169891357422, "timer/dataset_train_count": 2177.0, "timer/dataset_train_total": 0.36646175384521484, "timer/dataset_train_frac": 0.0003664157791614484, "timer/dataset_train_avg": 0.0001683333733786012, "timer/dataset_train_min": 8.416175842285156e-05, "timer/dataset_train_max": 0.0005087852478027344, "timer/agent.train_count": 2177.0, "timer/agent.train_total": 963.3565990924835, "timer/agent.train_frac": 0.9632357406003411, "timer/agent.train_avg": 0.4425156633405988, "timer/agent.train_min": 0.43052101135253906, "timer/agent.train_max": 0.8217868804931641, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4712364673614502, "timer/agent.report_frac": 0.00047117734810183076, "timer/agent.report_avg": 0.2356182336807251, "timer/agent.report_min": 0.22808194160461426, "timer/agent.report_max": 0.24315452575683594, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.6226043701171875e-05, "timer/dataset_eval_frac": 2.6222753496797324e-08, "timer/dataset_eval_avg": 2.6226043701171875e-05, "timer/dataset_eval_min": 2.6226043701171875e-05, "timer/dataset_eval_max": 2.6226043701171875e-05, "fps": 2.176699085637493}
{"step": 53128, "time": 24391.890372991562, "episode/length": 164.0, "episode/score": 6.281827632579734, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.18182749878360482}
{"step": 53272, "time": 24458.940213680267, "episode/length": 173.0, "episode/score": 4.272515307908179, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.17251521060825326}
{"step": 53368, "time": 24504.26545190811, "episode/length": 173.0, "episode/score": 5.2844669291635, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.18446674990718748}
{"step": 53544, "time": 24585.97748398781, "episode/length": 158.0, "episode/score": 4.2106044832517, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.11060440955498052}
{"step": 53632, "time": 24627.575004577637, "episode/length": 173.0, "episode/score": 4.278885920904941, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.17888580008911958}
{"step": 53768, "time": 24691.330214500427, "episode/length": 173.0, "episode/score": 5.298387532747256, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.19838739342139888}
{"step": 54056, "time": 24823.973081111908, "episode/length": 178.0, "episode/score": 5.269774280855927, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.1697741498828691}
{"step": 54368, "time": 24967.966223955154, "episode/length": 179.0, "episode/score": 4.284054904673212, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.1840547285601133}
{"step": 54616, "time": 25082.767596244812, "episode/length": 155.0, "episode/score": 5.273094082507669, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.17309399597615993}
{"step": 54624, "time": 25087.974368810654, "episode/length": 186.0, "episode/score": 4.2691848437643785, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.1691848368027422}
{"step": 54704, "time": 25126.069318532944, "episode/length": 178.0, "episode/score": 3.2835834361503657, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.1835832851829764}
{"step": 55000, "time": 25262.67660021782, "episode/length": 181.0, "episode/score": 2.2726892911773575, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.1726892972251335}
{"step": 55096, "time": 25307.93035507202, "episode/length": 182.0, "episode/score": 4.292932170731547, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.19293202231074247}
{"step": 55134, "time": 25327.28044319153, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.215507187954215, "train/action_min": 0.0, "train/action_std": 4.068660657350407, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.036300108703069905, "train/actor_opt_grad_steps": 52500.0, "train/actor_opt_loss": -15.388163157257923, "train/adv_mag": 0.6757502734661103, "train/adv_max": 0.604758947394615, "train/adv_mean": 0.0017008852230203555, "train/adv_min": -0.5582095615392507, "train/adv_std": 0.05149853496357452, "train/cont_avg": 0.9943359375, "train/cont_loss_mean": 5.426382112657023e-05, "train/cont_loss_std": 0.0016490635146790863, "train/cont_neg_acc": 0.9974750834842061, "train/cont_neg_loss": 0.004842700553219698, "train/cont_pos_acc": 0.9999908466671789, "train/cont_pos_loss": 2.6700124766288946e-05, "train/cont_pred": 0.9943363547325135, "train/cont_rate": 0.9943359375, "train/dyn_loss_mean": 2.9403818396634835, "train/dyn_loss_std": 7.749678613973218, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1158647517825282, "train/extr_critic_critic_opt_grad_steps": 52500.0, "train/extr_critic_critic_opt_loss": 14825.278769985465, "train/extr_critic_mag": 12.378632687413415, "train/extr_critic_max": 12.378632687413415, "train/extr_critic_mean": 2.4429245970969977, "train/extr_critic_min": -0.65969054976175, "train/extr_critic_std": 2.7121339587278146, "train/extr_return_normed_mag": 1.6027066180872362, "train/extr_return_normed_max": 1.6027066180872362, "train/extr_return_normed_mean": 0.33220640829829284, "train/extr_return_normed_min": -0.10349130890397139, "train/extr_return_normed_std": 0.3395855634018432, "train/extr_return_rate": 0.6558036919250044, "train/extr_return_raw_mag": 12.787228748410246, "train/extr_return_raw_max": 12.787228748410246, "train/extr_return_raw_mean": 2.456821731633918, "train/extr_return_raw_min": -1.0786757216897123, "train/extr_return_raw_std": 2.757120351458705, "train/extr_reward_mag": 1.0239783386851466, "train/extr_reward_max": 1.0239783386851466, "train/extr_reward_mean": 0.029946722003609635, "train/extr_reward_min": -0.6621905254763226, "train/extr_reward_std": 0.16957133166318716, "train/image_loss_mean": 2.0362367926641953, "train/image_loss_std": 5.841811772279961, "train/model_loss_mean": 3.8695704127466954, "train/model_loss_std": 9.516261741726897, "train/model_opt_grad_norm": 36.19071899236635, "train/model_opt_grad_steps": 52455.395348837206, "train/model_opt_loss": 5636.390751044695, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1453.4883720930231, "train/policy_entropy_mag": 2.53160439868306, "train/policy_entropy_max": 2.53160439868306, "train/policy_entropy_mean": 0.6200082123279571, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6738334451997003, "train/policy_logprob_mag": 7.438383718978527, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.6196444371411967, "train/policy_logprob_min": -7.438383718978527, "train/policy_logprob_std": 1.159029587202294, "train/policy_randomness_mag": 0.893545256936273, "train/policy_randomness_max": 0.893545256936273, "train/policy_randomness_mean": 0.21883569124133087, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.237833635543668, "train/post_ent_mag": 39.50316002424373, "train/post_ent_max": 39.50316002424373, "train/post_ent_mean": 19.977326140292856, "train/post_ent_min": 11.265900310250215, "train/post_ent_std": 3.619791715089665, "train/prior_ent_mag": 73.92101561080578, "train/prior_ent_max": 73.92101561080578, "train/prior_ent_mean": 22.931187749463458, "train/prior_ent_min": 12.488828388480252, "train/prior_ent_std": 8.876816144100456, "train/rep_loss_mean": 2.9403818396634835, "train/rep_loss_std": 7.749678613973218, "train/reward_avg": 0.014885526893898672, "train/reward_loss_mean": 0.06905025562574697, "train/reward_loss_std": 0.15887449473835702, "train/reward_max_data": 1.010552356409472, "train/reward_max_pred": 1.0115803785102313, "train/reward_neg_acc": 0.9994775411694549, "train/reward_neg_loss": 0.05114232282652411, "train/reward_pos_acc": 0.9054656461227771, "train/reward_pos_loss": 0.7308919695920723, "train/reward_pred": 0.014727331888537074, "train/reward_rate": 0.026394440406976746, "train_stats/sum_log_reward": 4.330769208761362, "train_stats/max_log_achievement_collect_drink": 2.230769230769231, "train_stats/max_log_achievement_collect_sapling": 1.6923076923076923, "train_stats/max_log_achievement_collect_wood": 2.5384615384615383, "train_stats/max_log_achievement_defeat_skeleton": 0.07692307692307693, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.07692307692307693, "train_stats/max_log_achievement_make_wood_pickaxe": 0.07692307692307693, "train_stats/max_log_achievement_make_wood_sword": 0.07692307692307693, "train_stats/max_log_achievement_place_plant": 1.5384615384615385, "train_stats/max_log_achievement_place_table": 1.0, "train_stats/max_log_achievement_wake_up": 1.8461538461538463, "train_stats/mean_log_entropy": 0.4706571125067197, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 6.592845238628797e-07, "report/cont_loss_std": 2.1237890450720442e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 2.9688269933103584e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 5.739888138123206e-07, "report/cont_pred": 0.9970698952674866, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 2.802600383758545, "report/dyn_loss_std": 7.5396857261657715, "report/image_loss_mean": 2.248541831970215, "report/image_loss_std": 6.912339210510254, "report/model_loss_mean": 3.9885754585266113, "report/model_loss_std": 10.087844848632812, "report/post_ent_mag": 35.03633499145508, "report/post_ent_max": 35.03633499145508, "report/post_ent_mean": 19.213708877563477, "report/post_ent_min": 9.073614120483398, "report/post_ent_std": 3.688628673553467, "report/prior_ent_mag": 73.17576599121094, "report/prior_ent_max": 73.17576599121094, "report/prior_ent_mean": 22.24457550048828, "report/prior_ent_min": 12.030284881591797, "report/prior_ent_std": 8.558809280395508, "report/rep_loss_mean": 2.802600383758545, "report/rep_loss_std": 7.5396857261657715, "report/reward_avg": 0.02005859650671482, "report/reward_loss_mean": 0.05847290903329849, "report/reward_loss_std": 0.13141050934791565, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0040411949157715, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.041334860026836395, "report/reward_pos_acc": 0.9599999785423279, "report/reward_pos_loss": 0.7433094382286072, "report/reward_pred": 0.019315415993332863, "report/reward_rate": 0.0244140625, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.012284280732274055, "eval/cont_loss_std": 0.392874538898468, "eval/cont_neg_acc": 0.6666666865348816, "eval/cont_neg_loss": 4.192821502685547, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 6.26593077868165e-07, "eval/cont_pred": 0.9980466365814209, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 26.927934646606445, "eval/dyn_loss_std": 12.892351150512695, "eval/image_loss_mean": 56.936458587646484, "eval/image_loss_std": 53.48069381713867, "eval/model_loss_mean": 73.2859878540039, "eval/model_loss_std": 57.40486145019531, "eval/post_ent_mag": 37.761985778808594, "eval/post_ent_max": 37.761985778808594, "eval/post_ent_mean": 25.7595157623291, "eval/post_ent_min": 14.999265670776367, "eval/post_ent_std": 3.9726297855377197, "eval/prior_ent_mag": 73.17576599121094, "eval/prior_ent_max": 73.17576599121094, "eval/prior_ent_mean": 34.4342041015625, "eval/prior_ent_min": 16.406225204467773, "eval/prior_ent_std": 8.927868843078613, "eval/rep_loss_mean": 26.927934646606445, "eval/rep_loss_std": 12.892351150512695, "eval/reward_avg": 0.01123046875, "eval/reward_loss_mean": 0.18048685789108276, "eval/reward_loss_std": 1.0675970315933228, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0048727989196777, "eval/reward_neg_acc": 0.9990089535713196, "eval/reward_neg_loss": 0.11942709982395172, "eval/reward_pos_acc": 0.5333333611488342, "eval/reward_pos_loss": 4.287774085998535, "eval/reward_pred": 0.00731267174705863, "eval/reward_rate": 0.0146484375, "replay/size": 54630.0, "replay/inserts": 2148.0, "replay/samples": 34368.0, "replay/insert_wait_avg": 2.5617787735866213e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.90080655664483e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 12456.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 6.854534149169922e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3679852485657, "timer/env.step_count": 268.0, "timer/env.step_total": 26.534688711166382, "timer/env.step_frac": 0.026524927928969252, "timer/env.step_avg": 0.09901003250435217, "timer/env.step_min": 0.023856401443481445, "timer/env.step_max": 1.615762710571289, "timer/replay._sample_count": 34368.0, "timer/replay._sample_total": 16.678319931030273, "timer/replay._sample_frac": 0.016672184812957746, "timer/replay._sample_avg": 0.0004852863108423613, "timer/replay._sample_min": 0.00034689903259277344, "timer/replay._sample_max": 0.011086702346801758, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 268.0, "timer/agent.policy_total": 4.1863062381744385, "timer/agent.policy_frac": 0.0041847663059051705, "timer/agent.policy_avg": 0.015620545664829994, "timer/agent.policy_min": 0.01455831527709961, "timer/agent.policy_max": 0.018174409866333008, "timer/dataset_train_count": 2148.0, "timer/dataset_train_total": 0.42412543296813965, "timer/dataset_train_frac": 0.0004239694184762974, "timer/dataset_train_avg": 0.00019745131888647098, "timer/dataset_train_min": 9.369850158691406e-05, "timer/dataset_train_max": 0.03175234794616699, "timer/agent.train_count": 2148.0, "timer/agent.train_total": 958.4977686405182, "timer/agent.train_frac": 0.9581451853463265, "timer/agent.train_avg": 0.4462280114713772, "timer/agent.train_min": 0.4364330768585205, "timer/agent.train_max": 0.5912065505981445, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47771477699279785, "timer/agent.report_frac": 0.00047753904966690635, "timer/agent.report_avg": 0.23885738849639893, "timer/agent.report_min": 0.2309572696685791, "timer/agent.report_max": 0.24675750732421875, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.6716461181640625e-05, "timer/dataset_eval_frac": 3.670295503560875e-08, "timer/dataset_eval_avg": 3.6716461181640625e-05, "timer/dataset_eval_min": 3.6716461181640625e-05, "timer/dataset_eval_max": 3.6716461181640625e-05, "fps": 2.1471789785770996}
{"step": 55200, "time": 25357.653380393982, "episode/length": 178.0, "episode/score": 4.291194369847744, "episode/reward_rate": 0.9664804469273743, "episode/intrinsic_return": 0.19119431576700663}
{"step": 55368, "time": 25435.86596751213, "episode/length": 93.0, "episode/score": 3.2056260293757077, "episode/reward_rate": 0.9893617021276596, "episode/intrinsic_return": 0.10562592776841484}
{"step": 55384, "time": 25444.798437833786, "episode/length": 165.0, "episode/score": 1.2444237800332303, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.1444238008366483}
{"step": 55680, "time": 25581.626190900803, "episode/length": 36.0, "episode/score": -0.8541666312376037, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.04583333234768361}
{"step": 55704, "time": 25594.14214682579, "episode/length": 166.0, "episode/score": 3.251760585465945, "episode/reward_rate": 0.9880239520958084, "episode/intrinsic_return": 0.15176052132983386}
{"step": 55952, "time": 25709.06587457657, "episode/length": 155.0, "episode/score": 2.2568229174148655, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.15682282139550807}
{"step": 56256, "time": 25849.60467004776, "episode/length": 203.0, "episode/score": 4.32208125140005, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.2220810486278424}
{"step": 56344, "time": 25891.179582118988, "episode/length": 155.0, "episode/score": 2.2773845470901506, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.17738448157160747}
{"step": 56360, "time": 25899.955782413483, "episode/length": 169.0, "episode/score": 4.284103434674307, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.18410336595434273}
{"step": 56376, "time": 25908.77414250374, "episode/length": 146.0, "episode/score": 4.272316855765894, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.17231667965279485}
{"step": 56648, "time": 26034.43953895569, "episode/length": 37.0, "episode/score": 0.14306548491003923, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.04306547550368123}
{"step": 56792, "time": 26101.57520222664, "episode/length": 177.0, "episode/score": 3.260231716045382, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.16023166865852545}
{"step": 57008, "time": 26201.611354351044, "episode/length": 44.0, "episode/score": -0.864433643348093, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.03556632885192812}
{"step": 57096, "time": 26243.265664339066, "episode/length": 173.0, "episode/score": 1.2591082452763658, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.15910817648364173}
{"step": 57232, "time": 26307.00317788124, "episode/length": 193.0, "episode/score": 4.30110607167353, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.20110589206797158}
{"step": 57272, "time": 26327.393818855286, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.204338287638727, "train/action_min": 0.0, "train/action_std": 3.9902683886412147, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03745092200898679, "train/actor_opt_grad_steps": 54645.0, "train/actor_opt_loss": -11.651665896734345, "train/adv_mag": 0.6558736142154052, "train/adv_max": 0.5863159644269498, "train/adv_mean": 0.002702009431809996, "train/adv_min": -0.5345668897868316, "train/adv_std": 0.05035090439509009, "train/cont_avg": 0.9945422021028038, "train/cont_loss_mean": 7.430953841588438e-05, "train/cont_loss_std": 0.0022915016755567868, "train/cont_neg_acc": 0.9988651540234824, "train/cont_neg_loss": 0.008790820250745289, "train/cont_pos_acc": 0.99999538370382, "train/cont_pos_loss": 9.612197687356584e-06, "train/cont_pred": 0.9945486511025473, "train/cont_rate": 0.9945422021028038, "train/dyn_loss_mean": 2.8332145626299847, "train/dyn_loss_std": 7.697835612519879, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0982773267777166, "train/extr_critic_critic_opt_grad_steps": 54645.0, "train/extr_critic_critic_opt_loss": 14769.121969918224, "train/extr_critic_mag": 12.484827166405793, "train/extr_critic_max": 12.484827166405793, "train/extr_critic_mean": 2.4879957203553102, "train/extr_critic_min": -0.6351722529001325, "train/extr_critic_std": 2.6385042711953135, "train/extr_return_normed_mag": 1.6404649264344544, "train/extr_return_normed_max": 1.6404649264344544, "train/extr_return_normed_mean": 0.3450499345487523, "train/extr_return_normed_min": -0.10241420943046285, "train/extr_return_normed_std": 0.3398275339157782, "train/extr_return_rate": 0.6874915198466488, "train/extr_return_raw_mag": 12.790072819896947, "train/extr_return_raw_max": 12.790072819896947, "train/extr_return_raw_mean": 2.509502168013671, "train/extr_return_raw_min": -1.02381740218011, "train/extr_return_raw_std": 2.6875425694144774, "train/extr_reward_mag": 1.0287483763471943, "train/extr_reward_max": 1.0287483763471943, "train/extr_reward_mean": 0.031737732252750166, "train/extr_reward_min": -0.6597472267730213, "train/extr_reward_std": 0.17426144512735794, "train/image_loss_mean": 1.762424557008476, "train/image_loss_std": 4.8993938180887815, "train/model_loss_mean": 3.5308337356442605, "train/model_loss_std": 8.643956855078724, "train/model_opt_grad_norm": 35.158468464824644, "train/model_opt_grad_steps": 54598.46728971963, "train/model_opt_loss": 4849.9200485086885, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1378.5046728971963, "train/policy_entropy_mag": 2.537665874044472, "train/policy_entropy_max": 2.537665874044472, "train/policy_entropy_mean": 0.5988594073558522, "train/policy_entropy_min": 0.07937501377869989, "train/policy_entropy_std": 0.6588486162858589, "train/policy_logprob_mag": 7.438383739685344, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5981421907928502, "train/policy_logprob_min": -7.438383739685344, "train/policy_logprob_std": 1.148167468398531, "train/policy_randomness_mag": 0.895684691511582, "train/policy_randomness_max": 0.895684691511582, "train/policy_randomness_mean": 0.21137109224762873, "train/policy_randomness_min": 0.028015896704082735, "train/policy_randomness_std": 0.2325446481738135, "train/post_ent_mag": 39.962248846749276, "train/post_ent_max": 39.962248846749276, "train/post_ent_mean": 20.09127874463518, "train/post_ent_min": 11.154340775213509, "train/post_ent_std": 3.6681831005577727, "train/prior_ent_mag": 74.02388135963511, "train/prior_ent_max": 74.02388135963511, "train/prior_ent_mean": 22.974525986430802, "train/prior_ent_min": 12.49693652625396, "train/prior_ent_std": 8.865623371623387, "train/rep_loss_mean": 2.8332145626299847, "train/rep_loss_std": 7.697835612519879, "train/reward_avg": 0.016074620894478444, "train/reward_loss_mean": 0.06840613207597042, "train/reward_loss_std": 0.14866048167242069, "train/reward_max_data": 1.0133995642171842, "train/reward_max_pred": 1.0148714034356803, "train/reward_neg_acc": 0.9994701653997474, "train/reward_neg_loss": 0.05018795638510557, "train/reward_pos_acc": 0.9040938108880944, "train/reward_pos_loss": 0.7168576759155666, "train/reward_pred": 0.01595706622568873, "train/reward_rate": 0.02729811623831776, "train_stats/sum_log_reward": 2.299999934434891, "train_stats/max_log_achievement_collect_drink": 1.2666666666666666, "train_stats/max_log_achievement_collect_sapling": 1.4666666666666666, "train_stats/max_log_achievement_collect_wood": 1.2, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.2666666666666666, "train_stats/max_log_achievement_place_table": 0.4666666666666667, "train_stats/max_log_achievement_wake_up": 1.2666666666666666, "train_stats/mean_log_entropy": 0.40153525670369467, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 4.288420768716605e-06, "report/cont_loss_std": 9.713724284665659e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 9.687010788184125e-06, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 4.272558271622984e-06, "report/cont_pred": 0.9970661401748657, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 3.0332934856414795, "report/dyn_loss_std": 8.161105155944824, "report/image_loss_mean": 2.0713951587677, "report/image_loss_std": 5.745371341705322, "report/model_loss_mean": 3.9528284072875977, "report/model_loss_std": 9.893013000488281, "report/post_ent_mag": 35.43586730957031, "report/post_ent_max": 35.43586730957031, "report/post_ent_mean": 20.10388946533203, "report/post_ent_min": 11.883219718933105, "report/post_ent_std": 3.9133219718933105, "report/prior_ent_mag": 74.2822036743164, "report/prior_ent_max": 74.2822036743164, "report/prior_ent_mean": 23.117435455322266, "report/prior_ent_min": 12.189872741699219, "report/prior_ent_std": 8.695389747619629, "report/rep_loss_mean": 3.0332934856414795, "report/rep_loss_std": 8.161105155944824, "report/reward_avg": 0.018338613212108612, "report/reward_loss_mean": 0.0614532008767128, "report/reward_loss_std": 0.11830415576696396, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0008471012115479, "report/reward_neg_acc": 0.9989969730377197, "report/reward_neg_loss": 0.04486611858010292, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6739464998245239, "report/reward_pred": 0.018611546605825424, "report/reward_rate": 0.0263671875, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 0.0011795940808951855, "eval/cont_loss_std": 0.03770975396037102, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 1.207302212715149, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 5.885137852601474e-07, "eval/cont_pred": 0.9997074007987976, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 21.940933227539062, "eval/dyn_loss_std": 15.142868041992188, "eval/image_loss_mean": 41.735008239746094, "eval/image_loss_std": 60.57013702392578, "eval/model_loss_mean": 55.058433532714844, "eval/model_loss_std": 66.30955505371094, "eval/post_ent_mag": 43.40010070800781, "eval/post_ent_max": 43.40010070800781, "eval/post_ent_mean": 24.59151840209961, "eval/post_ent_min": 15.755759239196777, "eval/post_ent_std": 3.9387991428375244, "eval/prior_ent_mag": 74.2822036743164, "eval/prior_ent_max": 74.2822036743164, "eval/prior_ent_mean": 31.781021118164062, "eval/prior_ent_min": 16.470191955566406, "eval/prior_ent_std": 9.303244590759277, "eval/rep_loss_mean": 21.940933227539062, "eval/rep_loss_std": 15.142868041992188, "eval/reward_avg": 0.02919921651482582, "eval/reward_loss_mean": 0.15768441557884216, "eval/reward_loss_std": 1.0220826864242554, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0005123615264893, "eval/reward_neg_acc": 0.9969757795333862, "eval/reward_neg_loss": 0.0784621462225914, "eval/reward_pos_acc": 0.71875, "eval/reward_pos_loss": 2.613574981689453, "eval/reward_pred": 0.022276297211647034, "eval/reward_rate": 0.03125, "replay/size": 56768.0, "replay/inserts": 2138.0, "replay/samples": 34208.0, "replay/insert_wait_avg": 2.5622748793342384e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.865136755862116e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 12456.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 8.940696716308594e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1005005836487, "timer/env.step_count": 267.0, "timer/env.step_total": 30.490536212921143, "timer/env.step_frac": 0.03048747220417065, "timer/env.step_avg": 0.11419676484240128, "timer/env.step_min": 0.024575233459472656, "timer/env.step_max": 1.692018985748291, "timer/replay._sample_count": 34208.0, "timer/replay._sample_total": 16.41047954559326, "timer/replay._sample_frac": 0.016408830448556188, "timer/replay._sample_avg": 0.00047972636651056076, "timer/replay._sample_min": 0.0003345012664794922, "timer/replay._sample_max": 0.010571956634521484, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 267.0, "timer/agent.policy_total": 4.171136856079102, "timer/agent.policy_frac": 0.004170717696516368, "timer/agent.policy_avg": 0.015622235416026597, "timer/agent.policy_min": 0.014479637145996094, "timer/agent.policy_max": 0.019326210021972656, "timer/dataset_train_count": 2138.0, "timer/dataset_train_total": 0.40715813636779785, "timer/dataset_train_frac": 0.00040711722084948906, "timer/dataset_train_avg": 0.00019043879156585493, "timer/dataset_train_min": 9.679794311523438e-05, "timer/dataset_train_max": 0.0007803440093994141, "timer/agent.train_count": 2138.0, "timer/agent.train_total": 954.0090208053589, "timer/agent.train_frac": 0.953913151976835, "timer/agent.train_avg": 0.4462156318079321, "timer/agent.train_min": 0.43650293350219727, "timer/agent.train_max": 0.5746245384216309, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47576427459716797, "timer/agent.report_frac": 0.0004757164648148028, "timer/agent.report_avg": 0.23788213729858398, "timer/agent.report_min": 0.23020672798156738, "timer/agent.report_max": 0.24555754661560059, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.075599670410156e-05, "timer/dataset_eval_frac": 3.075290601909775e-08, "timer/dataset_eval_avg": 3.075599670410156e-05, "timer/dataset_eval_min": 3.075599670410156e-05, "timer/dataset_eval_max": 3.075599670410156e-05, "fps": 2.1377566227848077}
{"step": 57616, "time": 26485.216614723206, "episode/length": 207.0, "episode/score": 2.2841864608108153, "episode/reward_rate": 0.9711538461538461, "episode/intrinsic_return": 0.18418641310381645}
{"step": 57712, "time": 26530.438145160675, "episode/length": 181.0, "episode/score": 3.2690935629075284, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.1690934528892285}
{"step": 57752, "time": 26550.387434005737, "episode/length": 171.0, "episode/score": 1.2488834266318918, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.14888344033397516}
{"step": 57792, "time": 26570.180028438568, "episode/length": 178.0, "episode/score": 4.304757054254878, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.2047569407732226}
{"step": 58064, "time": 26695.64529275894, "episode/length": 38.0, "episode/score": -0.8567916309111752, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.04320833267411217}
{"step": 58216, "time": 26766.29207777977, "episode/length": 139.0, "episode/score": 4.219794358667514, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.11979435412149542}
{"step": 58248, "time": 26782.39952492714, "episode/length": 154.0, "episode/score": 3.25419194521146, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.15419194050537044}
{"step": 58336, "time": 26823.877892017365, "episode/length": 137.0, "episode/score": 3.265084928701981, "episode/reward_rate": 0.9492753623188406, "episode/intrinsic_return": 0.16508481801429298}
{"step": 58360, "time": 26836.31583046913, "episode/length": 195.0, "episode/score": 2.290893058322581, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.1908930684594452}
{"step": 58424, "time": 26866.931257247925, "episode/length": 44.0, "episode/score": -0.8576040651969379, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.04239590153156314}
{"step": 58720, "time": 27003.119708776474, "episode/length": 125.0, "episode/score": 3.2480755042697638, "episode/reward_rate": 0.9523809523809523, "episode/intrinsic_return": 0.14807536890202755}
{"step": 58824, "time": 27051.797582149506, "episode/length": 150.0, "episode/score": 5.246497004654884, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.14649678516252607}
{"step": 59240, "time": 27242.19197368622, "episode/length": 180.0, "episode/score": 3.3014749657186258, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.201474915930703}
{"step": 59424, "time": 27327.75360059738, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.27155023619186, "train/action_min": 0.0, "train/action_std": 3.9644020901169887, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.038581953111083006, "train/actor_opt_grad_steps": 56790.0, "train/actor_opt_loss": -9.184685478238173, "train/adv_mag": 0.7360273438830708, "train/adv_max": 0.6740172239237053, "train/adv_mean": 0.002832152136905406, "train/adv_min": -0.5718027521011442, "train/adv_std": 0.05141967970791251, "train/cont_avg": 0.9942360101744186, "train/cont_loss_mean": 8.197279304552064e-05, "train/cont_loss_std": 0.002557849339031987, "train/cont_neg_acc": 0.9987080105515413, "train/cont_neg_loss": 0.0063123926617430865, "train/cont_pos_acc": 0.9999862332676732, "train/cont_pos_loss": 4.299772787214542e-05, "train/cont_pred": 0.9942264922829561, "train/cont_rate": 0.9942360101744186, "train/dyn_loss_mean": 2.9049750937971957, "train/dyn_loss_std": 7.727687509669814, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1714365485102631, "train/extr_critic_critic_opt_grad_steps": 56790.0, "train/extr_critic_critic_opt_loss": 14936.950826671511, "train/extr_critic_mag": 14.410969250701195, "train/extr_critic_max": 14.410969250701195, "train/extr_critic_mean": 2.7213272887606954, "train/extr_critic_min": -0.651955936675848, "train/extr_critic_std": 2.911284545410511, "train/extr_return_normed_mag": 1.7369083792664284, "train/extr_return_normed_max": 1.7369083792664284, "train/extr_return_normed_mean": 0.33950130599875783, "train/extr_return_normed_min": -0.09052858693135339, "train/extr_return_normed_std": 0.34058075242264324, "train/extr_return_rate": 0.781569808305696, "train/extr_return_raw_mag": 14.892574092953705, "train/extr_return_raw_max": 14.892574092953705, "train/extr_return_raw_mean": 2.7456025883208874, "train/extr_return_raw_min": -0.999576886032903, "train/extr_return_raw_std": 2.9674216447874557, "train/extr_reward_mag": 1.0250642998273982, "train/extr_reward_max": 1.0250642998273982, "train/extr_reward_mean": 0.03052077479660511, "train/extr_reward_min": -0.6520338180453278, "train/extr_reward_std": 0.1704122436601062, "train/image_loss_mean": 1.8659454761549483, "train/image_loss_std": 5.245003538907961, "train/model_loss_mean": 3.6781118326408917, "train/model_loss_std": 8.94272146668545, "train/model_opt_grad_norm": 37.17748991944069, "train/model_opt_grad_steps": 56741.76279069768, "train/model_opt_loss": 5718.656711028343, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1552.3255813953488, "train/policy_entropy_mag": 2.526133641531301, "train/policy_entropy_max": 2.526133641531301, "train/policy_entropy_mean": 0.5759249102237612, "train/policy_entropy_min": 0.07937501381302989, "train/policy_entropy_std": 0.6353518090968908, "train/policy_logprob_mag": 7.438383745592694, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5749166236367337, "train/policy_logprob_min": -7.438383745592694, "train/policy_logprob_std": 1.1342804947564769, "train/policy_randomness_mag": 0.8916143209435219, "train/policy_randomness_max": 0.8916143209435219, "train/policy_randomness_mean": 0.203276220830374, "train/policy_randomness_min": 0.02801589671262475, "train/policy_randomness_std": 0.2242513078589772, "train/post_ent_mag": 39.99960968549861, "train/post_ent_max": 39.99960968549861, "train/post_ent_mean": 20.219975546903388, "train/post_ent_min": 11.113728749474813, "train/post_ent_std": 3.6988137710926146, "train/prior_ent_mag": 74.05755483937818, "train/prior_ent_max": 74.05755483937818, "train/prior_ent_mean": 23.15845878068791, "train/prior_ent_min": 12.281392305950785, "train/prior_ent_std": 8.917976335037586, "train/rep_loss_mean": 2.9049750937971957, "train/rep_loss_std": 7.727687509669814, "train/reward_avg": 0.015785427337382422, "train/reward_loss_mean": 0.06909931452814923, "train/reward_loss_std": 0.1515699436151704, "train/reward_max_data": 1.010552356409472, "train/reward_max_pred": 1.0118563324906105, "train/reward_neg_acc": 0.9994066230086394, "train/reward_neg_loss": 0.050890410882095956, "train/reward_pos_acc": 0.9081857772760613, "train/reward_pos_loss": 0.717229520165643, "train/reward_pred": 0.01572451014071703, "train/reward_rate": 0.027389171511627907, "train_stats/sum_log_reward": 2.4846154038722696, "train_stats/max_log_achievement_collect_drink": 3.0, "train_stats/max_log_achievement_collect_sapling": 1.0769230769230769, "train_stats/max_log_achievement_collect_wood": 1.4615384615384615, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.0769230769230769, "train_stats/max_log_achievement_place_table": 0.6153846153846154, "train_stats/max_log_achievement_wake_up": 1.6923076923076923, "train_stats/mean_log_entropy": 0.5033061320965106, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 7.419063763336453e-07, "report/cont_loss_std": 2.6977388642990263e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 2.182904790970497e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 6.384366315614898e-07, "report/cont_pred": 0.9951167702674866, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 2.9741058349609375, "report/dyn_loss_std": 7.964034557342529, "report/image_loss_mean": 2.077897071838379, "report/image_loss_std": 5.964493274688721, "report/model_loss_mean": 3.9272031784057617, "report/model_loss_std": 9.460517883300781, "report/post_ent_mag": 42.14073944091797, "report/post_ent_max": 42.14073944091797, "report/post_ent_mean": 19.261350631713867, "report/post_ent_min": 9.597186088562012, "report/post_ent_std": 4.028353214263916, "report/prior_ent_mag": 74.54379272460938, "report/prior_ent_max": 74.54379272460938, "report/prior_ent_mean": 22.344633102416992, "report/prior_ent_min": 10.35654067993164, "report/prior_ent_std": 9.298661231994629, "report/rep_loss_mean": 2.9741058349609375, "report/rep_loss_std": 7.964034557342529, "report/reward_avg": 0.009389147162437439, "report/reward_loss_mean": 0.06484206020832062, "report/reward_loss_std": 0.12103109806776047, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0018229484558105, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.050254616886377335, "report/reward_pos_acc": 0.739130437374115, "report/reward_pos_loss": 0.6997127532958984, "report/reward_pred": 0.008855856955051422, "report/reward_rate": 0.0224609375, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 6.6387010519974865e-06, "eval/cont_loss_std": 0.00017560130800120533, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0018882725853472948, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.1099050425400492e-06, "eval/cont_pred": 0.9970747828483582, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 24.377944946289062, "eval/dyn_loss_std": 13.789714813232422, "eval/image_loss_mean": 46.745094299316406, "eval/image_loss_std": 53.52478790283203, "eval/model_loss_mean": 61.506370544433594, "eval/model_loss_std": 58.7370491027832, "eval/post_ent_mag": 42.14073944091797, "eval/post_ent_max": 42.14073944091797, "eval/post_ent_mean": 25.792869567871094, "eval/post_ent_min": 13.88404369354248, "eval/post_ent_std": 3.8211724758148193, "eval/prior_ent_mag": 74.54379272460938, "eval/prior_ent_max": 74.54379272460938, "eval/prior_ent_mean": 33.64503479003906, "eval/prior_ent_min": 15.57564640045166, "eval/prior_ent_std": 8.868683815002441, "eval/rep_loss_mean": 24.377944946289062, "eval/rep_loss_std": 13.789714813232422, "eval/reward_avg": 0.00839843787252903, "eval/reward_loss_mean": 0.13450422883033752, "eval/reward_loss_std": 0.9889032244682312, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0006318092346191, "eval/reward_neg_acc": 0.9970325827598572, "eval/reward_neg_loss": 0.08656081557273865, "eval/reward_pos_acc": 0.6153846383094788, "eval/reward_pos_loss": 3.863027811050415, "eval/reward_pred": 0.008211938664317131, "eval/reward_rate": 0.0126953125, "replay/size": 58920.0, "replay/inserts": 2152.0, "replay/samples": 34432.0, "replay/insert_wait_avg": 2.535967135518014e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.328296904227104e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 12456.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 7.003545761108398e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3465676307678, "timer/env.step_count": 269.0, "timer/env.step_total": 26.850050926208496, "timer/env.step_frac": 0.026840748791491793, "timer/env.step_avg": 0.09981431571081226, "timer/env.step_min": 0.023419618606567383, "timer/env.step_max": 1.6348357200622559, "timer/replay._sample_count": 34432.0, "timer/replay._sample_total": 16.252836227416992, "timer/replay._sample_frac": 0.016247205471909994, "timer/replay._sample_avg": 0.00047202707444868124, "timer/replay._sample_min": 0.0003249645233154297, "timer/replay._sample_max": 0.025855541229248047, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 269.0, "timer/agent.policy_total": 4.208896160125732, "timer/agent.policy_frac": 0.0042074379983070564, "timer/agent.policy_avg": 0.01564645412686146, "timer/agent.policy_min": 0.01438593864440918, "timer/agent.policy_max": 0.043897151947021484, "timer/dataset_train_count": 2152.0, "timer/dataset_train_total": 0.391798734664917, "timer/dataset_train_frac": 0.0003916629969480053, "timer/dataset_train_avg": 0.00018206260904503576, "timer/dataset_train_min": 8.940696716308594e-05, "timer/dataset_train_max": 0.0012125968933105469, "timer/agent.train_count": 2152.0, "timer/agent.train_total": 958.2805600166321, "timer/agent.train_frac": 0.9579485660516981, "timer/agent.train_avg": 0.4452976580002937, "timer/agent.train_min": 0.4344296455383301, "timer/agent.train_max": 0.5697884559631348, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4754369258880615, "timer/agent.report_frac": 0.0004752722119236054, "timer/agent.report_avg": 0.23771846294403076, "timer/agent.report_min": 0.23088359832763672, "timer/agent.report_max": 0.2445533275604248, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9325485229492188e-05, "timer/dataset_eval_frac": 2.931532548659311e-08, "timer/dataset_eval_avg": 2.9325485229492188e-05, "timer/dataset_eval_min": 2.9325485229492188e-05, "timer/dataset_eval_max": 2.9325485229492188e-05, "fps": 2.1512249740252494}
{"step": 59464, "time": 27346.271377801895, "episode/length": 151.0, "episode/score": 1.2655434930584306, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.16554342835479474}
{"step": 59576, "time": 27398.718087911606, "episode/length": 169.0, "episode/score": 3.2803777383483066, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.1803776191623001}
{"step": 59584, "time": 27404.07610297203, "episode/length": 152.0, "episode/score": 5.247303235265008, "episode/reward_rate": 0.9738562091503268, "episode/intrinsic_return": 0.1473032286526177}
{"step": 59760, "time": 27485.48223543167, "episode/length": 166.0, "episode/score": 5.270695226016869, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.17069506983989413}
{"step": 60008, "time": 27617.2404024601, "eval_episode/length": 121.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9590163934426229}
{"step": 60008, "time": 27620.21621155739, "eval_episode/length": 154.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.967741935483871}
{"step": 60008, "time": 27622.021169900894, "eval_episode/length": 161.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9691358024691358}
{"step": 60008, "time": 27623.678117990494, "eval_episode/length": 165.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9578313253012049}
{"step": 60008, "time": 27625.803800582886, "eval_episode/length": 178.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.994413407821229}
{"step": 60008, "time": 27627.755054950714, "eval_episode/length": 187.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9946808510638298}
{"step": 60008, "time": 27629.321141719818, "eval_episode/length": 189.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9947368421052631}
{"step": 60008, "time": 27632.71981024742, "eval_episode/length": 52.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9245283018867925}
{"step": 60176, "time": 27709.006554365158, "episode/length": 168.0, "episode/score": 4.270577067166869, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.1705769677423632}
{"step": 60424, "time": 27823.19090461731, "episode/length": 260.0, "episode/score": 4.378668761622976, "episode/reward_rate": 0.9846743295019157, "episode/intrinsic_return": 0.27866880188412324}
{"step": 60424, "time": 27823.200236558914, "episode/length": 212.0, "episode/score": 4.312905819567732, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.2129056788012349}
{"step": 60664, "time": 27935.89260816574, "episode/length": 134.0, "episode/score": 4.211584734941425, "episode/reward_rate": 0.9925925925925926, "episode/intrinsic_return": 0.11158456965495134}
{"step": 60776, "time": 27988.733030319214, "episode/length": 149.0, "episode/score": 3.237939021888451, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.1379388964160171}
{"step": 60800, "time": 28001.177516222, "episode/length": 194.0, "episode/score": 4.31234151845274, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.212341356658726}
{"step": 60816, "time": 28010.158473730087, "episode/length": 168.0, "episode/score": 4.259790214746317, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.15979006179986754}
{"step": 61256, "time": 28212.721394777298, "episode/length": 186.0, "episode/score": 5.312701387818379, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.21270117608219152}
{"step": 61503, "time": 28327.865993499756, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.103787935697115, "train/action_min": 0.0, "train/action_std": 3.9320872105084934, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03571986711512391, "train/actor_opt_grad_steps": 58905.0, "train/actor_opt_loss": -15.279193417527354, "train/adv_mag": 0.674344297641745, "train/adv_max": 0.6047462408359234, "train/adv_mean": 0.001236758840224621, "train/adv_min": -0.5331964229878324, "train/adv_std": 0.04628066355899836, "train/cont_avg": 0.9943800706129807, "train/cont_loss_mean": 4.45994101408058e-05, "train/cont_loss_std": 0.0013494531375256495, "train/cont_neg_acc": 0.9983516487364585, "train/cont_neg_loss": 0.005382738620743164, "train/cont_pos_acc": 0.9999952562726461, "train/cont_pos_loss": 1.4702427127925962e-05, "train/cont_pred": 0.994383021329458, "train/cont_rate": 0.9943800706129807, "train/dyn_loss_mean": 2.9017867743968964, "train/dyn_loss_std": 7.7224724522003765, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0880849152230299, "train/extr_critic_critic_opt_grad_steps": 58905.0, "train/extr_critic_critic_opt_loss": 14503.956270658053, "train/extr_critic_mag": 13.218041374133183, "train/extr_critic_max": 13.218041374133183, "train/extr_critic_mean": 2.648171961880647, "train/extr_critic_min": -0.6814127300794308, "train/extr_critic_std": 2.8403043809991617, "train/extr_return_normed_mag": 1.593139689702254, "train/extr_return_normed_max": 1.593139689702254, "train/extr_return_normed_mean": 0.33705672349494237, "train/extr_return_normed_min": -0.0967158696685846, "train/extr_return_normed_std": 0.3333074307212463, "train/extr_return_rate": 0.7868079950030034, "train/extr_return_raw_mag": 13.491382378798265, "train/extr_return_raw_max": 13.491382378798265, "train/extr_return_raw_mean": 2.6587378308176994, "train/extr_return_raw_min": -1.0787332966350591, "train/extr_return_raw_std": 2.87382471962617, "train/extr_reward_mag": 1.029412982555536, "train/extr_reward_max": 1.029412982555536, "train/extr_reward_mean": 0.03249880918659843, "train/extr_reward_min": -0.6691867015682734, "train/extr_reward_std": 0.17550167255103588, "train/image_loss_mean": 1.813318324776796, "train/image_loss_std": 5.131531975590265, "train/model_loss_mean": 3.6240981851632776, "train/model_loss_std": 8.841971518901678, "train/model_opt_grad_norm": 34.838562392271484, "train/model_opt_grad_steps": 58855.668269230766, "train/model_opt_loss": 8350.426923311674, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2301.6826923076924, "train/policy_entropy_mag": 2.5646948974866133, "train/policy_entropy_max": 2.5646948974866133, "train/policy_entropy_mean": 0.5708199524535582, "train/policy_entropy_min": 0.0793750137448884, "train/policy_entropy_std": 0.6453502921817394, "train/policy_logprob_mag": 7.43838374202068, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5708753574066437, "train/policy_logprob_min": -7.43838374202068, "train/policy_logprob_std": 1.137861637541881, "train/policy_randomness_mag": 0.9052247508214071, "train/policy_randomness_max": 0.9052247508214071, "train/policy_randomness_mean": 0.2014743942552461, "train/policy_randomness_min": 0.02801589668692591, "train/policy_randomness_std": 0.22778033257390445, "train/post_ent_mag": 40.13565835585961, "train/post_ent_max": 40.13565835585961, "train/post_ent_mean": 20.409175671063938, "train/post_ent_min": 11.322634706130394, "train/post_ent_std": 3.6409003677276464, "train/prior_ent_mag": 74.2246669622568, "train/prior_ent_max": 74.2246669622568, "train/prior_ent_mean": 23.319257662846493, "train/prior_ent_min": 12.39217854463137, "train/prior_ent_std": 8.865750062924166, "train/rep_loss_mean": 2.9017867743968964, "train/rep_loss_std": 7.7224724522003765, "train/reward_avg": 0.01627584362876615, "train/reward_loss_mean": 0.06966317912492041, "train/reward_loss_std": 0.15657210894502127, "train/reward_max_data": 1.0142308009358554, "train/reward_max_pred": 1.0155825030345182, "train/reward_neg_acc": 0.9994205812422129, "train/reward_neg_loss": 0.0509990443690465, "train/reward_pos_acc": 0.9025125741385497, "train/reward_pos_loss": 0.7209043732056251, "train/reward_pred": 0.01613589790045248, "train/reward_rate": 0.02784142127403846, "train_stats/sum_log_reward": 3.9333332777023315, "train_stats/max_log_achievement_collect_drink": 4.0, "train_stats/max_log_achievement_collect_sapling": 1.8333333333333333, "train_stats/max_log_achievement_collect_wood": 1.8333333333333333, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.75, "train_stats/max_log_achievement_place_table": 0.5, "train_stats/max_log_achievement_wake_up": 2.0, "train_stats/mean_log_entropy": 0.5426125476757685, "eval_stats/sum_log_reward": 2.7249999344348907, "eval_stats/max_log_achievement_collect_drink": 1.875, "eval_stats/max_log_achievement_collect_sapling": 2.5, "eval_stats/max_log_achievement_collect_wood": 0.5, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.125, "eval_stats/max_log_achievement_place_table": 0.125, "eval_stats/max_log_achievement_wake_up": 1.625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 1.8460940509612556e-06, "report/cont_loss_std": 9.998954737966415e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 1.6258423784165643e-05, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 1.7895749806484673e-06, "report/cont_pred": 0.9960920810699463, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 2.7847955226898193, "report/dyn_loss_std": 7.679316520690918, "report/image_loss_mean": 1.6913678646087646, "report/image_loss_std": 6.069686412811279, "report/model_loss_mean": 3.4327280521392822, "report/model_loss_std": 9.717153549194336, "report/post_ent_mag": 42.52003479003906, "report/post_ent_max": 42.52003479003906, "report/post_ent_mean": 20.379606246948242, "report/post_ent_min": 11.19498348236084, "report/post_ent_std": 3.7174062728881836, "report/prior_ent_mag": 74.065673828125, "report/prior_ent_max": 74.065673828125, "report/prior_ent_mean": 23.290647506713867, "report/prior_ent_min": 12.087664604187012, "report/prior_ent_std": 8.482979774475098, "report/rep_loss_mean": 2.7847955226898193, "report/rep_loss_std": 7.679316520690918, "report/reward_avg": 0.013796833343803883, "report/reward_loss_mean": 0.07048095017671585, "report/reward_loss_std": 0.22318385541439056, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0023608207702637, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.05538719519972801, "report/reward_pos_acc": 0.9599999785423279, "report/reward_pos_loss": 0.6736271381378174, "report/reward_pred": 0.014251377433538437, "report/reward_rate": 0.0244140625, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.014853603206574917, "eval/cont_loss_std": 0.3497177064418793, "eval/cont_neg_acc": 0.3333333432674408, "eval/cont_neg_loss": 5.0692596435546875, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.2628880742558977e-06, "eval/cont_pred": 0.9990167021751404, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 22.803743362426758, "eval/dyn_loss_std": 14.69599437713623, "eval/image_loss_mean": 40.582969665527344, "eval/image_loss_std": 52.721126556396484, "eval/model_loss_mean": 54.38843536376953, "eval/model_loss_std": 58.41740036010742, "eval/post_ent_mag": 42.52003479003906, "eval/post_ent_max": 42.52003479003906, "eval/post_ent_mean": 24.897598266601562, "eval/post_ent_min": 14.27712631225586, "eval/post_ent_std": 4.20711612701416, "eval/prior_ent_mag": 74.065673828125, "eval/prior_ent_max": 74.065673828125, "eval/prior_ent_mean": 32.1484375, "eval/prior_ent_min": 16.90206527709961, "eval/prior_ent_std": 9.608534812927246, "eval/rep_loss_mean": 22.803743362426758, "eval/rep_loss_std": 14.69599437713623, "eval/reward_avg": 0.02207031100988388, "eval/reward_loss_mean": 0.10837001353502274, "eval/reward_loss_std": 0.778357982635498, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.000819444656372, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.04552610218524933, "eval/reward_pos_acc": 0.7599999904632568, "eval/reward_pos_loss": 2.6196129322052, "eval/reward_pred": 0.015586711466312408, "eval/reward_rate": 0.0244140625, "replay/size": 60999.0, "replay/inserts": 2079.0, "replay/samples": 33264.0, "replay/insert_wait_avg": 2.5204249790736607e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.63829652365152e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 14312.0, "eval_replay/inserts": 1856.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1410949559047305e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 6.556510925292969e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0958681106567, "timer/env.step_count": 260.0, "timer/env.step_total": 26.00484848022461, "timer/env.step_frac": 0.026002355683512605, "timer/env.step_avg": 0.10001864800086388, "timer/env.step_min": 0.023975372314453125, "timer/env.step_max": 3.3164234161376953, "timer/replay._sample_count": 33264.0, "timer/replay._sample_total": 15.71557354927063, "timer/replay._sample_frac": 0.015714067071349765, "timer/replay._sample_avg": 0.0004724499022748506, "timer/replay._sample_min": 0.0003204345703125, "timer/replay._sample_max": 0.027531862258911133, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 492.0, "timer/agent.policy_total": 7.767529487609863, "timer/agent.policy_frac": 0.0077667849006155636, "timer/agent.policy_avg": 0.015787661560182648, "timer/agent.policy_min": 0.009441137313842773, "timer/agent.policy_max": 0.05084395408630371, "timer/dataset_train_count": 2079.0, "timer/dataset_train_total": 0.3666856288909912, "timer/dataset_train_frac": 0.00036665047880231707, "timer/dataset_train_avg": 0.00017637596387253064, "timer/dataset_train_min": 8.7738037109375e-05, "timer/dataset_train_max": 0.0005757808685302734, "timer/agent.train_count": 2079.0, "timer/agent.train_total": 926.3682994842529, "timer/agent.train_frac": 0.9262794988187611, "timer/agent.train_avg": 0.4455835976355233, "timer/agent.train_min": 0.43315744400024414, "timer/agent.train_max": 0.5977563858032227, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4769871234893799, "timer/agent.report_frac": 0.00047694140001846615, "timer/agent.report_avg": 0.23849356174468994, "timer/agent.report_min": 0.23094844818115234, "timer/agent.report_max": 0.24603867530822754, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0517578125e-05, "timer/dataset_eval_frac": 3.051465274289419e-08, "timer/dataset_eval_avg": 3.0517578125e-05, "timer/dataset_eval_min": 3.0517578125e-05, "timer/dataset_eval_max": 3.0517578125e-05, "fps": 2.078772071778351}
{"step": 61528, "time": 28339.64311528206, "episode/length": 168.0, "episode/score": 5.261210074040719, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.16120992260766798}
{"step": 61848, "time": 28487.400439739227, "episode/length": 73.0, "episode/score": 0.16405962833778176, "episode/reward_rate": 0.9324324324324325, "episode/intrinsic_return": 0.0640596849971189}
{"step": 61856, "time": 28492.509393930435, "episode/length": 178.0, "episode/score": 5.274752684199484, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.17475254423334263}
{"step": 61952, "time": 28537.960399627686, "episode/length": 143.0, "episode/score": 5.272544796293005, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.17254465347468795}
{"step": 62040, "time": 28579.986871242523, "episode/length": 171.0, "episode/score": 3.259242155629181, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.15924197451022337}
{"step": 62128, "time": 28621.923899888992, "episode/length": 34.0, "episode/score": 1.143333369283937, "episode/reward_rate": 0.8571428571428571, "episode/intrinsic_return": 0.04333333240356296}
{"step": 62200, "time": 28656.4691529274, "episode/length": 177.0, "episode/score": 4.302660684948933, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.2026605512110109}
{"step": 62208, "time": 28661.690101146698, "episode/length": 222.0, "episode/score": 4.3467494552714925, "episode/reward_rate": 0.9775784753363229, "episode/intrinsic_return": 0.2467493913245562}
{"step": 62280, "time": 28696.143825292587, "episode/length": 182.0, "episode/score": 6.309333293542295, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.20933309507745435}
{"step": 62944, "time": 29001.91243004799, "episode/length": 176.0, "episode/score": 2.2909397775511025, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.19093968188099097}
{"step": 63192, "time": 29117.021474838257, "episode/length": 166.0, "episode/score": 3.2656223144913383, "episode/reward_rate": 0.9640718562874252, "episode/intrinsic_return": 0.1656222966448695}
{"step": 63344, "time": 29188.00948691368, "episode/length": 141.0, "episode/score": 2.210836909592217, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.11083684116329096}
{"step": 63432, "time": 29229.924448251724, "episode/length": 184.0, "episode/score": 5.315069593463704, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.2150694420306536}
{"step": 63504, "time": 29264.38588285446, "episode/length": 162.0, "episode/score": 4.2595558172452, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.15955575935186062}
{"step": 63576, "time": 29299.09836268425, "episode/length": 191.0, "episode/score": 3.3106119284930173, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.21061183986603282}
{"step": 63635, "time": 29328.260068416595, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.271705305072623, "train/action_min": 0.0, "train/action_std": 4.040600068132642, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03605213879384625, "train/actor_opt_grad_steps": 61010.0, "train/actor_opt_loss": -13.277179309180084, "train/adv_mag": 0.648942145803165, "train/adv_max": 0.5801073844444025, "train/adv_mean": 0.0018047876849461848, "train/adv_min": -0.5283759607115822, "train/adv_std": 0.04466189388972773, "train/cont_avg": 0.994131455399061, "train/cont_loss_mean": 0.00011853826039505144, "train/cont_loss_std": 0.0037189667318511003, "train/cont_neg_acc": 0.9988262910798122, "train/cont_neg_loss": 0.017375120571213015, "train/cont_pos_acc": 0.9999907374941687, "train/cont_pos_loss": 5.001435485483242e-05, "train/cont_pred": 0.9941257227194701, "train/cont_rate": 0.994131455399061, "train/dyn_loss_mean": 2.8793784609423, "train/dyn_loss_std": 7.6728627983952915, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1067282949255106, "train/extr_critic_critic_opt_grad_steps": 61010.0, "train/extr_critic_critic_opt_loss": 14729.705137727406, "train/extr_critic_mag": 12.942245640105485, "train/extr_critic_max": 12.942245640105485, "train/extr_critic_mean": 2.7081993829476443, "train/extr_critic_min": -0.6813941880570891, "train/extr_critic_std": 2.8934900368883016, "train/extr_return_normed_mag": 1.481033185837974, "train/extr_return_normed_max": 1.481033185837974, "train/extr_return_normed_mean": 0.3290625019392497, "train/extr_return_normed_min": -0.10068823300966634, "train/extr_return_normed_std": 0.3212481313188311, "train/extr_return_rate": 0.7068668433198346, "train/extr_return_raw_mag": 13.260374651268615, "train/extr_return_raw_max": 13.260374651268615, "train/extr_return_raw_mean": 2.7247329133217324, "train/extr_return_raw_min": -1.2033220288899023, "train/extr_return_raw_std": 2.9377997330096965, "train/extr_reward_mag": 1.0312233844273526, "train/extr_reward_max": 1.0312233844273526, "train/extr_reward_mean": 0.0347244159095514, "train/extr_reward_min": -0.6745622756895325, "train/extr_reward_std": 0.18259349234507116, "train/image_loss_mean": 1.6999623677540274, "train/image_loss_std": 4.631591410704062, "train/model_loss_mean": 3.4988110132620367, "train/model_loss_std": 8.35327505953435, "train/model_opt_grad_norm": 36.05132608010735, "train/model_opt_grad_steps": 60958.77464788732, "train/model_opt_loss": 5433.871984347491, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1561.0328638497654, "train/policy_entropy_mag": 2.5871290556142026, "train/policy_entropy_max": 2.5871290556142026, "train/policy_entropy_mean": 0.61907948280724, "train/policy_entropy_min": 0.07937501381400605, "train/policy_entropy_std": 0.6937009672603697, "train/policy_logprob_mag": 7.4383837516319025, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.6196779741647658, "train/policy_logprob_min": -7.4383837516319025, "train/policy_logprob_std": 1.1689811390890201, "train/policy_randomness_mag": 0.9131430244781602, "train/policy_randomness_max": 0.9131430244781602, "train/policy_randomness_mean": 0.21850788859134548, "train/policy_randomness_min": 0.028015896704205324, "train/policy_randomness_std": 0.24484599811930052, "train/post_ent_mag": 40.20431953752544, "train/post_ent_max": 40.20431953752544, "train/post_ent_mean": 20.578854628012213, "train/post_ent_min": 11.22327055953478, "train/post_ent_std": 3.6807522169301206, "train/prior_ent_mag": 74.32162618860953, "train/prior_ent_max": 74.32162618860953, "train/prior_ent_mean": 23.496968524556763, "train/prior_ent_min": 12.491924523187915, "train/prior_ent_std": 8.921068184812304, "train/rep_loss_mean": 2.8793784609423, "train/rep_loss_std": 7.6728627983952915, "train/reward_avg": 0.016981349136470487, "train/reward_loss_mean": 0.07110303325552336, "train/reward_loss_std": 0.16082368521763127, "train/reward_max_data": 1.0134566042904563, "train/reward_max_pred": 1.0151331928414358, "train/reward_neg_acc": 0.9994234470694278, "train/reward_neg_loss": 0.05132063745822705, "train/reward_pos_acc": 0.9055764244196001, "train/reward_pos_loss": 0.7262667375551143, "train/reward_pred": 0.016787194716853436, "train/reward_rate": 0.02930604460093897, "train_stats/sum_log_reward": 3.5666665782531104, "train_stats/max_log_achievement_collect_drink": 3.1333333333333333, "train_stats/max_log_achievement_collect_sapling": 2.3333333333333335, "train_stats/max_log_achievement_collect_wood": 1.7333333333333334, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.06666666666666667, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 2.1333333333333333, "train_stats/max_log_achievement_place_table": 0.6, "train_stats/max_log_achievement_wake_up": 1.8, "train_stats/mean_log_entropy": 0.524850062529246, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 4.763256583828479e-06, "report/cont_loss_std": 8.004038681974635e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 1.6024299839045852e-05, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 4.685746716859285e-06, "report/cont_pred": 0.9931595325469971, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 3.03452205657959, "report/dyn_loss_std": 7.7258195877075195, "report/image_loss_mean": 2.112635612487793, "report/image_loss_std": 6.146037578582764, "report/model_loss_mean": 4.010922908782959, "report/model_loss_std": 9.610188484191895, "report/post_ent_mag": 42.79481887817383, "report/post_ent_max": 42.79481887817383, "report/post_ent_mean": 21.31623649597168, "report/post_ent_min": 11.19515609741211, "report/post_ent_std": 4.057458877563477, "report/prior_ent_mag": 74.21286010742188, "report/prior_ent_max": 74.21286010742188, "report/prior_ent_mean": 24.458141326904297, "report/prior_ent_min": 12.27490234375, "report/prior_ent_std": 9.237312316894531, "report/rep_loss_mean": 3.03452205657959, "report/rep_loss_std": 7.7258195877075195, "report/reward_avg": 0.01987660676240921, "report/reward_loss_mean": 0.07756862044334412, "report/reward_loss_std": 0.19688867032527924, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0012226104736328, "report/reward_neg_acc": 0.9989908933639526, "report/reward_neg_loss": 0.05219225957989693, "report/reward_pos_acc": 0.7575757503509521, "report/reward_pos_loss": 0.8396285176277161, "report/reward_pred": 0.017689479514956474, "report/reward_rate": 0.0322265625, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.0036804138217121363, "eval/cont_loss_std": 0.10476922988891602, "eval/cont_neg_acc": 0.8333333730697632, "eval/cont_neg_loss": 0.6277347803115845, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.293784064022475e-06, "eval/cont_pred": 0.9954280257225037, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 22.916095733642578, "eval/dyn_loss_std": 13.144404411315918, "eval/image_loss_mean": 32.621219635009766, "eval/image_loss_std": 32.141334533691406, "eval/model_loss_mean": 46.593544006347656, "eval/model_loss_std": 37.1138801574707, "eval/post_ent_mag": 37.530662536621094, "eval/post_ent_max": 37.530662536621094, "eval/post_ent_mean": 24.65038299560547, "eval/post_ent_min": 13.45150375366211, "eval/post_ent_std": 3.948577880859375, "eval/prior_ent_mag": 74.21286010742188, "eval/prior_ent_max": 74.21286010742188, "eval/prior_ent_mean": 32.17625427246094, "eval/prior_ent_min": 13.456716537475586, "eval/prior_ent_std": 10.267792701721191, "eval/rep_loss_mean": 22.916095733642578, "eval/rep_loss_std": 13.144404411315918, "eval/reward_avg": 0.01123046875, "eval/reward_loss_mean": 0.21898214519023895, "eval/reward_loss_std": 1.2143940925598145, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0028660297393799, "eval/reward_neg_acc": 0.9970149993896484, "eval/reward_neg_loss": 0.1633671075105667, "eval/reward_pos_acc": 0.7368420958518982, "eval/reward_pos_loss": 3.1607260704040527, "eval/reward_pred": 0.01001550443470478, "eval/reward_rate": 0.0185546875, "replay/size": 63131.0, "replay/inserts": 2132.0, "replay/samples": 34112.0, "replay/insert_wait_avg": 2.586483731726097e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.840722631558244e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 14312.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 7.301568984985352e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3816516399384, "timer/env.step_count": 267.0, "timer/env.step_total": 29.967746257781982, "timer/env.step_frac": 0.029956313381653367, "timer/env.step_avg": 0.112238750029146, "timer/env.step_min": 0.02405405044555664, "timer/env.step_max": 1.6767876148223877, "timer/replay._sample_count": 34112.0, "timer/replay._sample_total": 16.343169450759888, "timer/replay._sample_frac": 0.01633693443294199, "timer/replay._sample_avg": 0.0004791032320227453, "timer/replay._sample_min": 0.0003237724304199219, "timer/replay._sample_max": 0.012749671936035156, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 267.0, "timer/agent.policy_total": 4.215102910995483, "timer/agent.policy_frac": 0.004213494823786114, "timer/agent.policy_avg": 0.0157869022883726, "timer/agent.policy_min": 0.014519214630126953, "timer/agent.policy_max": 0.030378341674804688, "timer/dataset_train_count": 2132.0, "timer/dataset_train_total": 0.41327905654907227, "timer/dataset_train_frac": 0.00041312138809381264, "timer/dataset_train_avg": 0.00019384571132695697, "timer/dataset_train_min": 8.893013000488281e-05, "timer/dataset_train_max": 0.025737524032592773, "timer/agent.train_count": 2132.0, "timer/agent.train_total": 954.702629327774, "timer/agent.train_frac": 0.9543384045106365, "timer/agent.train_avg": 0.4477967304539278, "timer/agent.train_min": 0.43654465675354004, "timer/agent.train_max": 0.5825340747833252, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4770665168762207, "timer/agent.report_frac": 0.0004768845131197274, "timer/agent.report_avg": 0.23853325843811035, "timer/agent.report_min": 0.2320544719696045, "timer/agent.report_max": 0.2450120449066162, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0279159545898438e-05, "timer/dataset_eval_frac": 3.026760786372024e-08, "timer/dataset_eval_avg": 3.0279159545898438e-05, "timer/dataset_eval_min": 3.0279159545898438e-05, "timer/dataset_eval_max": 3.0279159545898438e-05, "fps": 2.1311575048486184}
{"step": 63752, "time": 29381.98254966736, "episode/length": 183.0, "episode/score": 2.2672811573547733, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.16728109067207697}
{"step": 64080, "time": 29533.693154096603, "episode/length": 243.0, "episode/score": 1.316459134643992, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.21645916150100675}
{"step": 64336, "time": 29652.56714105606, "episode/length": 173.0, "episode/score": 4.280019476051166, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.1800194386178191}
{"step": 64480, "time": 29720.195325613022, "episode/length": 49.0, "episode/score": 2.1433858951895672, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.043385844484873815}
{"step": 64736, "time": 29839.218216896057, "episode/length": 162.0, "episode/score": 2.24800419591611, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.1480042691646304}
{"step": 64736, "time": 29839.227613449097, "episode/length": 153.0, "episode/score": 2.2664229087286003, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.16642278639938013}
{"step": 64776, "time": 29860.768223762512, "episode/length": 197.0, "episode/score": 5.28646404772735, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.18646394740062533}
{"step": 64832, "time": 29887.9729282856, "episode/length": 156.0, "episode/score": 3.27727944777871, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.17727935245784465}
{"step": 65328, "time": 30115.55797624588, "episode/length": 196.0, "episode/score": 4.308700952522486, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.20870080819076975}
{"step": 65472, "time": 30182.819525003433, "episode/length": 141.0, "episode/score": 3.2217535879462957, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.12175345560535789}
{"step": 65568, "time": 30229.02402806282, "episode/length": 277.0, "episode/score": 5.392822916353907, "episode/reward_rate": 0.9964028776978417, "episode/intrinsic_return": 0.29282272857017233}
{"step": 65780, "time": 30328.516487836838, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.174703056867733, "train/action_min": 0.0, "train/action_std": 4.018884311720383, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.039640536938988884, "train/actor_opt_grad_steps": 63150.0, "train/actor_opt_loss": -15.618826480798942, "train/adv_mag": 0.8117899621641913, "train/adv_max": 0.7099045429118844, "train/adv_mean": 0.0011840832109788438, "train/adv_min": -0.6442097761603289, "train/adv_std": 0.050062859924726706, "train/cont_avg": 0.9944358648255814, "train/cont_loss_mean": 2.3275125059351624e-05, "train/cont_loss_std": 0.0006925666039785219, "train/cont_neg_acc": 0.9988372093023256, "train/cont_neg_loss": 0.0016617152958725604, "train/cont_pos_acc": 0.9999954134918922, "train/cont_pos_loss": 1.068108764483504e-05, "train/cont_pred": 0.994434097755787, "train/cont_rate": 0.9944358648255814, "train/dyn_loss_mean": 2.869128771715386, "train/dyn_loss_std": 7.680093878368998, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1701875231986822, "train/extr_critic_critic_opt_grad_steps": 63150.0, "train/extr_critic_critic_opt_loss": 14451.927043968024, "train/extr_critic_mag": 13.384933489422465, "train/extr_critic_max": 13.384933489422465, "train/extr_critic_mean": 2.502971401879954, "train/extr_critic_min": -0.6909529769143393, "train/extr_critic_std": 2.761291081406349, "train/extr_return_normed_mag": 1.7496070107748343, "train/extr_return_normed_max": 1.7496070107748343, "train/extr_return_normed_mean": 0.34743101853270864, "train/extr_return_normed_min": -0.10152250885270363, "train/extr_return_normed_std": 0.34844973218995473, "train/extr_return_rate": 0.6905899111614671, "train/extr_return_raw_mag": 13.773387758121935, "train/extr_return_raw_max": 13.773387758121935, "train/extr_return_raw_mean": 2.512433108063631, "train/extr_return_raw_min": -1.0981325268745423, "train/extr_return_raw_std": 2.8028067172959794, "train/extr_reward_mag": 1.0269348577011463, "train/extr_reward_max": 1.0269348577011463, "train/extr_reward_mean": 0.030283087799542172, "train/extr_reward_min": -0.6785700454268344, "train/extr_reward_std": 0.17124794305757035, "train/image_loss_mean": 1.7015813095625056, "train/image_loss_std": 4.857443062094755, "train/model_loss_mean": 3.4924282173777734, "train/model_loss_std": 8.561526203155518, "train/model_opt_grad_norm": 33.61388580410979, "train/model_opt_grad_steps": 63097.32558139535, "train/model_opt_loss": 5895.300048828125, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1686.046511627907, "train/policy_entropy_mag": 2.5891018690064898, "train/policy_entropy_max": 2.5891018690064898, "train/policy_entropy_mean": 0.6304955910804659, "train/policy_entropy_min": 0.07937501374372216, "train/policy_entropy_std": 0.7076374753963116, "train/policy_logprob_mag": 7.438383816563806, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.6306970822256664, "train/policy_logprob_min": -7.438383816563806, "train/policy_logprob_std": 1.1774635935938635, "train/policy_randomness_mag": 0.9138393407644227, "train/policy_randomness_max": 0.9138393407644227, "train/policy_randomness_mean": 0.22253727420817973, "train/policy_randomness_min": 0.028015896686634352, "train/policy_randomness_std": 0.2497649733410325, "train/post_ent_mag": 40.961275899133014, "train/post_ent_max": 40.961275899133014, "train/post_ent_mean": 20.780143578107968, "train/post_ent_min": 11.404694869906404, "train/post_ent_std": 3.671998965462973, "train/prior_ent_mag": 74.39393207638763, "train/prior_ent_max": 74.39393207638763, "train/prior_ent_mean": 23.684738726948584, "train/prior_ent_min": 12.660760693217433, "train/prior_ent_std": 8.841685978201932, "train/rep_loss_mean": 2.869128771715386, "train/rep_loss_std": 7.680093878368998, "train/reward_avg": 0.016258036828231674, "train/reward_loss_mean": 0.06934636372119882, "train/reward_loss_std": 0.15528171655050543, "train/reward_max_data": 1.013808171139207, "train/reward_max_pred": 1.01453489591909, "train/reward_neg_acc": 0.9993278004402338, "train/reward_neg_loss": 0.05086810595767442, "train/reward_pos_acc": 0.9074847121571386, "train/reward_pos_loss": 0.7192653046097867, "train/reward_pred": 0.01620998425452515, "train/reward_rate": 0.02765261627906977, "train_stats/sum_log_reward": 3.099999937144193, "train_stats/max_log_achievement_collect_drink": 2.8181818181818183, "train_stats/max_log_achievement_collect_sapling": 2.1818181818181817, "train_stats/max_log_achievement_collect_wood": 1.0, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.09090909090909091, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 2.090909090909091, "train_stats/max_log_achievement_place_table": 0.2727272727272727, "train_stats/max_log_achievement_wake_up": 2.272727272727273, "train_stats/mean_log_entropy": 0.5540539486841722, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 7.310164846785483e-07, "report/cont_loss_std": 1.2795380825991742e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 1.742559834383428e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 6.490999453490076e-07, "report/cont_pred": 0.9951164722442627, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 2.590644121170044, "report/dyn_loss_std": 7.366129398345947, "report/image_loss_mean": 1.0676778554916382, "report/image_loss_std": 3.3875997066497803, "report/model_loss_mean": 2.68679141998291, "report/model_loss_std": 7.192347049713135, "report/post_ent_mag": 43.18444061279297, "report/post_ent_max": 43.18444061279297, "report/post_ent_mean": 21.379159927368164, "report/post_ent_min": 13.176458358764648, "report/post_ent_std": 3.579124927520752, "report/prior_ent_mag": 74.19113159179688, "report/prior_ent_max": 74.19113159179688, "report/prior_ent_mean": 23.88528060913086, "report/prior_ent_min": 14.539451599121094, "report/prior_ent_std": 8.482215881347656, "report/rep_loss_mean": 2.590644121170044, "report/rep_loss_std": 7.366129398345947, "report/reward_avg": 0.018620993942022324, "report/reward_loss_mean": 0.0647265762090683, "report/reward_loss_std": 0.13785941898822784, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0041749477386475, "report/reward_neg_acc": 0.9989960789680481, "report/reward_neg_loss": 0.04759304225444794, "report/reward_pos_acc": 0.9642857313156128, "report/reward_pos_loss": 0.6741908192634583, "report/reward_pred": 0.019152529537677765, "report/reward_rate": 0.02734375, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.007613219786435366, "eval/cont_loss_std": 0.22287234663963318, "eval/cont_neg_acc": 0.800000011920929, "eval/cont_neg_loss": 1.5590571165084839, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 6.396082312676299e-07, "eval/cont_pred": 0.9965804815292358, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 23.47476577758789, "eval/dyn_loss_std": 14.128111839294434, "eval/image_loss_mean": 38.97539138793945, "eval/image_loss_std": 39.18330383300781, "eval/model_loss_mean": 53.24275207519531, "eval/model_loss_std": 44.29902648925781, "eval/post_ent_mag": 43.18444061279297, "eval/post_ent_max": 43.18444061279297, "eval/post_ent_mean": 25.587366104125977, "eval/post_ent_min": 15.408474922180176, "eval/post_ent_std": 3.655238628387451, "eval/prior_ent_mag": 74.19113159179688, "eval/prior_ent_max": 74.19113159179688, "eval/prior_ent_mean": 33.5131721496582, "eval/prior_ent_min": 17.583879470825195, "eval/prior_ent_std": 9.121735572814941, "eval/rep_loss_mean": 23.47476577758789, "eval/rep_loss_std": 14.128111839294434, "eval/reward_avg": 0.013671875, "eval/reward_loss_mean": 0.17488940060138702, "eval/reward_loss_std": 1.10981023311615, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0018274784088135, "eval/reward_neg_acc": 0.9970149993896484, "eval/reward_neg_loss": 0.07852770388126373, "eval/reward_pos_acc": 0.3684210479259491, "eval/reward_pos_loss": 5.271916389465332, "eval/reward_pred": 0.004386951215565205, "eval/reward_rate": 0.0185546875, "replay/size": 65276.0, "replay/inserts": 2145.0, "replay/samples": 34320.0, "replay/insert_wait_avg": 2.6350532656227235e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.815502740286447e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 14312.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 7.450580596923828e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2417736053467, "timer/env.step_count": 268.0, "timer/env.step_total": 24.652954578399658, "timer/env.step_frac": 0.02464699558541601, "timer/env.step_avg": 0.09198863648656588, "timer/env.step_min": 0.024379253387451172, "timer/env.step_max": 3.304028034210205, "timer/replay._sample_count": 34320.0, "timer/replay._sample_total": 16.57472825050354, "timer/replay._sample_frac": 0.016570721887329644, "timer/replay._sample_avg": 0.00048294662734567426, "timer/replay._sample_min": 0.00031828880310058594, "timer/replay._sample_max": 0.025722265243530273, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 268.0, "timer/agent.policy_total": 4.270897626876831, "timer/agent.policy_frac": 0.004269865286152253, "timer/agent.policy_avg": 0.015936185174913547, "timer/agent.policy_min": 0.014636039733886719, "timer/agent.policy_max": 0.042176008224487305, "timer/dataset_train_count": 2145.0, "timer/dataset_train_total": 0.3936619758605957, "timer/dataset_train_frac": 0.00039356682179114645, "timer/dataset_train_avg": 0.0001835253966716064, "timer/dataset_train_min": 8.845329284667969e-05, "timer/dataset_train_max": 0.0005123615264892578, "timer/agent.train_count": 2145.0, "timer/agent.train_total": 959.4959990978241, "timer/agent.train_frac": 0.9592640743640856, "timer/agent.train_avg": 0.4473174820968877, "timer/agent.train_min": 0.43595027923583984, "timer/agent.train_max": 0.5883638858795166, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4742753505706787, "timer/agent.report_frac": 0.0004741607110260602, "timer/agent.report_avg": 0.23713767528533936, "timer/agent.report_min": 0.23053312301635742, "timer/agent.report_max": 0.2437422275543213, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 5.173683166503906e-05, "timer/dataset_eval_frac": 5.1724326088236585e-08, "timer/dataset_eval_avg": 5.173683166503906e-05, "timer/dataset_eval_min": 5.173683166503906e-05, "timer/dataset_eval_max": 5.173683166503906e-05, "fps": 2.1444512770441593}
{"step": 65912, "time": 30389.76092481613, "episode/length": 146.0, "episode/score": 3.2684003954054788, "episode/reward_rate": 0.9591836734693877, "episode/intrinsic_return": 0.16840029449667782}
{"step": 66104, "time": 30479.730715036392, "episode/length": 158.0, "episode/score": 3.255094448028103, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.1550942993890203}
{"step": 66344, "time": 30591.582298755646, "episode/length": 232.0, "episode/score": 5.354597756871954, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.2545975486282259}
{"step": 66408, "time": 30622.368443727493, "episode/length": 208.0, "episode/score": 3.3368792672263226, "episode/reward_rate": 0.9712918660287081, "episode/intrinsic_return": 0.23687917656206992}
{"step": 66440, "time": 30638.538488149643, "episode/length": 207.0, "episode/score": 3.324617894999392, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.22461778361321194}
{"step": 66448, "time": 30643.73025083542, "episode/length": 42.0, "episode/score": -0.850625021266751, "episode/reward_rate": 0.8837209302325582, "episode/intrinsic_return": 0.04937499912921339}
{"step": 67032, "time": 30912.281218767166, "episode/length": 139.0, "episode/score": 1.1937281855261972, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.093728166195433}
{"step": 67040, "time": 30917.538101911545, "episode/length": 183.0, "episode/score": 4.278284154966968, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.17828403100793366}
{"step": 67128, "time": 30959.134732723236, "episode/length": 224.0, "episode/score": 4.328256928620249, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.22825677450964577}
{"step": 67248, "time": 31015.483516216278, "episode/length": 221.0, "episode/score": 3.3578258162160637, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.25782572438765783}
{"step": 67848, "time": 31290.46054005623, "episode/length": 187.0, "episode/score": 4.267433939028706, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.1674337893127813}
{"step": 67880, "time": 31306.536510944366, "episode/length": 178.0, "episode/score": 3.2910926373842813, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.19109254322756897}
{"step": 67924, "time": 31328.577476263046, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.194713842088931, "train/action_min": 0.0, "train/action_std": 4.077046885668675, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0409146700071815, "train/actor_opt_grad_steps": 65295.0, "train/actor_opt_loss": -13.532302259902739, "train/adv_mag": 0.7888106958609875, "train/adv_max": 0.7332210184257721, "train/adv_mean": 0.002108059711908681, "train/adv_min": -0.5795436148470807, "train/adv_std": 0.05373122275885299, "train/cont_avg": 0.9942729629088785, "train/cont_loss_mean": 5.225724341777503e-05, "train/cont_loss_std": 0.00160946668391593, "train/cont_neg_acc": 0.9987963752768864, "train/cont_neg_loss": 0.003104703145985457, "train/cont_pos_acc": 0.999995379247398, "train/cont_pos_loss": 2.3723384263562196e-05, "train/cont_pred": 0.9942731420013392, "train/cont_rate": 0.9942729629088785, "train/dyn_loss_mean": 2.9262962018217995, "train/dyn_loss_std": 7.74197084881435, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1690377414783584, "train/extr_critic_critic_opt_grad_steps": 65295.0, "train/extr_critic_critic_opt_loss": 14880.316949291764, "train/extr_critic_mag": 13.293047624213672, "train/extr_critic_max": 13.293047624213672, "train/extr_critic_mean": 2.3424897817807775, "train/extr_critic_min": -0.6823211262159259, "train/extr_critic_std": 2.629739265575587, "train/extr_return_normed_mag": 1.7074095111026941, "train/extr_return_normed_max": 1.7074095111026941, "train/extr_return_normed_mean": 0.32665795505603895, "train/extr_return_normed_min": -0.09949686104936578, "train/extr_return_normed_std": 0.32984135418294747, "train/extr_return_rate": 0.6940016286952473, "train/extr_return_raw_mag": 13.642524191152269, "train/extr_return_raw_max": 13.642524191152269, "train/extr_return_raw_mean": 2.3593452812355253, "train/extr_return_raw_min": -1.092971996169224, "train/extr_return_raw_std": 2.682270477865344, "train/extr_reward_mag": 1.0192492398146158, "train/extr_reward_max": 1.0192492398146158, "train/extr_reward_mean": 0.02748856925901687, "train/extr_reward_min": -0.6702220239371897, "train/extr_reward_std": 0.16332512303629768, "train/image_loss_mean": 1.7365049017924015, "train/image_loss_std": 4.870570868532234, "train/model_loss_mean": 3.5616962341504674, "train/model_loss_std": 8.611703872680664, "train/model_opt_grad_norm": 36.65727500288699, "train/model_opt_grad_steps": 65241.088785046726, "train/model_opt_loss": 6802.059132228388, "train/model_opt_model_opt_grad_overflow": 0.004672897196261682, "train/model_opt_model_opt_grad_scale": 1910.0467289719627, "train/policy_entropy_mag": 2.5935494309273834, "train/policy_entropy_max": 2.5935494309273834, "train/policy_entropy_mean": 0.627199954518648, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.7088022510582042, "train/policy_logprob_mag": 7.438383808759886, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.6265229447701267, "train/policy_logprob_min": -7.438383808759886, "train/policy_logprob_std": 1.173549578011593, "train/policy_randomness_mag": 0.9154091343701443, "train/policy_randomness_max": 0.9154091343701443, "train/policy_randomness_mean": 0.22137406231643997, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.2501760882055648, "train/post_ent_mag": 41.01659815779356, "train/post_ent_max": 41.01659815779356, "train/post_ent_mean": 20.910380301074447, "train/post_ent_min": 11.411198591517511, "train/post_ent_std": 3.669485503268019, "train/prior_ent_mag": 74.45713731284454, "train/prior_ent_max": 74.45713731284454, "train/prior_ent_mean": 23.85428617602197, "train/prior_ent_min": 12.667370386212786, "train/prior_ent_std": 8.86863660812378, "train/rep_loss_mean": 2.9262962018217995, "train/rep_loss_std": 7.74197084881435, "train/reward_avg": 0.016093963094569185, "train/reward_loss_mean": 0.06936134674769139, "train/reward_loss_std": 0.15679876450623306, "train/reward_max_data": 1.008726665906817, "train/reward_max_pred": 1.009464415434365, "train/reward_neg_acc": 0.9994597563119693, "train/reward_neg_loss": 0.05069653129326963, "train/reward_pos_acc": 0.9102868148099597, "train/reward_pos_loss": 0.727988632482903, "train/reward_pred": 0.015949801027787865, "train/reward_rate": 0.027526285046728972, "train_stats/sum_log_reward": 3.016666596134504, "train_stats/max_log_achievement_collect_drink": 2.4166666666666665, "train_stats/max_log_achievement_collect_sapling": 1.6666666666666667, "train_stats/max_log_achievement_collect_wood": 1.1666666666666667, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.08333333333333333, "train_stats/max_log_achievement_place_plant": 1.5833333333333333, "train_stats/max_log_achievement_place_table": 0.25, "train_stats/max_log_achievement_wake_up": 2.0, "train_stats/mean_log_entropy": 0.5897515279551347, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 6.963241503399331e-07, "report/cont_loss_std": 4.889423962595174e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 3.050806299143005e-05, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 4.911302085019997e-07, "report/cont_pred": 0.9931638836860657, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 4.098132133483887, "report/dyn_loss_std": 9.077868461608887, "report/image_loss_mean": 2.8460259437561035, "report/image_loss_std": 8.586002349853516, "report/model_loss_mean": 5.383191108703613, "report/model_loss_std": 12.637579917907715, "report/post_ent_mag": 43.98556900024414, "report/post_ent_max": 43.98556900024414, "report/post_ent_mean": 21.696592330932617, "report/post_ent_min": 11.973281860351562, "report/post_ent_std": 3.8994140625, "report/prior_ent_mag": 75.36404418945312, "report/prior_ent_max": 75.36404418945312, "report/prior_ent_mean": 25.264991760253906, "report/prior_ent_min": 12.379331588745117, "report/prior_ent_std": 9.681025505065918, "report/rep_loss_mean": 4.098132133483887, "report/rep_loss_std": 9.077868461608887, "report/reward_avg": 0.024767279624938965, "report/reward_loss_mean": 0.07828521728515625, "report/reward_loss_std": 0.1775205433368683, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.00718355178833, "report/reward_neg_acc": 0.9979776740074158, "report/reward_neg_loss": 0.054677918553352356, "report/reward_pos_acc": 0.9714285731315613, "report/reward_pos_loss": 0.7453597784042358, "report/reward_pred": 0.024795645847916603, "report/reward_rate": 0.0341796875, "eval/cont_avg": 0.9931640625, "eval/cont_loss_mean": 0.007316974923014641, "eval/cont_loss_std": 0.1679602861404419, "eval/cont_neg_acc": 0.7142857313156128, "eval/cont_neg_loss": 1.0702894926071167, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 5.461507157633605e-07, "eval/cont_pred": 0.9951072931289673, "eval/cont_rate": 0.9931640625, "eval/dyn_loss_mean": 24.137969970703125, "eval/dyn_loss_std": 14.226462364196777, "eval/image_loss_mean": 37.124114990234375, "eval/image_loss_std": 40.698612213134766, "eval/model_loss_mean": 51.771751403808594, "eval/model_loss_std": 46.550045013427734, "eval/post_ent_mag": 43.98556900024414, "eval/post_ent_max": 43.98556900024414, "eval/post_ent_mean": 25.853931427001953, "eval/post_ent_min": 14.41342544555664, "eval/post_ent_std": 4.058160781860352, "eval/prior_ent_mag": 75.36404418945312, "eval/prior_ent_max": 75.36404418945312, "eval/prior_ent_mean": 34.915550231933594, "eval/prior_ent_min": 13.986538887023926, "eval/prior_ent_std": 9.969537734985352, "eval/rep_loss_mean": 24.137969970703125, "eval/rep_loss_std": 14.226462364196777, "eval/reward_avg": 0.017578125, "eval/reward_loss_mean": 0.15753941237926483, "eval/reward_loss_std": 0.9079488515853882, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 1.002959966659546, "eval/reward_neg_acc": 0.9970000386238098, "eval/reward_neg_loss": 0.07556933909654617, "eval/reward_pos_acc": 0.5416666865348816, "eval/reward_pos_loss": 3.5729594230651855, "eval/reward_pred": 0.010343557223677635, "eval/reward_rate": 0.0234375, "replay/size": 67420.0, "replay/inserts": 2144.0, "replay/samples": 34304.0, "replay/insert_wait_avg": 2.5628885226463206e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.657834620618108e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 14312.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 7.599592208862305e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0500862598419, "timer/env.step_count": 268.0, "timer/env.step_total": 26.043596029281616, "timer/env.step_frac": 0.026042291668294238, "timer/env.step_avg": 0.09717759712418514, "timer/env.step_min": 0.023944854736328125, "timer/env.step_max": 2.0546927452087402, "timer/replay._sample_count": 34304.0, "timer/replay._sample_total": 16.73383331298828, "timer/replay._sample_frac": 0.016732995219841767, "timer/replay._sample_avg": 0.0004878099729765707, "timer/replay._sample_min": 0.00033736228942871094, "timer/replay._sample_max": 0.026556730270385742, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 268.0, "timer/agent.policy_total": 4.2163074016571045, "timer/agent.policy_frac": 0.004216096233165652, "timer/agent.policy_avg": 0.015732490304690688, "timer/agent.policy_min": 0.01461648941040039, "timer/agent.policy_max": 0.021544218063354492, "timer/dataset_train_count": 2144.0, "timer/dataset_train_total": 0.38953733444213867, "timer/dataset_train_frac": 0.00038951782495114513, "timer/dataset_train_avg": 0.00018168718957189302, "timer/dataset_train_min": 8.7738037109375e-05, "timer/dataset_train_max": 0.0007197856903076172, "timer/agent.train_count": 2144.0, "timer/agent.train_total": 958.6733386516571, "timer/agent.train_frac": 0.9586253246945534, "timer/agent.train_avg": 0.44714241541588484, "timer/agent.train_min": 0.4354894161224365, "timer/agent.train_max": 0.5908427238464355, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4775247573852539, "timer/agent.report_frac": 0.00047750084115404914, "timer/agent.report_avg": 0.23876237869262695, "timer/agent.report_min": 0.23103666305541992, "timer/agent.report_max": 0.24648809432983398, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0040740966796875e-05, "timer/dataset_eval_frac": 3.00392364137964e-08, "timer/dataset_eval_avg": 3.0040740966796875e-05, "timer/dataset_eval_min": 3.0040740966796875e-05, "timer/dataset_eval_max": 3.0040740966796875e-05, "fps": 2.1438642527283727}
{"step": 68096, "time": 31407.100451231003, "episode/length": 206.0, "episode/score": 3.314534697250565, "episode/reward_rate": 0.9806763285024155, "episode/intrinsic_return": 0.21453457177813107}
{"step": 68128, "time": 31423.242634296417, "episode/length": 214.0, "episode/score": 2.2718514798980323, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.1718514195017633}
{"step": 68288, "time": 31497.548139810562, "episode/length": 156.0, "episode/score": 4.251393885901052, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.15139376077786437}
{"step": 68288, "time": 31497.55596637726, "episode/length": 155.0, "episode/score": 4.262844815230892, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.16284471484595997}
{"step": 68800, "time": 31733.51618385315, "episode/length": 193.0, "episode/score": 4.2971041862683705, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.19710397651124367}
{"step": 69128, "time": 31884.39722585678, "episode/length": 155.0, "episode/score": 3.2270140913406067, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.12701402582206356}
{"step": 69160, "time": 31900.511909723282, "episode/length": 253.0, "episode/score": 2.362408499167941, "episode/reward_rate": 0.984251968503937, "episode/intrinsic_return": 0.2624084324852447}
{"step": 69208, "time": 31923.80966067314, "episode/length": 169.0, "episode/score": 4.298027016745436, "episode/reward_rate": 0.9588235294117647, "episode/intrinsic_return": 0.1980269032637807}
{"step": 69296, "time": 31965.38458752632, "episode/length": 145.0, "episode/score": 4.228115792561766, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.12811565829997562}
{"step": 69448, "time": 32036.107152462006, "episode/length": 168.0, "episode/score": 4.272041362042728, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.1720413124148763}
{"step": 69616, "time": 32114.11279654503, "episode/length": 165.0, "episode/score": 4.253044810618121, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.1530446910610408}
{"step": 69680, "time": 32144.684623241425, "episode/length": 173.0, "episode/score": 5.276198567783467, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.176198398611632}
{"step": 69800, "time": 32200.57385802269, "episode/length": 43.0, "episode/score": 2.1541667310521007, "episode/reward_rate": 0.8863636363636364, "episode/intrinsic_return": 0.054166665533557534}
{"step": 70076, "time": 32328.793729543686, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.339414800599564, "train/action_min": 0.0, "train/action_std": 4.080764731695486, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03957593575293242, "train/actor_opt_grad_steps": 67440.0, "train/actor_opt_loss": -13.523362367565548, "train/adv_mag": 0.7507062723470289, "train/adv_max": 0.667491978684137, "train/adv_mean": 0.0021588729727650495, "train/adv_min": -0.5926136120807293, "train/adv_std": 0.0515458611728147, "train/cont_avg": 0.9944494912790698, "train/cont_loss_mean": 6.192845109004593e-05, "train/cont_loss_std": 0.0019239114040900394, "train/cont_neg_acc": 0.9987541531407556, "train/cont_neg_loss": 0.007122484803930156, "train/cont_pos_acc": 0.999995422917743, "train/cont_pos_loss": 1.3923604509011247e-05, "train/cont_pred": 0.9944520844969639, "train/cont_rate": 0.9944494912790698, "train/dyn_loss_mean": 2.9174524395964867, "train/dyn_loss_std": 7.741026707582695, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1488387263098427, "train/extr_critic_critic_opt_grad_steps": 67440.0, "train/extr_critic_critic_opt_loss": 14689.096934047966, "train/extr_critic_mag": 12.595988127242688, "train/extr_critic_max": 12.595988127242688, "train/extr_critic_mean": 2.42153225444084, "train/extr_critic_min": -0.6450956455496855, "train/extr_critic_std": 2.649125826081564, "train/extr_return_normed_mag": 1.6619637650112773, "train/extr_return_normed_max": 1.6619637650112773, "train/extr_return_normed_mean": 0.3349995595771213, "train/extr_return_normed_min": -0.09832103054883869, "train/extr_return_normed_std": 0.33987923721934477, "train/extr_return_rate": 0.6973604407421378, "train/extr_return_raw_mag": 12.943680075711983, "train/extr_return_raw_max": 12.943680075711983, "train/extr_return_raw_mean": 2.4386195737262106, "train/extr_return_raw_min": -0.9885391728822575, "train/extr_return_raw_std": 2.6894901575044146, "train/extr_reward_mag": 1.0234142802482427, "train/extr_reward_max": 1.0234142802482427, "train/extr_reward_mean": 0.030932231403367465, "train/extr_reward_min": -0.6720028539036595, "train/extr_reward_std": 0.17179431364286776, "train/image_loss_mean": 1.7242925771447115, "train/image_loss_std": 4.916096593058387, "train/model_loss_mean": 3.5449970955072447, "train/model_loss_std": 8.66262306834376, "train/model_opt_grad_norm": 34.28815078291782, "train/model_opt_grad_steps": 67384.35813953489, "train/model_opt_loss": 6805.121433275799, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1918.6046511627908, "train/policy_entropy_mag": 2.5788868272027305, "train/policy_entropy_max": 2.5788868272027305, "train/policy_entropy_mean": 0.6108246783877528, "train/policy_entropy_min": 0.07937501377837602, "train/policy_entropy_std": 0.6944266493930373, "train/policy_logprob_mag": 7.438383880881376, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.6108571749786998, "train/policy_logprob_min": -7.438383880881376, "train/policy_logprob_std": 1.1614659730778185, "train/policy_randomness_mag": 0.9102338774259701, "train/policy_randomness_max": 0.9102338774259701, "train/policy_randomness_mean": 0.2155943067960961, "train/policy_randomness_min": 0.028015896703961284, "train/policy_randomness_std": 0.24510213268357653, "train/post_ent_mag": 41.06163855264353, "train/post_ent_max": 41.06163855264353, "train/post_ent_mean": 20.98611832552178, "train/post_ent_min": 11.289670363137889, "train/post_ent_std": 3.735370342121568, "train/prior_ent_mag": 74.57204980184865, "train/prior_ent_max": 74.57204980184865, "train/prior_ent_mean": 23.911729413409567, "train/prior_ent_min": 12.668919106416924, "train/prior_ent_std": 8.875089729663937, "train/rep_loss_mean": 2.9174524395964867, "train/rep_loss_std": 7.741026707582695, "train/reward_avg": 0.01683757757703059, "train/reward_loss_mean": 0.07017114560964495, "train/reward_loss_std": 0.1615826371104218, "train/reward_max_data": 1.0114825891893964, "train/reward_max_pred": 1.0117548798405847, "train/reward_neg_acc": 0.9993831631749175, "train/reward_neg_loss": 0.05090867073036903, "train/reward_pos_acc": 0.9136804561282313, "train/reward_pos_loss": 0.73254856924678, "train/reward_pred": 0.016691699822238365, "train/reward_rate": 0.028361191860465117, "train_stats/sum_log_reward": 3.5615383845109205, "train_stats/max_log_achievement_collect_drink": 4.769230769230769, "train_stats/max_log_achievement_collect_sapling": 1.7692307692307692, "train_stats/max_log_achievement_collect_wood": 1.3846153846153846, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.7692307692307692, "train_stats/max_log_achievement_place_table": 0.38461538461538464, "train_stats/max_log_achievement_wake_up": 2.0, "train_stats/mean_log_entropy": 0.5386466876818583, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 2.607846454338869e-07, "report/cont_loss_std": 3.1187903459795052e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 1.1290551810816396e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.066641116016399e-07, "report/cont_pred": 0.9951170682907104, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 2.8024139404296875, "report/dyn_loss_std": 7.925992488861084, "report/image_loss_mean": 1.2951116561889648, "report/image_loss_std": 3.6285693645477295, "report/model_loss_mean": 3.045076847076416, "report/model_loss_std": 7.848015308380127, "report/post_ent_mag": 36.099700927734375, "report/post_ent_max": 36.099700927734375, "report/post_ent_mean": 20.932666778564453, "report/post_ent_min": 11.104903221130371, "report/post_ent_std": 3.553896903991699, "report/prior_ent_mag": 74.95664978027344, "report/prior_ent_max": 74.95664978027344, "report/prior_ent_mean": 23.915088653564453, "report/prior_ent_min": 14.169631004333496, "report/prior_ent_std": 8.689844131469727, "report/rep_loss_mean": 2.8024139404296875, "report/rep_loss_std": 7.925992488861084, "report/reward_avg": 0.020091190934181213, "report/reward_loss_mean": 0.06851644068956375, "report/reward_loss_std": 0.15045398473739624, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0048093795776367, "report/reward_neg_acc": 0.998992919921875, "report/reward_neg_loss": 0.0471782386302948, "report/reward_pos_acc": 0.9032257795333862, "report/reward_pos_loss": 0.7520270943641663, "report/reward_pred": 0.01969161629676819, "report/reward_rate": 0.0302734375, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 5.811536084365798e-06, "eval/cont_loss_std": 0.00016768783098086715, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0011655500857159495, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.2096418799956155e-07, "eval/cont_pred": 0.9951227903366089, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 25.30362892150879, "eval/dyn_loss_std": 14.308332443237305, "eval/image_loss_mean": 43.918861389160156, "eval/image_loss_std": 44.416202545166016, "eval/model_loss_mean": 59.23443603515625, "eval/model_loss_std": 49.60429763793945, "eval/post_ent_mag": 37.03861999511719, "eval/post_ent_max": 37.03861999511719, "eval/post_ent_mean": 25.69786834716797, "eval/post_ent_min": 14.988987922668457, "eval/post_ent_std": 3.9111828804016113, "eval/prior_ent_mag": 74.95664978027344, "eval/prior_ent_max": 74.95664978027344, "eval/prior_ent_mean": 34.59151840209961, "eval/prior_ent_min": 15.113191604614258, "eval/prior_ent_std": 9.134403228759766, "eval/rep_loss_mean": 25.30362892150879, "eval/rep_loss_std": 14.308332443237305, "eval/reward_avg": 0.02685546875, "eval/reward_loss_mean": 0.13339197635650635, "eval/reward_loss_std": 0.7520697712898254, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 1.002974271774292, "eval/reward_neg_acc": 0.9939515590667725, "eval/reward_neg_loss": 0.0561562106013298, "eval/reward_pos_acc": 0.71875, "eval/reward_pos_loss": 2.527700424194336, "eval/reward_pred": 0.017133837565779686, "eval/reward_rate": 0.03125, "replay/size": 69572.0, "replay/inserts": 2152.0, "replay/samples": 34432.0, "replay/insert_wait_avg": 2.55690631370119e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.70228004366935e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 14312.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 1.2069940567016602e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2001888751984, "timer/env.step_count": 269.0, "timer/env.step_total": 26.635095834732056, "timer/env.step_frac": 0.026629764852059524, "timer/env.step_avg": 0.09901522615142028, "timer/env.step_min": 0.023934125900268555, "timer/env.step_max": 3.1883625984191895, "timer/replay._sample_count": 34432.0, "timer/replay._sample_total": 16.323533535003662, "timer/replay._sample_frac": 0.016320266399230263, "timer/replay._sample_avg": 0.0004740803187442978, "timer/replay._sample_min": 0.0003342628479003906, "timer/replay._sample_max": 0.009877443313598633, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 269.0, "timer/agent.policy_total": 4.179863452911377, "timer/agent.policy_frac": 0.004179026858225205, "timer/agent.policy_avg": 0.01553852584725419, "timer/agent.policy_min": 0.014440774917602539, "timer/agent.policy_max": 0.03908872604370117, "timer/dataset_train_count": 2152.0, "timer/dataset_train_total": 0.3790764808654785, "timer/dataset_train_frac": 0.0003790006091598313, "timer/dataset_train_avg": 0.000176150781071319, "timer/dataset_train_min": 8.869171142578125e-05, "timer/dataset_train_max": 0.0005681514739990234, "timer/agent.train_count": 2152.0, "timer/agent.train_total": 958.6313173770905, "timer/agent.train_frac": 0.9584394484619572, "timer/agent.train_avg": 0.4454606493387967, "timer/agent.train_min": 0.4353675842285156, "timer/agent.train_max": 0.56683349609375, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4791293144226074, "timer/agent.report_frac": 0.0004790334172616234, "timer/agent.report_avg": 0.2395646572113037, "timer/agent.report_min": 0.2324976921081543, "timer/agent.report_max": 0.24663162231445312, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.24249267578125e-05, "timer/dataset_eval_frac": 3.2418436947384315e-08, "timer/dataset_eval_avg": 3.24249267578125e-05, "timer/dataset_eval_min": 3.24249267578125e-05, "timer/dataset_eval_max": 3.24249267578125e-05, "fps": 2.1515395049148993}
{"step": 70096, "time": 32353.21816086769, "eval_episode/length": 53.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9074074074074074}
{"step": 70096, "time": 32359.502719163895, "eval_episode/length": 167.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9761904761904762}
{"step": 70096, "time": 32361.08433318138, "eval_episode/length": 168.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9940828402366864}
{"step": 70096, "time": 32363.305577754974, "eval_episode/length": 184.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9945945945945946}
{"step": 70096, "time": 32364.83882665634, "eval_episode/length": 185.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9731182795698925}
{"step": 70096, "time": 32366.724894285202, "eval_episode/length": 194.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9948717948717949}
{"step": 70096, "time": 32368.823716640472, "eval_episode/length": 197.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9949494949494949}
{"step": 70096, "time": 32372.125504732132, "eval_episode/length": 154.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.967741935483871}
{"step": 70120, "time": 32383.19349193573, "episode/length": 39.0, "episode/score": 2.1452917882124893, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.04529166588326916}
{"step": 70176, "time": 32410.118392705917, "episode/length": 171.0, "episode/score": 3.2401341253125793, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.1401340824950239}
{"step": 70448, "time": 32535.86292886734, "episode/length": 160.0, "episode/score": 4.230519879381063, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.13051973345227452}
{"step": 70584, "time": 32599.557909488678, "episode/length": 171.0, "episode/score": 3.2761485106479995, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.176148415327134}
{"step": 70616, "time": 32615.544887304306, "episode/length": 164.0, "episode/score": 4.258741521273805, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.15874146338046558}
{"step": 70936, "time": 32762.938121318817, "episode/length": 156.0, "episode/score": 2.265965841133493, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.16596577561494996}
{"step": 71048, "time": 32815.04624605179, "episode/length": 178.0, "episode/score": 3.2537711926511292, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.15377109849441695}
{"step": 71544, "time": 33040.97403168678, "episode/length": 177.0, "episode/score": 4.284487434171751, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.1844873102127167}
{"step": 71592, "time": 33064.38870191574, "episode/length": 307.0, "episode/score": 5.408274945672929, "episode/reward_rate": 0.9967532467532467, "episode/intrinsic_return": 0.3082749465111192}
{"step": 71704, "time": 33116.93344449997, "episode/length": 190.0, "episode/score": 1.2924521594650287, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.1924521214205015}
{"step": 71816, "time": 33169.27145695686, "episode/length": 170.0, "episode/score": 1.2678537610863714, "episode/reward_rate": 0.9649122807017544, "episode/intrinsic_return": 0.16785372769845708}
{"step": 71824, "time": 33174.378967523575, "episode/length": 150.0, "episode/score": 4.257887921248766, "episode/reward_rate": 0.9602649006622517, "episode/intrinsic_return": 0.15788780194634455}
{"step": 72008, "time": 33259.42606139183, "episode/length": 37.0, "episode/score": 1.1462500359630212, "episode/reward_rate": 0.868421052631579, "episode/intrinsic_return": 0.046249999082647264}
{"step": 72104, "time": 33304.392127752304, "episode/length": 131.0, "episode/score": 3.2267163835313113, "episode/reward_rate": 0.9924242424242424, "episode/intrinsic_return": 0.12671623256392195}
{"step": 72144, "time": 33324.122824430466, "episode/length": 194.0, "episode/score": 3.2809594191876386, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.18095930780145864}
{"step": 72150, "time": 33329.026935338974, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.122173602764423, "train/action_min": 0.0, "train/action_std": 3.965910338438474, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0378365953399155, "train/actor_opt_grad_steps": 69555.0, "train/actor_opt_loss": -15.005414228743085, "train/adv_mag": 0.6608498536336881, "train/adv_max": 0.5705969249113247, "train/adv_mean": 0.0014163468420327683, "train/adv_min": -0.5438512627465221, "train/adv_std": 0.047719752219004125, "train/cont_avg": 0.9942204402043269, "train/cont_loss_mean": 4.232082725631213e-05, "train/cont_loss_std": 0.0013103694446583948, "train/cont_neg_acc": 0.9990384615957737, "train/cont_neg_loss": 0.001794952623841849, "train/cont_pos_acc": 0.9999905561025326, "train/cont_pos_loss": 3.298948434030754e-05, "train/cont_pred": 0.9942115023732185, "train/cont_rate": 0.9942204402043269, "train/dyn_loss_mean": 2.8634768403493442, "train/dyn_loss_std": 7.730305928450364, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.085108785961683, "train/extr_critic_critic_opt_grad_steps": 69555.0, "train/extr_critic_critic_opt_loss": 14296.649930513822, "train/extr_critic_mag": 10.873086851376753, "train/extr_critic_max": 10.873086851376753, "train/extr_critic_mean": 2.37749284104659, "train/extr_critic_min": -0.666998413319771, "train/extr_critic_std": 2.478891909122467, "train/extr_return_normed_mag": 1.5312630087137222, "train/extr_return_normed_max": 1.5312630087137222, "train/extr_return_normed_mean": 0.34962566354526925, "train/extr_return_normed_min": -0.09958072132072769, "train/extr_return_normed_std": 0.3347917551604601, "train/extr_return_rate": 0.6981743012483304, "train/extr_return_raw_mag": 11.245086527787722, "train/extr_return_raw_max": 11.245086527787722, "train/extr_return_raw_mean": 2.388141778799204, "train/extr_return_raw_min": -0.9802397168599642, "train/extr_return_raw_std": 2.5109206271859317, "train/extr_reward_mag": 1.0292036819916506, "train/extr_reward_max": 1.0292036819916506, "train/extr_reward_mean": 0.03158929875980203, "train/extr_reward_min": -0.6647531590782679, "train/extr_reward_std": 0.17433425028306934, "train/image_loss_mean": 1.6168325918798263, "train/image_loss_std": 4.62365281696503, "train/model_loss_mean": 3.4042700838584166, "train/model_loss_std": 8.377718230852714, "train/model_opt_grad_norm": 33.828663766384125, "train/model_opt_grad_steps": 69498.04807692308, "train/model_opt_loss": 8630.769430307242, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2536.0576923076924, "train/policy_entropy_mag": 2.5833234168015995, "train/policy_entropy_max": 2.5833234168015995, "train/policy_entropy_mean": 0.5848137753514143, "train/policy_entropy_min": 0.0793750137448884, "train/policy_entropy_std": 0.6797868100783, "train/policy_logprob_mag": 7.438383840597593, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5850056992987027, "train/policy_logprob_min": -7.438383840597593, "train/policy_logprob_std": 1.1500820589180176, "train/policy_randomness_mag": 0.9117998013702723, "train/policy_randomness_max": 0.9117998013702723, "train/policy_randomness_mean": 0.20641359826549888, "train/policy_randomness_min": 0.02801589668692591, "train/policy_randomness_std": 0.23993491130666092, "train/post_ent_mag": 41.56074010408842, "train/post_ent_max": 41.56074010408842, "train/post_ent_mean": 21.115201427386356, "train/post_ent_min": 11.481967091560364, "train/post_ent_std": 3.781029380284823, "train/prior_ent_mag": 74.67013116983267, "train/prior_ent_max": 74.67013116983267, "train/prior_ent_mean": 23.983885068159836, "train/prior_ent_min": 12.716234794029823, "train/prior_ent_std": 8.89129141660837, "train/rep_loss_mean": 2.8634768403493442, "train/rep_loss_std": 7.730305928450364, "train/reward_avg": 0.01689726937351784, "train/reward_loss_mean": 0.06930905974541719, "train/reward_loss_std": 0.153458701661573, "train/reward_max_data": 1.016634647662823, "train/reward_max_pred": 1.01652225622764, "train/reward_neg_acc": 0.9993669118445653, "train/reward_neg_loss": 0.050654617782968744, "train/reward_pos_acc": 0.9142232465629394, "train/reward_pos_loss": 0.7184880731197504, "train/reward_pred": 0.01679845214731848, "train/reward_rate": 0.0279541015625, "eval_stats/sum_log_reward": 3.099999874830246, "eval_stats/max_log_achievement_collect_drink": 2.125, "eval_stats/max_log_achievement_collect_sapling": 2.0, "eval_stats/max_log_achievement_collect_wood": 0.75, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.0, "eval_stats/max_log_achievement_place_table": 0.25, "eval_stats/max_log_achievement_wake_up": 2.375, "eval_stats/mean_log_entropy": 0.0, "train_stats/sum_log_reward": 2.966666579246521, "train_stats/max_log_achievement_collect_drink": 3.2, "train_stats/max_log_achievement_collect_sapling": 1.8666666666666667, "train_stats/max_log_achievement_collect_wood": 1.2, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.7333333333333334, "train_stats/max_log_achievement_place_table": 0.4, "train_stats/max_log_achievement_wake_up": 1.8, "train_stats/mean_log_entropy": 0.5072116633256276, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 2.3132799924496794e-06, "report/cont_loss_std": 2.652982948347926e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00027719189529307187, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 4.212935209579882e-07, "report/cont_pred": 0.9931656122207642, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 3.023932933807373, "report/dyn_loss_std": 8.023303985595703, "report/image_loss_mean": 1.8568836450576782, "report/image_loss_std": 4.942397117614746, "report/model_loss_mean": 3.74662709236145, "report/model_loss_std": 8.979279518127441, "report/post_ent_mag": 45.545143127441406, "report/post_ent_max": 45.545143127441406, "report/post_ent_mean": 21.118080139160156, "report/post_ent_min": 10.909987449645996, "report/post_ent_std": 4.5986199378967285, "report/prior_ent_mag": 74.99837493896484, "report/prior_ent_max": 74.99837493896484, "report/prior_ent_mean": 24.222415924072266, "report/prior_ent_min": 12.8682279586792, "report/prior_ent_std": 9.3021879196167, "report/rep_loss_mean": 3.023932933807373, "report/rep_loss_std": 8.023303985595703, "report/reward_avg": 0.011521561071276665, "report/reward_loss_mean": 0.07538104057312012, "report/reward_loss_std": 0.23783190548419952, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0011811256408691, "report/reward_neg_acc": 0.9989989995956421, "report/reward_neg_loss": 0.05521709471940994, "report/reward_pos_acc": 0.9199999570846558, "report/reward_pos_loss": 0.8811325430870056, "report/reward_pred": 0.010915687307715416, "report/reward_rate": 0.0244140625, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.0016235669609159231, "eval/cont_loss_std": 0.04762096703052521, "eval/cont_neg_acc": 0.5, "eval/cont_neg_loss": 0.8311392068862915, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.4822179511829745e-07, "eval/cont_pred": 0.9989405870437622, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 27.06658935546875, "eval/dyn_loss_std": 15.74927043914795, "eval/image_loss_mean": 46.45008850097656, "eval/image_loss_std": 49.98484420776367, "eval/model_loss_mean": 62.88716506958008, "eval/model_loss_std": 56.61279296875, "eval/post_ent_mag": 45.545143127441406, "eval/post_ent_max": 45.545143127441406, "eval/post_ent_mean": 25.2362060546875, "eval/post_ent_min": 15.982760429382324, "eval/post_ent_std": 3.319204330444336, "eval/prior_ent_mag": 74.99837493896484, "eval/prior_ent_max": 74.99837493896484, "eval/prior_ent_mean": 34.1815185546875, "eval/prior_ent_min": 18.20604133605957, "eval/prior_ent_std": 8.708829879760742, "eval/rep_loss_mean": 27.06658935546875, "eval/rep_loss_std": 15.74927043914795, "eval/reward_avg": 0.03125, "eval/reward_loss_mean": 0.19550210237503052, "eval/reward_loss_std": 1.2527186870574951, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0012366771697998, "eval/reward_neg_acc": 0.992929220199585, "eval/reward_neg_loss": 0.0858931690454483, "eval/reward_pos_acc": 0.6470588445663452, "eval/reward_pos_loss": 3.3870558738708496, "eval/reward_pred": 0.02289215847849846, "eval/reward_rate": 0.033203125, "replay/size": 71646.0, "replay/inserts": 2074.0, "replay/samples": 33184.0, "replay/insert_wait_avg": 2.5429399172158457e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.644999797456865e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 15984.0, "eval_replay/inserts": 1672.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1922354903517728e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.642673492431641e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2216968536377, "timer/env.step_count": 259.0, "timer/env.step_total": 29.334331274032593, "timer/env.step_frac": 0.029327829386533576, "timer/env.step_avg": 0.11325996630900614, "timer/env.step_min": 0.023827552795410156, "timer/env.step_max": 1.653867483139038, "timer/replay._sample_count": 33184.0, "timer/replay._sample_total": 15.679707050323486, "timer/replay._sample_frac": 0.015676231679083337, "timer/replay._sample_avg": 0.00047250804756278586, "timer/replay._sample_min": 0.0003490447998046875, "timer/replay._sample_max": 0.03034496307373047, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 468.0, "timer/agent.policy_total": 7.51848030090332, "timer/agent.policy_frac": 0.007516813846924077, "timer/agent.policy_avg": 0.016065128848084018, "timer/agent.policy_min": 0.00972604751586914, "timer/agent.policy_max": 0.09496235847473145, "timer/dataset_train_count": 2074.0, "timer/dataset_train_total": 0.3599677085876465, "timer/dataset_train_frac": 0.00035988792256755103, "timer/dataset_train_avg": 0.00017356205814254892, "timer/dataset_train_min": 8.463859558105469e-05, "timer/dataset_train_max": 0.0006966590881347656, "timer/agent.train_count": 2074.0, "timer/agent.train_total": 922.6008443832397, "timer/agent.train_frac": 0.9223963520141913, "timer/agent.train_avg": 0.44484129430242997, "timer/agent.train_min": 0.43187499046325684, "timer/agent.train_max": 0.5990378856658936, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.46791839599609375, "timer/agent.report_frac": 0.0004678146829527976, "timer/agent.report_avg": 0.23395919799804688, "timer/agent.report_min": 0.22324681282043457, "timer/agent.report_max": 0.24467158317565918, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.123283386230469e-05, "timer/dataset_eval_frac": 3.122591117604499e-08, "timer/dataset_eval_avg": 3.123283386230469e-05, "timer/dataset_eval_min": 3.123283386230469e-05, "timer/dataset_eval_max": 3.123283386230469e-05, "fps": 2.0735148969486072}
{"step": 72288, "time": 33391.92034697533, "episode/length": 168.0, "episode/score": 3.2754294491205656, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.17542933377626468}
{"step": 72432, "time": 33458.557193517685, "episode/length": 52.0, "episode/score": 0.15078921440272097, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.05078913328452472}
{"step": 72968, "time": 33703.44284749031, "episode/length": 171.0, "episode/score": 4.285191532053432, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.18519139202908264}
{"step": 73008, "time": 33722.909011125565, "episode/length": 182.0, "episode/score": 1.2885302175654942, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.18853017952096707}
{"step": 73152, "time": 33789.34680175781, "episode/length": 166.0, "episode/score": 3.2547459569059356, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.1547458615850701}
{"step": 73192, "time": 33808.91425323486, "episode/length": 130.0, "episode/score": 3.215603356169595, "episode/reward_rate": 0.9923664122137404, "episode/intrinsic_return": 0.11560314489906887}
{"step": 73392, "time": 33900.64567732811, "episode/length": 195.0, "episode/score": 5.305504858371023, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.20550465012729546}
{"step": 73464, "time": 33934.57335329056, "episode/length": 146.0, "episode/score": 3.2083069031386913, "episode/reward_rate": 0.9659863945578231, "episode/intrinsic_return": 0.10830680898197897}
{"step": 73488, "time": 33946.786712408066, "episode/length": 172.0, "episode/score": 2.2756373942820574, "episode/reward_rate": 0.9595375722543352, "episode/intrinsic_return": 0.17563735006751813}
{"step": 74256, "time": 34295.46487259865, "episode/length": 227.0, "episode/score": 4.35764313051277, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.25764298338708613}
{"step": 74326, "time": 34329.18378376961, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.02433586999568, "train/action_min": 0.0, "train/action_std": 3.960345958235077, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.039037851977252194, "train/actor_opt_grad_steps": 71680.0, "train/actor_opt_loss": -13.243550411292485, "train/adv_mag": 0.681130610784078, "train/adv_max": 0.6044108692539453, "train/adv_mean": 0.002397807978998525, "train/adv_min": -0.5356226445343087, "train/adv_std": 0.05041839934301816, "train/cont_avg": 0.9942171298963134, "train/cont_loss_mean": 1.4153635064552002e-05, "train/cont_loss_std": 0.0003158104286609151, "train/cont_neg_acc": 1.0, "train/cont_neg_loss": 0.0008492531640592968, "train/cont_pos_acc": 0.9999999824207499, "train/cont_pos_loss": 9.136219547872419e-06, "train/cont_pred": 0.9942130001459254, "train/cont_rate": 0.9942171298963134, "train/dyn_loss_mean": 2.9729790423872284, "train/dyn_loss_std": 7.77213409309563, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1129651014705957, "train/extr_critic_critic_opt_grad_steps": 71680.0, "train/extr_critic_critic_opt_loss": 14814.607156358006, "train/extr_critic_mag": 11.728681445671116, "train/extr_critic_max": 11.728681445671116, "train/extr_critic_mean": 2.3686637861937423, "train/extr_critic_min": -0.6494258807002125, "train/extr_critic_std": 2.4612465476110783, "train/extr_return_normed_mag": 1.675126800339343, "train/extr_return_normed_max": 1.675126800339343, "train/extr_return_normed_mean": 0.35053054974650455, "train/extr_return_normed_min": -0.10488085586079804, "train/extr_return_normed_std": 0.33883320145343304, "train/extr_return_rate": 0.7234942402158465, "train/extr_return_raw_mag": 12.183146226241291, "train/extr_return_raw_max": 12.183146226241291, "train/extr_return_raw_mean": 2.3864492963535993, "train/extr_return_raw_min": -0.9808061198430127, "train/extr_return_raw_std": 2.5062214932683426, "train/extr_reward_mag": 1.0272691304782569, "train/extr_reward_max": 1.0272691304782569, "train/extr_reward_mean": 0.03252699598670006, "train/extr_reward_min": -0.6628691869946669, "train/extr_reward_std": 0.1767169472671324, "train/image_loss_mean": 1.7692894100593533, "train/image_loss_std": 5.2622300029350315, "train/model_loss_mean": 3.623280783402755, "train/model_loss_std": 9.003724790388539, "train/model_opt_grad_norm": 36.05027619375062, "train/model_opt_grad_steps": 71621.12442396313, "train/model_opt_loss": 7027.614099177347, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1923.963133640553, "train/policy_entropy_mag": 2.5605754434787733, "train/policy_entropy_max": 2.5605754434787733, "train/policy_entropy_mean": 0.5475583588747385, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6454614389876616, "train/policy_logprob_mag": 7.438383862719558, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5473275994924905, "train/policy_logprob_min": -7.438383862719558, "train/policy_logprob_std": 1.127007583044641, "train/policy_randomness_mag": 0.9037707651265755, "train/policy_randomness_max": 0.9037707651265755, "train/policy_randomness_mean": 0.19326407184249245, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.22781956326302297, "train/post_ent_mag": 41.423526482648015, "train/post_ent_max": 41.423526482648015, "train/post_ent_mean": 21.40986678127869, "train/post_ent_min": 11.560278066292337, "train/post_ent_std": 3.7869801993743617, "train/prior_ent_mag": 74.66377915764734, "train/prior_ent_max": 74.66377915764734, "train/prior_ent_mean": 24.382073995704474, "train/prior_ent_min": 12.742987180085775, "train/prior_ent_std": 8.909738369251725, "train/rep_loss_mean": 2.9729790423872284, "train/rep_loss_std": 7.77213409309563, "train/reward_avg": 0.017319027604835648, "train/reward_loss_mean": 0.07018978576162993, "train/reward_loss_std": 0.15780564655082016, "train/reward_max_data": 1.0113882798753027, "train/reward_max_pred": 1.0125883998958747, "train/reward_neg_acc": 0.9993606539365882, "train/reward_neg_loss": 0.050694925736309744, "train/reward_pos_acc": 0.9151012128399264, "train/reward_pos_loss": 0.725741115308577, "train/reward_pred": 0.017160158428419295, "train/reward_rate": 0.02888284850230415, "train_stats/sum_log_reward": 2.899999940395355, "train_stats/max_log_achievement_collect_drink": 2.1, "train_stats/max_log_achievement_collect_sapling": 1.5, "train_stats/max_log_achievement_collect_wood": 1.1, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.2, "train_stats/max_log_achievement_place_table": 0.4, "train_stats/max_log_achievement_wake_up": 1.6, "train_stats/mean_log_entropy": 0.4711348325014114, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 2.2799147245677887e-06, "report/cont_loss_std": 3.498885780572891e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 1.1337716387060937e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.2354702196025755e-06, "report/cont_pred": 0.9951150417327881, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 2.795009136199951, "report/dyn_loss_std": 7.626296520233154, "report/image_loss_mean": 1.5993688106536865, "report/image_loss_std": 3.2729058265686035, "report/model_loss_mean": 3.3347086906433105, "report/model_loss_std": 6.967756748199463, "report/post_ent_mag": 33.70317077636719, "report/post_ent_max": 33.70317077636719, "report/post_ent_mean": 21.79584312438965, "report/post_ent_min": 11.546232223510742, "report/post_ent_std": 3.717334747314453, "report/prior_ent_mag": 74.63045501708984, "report/prior_ent_max": 74.63045501708984, "report/prior_ent_mean": 24.565567016601562, "report/prior_ent_min": 12.629881858825684, "report/prior_ent_std": 8.622074127197266, "report/rep_loss_mean": 2.795009136199951, "report/rep_loss_std": 7.626296520233154, "report/reward_avg": 0.008600734174251556, "report/reward_loss_mean": 0.05833197385072708, "report/reward_loss_std": 0.10555268079042435, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0054070949554443, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.04670913890004158, "report/reward_pos_acc": 0.9473684430122375, "report/reward_pos_loss": 0.6731187701225281, "report/reward_pred": 0.008602824062108994, "report/reward_rate": 0.0185546875, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.00010301172733306885, "eval/cont_loss_std": 0.0031250598840415478, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.02599424123764038, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 1.4774992678212584e-06, "eval/cont_pred": 0.9961891174316406, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 24.517547607421875, "eval/dyn_loss_std": 13.81591510772705, "eval/image_loss_mean": 45.540931701660156, "eval/image_loss_std": 48.407657623291016, "eval/model_loss_mean": 60.467586517333984, "eval/model_loss_std": 52.92586135864258, "eval/post_ent_mag": 36.87192153930664, "eval/post_ent_max": 36.87192153930664, "eval/post_ent_mean": 25.51711654663086, "eval/post_ent_min": 15.707181930541992, "eval/post_ent_std": 3.2508645057678223, "eval/prior_ent_mag": 74.63045501708984, "eval/prior_ent_max": 74.63045501708984, "eval/prior_ent_mean": 34.168067932128906, "eval/prior_ent_min": 16.695560455322266, "eval/prior_ent_std": 8.333041191101074, "eval/rep_loss_mean": 24.517547607421875, "eval/rep_loss_std": 13.81591510772705, "eval/reward_avg": 0.01386718638241291, "eval/reward_loss_mean": 0.21602292358875275, "eval/reward_loss_std": 1.2995867729187012, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0492908954620361, "eval/reward_neg_acc": 0.9950249195098877, "eval/reward_neg_loss": 0.11525458097457886, "eval/reward_pos_acc": 0.5263158082962036, "eval/reward_pos_loss": 5.546136856079102, "eval/reward_pred": 0.008934294804930687, "eval/reward_rate": 0.0185546875, "replay/size": 73822.0, "replay/inserts": 2176.0, "replay/samples": 34816.0, "replay/insert_wait_avg": 2.464498667155995e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.563366499893806e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 15984.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 7.450580596923828e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1423528194427, "timer/env.step_count": 272.0, "timer/env.step_total": 21.63684058189392, "timer/env.step_frac": 0.021633760955026823, "timer/env.step_avg": 0.07954720802166883, "timer/env.step_min": 0.023563623428344727, "timer/env.step_max": 1.5888071060180664, "timer/replay._sample_count": 34816.0, "timer/replay._sample_total": 16.247191429138184, "timer/replay._sample_frac": 0.01624487892482173, "timer/replay._sample_avg": 0.00046665876117699286, "timer/replay._sample_min": 0.0003502368927001953, "timer/replay._sample_max": 0.021911144256591797, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 272.0, "timer/agent.policy_total": 4.1417014598846436, "timer/agent.policy_frac": 0.004141111960921378, "timer/agent.policy_avg": 0.015226843602517071, "timer/agent.policy_min": 0.014360666275024414, "timer/agent.policy_max": 0.01713418960571289, "timer/dataset_train_count": 2176.0, "timer/dataset_train_total": 0.3882875442504883, "timer/dataset_train_frac": 0.0003882322782910749, "timer/dataset_train_avg": 0.0001784409670268788, "timer/dataset_train_min": 8.344650268554688e-05, "timer/dataset_train_max": 0.022005558013916016, "timer/agent.train_count": 2176.0, "timer/agent.train_total": 963.9874484539032, "timer/agent.train_frac": 0.9638502416544831, "timer/agent.train_avg": 0.44300893770859523, "timer/agent.train_min": 0.4300117492675781, "timer/agent.train_max": 0.5783994197845459, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47510552406311035, "timer/agent.report_frac": 0.00047503790107854965, "timer/agent.report_avg": 0.23755276203155518, "timer/agent.report_min": 0.23122620582580566, "timer/agent.report_max": 0.2438793182373047, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.765655517578125e-05, "timer/dataset_eval_frac": 2.7652618747537562e-08, "timer/dataset_eval_avg": 2.765655517578125e-05, "timer/dataset_eval_min": 2.765655517578125e-05, "timer/dataset_eval_max": 2.765655517578125e-05, "fps": 2.175662509901719}
{"step": 74336, "time": 34334.01683354378, "episode/length": 170.0, "episode/score": 4.279303410018656, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.17930331592015136}
{"step": 74544, "time": 34429.69285392761, "episode/length": 168.0, "episode/score": 3.230451448610438, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.13045132430215745}
{"step": 74712, "time": 34507.72514295578, "episode/length": 155.0, "episode/score": 2.23041440488214, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.1304143733859746}
{"step": 74888, "time": 34588.96793413162, "episode/length": 216.0, "episode/score": 5.332671926859803, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.2326717679761714}
{"step": 74992, "time": 34637.66969180107, "episode/length": 187.0, "episode/score": 4.3239769608535426, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.22397678124798404}
{"step": 75048, "time": 34664.50120782852, "episode/length": 88.0, "episode/score": 1.189387343269118, "episode/reward_rate": 0.9887640449438202, "episode/intrinsic_return": 0.08938730976478837}
{"step": 75120, "time": 34698.77174091339, "episode/length": 263.0, "episode/score": 3.396517469079299, "episode/reward_rate": 0.9810606060606061, "episode/intrinsic_return": 0.2965173146194502}
{"step": 75560, "time": 34899.57293057442, "episode/length": 270.0, "episode/score": 3.3927778711058636, "episode/reward_rate": 0.996309963099631, "episode/intrinsic_return": 0.29277773081958003}
{"step": 75624, "time": 34930.112718105316, "episode/length": 170.0, "episode/score": 3.250599785990744, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.15059963036674162}
{"step": 75808, "time": 35015.16799044609, "episode/length": 157.0, "episode/score": 4.253427844521866, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.1534278121744137}
{"step": 76200, "time": 35194.615595817566, "episode/length": 185.0, "episode/score": 2.272350433291649, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.17235036777310597}
{"step": 76296, "time": 35239.59191823006, "episode/length": 175.0, "episode/score": 4.25297487308535, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.15297487403995547}
{"step": 76344, "time": 35262.91234564781, "episode/length": 161.0, "episode/score": 3.2324355316673063, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.1324354216781103}
{"step": 76486, "time": 35329.538094997406, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.894319604944299, "train/action_min": 0.0, "train/action_std": 3.884660396311018, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03989480329780943, "train/actor_opt_grad_steps": 73845.0, "train/actor_opt_loss": -15.421790823064468, "train/adv_mag": 0.7329771339341447, "train/adv_max": 0.6623630565073755, "train/adv_mean": 0.0020549514320178045, "train/adv_min": -0.6081075079187199, "train/adv_std": 0.051635369598106655, "train/cont_avg": 0.9942943431712963, "train/cont_loss_mean": 2.5429418755870166e-05, "train/cont_loss_std": 0.0007395022348691045, "train/cont_neg_acc": 0.9989068930347761, "train/cont_neg_loss": 0.0026132195923985867, "train/cont_pos_acc": 0.9999999837191017, "train/cont_pos_loss": 4.965754974427404e-06, "train/cont_pred": 0.9942982814930104, "train/cont_rate": 0.9942943431712963, "train/dyn_loss_mean": 2.9631329388530165, "train/dyn_loss_std": 7.7601689011962325, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1053703471466347, "train/extr_critic_critic_opt_grad_steps": 73845.0, "train/extr_critic_critic_opt_loss": 14788.472131799768, "train/extr_critic_mag": 12.621576212070606, "train/extr_critic_max": 12.621576212070606, "train/extr_critic_mean": 2.387503926400785, "train/extr_critic_min": -0.6745121992296643, "train/extr_critic_std": 2.49699516484031, "train/extr_return_normed_mag": 1.7173007169255503, "train/extr_return_normed_max": 1.7173007169255503, "train/extr_return_normed_mean": 0.3442704710695479, "train/extr_return_normed_min": -0.1121738368852271, "train/extr_return_normed_std": 0.33220885942379635, "train/extr_return_rate": 0.7156654272090506, "train/extr_return_raw_mag": 12.906233734554714, "train/extr_return_raw_max": 12.906233734554714, "train/extr_return_raw_mean": 2.4029943727784686, "train/extr_return_raw_min": -1.0890332617693477, "train/extr_return_raw_std": 2.5431561961218163, "train/extr_reward_mag": 1.0331072939766779, "train/extr_reward_max": 1.0331072939766779, "train/extr_reward_mean": 0.031097844221491228, "train/extr_reward_min": -0.6769474231534534, "train/extr_reward_std": 0.1736357435239134, "train/image_loss_mean": 1.708591428619844, "train/image_loss_std": 5.112843526734246, "train/model_loss_mean": 3.556010397496047, "train/model_loss_std": 8.851401724197247, "train/model_opt_grad_norm": 35.35513636800978, "train/model_opt_grad_steps": 73783.48611111111, "train/model_opt_loss": 4381.364006890191, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1244.212962962963, "train/policy_entropy_mag": 2.560978063830623, "train/policy_entropy_max": 2.560978063830623, "train/policy_entropy_mean": 0.5481356201624429, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.64953010391306, "train/policy_logprob_mag": 7.4383838684470565, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5494267010578403, "train/policy_logprob_min": -7.4383838684470565, "train/policy_logprob_std": 1.1279776270190875, "train/policy_randomness_mag": 0.9039128701444026, "train/policy_randomness_max": 0.9039128701444026, "train/policy_randomness_mean": 0.19346782071860852, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.22925562335661165, "train/post_ent_mag": 42.345553910290754, "train/post_ent_max": 42.345553910290754, "train/post_ent_mean": 21.54545641828466, "train/post_ent_min": 11.735608012587935, "train/post_ent_std": 3.8728636138968997, "train/prior_ent_mag": 74.69281871230514, "train/prior_ent_max": 74.69281871230514, "train/prior_ent_mean": 24.52399115209226, "train/prior_ent_min": 12.986681112536678, "train/prior_ent_std": 8.916283797334742, "train/rep_loss_mean": 2.9631329388530165, "train/rep_loss_std": 7.7601689011962325, "train/reward_avg": 0.017225966992555186, "train/reward_loss_mean": 0.06951378134113771, "train/reward_loss_std": 0.15318185708451051, "train/reward_max_data": 1.0132870685171198, "train/reward_max_pred": 1.0143987878605172, "train/reward_neg_acc": 0.9994552325871255, "train/reward_neg_loss": 0.05053446205608823, "train/reward_pos_acc": 0.9131026560509646, "train/reward_pos_loss": 0.7159629320656812, "train/reward_pred": 0.017107717476190172, "train/reward_rate": 0.02850567853009259, "train_stats/sum_log_reward": 3.2538460676486674, "train_stats/max_log_achievement_collect_drink": 2.1538461538461537, "train_stats/max_log_achievement_collect_sapling": 2.4615384615384617, "train_stats/max_log_achievement_collect_wood": 1.3846153846153846, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.9230769230769231, "train_stats/max_log_achievement_place_table": 0.38461538461538464, "train_stats/max_log_achievement_wake_up": 2.230769230769231, "train_stats/mean_log_entropy": 0.5137161073776392, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 8.60216232467792e-07, "report/cont_loss_std": 1.1583566674744361e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 2.0393186787259765e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 8.219912501772342e-07, "report/cont_pred": 0.9980460405349731, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 2.6413474082946777, "report/dyn_loss_std": 7.211179256439209, "report/image_loss_mean": 1.1620843410491943, "report/image_loss_std": 4.918509006500244, "report/model_loss_mean": 2.807516574859619, "report/model_loss_std": 8.383988380432129, "report/post_ent_mag": 36.09275436401367, "report/post_ent_max": 36.09275436401367, "report/post_ent_mean": 21.818618774414062, "report/post_ent_min": 11.760663032531738, "report/post_ent_std": 3.850641965866089, "report/prior_ent_mag": 74.58309173583984, "report/prior_ent_max": 74.58309173583984, "report/prior_ent_mean": 24.599384307861328, "report/prior_ent_min": 13.135232925415039, "report/prior_ent_std": 8.155477523803711, "report/rep_loss_mean": 2.6413474082946777, "report/rep_loss_std": 7.211179256439209, "report/reward_avg": 0.011104580946266651, "report/reward_loss_mean": 0.060622673481702805, "report/reward_loss_std": 0.1145704984664917, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.003016471862793, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.045929454267024994, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6728402972221375, "report/reward_pred": 0.011225845664739609, "report/reward_rate": 0.0234375, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 6.656109235336771e-06, "eval/cont_loss_std": 0.00018161088519264013, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0019861485343426466, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 8.397757937927963e-07, "eval/cont_pred": 0.9970752000808716, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 25.912960052490234, "eval/dyn_loss_std": 15.698023796081543, "eval/image_loss_mean": 38.63279724121094, "eval/image_loss_std": 43.09451675415039, "eval/model_loss_mean": 54.38882827758789, "eval/model_loss_std": 49.81285095214844, "eval/post_ent_mag": 43.64530563354492, "eval/post_ent_max": 43.64530563354492, "eval/post_ent_mean": 25.30276107788086, "eval/post_ent_min": 16.336986541748047, "eval/post_ent_std": 3.249793529510498, "eval/prior_ent_mag": 74.58309173583984, "eval/prior_ent_max": 74.58309173583984, "eval/prior_ent_mean": 34.75334930419922, "eval/prior_ent_min": 17.256149291992188, "eval/prior_ent_std": 8.71487045288086, "eval/rep_loss_mean": 25.912960052490234, "eval/rep_loss_std": 15.698023796081543, "eval/reward_avg": 0.02548828162252903, "eval/reward_loss_mean": 0.20825551450252533, "eval/reward_loss_std": 1.2836978435516357, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 1.0018322467803955, "eval/reward_neg_acc": 0.9949748516082764, "eval/reward_neg_loss": 0.10290607810020447, "eval/reward_pos_acc": 0.6551724076271057, "eval/reward_pos_loss": 3.8228306770324707, "eval/reward_pred": 0.01851874776184559, "eval/reward_rate": 0.0283203125, "replay/size": 75982.0, "replay/inserts": 2160.0, "replay/samples": 34560.0, "replay/insert_wait_avg": 2.4958893104835792e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.705727480075978e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 15984.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 7.003545761108398e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3384590148926, "timer/env.step_count": 270.0, "timer/env.step_total": 27.082717418670654, "timer/env.step_frac": 0.027073554130210103, "timer/env.step_avg": 0.10030636080989132, "timer/env.step_min": 0.023748159408569336, "timer/env.step_max": 1.710561990737915, "timer/replay._sample_count": 34560.0, "timer/replay._sample_total": 16.25713086128235, "timer/replay._sample_frac": 0.016251630350483527, "timer/replay._sample_avg": 0.0004704030920509939, "timer/replay._sample_min": 0.0003368854522705078, "timer/replay._sample_max": 0.011005878448486328, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 270.0, "timer/agent.policy_total": 4.131720542907715, "timer/agent.policy_frac": 0.0041303225979900104, "timer/agent.policy_avg": 0.01530266867743598, "timer/agent.policy_min": 0.014345169067382812, "timer/agent.policy_max": 0.020427703857421875, "timer/dataset_train_count": 2160.0, "timer/dataset_train_total": 0.3641788959503174, "timer/dataset_train_frac": 0.00036405567802416726, "timer/dataset_train_avg": 0.00016860134071773952, "timer/dataset_train_min": 8.392333984375e-05, "timer/dataset_train_max": 0.0005896091461181641, "timer/agent.train_count": 2160.0, "timer/agent.train_total": 958.6921060085297, "timer/agent.train_frac": 0.9583677378080863, "timer/agent.train_avg": 0.4438389379669119, "timer/agent.train_min": 0.4334695339202881, "timer/agent.train_max": 0.5639915466308594, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4736013412475586, "timer/agent.report_frac": 0.000473441100838959, "timer/agent.report_avg": 0.2368006706237793, "timer/agent.report_min": 0.2303624153137207, "timer/agent.report_max": 0.2432389259338379, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.765655517578125e-05, "timer/dataset_eval_frac": 2.7647197732472177e-08, "timer/dataset_eval_avg": 2.765655517578125e-05, "timer/dataset_eval_min": 2.765655517578125e-05, "timer/dataset_eval_max": 2.765655517578125e-05, "fps": 2.159234118437493}
{"step": 76536, "time": 35352.381412029266, "episode/length": 176.0, "episode/score": 4.272733602257631, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.17273357778640275}
{"step": 76712, "time": 35433.917492866516, "episode/length": 214.0, "episode/score": 4.321617066805629, "episode/reward_rate": 0.9813953488372092, "episode/intrinsic_return": 0.2216169571656792}
{"step": 76744, "time": 35449.88914012909, "episode/length": 49.0, "episode/score": 1.1494511893706658, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.04945119970398082}
{"step": 76864, "time": 35505.80181837082, "episode/length": 154.0, "episode/score": 5.264758398946924, "episode/reward_rate": 0.9612903225806452, "episode/intrinsic_return": 0.164758251006333}
{"step": 77000, "time": 35568.929852962494, "episode/length": 57.0, "episode/score": 1.1586015964676335, "episode/reward_rate": 0.9137931034482759, "episode/intrinsic_return": 0.058601561566320015}
{"step": 77024, "time": 35581.285311460495, "episode/length": 182.0, "episode/score": 3.3100566837333645, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.21005657781870468}
{"step": 77256, "time": 35688.07701444626, "episode/length": 180.0, "episode/score": 3.2733745395548794, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.1733744549151197}
{"step": 77440, "time": 35773.09408688545, "episode/length": 154.0, "episode/score": 3.2591056651826875, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.15910556017024646}
{"step": 77640, "time": 35865.35690665245, "episode/length": 167.0, "episode/score": 4.260571416248695, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.16057126446639813}
{"step": 77944, "time": 36004.88874030113, "episode/length": 153.0, "episode/score": 5.257341485086727, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.15734133248952276}
{"step": 78064, "time": 36060.736921310425, "episode/length": 149.0, "episode/score": 3.2378883425535605, "episode/reward_rate": 0.9733333333333334, "episode/intrinsic_return": 0.13788832831596665}
{"step": 78304, "time": 36171.02516198158, "episode/length": 194.0, "episode/score": 4.326858910522333, "episode/reward_rate": 0.958974358974359, "episode/intrinsic_return": 0.2268587697849398}
{"step": 78400, "time": 36215.92556285858, "episode/length": 174.0, "episode/score": 3.275921096705133, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.17592106977826916}
{"step": 78416, "time": 36224.69125986099, "episode/length": 173.0, "episode/score": 5.284330638766278, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.1843305510706159}
{"step": 78568, "time": 36294.94658064842, "episode/length": 163.0, "episode/score": 3.2496110763304387, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.14961098217372637}
{"step": 78640, "time": 36329.563692092896, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.892006485550492, "train/action_min": 0.0, "train/action_std": 3.836708880133099, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03845884313772398, "train/actor_opt_grad_steps": 76005.0, "train/actor_opt_loss": -15.833542667046155, "train/adv_mag": 0.6965599111108868, "train/adv_max": 0.6252601915901458, "train/adv_mean": 0.0014136489162410726, "train/adv_min": -0.573038405014409, "train/adv_std": 0.050029208711176006, "train/cont_avg": 0.9943079065393519, "train/cont_loss_mean": 7.240160939850874e-06, "train/cont_loss_std": 0.00016357449304262286, "train/cont_neg_acc": 1.0, "train/cont_neg_loss": 0.0005657647461829482, "train/cont_pos_acc": 0.9999999839950491, "train/cont_pos_loss": 3.4919663588031773e-06, "train/cont_pred": 0.9943078002995915, "train/cont_rate": 0.9943079065393519, "train/dyn_loss_mean": 2.9334813786877527, "train/dyn_loss_std": 7.760229097472297, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1169914415589086, "train/extr_critic_critic_opt_grad_steps": 76005.0, "train/extr_critic_critic_opt_loss": 14723.746532298901, "train/extr_critic_mag": 11.970660302374098, "train/extr_critic_max": 11.970660302374098, "train/extr_critic_mean": 2.2053881364840047, "train/extr_critic_min": -0.7092455951152025, "train/extr_critic_std": 2.3961491921433695, "train/extr_return_normed_mag": 1.7129729627459138, "train/extr_return_normed_max": 1.7129729627459138, "train/extr_return_normed_mean": 0.34218870827721226, "train/extr_return_normed_min": -0.11567707727145818, "train/extr_return_normed_std": 0.33292756664256257, "train/extr_return_rate": 0.6866814117464755, "train/extr_return_raw_mag": 12.223302964810971, "train/extr_return_raw_max": 12.223302964810971, "train/extr_return_raw_mean": 2.215770843404311, "train/extr_return_raw_min": -1.1277488748784419, "train/extr_return_raw_std": 2.432494838480596, "train/extr_reward_mag": 1.0283381265622598, "train/extr_reward_max": 1.0283381265622598, "train/extr_reward_mean": 0.030086720043241425, "train/extr_reward_min": -0.6785880343781577, "train/extr_reward_std": 0.17092810429770638, "train/image_loss_mean": 1.6376604871065528, "train/image_loss_std": 4.765869280806294, "train/model_loss_mean": 3.46687368772648, "train/model_loss_std": 8.548863397704231, "train/model_opt_grad_norm": 35.032290072773776, "train/model_opt_grad_steps": 75942.16203703704, "train/model_opt_loss": 6007.175179940683, "train/model_opt_model_opt_grad_overflow": 0.004629629629629629, "train/model_opt_model_opt_grad_scale": 1730.3240740740741, "train/policy_entropy_mag": 2.585098734608403, "train/policy_entropy_max": 2.585098734608403, "train/policy_entropy_mean": 0.5832493063752298, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6731088564351753, "train/policy_logprob_mag": 7.438383877277374, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5823654944973963, "train/policy_logprob_min": -7.438383877277374, "train/policy_logprob_std": 1.1464000151113227, "train/policy_randomness_mag": 0.9124264115536654, "train/policy_randomness_max": 0.9124264115536654, "train/policy_randomness_mean": 0.2058614115058272, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.23757788697602572, "train/post_ent_mag": 42.4738706306175, "train/post_ent_max": 42.4738706306175, "train/post_ent_mean": 21.737077015417594, "train/post_ent_min": 11.55889798976757, "train/post_ent_std": 3.895525051487817, "train/prior_ent_mag": 74.8412919221101, "train/prior_ent_max": 74.8412919221101, "train/prior_ent_mean": 24.67808089432893, "train/prior_ent_min": 12.877961600268328, "train/prior_ent_std": 8.909135557987073, "train/rep_loss_mean": 2.9334813786877527, "train/rep_loss_std": 7.760229097472297, "train/reward_avg": 0.01697549429782494, "train/reward_loss_mean": 0.06911713571322185, "train/reward_loss_std": 0.14833418486846817, "train/reward_max_data": 1.0091204008570425, "train/reward_max_pred": 1.0106740836743955, "train/reward_neg_acc": 0.9993484530735899, "train/reward_neg_loss": 0.05053054779354069, "train/reward_pos_acc": 0.9252498381667666, "train/reward_pos_loss": 0.708372747456586, "train/reward_pred": 0.01692726885084994, "train/reward_rate": 0.028225368923611112, "train_stats/sum_log_reward": 3.499999984105428, "train_stats/max_log_achievement_collect_drink": 1.9333333333333333, "train_stats/max_log_achievement_collect_sapling": 2.3333333333333335, "train_stats/max_log_achievement_collect_wood": 2.066666666666667, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.06666666666666667, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 2.0, "train_stats/max_log_achievement_place_table": 0.7333333333333333, "train_stats/max_log_achievement_wake_up": 1.8, "train_stats/mean_log_entropy": 0.46371152500311535, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 9.390962532052072e-07, "report/cont_loss_std": 2.7176085950486595e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 1.0303480848961044e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 9.20770617085509e-07, "report/cont_pred": 0.998045802116394, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 2.511565923690796, "report/dyn_loss_std": 6.940036296844482, "report/image_loss_mean": 1.0681551694869995, "report/image_loss_std": 2.5848705768585205, "report/model_loss_mean": 2.627562999725342, "report/model_loss_std": 6.33945369720459, "report/post_ent_mag": 40.79039001464844, "report/post_ent_max": 40.79039001464844, "report/post_ent_mean": 21.081539154052734, "report/post_ent_min": 10.260828018188477, "report/post_ent_std": 4.10646390914917, "report/prior_ent_mag": 74.3326644897461, "report/prior_ent_max": 74.3326644897461, "report/prior_ent_mean": 23.74106788635254, "report/prior_ent_min": 10.582024574279785, "report/prior_ent_std": 8.372417449951172, "report/rep_loss_mean": 2.511565923690796, "report/rep_loss_std": 6.940036296844482, "report/reward_avg": 0.021138755604624748, "report/reward_loss_mean": 0.052467230707407, "report/reward_loss_std": 0.10193421691656113, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0042195320129395, "report/reward_neg_acc": 0.9980040192604065, "report/reward_neg_loss": 0.038780808448791504, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6758214235305786, "report/reward_pred": 0.021505605429410934, "report/reward_rate": 0.021484375, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.00510568730533123, "eval/cont_loss_std": 0.14074772596359253, "eval/cont_neg_acc": 0.6000000238418579, "eval/cont_neg_loss": 1.0451546907424927, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.40484382629802e-06, "eval/cont_pred": 0.9966129064559937, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 23.602291107177734, "eval/dyn_loss_std": 13.89776611328125, "eval/image_loss_mean": 36.032798767089844, "eval/image_loss_std": 40.27855682373047, "eval/model_loss_mean": 50.33189010620117, "eval/model_loss_std": 45.700557708740234, "eval/post_ent_mag": 44.043235778808594, "eval/post_ent_max": 44.043235778808594, "eval/post_ent_mean": 26.035350799560547, "eval/post_ent_min": 16.299564361572266, "eval/post_ent_std": 3.5976665019989014, "eval/prior_ent_mag": 74.3326644897461, "eval/prior_ent_max": 74.3326644897461, "eval/prior_ent_mean": 33.43234634399414, "eval/prior_ent_min": 17.759254455566406, "eval/prior_ent_std": 9.054588317871094, "eval/rep_loss_mean": 23.602291107177734, "eval/rep_loss_std": 13.89776611328125, "eval/reward_avg": 0.007031249813735485, "eval/reward_loss_mean": 0.13260993361473083, "eval/reward_loss_std": 0.8915837407112122, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0012404918670654, "eval/reward_neg_acc": 0.9960435032844543, "eval/reward_neg_loss": 0.09268373996019363, "eval/reward_pos_acc": 0.692307710647583, "eval/reward_pos_loss": 3.2376387119293213, "eval/reward_pred": 0.006673309952020645, "eval/reward_rate": 0.0126953125, "replay/size": 78136.0, "replay/inserts": 2154.0, "replay/samples": 34464.0, "replay/insert_wait_avg": 2.4566854053663786e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.71505199545716e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 15984.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 8.344650268554688e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0145709514618, "timer/env.step_count": 269.0, "timer/env.step_total": 29.50092339515686, "timer/env.step_frac": 0.029500493544897317, "timer/env.step_avg": 0.10966886020504409, "timer/env.step_min": 0.023983001708984375, "timer/env.step_max": 1.694807767868042, "timer/replay._sample_count": 34464.0, "timer/replay._sample_total": 16.143143892288208, "timer/replay._sample_frac": 0.016142908674749455, "timer/replay._sample_avg": 0.00046840598573259654, "timer/replay._sample_min": 0.0003440380096435547, "timer/replay._sample_max": 0.01813340187072754, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 269.0, "timer/agent.policy_total": 4.112006187438965, "timer/agent.policy_frac": 0.004111946272469415, "timer/agent.policy_avg": 0.015286268354791691, "timer/agent.policy_min": 0.014391660690307617, "timer/agent.policy_max": 0.02632308006286621, "timer/dataset_train_count": 2154.0, "timer/dataset_train_total": 0.36795663833618164, "timer/dataset_train_frac": 0.0003679512769359851, "timer/dataset_train_avg": 0.00017082480888402118, "timer/dataset_train_min": 8.678436279296875e-05, "timer/dataset_train_max": 0.0005586147308349609, "timer/agent.train_count": 2154.0, "timer/agent.train_total": 956.1664807796478, "timer/agent.train_frac": 0.9561525487272703, "timer/agent.train_avg": 0.4439027301669674, "timer/agent.train_min": 0.4343247413635254, "timer/agent.train_max": 0.5677192211151123, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4754636287689209, "timer/agent.report_frac": 0.00047545670091240973, "timer/agent.report_avg": 0.23773181438446045, "timer/agent.report_min": 0.23137617111206055, "timer/agent.report_max": 0.24408745765686035, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9802322387695312e-05, "timer/dataset_eval_frac": 2.980188814582967e-08, "timer/dataset_eval_avg": 2.9802322387695312e-05, "timer/dataset_eval_min": 2.9802322387695312e-05, "timer/dataset_eval_max": 2.9802322387695312e-05, "fps": 2.1539406081344574}
{"step": 78832, "time": 36417.438749074936, "episode/length": 148.0, "episode/score": 4.248061998679987, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.14806186005262134}
{"step": 79288, "time": 36626.80996441841, "episode/length": 230.0, "episode/score": 5.313036874889349, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.2130366712731302}
{"step": 79496, "time": 36723.392763376236, "episode/length": 148.0, "episode/score": 1.2622210478702982, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.1622209541792472}
{"step": 79504, "time": 36728.70728969574, "episode/length": 179.0, "episode/score": 3.2808553484146614, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.18085525425794913}
{"step": 79552, "time": 36752.0930223465, "episode/length": 200.0, "episode/score": 4.315221059100622, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.21522107670261903}
{"step": 79936, "time": 36928.80462265015, "episode/length": 170.0, "episode/score": 2.2799356187315425, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.1799354685790604}
{"step": 79960, "time": 36941.29540872574, "episode/length": 192.0, "episode/score": 6.294776481192002, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.1947764863084558}
{"step": 80016, "time": 36968.35396385193, "episode/length": 201.0, "episode/score": 6.319548562315504, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.21954835325686872}
{"step": 80080, "time": 37018.05819153786, "eval_episode/length": 152.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9673202614379085}
{"step": 80080, "time": 37019.787558317184, "eval_episode/length": 155.0, "eval_episode/score": 3.0999999791383743, "eval_episode/reward_rate": 0.9935897435897436}
{"step": 80080, "time": 37021.42398619652, "eval_episode/length": 159.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.96875}
{"step": 80080, "time": 37023.406042099, "eval_episode/length": 168.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9940828402366864}
{"step": 80080, "time": 37025.5628554821, "eval_episode/length": 179.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 80080, "time": 37027.32902121544, "eval_episode/length": 185.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9731182795698925}
{"step": 80080, "time": 37029.743413448334, "eval_episode/length": 206.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9951690821256038}
{"step": 80080, "time": 37031.9089744091, "eval_episode/length": 221.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9774774774774775}
{"step": 80400, "time": 37177.21505403519, "episode/length": 138.0, "episode/score": 3.241324785690722, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.1413246513707236}
{"step": 80731, "time": 37329.93649148941, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.039416445499402, "train/action_min": 0.0, "train/action_std": 3.9550053651253, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04189563664701282, "train/actor_opt_grad_steps": 78130.0, "train/actor_opt_loss": -14.237246668581188, "train/adv_mag": 0.7255158624010223, "train/adv_max": 0.6585450872565001, "train/adv_mean": 0.0024733209815271796, "train/adv_min": -0.5786677941180872, "train/adv_std": 0.05467581679447416, "train/cont_avg": 0.9943555622009569, "train/cont_loss_mean": 1.939759744268007e-05, "train/cont_loss_std": 0.0005491780476460556, "train/cont_neg_acc": 0.9980063797754534, "train/cont_neg_loss": 0.002759384993098364, "train/cont_pos_acc": 0.999999982603429, "train/cont_pos_loss": 6.0379493951429825e-06, "train/cont_pred": 0.9943583755972283, "train/cont_rate": 0.9943555622009569, "train/dyn_loss_mean": 2.8964848301627417, "train/dyn_loss_std": 7.704548206055564, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1171343115528234, "train/extr_critic_critic_opt_grad_steps": 78130.0, "train/extr_critic_critic_opt_loss": 14873.830764989534, "train/extr_critic_mag": 10.86254810716547, "train/extr_critic_max": 10.86254810716547, "train/extr_critic_mean": 2.0865964444630456, "train/extr_critic_min": -0.6638618519431666, "train/extr_critic_std": 2.190901669588956, "train/extr_return_normed_mag": 1.7307420432852787, "train/extr_return_normed_max": 1.7307420432852787, "train/extr_return_normed_mean": 0.353184038871213, "train/extr_return_normed_min": -0.11504406460592051, "train/extr_return_normed_std": 0.33946336413684647, "train/extr_return_rate": 0.6761005736138832, "train/extr_return_raw_mag": 11.16092421107315, "train/extr_return_raw_max": 11.16092421107315, "train/extr_return_raw_mean": 2.1027717607443415, "train/extr_return_raw_min": -0.9767736413262107, "train/extr_return_raw_std": 2.2325686763918573, "train/extr_reward_mag": 1.0247030497738048, "train/extr_reward_max": 1.0247030497738048, "train/extr_reward_mean": 0.03003701433521566, "train/extr_reward_min": -0.6808646483854814, "train/extr_reward_std": 0.1714973821879574, "train/image_loss_mean": 1.5890215030697543, "train/image_loss_std": 4.724780757461438, "train/model_loss_mean": 3.3960712925669108, "train/model_loss_std": 8.474313954987595, "train/model_opt_grad_norm": 35.85409664081044, "train/model_opt_grad_steps": 78065.17224880382, "train/model_opt_loss": 6326.260216525867, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1860.047846889952, "train/policy_entropy_mag": 2.5700578655352433, "train/policy_entropy_max": 2.5700578655352433, "train/policy_entropy_mean": 0.5642563068980806, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.659849892677873, "train/policy_logprob_mag": 7.438383875851426, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5650632659499155, "train/policy_logprob_min": -7.438383875851426, "train/policy_logprob_std": 1.1378746446239891, "train/policy_randomness_mag": 0.9071176434247687, "train/policy_randomness_max": 0.9071176434247687, "train/policy_randomness_mean": 0.19915771569931906, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.23289805693489513, "train/post_ent_mag": 42.65838731647108, "train/post_ent_max": 42.65838731647108, "train/post_ent_mean": 21.893763355090858, "train/post_ent_min": 11.719133440957686, "train/post_ent_std": 3.9240218440881756, "train/prior_ent_mag": 74.87154220508046, "train/prior_ent_max": 74.87154220508046, "train/prior_ent_mean": 24.78727201069371, "train/prior_ent_min": 12.910383283806759, "train/prior_ent_std": 8.87077822069232, "train/rep_loss_mean": 2.8964848301627417, "train/rep_loss_std": 7.704548206055564, "train/reward_avg": 0.016420772645631403, "train/reward_loss_mean": 0.06913949319263965, "train/reward_loss_std": 0.15029165277070405, "train/reward_max_data": 1.0079485948005933, "train/reward_max_pred": 1.0086082282819246, "train/reward_neg_acc": 0.9993989014169246, "train/reward_neg_loss": 0.05066796538362092, "train/reward_pos_acc": 0.9173321541416588, "train/reward_pos_loss": 0.7161731993752803, "train/reward_pred": 0.016285088415698784, "train/reward_rate": 0.027726898923444977, "train_stats/sum_log_reward": 3.877777748637729, "train_stats/max_log_achievement_collect_drink": 4.222222222222222, "train_stats/max_log_achievement_collect_sapling": 2.4444444444444446, "train_stats/max_log_achievement_collect_wood": 1.7777777777777777, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.1111111111111111, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.1111111111111111, "train_stats/max_log_achievement_place_plant": 2.2222222222222223, "train_stats/max_log_achievement_place_table": 0.5555555555555556, "train_stats/max_log_achievement_wake_up": 2.0, "train_stats/mean_log_entropy": 0.47233326236406964, "eval_stats/sum_log_reward": 3.7249999195337296, "eval_stats/max_log_achievement_collect_drink": 1.875, "eval_stats/max_log_achievement_collect_sapling": 2.625, "eval_stats/max_log_achievement_collect_wood": 1.75, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.25, "eval_stats/max_log_achievement_place_table": 0.375, "eval_stats/max_log_achievement_wake_up": 1.875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 6.927525646460708e-07, "report/cont_loss_std": 1.4154587688608444e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 2.179803414037451e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 6.307390094661969e-07, "report/cont_pred": 0.9970697164535522, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 3.776564598083496, "report/dyn_loss_std": 8.885692596435547, "report/image_loss_mean": 2.753906726837158, "report/image_loss_std": 10.359540939331055, "report/model_loss_mean": 5.088492393493652, "report/model_loss_std": 14.630045890808105, "report/post_ent_mag": 44.30615234375, "report/post_ent_max": 44.30615234375, "report/post_ent_mean": 21.240936279296875, "report/post_ent_min": 10.197992324829102, "report/post_ent_std": 4.307430267333984, "report/prior_ent_mag": 75.25099182128906, "report/prior_ent_max": 75.25099182128906, "report/prior_ent_mean": 24.595489501953125, "report/prior_ent_min": 12.61922550201416, "report/prior_ent_std": 9.27768611907959, "report/rep_loss_mean": 3.776564598083496, "report/rep_loss_std": 8.885692596435547, "report/reward_avg": 0.016413960605859756, "report/reward_loss_mean": 0.06864634156227112, "report/reward_loss_std": 0.4774761497974396, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.001814365386963, "report/reward_neg_acc": 0.9990040063858032, "report/reward_neg_loss": 0.05540918558835983, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7331517338752747, "report/reward_pred": 0.01612755097448826, "report/reward_rate": 0.01953125, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 6.190080966916867e-06, "eval/cont_loss_std": 0.00017265228962060064, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0011459621600806713, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 5.974798682473192e-07, "eval/cont_pred": 0.9951221942901611, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 25.02743148803711, "eval/dyn_loss_std": 14.373635292053223, "eval/image_loss_mean": 34.420318603515625, "eval/image_loss_std": 37.45146942138672, "eval/model_loss_mean": 49.557952880859375, "eval/model_loss_std": 43.135284423828125, "eval/post_ent_mag": 44.30615234375, "eval/post_ent_max": 44.30615234375, "eval/post_ent_mean": 26.325641632080078, "eval/post_ent_min": 18.191713333129883, "eval/post_ent_std": 3.4919350147247314, "eval/prior_ent_mag": 75.25099182128906, "eval/prior_ent_max": 75.25099182128906, "eval/prior_ent_mean": 35.638458251953125, "eval/prior_ent_min": 19.98838996887207, "eval/prior_ent_std": 8.81934928894043, "eval/rep_loss_mean": 25.02743148803711, "eval/rep_loss_std": 14.373635292053223, "eval/reward_avg": 0.02226562425494194, "eval/reward_loss_mean": 0.12117449194192886, "eval/reward_loss_std": 0.9212075471878052, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0012354850769043, "eval/reward_neg_acc": 0.9949849843978882, "eval/reward_neg_loss": 0.04761926457285881, "eval/reward_pos_acc": 0.8148148059844971, "eval/reward_pos_loss": 2.8372695446014404, "eval/reward_pred": 0.0191185399889946, "eval/reward_rate": 0.0263671875, "replay/size": 80227.0, "replay/inserts": 2091.0, "replay/samples": 33456.0, "replay/insert_wait_avg": 2.483156296352859e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.993108287831347e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 17760.0, "eval_replay/inserts": 1776.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1417511347177867e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.748603820800781e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3551003932953, "timer/env.step_count": 262.0, "timer/env.step_total": 20.39238405227661, "timer/env.step_frac": 0.020385145279170597, "timer/env.step_avg": 0.0778335269170863, "timer/env.step_min": 0.024001598358154297, "timer/env.step_max": 1.683253288269043, "timer/replay._sample_count": 33456.0, "timer/replay._sample_total": 16.313842058181763, "timer/replay._sample_frac": 0.01630805106283547, "timer/replay._sample_avg": 0.0004876208171383836, "timer/replay._sample_min": 0.00036144256591796875, "timer/replay._sample_max": 0.022556543350219727, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 484.0, "timer/agent.policy_total": 7.6326844692230225, "timer/agent.policy_frac": 0.007629975062077646, "timer/agent.policy_avg": 0.015770009233931865, "timer/agent.policy_min": 0.00980997085571289, "timer/agent.policy_max": 0.040482282638549805, "timer/dataset_train_count": 2091.0, "timer/dataset_train_total": 0.36939334869384766, "timer/dataset_train_frac": 0.000369262223533042, "timer/dataset_train_avg": 0.00017665870334473825, "timer/dataset_train_min": 9.250640869140625e-05, "timer/dataset_train_max": 0.000461578369140625, "timer/agent.train_count": 2091.0, "timer/agent.train_total": 932.2811594009399, "timer/agent.train_frac": 0.9319502235100399, "timer/agent.train_avg": 0.4458542130085796, "timer/agent.train_min": 0.43509578704833984, "timer/agent.train_max": 0.5606749057769775, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4774017333984375, "timer/agent.report_frac": 0.000477232268032366, "timer/agent.report_avg": 0.23870086669921875, "timer/agent.report_min": 0.2299795150756836, "timer/agent.report_max": 0.2474222183227539, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7894973754882812e-05, "timer/dataset_eval_frac": 2.788507175493557e-08, "timer/dataset_eval_avg": 2.7894973754882812e-05, "timer/dataset_eval_min": 2.7894973754882812e-05, "timer/dataset_eval_max": 2.7894973754882812e-05, "fps": 2.090230048750453}
{"step": 80816, "time": 37369.06768512726, "episode/length": 157.0, "episode/score": 4.291541779704858, "episode/reward_rate": 0.9620253164556962, "episode/intrinsic_return": 0.19154166273074225}
{"step": 80856, "time": 37388.804490327835, "episode/length": 169.0, "episode/score": 3.252469125367952, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.15246904782952697}
{"step": 81016, "time": 37463.587792634964, "episode/length": 188.0, "episode/score": 4.304283680831759, "episode/reward_rate": 0.9682539682539683, "episode/intrinsic_return": 0.20428356152933702}
{"step": 81072, "time": 37490.89669585228, "episode/length": 279.0, "episode/score": 6.403885205717415, "episode/reward_rate": 0.9785714285714285, "episode/intrinsic_return": 0.3038850779166751}
{"step": 81184, "time": 37543.939735889435, "episode/length": 152.0, "episode/score": 4.232239505434791, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.13223944367064178}
{"step": 81424, "time": 37655.840871572495, "episode/length": 185.0, "episode/score": 5.287879778814386, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.18787963250360917}
{"step": 81512, "time": 37697.85742378235, "episode/length": 186.0, "episode/score": 5.2982953753839865, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.1982952239509359}
{"step": 82264, "time": 38045.455703258514, "episode/length": 180.0, "episode/score": 4.28976796407278, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.18976787489282287}
{"step": 82368, "time": 38094.77532315254, "episode/length": 245.0, "episode/score": 5.351986052675784, "episode/reward_rate": 0.9796747967479674, "episode/intrinsic_return": 0.2519858552586811}
{"step": 82368, "time": 38094.78371310234, "episode/length": 188.0, "episode/score": 5.285387195908243, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.18538708527876224}
{"step": 82504, "time": 38160.743389606476, "episode/length": 185.0, "episode/score": 4.272185659699517, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.17218564741187947}
{"step": 82704, "time": 38253.97867488861, "episode/length": 203.0, "episode/score": 4.2879703750049885, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.187970286712698}
{"step": 82808, "time": 38303.3696436882, "episode/length": 37.0, "episode/score": 1.139866449208057, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.03986640138464281}
{"step": 82862, "time": 38330.311527490616, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.336528079610475, "train/action_min": 0.0, "train/action_std": 4.139894367943348, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04472072995289671, "train/actor_opt_grad_steps": 80240.0, "train/actor_opt_loss": -13.056045825772442, "train/adv_mag": 0.9068001099455525, "train/adv_max": 0.8403032545892286, "train/adv_mean": 0.003595833782606698, "train/adv_min": -0.691602263512186, "train/adv_std": 0.059203482630876866, "train/cont_avg": 0.9940810225938967, "train/cont_loss_mean": 4.8736299252600194e-05, "train/cont_loss_std": 0.0014692980725695332, "train/cont_neg_acc": 0.9994783516221203, "train/cont_neg_loss": 0.0024759383794483517, "train/cont_pos_acc": 0.999990743930351, "train/cont_pos_loss": 2.7989615262692427e-05, "train/cont_pred": 0.9940713176704908, "train/cont_rate": 0.9940810225938967, "train/dyn_loss_mean": 2.962553512322511, "train/dyn_loss_std": 7.796662404503621, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1365546220345117, "train/extr_critic_critic_opt_grad_steps": 80240.0, "train/extr_critic_critic_opt_loss": 15194.55498092723, "train/extr_critic_mag": 15.406875988687148, "train/extr_critic_max": 15.406875988687148, "train/extr_critic_mean": 2.2906813979708534, "train/extr_critic_min": -0.6267184612336852, "train/extr_critic_std": 2.7447454845401604, "train/extr_return_normed_mag": 2.0361134451879583, "train/extr_return_normed_max": 2.0361134451879583, "train/extr_return_normed_mean": 0.3226384417691701, "train/extr_return_normed_min": -0.09373298420312819, "train/extr_return_normed_std": 0.36141710822850887, "train/extr_return_rate": 0.6231031510191904, "train/extr_return_raw_mag": 15.678417863980146, "train/extr_return_raw_max": 15.678417863980146, "train/extr_return_raw_mean": 2.3188029018366283, "train/extr_return_raw_min": -0.9230610725465515, "train/extr_return_raw_std": 2.825669785620461, "train/extr_reward_mag": 1.020310363859078, "train/extr_reward_max": 1.020310363859078, "train/extr_reward_mean": 0.030018651446965937, "train/extr_reward_min": -0.6717085720787586, "train/extr_reward_std": 0.17083568374315897, "train/image_loss_mean": 1.6809747599659952, "train/image_loss_std": 4.8339480178456915, "train/model_loss_mean": 3.5284946244647246, "train/model_loss_std": 8.635103317493565, "train/model_opt_grad_norm": 34.47131929263263, "train/model_opt_grad_steps": 80173.7089201878, "train/model_opt_loss": 5621.934678055311, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1590.3755868544602, "train/policy_entropy_mag": 2.574113218997006, "train/policy_entropy_max": 2.574113218997006, "train/policy_entropy_mean": 0.6229765695025663, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.7049084179837939, "train/policy_logprob_mag": 7.438383854610819, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.6233978628272742, "train/policy_logprob_min": -7.438383854610819, "train/policy_logprob_std": 1.1701460329579636, "train/policy_randomness_mag": 0.9085490048771173, "train/policy_randomness_max": 0.9085490048771173, "train/policy_randomness_mean": 0.2198833921145945, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.24880173788384094, "train/post_ent_mag": 43.328284250178804, "train/post_ent_max": 43.328284250178804, "train/post_ent_mean": 22.151183822345285, "train/post_ent_min": 11.801964527004762, "train/post_ent_std": 3.9697728548811075, "train/prior_ent_mag": 74.96681310089541, "train/prior_ent_max": 74.96681310089541, "train/prior_ent_mean": 25.091154080601367, "train/prior_ent_min": 13.090554846284535, "train/prior_ent_std": 8.934367757448008, "train/rep_loss_mean": 2.962553512322511, "train/rep_loss_std": 7.796662404503621, "train/reward_avg": 0.01694255479843194, "train/reward_loss_mean": 0.06993899823214526, "train/reward_loss_std": 0.1506389297649894, "train/reward_max_data": 1.0092312511703778, "train/reward_max_pred": 1.0096052700365092, "train/reward_neg_acc": 0.9994478939284741, "train/reward_neg_loss": 0.05122090951307839, "train/reward_pos_acc": 0.9226318004545472, "train/reward_pos_loss": 0.7091129836342145, "train/reward_pred": 0.016869848915441354, "train/reward_rate": 0.028462441314553992, "train_stats/sum_log_reward": 4.2538460951585035, "train_stats/max_log_achievement_collect_drink": 2.230769230769231, "train_stats/max_log_achievement_collect_sapling": 2.076923076923077, "train_stats/max_log_achievement_collect_wood": 2.6923076923076925, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.07692307692307693, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.9230769230769231, "train_stats/max_log_achievement_place_table": 1.1538461538461537, "train_stats/max_log_achievement_wake_up": 1.7692307692307692, "train_stats/mean_log_entropy": 0.5208671253461105, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 2.0268644220777787e-06, "report/cont_loss_std": 1.2823349607060663e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 3.4043550840578973e-06, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.0228169432812138e-06, "report/cont_pred": 0.9970682859420776, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 3.904083490371704, "report/dyn_loss_std": 8.786354064941406, "report/image_loss_mean": 1.8425419330596924, "report/image_loss_std": 5.204220771789551, "report/model_loss_mean": 4.252400875091553, "report/model_loss_std": 9.643471717834473, "report/post_ent_mag": 40.928138732910156, "report/post_ent_max": 40.928138732910156, "report/post_ent_mean": 22.711854934692383, "report/post_ent_min": 11.588943481445312, "report/post_ent_std": 4.286409378051758, "report/prior_ent_mag": 74.9898681640625, "report/prior_ent_max": 74.9898681640625, "report/prior_ent_mean": 26.093870162963867, "report/prior_ent_min": 12.988611221313477, "report/prior_ent_std": 9.142282485961914, "report/rep_loss_mean": 3.904083490371704, "report/rep_loss_std": 8.786354064941406, "report/reward_avg": 0.01495698094367981, "report/reward_loss_mean": 0.06740672886371613, "report/reward_loss_std": 0.19034641981124878, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.003025770187378, "report/reward_neg_acc": 0.9990019798278809, "report/reward_neg_loss": 0.0488220639526844, "report/reward_pos_acc": 0.9090909361839294, "report/reward_pos_loss": 0.9138537645339966, "report/reward_pred": 0.013504834845662117, "report/reward_rate": 0.021484375, "eval/cont_avg": 0.9921875, "eval/cont_loss_mean": 0.002967008389532566, "eval/cont_loss_std": 0.09469892829656601, "eval/cont_neg_acc": 0.875, "eval/cont_neg_loss": 0.3795885145664215, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.4842686368865543e-06, "eval/cont_pred": 0.9931201934814453, "eval/cont_rate": 0.9921875, "eval/dyn_loss_mean": 24.62921142578125, "eval/dyn_loss_std": 14.82483196258545, "eval/image_loss_mean": 30.341552734375, "eval/image_loss_std": 33.37311553955078, "eval/model_loss_mean": 45.29449462890625, "eval/model_loss_std": 39.78264617919922, "eval/post_ent_mag": 44.911617279052734, "eval/post_ent_max": 44.911617279052734, "eval/post_ent_mean": 26.44237518310547, "eval/post_ent_min": 17.17278289794922, "eval/post_ent_std": 3.404209852218628, "eval/prior_ent_mag": 74.9898681640625, "eval/prior_ent_max": 74.9898681640625, "eval/prior_ent_mean": 36.504249572753906, "eval/prior_ent_min": 21.09459686279297, "eval/prior_ent_std": 8.81443977355957, "eval/rep_loss_mean": 24.62921142578125, "eval/rep_loss_std": 14.82483196258545, "eval/reward_avg": 0.01523437537252903, "eval/reward_loss_mean": 0.1724470853805542, "eval/reward_loss_std": 1.131716251373291, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 1.0054166316986084, "eval/reward_neg_acc": 0.9930139780044556, "eval/reward_neg_loss": 0.07397138327360153, "eval/reward_pos_acc": 0.5909091234207153, "eval/reward_pos_loss": 4.657567024230957, "eval/reward_pred": 0.011157091706991196, "eval/reward_rate": 0.021484375, "replay/size": 82358.0, "replay/inserts": 2131.0, "replay/samples": 34096.0, "replay/insert_wait_avg": 2.563978684782031e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.876218176402715e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 17760.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 8.344650268554688e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3632843494415, "timer/env.step_count": 266.0, "timer/env.step_total": 26.827510356903076, "timer/env.step_frac": 0.026817767881544757, "timer/env.step_avg": 0.10085530209362059, "timer/env.step_min": 0.02393484115600586, "timer/env.step_max": 3.3526580333709717, "timer/replay._sample_count": 34096.0, "timer/replay._sample_total": 16.82871699333191, "timer/replay._sample_frac": 0.01682260560399915, "timer/replay._sample_avg": 0.0004935686588846759, "timer/replay._sample_min": 0.000347137451171875, "timer/replay._sample_max": 0.010457992553710938, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 266.0, "timer/agent.policy_total": 4.232434272766113, "timer/agent.policy_frac": 0.004230897254009636, "timer/agent.policy_avg": 0.01591140704047411, "timer/agent.policy_min": 0.014806747436523438, "timer/agent.policy_max": 0.026552438735961914, "timer/dataset_train_count": 2131.0, "timer/dataset_train_total": 0.4322507381439209, "timer/dataset_train_frac": 0.0004320937652415174, "timer/dataset_train_avg": 0.0002028393890867766, "timer/dataset_train_min": 9.202957153320312e-05, "timer/dataset_train_max": 0.041402578353881836, "timer/agent.train_count": 2131.0, "timer/agent.train_total": 958.0493183135986, "timer/agent.train_frac": 0.9577014003834011, "timer/agent.train_avg": 0.44957734317860093, "timer/agent.train_min": 0.436018705368042, "timer/agent.train_max": 0.5847516059875488, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47434282302856445, "timer/agent.report_frac": 0.00047417056428359435, "timer/agent.report_avg": 0.23717141151428223, "timer/agent.report_min": 0.2300868034362793, "timer/agent.report_max": 0.24425601959228516, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7894973754882812e-05, "timer/dataset_eval_frac": 2.788484362760628e-08, "timer/dataset_eval_avg": 2.7894973754882812e-05, "timer/dataset_eval_min": 2.7894973754882812e-05, "timer/dataset_eval_max": 2.7894973754882812e-05, "fps": 2.1301985645327983}
{"step": 82872, "time": 38335.14702129364, "episode/length": 169.0, "episode/score": 5.271715778974794, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.17171559679354687}
{"step": 82912, "time": 38355.001806497574, "episode/length": 215.0, "episode/score": 5.311658665912091, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.21165841369247573}
{"step": 82936, "time": 38367.45659017563, "episode/length": 188.0, "episode/score": 3.277188544275077, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.17718843134639428}
{"step": 83584, "time": 38666.92192745209, "episode/length": 151.0, "episode/score": 5.268856752576539, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.16885663193534128}
{"step": 83792, "time": 38764.058795928955, "episode/length": 190.0, "episode/score": 5.301971007054135, "episode/reward_rate": 0.9685863874345549, "episode/intrinsic_return": 0.20197087343262865}
{"step": 83816, "time": 38776.63344478607, "episode/length": 180.0, "episode/score": 5.28883973398797, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.18883976177630757}
{"step": 84160, "time": 38936.50985503197, "episode/length": 42.0, "episode/score": -0.8562192103418056, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.04378075324348174}
{"step": 84248, "time": 38978.33899998665, "episode/length": 171.0, "episode/score": 4.287192802911932, "episode/reward_rate": 0.9651162790697675, "episode/intrinsic_return": 0.18719268593781635}
{"step": 84376, "time": 39038.34020161629, "episode/length": 195.0, "episode/score": 5.29780050373688, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.197800335074362}
{"step": 84648, "time": 39163.805188179016, "episode/length": 213.0, "episode/score": 5.319433644981245, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.21943352108041836}
{"step": 84736, "time": 39205.33498477936, "episode/length": 227.0, "episode/score": 3.32924655662805, "episode/reward_rate": 0.9780701754385965, "episode/intrinsic_return": 0.2292464870204185}
{"step": 85006, "time": 39330.35856485367, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.270243992315274, "train/action_min": 0.0, "train/action_std": 4.129117078870256, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0382598186190301, "train/actor_opt_grad_steps": 82375.0, "train/actor_opt_loss": -15.435603574188166, "train/adv_mag": 0.7247532834516508, "train/adv_max": 0.6477922786062009, "train/adv_mean": 0.0015158625510402744, "train/adv_min": -0.5885437895482946, "train/adv_std": 0.04958819533550294, "train/cont_avg": 0.9945604556074766, "train/cont_loss_mean": 9.427997610896243e-05, "train/cont_loss_std": 0.002938348696390488, "train/cont_neg_acc": 0.9983978641924457, "train/cont_neg_loss": 0.012898328600754553, "train/cont_pos_acc": 0.9999953934522433, "train/cont_pos_loss": 2.6864631403150185e-05, "train/cont_pred": 0.994565499441646, "train/cont_rate": 0.9945604556074766, "train/dyn_loss_mean": 2.952940613309914, "train/dyn_loss_std": 7.754813530734766, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1577672440314961, "train/extr_critic_critic_opt_grad_steps": 82375.0, "train/extr_critic_critic_opt_loss": 15232.62084276431, "train/extr_critic_mag": 15.221204334330336, "train/extr_critic_max": 15.221204334330336, "train/extr_critic_mean": 2.30011226139336, "train/extr_critic_min": -0.6550625267429887, "train/extr_critic_std": 2.9322069955763417, "train/extr_return_normed_mag": 1.7218664650605104, "train/extr_return_normed_max": 1.7218664650605104, "train/extr_return_normed_mean": 0.27942248426865196, "train/extr_return_normed_min": -0.08363651103018044, "train/extr_return_normed_std": 0.3269932338289011, "train/extr_return_rate": 0.5930466621278603, "train/extr_return_raw_mag": 15.406328000754954, "train/extr_return_raw_max": 15.406328000754954, "train/extr_return_raw_mean": 2.314095643636222, "train/extr_return_raw_min": -0.9803902647484128, "train/extr_return_raw_std": 2.9795547651353282, "train/extr_reward_mag": 1.0269015069319822, "train/extr_reward_max": 1.0269015069319822, "train/extr_reward_mean": 0.029655853556207964, "train/extr_reward_min": -0.6570224355314379, "train/extr_reward_std": 0.16951606523628546, "train/image_loss_mean": 1.6148969976701468, "train/image_loss_std": 4.827623933275169, "train/model_loss_mean": 3.4562549223409635, "train/model_loss_std": 8.600712096579722, "train/model_opt_grad_norm": 33.62102652267671, "train/model_opt_grad_steps": 82307.35514018692, "train/model_opt_loss": 5845.265707140771, "train/model_opt_model_opt_grad_overflow": 0.004672897196261682, "train/model_opt_model_opt_grad_scale": 1688.0841121495328, "train/policy_entropy_mag": 2.6425511747877173, "train/policy_entropy_max": 2.6425511747877173, "train/policy_entropy_mean": 0.6899471986238087, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.7688465240959809, "train/policy_logprob_mag": 7.438383915714014, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.689127136613721, "train/policy_logprob_min": -7.438383915714014, "train/policy_logprob_std": 1.2079798072297996, "train/policy_randomness_mag": 0.9327045977115631, "train/policy_randomness_max": 0.9327045977115631, "train/policy_randomness_mean": 0.24352108582715007, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.2713690820698426, "train/post_ent_mag": 42.56889359304838, "train/post_ent_max": 42.56889359304838, "train/post_ent_mean": 22.304965063790295, "train/post_ent_min": 11.950214568699632, "train/post_ent_std": 4.028016206260039, "train/prior_ent_mag": 74.9944451234051, "train/prior_ent_max": 74.9944451234051, "train/prior_ent_mean": 25.217804810711158, "train/prior_ent_min": 13.177724009362336, "train/prior_ent_std": 8.908487065930233, "train/rep_loss_mean": 2.952940613309914, "train/rep_loss_std": 7.754813530734766, "train/reward_avg": 0.017728718108645528, "train/reward_loss_mean": 0.06949925295590798, "train/reward_loss_std": 0.15416416543248657, "train/reward_max_data": 1.013866854048221, "train/reward_max_pred": 1.015183014847408, "train/reward_neg_acc": 0.9993277219968422, "train/reward_neg_loss": 0.05038730519884658, "train/reward_pos_acc": 0.9067051391178202, "train/reward_pos_loss": 0.7173059774893467, "train/reward_pred": 0.01767638404679563, "train/reward_rate": 0.028694509345794393, "train_stats/sum_log_reward": 4.099999915469777, "train_stats/max_log_achievement_collect_drink": 2.090909090909091, "train_stats/max_log_achievement_collect_sapling": 1.6363636363636365, "train_stats/max_log_achievement_collect_wood": 2.727272727272727, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.09090909090909091, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.5454545454545454, "train_stats/max_log_achievement_place_table": 1.0909090909090908, "train_stats/max_log_achievement_wake_up": 1.8181818181818181, "train_stats/mean_log_entropy": 0.6677409654313867, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 4.479267772694584e-06, "report/cont_loss_std": 0.00012205931852804497, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0013449571561068296, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 5.405470346886432e-07, "report/cont_pred": 0.9970738291740417, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 2.68192720413208, "report/dyn_loss_std": 7.78192138671875, "report/image_loss_mean": 1.1279237270355225, "report/image_loss_std": 3.5784995555877686, "report/model_loss_mean": 2.791688919067383, "report/model_loss_std": 7.750269412994385, "report/post_ent_mag": 38.79857635498047, "report/post_ent_max": 38.79857635498047, "report/post_ent_mean": 22.27190399169922, "report/post_ent_min": 12.996369361877441, "report/post_ent_std": 4.057287216186523, "report/prior_ent_mag": 74.51783752441406, "report/prior_ent_max": 74.51783752441406, "report/prior_ent_mean": 24.731380462646484, "report/prior_ent_min": 14.598379135131836, "report/prior_ent_std": 8.383586883544922, "report/rep_loss_mean": 2.68192720413208, "report/rep_loss_std": 7.78192138671875, "report/reward_avg": 0.013460558839142323, "report/reward_loss_mean": 0.054603949189186096, "report/reward_loss_std": 0.12230615317821503, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0024333000183105, "report/reward_neg_acc": 1.0000001192092896, "report/reward_neg_loss": 0.04173882305622101, "report/reward_pos_acc": 0.944444477558136, "report/reward_pos_loss": 0.7736217975616455, "report/reward_pred": 0.012704052031040192, "report/reward_rate": 0.017578125, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 1.7199396097566932e-05, "eval/cont_loss_std": 0.0003954718995373696, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.002547549782320857, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.285739356011618e-06, "eval/cont_pred": 0.9941532611846924, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 24.109601974487305, "eval/dyn_loss_std": 13.617761611938477, "eval/image_loss_mean": 31.905168533325195, "eval/image_loss_std": 30.94152069091797, "eval/model_loss_mean": 46.55954360961914, "eval/model_loss_std": 36.58722686767578, "eval/post_ent_mag": 41.79916763305664, "eval/post_ent_max": 41.79916763305664, "eval/post_ent_mean": 26.8900089263916, "eval/post_ent_min": 17.39742660522461, "eval/post_ent_std": 3.4739291667938232, "eval/prior_ent_mag": 74.51783752441406, "eval/prior_ent_max": 74.51783752441406, "eval/prior_ent_mean": 35.89698028564453, "eval/prior_ent_min": 17.562496185302734, "eval/prior_ent_std": 8.504738807678223, "eval/rep_loss_mean": 24.109601974487305, "eval/rep_loss_std": 13.617761611938477, "eval/reward_avg": 0.01865234412252903, "eval/reward_loss_mean": 0.18859893083572388, "eval/reward_loss_std": 1.123008370399475, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0024290084838867, "eval/reward_neg_acc": 0.9970000386238098, "eval/reward_neg_loss": 0.1027950793504715, "eval/reward_pos_acc": 0.5833333730697632, "eval/reward_pos_loss": 3.7637593746185303, "eval/reward_pred": 0.014084451831877232, "eval/reward_rate": 0.0234375, "replay/size": 84502.0, "replay/inserts": 2144.0, "replay/samples": 34304.0, "replay/insert_wait_avg": 2.5281932816576604e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.85966751290791e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 17760.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 1.1622905731201172e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0363252162933, "timer/env.step_count": 268.0, "timer/env.step_total": 23.845881700515747, "timer/env.step_frac": 0.023845015525169277, "timer/env.step_avg": 0.08897717052431249, "timer/env.step_min": 0.023615121841430664, "timer/env.step_max": 1.6512925624847412, "timer/replay._sample_count": 34304.0, "timer/replay._sample_total": 16.96974492073059, "timer/replay._sample_frac": 0.01696912851346703, "timer/replay._sample_avg": 0.0004946870604224169, "timer/replay._sample_min": 0.0003402233123779297, "timer/replay._sample_max": 0.026282072067260742, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 268.0, "timer/agent.policy_total": 4.2786946296691895, "timer/agent.policy_frac": 0.0042785392108069375, "timer/agent.policy_avg": 0.015965278468914886, "timer/agent.policy_min": 0.014603137969970703, "timer/agent.policy_max": 0.04177379608154297, "timer/dataset_train_count": 2144.0, "timer/dataset_train_total": 0.3907902240753174, "timer/dataset_train_frac": 0.00039077602905153983, "timer/dataset_train_avg": 0.00018227155973662192, "timer/dataset_train_min": 8.821487426757812e-05, "timer/dataset_train_max": 0.0009329319000244141, "timer/agent.train_count": 2144.0, "timer/agent.train_total": 960.8433923721313, "timer/agent.train_frac": 0.9608084907958867, "timer/agent.train_avg": 0.44815456733774783, "timer/agent.train_min": 0.4365231990814209, "timer/agent.train_max": 0.5814073085784912, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4782528877258301, "timer/agent.report_frac": 0.0004782355157172825, "timer/agent.report_avg": 0.23912644386291504, "timer/agent.report_min": 0.23144960403442383, "timer/agent.report_max": 0.24680328369140625, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0040740966796875e-05, "timer/dataset_eval_frac": 3.0039649770021605e-08, "timer/dataset_eval_avg": 3.0040740966796875e-05, "timer/dataset_eval_min": 3.0040740966796875e-05, "timer/dataset_eval_max": 3.0040740966796875e-05, "fps": 2.143892741061049}
{"step": 85344, "time": 39485.60381293297, "episode/length": 329.0, "episode/score": 3.4488510603709983, "episode/reward_rate": 0.9878787878787879, "episode/intrinsic_return": 0.3488509901667385}
{"step": 85408, "time": 39516.53884243965, "episode/length": 144.0, "episode/score": 4.262996133618117, "episode/reward_rate": 0.9586206896551724, "episode/intrinsic_return": 0.16299592386098993}
{"step": 85472, "time": 39547.444529533386, "episode/length": 163.0, "episode/score": 3.2837608882798577, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.18376071926809345}
{"step": 85576, "time": 39596.89206123352, "episode/length": 222.0, "episode/score": 5.332548952339721, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.2325487642067401}
{"step": 85696, "time": 39653.69327068329, "episode/length": 164.0, "episode/score": 5.279385426373437, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.17938537296208779}
{"step": 85736, "time": 39673.64222288132, "episode/length": 268.0, "episode/score": 4.369653054739729, "episode/reward_rate": 0.9962825278810409, "episode/intrinsic_return": 0.26965297068204563}
{"step": 86040, "time": 39814.867752075195, "episode/length": 173.0, "episode/score": 5.279682200821071, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.1796822112926293}
{"step": 86360, "time": 39962.973563194275, "episode/length": 202.0, "episode/score": 4.296384288131776, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.19638415973440715}
{"step": 86664, "time": 40103.44346952438, "episode/length": 148.0, "episode/score": 3.27072767240702, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.17072757651862958}
{"step": 86664, "time": 40103.45117521286, "episode/length": 135.0, "episode/score": 2.2345130305313887, "episode/reward_rate": 0.9926470588235294, "episode/intrinsic_return": 0.13451296419793835}
{"step": 86712, "time": 40128.62049078941, "episode/length": 170.0, "episode/score": 3.2676680626457255, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.16766796661181615}
{"step": 86776, "time": 40159.38586807251, "episode/length": 170.0, "episode/score": 4.282974053344333, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.18297391430951393}
{"step": 87104, "time": 40309.98728466034, "episode/length": 170.0, "episode/score": 4.259662437102179, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.15966228415572914}
{"step": 87145, "time": 40330.58797311783, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.135188592928592, "train/action_min": 0.0, "train/action_std": 4.0882950297025875, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04653760392184012, "train/actor_opt_grad_steps": 84515.0, "train/actor_opt_loss": -11.657898523642956, "train/adv_mag": 0.9437355180488569, "train/adv_max": 0.888737265333951, "train/adv_mean": 0.004055629877083975, "train/adv_min": -0.6764701108369872, "train/adv_std": 0.06012368379770038, "train/cont_avg": 0.9941223714953271, "train/cont_loss_mean": 1.1577767136548883e-05, "train/cont_loss_std": 0.00034990195069031706, "train/cont_neg_acc": 1.0, "train/cont_neg_loss": 0.0005816926669875645, "train/cont_pos_acc": 0.999995379247398, "train/cont_pos_loss": 7.750212193484001e-06, "train/cont_pred": 0.9941199346680507, "train/cont_rate": 0.9941223714953271, "train/dyn_loss_mean": 2.9562224428230355, "train/dyn_loss_std": 7.74044643607095, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1391161162162495, "train/extr_critic_critic_opt_grad_steps": 84515.0, "train/extr_critic_critic_opt_loss": 15666.229793370327, "train/extr_critic_mag": 15.700381974193537, "train/extr_critic_max": 15.700381974193537, "train/extr_critic_mean": 2.220113581586107, "train/extr_critic_min": -0.6399327082054638, "train/extr_critic_std": 2.7126248417613663, "train/extr_return_normed_mag": 2.0182506391935258, "train/extr_return_normed_max": 2.0182506391935258, "train/extr_return_normed_mean": 0.3051952058884585, "train/extr_return_normed_min": -0.09456056286798459, "train/extr_return_normed_std": 0.3469085950996274, "train/extr_return_rate": 0.6012832533533328, "train/extr_return_raw_mag": 16.04982667548634, "train/extr_return_raw_max": 16.04982667548634, "train/extr_return_raw_mean": 2.252865686594883, "train/extr_return_raw_min": -0.9648219235589571, "train/extr_return_raw_std": 2.796958670437893, "train/extr_reward_mag": 1.0211366426164858, "train/extr_reward_max": 1.0211366426164858, "train/extr_reward_mean": 0.030031472344438884, "train/extr_reward_min": -0.6604863210259196, "train/extr_reward_std": 0.17083672938920627, "train/image_loss_mean": 1.608183573339587, "train/image_loss_std": 4.730463041323367, "train/model_loss_mean": 3.4525879019888763, "train/model_loss_std": 8.498028476661611, "train/model_opt_grad_norm": 35.03940008288232, "train/model_opt_grad_steps": 84445.95327102803, "train/model_opt_loss": 5661.376281167859, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1641.3551401869158, "train/policy_entropy_mag": 2.638026250857059, "train/policy_entropy_max": 2.638026250857059, "train/policy_entropy_mean": 0.6249805691643296, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.7244365105283594, "train/policy_logprob_mag": 7.438383926855069, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.6255393692544687, "train/policy_logprob_min": -7.438383926855069, "train/policy_logprob_std": 1.179812417130604, "train/policy_randomness_mag": 0.9311075021173353, "train/policy_randomness_max": 0.9311075021173353, "train/policy_randomness_mean": 0.2205907157926916, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.25569429596729365, "train/post_ent_mag": 43.18720551963165, "train/post_ent_max": 43.18720551963165, "train/post_ent_mean": 22.448875195512148, "train/post_ent_min": 11.966801059580295, "train/post_ent_std": 4.0175711373302425, "train/prior_ent_mag": 75.04501128865179, "train/prior_ent_max": 75.04501128865179, "train/prior_ent_mean": 25.37844731874555, "train/prior_ent_min": 13.074927784572138, "train/prior_ent_std": 8.92751320277419, "train/rep_loss_mean": 2.9562224428230355, "train/rep_loss_std": 7.74044643607095, "train/reward_avg": 0.018155435520163344, "train/reward_loss_mean": 0.07065928032813228, "train/reward_loss_std": 0.1569907066769132, "train/reward_max_data": 1.008726665906817, "train/reward_max_pred": 1.0098523313754073, "train/reward_neg_acc": 0.9993562325138912, "train/reward_neg_loss": 0.051070146837106374, "train/reward_pos_acc": 0.9204561715928193, "train/reward_pos_loss": 0.717708410225182, "train/reward_pred": 0.018045933120753442, "train/reward_rate": 0.029420086156542055, "train_stats/sum_log_reward": 3.8692306738633375, "train_stats/max_log_achievement_collect_drink": 2.5384615384615383, "train_stats/max_log_achievement_collect_sapling": 2.3846153846153846, "train_stats/max_log_achievement_collect_wood": 1.4615384615384615, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 2.0, "train_stats/max_log_achievement_place_table": 0.46153846153846156, "train_stats/max_log_achievement_wake_up": 1.7692307692307692, "train_stats/mean_log_entropy": 0.6644314298262963, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 6.760389624105301e-06, "report/cont_loss_std": 3.882325108861551e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 1.31824617710663e-05, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 6.735204351571156e-06, "report/cont_pred": 0.9960870742797852, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 2.880364179611206, "report/dyn_loss_std": 7.773346900939941, "report/image_loss_mean": 1.2034013271331787, "report/image_loss_std": 3.589872121810913, "report/model_loss_mean": 2.993802309036255, "report/model_loss_std": 7.483738422393799, "report/post_ent_mag": 38.32554244995117, "report/post_ent_max": 38.32554244995117, "report/post_ent_mean": 21.665164947509766, "report/post_ent_min": 10.73896312713623, "report/post_ent_std": 4.229946613311768, "report/prior_ent_mag": 75.1477279663086, "report/prior_ent_max": 75.1477279663086, "report/prior_ent_mean": 24.594402313232422, "report/prior_ent_min": 12.584428787231445, "report/prior_ent_std": 9.054245948791504, "report/rep_loss_mean": 2.880364179611206, "report/rep_loss_std": 7.773346900939941, "report/reward_avg": 0.019640084356069565, "report/reward_loss_mean": 0.06217576563358307, "report/reward_loss_std": 0.1430933177471161, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0036227703094482, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.04378948733210564, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7411059737205505, "report/reward_pred": 0.018794476985931396, "report/reward_rate": 0.0263671875, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 8.644552144687623e-05, "eval/cont_loss_std": 0.0025441963225603104, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.020431309938430786, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 6.661732641077833e-06, "eval/cont_pred": 0.9961637258529663, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 25.735872268676758, "eval/dyn_loss_std": 14.969511032104492, "eval/image_loss_mean": 41.411460876464844, "eval/image_loss_std": 47.206199645996094, "eval/model_loss_mean": 57.005638122558594, "eval/model_loss_std": 53.08097457885742, "eval/post_ent_mag": 41.01306915283203, "eval/post_ent_max": 41.01306915283203, "eval/post_ent_mean": 26.91948699951172, "eval/post_ent_min": 14.22456169128418, "eval/post_ent_std": 3.4975173473358154, "eval/prior_ent_mag": 75.1477279663086, "eval/prior_ent_max": 75.1477279663086, "eval/prior_ent_mean": 35.400169372558594, "eval/prior_ent_min": 19.555805206298828, "eval/prior_ent_std": 8.24727725982666, "eval/rep_loss_mean": 25.735872268676758, "eval/rep_loss_std": 14.969511032104492, "eval/reward_avg": 0.02470703050494194, "eval/reward_loss_mean": 0.15256842970848083, "eval/reward_loss_std": 1.0917021036148071, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.002431869506836, "eval/reward_neg_acc": 0.9959840178489685, "eval/reward_neg_loss": 0.04418720304965973, "eval/reward_pos_acc": 0.6428571939468384, "eval/reward_pos_loss": 4.007843017578125, "eval/reward_pred": 0.01571953482925892, "eval/reward_rate": 0.02734375, "replay/size": 86641.0, "replay/inserts": 2139.0, "replay/samples": 34224.0, "replay/insert_wait_avg": 2.6199292668453607e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.826906322819878e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 17760.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 7.748603820800781e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2158687114716, "timer/env.step_count": 268.0, "timer/env.step_total": 27.193346977233887, "timer/env.step_frac": 0.027187478051378774, "timer/env.step_avg": 0.10146771260161898, "timer/env.step_min": 0.02422642707824707, "timer/env.step_max": 3.192308187484741, "timer/replay._sample_count": 34224.0, "timer/replay._sample_total": 16.33800721168518, "timer/replay._sample_frac": 0.016334481108295777, "timer/replay._sample_avg": 0.0004773845024452192, "timer/replay._sample_min": 0.00034737586975097656, "timer/replay._sample_max": 0.010854244232177734, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 268.0, "timer/agent.policy_total": 4.207463264465332, "timer/agent.policy_frac": 0.004206555200814398, "timer/agent.policy_avg": 0.01569948979278109, "timer/agent.policy_min": 0.014447689056396484, "timer/agent.policy_max": 0.04763460159301758, "timer/dataset_train_count": 2139.0, "timer/dataset_train_total": 0.3833184242248535, "timer/dataset_train_frac": 0.0003832356956290482, "timer/dataset_train_avg": 0.00017920449940385857, "timer/dataset_train_min": 8.797645568847656e-05, "timer/dataset_train_max": 0.0009336471557617188, "timer/agent.train_count": 2139.0, "timer/agent.train_total": 957.77605509758, "timer/agent.train_frac": 0.9575693458367495, "timer/agent.train_avg": 0.44776814170059837, "timer/agent.train_min": 0.433657169342041, "timer/agent.train_max": 0.9210877418518066, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47592806816101074, "timer/agent.report_frac": 0.0004758253523553123, "timer/agent.report_avg": 0.23796403408050537, "timer/agent.report_min": 0.23149776458740234, "timer/agent.report_max": 0.2444303035736084, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8371810913085938e-05, "timer/dataset_eval_frac": 2.836568764864322e-08, "timer/dataset_eval_avg": 2.8371810913085938e-05, "timer/dataset_eval_min": 2.8371810913085938e-05, "timer/dataset_eval_max": 2.8371810913085938e-05, "fps": 2.1385072806017775}
{"step": 87264, "time": 40384.72312283516, "episode/length": 195.0, "episode/score": 4.291721924751755, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.1917219260847105}
{"step": 87280, "time": 40393.4773850441, "episode/length": 154.0, "episode/score": 4.259560029884369, "episode/reward_rate": 0.9612903225806452, "episode/intrinsic_return": 0.15955998374897717}
{"step": 87616, "time": 40547.13855409622, "episode/length": 156.0, "episode/score": 4.270164260112551, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.17016413964597632}
{"step": 87800, "time": 40631.88984012604, "episode/length": 141.0, "episode/score": 3.2529018052680385, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.15290165779310882}
{"step": 88064, "time": 40752.69837617874, "episode/length": 160.0, "episode/score": 1.2303880290185134, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.13038794475710347}
{"step": 88128, "time": 40783.358011722565, "episode/length": 182.0, "episode/score": 3.2821284638080215, "episode/reward_rate": 0.9672131147540983, "episode/intrinsic_return": 0.18212839504440126}
{"step": 88344, "time": 40882.72728013992, "episode/length": 203.0, "episode/score": 5.327961324930584, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.2279611734975333}
{"step": 88384, "time": 40902.257944345474, "episode/length": 137.0, "episode/score": 5.23034774847838, "episode/reward_rate": 0.9927536231884058, "episode/intrinsic_return": 0.13034760513619403}
{"step": 88576, "time": 40990.76776623726, "episode/length": 183.0, "episode/score": 5.265076810179153, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.16507664920004572}
{"step": 88720, "time": 41057.4831237793, "episode/length": 181.0, "episode/score": 2.2904713357427227, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.19047128952001913}
{"step": 88744, "time": 41069.72295713425, "episode/length": 140.0, "episode/score": 3.217405162516343, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.11740499511984126}
{"step": 89256, "time": 41302.695768117905, "episode/length": 181.0, "episode/score": 4.264044234052108, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.16404403861406536}
{"step": 89314, "time": 41330.94322156906, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.10115719281034, "train/action_min": 0.0, "train/action_std": 4.056130215868972, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04482628148443962, "train/actor_opt_grad_steps": 86670.0, "train/actor_opt_loss": -12.140396382093154, "train/adv_mag": 0.9446991871578903, "train/adv_max": 0.8812170818379398, "train/adv_mean": 0.0028823189299783244, "train/adv_min": -0.6714213200703195, "train/adv_std": 0.059102738576550636, "train/cont_avg": 0.9942576324884793, "train/cont_loss_mean": 3.506560856308934e-05, "train/cont_loss_std": 0.0010800589871881585, "train/cont_neg_acc": 0.9986559141616118, "train/cont_neg_loss": 0.0032544800373612345, "train/cont_pos_acc": 0.9999954475235829, "train/cont_pos_loss": 1.2241510622179085e-05, "train/cont_pred": 0.9942595618111747, "train/cont_rate": 0.9942576324884793, "train/dyn_loss_mean": 3.006899188740462, "train/dyn_loss_std": 7.780979712437924, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1140792086926474, "train/extr_critic_critic_opt_grad_steps": 86670.0, "train/extr_critic_critic_opt_loss": 15377.02850032402, "train/extr_critic_mag": 15.10556765965053, "train/extr_critic_max": 15.10556765965053, "train/extr_critic_mean": 2.322550945567645, "train/extr_critic_min": -0.6001147449291246, "train/extr_critic_std": 2.7370223499113515, "train/extr_return_normed_mag": 1.9845093576589488, "train/extr_return_normed_max": 1.9845093576589488, "train/extr_return_normed_mean": 0.3170904138807877, "train/extr_return_normed_min": -0.10228121744185549, "train/extr_return_normed_std": 0.35601569883834383, "train/extr_return_rate": 0.6188487410545349, "train/extr_return_raw_mag": 15.434977751173731, "train/extr_return_raw_max": 15.434977751173731, "train/extr_return_raw_mean": 2.345057799519482, "train/extr_return_raw_min": -0.9442902045315861, "train/extr_return_raw_std": 2.797564821309208, "train/extr_reward_mag": 1.0244260647329866, "train/extr_reward_max": 1.0244260647329866, "train/extr_reward_mean": 0.030680893293757866, "train/extr_reward_min": -0.6601626230275026, "train/extr_reward_std": 0.1711539877106517, "train/image_loss_mean": 1.7287321824082582, "train/image_loss_std": 5.337748964810701, "train/model_loss_mean": 3.6026592628197736, "train/model_loss_std": 9.082202392789076, "train/model_opt_grad_norm": 34.18644481869887, "train/model_opt_grad_steps": 86599.52534562213, "train/model_opt_loss": 7199.207737795219, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1998.847926267281, "train/policy_entropy_mag": 2.653479150912729, "train/policy_entropy_max": 2.653479150912729, "train/policy_entropy_mean": 0.6187532656753119, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.7266573864743456, "train/policy_logprob_mag": 7.438383946220996, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.6185925862481517, "train/policy_logprob_min": -7.438383946220996, "train/policy_logprob_std": 1.1788358548269844, "train/policy_randomness_mag": 0.9365616951669965, "train/policy_randomness_max": 0.9365616951669965, "train/policy_randomness_mean": 0.21839274953587265, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.2564781672119545, "train/post_ent_mag": 43.08728545931627, "train/post_ent_max": 43.08728545931627, "train/post_ent_mean": 22.678354166619787, "train/post_ent_min": 12.020308274827245, "train/post_ent_std": 4.013576671275126, "train/prior_ent_mag": 75.07711957237139, "train/prior_ent_max": 75.07711957237139, "train/prior_ent_mean": 25.64685749458278, "train/prior_ent_min": 13.257604010094147, "train/prior_ent_std": 8.892102406321582, "train/rep_loss_mean": 3.006899188740462, "train/rep_loss_std": 7.780979712437924, "train/reward_avg": 0.0178841208343819, "train/reward_loss_mean": 0.06975252524636308, "train/reward_loss_std": 0.14944244375289312, "train/reward_max_data": 1.0127707686841763, "train/reward_max_pred": 1.0137550655048564, "train/reward_neg_acc": 0.9993507664324501, "train/reward_neg_loss": 0.050441256522582974, "train/reward_pos_acc": 0.9190617415212816, "train/reward_pos_loss": 0.7098257036253055, "train/reward_pred": 0.017801313122416833, "train/reward_rate": 0.0292698732718894, "train_stats/sum_log_reward": 3.6833332777023315, "train_stats/max_log_achievement_collect_drink": 2.75, "train_stats/max_log_achievement_collect_sapling": 1.25, "train_stats/max_log_achievement_collect_wood": 2.6666666666666665, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 0.75, "train_stats/max_log_achievement_place_table": 1.0833333333333333, "train_stats/max_log_achievement_wake_up": 1.8333333333333333, "train_stats/mean_log_entropy": 0.5598523815472921, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 0.0008950763731263578, "report/cont_loss_std": 0.028433794155716896, "report/cont_neg_acc": 0.875, "report/cont_neg_loss": 0.11448381096124649, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 6.769439551135292e-07, "report/cont_pred": 0.9927759170532227, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 2.899693489074707, "report/dyn_loss_std": 7.658535003662109, "report/image_loss_mean": 1.2011559009552002, "report/image_loss_std": 3.77500057220459, "report/model_loss_mean": 3.020514726638794, "report/model_loss_std": 7.633458614349365, "report/post_ent_mag": 44.747528076171875, "report/post_ent_max": 44.747528076171875, "report/post_ent_mean": 23.33562469482422, "report/post_ent_min": 14.325176239013672, "report/post_ent_std": 3.5798025131225586, "report/prior_ent_mag": 75.24339294433594, "report/prior_ent_max": 75.24339294433594, "report/prior_ent_mean": 26.272579193115234, "report/prior_ent_min": 15.365398406982422, "report/prior_ent_std": 8.886802673339844, "report/rep_loss_mean": 2.899693489074707, "report/rep_loss_std": 7.658535003662109, "report/reward_avg": 0.023128855973482132, "report/reward_loss_mean": 0.07864773273468018, "report/reward_loss_std": 0.20689675211906433, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0024304389953613, "report/reward_neg_acc": 0.9989867806434631, "report/reward_neg_loss": 0.051805973052978516, "report/reward_pos_acc": 0.9459459185600281, "report/reward_pos_loss": 0.7946697473526001, "report/reward_pred": 0.022417547181248665, "report/reward_rate": 0.0361328125, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.0013006810331717134, "eval/cont_loss_std": 0.0411088801920414, "eval/cont_neg_acc": 0.800000011920929, "eval/cont_neg_loss": 0.2656048834323883, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 3.8009807212802116e-06, "eval/cont_pred": 0.9958397150039673, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 24.02136993408203, "eval/dyn_loss_std": 13.299898147583008, "eval/image_loss_mean": 41.53948974609375, "eval/image_loss_std": 49.91830062866211, "eval/model_loss_mean": 56.10313415527344, "eval/model_loss_std": 54.278045654296875, "eval/post_ent_mag": 40.675926208496094, "eval/post_ent_max": 40.675926208496094, "eval/post_ent_mean": 27.360858917236328, "eval/post_ent_min": 18.304359436035156, "eval/post_ent_std": 3.471132278442383, "eval/prior_ent_mag": 75.24339294433594, "eval/prior_ent_max": 75.24339294433594, "eval/prior_ent_mean": 36.710693359375, "eval/prior_ent_min": 18.842878341674805, "eval/prior_ent_std": 8.380736351013184, "eval/rep_loss_mean": 24.02136993408203, "eval/rep_loss_std": 13.299898147583008, "eval/reward_avg": 0.01835937425494194, "eval/reward_loss_mean": 0.14951945841312408, "eval/reward_loss_std": 0.9211530685424805, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.001835823059082, "eval/reward_neg_acc": 0.9970029592514038, "eval/reward_neg_loss": 0.08090276271104813, "eval/reward_pos_acc": 0.6086956858634949, "eval/reward_pos_loss": 3.1358377933502197, "eval/reward_pred": 0.011946490965783596, "eval/reward_rate": 0.0224609375, "replay/size": 88810.0, "replay/inserts": 2169.0, "replay/samples": 34704.0, "replay/insert_wait_avg": 2.5547831330006986e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.660254842952519e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 17760.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 7.301568984985352e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3396027088165, "timer/env.step_count": 271.0, "timer/env.step_total": 25.30185890197754, "timer/env.step_frac": 0.02529326923922907, "timer/env.step_avg": 0.09336479299622708, "timer/env.step_min": 0.023803234100341797, "timer/env.step_max": 1.688366174697876, "timer/replay._sample_count": 34704.0, "timer/replay._sample_total": 16.43886423110962, "timer/replay._sample_frac": 0.016433283443537443, "timer/replay._sample_avg": 0.0004736878812560402, "timer/replay._sample_min": 0.00033736228942871094, "timer/replay._sample_max": 0.010447502136230469, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 271.0, "timer/agent.policy_total": 4.289853096008301, "timer/agent.policy_frac": 0.004288396744857267, "timer/agent.policy_avg": 0.015829716221432845, "timer/agent.policy_min": 0.014403581619262695, "timer/agent.policy_max": 0.04193925857543945, "timer/dataset_train_count": 2169.0, "timer/dataset_train_total": 0.381664514541626, "timer/dataset_train_frac": 0.00038153494424105356, "timer/dataset_train_avg": 0.00017596335386889164, "timer/dataset_train_min": 8.916854858398438e-05, "timer/dataset_train_max": 0.000659942626953125, "timer/agent.train_count": 2169.0, "timer/agent.train_total": 959.6720142364502, "timer/agent.train_frac": 0.9593462176622392, "timer/agent.train_avg": 0.44244906142759344, "timer/agent.train_min": 0.43215131759643555, "timer/agent.train_max": 0.5798876285552979, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47933459281921387, "timer/agent.report_frac": 0.0004791718647559541, "timer/agent.report_avg": 0.23966729640960693, "timer/agent.report_min": 0.2334129810333252, "timer/agent.report_max": 0.24592161178588867, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8848648071289062e-05, "timer/dataset_eval_frac": 2.883885431824342e-08, "timer/dataset_eval_avg": 2.8848648071289062e-05, "timer/dataset_eval_min": 2.8848648071289062e-05, "timer/dataset_eval_max": 2.8848648071289062e-05, "fps": 2.168234584403938}
{"step": 89336, "time": 41341.07832455635, "episode/length": 158.0, "episode/score": 4.245898016094543, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.1458978859363924}
{"step": 89512, "time": 41422.33710861206, "episode/length": 172.0, "episode/score": 3.265652899529641, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.16565275141442726}
{"step": 89696, "time": 41507.10985684395, "episode/length": 163.0, "episode/score": 2.2516042386696427, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.1516041512504671}
{"step": 89992, "time": 41642.308512449265, "episode/length": 176.0, "episode/score": 3.2838235548820194, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.1838234762085449}
{"step": 90064, "time": 41695.89520859718, "eval_episode/length": 155.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 90064, "time": 41697.74313926697, "eval_episode/length": 163.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9695121951219512}
{"step": 90064, "time": 41699.34128546715, "eval_episode/length": 166.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9700598802395209}
{"step": 90064, "time": 41701.43283343315, "eval_episode/length": 176.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9717514124293786}
{"step": 90064, "time": 41702.923679828644, "eval_episode/length": 177.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9943820224719101}
{"step": 90064, "time": 41705.10713171959, "eval_episode/length": 194.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9692307692307692}
{"step": 90064, "time": 41706.74759173393, "eval_episode/length": 199.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.97}
{"step": 90064, "time": 41708.85741496086, "eval_episode/length": 212.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9953051643192489}
{"step": 90104, "time": 41726.8566198349, "episode/length": 219.0, "episode/score": 4.332398978484434, "episode/reward_rate": 0.9727272727272728, "episode/intrinsic_return": 0.23239886151031897}
{"step": 90224, "time": 41783.40752720833, "episode/length": 184.0, "episode/score": 2.2977140748678266, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.19771395253860646}
{"step": 90280, "time": 41810.092714071274, "episode/length": 194.0, "episode/score": 5.297902413446309, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.19790224404164292}
{"step": 90464, "time": 41894.49764728546, "episode/length": 150.0, "episode/score": 4.243037788572565, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.14303768440413478}
{"step": 90968, "time": 42123.40902304649, "episode/length": 203.0, "episode/score": 5.2960226954799055, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.19602260894839674}
{"step": 90992, "time": 42135.74489378929, "episode/length": 184.0, "episode/score": 5.302012495686995, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.20201230790326008}
{"step": 91264, "time": 42259.912976026535, "episode/length": 195.0, "episode/score": 4.2976352212649545, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.19763506715435142}
{"step": 91408, "time": 42326.34669327736, "episode/length": 51.0, "episode/score": -0.8517557594127538, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.04824421243802135}
{"step": 91414, "time": 42331.049389600754, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.130347260974703, "train/action_min": 0.0, "train/action_std": 4.06497335093362, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.042788515594743545, "train/actor_opt_grad_steps": 88805.0, "train/actor_opt_loss": -16.92768884655975, "train/adv_mag": 0.8601952545699619, "train/adv_max": 0.7640753482069288, "train/adv_mean": 0.0014670508987148336, "train/adv_min": -0.6752948836201713, "train/adv_std": 0.05536180547482911, "train/cont_avg": 0.9945172991071428, "train/cont_loss_mean": 2.433141768793099e-05, "train/cont_loss_std": 0.0007282257389149327, "train/cont_neg_acc": 1.0, "train/cont_neg_loss": 0.0009485998914767281, "train/cont_pos_acc": 0.9999953079791296, "train/cont_pos_loss": 1.912995647032966e-05, "train/cont_pred": 0.9945110122362772, "train/cont_rate": 0.9945172991071428, "train/dyn_loss_mean": 2.973108339309692, "train/dyn_loss_std": 7.77009604090736, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0949210751624334, "train/extr_critic_critic_opt_grad_steps": 88805.0, "train/extr_critic_critic_opt_loss": 14991.492140997023, "train/extr_critic_mag": 13.036168420882452, "train/extr_critic_max": 13.036168420882452, "train/extr_critic_mean": 2.1673444248381113, "train/extr_critic_min": -0.6247728904088338, "train/extr_critic_std": 2.505713551385062, "train/extr_return_normed_mag": 1.8055599939255487, "train/extr_return_normed_max": 1.8055599939255487, "train/extr_return_normed_mean": 0.3177391643325488, "train/extr_return_normed_min": -0.10202758416888259, "train/extr_return_normed_std": 0.3435390493699482, "train/extr_return_rate": 0.621568732318424, "train/extr_return_raw_mag": 13.16850485120501, "train/extr_return_raw_max": 13.16850485120501, "train/extr_return_raw_mean": 2.178163571017129, "train/extr_return_raw_min": -0.9216316298359917, "train/extr_return_raw_std": 2.5372462051255362, "train/extr_reward_mag": 1.0249462502343314, "train/extr_reward_max": 1.0249462502343314, "train/extr_reward_mean": 0.03168837474215598, "train/extr_reward_min": -0.6509925166765849, "train/extr_reward_std": 0.1736953242903664, "train/image_loss_mean": 1.605497362783977, "train/image_loss_std": 4.931741330737159, "train/model_loss_mean": 3.4593023958660307, "train/model_loss_std": 8.71482926096235, "train/model_opt_grad_norm": 32.30311163039435, "train/model_opt_grad_steps": 88732.42380952381, "train/model_opt_loss": 5415.658457728795, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1571.4285714285713, "train/policy_entropy_mag": 2.658736499150594, "train/policy_entropy_max": 2.658736499150594, "train/policy_entropy_mean": 0.6314605820746649, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.7365710872979391, "train/policy_logprob_mag": 7.438383972077142, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.6314797205584389, "train/policy_logprob_min": -7.438383972077142, "train/policy_logprob_std": 1.1821631471316019, "train/policy_randomness_mag": 0.9384173098064604, "train/policy_randomness_max": 0.9384173098064604, "train/policy_randomness_mean": 0.22287787461564654, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.25997726952745803, "train/post_ent_mag": 43.180381629580545, "train/post_ent_max": 43.180381629580545, "train/post_ent_mean": 22.913495826721192, "train/post_ent_min": 11.978138528551375, "train/post_ent_std": 4.125010982013884, "train/prior_ent_mag": 75.13103997366768, "train/prior_ent_max": 75.13103997366768, "train/prior_ent_mean": 25.82922882806687, "train/prior_ent_min": 13.273326782953172, "train/prior_ent_std": 8.895245402199881, "train/rep_loss_mean": 2.973108339309692, "train/rep_loss_std": 7.77009604090736, "train/reward_avg": 0.018251535493791812, "train/reward_loss_mean": 0.06991569025530701, "train/reward_loss_std": 0.1516376714976061, "train/reward_max_data": 1.0136309839430309, "train/reward_max_pred": 1.0149637313116164, "train/reward_neg_acc": 0.9993242189997719, "train/reward_neg_loss": 0.05024865418672562, "train/reward_pos_acc": 0.9166589536837169, "train/reward_pos_loss": 0.7127831192243667, "train/reward_pred": 0.0181667734070548, "train/reward_rate": 0.02972470238095238, "train_stats/sum_log_reward": 3.433333247900009, "train_stats/max_log_achievement_collect_drink": 2.5833333333333335, "train_stats/max_log_achievement_collect_sapling": 2.1666666666666665, "train_stats/max_log_achievement_collect_wood": 2.75, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.3333333333333333, "train_stats/max_log_achievement_place_table": 1.0, "train_stats/max_log_achievement_wake_up": 1.6666666666666667, "train_stats/mean_log_entropy": 0.49776742855707806, "eval_stats/sum_log_reward": 4.474999904632568, "eval_stats/max_log_achievement_collect_drink": 3.625, "eval_stats/max_log_achievement_collect_sapling": 1.5, "eval_stats/max_log_achievement_collect_wood": 2.5, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 1.5, "eval_stats/max_log_achievement_place_table": 1.0, "eval_stats/max_log_achievement_wake_up": 2.125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9912109375, "report/cont_loss_mean": 3.6923677271261113e-07, "report/cont_loss_std": 1.3887564591641421e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 1.0835569810296874e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.764319049219921e-07, "report/cont_pred": 0.9912109375, "report/cont_rate": 0.9912109375, "report/dyn_loss_mean": 3.2119174003601074, "report/dyn_loss_std": 7.7873687744140625, "report/image_loss_mean": 1.2440099716186523, "report/image_loss_std": 3.995131254196167, "report/model_loss_mean": 3.2541279792785645, "report/model_loss_std": 7.828503131866455, "report/post_ent_mag": 44.440670013427734, "report/post_ent_max": 44.440670013427734, "report/post_ent_mean": 24.188581466674805, "report/post_ent_min": 13.453699111938477, "report/post_ent_std": 4.004843711853027, "report/prior_ent_mag": 74.71668243408203, "report/prior_ent_max": 74.71668243408203, "report/prior_ent_mean": 27.41852569580078, "report/prior_ent_min": 13.042597770690918, "report/prior_ent_std": 9.24555778503418, "report/rep_loss_mean": 3.2119174003601074, "report/rep_loss_std": 7.7873687744140625, "report/reward_avg": 0.026564162224531174, "report/reward_loss_mean": 0.0829673632979393, "report/reward_loss_std": 0.19937680661678314, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0024268627166748, "report/reward_neg_acc": 0.9969573616981506, "report/reward_neg_loss": 0.059749845415353775, "report/reward_pos_acc": 0.9736841917037964, "report/reward_pos_loss": 0.6854009032249451, "report/reward_pred": 0.028078824281692505, "report/reward_rate": 0.037109375, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.007366975769400597, "eval/cont_loss_std": 0.23561915755271912, "eval/cont_neg_acc": 0.5, "eval/cont_neg_loss": 3.7717573642730713, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.618658356823289e-07, "eval/cont_pred": 0.9990228414535522, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 24.757497787475586, "eval/dyn_loss_std": 14.090961456298828, "eval/image_loss_mean": 41.796348571777344, "eval/image_loss_std": 48.09041213989258, "eval/model_loss_mean": 56.807857513427734, "eval/model_loss_std": 53.71082305908203, "eval/post_ent_mag": 44.440670013427734, "eval/post_ent_max": 44.440670013427734, "eval/post_ent_mean": 27.217023849487305, "eval/post_ent_min": 14.890119552612305, "eval/post_ent_std": 3.5267128944396973, "eval/prior_ent_mag": 74.71668243408203, "eval/prior_ent_max": 74.71668243408203, "eval/prior_ent_mean": 35.774749755859375, "eval/prior_ent_min": 16.117828369140625, "eval/prior_ent_std": 8.773528099060059, "eval/rep_loss_mean": 24.757497787475586, "eval/rep_loss_std": 14.090961456298828, "eval/reward_avg": 0.02177734300494194, "eval/reward_loss_mean": 0.14964905381202698, "eval/reward_loss_std": 1.0939879417419434, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.002424716949463, "eval/reward_neg_acc": 0.9960000514984131, "eval/reward_neg_loss": 0.05511399358510971, "eval/reward_pos_acc": 0.625, "eval/reward_pos_loss": 4.08860969543457, "eval/reward_pred": 0.015346352010965347, "eval/reward_rate": 0.0234375, "replay/size": 90910.0, "replay/inserts": 2100.0, "replay/samples": 33600.0, "replay/insert_wait_avg": 2.543699173700242e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.398213659014021e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 19464.0, "eval_replay/inserts": 1704.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.128850408563032e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.003545761108398e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0936818122864, "timer/env.step_count": 262.0, "timer/env.step_total": 25.175997018814087, "timer/env.step_frac": 0.0251736387067182, "timer/env.step_avg": 0.09609159167486293, "timer/env.step_min": 0.023622512817382812, "timer/env.step_max": 1.7818491458892822, "timer/replay._sample_count": 33600.0, "timer/replay._sample_total": 15.731981039047241, "timer/replay._sample_frac": 0.015730507376608017, "timer/replay._sample_avg": 0.00046821372140021554, "timer/replay._sample_min": 0.00034618377685546875, "timer/replay._sample_max": 0.010106563568115234, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 475.0, "timer/agent.policy_total": 7.356320858001709, "timer/agent.policy_frac": 0.00735563176908707, "timer/agent.policy_avg": 0.015486991280003597, "timer/agent.policy_min": 0.00934600830078125, "timer/agent.policy_max": 0.04073166847229004, "timer/dataset_train_count": 2100.0, "timer/dataset_train_total": 0.36322712898254395, "timer/dataset_train_frac": 0.00036319310439431436, "timer/dataset_train_avg": 0.00017296529951549712, "timer/dataset_train_min": 8.463859558105469e-05, "timer/dataset_train_max": 0.002585172653198242, "timer/agent.train_count": 2100.0, "timer/agent.train_total": 928.1589186191559, "timer/agent.train_frac": 0.9280719751545912, "timer/agent.train_avg": 0.4419804374376933, "timer/agent.train_min": 0.4306488037109375, "timer/agent.train_max": 0.584552526473999, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4739034175872803, "timer/agent.report_frac": 0.0004738590256149924, "timer/agent.report_avg": 0.23695170879364014, "timer/agent.report_min": 0.22973132133483887, "timer/agent.report_max": 0.2441720962524414, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9087066650390625e-05, "timer/dataset_eval_frac": 2.9084341976525108e-08, "timer/dataset_eval_avg": 2.9087066650390625e-05, "timer/dataset_eval_min": 2.9087066650390625e-05, "timer/dataset_eval_max": 2.9087066650390625e-05, "fps": 2.0997752962726044}
{"step": 91800, "time": 42505.901693582535, "episode/length": 211.0, "episode/score": 3.3375854015466757, "episode/reward_rate": 0.9716981132075472, "episode/intrinsic_return": 0.2375853132107295}
{"step": 91816, "time": 42514.70576143265, "episode/length": 191.0, "episode/score": 2.2736426806905, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.1736426194283922}
{"step": 91840, "time": 42527.151962041855, "episode/length": 201.0, "episode/score": 5.3098223951951695, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.20982231086827596}
{"step": 91880, "time": 42546.919461250305, "episode/length": 176.0, "episode/score": 5.2634016450329, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.16340146983657178}
{"step": 92352, "time": 42762.80063056946, "episode/length": 294.0, "episode/score": 5.397835542395342, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.29783548918771885}
{"step": 92368, "time": 42771.653707027435, "episode/length": 137.0, "episode/score": 5.225685627621033, "episode/reward_rate": 0.9927536231884058, "episode/intrinsic_return": 0.12568548316562556}
{"step": 92472, "time": 42820.41969895363, "episode/length": 132.0, "episode/score": 6.233815333281427, "episode/reward_rate": 0.9924812030075187, "episode/intrinsic_return": 0.13381522439817672}
{"step": 92872, "time": 43003.57133555412, "episode/length": 131.0, "episode/score": 3.2289901083649966, "episode/reward_rate": 0.9924242424242424, "episode/intrinsic_return": 0.12899000416746276}
{"step": 92872, "time": 43003.58066153526, "episode/length": 237.0, "episode/score": 5.360416478966272, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.26041627072254414}
{"step": 93088, "time": 43104.8836081028, "episode/length": 160.0, "episode/score": 4.271191707471189, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.17119163642291824}
{"step": 93144, "time": 43131.73481321335, "episode/length": 162.0, "episode/score": 3.264051778962994, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.16405164953243911}
{"step": 93176, "time": 43147.697514772415, "episode/length": 37.0, "episode/score": 1.1397303370176814, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.03973039158154279}
{"step": 93577, "time": 43331.189907073975, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.136993690773293, "train/action_min": 0.0, "train/action_std": 4.000195608094886, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04233179952845805, "train/actor_opt_grad_steps": 90935.0, "train/actor_opt_loss": -13.389221883896324, "train/adv_mag": 0.8010583947654124, "train/adv_max": 0.7409237861909248, "train/adv_mean": 0.0021406282854783327, "train/adv_min": -0.5914024540947543, "train/adv_std": 0.053751080900568654, "train/cont_avg": 0.9944028501157407, "train/cont_loss_mean": 5.140314305249502e-05, "train/cont_loss_std": 0.0016028036564903316, "train/cont_neg_acc": 0.997255291375849, "train/cont_neg_loss": 0.008347544507614657, "train/cont_pos_acc": 0.9999999817874696, "train/cont_pos_loss": 6.733653625603766e-06, "train/cont_pred": 0.9944124552938673, "train/cont_rate": 0.9944028501157407, "train/dyn_loss_mean": 2.977320844376529, "train/dyn_loss_std": 7.778497400107207, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0625958862128082, "train/extr_critic_critic_opt_grad_steps": 90935.0, "train/extr_critic_critic_opt_loss": 14837.154608832465, "train/extr_critic_mag": 11.573620941903856, "train/extr_critic_max": 11.573620941903856, "train/extr_critic_mean": 2.0266623298327127, "train/extr_critic_min": -0.6298640160648911, "train/extr_critic_std": 2.2674807944783457, "train/extr_return_normed_mag": 1.806638103392389, "train/extr_return_normed_max": 1.806638103392389, "train/extr_return_normed_mean": 0.3328914519537378, "train/extr_return_normed_min": -0.11776286330832927, "train/extr_return_normed_std": 0.3422213417512399, "train/extr_return_rate": 0.6276038978938703, "train/extr_return_raw_mag": 11.956628889949233, "train/extr_return_raw_max": 11.956628889949233, "train/extr_return_raw_mean": 2.040751824224437, "train/extr_return_raw_min": -0.987205506198936, "train/extr_return_raw_std": 2.303207893614416, "train/extr_reward_mag": 1.0171586981526128, "train/extr_reward_max": 1.0171586981526128, "train/extr_reward_mean": 0.031718644279020804, "train/extr_reward_min": -0.6656961225801044, "train/extr_reward_std": 0.17399796467550374, "train/image_loss_mean": 1.5760809492181849, "train/image_loss_std": 4.846674303213756, "train/model_loss_mean": 3.4325446011843503, "train/model_loss_std": 8.623557466047782, "train/model_opt_grad_norm": 32.509522053930496, "train/model_opt_grad_steps": 90861.23611111111, "train/model_opt_loss": 8762.850897894965, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2557.8703703703704, "train/policy_entropy_mag": 2.641617718670103, "train/policy_entropy_max": 2.641617718670103, "train/policy_entropy_mean": 0.6229319346171839, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.7318422303155616, "train/policy_logprob_mag": 7.4383839633729725, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.6236822057377409, "train/policy_logprob_min": -7.4383839633729725, "train/policy_logprob_std": 1.1795061495569017, "train/policy_randomness_mag": 0.9323751311059352, "train/policy_randomness_max": 0.9323751311059352, "train/policy_randomness_mean": 0.2198676386917079, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.2583081903005088, "train/post_ent_mag": 43.58889789934511, "train/post_ent_max": 43.58889789934511, "train/post_ent_mean": 23.108553303612602, "train/post_ent_min": 11.876062662513167, "train/post_ent_std": 4.216493561312005, "train/prior_ent_mag": 75.23658434549968, "train/prior_ent_max": 75.23658434549968, "train/prior_ent_mean": 26.04308493932088, "train/prior_ent_min": 13.215888990296257, "train/prior_ent_std": 8.942995426831422, "train/rep_loss_mean": 2.977320844376529, "train/rep_loss_std": 7.778497400107207, "train/reward_avg": 0.018059080274758377, "train/reward_loss_mean": 0.07001974149089721, "train/reward_loss_std": 0.15459884406515845, "train/reward_max_data": 1.0068055854903326, "train/reward_max_pred": 1.0077182120747037, "train/reward_neg_acc": 0.9993055719468329, "train/reward_neg_loss": 0.05051033990457654, "train/reward_pos_acc": 0.9139835925565826, "train/reward_pos_loss": 0.7184585490160518, "train/reward_pred": 0.0179486242661908, "train/reward_rate": 0.02924714265046296, "train_stats/sum_log_reward": 4.01666659116745, "train_stats/max_log_achievement_collect_drink": 3.3333333333333335, "train_stats/max_log_achievement_collect_sapling": 1.9166666666666667, "train_stats/max_log_achievement_collect_wood": 3.1666666666666665, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.08333333333333333, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.08333333333333333, "train_stats/max_log_achievement_place_plant": 1.4166666666666667, "train_stats/max_log_achievement_place_table": 1.1666666666666667, "train_stats/max_log_achievement_wake_up": 1.75, "train_stats/mean_log_entropy": 0.5465750346581141, "report/cont_avg": 0.990234375, "report/cont_loss_mean": 8.806346158962697e-07, "report/cont_loss_std": 7.235221801238367e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 4.641327541321516e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 4.3159477058907214e-07, "report/cont_pred": 0.9902344942092896, "report/cont_rate": 0.990234375, "report/dyn_loss_mean": 2.988041639328003, "report/dyn_loss_std": 8.22740650177002, "report/image_loss_mean": 1.7702736854553223, "report/image_loss_std": 5.247175693511963, "report/model_loss_mean": 3.635953903198242, "report/model_loss_std": 9.218857765197754, "report/post_ent_mag": 45.15446472167969, "report/post_ent_max": 45.15446472167969, "report/post_ent_mean": 23.695148468017578, "report/post_ent_min": 12.739567756652832, "report/post_ent_std": 4.393002510070801, "report/prior_ent_mag": 75.01331329345703, "report/prior_ent_max": 75.01331329345703, "report/prior_ent_mean": 26.681774139404297, "report/prior_ent_min": 13.91350269317627, "report/prior_ent_std": 9.489516258239746, "report/rep_loss_mean": 2.988041639328003, "report/rep_loss_std": 8.22740650177002, "report/reward_avg": 0.011966239660978317, "report/reward_loss_mean": 0.07285445183515549, "report/reward_loss_std": 0.13155315816402435, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0007176399230957, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.05658935382962227, "report/reward_pos_acc": 0.8518518805503845, "report/reward_pos_loss": 0.6734582185745239, "report/reward_pred": 0.012154024094343185, "report/reward_rate": 0.0263671875, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.0033491242211312056, "eval/cont_loss_std": 0.10140687227249146, "eval/cont_neg_acc": 0.75, "eval/cont_neg_loss": 0.8572618365287781, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 4.468154486403364e-07, "eval/cont_pred": 0.9972020387649536, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 25.4578914642334, "eval/dyn_loss_std": 14.360527992248535, "eval/image_loss_mean": 37.748687744140625, "eval/image_loss_std": 48.1396369934082, "eval/model_loss_mean": 53.17017364501953, "eval/model_loss_std": 53.72666549682617, "eval/post_ent_mag": 38.69764709472656, "eval/post_ent_max": 38.69764709472656, "eval/post_ent_mean": 27.117156982421875, "eval/post_ent_min": 18.22020721435547, "eval/post_ent_std": 3.3783013820648193, "eval/prior_ent_mag": 75.01331329345703, "eval/prior_ent_max": 75.01331329345703, "eval/prior_ent_mean": 37.563899993896484, "eval/prior_ent_min": 20.604419708251953, "eval/prior_ent_std": 8.160024642944336, "eval/rep_loss_mean": 25.4578914642334, "eval/rep_loss_std": 14.360527992248535, "eval/reward_avg": 0.01845703274011612, "eval/reward_loss_mean": 0.14340104162693024, "eval/reward_loss_std": 1.0143083333969116, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0048165321350098, "eval/reward_neg_acc": 0.9940119981765747, "eval/reward_neg_loss": 0.07013611495494843, "eval/reward_pos_acc": 0.6363636255264282, "eval/reward_pos_loss": 3.480285167694092, "eval/reward_pred": 0.013861071318387985, "eval/reward_rate": 0.021484375, "replay/size": 93073.0, "replay/inserts": 2163.0, "replay/samples": 34608.0, "replay/insert_wait_avg": 2.5175591061857085e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.711884824423894e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 19464.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 8.791685104370117e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1273927688599, "timer/env.step_count": 271.0, "timer/env.step_total": 25.48725962638855, "timer/env.step_frac": 0.025484013147392043, "timer/env.step_avg": 0.09404892851065885, "timer/env.step_min": 0.02362680435180664, "timer/env.step_max": 3.2104978561401367, "timer/replay._sample_count": 34608.0, "timer/replay._sample_total": 16.858941793441772, "timer/replay._sample_frac": 0.016856794359734185, "timer/replay._sample_avg": 0.0004871400194591358, "timer/replay._sample_min": 0.00034117698669433594, "timer/replay._sample_max": 0.034744977951049805, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 271.0, "timer/agent.policy_total": 4.275239944458008, "timer/agent.policy_frac": 0.004274695379177622, "timer/agent.policy_avg": 0.01577579315298158, "timer/agent.policy_min": 0.01430821418762207, "timer/agent.policy_max": 0.042836904525756836, "timer/dataset_train_count": 2163.0, "timer/dataset_train_total": 0.3737521171569824, "timer/dataset_train_frac": 0.00037370450990473024, "timer/dataset_train_avg": 0.0001727933967438661, "timer/dataset_train_min": 8.535385131835938e-05, "timer/dataset_train_max": 0.0007188320159912109, "timer/agent.train_count": 2163.0, "timer/agent.train_total": 959.5131075382233, "timer/agent.train_frac": 0.9593908880765722, "timer/agent.train_avg": 0.44360291610643704, "timer/agent.train_min": 0.43238186836242676, "timer/agent.train_max": 0.5625832080841064, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.474745512008667, "timer/agent.report_frac": 0.00047468504056701283, "timer/agent.report_avg": 0.2373727560043335, "timer/agent.report_min": 0.22736501693725586, "timer/agent.report_max": 0.24738049507141113, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.956390380859375e-05, "timer/dataset_eval_frac": 2.956013806075831e-08, "timer/dataset_eval_avg": 2.956390380859375e-05, "timer/dataset_eval_min": 2.956390380859375e-05, "timer/dataset_eval_max": 2.956390380859375e-05, "fps": 2.162695850270981}
{"step": 93688, "time": 43381.68745160103, "episode/length": 166.0, "episode/score": 5.259128122676202, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.15912798861813826}
{"step": 94072, "time": 43557.26925730705, "episode/length": 212.0, "episode/score": 5.341387607270235, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.24138744825563663}
{"step": 94088, "time": 43565.98986363411, "episode/length": 151.0, "episode/score": 5.267650734411063, "episode/reward_rate": 0.9605263157894737, "episode/intrinsic_return": 0.16765057261704897}
{"step": 94136, "time": 43589.27389097214, "episode/length": 207.0, "episode/score": 3.310485171115488, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.21048506162833291}
{"step": 94296, "time": 43663.37448167801, "episode/length": 301.0, "episode/score": 3.4342660124614213, "episode/reward_rate": 0.9867549668874173, "episode/intrinsic_return": 0.33426585683741905}
{"step": 94408, "time": 43715.82257604599, "episode/length": 164.0, "episode/score": 5.248982294632015, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.14898214203481075}
{"step": 94640, "time": 43823.02542376518, "episode/length": 182.0, "episode/score": 3.284235570360579, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.18423548935879808}
{"step": 94840, "time": 43915.48134589195, "episode/length": 143.0, "episode/score": 4.233877609423871, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.1338775099702616}
{"step": 94968, "time": 43975.400240421295, "episode/length": 227.0, "episode/score": 5.335993622596106, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.23599349410415016}
{"step": 95472, "time": 44205.77203989029, "episode/length": 174.0, "episode/score": 4.291900060389253, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.19189996831346434}
{"step": 95512, "time": 44225.3962187767, "episode/length": 171.0, "episode/score": 5.281807573768674, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.181807441631463}
{"step": 95672, "time": 44299.53553771973, "episode/length": 197.0, "episode/score": 5.300335373001076, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.20033523082304328}
{"step": 95704, "time": 44315.527487277985, "episode/length": 175.0, "episode/score": 4.289742265894006, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.18974214542743084}
{"step": 95734, "time": 44331.209698200226, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.143934179235388, "train/action_min": 0.0, "train/action_std": 3.958051841568064, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.040477977125664, "train/actor_opt_grad_steps": 93095.0, "train/actor_opt_loss": -15.12125815561524, "train/adv_mag": 0.6773518446694922, "train/adv_max": 0.6047905251659729, "train/adv_mean": 0.001929493619431671, "train/adv_min": -0.5295727440604457, "train/adv_std": 0.05099478493341141, "train/cont_avg": 0.9945249204282407, "train/cont_loss_mean": 8.602550765483367e-05, "train/cont_loss_std": 0.0027141184467108165, "train/cont_neg_acc": 0.9971450619675495, "train/cont_neg_loss": 0.013705419197753633, "train/cont_pos_acc": 0.999995437209253, "train/cont_pos_loss": 1.3570220611477432e-05, "train/cont_pred": 0.994529120348118, "train/cont_rate": 0.9945249204282407, "train/dyn_loss_mean": 2.955625981092453, "train/dyn_loss_std": 7.754162572048329, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0582398052016895, "train/extr_critic_critic_opt_grad_steps": 93095.0, "train/extr_critic_critic_opt_loss": 14796.062396014178, "train/extr_critic_mag": 10.340186679804766, "train/extr_critic_max": 10.340186679804766, "train/extr_critic_mean": 2.107000324461195, "train/extr_critic_min": -0.6236546194111859, "train/extr_critic_std": 2.2252403762605457, "train/extr_return_normed_mag": 1.6236623602884788, "train/extr_return_normed_max": 1.6236623602884788, "train/extr_return_normed_mean": 0.34427093321250546, "train/extr_return_normed_min": -0.11457791577817665, "train/extr_return_normed_std": 0.3372476458273552, "train/extr_return_rate": 0.6676785279479291, "train/extr_return_raw_mag": 10.694348944558037, "train/extr_return_raw_max": 10.694348944558037, "train/extr_return_raw_mean": 2.1199186499472016, "train/extr_return_raw_min": -0.9553846871411359, "train/extr_return_raw_std": 2.2601129992140665, "train/extr_reward_mag": 1.0213196928854342, "train/extr_reward_max": 1.0213196928854342, "train/extr_reward_mean": 0.032445048413204926, "train/extr_reward_min": -0.6704228051282741, "train/extr_reward_std": 0.17626973193276813, "train/image_loss_mean": 1.5658937722996429, "train/image_loss_std": 4.773077211998127, "train/model_loss_mean": 3.4093534880214267, "train/model_loss_std": 8.541141677785802, "train/model_opt_grad_norm": 32.9617292130435, "train/model_opt_grad_steps": 93019.0, "train/model_opt_loss": 7202.845996997975, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2112.2685185185187, "train/policy_entropy_mag": 2.623192516741929, "train/policy_entropy_max": 2.623192516741929, "train/policy_entropy_mean": 0.5889192304953381, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.7004240182814775, "train/policy_logprob_mag": 7.438383983241187, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5888638137667267, "train/policy_logprob_min": -7.438383983241187, "train/policy_logprob_std": 1.156944460063069, "train/policy_randomness_mag": 0.9258718427132677, "train/policy_randomness_max": 0.9258718427132677, "train/policy_randomness_mean": 0.2078626459395444, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.24721894054501145, "train/post_ent_mag": 43.3812758481061, "train/post_ent_max": 43.3812758481061, "train/post_ent_mean": 23.16472519768609, "train/post_ent_min": 11.824693260369477, "train/post_ent_std": 4.197322426018892, "train/prior_ent_mag": 75.25987653379087, "train/prior_ent_max": 75.25987653379087, "train/prior_ent_mean": 26.08956829706828, "train/prior_ent_min": 13.131258571589434, "train/prior_ent_std": 8.894451724158394, "train/rep_loss_mean": 2.955625981092453, "train/rep_loss_std": 7.754162572048329, "train/reward_avg": 0.018406954328788236, "train/reward_loss_mean": 0.06999811014436462, "train/reward_loss_std": 0.15267988632398624, "train/reward_max_data": 1.0109722531504102, "train/reward_max_pred": 1.011492560307185, "train/reward_neg_acc": 0.9992689095713474, "train/reward_neg_loss": 0.050469887891301406, "train/reward_pos_acc": 0.922417161917245, "train/reward_pos_loss": 0.7102023407264992, "train/reward_pred": 0.018275199458003044, "train/reward_rate": 0.029581705729166668, "train_stats/sum_log_reward": 4.407692285684439, "train_stats/max_log_achievement_collect_drink": 3.3846153846153846, "train_stats/max_log_achievement_collect_sapling": 2.5384615384615383, "train_stats/max_log_achievement_collect_wood": 2.3846153846153846, "train_stats/max_log_achievement_defeat_skeleton": 0.07692307692307693, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.07692307692307693, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 2.4615384615384617, "train_stats/max_log_achievement_place_table": 1.0, "train_stats/max_log_achievement_wake_up": 2.076923076923077, "train_stats/mean_log_entropy": 0.5612830840624295, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 1.215387555930647e-06, "report/cont_loss_std": 3.55964107257023e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 6.700669473502785e-06, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.2046531310261344e-06, "report/cont_pred": 0.9980457425117493, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 2.917694091796875, "report/dyn_loss_std": 7.8816328048706055, "report/image_loss_mean": 1.405517816543579, "report/image_loss_std": 3.7124555110931396, "report/model_loss_mean": 3.2202272415161133, "report/model_loss_std": 7.6842522621154785, "report/post_ent_mag": 34.656578063964844, "report/post_ent_max": 34.656578063964844, "report/post_ent_mean": 22.97093391418457, "report/post_ent_min": 12.32499885559082, "report/post_ent_std": 3.833864212036133, "report/prior_ent_mag": 75.527099609375, "report/prior_ent_max": 75.527099609375, "report/prior_ent_mean": 25.81598663330078, "report/prior_ent_min": 13.897738456726074, "report/prior_ent_std": 8.283506393432617, "report/rep_loss_mean": 2.917694091796875, "report/rep_loss_std": 7.8816328048706055, "report/reward_avg": 0.02466472238302231, "report/reward_loss_mean": 0.06409197300672531, "report/reward_loss_std": 0.11926478892564774, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0018279552459717, "report/reward_neg_acc": 0.998992919921875, "report/reward_neg_loss": 0.04509497806429863, "report/reward_pos_acc": 0.9677419066429138, "report/reward_pos_loss": 0.672608494758606, "report/reward_pred": 0.025126229971647263, "report/reward_rate": 0.0302734375, "eval/cont_avg": 0.9931640625, "eval/cont_loss_mean": 0.0016698024701327085, "eval/cont_loss_std": 0.0421220138669014, "eval/cont_neg_acc": 0.8571429252624512, "eval/cont_neg_loss": 0.24401706457138062, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 1.729036284814356e-06, "eval/cont_pred": 0.9942079782485962, "eval/cont_rate": 0.9931640625, "eval/dyn_loss_mean": 23.723466873168945, "eval/dyn_loss_std": 15.04816722869873, "eval/image_loss_mean": 35.51557540893555, "eval/image_loss_std": 35.80988693237305, "eval/model_loss_mean": 49.937347412109375, "eval/model_loss_std": 42.45012283325195, "eval/post_ent_mag": 47.721717834472656, "eval/post_ent_max": 47.721717834472656, "eval/post_ent_mean": 27.766141891479492, "eval/post_ent_min": 14.130485534667969, "eval/post_ent_std": 4.171536445617676, "eval/prior_ent_mag": 75.527099609375, "eval/prior_ent_max": 75.527099609375, "eval/prior_ent_mean": 37.43140411376953, "eval/prior_ent_min": 15.987203598022461, "eval/prior_ent_std": 9.705263137817383, "eval/rep_loss_mean": 23.723466873168945, "eval/rep_loss_std": 15.04816722869873, "eval/reward_avg": 0.01406249962747097, "eval/reward_loss_mean": 0.18602100014686584, "eval/reward_loss_std": 1.1340444087982178, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0014841556549072, "eval/reward_neg_acc": 0.9960159659385681, "eval/reward_neg_loss": 0.11948282271623611, "eval/reward_pos_acc": 0.6500000357627869, "eval/reward_pos_loss": 3.526237964630127, "eval/reward_pred": 0.011264467611908913, "eval/reward_rate": 0.01953125, "replay/size": 95230.0, "replay/inserts": 2157.0, "replay/samples": 34512.0, "replay/insert_wait_avg": 2.482780771339498e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.939686861422861e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 19464.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 8.493661880493164e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0043272972107, "timer/env.step_count": 269.0, "timer/env.step_total": 27.07115888595581, "timer/env.step_frac": 0.02707104174151239, "timer/env.step_avg": 0.10063627838645282, "timer/env.step_min": 0.023769378662109375, "timer/env.step_max": 1.726978063583374, "timer/replay._sample_count": 34512.0, "timer/replay._sample_total": 16.928518295288086, "timer/replay._sample_frac": 0.016928445040875078, "timer/replay._sample_avg": 0.0004905110771699145, "timer/replay._sample_min": 0.0003528594970703125, "timer/replay._sample_max": 0.034159183502197266, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 269.0, "timer/agent.policy_total": 4.2575602531433105, "timer/agent.policy_frac": 0.004257541829494427, "timer/agent.policy_avg": 0.01582736153584874, "timer/agent.policy_min": 0.014637470245361328, "timer/agent.policy_max": 0.04147791862487793, "timer/dataset_train_count": 2157.0, "timer/dataset_train_total": 0.3742814064025879, "timer/dataset_train_frac": 0.00037427978678271053, "timer/dataset_train_avg": 0.00017351942809577556, "timer/dataset_train_min": 9.059906005859375e-05, "timer/dataset_train_max": 0.00057220458984375, "timer/agent.train_count": 2157.0, "timer/agent.train_total": 957.8194842338562, "timer/agent.train_frac": 0.9578153394822093, "timer/agent.train_avg": 0.4440516848557516, "timer/agent.train_min": 0.43306899070739746, "timer/agent.train_max": 0.5649981498718262, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4724996089935303, "timer/agent.report_frac": 0.000472497564356138, "timer/agent.report_avg": 0.23624980449676514, "timer/agent.report_min": 0.2295970916748047, "timer/agent.report_max": 0.24290251731872559, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.075599670410156e-05, "timer/dataset_eval_frac": 3.075586361433873e-08, "timer/dataset_eval_avg": 3.075599670410156e-05, "timer/dataset_eval_min": 3.075599670410156e-05, "timer/dataset_eval_max": 3.075599670410156e-05, "fps": 2.1569619818007015}
{"step": 95816, "time": 44368.5842359066, "episode/length": 175.0, "episode/score": 4.2827952785359, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.18279511176513097}
{"step": 95856, "time": 44388.33060193062, "episode/length": 151.0, "episode/score": 3.205992652494274, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.10599260737023997}
{"step": 96008, "time": 44459.00355410576, "episode/length": 129.0, "episode/score": 3.218858481604343, "episode/reward_rate": 0.9923076923076923, "episode/intrinsic_return": 0.11885841275341136}
{"step": 96240, "time": 44566.31411194801, "episode/length": 174.0, "episode/score": 4.234520398353084, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.1345202650226156}
{"step": 96552, "time": 44711.03419852257, "episode/length": 38.0, "episode/score": 1.1442340649082325, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.04423397354548797}
{"step": 96672, "time": 44767.54772782326, "episode/length": 101.0, "episode/score": 4.201163466001162, "episode/reward_rate": 0.9509803921568627, "episode/intrinsic_return": 0.1011634242895525}
{"step": 96848, "time": 44849.36286306381, "episode/length": 171.0, "episode/score": 4.252778816022328, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.15277870754653122}
{"step": 96856, "time": 44854.535024642944, "episode/length": 147.0, "episode/score": 4.271065114215162, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.17106494392282912}
{"step": 97032, "time": 44935.85095524788, "episode/length": 189.0, "episode/score": 5.313102843243541, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.2131026507158822}
{"step": 97296, "time": 45057.69414687157, "episode/length": 198.0, "episode/score": 4.3038096504460555, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.20380947782541625}
{"step": 97328, "time": 45073.775884866714, "episode/length": 188.0, "episode/score": 4.28861131272788, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.18861118993299897}
{"step": 97584, "time": 45191.93525958061, "episode/length": 196.0, "episode/score": 4.293090470277093, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.19309034631805844}
{"step": 97885, "time": 45331.523655653, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.2944162767986915, "train/action_min": 0.0, "train/action_std": 4.016474202621815, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0409500707287428, "train/actor_opt_grad_steps": 95250.0, "train/actor_opt_loss": -16.54638938179976, "train/adv_mag": 0.6849960383980773, "train/adv_max": 0.6156564562819725, "train/adv_mean": 0.0017150671111534033, "train/adv_min": -0.5484916880380276, "train/adv_std": 0.05067730279162873, "train/cont_avg": 0.9943223110465116, "train/cont_loss_mean": 0.0001947148128279682, "train/cont_loss_std": 0.005938070228541929, "train/cont_neg_acc": 0.9932115177775538, "train/cont_neg_loss": 0.03408769514706914, "train/cont_pos_acc": 0.999990852211797, "train/cont_pos_loss": 1.3771296765597516e-05, "train/cont_pred": 0.9943364908528882, "train/cont_rate": 0.9943223110465116, "train/dyn_loss_mean": 3.013738462536834, "train/dyn_loss_std": 7.790663031644599, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0242649896200313, "train/extr_critic_critic_opt_grad_steps": 95250.0, "train/extr_critic_critic_opt_loss": 14716.813149527616, "train/extr_critic_mag": 10.537413619285406, "train/extr_critic_max": 10.537413619285406, "train/extr_critic_mean": 2.074755644243817, "train/extr_critic_min": -0.6307497723158015, "train/extr_critic_std": 2.272960944508397, "train/extr_return_normed_mag": 1.6521809500317242, "train/extr_return_normed_max": 1.6521809500317242, "train/extr_return_normed_mean": 0.33902625296004985, "train/extr_return_normed_min": -0.11108541623797527, "train/extr_return_normed_std": 0.34431301161300304, "train/extr_return_rate": 0.6496648243693418, "train/extr_return_raw_mag": 10.878328578416692, "train/extr_return_raw_max": 10.878328578416692, "train/extr_return_raw_mean": 2.0862374250278917, "train/extr_return_raw_min": -0.9286680911862573, "train/extr_return_raw_std": 2.305786998327388, "train/extr_reward_mag": 1.0204899288887201, "train/extr_reward_max": 1.0204899288887201, "train/extr_reward_mean": 0.031217467009501402, "train/extr_reward_min": -0.6842115818068039, "train/extr_reward_std": 0.17338765963565472, "train/image_loss_mean": 1.6306222297424493, "train/image_loss_std": 4.98094710416572, "train/model_loss_mean": 3.509777375154717, "train/model_loss_std": 8.765540859311127, "train/model_opt_grad_norm": 32.08828421304392, "train/model_opt_grad_steps": 95172.61395348837, "train/model_opt_loss": 8184.4318450218025, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2331.3953488372094, "train/policy_entropy_mag": 2.6177815670190854, "train/policy_entropy_max": 2.6177815670190854, "train/policy_entropy_mean": 0.612316502526749, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.711499169122341, "train/policy_logprob_mag": 7.4383840183879055, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.6122770958168562, "train/policy_logprob_min": -7.4383840183879055, "train/policy_logprob_std": 1.167636245904967, "train/policy_randomness_mag": 0.9239620128343272, "train/policy_randomness_max": 0.9239620128343272, "train/policy_randomness_mean": 0.21612085499042688, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.2511279831792033, "train/post_ent_mag": 43.81401379607445, "train/post_ent_max": 43.81401379607445, "train/post_ent_mean": 23.47035445279853, "train/post_ent_min": 12.162418698155603, "train/post_ent_std": 4.212315155739008, "train/prior_ent_mag": 75.28999928319178, "train/prior_ent_max": 75.28999928319178, "train/prior_ent_mean": 26.43640179301417, "train/prior_ent_min": 13.453284889043763, "train/prior_ent_std": 8.917646117543065, "train/rep_loss_mean": 3.013738462536834, "train/rep_loss_std": 7.790663031644599, "train/reward_avg": 0.018168068425946458, "train/reward_loss_mean": 0.07071736401250196, "train/reward_loss_std": 0.15461137284373128, "train/reward_max_data": 1.0091570072395857, "train/reward_max_pred": 1.0097074974414915, "train/reward_neg_acc": 0.999362962190495, "train/reward_neg_loss": 0.05101161557574605, "train/reward_pos_acc": 0.9178519157476204, "train/reward_pos_loss": 0.7105411110922347, "train/reward_pred": 0.018113936894291707, "train/reward_rate": 0.02982830668604651, "train_stats/sum_log_reward": 3.7666666011015573, "train_stats/max_log_achievement_collect_drink": 2.0833333333333335, "train_stats/max_log_achievement_collect_sapling": 1.9166666666666667, "train_stats/max_log_achievement_collect_wood": 2.8333333333333335, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.9166666666666667, "train_stats/max_log_achievement_place_table": 1.0833333333333333, "train_stats/max_log_achievement_wake_up": 2.0, "train_stats/mean_log_entropy": 0.4923940810064475, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 1.2869254533143248e-06, "report/cont_loss_std": 1.3293674783199094e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 3.628169906733092e-06, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.2684904504567385e-06, "report/cont_pred": 0.9921861886978149, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 2.8546857833862305, "report/dyn_loss_std": 8.090893745422363, "report/image_loss_mean": 1.7163276672363281, "report/image_loss_std": 4.497200965881348, "report/model_loss_mean": 3.499608278274536, "report/model_loss_std": 8.550628662109375, "report/post_ent_mag": 42.49490737915039, "report/post_ent_max": 42.49490737915039, "report/post_ent_mean": 22.789657592773438, "report/post_ent_min": 13.19293212890625, "report/post_ent_std": 3.958897829055786, "report/prior_ent_mag": 75.17977142333984, "report/prior_ent_max": 75.17977142333984, "report/prior_ent_mean": 25.689289093017578, "report/prior_ent_min": 13.948375701904297, "report/prior_ent_std": 8.798324584960938, "report/rep_loss_mean": 2.8546857833862305, "report/rep_loss_std": 8.090893745422363, "report/reward_avg": 0.016460150480270386, "report/reward_loss_mean": 0.07046784460544586, "report/reward_loss_std": 0.13055142760276794, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.004216194152832, "report/reward_neg_acc": 0.998992919921875, "report/reward_neg_loss": 0.051660213619470596, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6729185581207275, "report/reward_pred": 0.016634054481983185, "report/reward_rate": 0.0302734375, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 1.9539093045750633e-06, "eval/cont_loss_std": 1.0063395166071132e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 4.465893653105013e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.7022098290908616e-06, "eval/cont_pred": 0.9941391348838806, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 21.76897430419922, "eval/dyn_loss_std": 14.183544158935547, "eval/image_loss_mean": 36.11000061035156, "eval/image_loss_std": 49.41191101074219, "eval/model_loss_mean": 49.34813690185547, "eval/model_loss_std": 54.10567092895508, "eval/post_ent_mag": 45.84074401855469, "eval/post_ent_max": 45.84074401855469, "eval/post_ent_mean": 27.379411697387695, "eval/post_ent_min": 14.745405197143555, "eval/post_ent_std": 3.58870267868042, "eval/prior_ent_mag": 75.17977142333984, "eval/prior_ent_max": 75.17977142333984, "eval/prior_ent_mean": 35.93431854248047, "eval/prior_ent_min": 14.865473747253418, "eval/prior_ent_std": 8.662891387939453, "eval/rep_loss_mean": 21.76897430419922, "eval/rep_loss_std": 14.183544158935547, "eval/reward_avg": 0.0126953125, "eval/reward_loss_mean": 0.1767488420009613, "eval/reward_loss_std": 1.075941562652588, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0006752014160156, "eval/reward_neg_acc": 0.9960159659385681, "eval/reward_neg_loss": 0.09953396767377853, "eval/reward_pos_acc": 0.6000000238418579, "eval/reward_pos_loss": 4.05293607711792, "eval/reward_pred": 0.007840449921786785, "eval/reward_rate": 0.01953125, "replay/size": 97381.0, "replay/inserts": 2151.0, "replay/samples": 34416.0, "replay/insert_wait_avg": 2.5311607030977597e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.933638695504487e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 19464.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 7.748603820800781e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.302859544754, "timer/env.step_count": 269.0, "timer/env.step_total": 25.486002922058105, "timer/env.step_frac": 0.02547828657978344, "timer/env.step_avg": 0.09474350528646136, "timer/env.step_min": 0.024321556091308594, "timer/env.step_max": 1.6459128856658936, "timer/replay._sample_count": 34416.0, "timer/replay._sample_total": 16.87651538848877, "timer/replay._sample_frac": 0.016871405722232374, "timer/replay._sample_avg": 0.0004903682992936067, "timer/replay._sample_min": 0.0003535747528076172, "timer/replay._sample_max": 0.019831418991088867, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 269.0, "timer/agent.policy_total": 4.282902002334595, "timer/agent.policy_frac": 0.004281605277309492, "timer/agent.policy_avg": 0.015921568781912993, "timer/agent.policy_min": 0.014660120010375977, "timer/agent.policy_max": 0.04696464538574219, "timer/dataset_train_count": 2151.0, "timer/dataset_train_total": 0.38774561882019043, "timer/dataset_train_frac": 0.00038762822191336794, "timer/dataset_train_avg": 0.00018026295621580214, "timer/dataset_train_min": 9.107589721679688e-05, "timer/dataset_train_max": 0.0006725788116455078, "timer/agent.train_count": 2151.0, "timer/agent.train_total": 959.588508605957, "timer/agent.train_frac": 0.9592979760576448, "timer/agent.train_avg": 0.44611274226218367, "timer/agent.train_min": 0.43514013290405273, "timer/agent.train_max": 0.5753703117370605, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4779391288757324, "timer/agent.report_frac": 0.0004777944242739108, "timer/agent.report_avg": 0.2389695644378662, "timer/agent.report_min": 0.23316431045532227, "timer/agent.report_max": 0.24477481842041016, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 4.982948303222656e-05, "timer/dataset_eval_frac": 4.9814396266850986e-08, "timer/dataset_eval_avg": 4.982948303222656e-05, "timer/dataset_eval_min": 4.982948303222656e-05, "timer/dataset_eval_max": 4.982948303222656e-05, "fps": 2.15031990782626}
{"step": 97952, "time": 45362.30594277382, "episode/length": 159.0, "episode/score": 5.260398282045571, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.16039813061252062}
{"step": 97952, "time": 45362.31473827362, "episode/length": 174.0, "episode/score": 4.28142138068506, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.18142125789017882}
{"step": 98568, "time": 45646.32394862175, "episode/length": 213.0, "episode/score": 5.3225162675207685, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.2225160557845811}
{"step": 98600, "time": 45662.291647195816, "episode/length": 158.0, "episode/score": 4.243134479900618, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.1431343269541685}
{"step": 98600, "time": 45662.300043821335, "episode/length": 218.0, "episode/score": 5.317289653468833, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.21728957159393758}
{"step": 98736, "time": 45727.05374622345, "episode/length": 143.0, "episode/score": 6.248101617280554, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.1481013502470887}
{"step": 98888, "time": 45797.76840853691, "episode/length": 35.0, "episode/score": 1.1411250534583814, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.04112499934853986}
{"step": 98912, "time": 45810.198546886444, "episode/length": 234.0, "episode/score": 6.357524352561086, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.257524115329943}
{"step": 98968, "time": 45837.21741724014, "episode/length": 208.0, "episode/score": 6.305533441842272, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.20553330612528953}
{"step": 99160, "time": 45925.749083042145, "episode/length": 150.0, "episode/score": 4.246328060162341, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.14632798038292094}
{"step": 99368, "time": 46021.660408973694, "episode/length": 176.0, "episode/score": 5.2844756079721265, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.18447541777277365}
{"step": 99848, "time": 46241.02437710762, "episode/length": 155.0, "episode/score": 2.1948014371628233, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.09480140364030376}
{"step": 99976, "time": 46300.73264336586, "episode/length": 175.0, "episode/score": 0.28296052898258495, "episode/reward_rate": 0.9545454545454546, "episode/intrinsic_return": 0.1829605332841311}
{"step": 100039, "time": 46331.54267811775, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.349477084847384, "train/action_min": 0.0, "train/action_std": 4.059001670881759, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04411781743861908, "train/actor_opt_grad_steps": 97400.0, "train/actor_opt_loss": -11.699369329266077, "train/adv_mag": 0.7756792855817218, "train/adv_max": 0.7209472909916279, "train/adv_mean": 0.003674413989701438, "train/adv_min": -0.5867116463045742, "train/adv_std": 0.05508147613253704, "train/cont_avg": 0.9942450944767441, "train/cont_loss_mean": 2.2674352182844435e-05, "train/cont_loss_std": 0.0006643240522190924, "train/cont_neg_acc": 1.0, "train/cont_neg_loss": 0.0007193767165304222, "train/cont_pos_acc": 0.9999954154325086, "train/cont_pos_loss": 1.7811081309956577e-05, "train/cont_pred": 0.9942364188127739, "train/cont_rate": 0.9942450944767441, "train/dyn_loss_mean": 2.9883655769880426, "train/dyn_loss_std": 7.805310786047647, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.06706805839095, "train/extr_critic_critic_opt_grad_steps": 97400.0, "train/extr_critic_critic_opt_loss": 14807.125454215116, "train/extr_critic_mag": 11.652519871467767, "train/extr_critic_max": 11.652519871467767, "train/extr_critic_mean": 2.1217213647310125, "train/extr_critic_min": -0.6430158748183139, "train/extr_critic_std": 2.3566483630690462, "train/extr_return_normed_mag": 1.742871123136476, "train/extr_return_normed_max": 1.742871123136476, "train/extr_return_normed_mean": 0.3367324226124342, "train/extr_return_normed_min": -0.11052617673263994, "train/extr_return_normed_std": 0.3461101702479429, "train/extr_return_rate": 0.6189856196558753, "train/extr_return_raw_mag": 11.99193937168565, "train/extr_return_raw_max": 11.99193937168565, "train/extr_return_raw_mean": 2.1476956029270973, "train/extr_return_raw_min": -0.965771375423254, "train/extr_return_raw_std": 2.414063992056736, "train/extr_reward_mag": 1.0264344980550366, "train/extr_reward_max": 1.0264344980550366, "train/extr_reward_mean": 0.032197927683591844, "train/extr_reward_min": -0.6717773808989413, "train/extr_reward_std": 0.17536242455244064, "train/image_loss_mean": 1.6218522590260174, "train/image_loss_std": 4.879666309578474, "train/model_loss_mean": 3.4858900702276894, "train/model_loss_std": 8.677372369100881, "train/model_opt_grad_norm": 32.59928983643997, "train/model_opt_grad_steps": 97320.18604651163, "train/model_opt_loss": 6706.773012808866, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1918.6046511627908, "train/policy_entropy_mag": 2.632739026047463, "train/policy_entropy_max": 2.632739026047463, "train/policy_entropy_mean": 0.6257189006306404, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.7173966165198836, "train/policy_logprob_mag": 7.438383989555891, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.625693338554959, "train/policy_logprob_min": -7.438383989555891, "train/policy_logprob_std": 1.1734169325163197, "train/policy_randomness_mag": 0.9292413414910782, "train/policy_randomness_max": 0.9292413414910782, "train/policy_randomness_mean": 0.22085131586984147, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.2532095220199851, "train/post_ent_mag": 43.95382167017737, "train/post_ent_max": 43.95382167017737, "train/post_ent_mean": 23.67834333375443, "train/post_ent_min": 12.416684749514557, "train/post_ent_std": 4.249203457943229, "train/prior_ent_mag": 75.36735282720521, "train/prior_ent_max": 75.36735282720521, "train/prior_ent_mean": 26.612865235084712, "train/prior_ent_min": 13.677291187020236, "train/prior_ent_std": 8.908957073300384, "train/rep_loss_mean": 2.9883655769880426, "train/rep_loss_std": 7.805310786047647, "train/reward_avg": 0.01857113732284931, "train/reward_loss_mean": 0.07099579884562382, "train/reward_loss_std": 0.1545365463509116, "train/reward_max_data": 1.0110174727994343, "train/reward_max_pred": 1.0122949688933616, "train/reward_neg_acc": 0.9993019284203996, "train/reward_neg_loss": 0.05087254593192145, "train/reward_pos_acc": 0.9245911994645762, "train/reward_pos_loss": 0.716431689539621, "train/reward_pred": 0.018397432175833124, "train/reward_rate": 0.030246184593023254, "train_stats/sum_log_reward": 4.176922999895536, "train_stats/max_log_achievement_collect_drink": 2.6923076923076925, "train_stats/max_log_achievement_collect_sapling": 1.9230769230769231, "train_stats/max_log_achievement_collect_wood": 3.8461538461538463, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.07692307692307693, "train_stats/max_log_achievement_make_wood_pickaxe": 0.07692307692307693, "train_stats/max_log_achievement_make_wood_sword": 0.07692307692307693, "train_stats/max_log_achievement_place_plant": 1.4615384615384615, "train_stats/max_log_achievement_place_table": 1.5384615384615385, "train_stats/max_log_achievement_wake_up": 2.3076923076923075, "train_stats/mean_log_entropy": 0.5097977140775094, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 3.0063692975090817e-06, "report/cont_loss_std": 6.0552476497832686e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00043281129910610616, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 8.974150205176556e-07, "report/cont_pred": 0.9951183199882507, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 2.818896770477295, "report/dyn_loss_std": 8.01922607421875, "report/image_loss_mean": 1.4709374904632568, "report/image_loss_std": 3.201981544494629, "report/model_loss_mean": 3.2295422554016113, "report/model_loss_std": 7.457482814788818, "report/post_ent_mag": 41.2514533996582, "report/post_ent_max": 41.2514533996582, "report/post_ent_mean": 22.73190689086914, "report/post_ent_min": 10.665445327758789, "report/post_ent_std": 5.233290672302246, "report/prior_ent_mag": 75.34576416015625, "report/prior_ent_max": 75.34576416015625, "report/prior_ent_mean": 25.443574905395508, "report/prior_ent_min": 12.944040298461914, "report/prior_ent_std": 9.368152618408203, "report/rep_loss_mean": 2.818896770477295, "report/rep_loss_std": 8.01922607421875, "report/reward_avg": 0.01868683472275734, "report/reward_loss_mean": 0.06726367771625519, "report/reward_loss_std": 0.1268995851278305, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0163195133209229, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.04771989583969116, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6731210947036743, "report/reward_pred": 0.018762104213237762, "report/reward_rate": 0.03125, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 1.0925499509539804e-06, "eval/cont_loss_std": 5.859622888237936e-06, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 9.762046101968735e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 8.089223797469458e-07, "eval/cont_pred": 0.9970697164535522, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 24.443302154541016, "eval/dyn_loss_std": 12.992691993713379, "eval/image_loss_mean": 38.15660095214844, "eval/image_loss_std": 42.16944885253906, "eval/model_loss_mean": 52.97309112548828, "eval/model_loss_std": 47.20810317993164, "eval/post_ent_mag": 39.80405807495117, "eval/post_ent_max": 39.80405807495117, "eval/post_ent_mean": 28.049299240112305, "eval/post_ent_min": 17.9622802734375, "eval/post_ent_std": 3.3531017303466797, "eval/prior_ent_mag": 75.34576416015625, "eval/prior_ent_max": 75.34576416015625, "eval/prior_ent_mean": 38.73937225341797, "eval/prior_ent_min": 21.136394500732422, "eval/prior_ent_std": 8.088545799255371, "eval/rep_loss_mean": 24.443302154541016, "eval/rep_loss_std": 12.992691993713379, "eval/reward_avg": 0.02763671800494194, "eval/reward_loss_mean": 0.15051203966140747, "eval/reward_loss_std": 0.9997851848602295, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0108294486999512, "eval/reward_neg_acc": 0.9979858994483948, "eval/reward_neg_loss": 0.046240199357271194, "eval/reward_pos_acc": 0.6451612710952759, "eval/reward_pos_loss": 3.490574359893799, "eval/reward_pred": 0.016159161925315857, "eval/reward_rate": 0.0302734375, "replay/size": 99535.0, "replay/inserts": 2154.0, "replay/samples": 34464.0, "replay/insert_wait_avg": 2.4886737848280088e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.640961263615884e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 19464.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 8.791685104370117e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0049769878387, "timer/env.step_count": 269.0, "timer/env.step_total": 27.306521892547607, "timer/env.step_frac": 0.02730638598899662, "timer/env.step_avg": 0.10151123380129222, "timer/env.step_min": 0.02402782440185547, "timer/env.step_max": 3.4151854515075684, "timer/replay._sample_count": 34464.0, "timer/replay._sample_total": 16.573796272277832, "timer/replay._sample_frac": 0.01657371378510588, "timer/replay._sample_avg": 0.0004809017024221748, "timer/replay._sample_min": 0.00036072731018066406, "timer/replay._sample_max": 0.028763771057128906, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 269.0, "timer/agent.policy_total": 4.108189582824707, "timer/agent.policy_frac": 0.004108169136516875, "timer/agent.policy_avg": 0.015272080233549097, "timer/agent.policy_min": 0.01441812515258789, "timer/agent.policy_max": 0.017453908920288086, "timer/dataset_train_count": 2154.0, "timer/dataset_train_total": 0.3879415988922119, "timer/dataset_train_frac": 0.0003879396681212015, "timer/dataset_train_avg": 0.00018010287785153757, "timer/dataset_train_min": 9.107589721679688e-05, "timer/dataset_train_max": 0.0010662078857421875, "timer/agent.train_count": 2154.0, "timer/agent.train_total": 957.9641771316528, "timer/agent.train_frac": 0.9579594093793223, "timer/agent.train_avg": 0.44473731528860394, "timer/agent.train_min": 0.4322545528411865, "timer/agent.train_max": 0.5692358016967773, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47684645652770996, "timer/agent.report_frac": 0.0004768440832805065, "timer/agent.report_avg": 0.23842322826385498, "timer/agent.report_min": 0.231109619140625, "timer/agent.report_max": 0.24573683738708496, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9802322387695312e-05, "timer/dataset_eval_frac": 2.9802174062637435e-08, "timer/dataset_eval_avg": 2.9802322387695312e-05, "timer/dataset_eval_min": 2.9802322387695312e-05, "timer/dataset_eval_max": 2.9802322387695312e-05, "fps": 2.1539588317609435}
{"step": 100040, "time": 46332.18017363548, "episode/length": 143.0, "episode/score": 3.2414457175764255, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.14144553645746782}
{"step": 100048, "time": 46356.89820766449, "eval_episode/length": 153.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9675324675324676}
{"step": 100048, "time": 46358.946548461914, "eval_episode/length": 165.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9939759036144579}
{"step": 100048, "time": 46360.55459570885, "eval_episode/length": 169.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9941176470588236}
{"step": 100048, "time": 46362.5929248333, "eval_episode/length": 179.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 100048, "time": 46364.49045777321, "eval_episode/length": 182.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9726775956284153}
{"step": 100048, "time": 46367.268681287766, "eval_episode/length": 211.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9764150943396226}
{"step": 100048, "time": 46369.05430483818, "eval_episode/length": 218.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9817351598173516}
{"step": 100048, "time": 46370.90500807762, "eval_episode/length": 226.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9955947136563876}
{"step": 100096, "time": 46392.64029073715, "episode/length": 169.0, "episode/score": 5.281180052003947, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.18117989940674306}
{"step": 100352, "time": 46509.61434340477, "episode/length": 179.0, "episode/score": 5.271420044550723, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.17141990743675706}
{"step": 100664, "time": 46651.76657485962, "episode/length": 211.0, "episode/score": 4.336061546147903, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.23606142568132782}
{"step": 100800, "time": 46714.58680558205, "episode/length": 204.0, "episode/score": 5.3423684323852285, "episode/reward_rate": 0.9707317073170731, "episode/intrinsic_return": 0.24236829876372212}
{"step": 100992, "time": 46803.0074198246, "episode/length": 40.0, "episode/score": 2.144690599612659, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.04469047553720884}
{"step": 101040, "time": 46826.289404153824, "episode/length": 208.0, "episode/score": 5.306033444578134, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.2060332676210237}
{"step": 101040, "time": 46826.29763507843, "episode/length": 148.0, "episode/score": 5.2565827702565, "episode/reward_rate": 0.9731543624161074, "episode/intrinsic_return": 0.15658261765929637}
{"step": 101336, "time": 46963.87585926056, "episode/length": 36.0, "episode/score": -0.881172581723149, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.01882738186213828}
{"step": 101360, "time": 46976.398829221725, "episode/length": 172.0, "episode/score": 2.269777376248385, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.16977732737723272}
{"step": 101440, "time": 47014.00238585472, "episode/length": 167.0, "episode/score": 4.259547007095534, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.15954685379983857}
{"step": 101504, "time": 47044.33947348595, "episode/length": 182.0, "episode/score": 4.286715802050821, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.18671574415748182}
{"step": 101568, "time": 47074.79653096199, "episode/length": 151.0, "episode/score": 4.267364280399306, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.16736431860681478}
{"step": 102132, "time": 47331.72079062462, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.234010242280506, "train/action_min": 0.0, "train/action_std": 4.097957188742502, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04427115985502799, "train/actor_opt_grad_steps": 99525.0, "train/actor_opt_loss": -12.86843783863421, "train/adv_mag": 0.7134624282519023, "train/adv_max": 0.6515524150360198, "train/adv_mean": 0.0021411349973017683, "train/adv_min": -0.5655591301974796, "train/adv_std": 0.05570174462738491, "train/cont_avg": 0.9943126860119048, "train/cont_loss_mean": 0.00015569818457920735, "train/cont_loss_std": 0.004865898321038133, "train/cont_neg_acc": 0.9984126987911406, "train/cont_neg_loss": 0.014446103320776837, "train/cont_pos_acc": 0.9999906074433099, "train/cont_pos_loss": 7.482118769314097e-05, "train/cont_pred": 0.9943118983790988, "train/cont_rate": 0.9943126860119048, "train/dyn_loss_mean": 2.988903458913167, "train/dyn_loss_std": 7.767701537268502, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0739783692927587, "train/extr_critic_critic_opt_grad_steps": 99525.0, "train/extr_critic_critic_opt_loss": 15293.417643229166, "train/extr_critic_mag": 12.643953096298944, "train/extr_critic_max": 12.643953096298944, "train/extr_critic_mean": 2.337903206121354, "train/extr_critic_min": -0.6482149714515323, "train/extr_critic_std": 2.6061415167081923, "train/extr_return_normed_mag": 1.6618031024932862, "train/extr_return_normed_max": 1.6618031024932862, "train/extr_return_normed_mean": 0.32284705880142395, "train/extr_return_normed_min": -0.09571285570661227, "train/extr_return_normed_std": 0.332583080586933, "train/extr_return_rate": 0.6456237944818678, "train/extr_return_raw_mag": 13.053736346108574, "train/extr_return_raw_max": 13.053736346108574, "train/extr_return_raw_mean": 2.35507010335014, "train/extr_return_raw_min": -0.9731557709830148, "train/extr_return_raw_std": 2.655389778954642, "train/extr_reward_mag": 1.0218985080718994, "train/extr_reward_max": 1.0218985080718994, "train/extr_reward_mean": 0.03153625023329542, "train/extr_reward_min": -0.669103265376318, "train/extr_reward_std": 0.17394992098921822, "train/image_loss_mean": 1.5218758324782053, "train/image_loss_std": 4.763140124366397, "train/model_loss_mean": 3.3861474582127165, "train/model_loss_std": 8.550277344385783, "train/model_opt_grad_norm": 31.928940346127465, "train/model_opt_grad_steps": 99443.09047619048, "train/model_opt_loss": 5521.716377185639, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1630.952380952381, "train/policy_entropy_mag": 2.647821210679554, "train/policy_entropy_max": 2.647821210679554, "train/policy_entropy_mean": 0.6274735199553626, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.7275649592989967, "train/policy_logprob_mag": 7.438383978889102, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.6272160757155646, "train/policy_logprob_min": -7.438383978889102, "train/policy_logprob_std": 1.1767619768778483, "train/policy_randomness_mag": 0.9345646895113445, "train/policy_randomness_max": 0.9345646895113445, "train/policy_randomness_mean": 0.22147061760936465, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.2567985028028488, "train/post_ent_mag": 44.23321861993699, "train/post_ent_max": 44.23321861993699, "train/post_ent_mean": 23.95544047582717, "train/post_ent_min": 12.304084823245095, "train/post_ent_std": 4.32409629594712, "train/prior_ent_mag": 75.4495822724842, "train/prior_ent_max": 75.4495822724842, "train/prior_ent_mean": 26.90031839098249, "train/prior_ent_min": 13.577474921090262, "train/prior_ent_std": 8.924303790501186, "train/rep_loss_mean": 2.988903458913167, "train/rep_loss_std": 7.767701537268502, "train/reward_avg": 0.01849977344141475, "train/reward_loss_mean": 0.07077384374680973, "train/reward_loss_std": 0.15642521927754086, "train/reward_max_data": 1.006488125097184, "train/reward_max_pred": 1.0078643935067313, "train/reward_neg_acc": 0.999324647585551, "train/reward_neg_loss": 0.05076955155957313, "train/reward_pos_acc": 0.9225348214308421, "train/reward_pos_loss": 0.7196048713865735, "train/reward_pred": 0.018346523941450175, "train/reward_rate": 0.029952566964285714, "train_stats/sum_log_reward": 3.71538454752702, "train_stats/max_log_achievement_collect_drink": 2.3846153846153846, "train_stats/max_log_achievement_collect_sapling": 1.6923076923076923, "train_stats/max_log_achievement_collect_wood": 2.076923076923077, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.15384615384615385, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.4615384615384615, "train_stats/max_log_achievement_place_table": 0.8461538461538461, "train_stats/max_log_achievement_wake_up": 1.7692307692307692, "train_stats/mean_log_entropy": 0.5160729541228368, "eval_stats/sum_log_reward": 4.099999904632568, "eval_stats/max_log_achievement_collect_drink": 3.625, "eval_stats/max_log_achievement_collect_sapling": 2.5, "eval_stats/max_log_achievement_collect_wood": 2.25, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.125, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 1.75, "eval_stats/max_log_achievement_place_table": 0.875, "eval_stats/max_log_achievement_wake_up": 2.125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.00026200138381682336, "report/cont_loss_std": 0.00770904403179884, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 4.965425978298299e-05, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0002634629490785301, "report/cont_pred": 0.9929301738739014, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 2.8422646522521973, "report/dyn_loss_std": 7.67288875579834, "report/image_loss_mean": 0.8078393936157227, "report/image_loss_std": 3.260171890258789, "report/model_loss_mean": 2.583122968673706, "report/model_loss_std": 7.235845565795898, "report/post_ent_mag": 46.18628692626953, "report/post_ent_max": 46.18628692626953, "report/post_ent_mean": 24.654747009277344, "report/post_ent_min": 13.745284080505371, "report/post_ent_std": 3.8604671955108643, "report/prior_ent_mag": 75.41948699951172, "report/prior_ent_max": 75.41948699951172, "report/prior_ent_mean": 27.38490867614746, "report/prior_ent_min": 15.656397819519043, "report/prior_ent_std": 8.654871940612793, "report/rep_loss_mean": 2.8422646522521973, "report/rep_loss_std": 7.67288875579834, "report/reward_avg": 0.017193950712680817, "report/reward_loss_mean": 0.0696626752614975, "report/reward_loss_std": 0.13451841473579407, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0023937225341797, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.05081157386302948, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6735060811042786, "report/reward_pred": 0.017198000103235245, "report/reward_rate": 0.0302734375, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 1.324878576269839e-05, "eval/cont_loss_std": 5.508227332029492e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0004927346017211676, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 1.1368449122528546e-05, "eval/cont_pred": 0.9960843324661255, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 25.270248413085938, "eval/dyn_loss_std": 13.44149112701416, "eval/image_loss_mean": 33.57036590576172, "eval/image_loss_std": 32.249210357666016, "eval/model_loss_mean": 48.866329193115234, "eval/model_loss_std": 37.9986686706543, "eval/post_ent_mag": 46.18628692626953, "eval/post_ent_max": 46.18628692626953, "eval/post_ent_mean": 27.749990463256836, "eval/post_ent_min": 14.457409858703613, "eval/post_ent_std": 3.9255199432373047, "eval/prior_ent_mag": 75.41948699951172, "eval/prior_ent_max": 75.41948699951172, "eval/prior_ent_mean": 37.85681915283203, "eval/prior_ent_min": 16.517765045166016, "eval/prior_ent_std": 8.662705421447754, "eval/rep_loss_mean": 25.270248413085938, "eval/rep_loss_std": 13.44149112701416, "eval/reward_avg": 0.01728515699505806, "eval/reward_loss_mean": 0.13379985094070435, "eval/reward_loss_std": 1.0353130102157593, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0028998851776123, "eval/reward_neg_acc": 0.9930209517478943, "eval/reward_neg_loss": 0.09501545876264572, "eval/reward_pos_acc": 0.8095238208770752, "eval/reward_pos_loss": 1.98621666431427, "eval/reward_pred": 0.019109763205051422, "eval/reward_rate": 0.0205078125, "replay/size": 101628.0, "replay/inserts": 2093.0, "replay/samples": 33488.0, "replay/insert_wait_avg": 2.476226981610017e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.740487564823243e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 21280.0, "eval_replay/inserts": 1816.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2344988432224628e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.450580596923828e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1631393432617, "timer/env.step_count": 262.0, "timer/env.step_total": 26.720484733581543, "timer/env.step_frac": 0.026716126282285355, "timer/env.step_avg": 0.10198658295260131, "timer/env.step_min": 0.023366928100585938, "timer/env.step_max": 3.1970877647399902, "timer/replay._sample_count": 33488.0, "timer/replay._sample_total": 15.780635833740234, "timer/replay._sample_frac": 0.015778061811098427, "timer/replay._sample_avg": 0.000471232555952587, "timer/replay._sample_min": 0.0003337860107421875, "timer/replay._sample_max": 0.02921748161315918, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 489.0, "timer/agent.policy_total": 7.617295265197754, "timer/agent.policy_frac": 0.00761605278734778, "timer/agent.policy_avg": 0.015577290930874753, "timer/agent.policy_min": 0.009589910507202148, "timer/agent.policy_max": 0.026014328002929688, "timer/dataset_train_count": 2093.0, "timer/dataset_train_total": 0.37213134765625, "timer/dataset_train_frac": 0.00037207064829504016, "timer/dataset_train_avg": 0.00017779806385869566, "timer/dataset_train_min": 9.179115295410156e-05, "timer/dataset_train_max": 0.0008418560028076172, "timer/agent.train_count": 2093.0, "timer/agent.train_total": 926.0298223495483, "timer/agent.train_frac": 0.9258787750942395, "timer/agent.train_avg": 0.44244138669352523, "timer/agent.train_min": 0.43182873725891113, "timer/agent.train_max": 0.6052258014678955, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4748523235321045, "timer/agent.report_frac": 0.00047477486907176694, "timer/agent.report_avg": 0.23742616176605225, "timer/agent.report_min": 0.23068904876708984, "timer/agent.report_max": 0.24416327476501465, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.574920654296875e-05, "timer/dataset_eval_frac": 2.5745006519512887e-08, "timer/dataset_eval_avg": 2.574920654296875e-05, "timer/dataset_eval_min": 2.574920654296875e-05, "timer/dataset_eval_max": 2.574920654296875e-05, "fps": 2.0926317828723064}
{"step": 102176, "time": 47351.764441013336, "episode/length": 171.0, "episode/score": 5.25946240513349, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.15946244235146878}
{"step": 102240, "time": 47382.35032272339, "episode/length": 149.0, "episode/score": 4.245287907749116, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.14528775683993445}
{"step": 102336, "time": 47427.51801490784, "episode/length": 167.0, "episode/score": 3.2680103804214014, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.16801034511263424}
{"step": 102664, "time": 47577.66076207161, "episode/length": 162.0, "episode/score": 2.259403753399056, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.15940373665853258}
{"step": 102928, "time": 47698.92164206505, "episode/length": 185.0, "episode/score": 1.243472058282805, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.143471998570476}
{"step": 103032, "time": 47747.69931221008, "episode/length": 182.0, "episode/score": 3.243768728069881, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.14376869916395663}
{"step": 103136, "time": 47796.20555186272, "episode/length": 224.0, "episode/score": 3.3388688376317077, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.23886868666431837}
{"step": 103192, "time": 47823.097526073456, "episode/length": 210.0, "episode/score": 4.315016108014333, "episode/reward_rate": 0.9715639810426541, "episode/intrinsic_return": 0.21501598540862688}
{"step": 103344, "time": 47893.600487947464, "episode/length": 125.0, "episode/score": 3.2133674215924657, "episode/reward_rate": 0.9603174603174603, "episode/intrinsic_return": 0.11336726713261669}
{"step": 103360, "time": 47902.33345746994, "episode/length": 147.0, "episode/score": 3.244841730101143, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.14484163478027767}
{"step": 103784, "time": 48096.053383111954, "episode/length": 192.0, "episode/score": 4.262902556501558, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.16290245413756566}
{"step": 103984, "time": 48188.18085503578, "episode/length": 164.0, "episode/score": 3.255369252685796, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.1553692222664722}
{"step": 104296, "time": 48331.741569280624, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.055013020833333, "train/action_min": 0.0, "train/action_std": 3.8637546322963856, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04206327632655976, "train/actor_opt_grad_steps": 101655.0, "train/actor_opt_loss": -13.530425510196775, "train/adv_mag": 0.6690975150300397, "train/adv_max": 0.6190352775156498, "train/adv_mean": 0.002035896447818299, "train/adv_min": -0.527046829186104, "train/adv_std": 0.05322135089793139, "train/cont_avg": 0.9942265263310185, "train/cont_loss_mean": 1.2153196013602812e-05, "train/cont_loss_std": 0.0003128563052962258, "train/cont_neg_acc": 0.9990740741292635, "train/cont_neg_loss": 0.0017158680800253864, "train/cont_pos_acc": 0.9999999842709966, "train/cont_pos_loss": 3.5475954026272425e-06, "train/cont_pred": 0.9942282217520254, "train/cont_rate": 0.9942265263310185, "train/dyn_loss_mean": 3.0319606209242784, "train/dyn_loss_std": 7.784334244551482, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.070624227601069, "train/extr_critic_critic_opt_grad_steps": 101655.0, "train/extr_critic_critic_opt_loss": 15032.281204788773, "train/extr_critic_mag": 11.506564246283638, "train/extr_critic_max": 11.506564246283638, "train/extr_critic_mean": 2.2589553401426032, "train/extr_critic_min": -0.6458126096813767, "train/extr_critic_std": 2.4263753156971046, "train/extr_return_normed_mag": 1.6406119912862778, "train/extr_return_normed_max": 1.6406119912862778, "train/extr_return_normed_mean": 0.3387321597310128, "train/extr_return_normed_min": -0.10447940489070283, "train/extr_return_normed_std": 0.33632215926492653, "train/extr_return_rate": 0.7093075213057024, "train/extr_return_raw_mag": 11.820104537186799, "train/extr_return_raw_max": 11.820104537186799, "train/extr_return_raw_mean": 2.2738533693331258, "train/extr_return_raw_min": -0.9722685918763831, "train/extr_return_raw_std": 2.464571093519529, "train/extr_reward_mag": 1.0230535445389923, "train/extr_reward_max": 1.0230535445389923, "train/extr_reward_mean": 0.0307524187826655, "train/extr_reward_min": -0.6668226150450883, "train/extr_reward_std": 0.17253738945281064, "train/image_loss_mean": 1.547463812485889, "train/image_loss_std": 4.770990211654593, "train/model_loss_mean": 3.4374355022554046, "train/model_loss_std": 8.55769517465874, "train/model_opt_grad_norm": 32.99645453470725, "train/model_opt_grad_steps": 101571.64351851853, "train/model_opt_loss": 7459.151760525174, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2170.1388888888887, "train/policy_entropy_mag": 2.6330072151290045, "train/policy_entropy_max": 2.6330072151290045, "train/policy_entropy_mean": 0.5982397604319785, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.7027625190439047, "train/policy_logprob_mag": 7.438383996486664, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5982019084471243, "train/policy_logprob_min": -7.438383996486664, "train/policy_logprob_std": 1.1615967562905065, "train/policy_randomness_mag": 0.9293360025794418, "train/policy_randomness_max": 0.9293360025794418, "train/policy_randomness_mean": 0.2111523846095359, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.248044328764081, "train/post_ent_mag": 44.494674876884176, "train/post_ent_max": 44.494674876884176, "train/post_ent_mean": 24.218793630599976, "train/post_ent_min": 12.39671097640638, "train/post_ent_std": 4.333075364430745, "train/prior_ent_mag": 75.44987441875317, "train/prior_ent_max": 75.44987441875317, "train/prior_ent_mean": 27.195993732523036, "train/prior_ent_min": 13.717773993810018, "train/prior_ent_std": 8.88902414728094, "train/rep_loss_mean": 3.0319606209242784, "train/rep_loss_std": 7.784334244551482, "train/reward_avg": 0.018284806323073874, "train/reward_loss_mean": 0.07078313349780661, "train/reward_loss_std": 0.15655821058209296, "train/reward_max_data": 1.0128241054437779, "train/reward_max_pred": 1.0132078506328441, "train/reward_neg_acc": 0.9992774846377196, "train/reward_neg_loss": 0.051047595511018125, "train/reward_pos_acc": 0.9219559908465103, "train/reward_pos_loss": 0.7185577446663821, "train/reward_pred": 0.018209007913591684, "train/reward_rate": 0.029631438078703703, "train_stats/sum_log_reward": 3.266666611035665, "train_stats/max_log_achievement_collect_drink": 3.8333333333333335, "train_stats/max_log_achievement_collect_sapling": 1.5833333333333333, "train_stats/max_log_achievement_collect_wood": 2.25, "train_stats/max_log_achievement_defeat_skeleton": 0.08333333333333333, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.3333333333333333, "train_stats/max_log_achievement_place_table": 1.0, "train_stats/max_log_achievement_wake_up": 2.25, "train_stats/mean_log_entropy": 0.5797097956140836, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 5.652467507388792e-07, "report/cont_loss_std": 1.075457703336724e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 1.1468610864540096e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 5.009833330404945e-07, "report/cont_pred": 0.9941402673721313, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 2.958845376968384, "report/dyn_loss_std": 7.584494113922119, "report/image_loss_mean": 1.2026299238204956, "report/image_loss_std": 2.3811872005462646, "report/model_loss_mean": 3.0501952171325684, "report/model_loss_std": 6.149397373199463, "report/post_ent_mag": 46.71331787109375, "report/post_ent_max": 46.71331787109375, "report/post_ent_mean": 25.100719451904297, "report/post_ent_min": 13.647379875183105, "report/post_ent_std": 4.367485046386719, "report/prior_ent_mag": 75.25662231445312, "report/prior_ent_max": 75.25662231445312, "report/prior_ent_mean": 27.93325424194336, "report/prior_ent_min": 13.723731994628906, "report/prior_ent_std": 8.751934051513672, "report/rep_loss_mean": 2.958845376968384, "report/rep_loss_std": 7.584494113922119, "report/reward_avg": 0.014884430915117264, "report/reward_loss_mean": 0.07225748896598816, "report/reward_loss_std": 0.13244687020778656, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0018224716186523, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.05231636017560959, "report/reward_pos_acc": 0.8484848141670227, "report/reward_pos_loss": 0.6710957288742065, "report/reward_pred": 0.014913158491253853, "report/reward_rate": 0.0322265625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.0003576114831957966, "eval/cont_loss_std": 0.010141436941921711, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.08188126981258392, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 3.791087874560617e-05, "eval/cont_pred": 0.9963308572769165, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 24.160724639892578, "eval/dyn_loss_std": 13.884225845336914, "eval/image_loss_mean": 35.96735382080078, "eval/image_loss_std": 40.33760070800781, "eval/model_loss_mean": 50.62285232543945, "eval/model_loss_std": 45.87960433959961, "eval/post_ent_mag": 46.71331787109375, "eval/post_ent_max": 46.71331787109375, "eval/post_ent_mean": 28.466739654541016, "eval/post_ent_min": 20.43534278869629, "eval/post_ent_std": 3.1803512573242188, "eval/prior_ent_mag": 75.25662231445312, "eval/prior_ent_max": 75.25662231445312, "eval/prior_ent_mean": 38.89813995361328, "eval/prior_ent_min": 21.235008239746094, "eval/prior_ent_std": 8.111573219299316, "eval/rep_loss_mean": 24.160724639892578, "eval/rep_loss_std": 13.884225845336914, "eval/reward_avg": 0.01738281175494194, "eval/reward_loss_mean": 0.15870440006256104, "eval/reward_loss_std": 1.0112969875335693, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0018231868743896, "eval/reward_neg_acc": 0.9960119724273682, "eval/reward_neg_loss": 0.1136462613940239, "eval/reward_pos_acc": 0.8095238208770752, "eval/reward_pos_loss": 2.3107666969299316, "eval/reward_pred": 0.017613252624869347, "eval/reward_rate": 0.0205078125, "replay/size": 103792.0, "replay/inserts": 2164.0, "replay/samples": 34624.0, "replay/insert_wait_avg": 2.4721053964329297e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.60530753408915e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 21280.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 8.195638656616211e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0099058151245, "timer/env.step_count": 270.0, "timer/env.step_total": 25.083438634872437, "timer/env.step_frac": 0.025083190165427923, "timer/env.step_avg": 0.09290162457360161, "timer/env.step_min": 0.023209810256958008, "timer/env.step_max": 1.6707215309143066, "timer/replay._sample_count": 34624.0, "timer/replay._sample_total": 16.227031707763672, "timer/replay._sample_frac": 0.01622687096737982, "timer/replay._sample_avg": 0.00046866427067247205, "timer/replay._sample_min": 0.0003402233123779297, "timer/replay._sample_max": 0.021425485610961914, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 270.0, "timer/agent.policy_total": 4.1412270069122314, "timer/agent.policy_frac": 0.004141185985089467, "timer/agent.policy_avg": 0.015337877803378634, "timer/agent.policy_min": 0.014361858367919922, "timer/agent.policy_max": 0.03814053535461426, "timer/dataset_train_count": 2164.0, "timer/dataset_train_total": 0.3746514320373535, "timer/dataset_train_frac": 0.000374647720846294, "timer/dataset_train_avg": 0.000173129127558851, "timer/dataset_train_min": 8.630752563476562e-05, "timer/dataset_train_max": 0.0011515617370605469, "timer/agent.train_count": 2164.0, "timer/agent.train_total": 960.3669633865356, "timer/agent.train_frac": 0.9603574502631799, "timer/agent.train_avg": 0.44379249694387046, "timer/agent.train_min": 0.43302083015441895, "timer/agent.train_max": 0.562762975692749, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4722709655761719, "timer/agent.report_frac": 0.0004722662873936394, "timer/agent.report_avg": 0.23613548278808594, "timer/agent.report_min": 0.22928071022033691, "timer/agent.report_max": 0.24299025535583496, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 0.00011920928955078125, "timer/dataset_eval_frac": 1.1920810869729515e-07, "timer/dataset_eval_avg": 0.00011920928955078125, "timer/dataset_eval_min": 0.00011920928955078125, "timer/dataset_eval_max": 0.00011920928955078125, "fps": 2.163950776525572}
{"step": 104360, "time": 48360.98591852188, "episode/length": 165.0, "episode/score": 2.2591347962470536, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.15913467391783342}
{"step": 104360, "time": 48360.99493050575, "episode/length": 126.0, "episode/score": 4.245554964452367, "episode/reward_rate": 0.952755905511811, "episode/intrinsic_return": 0.14555484514994532}
{"step": 104568, "time": 48458.456077337265, "episode/length": 178.0, "episode/score": 3.2681630264110026, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.16816295155012995}
{"step": 104584, "time": 48467.237246751785, "episode/length": 173.0, "episode/score": 3.268202363538421, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.16820231699557553}
{"step": 105232, "time": 48761.92443108559, "episode/length": 287.0, "episode/score": 5.393968754812249, "episode/reward_rate": 0.9861111111111112, "episode/intrinsic_return": 0.2939685863825616}
{"step": 105232, "time": 48761.9361615181, "episode/length": 233.0, "episode/score": 5.365674924536506, "episode/reward_rate": 0.9786324786324786, "episode/intrinsic_return": 0.26567477310345566}
{"step": 105416, "time": 48848.480357170105, "episode/length": 203.0, "episode/score": 5.317474303806193, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.21747415470144915}
{"step": 105504, "time": 48889.863313913345, "episode/length": 142.0, "episode/score": 4.250183499531886, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.15018336669618293}
{"step": 105584, "time": 48927.639860630035, "episode/length": 152.0, "episode/score": 4.263425194967567, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.16342507217268576}
{"step": 105864, "time": 49055.96604204178, "episode/length": 78.0, "episode/score": 2.1503803236132626, "episode/reward_rate": 0.9873417721518988, "episode/intrinsic_return": 0.05038029120032661}
{"step": 106080, "time": 49155.383248806, "episode/length": 261.0, "episode/score": 5.384951101933893, "episode/reward_rate": 0.9809160305343512, "episode/intrinsic_return": 0.2849509226775808}
{"step": 106096, "time": 49164.08219361305, "episode/length": 190.0, "episode/score": 5.310663558370834, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.2106633750254332}
{"step": 106152, "time": 49190.893224954605, "episode/length": 195.0, "episode/score": 4.316417196784187, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.21641712515383915}
{"step": 106459, "time": 49332.157693862915, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.130510400842737, "train/action_min": 0.0, "train/action_std": 3.9658607884689614, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.043746190068001546, "train/actor_opt_grad_steps": 103815.0, "train/actor_opt_loss": -14.45274187679644, "train/adv_mag": 0.6507071100727275, "train/adv_max": 0.5950649086799886, "train/adv_mean": 0.0024221198838682133, "train/adv_min": -0.5438833333275936, "train/adv_std": 0.053161289663640435, "train/cont_avg": 0.9943305121527778, "train/cont_loss_mean": 4.1305619833414756e-05, "train/cont_loss_std": 0.0012522990118285628, "train/cont_neg_acc": 0.9979809671640396, "train/cont_neg_loss": 0.0055099547669909855, "train/cont_pos_acc": 0.9999999804077325, "train/cont_pos_loss": 7.455271811254407e-06, "train/cont_pred": 0.9943376917529989, "train/cont_rate": 0.9943305121527778, "train/dyn_loss_mean": 3.0523921339600175, "train/dyn_loss_std": 7.84806901216507, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.079743306118029, "train/extr_critic_critic_opt_grad_steps": 103815.0, "train/extr_critic_critic_opt_loss": 15244.972574869791, "train/extr_critic_mag": 12.81606799584848, "train/extr_critic_max": 12.81606799584848, "train/extr_critic_mean": 2.517215227087339, "train/extr_critic_min": -0.6499568201877453, "train/extr_critic_std": 2.798657066292233, "train/extr_return_normed_mag": 1.5359786136282816, "train/extr_return_normed_max": 1.5359786136282816, "train/extr_return_normed_mean": 0.314669762496595, "train/extr_return_normed_min": -0.08682877799772003, "train/extr_return_normed_std": 0.32429443465338814, "train/extr_return_rate": 0.7029004880675563, "train/extr_return_raw_mag": 13.273542077453047, "train/extr_return_raw_max": 13.273542077453047, "train/extr_return_raw_mean": 2.5384066706454314, "train/extr_return_raw_min": -0.9921302409083755, "train/extr_return_raw_std": 2.8584186925932213, "train/extr_reward_mag": 1.0176595879925623, "train/extr_reward_max": 1.0176595879925623, "train/extr_reward_mean": 0.03028557808742065, "train/extr_reward_min": -0.6646499782800674, "train/extr_reward_std": 0.17087937988064908, "train/image_loss_mean": 1.6417897335357137, "train/image_loss_std": 5.001677093682466, "train/model_loss_mean": 3.5444679105723345, "train/model_loss_std": 8.83228431586866, "train/model_opt_grad_norm": 34.03533857840079, "train/model_opt_grad_steps": 103729.72222222222, "train/model_opt_loss": 6580.00552255136, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1840.2777777777778, "train/policy_entropy_mag": 2.654240080603847, "train/policy_entropy_max": 2.654240080603847, "train/policy_entropy_mean": 0.6388349534460792, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.739293750513483, "train/policy_logprob_mag": 7.438384022977617, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.6391872763633728, "train/policy_logprob_min": -7.438384022977617, "train/policy_logprob_std": 1.1836319146332916, "train/policy_randomness_mag": 0.9368302714493539, "train/policy_randomness_max": 0.9368302714493539, "train/policy_randomness_mean": 0.2254807050857279, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.26093824918347375, "train/post_ent_mag": 44.264453640690554, "train/post_ent_max": 44.264453640690554, "train/post_ent_mean": 24.36441973403648, "train/post_ent_min": 12.414423523125825, "train/post_ent_std": 4.3746011577270645, "train/prior_ent_mag": 75.4625563091702, "train/prior_ent_max": 75.4625563091702, "train/prior_ent_mean": 27.337791751932215, "train/prior_ent_min": 13.787627432081434, "train/prior_ent_std": 8.910450052331996, "train/rep_loss_mean": 3.0523921339600175, "train/rep_loss_std": 7.84806901216507, "train/reward_avg": 0.018933662760968285, "train/reward_loss_mean": 0.07120160520490673, "train/reward_loss_std": 0.16191850554336001, "train/reward_max_data": 1.0058796593436488, "train/reward_max_pred": 1.0062876531371363, "train/reward_neg_acc": 0.9993340908377258, "train/reward_neg_loss": 0.05104784360500397, "train/reward_pos_acc": 0.9210053599543042, "train/reward_pos_loss": 0.7195537388324738, "train/reward_pred": 0.018780343739005428, "train/reward_rate": 0.030056423611111112, "train_stats/sum_log_reward": 4.023076901069055, "train_stats/max_log_achievement_collect_drink": 4.153846153846154, "train_stats/max_log_achievement_collect_sapling": 1.8461538461538463, "train_stats/max_log_achievement_collect_wood": 2.3846153846153846, "train_stats/max_log_achievement_defeat_skeleton": 0.07692307692307693, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.6923076923076923, "train_stats/max_log_achievement_place_table": 1.0, "train_stats/max_log_achievement_wake_up": 2.076923076923077, "train_stats/mean_log_entropy": 0.5969248242103137, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 1.4338529581436887e-06, "report/cont_loss_std": 2.500035407138057e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 1.5871743016759865e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.3487573369275196e-06, "report/cont_pred": 0.9941394925117493, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 2.608452558517456, "report/dyn_loss_std": 7.32658576965332, "report/image_loss_mean": 1.3036861419677734, "report/image_loss_std": 3.224616527557373, "report/model_loss_mean": 2.932168483734131, "report/model_loss_std": 6.932065486907959, "report/post_ent_mag": 46.27703094482422, "report/post_ent_max": 46.27703094482422, "report/post_ent_mean": 23.270856857299805, "report/post_ent_min": 11.472990989685059, "report/post_ent_std": 4.402932643890381, "report/prior_ent_mag": 75.3523178100586, "report/prior_ent_max": 75.3523178100586, "report/prior_ent_mean": 26.099365234375, "report/prior_ent_min": 13.312517166137695, "report/prior_ent_std": 8.974401473999023, "report/rep_loss_mean": 2.608452558517456, "report/rep_loss_std": 7.32658576965332, "report/reward_avg": 0.015416625887155533, "report/reward_loss_mean": 0.06340954452753067, "report/reward_loss_std": 0.12070301920175552, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0065999031066895, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.04689539968967438, "report/reward_pos_acc": 0.9629629850387573, "report/reward_pos_loss": 0.6732096076011658, "report/reward_pred": 0.015564341098070145, "report/reward_rate": 0.0263671875, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 3.094814701398718e-06, "eval/cont_loss_std": 8.268444798886776e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0009306006832048297, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 3.6952826576452935e-07, "eval/cont_pred": 0.9970728158950806, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 26.20449447631836, "eval/dyn_loss_std": 13.835378646850586, "eval/image_loss_mean": 34.73171615600586, "eval/image_loss_std": 35.621665954589844, "eval/model_loss_mean": 50.63639450073242, "eval/model_loss_std": 41.22492980957031, "eval/post_ent_mag": 42.34966278076172, "eval/post_ent_max": 42.34966278076172, "eval/post_ent_mean": 27.825084686279297, "eval/post_ent_min": 18.121562957763672, "eval/post_ent_std": 3.4457168579101562, "eval/prior_ent_mag": 75.3523178100586, "eval/prior_ent_max": 75.3523178100586, "eval/prior_ent_mean": 38.77684020996094, "eval/prior_ent_min": 19.523921966552734, "eval/prior_ent_std": 7.593083381652832, "eval/rep_loss_mean": 26.20449447631836, "eval/rep_loss_std": 13.835378646850586, "eval/reward_avg": 0.02851562388241291, "eval/reward_loss_mean": 0.1819802224636078, "eval/reward_loss_std": 1.0641422271728516, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0024092197418213, "eval/reward_neg_acc": 0.9939515590667725, "eval/reward_neg_loss": 0.08779817819595337, "eval/reward_pos_acc": 0.625, "eval/reward_pos_loss": 3.101623773574829, "eval/reward_pred": 0.020467495545744896, "eval/reward_rate": 0.03125, "replay/size": 105955.0, "replay/inserts": 2163.0, "replay/samples": 34608.0, "replay/insert_wait_avg": 2.448888382755161e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.597181017730614e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 21280.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 6.705522537231445e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4025242328644, "timer/env.step_count": 271.0, "timer/env.step_total": 27.282373666763306, "timer/env.step_frac": 0.027271396268901026, "timer/env.step_avg": 0.10067296556001219, "timer/env.step_min": 0.023384571075439453, "timer/env.step_max": 3.3510043621063232, "timer/replay._sample_count": 34608.0, "timer/replay._sample_total": 16.123798370361328, "timer/replay._sample_frac": 0.016117310762210933, "timer/replay._sample_avg": 0.0004658980111639311, "timer/replay._sample_min": 0.0003371238708496094, "timer/replay._sample_max": 0.010311126708984375, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 271.0, "timer/agent.policy_total": 4.129909515380859, "timer/agent.policy_frac": 0.0041282477956038595, "timer/agent.policy_avg": 0.01523951850694044, "timer/agent.policy_min": 0.014116764068603516, "timer/agent.policy_max": 0.04014468193054199, "timer/dataset_train_count": 2163.0, "timer/dataset_train_total": 0.3772084712982178, "timer/dataset_train_frac": 0.00037705669684057566, "timer/dataset_train_avg": 0.00017439134133066008, "timer/dataset_train_min": 8.893013000488281e-05, "timer/dataset_train_max": 0.0029413700103759766, "timer/agent.train_count": 2163.0, "timer/agent.train_total": 958.766829252243, "timer/agent.train_frac": 0.9583810576522198, "timer/agent.train_avg": 0.44325789609442584, "timer/agent.train_min": 0.43139100074768066, "timer/agent.train_max": 0.5555446147918701, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4757266044616699, "timer/agent.report_frac": 0.00047553519002410547, "timer/agent.report_avg": 0.23786330223083496, "timer/agent.report_min": 0.2324373722076416, "timer/agent.report_max": 0.24328923225402832, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7418136596679688e-05, "timer/dataset_eval_frac": 2.7407104572936433e-08, "timer/dataset_eval_avg": 2.7418136596679688e-05, "timer/dataset_eval_min": 2.7418136596679688e-05, "timer/dataset_eval_max": 2.7418136596679688e-05, "fps": 2.1621002386915142}
{"step": 106600, "time": 49397.495812654495, "episode/length": 170.0, "episode/score": 3.288202238752092, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.18820214459537965}
{"step": 106704, "time": 49446.33887052536, "episode/length": 149.0, "episode/score": 6.259429659230136, "episode/reward_rate": 0.9866666666666667, "episode/intrinsic_return": 0.1594294598048691}
{"step": 106848, "time": 49513.619525671005, "episode/length": 178.0, "episode/score": 3.2853562566137953, "episode/reward_rate": 0.9664804469273743, "episode/intrinsic_return": 0.18535616594954263}
{"step": 106912, "time": 49544.43109512329, "episode/length": 165.0, "episode/score": 3.2394716457888535, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.13947152148057285}
{"step": 107224, "time": 49688.618985414505, "episode/length": 142.0, "episode/score": 4.237236601013592, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.1372364913736419}
{"step": 107448, "time": 49792.41790652275, "episode/length": 168.0, "episode/score": 5.276036013527573, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.17603580528384555}
{"step": 107496, "time": 49815.823742866516, "episode/length": 167.0, "episode/score": 5.277591341051902, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.17759123638870733}
{"step": 107840, "time": 49974.080194950104, "episode/length": 154.0, "episode/score": 4.2785933731124715, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.17859328890926918}
{"step": 107872, "time": 49990.254789114, "episode/length": 145.0, "episode/score": 3.2515638166883036, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.15156374680418594}
{"step": 107984, "time": 50042.702395915985, "episode/length": 133.0, "episode/score": 4.232656515941471, "episode/reward_rate": 0.9925373134328358, "episode/intrinsic_return": 0.13265643712247766}
{"step": 108248, "time": 50164.40411257744, "episode/length": 297.0, "episode/score": 5.404404746328055, "episode/reward_rate": 0.9865771812080537, "episode/intrinsic_return": 0.3044045629972061}
{"step": 108576, "time": 50315.47490024567, "episode/length": 215.0, "episode/score": 4.328906803007158, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.22890670099241106}
{"step": 108609, "time": 50332.61792635918, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.049510015443314, "train/action_min": 0.0, "train/action_std": 3.9565592976503594, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.039710845832907876, "train/actor_opt_grad_steps": 105970.0, "train/actor_opt_loss": -16.577243456591006, "train/adv_mag": 0.5706760561743448, "train/adv_max": 0.47825764154278955, "train/adv_mean": 0.0009180563092698765, "train/adv_min": -0.48669799545476605, "train/adv_std": 0.04779848925942599, "train/cont_avg": 0.9944903706395349, "train/cont_loss_mean": 5.600476808393618e-05, "train/cont_loss_std": 0.001723266892753769, "train/cont_neg_acc": 0.9990697674973067, "train/cont_neg_loss": 0.009039406625279934, "train/cont_pos_acc": 0.9999954168186631, "train/cont_pos_loss": 1.1462135284868646e-05, "train/cont_pred": 0.9944874034371487, "train/cont_rate": 0.9944903706395349, "train/dyn_loss_mean": 3.0017813527306845, "train/dyn_loss_std": 7.742755938685217, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0598863981490911, "train/extr_critic_critic_opt_grad_steps": 105970.0, "train/extr_critic_critic_opt_loss": 15061.711032885174, "train/extr_critic_mag": 9.558531887586726, "train/extr_critic_max": 9.558531887586726, "train/extr_critic_mean": 2.0895970860192943, "train/extr_critic_min": -0.6201324307641317, "train/extr_critic_std": 2.2910582514696345, "train/extr_return_normed_mag": 1.4768345006676606, "train/extr_return_normed_max": 1.4768345006676606, "train/extr_return_normed_mean": 0.33042654318864956, "train/extr_return_normed_min": -0.10720356011459994, "train/extr_return_normed_std": 0.3302340099284815, "train/extr_return_rate": 0.6167563303958538, "train/extr_return_raw_mag": 10.124945046180903, "train/extr_return_raw_max": 10.124945046180903, "train/extr_return_raw_mean": 2.0957333370696665, "train/extr_return_raw_min": -0.9673179440720137, "train/extr_return_raw_std": 2.3149921627931818, "train/extr_reward_mag": 1.0231413242428802, "train/extr_reward_max": 1.0231413242428802, "train/extr_reward_mean": 0.03154385757394308, "train/extr_reward_min": -0.6616932175880255, "train/extr_reward_std": 0.17430412450502086, "train/image_loss_mean": 1.5843475727147833, "train/image_loss_std": 4.723574019587317, "train/model_loss_mean": 3.455987328152324, "train/model_loss_std": 8.4838371254677, "train/model_opt_grad_norm": 32.53877067122348, "train/model_opt_grad_steps": 105882.7534883721, "train/model_opt_loss": 6180.502006495276, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1779.0697674418604, "train/policy_entropy_mag": 2.6589492875476215, "train/policy_entropy_max": 2.6589492875476215, "train/policy_entropy_mean": 0.6172529345334963, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.7249028957167337, "train/policy_logprob_mag": 7.438383987338044, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.6177881378074025, "train/policy_logprob_min": -7.438383987338044, "train/policy_logprob_std": 1.172436608547388, "train/policy_randomness_mag": 0.9384924134542776, "train/policy_randomness_max": 0.9384924134542776, "train/policy_randomness_mean": 0.21786319953064587, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.25585890952930895, "train/post_ent_mag": 44.667132107047145, "train/post_ent_max": 44.667132107047145, "train/post_ent_mean": 24.526116890131043, "train/post_ent_min": 12.46595362286235, "train/post_ent_std": 4.454774539415227, "train/prior_ent_mag": 75.59129510923873, "train/prior_ent_max": 75.59129510923873, "train/prior_ent_mean": 27.47059272056402, "train/prior_ent_min": 13.775784363857536, "train/prior_ent_std": 8.907483890444734, "train/rep_loss_mean": 3.0017813527306845, "train/rep_loss_std": 7.742755938685217, "train/reward_avg": 0.018569139761547015, "train/reward_loss_mean": 0.0705149396041105, "train/reward_loss_std": 0.15701737369215765, "train/reward_max_data": 1.006831425289775, "train/reward_max_pred": 1.0077702932579573, "train/reward_neg_acc": 0.9993160807809164, "train/reward_neg_loss": 0.05053332184636316, "train/reward_pos_acc": 0.9300784238549166, "train/reward_pos_loss": 0.7166850295177726, "train/reward_pred": 0.01848198466522749, "train/reward_rate": 0.029996366279069767, "train_stats/sum_log_reward": 4.183333237965901, "train_stats/max_log_achievement_collect_drink": 2.1666666666666665, "train_stats/max_log_achievement_collect_sapling": 2.4166666666666665, "train_stats/max_log_achievement_collect_wood": 2.6666666666666665, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.08333333333333333, "train_stats/max_log_achievement_make_wood_pickaxe": 0.08333333333333333, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.6666666666666667, "train_stats/max_log_achievement_place_table": 1.0, "train_stats/max_log_achievement_wake_up": 2.1666666666666665, "train_stats/mean_log_entropy": 0.5487973168492317, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 5.479087690218876e-07, "report/cont_loss_std": 1.916468136187177e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 2.1184914658078924e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 4.466477321329876e-07, "report/cont_pred": 0.9951169490814209, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 4.372045993804932, "report/dyn_loss_std": 9.289349555969238, "report/image_loss_mean": 1.8782966136932373, "report/image_loss_std": 5.449902057647705, "report/model_loss_mean": 4.576155662536621, "report/model_loss_std": 10.158365249633789, "report/post_ent_mag": 48.024192810058594, "report/post_ent_max": 48.024192810058594, "report/post_ent_mean": 25.921274185180664, "report/post_ent_min": 13.229475975036621, "report/post_ent_std": 4.507327079772949, "report/prior_ent_mag": 75.617431640625, "report/prior_ent_max": 75.617431640625, "report/prior_ent_mean": 29.836071014404297, "report/prior_ent_min": 14.796910285949707, "report/prior_ent_std": 9.284972190856934, "report/rep_loss_mean": 4.372045993804932, "report/rep_loss_std": 9.289349555969238, "report/reward_avg": 0.027435414493083954, "report/reward_loss_mean": 0.0746307522058487, "report/reward_loss_std": 0.2581688463687897, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.003028154373169, "report/reward_neg_acc": 0.9989867806434631, "report/reward_neg_loss": 0.04524767026305199, "report/reward_pos_acc": 0.9729729294776917, "report/reward_pos_loss": 0.8584442734718323, "report/reward_pred": 0.02633829414844513, "report/reward_rate": 0.0361328125, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 3.9917416870594025e-05, "eval/cont_loss_std": 0.0012489043874666095, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.008096526376903057, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 3.8547904068764183e-07, "eval/cont_pred": 0.9951556921005249, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 22.503154754638672, "eval/dyn_loss_std": 13.655652046203613, "eval/image_loss_mean": 27.02315902709961, "eval/image_loss_std": 39.38043212890625, "eval/model_loss_mean": 40.66347885131836, "eval/model_loss_std": 45.12409210205078, "eval/post_ent_mag": 48.024192810058594, "eval/post_ent_max": 48.024192810058594, "eval/post_ent_mean": 28.070117950439453, "eval/post_ent_min": 14.448263168334961, "eval/post_ent_std": 4.2254204750061035, "eval/prior_ent_mag": 75.617431640625, "eval/prior_ent_max": 75.617431640625, "eval/prior_ent_mean": 37.106727600097656, "eval/prior_ent_min": 15.033405303955078, "eval/prior_ent_std": 9.191842079162598, "eval/rep_loss_mean": 22.503154754638672, "eval/rep_loss_std": 13.655652046203613, "eval/reward_avg": 0.01806640625, "eval/reward_loss_mean": 0.1383868157863617, "eval/reward_loss_std": 0.8709357380867004, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 1.0020456314086914, "eval/reward_neg_acc": 0.9940119981765747, "eval/reward_neg_loss": 0.08211888372898102, "eval/reward_pos_acc": 0.6363636255264282, "eval/reward_pos_loss": 2.7011351585388184, "eval/reward_pred": 0.014993644319474697, "eval/reward_rate": 0.021484375, "replay/size": 108105.0, "replay/inserts": 2150.0, "replay/samples": 34400.0, "replay/insert_wait_avg": 2.498515816622002e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.709652878517328e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 21280.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 7.748603820800781e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4444241523743, "timer/env.step_count": 269.0, "timer/env.step_total": 25.024466037750244, "timer/env.step_frac": 0.025013349501100176, "timer/env.step_avg": 0.09302775478717563, "timer/env.step_min": 0.023871421813964844, "timer/env.step_max": 1.6608881950378418, "timer/replay._sample_count": 34400.0, "timer/replay._sample_total": 16.711403608322144, "timer/replay._sample_frac": 0.016703979956188837, "timer/replay._sample_avg": 0.00048579661652099255, "timer/replay._sample_min": 0.000347137451171875, "timer/replay._sample_max": 0.032929182052612305, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 269.0, "timer/agent.policy_total": 4.247242212295532, "timer/agent.policy_frac": 0.004245355473787567, "timer/agent.policy_avg": 0.01578900450667484, "timer/agent.policy_min": 0.014549493789672852, "timer/agent.policy_max": 0.04297518730163574, "timer/dataset_train_count": 2150.0, "timer/dataset_train_total": 0.38389110565185547, "timer/dataset_train_frac": 0.000383720570962357, "timer/dataset_train_avg": 0.00017855400262877, "timer/dataset_train_min": 9.417533874511719e-05, "timer/dataset_train_max": 0.0005488395690917969, "timer/agent.train_count": 2150.0, "timer/agent.train_total": 960.3211107254028, "timer/agent.train_frac": 0.9598945104212402, "timer/agent.train_avg": 0.4466609817327455, "timer/agent.train_min": 0.4336378574371338, "timer/agent.train_max": 0.6203186511993408, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4759407043457031, "timer/agent.report_frac": 0.0004757292787642287, "timer/agent.report_avg": 0.23797035217285156, "timer/agent.report_min": 0.230241060256958, "timer/agent.report_max": 0.24569964408874512, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.956390380859375e-05, "timer/dataset_eval_frac": 2.9550770732359013e-08, "timer/dataset_eval_avg": 2.956390380859375e-05, "timer/dataset_eval_min": 2.956390380859375e-05, "timer/dataset_eval_max": 2.956390380859375e-05, "fps": 2.1490142728966957}
{"step": 108944, "time": 50486.092748880386, "episode/length": 180.0, "episode/score": 3.271292165086379, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.17129205509718304}
{"step": 109144, "time": 50579.18007159233, "episode/length": 239.0, "episode/score": 5.343006834326616, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.24300671467494794}
{"step": 109160, "time": 50588.063792705536, "episode/length": 146.0, "episode/score": 4.260987918098181, "episode/reward_rate": 0.9727891156462585, "episode/intrinsic_return": 0.16098779646745243}
{"step": 109200, "time": 50607.806186676025, "episode/length": 169.0, "episode/score": 5.280179378675712, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.18017940335539606}
{"step": 109216, "time": 50616.62556242943, "episode/length": 33.0, "episode/score": 2.140416818438098, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.040416665957309306}
{"step": 109352, "time": 50680.512906074524, "episode/length": 184.0, "episode/score": 6.267690896634122, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.1676906945021983}
{"step": 109368, "time": 50689.41258239746, "episode/length": 239.0, "episode/score": 5.360754260856083, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.26075407927146443}
{"step": 110032, "time": 51013.81003546715, "eval_episode/length": 136.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9562043795620438}
{"step": 110032, "time": 51016.04405641556, "eval_episode/length": 154.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9935483870967742}
{"step": 110032, "time": 51018.63046479225, "eval_episode/length": 179.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9944444444444445}
{"step": 110032, "time": 51020.2407245636, "eval_episode/length": 182.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9617486338797814}
{"step": 110032, "time": 51021.887602090836, "eval_episode/length": 184.0, "eval_episode/score": 4.099999971687794, "eval_episode/reward_rate": 0.9945945945945946}
{"step": 110032, "time": 51023.61851835251, "eval_episode/length": 191.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9947916666666666}
{"step": 110032, "time": 51027.729939460754, "eval_episode/length": 251.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9801587301587301}
{"step": 110032, "time": 51031.93829250336, "eval_episode/length": 163.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9695121951219512}
{"step": 110240, "time": 51127.18720579147, "episode/length": 207.0, "episode/score": 3.345815588691039, "episode/reward_rate": 0.9663461538461539, "episode/intrinsic_return": 0.24581547136767767}
{"step": 110264, "time": 51139.773112773895, "episode/length": 251.0, "episode/score": 3.369719343970246, "episode/reward_rate": 0.9841269841269841, "episode/intrinsic_return": 0.26971928936563927}
{"step": 110336, "time": 51174.44376158714, "episode/length": 141.0, "episode/score": 4.217989092134076, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.11798892684760176}
{"step": 110336, "time": 51174.49197149277, "episode/length": 146.0, "episode/score": 4.24711190890298, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.14711175089246353}
{"step": 110584, "time": 51290.980727910995, "episode/length": 179.0, "episode/score": 5.312583478342276, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.21258332923753187}
{"step": 110671, "time": 51332.89669442177, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.041841221316425, "train/action_min": 0.0, "train/action_std": 3.94820785637639, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.042521125083600265, "train/actor_opt_grad_steps": 108080.0, "train/actor_opt_loss": -11.92336313350909, "train/adv_mag": 0.6918215944571195, "train/adv_max": 0.6266698500384456, "train/adv_mean": 0.003063230291614664, "train/adv_min": -0.5261076264047392, "train/adv_std": 0.05071786078421966, "train/cont_avg": 0.9944755812198067, "train/cont_loss_mean": 1.469592367892041e-05, "train/cont_loss_std": 0.0004038463541772838, "train/cont_neg_acc": 0.9995169083853275, "train/cont_neg_loss": 0.0010759602879505214, "train/cont_pos_acc": 0.9999999807076754, "train/cont_pos_loss": 5.598379082536539e-06, "train/cont_pred": 0.9944764286423651, "train/cont_rate": 0.9944755812198067, "train/dyn_loss_mean": 2.991457473828597, "train/dyn_loss_std": 7.744827692059503, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0172578030162387, "train/extr_critic_critic_opt_grad_steps": 108080.0, "train/extr_critic_critic_opt_loss": 14954.287232035023, "train/extr_critic_mag": 10.500049130352222, "train/extr_critic_max": 10.500049130352222, "train/extr_critic_mean": 2.0815920282677176, "train/extr_critic_min": -0.6710216774456743, "train/extr_critic_std": 2.348748949414866, "train/extr_return_normed_mag": 1.578372950139253, "train/extr_return_normed_max": 1.578372950139253, "train/extr_return_normed_mean": 0.332737253052025, "train/extr_return_normed_min": -0.11310826414737149, "train/extr_return_normed_std": 0.33974416338015295, "train/extr_return_rate": 0.6149264978613831, "train/extr_return_raw_mag": 10.926988866594103, "train/extr_return_raw_max": 10.926988866594103, "train/extr_return_raw_mean": 2.1035283832734333, "train/extr_return_raw_min": -1.0381487800879179, "train/extr_return_raw_std": 2.3980688634126084, "train/extr_reward_mag": 1.0194216534711313, "train/extr_reward_max": 1.0194216534711313, "train/extr_reward_mean": 0.03175347797788572, "train/extr_reward_min": -0.6665078821965462, "train/extr_reward_std": 0.17522502830926923, "train/image_loss_mean": 1.53333431367137, "train/image_loss_std": 4.787254336375545, "train/model_loss_mean": 3.3992320546781385, "train/model_loss_std": 8.574335153552068, "train/model_opt_grad_norm": 32.18525843018467, "train/model_opt_grad_steps": 107991.7149758454, "train/model_opt_loss": 7601.227688849261, "train/model_opt_model_opt_grad_overflow": 0.004830917874396135, "train/model_opt_model_opt_grad_scale": 2228.2608695652175, "train/policy_entropy_mag": 2.661079640549738, "train/policy_entropy_max": 2.661079640549738, "train/policy_entropy_mean": 0.6059017925734681, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.7187283312640904, "train/policy_logprob_mag": 7.4383840238414525, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.6053916716921157, "train/policy_logprob_min": -7.4383840238414525, "train/policy_logprob_std": 1.1666413773085185, "train/policy_randomness_mag": 0.9392443351123644, "train/policy_randomness_max": 0.9392443351123644, "train/policy_randomness_mean": 0.21385674300976998, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.2536795592826346, "train/post_ent_mag": 44.91378559352119, "train/post_ent_max": 44.91378559352119, "train/post_ent_mean": 24.765664823965174, "train/post_ent_min": 12.363922533781633, "train/post_ent_std": 4.435711729353753, "train/prior_ent_mag": 75.68914654865357, "train/prior_ent_max": 75.68914654865357, "train/prior_ent_mean": 27.707682374594867, "train/prior_ent_min": 13.619718012602434, "train/prior_ent_std": 8.884092743270063, "train/rep_loss_mean": 2.991457473828597, "train/rep_loss_std": 7.744827692059503, "train/reward_avg": 0.018335307632226516, "train/reward_loss_mean": 0.07100856012624243, "train/reward_loss_std": 0.15505478120800378, "train/reward_max_data": 1.00946259095473, "train/reward_max_pred": 1.0093783353261903, "train/reward_neg_acc": 0.9993633829453141, "train/reward_neg_loss": 0.051101106268484235, "train/reward_pos_acc": 0.9237535345381584, "train/reward_pos_loss": 0.7187506435573965, "train/reward_pred": 0.018179381374215733, "train/reward_rate": 0.029825256642512076, "train_stats/sum_log_reward": 4.1833332777023315, "train_stats/max_log_achievement_collect_drink": 3.9166666666666665, "train_stats/max_log_achievement_collect_sapling": 2.0833333333333335, "train_stats/max_log_achievement_collect_wood": 3.0833333333333335, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.08333333333333333, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 2.0, "train_stats/max_log_achievement_place_table": 1.4166666666666667, "train_stats/max_log_achievement_wake_up": 2.0833333333333335, "train_stats/mean_log_entropy": 0.5714237354695797, "eval_stats/sum_log_reward": 4.724999904632568, "eval_stats/max_log_achievement_collect_drink": 3.625, "eval_stats/max_log_achievement_collect_sapling": 2.375, "eval_stats/max_log_achievement_collect_wood": 3.0, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.125, "eval_stats/max_log_achievement_place_table": 1.125, "eval_stats/max_log_achievement_wake_up": 1.625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 3.297921580269758e-07, "report/cont_loss_std": 1.543737653264543e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 2.2947944671614096e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.6333333380534896e-07, "report/cont_pred": 0.9970702528953552, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 2.9326157569885254, "report/dyn_loss_std": 7.450658321380615, "report/image_loss_mean": 1.206262469291687, "report/image_loss_std": 4.2019877433776855, "report/model_loss_mean": 3.0344066619873047, "report/model_loss_std": 7.919171333312988, "report/post_ent_mag": 47.11582946777344, "report/post_ent_max": 47.11582946777344, "report/post_ent_mean": 24.06749153137207, "report/post_ent_min": 12.065526962280273, "report/post_ent_std": 4.529282569885254, "report/prior_ent_mag": 75.79609680175781, "report/prior_ent_max": 75.79609680175781, "report/prior_ent_mean": 26.99822998046875, "report/prior_ent_min": 12.612136840820312, "report/prior_ent_std": 9.04216480255127, "report/rep_loss_mean": 2.9326157569885254, "report/rep_loss_std": 7.450658321380615, "report/reward_avg": 0.026239942759275436, "report/reward_loss_mean": 0.06857415288686752, "report/reward_loss_std": 0.15174980461597443, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0018198490142822, "report/reward_neg_acc": 0.9979715943336487, "report/reward_neg_loss": 0.04336952418088913, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7225679159164429, "report/reward_pred": 0.02571142464876175, "report/reward_rate": 0.037109375, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 1.0431505188535084e-06, "eval/cont_loss_std": 1.6460175174870528e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00020986294839531183, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 2.2424936219067604e-07, "eval/cont_pred": 0.9960944652557373, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 25.44594955444336, "eval/dyn_loss_std": 14.245163917541504, "eval/image_loss_mean": 30.024900436401367, "eval/image_loss_std": 34.7757682800293, "eval/model_loss_mean": 45.428260803222656, "eval/model_loss_std": 40.723262786865234, "eval/post_ent_mag": 40.630592346191406, "eval/post_ent_max": 40.630592346191406, "eval/post_ent_mean": 28.604000091552734, "eval/post_ent_min": 18.100231170654297, "eval/post_ent_std": 3.4893758296966553, "eval/prior_ent_mag": 75.79609680175781, "eval/prior_ent_max": 75.79609680175781, "eval/prior_ent_mean": 40.44704818725586, "eval/prior_ent_min": 21.58133888244629, "eval/prior_ent_std": 7.540063381195068, "eval/rep_loss_mean": 25.44594955444336, "eval/rep_loss_std": 14.245163917541504, "eval/reward_avg": 0.02031249925494194, "eval/reward_loss_mean": 0.1357879936695099, "eval/reward_loss_std": 0.7653218507766724, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0012409687042236, "eval/reward_neg_acc": 0.9979979991912842, "eval/reward_neg_loss": 0.09405257552862167, "eval/reward_pos_acc": 0.8399999737739563, "eval/reward_pos_loss": 1.8035351037979126, "eval/reward_pred": 0.018109042197465897, "eval/reward_rate": 0.0244140625, "replay/size": 110167.0, "replay/inserts": 2062.0, "replay/samples": 32992.0, "replay/insert_wait_avg": 2.463966983828466e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.847752187231232e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 23832.0, "eval_replay/inserts": 2552.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1972312269539668e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.450580596923828e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2662763595581, "timer/env.step_count": 257.0, "timer/env.step_total": 24.981698036193848, "timer/env.step_frac": 0.02497504777139349, "timer/env.step_avg": 0.09720505072448968, "timer/env.step_min": 0.023823976516723633, "timer/env.step_max": 3.179558515548706, "timer/replay._sample_count": 32992.0, "timer/replay._sample_total": 16.066938161849976, "timer/replay._sample_frac": 0.01606266105493945, "timer/replay._sample_avg": 0.0004869949733829406, "timer/replay._sample_min": 0.0003466606140136719, "timer/replay._sample_max": 0.010935306549072266, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 576.0, "timer/agent.policy_total": 9.225400924682617, "timer/agent.policy_frac": 0.009222945072444323, "timer/agent.policy_avg": 0.01601632104979621, "timer/agent.policy_min": 0.009657144546508789, "timer/agent.policy_max": 0.04200887680053711, "timer/dataset_train_count": 2062.0, "timer/dataset_train_total": 0.36838579177856445, "timer/dataset_train_frac": 0.00036828772546375804, "timer/dataset_train_avg": 0.00017865460319038044, "timer/dataset_train_min": 9.512901306152344e-05, "timer/dataset_train_max": 0.0004944801330566406, "timer/agent.train_count": 2062.0, "timer/agent.train_total": 924.4190640449524, "timer/agent.train_frac": 0.9241729786286011, "timer/agent.train_avg": 0.4483118642313057, "timer/agent.train_min": 0.4380934238433838, "timer/agent.train_max": 0.601416826248169, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4727144241333008, "timer/agent.report_frac": 0.0004725885849653275, "timer/agent.report_avg": 0.2363572120666504, "timer/agent.report_min": 0.22985029220581055, "timer/agent.report_max": 0.24286413192749023, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9087066650390625e-05, "timer/dataset_eval_frac": 2.9079323513986907e-08, "timer/dataset_eval_avg": 2.9087066650390625e-05, "timer/dataset_eval_min": 2.9087066650390625e-05, "timer/dataset_eval_max": 2.9087066650390625e-05, "fps": 2.06142534094301}
{"step": 110816, "time": 51399.11870098114, "episode/length": 199.0, "episode/score": 4.313136122994592, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.2131359990355577}
{"step": 110824, "time": 51404.27771639824, "episode/length": 183.0, "episode/score": 4.289479808967371, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.18947967816893652}
{"step": 110864, "time": 51423.82604980469, "episode/length": 186.0, "episode/score": 4.275239564693948, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.1752395266057647}
{"step": 111464, "time": 51699.08919453621, "episode/length": 140.0, "episode/score": 4.247072871849468, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.147072725349517}
{"step": 111584, "time": 51755.1523270607, "episode/length": 155.0, "episode/score": 1.2554055492416865, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.15540543874317336}
{"step": 111704, "time": 51811.20988082886, "episode/length": 182.0, "episode/score": 5.282868595306354, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.18286844176327577}
{"step": 111792, "time": 51852.57606506348, "episode/length": 190.0, "episode/score": 6.301116736880886, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.20111661184500917}
{"step": 112192, "time": 52035.55183386803, "episode/length": 170.0, "episode/score": 5.264062529701732, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.16406250812997314}
{"step": 112248, "time": 52062.41862201691, "episode/length": 207.0, "episode/score": 4.309313359929774, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.20931329831114454}
{"step": 112336, "time": 52104.063235998154, "episode/length": 189.0, "episode/score": 3.298108459882542, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.19810830891515252}
{"step": 112344, "time": 52109.19878077507, "episode/length": 184.0, "episode/score": 5.265105404527958, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.1651053490211325}
{"step": 112834, "time": 52333.06407856941, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.0652895326967595, "train/action_min": 0.0, "train/action_std": 4.058473660990044, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.049904999176592184, "train/actor_opt_grad_steps": 110195.0, "train/actor_opt_loss": -13.171406792752721, "train/adv_mag": 0.6944203333998168, "train/adv_max": 0.6357442397210333, "train/adv_mean": 0.0019286688372252866, "train/adv_min": -0.5957472055322595, "train/adv_std": 0.05797509186797672, "train/cont_avg": 0.9943033854166666, "train/cont_loss_mean": 3.9224368972938875e-05, "train/cont_loss_std": 0.0011947997989760022, "train/cont_neg_acc": 0.9985670198996862, "train/cont_neg_loss": 0.00515392328254115, "train/cont_pos_acc": 0.999999982615312, "train/cont_pos_loss": 6.620745760159778e-06, "train/cont_pred": 0.9943077773959549, "train/cont_rate": 0.9943033854166666, "train/dyn_loss_mean": 3.0196524604603097, "train/dyn_loss_std": 7.767124818431006, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1130837061338954, "train/extr_critic_critic_opt_grad_steps": 110195.0, "train/extr_critic_critic_opt_loss": 15829.334594726562, "train/extr_critic_mag": 13.011400099153873, "train/extr_critic_max": 13.011400099153873, "train/extr_critic_mean": 2.3228340573884823, "train/extr_critic_min": -0.6649615494189439, "train/extr_critic_std": 2.8387445553585335, "train/extr_return_normed_mag": 1.5386525922351413, "train/extr_return_normed_max": 1.5386525922351413, "train/extr_return_normed_mean": 0.29269638250547425, "train/extr_return_normed_min": -0.08258243576037111, "train/extr_return_normed_std": 0.32604262108604115, "train/extr_return_rate": 0.6064818137221866, "train/extr_return_raw_mag": 13.338318815937749, "train/extr_return_raw_max": 13.338318815937749, "train/extr_return_raw_mean": 2.3399983925951853, "train/extr_return_raw_min": -0.9835955448172711, "train/extr_return_raw_std": 2.898485951953464, "train/extr_reward_mag": 1.0193452923386186, "train/extr_reward_max": 1.0193452923386186, "train/extr_reward_mean": 0.028128116382975823, "train/extr_reward_min": -0.6541664081591146, "train/extr_reward_std": 0.16575323255663668, "train/image_loss_mean": 1.5548485357452322, "train/image_loss_std": 4.826490400565995, "train/model_loss_mean": 3.4372706203548997, "train/model_loss_std": 8.601005942733199, "train/model_opt_grad_norm": 32.21939346083888, "train/model_opt_grad_steps": 110104.57870370371, "train/model_opt_loss": 4603.680471914786, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1342.5925925925926, "train/policy_entropy_mag": 2.661985499991311, "train/policy_entropy_max": 2.661985499991311, "train/policy_entropy_mean": 0.6332699766865483, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.7470247381263309, "train/policy_logprob_mag": 7.438384038430673, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.6331797540187836, "train/policy_logprob_min": -7.438384038430673, "train/policy_logprob_std": 1.182001540782275, "train/policy_randomness_mag": 0.9395640638691408, "train/policy_randomness_max": 0.9395640638691408, "train/policy_randomness_mean": 0.22351651328305402, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.2636669483035803, "train/post_ent_mag": 44.375633504655625, "train/post_ent_max": 44.375633504655625, "train/post_ent_mean": 25.031824818363898, "train/post_ent_min": 12.822080859431514, "train/post_ent_std": 4.470585681773998, "train/prior_ent_mag": 75.6425513514766, "train/prior_ent_max": 75.6425513514766, "train/prior_ent_mean": 27.984850971787065, "train/prior_ent_min": 14.099247504163671, "train/prior_ent_std": 8.86741539284035, "train/rep_loss_mean": 3.0196524604603097, "train/rep_loss_std": 7.767124818431006, "train/reward_avg": 0.018480936106277147, "train/reward_loss_mean": 0.07059139513445122, "train/reward_loss_std": 0.15390196128713865, "train/reward_max_data": 1.0077315116370167, "train/reward_max_pred": 1.0086593042921137, "train/reward_neg_acc": 0.9991851484885922, "train/reward_neg_loss": 0.05107354800458307, "train/reward_pos_acc": 0.9322413504123688, "train/reward_pos_loss": 0.7109639605990162, "train/reward_pred": 0.018446474413697917, "train/reward_rate": 0.029617874710648147, "train_stats/sum_log_reward": 4.1909090497277, "train_stats/max_log_achievement_collect_drink": 7.090909090909091, "train_stats/max_log_achievement_collect_sapling": 1.7272727272727273, "train_stats/max_log_achievement_collect_wood": 2.0, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.18181818181818182, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.5454545454545454, "train_stats/max_log_achievement_place_table": 0.45454545454545453, "train_stats/max_log_achievement_wake_up": 1.7272727272727273, "train_stats/mean_log_entropy": 0.568565542047674, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 3.7523614082601853e-07, "report/cont_loss_std": 2.1764692519354867e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 2.4869765184121206e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.5504706968604296e-07, "report/cont_pred": 0.9951171875, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 3.077606678009033, "report/dyn_loss_std": 7.966775894165039, "report/image_loss_mean": 2.2273244857788086, "report/image_loss_std": 5.2267351150512695, "report/model_loss_mean": 4.145005702972412, "report/model_loss_std": 8.972046852111816, "report/post_ent_mag": 47.04875183105469, "report/post_ent_max": 47.04875183105469, "report/post_ent_mean": 24.457855224609375, "report/post_ent_min": 11.448843002319336, "report/post_ent_std": 4.860644340515137, "report/prior_ent_mag": 75.6748046875, "report/prior_ent_max": 75.6748046875, "report/prior_ent_mean": 27.47772789001465, "report/prior_ent_min": 12.272741317749023, "report/prior_ent_std": 9.077573776245117, "report/rep_loss_mean": 3.077606678009033, "report/rep_loss_std": 7.966775894165039, "report/reward_avg": 0.018302353098988533, "report/reward_loss_mean": 0.07111673802137375, "report/reward_loss_std": 0.16353505849838257, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0018365383148193, "report/reward_neg_acc": 0.9979920387268066, "report/reward_neg_loss": 0.05324939265847206, "report/reward_pos_acc": 0.9285714626312256, "report/reward_pos_loss": 0.7066839933395386, "report/reward_pred": 0.018869318068027496, "report/reward_rate": 0.02734375, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 7.280401769094169e-05, "eval/cont_loss_std": 0.0022561317309737206, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.018487824127078056, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 5.882462232875696e-07, "eval/cont_pred": 0.9961629509925842, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 24.59773063659668, "eval/dyn_loss_std": 14.282029151916504, "eval/image_loss_mean": 39.83935546875, "eval/image_loss_std": 48.932186126708984, "eval/model_loss_mean": 54.7703971862793, "eval/model_loss_std": 55.00780487060547, "eval/post_ent_mag": 47.04875183105469, "eval/post_ent_max": 47.04875183105469, "eval/post_ent_mean": 28.4749698638916, "eval/post_ent_min": 15.713753700256348, "eval/post_ent_std": 3.555448293685913, "eval/prior_ent_mag": 75.6748046875, "eval/prior_ent_max": 75.6748046875, "eval/prior_ent_mean": 38.686302185058594, "eval/prior_ent_min": 15.844100952148438, "eval/prior_ent_std": 8.105986595153809, "eval/rep_loss_mean": 24.59773063659668, "eval/rep_loss_std": 14.282029151916504, "eval/reward_avg": 0.02060546725988388, "eval/reward_loss_mean": 0.17233231663703918, "eval/reward_loss_std": 1.1772693395614624, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0014162063598633, "eval/reward_neg_acc": 0.9969969987869263, "eval/reward_neg_loss": 0.08348044753074646, "eval/reward_pos_acc": 0.6399999856948853, "eval/reward_pos_loss": 3.722852945327759, "eval/reward_pred": 0.013766337186098099, "eval/reward_rate": 0.0244140625, "replay/size": 112330.0, "replay/inserts": 2163.0, "replay/samples": 34608.0, "replay/insert_wait_avg": 2.4516440297628077e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.914424879485901e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 23832.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 8.493661880493164e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.153970003128, "timer/env.step_count": 271.0, "timer/env.step_total": 23.717254161834717, "timer/env.step_frac": 0.023713602978309968, "timer/env.step_avg": 0.08751754303260043, "timer/env.step_min": 0.023234128952026367, "timer/env.step_max": 1.6532189846038818, "timer/replay._sample_count": 34608.0, "timer/replay._sample_total": 16.629887104034424, "timer/replay._sample_frac": 0.01662732699444508, "timer/replay._sample_avg": 0.0004805214720305832, "timer/replay._sample_min": 0.00032973289489746094, "timer/replay._sample_max": 0.028945207595825195, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 271.0, "timer/agent.policy_total": 4.194046974182129, "timer/agent.policy_frac": 0.004193401316168362, "timer/agent.policy_avg": 0.015476188096613021, "timer/agent.policy_min": 0.014369010925292969, "timer/agent.policy_max": 0.029688358306884766, "timer/dataset_train_count": 2163.0, "timer/dataset_train_total": 0.4086723327636719, "timer/dataset_train_frac": 0.0004086094191701241, "timer/dataset_train_avg": 0.00018893774052874336, "timer/dataset_train_min": 8.988380432128906e-05, "timer/dataset_train_max": 0.02529120445251465, "timer/agent.train_count": 2163.0, "timer/agent.train_total": 961.7607078552246, "timer/agent.train_frac": 0.9616126483527497, "timer/agent.train_avg": 0.44464202859696006, "timer/agent.train_min": 0.4327218532562256, "timer/agent.train_max": 0.5756180286407471, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.515078067779541, "timer/agent.report_frac": 0.0005149987734167871, "timer/agent.report_avg": 0.2575390338897705, "timer/agent.report_min": 0.23123407363891602, "timer/agent.report_max": 0.283843994140625, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7894973754882812e-05, "timer/dataset_eval_frac": 2.7890679426884212e-08, "timer/dataset_eval_avg": 2.7894973754882812e-05, "timer/dataset_eval_min": 2.7894973754882812e-05, "timer/dataset_eval_max": 2.7894973754882812e-05, "fps": 2.162636426529693}
{"step": 113008, "time": 52412.25879740715, "episode/length": 177.0, "episode/score": 3.2941308274457697, "episode/reward_rate": 0.9662921348314607, "episode/intrinsic_return": 0.19413073643227108}
{"step": 113168, "time": 52486.45792245865, "episode/length": 182.0, "episode/score": 3.266464056312543, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.16646394376220996}
{"step": 113224, "time": 52513.287170648575, "episode/length": 178.0, "episode/score": 4.297704509401228, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.19770436937687919}
{"step": 113264, "time": 52532.99560189247, "episode/length": 224.0, "episode/score": 3.3471329477761174, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.2471327689854661}
{"step": 113368, "time": 52581.70343899727, "episode/length": 146.0, "episode/score": 1.2416212058160454, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.14162108197342604}
{"step": 113632, "time": 52703.01275777817, "episode/length": 172.0, "episode/score": 3.282496676158189, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.18249655184990843}
{"step": 113792, "time": 52776.85971450806, "episode/length": 181.0, "episode/score": 5.293757240342529, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.193757034427108}
{"step": 113992, "time": 52869.00391745567, "episode/length": 205.0, "episode/score": 5.304048178173616, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.20404799891730363}
{"step": 114288, "time": 53004.662142038345, "episode/length": 159.0, "episode/score": 5.273140891842559, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.1731407686984312}
{"step": 114488, "time": 53096.376752614975, "episode/length": 164.0, "episode/score": 3.2781781420417246, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.17817811278655427}
{"step": 114568, "time": 53134.103212594986, "episode/length": 162.0, "episode/score": 5.264532324235915, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.16453215580622782}
{"step": 114640, "time": 53168.203095436096, "episode/length": 105.0, "episode/score": 3.204860903295412, "episode/reward_rate": 0.9528301886792453, "episode/intrinsic_return": 0.10486086798664473}
{"step": 114752, "time": 53221.00707960129, "episode/length": 172.0, "episode/score": 5.290081723935145, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.19008151569141774}
{"step": 114768, "time": 53229.800263404846, "episode/length": 192.0, "episode/score": 3.301520201128369, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.20152007565593522}
{"step": 114976, "time": 53325.54210686684, "episode/length": 167.0, "episode/score": 4.288716695929907, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.18871660183140193}
{"step": 114988, "time": 53333.06332159042, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.977851051507995, "train/action_min": 0.0, "train/action_std": 4.003981654588566, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0500837956923385, "train/actor_opt_grad_steps": 112350.0, "train/actor_opt_loss": -12.824179753591848, "train/adv_mag": 0.7891428337540738, "train/adv_max": 0.7374223070089208, "train/adv_mean": 0.003222906473151958, "train/adv_min": -0.6429309775662977, "train/adv_std": 0.0653309382324995, "train/cont_avg": 0.9943495639534884, "train/cont_loss_mean": 5.622473565915433e-05, "train/cont_loss_std": 0.0017427877267947266, "train/cont_neg_acc": 0.9988704323768616, "train/cont_neg_loss": 0.003502005051340411, "train/cont_pos_acc": 0.9999954295712848, "train/cont_pos_loss": 2.6476834918034275e-05, "train/cont_pred": 0.9943511109019435, "train/cont_rate": 0.9943495639534884, "train/dyn_loss_mean": 3.0974767119385476, "train/dyn_loss_std": 7.817070410972418, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.11880129769791, "train/extr_critic_critic_opt_grad_steps": 112350.0, "train/extr_critic_critic_opt_loss": 16184.886096475291, "train/extr_critic_mag": 14.81632607038631, "train/extr_critic_max": 14.81632607038631, "train/extr_critic_mean": 2.235327118496562, "train/extr_critic_min": -0.6617436359095019, "train/extr_critic_std": 2.7811114971027817, "train/extr_return_normed_mag": 1.7265870487967203, "train/extr_return_normed_max": 1.7265870487967203, "train/extr_return_normed_mean": 0.2831877218429432, "train/extr_return_normed_min": -0.08840097152563028, "train/extr_return_normed_std": 0.32520152711591055, "train/extr_return_rate": 0.6200487854868867, "train/extr_return_raw_mag": 15.066642548317134, "train/extr_return_raw_max": 15.066642548317134, "train/extr_return_raw_mean": 2.263957068532012, "train/extr_return_raw_min": -1.0086247178011163, "train/extr_return_raw_std": 2.8761875729228175, "train/extr_reward_mag": 1.0176976869272631, "train/extr_reward_max": 1.0176976869272631, "train/extr_reward_mean": 0.0277825812181068, "train/extr_reward_min": -0.6743216764095218, "train/extr_reward_std": 0.1654429909448291, "train/image_loss_mean": 1.7187349083811738, "train/image_loss_std": 5.418641390911368, "train/model_loss_mean": 3.64839624582335, "train/model_loss_std": 9.17393279186515, "train/model_opt_grad_norm": 32.993724676620126, "train/model_opt_grad_steps": 112258.35813953489, "train/model_opt_loss": 6937.98954056141, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1918.6046511627908, "train/policy_entropy_mag": 2.6671319717584656, "train/policy_entropy_max": 2.6671319717584656, "train/policy_entropy_mean": 0.6220550347206204, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.7427965685378674, "train/policy_logprob_mag": 7.438384042784225, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.6210780635822651, "train/policy_logprob_min": -7.438384042784225, "train/policy_logprob_std": 1.1769146919250488, "train/policy_randomness_mag": 0.9413805426553238, "train/policy_randomness_max": 0.9413805426553238, "train/policy_randomness_mean": 0.21955812864525373, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.2621745922537737, "train/post_ent_mag": 45.00530459381813, "train/post_ent_max": 45.00530459381813, "train/post_ent_mean": 25.257499801280886, "train/post_ent_min": 12.86114971693172, "train/post_ent_std": 4.462023757224859, "train/prior_ent_mag": 75.7363918570585, "train/prior_ent_max": 75.7363918570585, "train/prior_ent_mean": 28.278357084407364, "train/prior_ent_min": 14.105643649433935, "train/prior_ent_std": 8.868444602434025, "train/rep_loss_mean": 3.0974767119385476, "train/rep_loss_std": 7.817070410972418, "train/reward_avg": 0.019755537610847588, "train/reward_loss_mean": 0.07111909266474635, "train/reward_loss_std": 0.15343982182269872, "train/reward_max_data": 1.006366308899813, "train/reward_max_pred": 1.0073755386263825, "train/reward_neg_acc": 0.9992594394572946, "train/reward_neg_loss": 0.05057295311328976, "train/reward_pos_acc": 0.9310056068176447, "train/reward_pos_loss": 0.7124591228573821, "train/reward_pred": 0.01966132601982979, "train/reward_rate": 0.03105014534883721, "train_stats/sum_log_reward": 3.766666579246521, "train_stats/max_log_achievement_collect_drink": 3.8, "train_stats/max_log_achievement_collect_sapling": 0.9333333333333333, "train_stats/max_log_achievement_collect_wood": 3.533333333333333, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 0.8, "train_stats/max_log_achievement_place_table": 1.4, "train_stats/max_log_achievement_wake_up": 1.8666666666666667, "train_stats/mean_log_entropy": 0.5588109791278839, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 2.8408712751115672e-06, "report/cont_loss_std": 2.1776966605102643e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00014071764599066228, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.4357482288905885e-06, "report/cont_pred": 0.9970682859420776, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 2.8152098655700684, "report/dyn_loss_std": 7.2907562255859375, "report/image_loss_mean": 0.9911206960678101, "report/image_loss_std": 2.8138115406036377, "report/model_loss_mean": 2.741032123565674, "report/model_loss_std": 6.500490665435791, "report/post_ent_mag": 44.54380798339844, "report/post_ent_max": 44.54380798339844, "report/post_ent_mean": 25.32111358642578, "report/post_ent_min": 12.867753982543945, "report/post_ent_std": 4.3623175621032715, "report/prior_ent_mag": 76.29798889160156, "report/prior_ent_max": 76.29798889160156, "report/prior_ent_mean": 28.137161254882812, "report/prior_ent_min": 13.490009307861328, "report/prior_ent_std": 8.520796775817871, "report/rep_loss_mean": 2.8152098655700684, "report/rep_loss_std": 7.2907562255859375, "report/reward_avg": 0.027041137218475342, "report/reward_loss_mean": 0.06078249588608742, "report/reward_loss_std": 0.1185208335518837, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0013399124145508, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.04031844064593315, "report/reward_pos_acc": 0.9999999403953552, "report/reward_pos_loss": 0.6753242611885071, "report/reward_pred": 0.02701687440276146, "report/reward_rate": 0.0322265625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.0006161738419905305, "eval/cont_loss_std": 0.01917221024632454, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0009007230401039124, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.0006150578847154975, "eval/cont_pred": 0.9956360459327698, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 22.17782974243164, "eval/dyn_loss_std": 13.492725372314453, "eval/image_loss_mean": 32.74028015136719, "eval/image_loss_std": 40.289127349853516, "eval/model_loss_mean": 46.22814178466797, "eval/model_loss_std": 45.08856201171875, "eval/post_ent_mag": 43.75470733642578, "eval/post_ent_max": 43.75470733642578, "eval/post_ent_mean": 28.461519241333008, "eval/post_ent_min": 13.515568733215332, "eval/post_ent_std": 4.104159355163574, "eval/prior_ent_mag": 76.29798889160156, "eval/prior_ent_max": 76.29798889160156, "eval/prior_ent_mean": 37.47394943237305, "eval/prior_ent_min": 14.967680931091309, "eval/prior_ent_std": 9.108200073242188, "eval/rep_loss_mean": 22.17782974243164, "eval/rep_loss_std": 13.492725372314453, "eval/reward_avg": 0.01679687388241291, "eval/reward_loss_mean": 0.18054616451263428, "eval/reward_loss_std": 0.9928590059280396, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.001206398010254, "eval/reward_neg_acc": 0.9940059781074524, "eval/reward_neg_loss": 0.12453930824995041, "eval/reward_pos_acc": 0.739130437374115, "eval/reward_pos_loss": 2.6180624961853027, "eval/reward_pred": 0.015396172180771828, "eval/reward_rate": 0.0224609375, "replay/size": 114484.0, "replay/inserts": 2154.0, "replay/samples": 34464.0, "replay/insert_wait_avg": 2.5007386061474474e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.912419743303248e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 23832.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 7.599592208862305e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 999.9879605770111, "timer/env.step_count": 269.0, "timer/env.step_total": 29.48464012145996, "timer/env.step_frac": 0.02948499510378784, "timer/env.step_avg": 0.10960832758907049, "timer/env.step_min": 0.023171186447143555, "timer/env.step_max": 1.673478603363037, "timer/replay._sample_count": 34464.0, "timer/replay._sample_total": 16.33825445175171, "timer/replay._sample_frac": 0.016338451157276175, "timer/replay._sample_avg": 0.0004740672716966025, "timer/replay._sample_min": 0.0003590583801269531, "timer/replay._sample_max": 0.025446414947509766, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 269.0, "timer/agent.policy_total": 4.122905015945435, "timer/agent.policy_frac": 0.004122954653940477, "timer/agent.policy_avg": 0.01532678444589381, "timer/agent.policy_min": 0.014365434646606445, "timer/agent.policy_max": 0.03479409217834473, "timer/dataset_train_count": 2154.0, "timer/dataset_train_total": 0.38378262519836426, "timer/dataset_train_frac": 0.0003837872457753539, "timer/dataset_train_avg": 0.00017817206369469092, "timer/dataset_train_min": 9.322166442871094e-05, "timer/dataset_train_max": 0.0007903575897216797, "timer/agent.train_count": 2154.0, "timer/agent.train_total": 955.8971834182739, "timer/agent.train_frac": 0.9559086920073557, "timer/agent.train_avg": 0.44377770817932866, "timer/agent.train_min": 0.4310941696166992, "timer/agent.train_max": 0.5825574398040771, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4739649295806885, "timer/agent.report_frac": 0.0004739706359136586, "timer/agent.report_avg": 0.23698246479034424, "timer/agent.report_min": 0.22925901412963867, "timer/agent.report_max": 0.2447059154510498, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 9.894371032714844e-05, "timer/dataset_eval_frac": 9.8944901566671e-08, "timer/dataset_eval_avg": 9.894371032714844e-05, "timer/dataset_eval_min": 9.894371032714844e-05, "timer/dataset_eval_max": 9.894371032714844e-05, "fps": 2.153996657798231}
{"step": 115600, "time": 53610.321816921234, "episode/length": 163.0, "episode/score": 5.276697715121372, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.1766975489035758}
{"step": 115712, "time": 53662.354936122894, "episode/length": 214.0, "episode/score": 4.332413392203307, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.23241329368102015}
{"step": 116040, "time": 53812.43279838562, "episode/length": 158.0, "episode/score": 3.254142942402723, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.1541428768841797}
{"step": 116160, "time": 53868.621552705765, "episode/length": 175.0, "episode/score": 4.271101821199409, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.17110169724037405}
{"step": 116168, "time": 53873.74149227142, "episode/length": 190.0, "episode/score": 5.31011208050586, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.21011192790865607}
{"step": 116208, "time": 53893.59047675133, "episode/length": 153.0, "episode/score": 5.238397111244012, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.13839697410094232}
{"step": 116336, "time": 53953.41810822487, "episode/length": 220.0, "episode/score": 1.3109304085664917, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.21093038030085154}
{"step": 116368, "time": 53969.37831759453, "episode/length": 234.0, "episode/score": 5.345685338286785, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.24568532230296114}
{"step": 116416, "time": 53992.72802901268, "episode/length": 87.0, "episode/score": 4.1845324880259795, "episode/reward_rate": 0.9431818181818182, "episode/intrinsic_return": 0.08453233507952973}
{"step": 116944, "time": 54234.5873773098, "episode/length": 167.0, "episode/score": 5.286903556618199, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.1869034012852353}
{"step": 117157, "time": 54333.47733807564, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.96128177203341, "train/action_min": 0.0, "train/action_std": 3.9121926830660914, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.041926087888841806, "train/actor_opt_grad_steps": 114510.0, "train/actor_opt_loss": -14.928820723006803, "train/adv_mag": 0.6122215376471594, "train/adv_max": 0.5513757575766831, "train/adv_mean": 0.0019045806338028578, "train/adv_min": -0.478956937789917, "train/adv_std": 0.051834730216847036, "train/cont_avg": 0.9944961477534562, "train/cont_loss_mean": 1.2291589487784407e-05, "train/cont_loss_std": 0.000354946223831697, "train/cont_neg_acc": 0.9994879672604222, "train/cont_neg_loss": 0.0014107644368073857, "train/cont_pos_acc": 0.9999999848928319, "train/cont_pos_loss": 2.633700804495813e-06, "train/cont_pred": 0.9945011111448437, "train/cont_rate": 0.9944961477534562, "train/dyn_loss_mean": 3.0483103380774574, "train/dyn_loss_std": 7.798371064498128, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.060305916219263, "train/extr_critic_critic_opt_grad_steps": 114510.0, "train/extr_critic_critic_opt_loss": 15286.88969344038, "train/extr_critic_mag": 9.161078668409779, "train/extr_critic_max": 9.161078668409779, "train/extr_critic_mean": 1.9965779882971593, "train/extr_critic_min": -0.6610459001382925, "train/extr_critic_std": 2.14871213183425, "train/extr_return_normed_mag": 1.515480342273888, "train/extr_return_normed_max": 1.515480342273888, "train/extr_return_normed_mean": 0.34079976709482307, "train/extr_return_normed_min": -0.11417008431688432, "train/extr_return_normed_std": 0.33077836785173637, "train/extr_return_rate": 0.6537328726410316, "train/extr_return_raw_mag": 9.7569077685132, "train/extr_return_raw_max": 9.7569077685132, "train/extr_return_raw_mean": 2.0091330980375615, "train/extr_return_raw_min": -0.9882235299057675, "train/extr_return_raw_std": 2.1803183945642637, "train/extr_reward_mag": 1.0174825114588584, "train/extr_reward_max": 1.0174825114588584, "train/extr_reward_mean": 0.03184858230178669, "train/extr_reward_min": -0.6748052698126586, "train/extr_reward_std": 0.17578907681774983, "train/image_loss_mean": 1.5877457604430238, "train/image_loss_std": 4.897341713377957, "train/model_loss_mean": 3.4882394498394382, "train/model_loss_std": 8.663849681203816, "train/model_opt_grad_norm": 31.961463106392717, "train/model_opt_grad_steps": 114416.75115207373, "train/model_opt_loss": 5304.17475968462, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1514.9769585253457, "train/policy_entropy_mag": 2.641912161479897, "train/policy_entropy_max": 2.641912161479897, "train/policy_entropy_mean": 0.5643253156117031, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6894367684691732, "train/policy_logprob_mag": 7.438384025327621, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5639571855145116, "train/policy_logprob_min": -7.438384025327621, "train/policy_logprob_std": 1.141450655899839, "train/policy_randomness_mag": 0.9324790544224225, "train/policy_randomness_max": 0.9324790544224225, "train/policy_randomness_mean": 0.19918207178742106, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.24334092335217558, "train/post_ent_mag": 44.819972657937605, "train/post_ent_max": 44.819972657937605, "train/post_ent_mean": 25.373154468800067, "train/post_ent_min": 12.667616888125371, "train/post_ent_std": 4.552396327119818, "train/prior_ent_mag": 75.84573670136764, "train/prior_ent_max": 75.84573670136764, "train/prior_ent_mean": 28.369017763621247, "train/prior_ent_min": 14.101498748849615, "train/prior_ent_std": 8.87724480870682, "train/rep_loss_mean": 3.0483103380774574, "train/rep_loss_std": 7.798371064498128, "train/reward_avg": 0.01972078311381527, "train/reward_loss_mean": 0.07149520722402405, "train/reward_loss_std": 0.15533107560351148, "train/reward_max_data": 1.0086233022575555, "train/reward_max_pred": 1.0093658135233936, "train/reward_neg_acc": 0.9992330055082997, "train/reward_neg_loss": 0.050720038931078626, "train/reward_pos_acc": 0.935922401841335, "train/reward_pos_loss": 0.7162266612602269, "train/reward_pred": 0.01959857734967418, "train/reward_rate": 0.031259000576036866, "train_stats/sum_log_reward": 4.199999964237213, "train_stats/max_log_achievement_collect_drink": 5.0, "train_stats/max_log_achievement_collect_sapling": 1.8, "train_stats/max_log_achievement_collect_wood": 3.7, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.2, "train_stats/max_log_achievement_place_plant": 1.5, "train_stats/max_log_achievement_place_table": 1.7, "train_stats/max_log_achievement_wake_up": 1.6, "train_stats/mean_log_entropy": 0.5366969257593155, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 7.980713689903496e-07, "report/cont_loss_std": 2.9881548471166752e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 1.61598563863663e-05, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 6.92336357133172e-07, "report/cont_pred": 0.9931635856628418, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 2.913177490234375, "report/dyn_loss_std": 8.197362899780273, "report/image_loss_mean": 1.7736382484436035, "report/image_loss_std": 4.696529865264893, "report/model_loss_mean": 3.5976266860961914, "report/model_loss_std": 8.797723770141602, "report/post_ent_mag": 40.15043640136719, "report/post_ent_max": 40.15043640136719, "report/post_ent_mean": 25.48920440673828, "report/post_ent_min": 12.684223175048828, "report/post_ent_std": 4.682700157165527, "report/prior_ent_mag": 75.9056396484375, "report/prior_ent_max": 75.9056396484375, "report/prior_ent_mean": 28.20237159729004, "report/prior_ent_min": 13.393917083740234, "report/prior_ent_std": 9.000520706176758, "report/rep_loss_mean": 2.913177490234375, "report/rep_loss_std": 8.197362899780273, "report/reward_avg": 0.012667627073824406, "report/reward_loss_mean": 0.07608090341091156, "report/reward_loss_std": 0.1518343985080719, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.001244068145752, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.05694831535220146, "report/reward_pos_acc": 0.71875, "report/reward_pos_loss": 0.6691911220550537, "report/reward_pred": 0.012840013951063156, "report/reward_rate": 0.03125, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 1.272250983674894e-06, "eval/cont_loss_std": 1.4578788977814838e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0004077357007190585, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 8.749260018703353e-07, "eval/cont_pred": 0.9990230798721313, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 25.381446838378906, "eval/dyn_loss_std": 13.960297584533691, "eval/image_loss_mean": 33.15375900268555, "eval/image_loss_std": 32.36976623535156, "eval/model_loss_mean": 48.53568649291992, "eval/model_loss_std": 38.57247543334961, "eval/post_ent_mag": 39.65234375, "eval/post_ent_max": 39.65234375, "eval/post_ent_mean": 29.43029022216797, "eval/post_ent_min": 17.738868713378906, "eval/post_ent_std": 3.587244749069214, "eval/prior_ent_mag": 75.9056396484375, "eval/prior_ent_max": 75.9056396484375, "eval/prior_ent_mean": 40.653724670410156, "eval/prior_ent_min": 17.85118865966797, "eval/prior_ent_std": 7.8495025634765625, "eval/rep_loss_mean": 25.381446838378906, "eval/rep_loss_std": 13.960297584533691, "eval/reward_avg": 0.02724609337747097, "eval/reward_loss_mean": 0.15305651724338531, "eval/reward_loss_std": 1.0760858058929443, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0014598369598389, "eval/reward_neg_acc": 0.9969818592071533, "eval/reward_neg_loss": 0.06388205289840698, "eval/reward_pos_acc": 0.6666666865348816, "eval/reward_pos_loss": 3.1077041625976562, "eval/reward_pred": 0.020061004906892776, "eval/reward_rate": 0.029296875, "replay/size": 116653.0, "replay/inserts": 2169.0, "replay/samples": 34704.0, "replay/insert_wait_avg": 2.5022409104047804e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.680865024410123e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 23832.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 8.195638656616211e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.398001909256, "timer/env.step_count": 271.0, "timer/env.step_total": 21.946210384368896, "timer/env.step_frac": 0.021937479225752784, "timer/env.step_avg": 0.08098232614158264, "timer/env.step_min": 0.02365422248840332, "timer/env.step_max": 1.5943503379821777, "timer/replay._sample_count": 34704.0, "timer/replay._sample_total": 16.62428379058838, "timer/replay._sample_frac": 0.016617669926230354, "timer/replay._sample_avg": 0.00047903076851626264, "timer/replay._sample_min": 0.00033593177795410156, "timer/replay._sample_max": 0.010053396224975586, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 271.0, "timer/agent.policy_total": 4.173397779464722, "timer/agent.policy_frac": 0.004171737420006644, "timer/agent.policy_avg": 0.015399991806142885, "timer/agent.policy_min": 0.014438390731811523, "timer/agent.policy_max": 0.03412199020385742, "timer/dataset_train_count": 2169.0, "timer/dataset_train_total": 0.3978400230407715, "timer/dataset_train_frac": 0.0003976817449470063, "timer/dataset_train_avg": 0.00018342094192751106, "timer/dataset_train_min": 9.441375732421875e-05, "timer/dataset_train_max": 0.0007011890411376953, "timer/agent.train_count": 2169.0, "timer/agent.train_total": 963.406788110733, "timer/agent.train_frac": 0.9630235029179133, "timer/agent.train_avg": 0.4441709488753956, "timer/agent.train_min": 0.4319343566894531, "timer/agent.train_max": 0.5756387710571289, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4761228561401367, "timer/agent.report_frac": 0.0004759334337248355, "timer/agent.report_avg": 0.23806142807006836, "timer/agent.report_min": 0.23238396644592285, "timer/agent.report_max": 0.24373888969421387, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.86102294921875e-05, "timer/dataset_eval_frac": 2.8598847096440598e-08, "timer/dataset_eval_avg": 2.86102294921875e-05, "timer/dataset_eval_min": 2.86102294921875e-05, "timer/dataset_eval_max": 2.86102294921875e-05, "fps": 2.1681068626101188}
{"step": 117392, "time": 54440.66225671768, "episode/length": 153.0, "episode/score": 4.28675011190353, "episode/reward_rate": 0.9545454545454546, "episode/intrinsic_return": 0.18674999609356746}
{"step": 117488, "time": 54485.904500961304, "episode/length": 180.0, "episode/score": 6.302500267081086, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.20250015295914636}
{"step": 117536, "time": 54509.508093595505, "episode/length": 170.0, "episode/score": 4.278051638281795, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.17805151432276034}
{"step": 117544, "time": 54514.756178855896, "episode/length": 146.0, "episode/score": 4.25818094853912, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.15818086413219135}
{"step": 117680, "time": 54578.40835785866, "episode/length": 167.0, "episode/score": 3.257381247137346, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.1573811529806335}
{"step": 117800, "time": 54634.66012978554, "episode/length": 198.0, "episode/score": 5.28147058104787, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.18147053159464122}
{"step": 118144, "time": 54792.924589157104, "episode/length": 215.0, "episode/score": 5.34702286650554, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.24702271844853385}
{"step": 118400, "time": 54911.43992495537, "episode/length": 113.0, "episode/score": 4.236833480012137, "episode/reward_rate": 0.9473684210526315, "episode/intrinsic_return": 0.13683333055814728}
{"step": 118432, "time": 54927.7959253788, "episode/length": 185.0, "episode/score": 5.286915600325301, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.18691554831093526}
{"step": 118936, "time": 55160.19540953636, "episode/length": 192.0, "episode/score": 5.306617980591909, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.20661789638870687}
{"step": 119152, "time": 55260.535086393356, "episode/length": 168.0, "episode/score": 5.289907319451231, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.1899071668540273}
{"step": 119272, "time": 55316.978375673294, "episode/length": 216.0, "episode/score": 6.349075589410859, "episode/reward_rate": 0.9631336405529954, "episode/intrinsic_return": 0.24907544260531722}
{"step": 119272, "time": 55316.98791241646, "episode/length": 198.0, "episode/score": 5.300686411324023, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.20068619899120677}
{"step": 119300, "time": 55333.72946047783, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.811622513172239, "train/action_min": 0.0, "train/action_std": 3.925405850521354, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04570038383610027, "train/actor_opt_grad_steps": 116670.0, "train/actor_opt_loss": -9.096666740123617, "train/adv_mag": 0.656401917130448, "train/adv_max": 0.5993764008200446, "train/adv_mean": 0.0042035215256091335, "train/adv_min": -0.5116224124681118, "train/adv_std": 0.05646218595116637, "train/cont_avg": 0.9942314680232558, "train/cont_loss_mean": 1.608446798585181e-05, "train/cont_loss_std": 0.00045677545751623467, "train/cont_neg_acc": 0.9994832041651703, "train/cont_neg_loss": 0.0016648137794343415, "train/cont_pos_acc": 0.9999999817027602, "train/cont_pos_loss": 2.943649587376608e-06, "train/cont_pred": 0.9942351892937061, "train/cont_rate": 0.9942314680232558, "train/dyn_loss_mean": 3.0529172309609347, "train/dyn_loss_std": 7.837371792904166, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.078241627160893, "train/extr_critic_critic_opt_grad_steps": 116670.0, "train/extr_critic_critic_opt_loss": 15385.35913880814, "train/extr_critic_mag": 9.658226294850195, "train/extr_critic_max": 9.658226294850195, "train/extr_critic_mean": 2.128590832754623, "train/extr_critic_min": -0.6662165103956711, "train/extr_critic_std": 2.149105650879616, "train/extr_return_normed_mag": 1.6110127354777137, "train/extr_return_normed_max": 1.6110127354777137, "train/extr_return_normed_mean": 0.36660965798899187, "train/extr_return_normed_min": -0.11433706453373266, "train/extr_return_normed_std": 0.34056775188723276, "train/extr_return_rate": 0.6869698166847229, "train/extr_return_raw_mag": 10.231570152903712, "train/extr_return_raw_max": 10.231570152903712, "train/extr_return_raw_mean": 2.156392176206722, "train/extr_return_raw_min": -0.9487860715666483, "train/extr_return_raw_std": 2.203306669967119, "train/extr_reward_mag": 1.0182690332102222, "train/extr_reward_max": 1.0182690332102222, "train/extr_reward_mean": 0.03385759643170723, "train/extr_reward_min": -0.6671677644862685, "train/extr_reward_std": 0.18020045188970343, "train/image_loss_mean": 1.5984533653702846, "train/image_loss_std": 4.910163210713586, "train/model_loss_mean": 3.501770985403726, "train/model_loss_std": 8.734106125942496, "train/model_opt_grad_norm": 33.09454748020616, "train/model_opt_grad_steps": 116575.57674418605, "train/model_opt_loss": 6261.085217569041, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1802.3255813953488, "train/policy_entropy_mag": 2.618979894283206, "train/policy_entropy_max": 2.618979894283206, "train/policy_entropy_mean": 0.5044248032015424, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6350000044634175, "train/policy_logprob_mag": 7.438384058309156, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5043448911156765, "train/policy_logprob_min": -7.438384058309156, "train/policy_logprob_std": 1.0992068243581194, "train/policy_randomness_mag": 0.9243849734927333, "train/policy_randomness_max": 0.9243849734927333, "train/policy_randomness_mean": 0.17803982052692147, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.22412713641344115, "train/post_ent_mag": 45.381423666310866, "train/post_ent_max": 45.381423666310866, "train/post_ent_mean": 25.692458316891692, "train/post_ent_min": 13.119626741631086, "train/post_ent_std": 4.53143856469975, "train/prior_ent_mag": 75.8599263745685, "train/prior_ent_max": 75.8599263745685, "train/prior_ent_mean": 28.663961357294127, "train/prior_ent_min": 14.525672411364178, "train/prior_ent_std": 8.856818715916123, "train/rep_loss_mean": 3.0529172309609347, "train/rep_loss_std": 7.837371792904166, "train/reward_avg": 0.019749558830720396, "train/reward_loss_mean": 0.07155119180679322, "train/reward_loss_std": 0.15676458017077557, "train/reward_max_data": 1.0091570072395857, "train/reward_max_pred": 1.0096543223358865, "train/reward_neg_acc": 0.9992828083592792, "train/reward_neg_loss": 0.0510849968638531, "train/reward_pos_acc": 0.9366313834523046, "train/reward_pos_loss": 0.7136623360389887, "train/reward_pred": 0.019695617949460134, "train/reward_rate": 0.03091388081395349, "train_stats/sum_log_reward": 4.792307670299824, "train_stats/max_log_achievement_collect_drink": 3.769230769230769, "train_stats/max_log_achievement_collect_sapling": 2.1538461538461537, "train_stats/max_log_achievement_collect_wood": 4.6923076923076925, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.15384615384615385, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 2.076923076923077, "train_stats/max_log_achievement_place_table": 1.9230769230769231, "train_stats/max_log_achievement_wake_up": 1.3846153846153846, "train_stats/mean_log_entropy": 0.41577593638346744, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 2.4180539526241773e-07, "report/cont_loss_std": 4.7531310087833845e-07, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 6.358125574479345e-06, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 2.1781981729418476e-07, "report/cont_pred": 0.9960936307907104, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 2.942188262939453, "report/dyn_loss_std": 7.4541239738464355, "report/image_loss_mean": 1.1199266910552979, "report/image_loss_std": 5.449841499328613, "report/model_loss_mean": 2.955265998840332, "report/model_loss_std": 9.042587280273438, "report/post_ent_mag": 48.159034729003906, "report/post_ent_max": 48.159034729003906, "report/post_ent_mean": 26.1688289642334, "report/post_ent_min": 14.603656768798828, "report/post_ent_std": 4.085000514984131, "report/prior_ent_mag": 76.13507080078125, "report/prior_ent_max": 76.13507080078125, "report/prior_ent_mean": 29.12557601928711, "report/prior_ent_min": 16.010311126708984, "report/prior_ent_std": 8.360867500305176, "report/rep_loss_mean": 2.942188262939453, "report/rep_loss_std": 7.4541239738464355, "report/reward_avg": 0.02657381445169449, "report/reward_loss_mean": 0.07002611458301544, "report/reward_loss_std": 0.14304949343204498, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.003730058670044, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.04627430811524391, "report/reward_pos_acc": 0.9210526347160339, "report/reward_pos_loss": 0.6863230466842651, "report/reward_pred": 0.026686299592256546, "report/reward_rate": 0.037109375, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 3.6730798456119373e-05, "eval/cont_loss_std": 0.001145828515291214, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0002882167755160481, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 3.6238652683096007e-05, "eval/cont_pred": 0.9980120062828064, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 25.038171768188477, "eval/dyn_loss_std": 13.663491249084473, "eval/image_loss_mean": 44.51287841796875, "eval/image_loss_std": 42.52910614013672, "eval/model_loss_mean": 59.7479362487793, "eval/model_loss_std": 48.078453063964844, "eval/post_ent_mag": 40.991539001464844, "eval/post_ent_max": 40.991539001464844, "eval/post_ent_mean": 28.468456268310547, "eval/post_ent_min": 14.136439323425293, "eval/post_ent_std": 3.7093610763549805, "eval/prior_ent_mag": 76.13507080078125, "eval/prior_ent_max": 76.13507080078125, "eval/prior_ent_mean": 38.66442108154297, "eval/prior_ent_min": 14.742637634277344, "eval/prior_ent_std": 8.467838287353516, "eval/rep_loss_mean": 25.038171768188477, "eval/rep_loss_std": 13.663491249084473, "eval/reward_avg": 0.02939453162252903, "eval/reward_loss_mean": 0.21212059259414673, "eval/reward_loss_std": 1.2467888593673706, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0040650367736816, "eval/reward_neg_acc": 0.9939454793930054, "eval/reward_neg_loss": 0.12696295976638794, "eval/reward_pos_acc": 0.7575757503509521, "eval/reward_pos_loss": 2.7694294452667236, "eval/reward_pred": 0.025035912171006203, "eval/reward_rate": 0.0322265625, "replay/size": 118796.0, "replay/inserts": 2143.0, "replay/samples": 34288.0, "replay/insert_wait_avg": 2.5792150813399547e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.962768900021737e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 23832.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 9.685754776000977e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.239004611969, "timer/env.step_count": 268.0, "timer/env.step_total": 27.855157136917114, "timer/env.step_frac": 0.0278485012166899, "timer/env.step_avg": 0.10393715349595938, "timer/env.step_min": 0.024668455123901367, "timer/env.step_max": 3.2850959300994873, "timer/replay._sample_count": 34288.0, "timer/replay._sample_total": 16.719275951385498, "timer/replay._sample_frac": 0.016715280922154747, "timer/replay._sample_avg": 0.00048761304104600727, "timer/replay._sample_min": 0.00035762786865234375, "timer/replay._sample_max": 0.02888345718383789, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 268.0, "timer/agent.policy_total": 4.257555246353149, "timer/agent.policy_frac": 0.004256537914160644, "timer/agent.policy_avg": 0.015886400172959513, "timer/agent.policy_min": 0.014460086822509766, "timer/agent.policy_max": 0.04499173164367676, "timer/dataset_train_count": 2143.0, "timer/dataset_train_total": 0.41217875480651855, "timer/dataset_train_frac": 0.0004120802657225095, "timer/dataset_train_avg": 0.00019233726309216917, "timer/dataset_train_min": 9.560585021972656e-05, "timer/dataset_train_max": 0.0008764266967773438, "timer/agent.train_count": 2143.0, "timer/agent.train_total": 956.3852469921112, "timer/agent.train_frac": 0.9561567211259969, "timer/agent.train_avg": 0.44628336303878263, "timer/agent.train_min": 0.4359097480773926, "timer/agent.train_max": 0.5971806049346924, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47376012802124023, "timer/agent.report_frac": 0.0004736469242219063, "timer/agent.report_avg": 0.23688006401062012, "timer/agent.report_min": 0.2297525405883789, "timer/agent.report_max": 0.24400758743286133, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7418136596679688e-05, "timer/dataset_eval_frac": 2.7411585101419067e-08, "timer/dataset_eval_avg": 2.7418136596679688e-05, "timer/dataset_eval_min": 2.7418136596679688e-05, "timer/dataset_eval_max": 2.7418136596679688e-05, "fps": 2.1424585305557695}
{"step": 119392, "time": 55376.14320707321, "episode/length": 230.0, "episode/score": 4.353405249516982, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.25340508038880216}
{"step": 119408, "time": 55384.97075009346, "episode/length": 157.0, "episode/score": 5.28334545229518, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.18334536832480808}
{"step": 119744, "time": 55540.95900726318, "episode/length": 167.0, "episode/score": 5.298610250029014, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.19861011509783566}
{"step": 119928, "time": 55627.09174871445, "episode/length": 186.0, "episode/score": 4.277824676379623, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.17782458265946843}
{"step": 120016, "time": 55687.44472503662, "eval_episode/length": 97.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9489795918367347}
{"step": 120016, "time": 55692.1057870388, "eval_episode/length": 169.0, "eval_episode/score": 4.099999971687794, "eval_episode/reward_rate": 0.9941176470588236}
{"step": 120016, "time": 55693.82142210007, "eval_episode/length": 170.0, "eval_episode/score": 4.099999979138374, "eval_episode/reward_rate": 0.9941520467836257}
{"step": 120016, "time": 55695.51004767418, "eval_episode/length": 175.0, "eval_episode/score": 2.100000023841858, "eval_episode/reward_rate": 0.9943181818181818}
{"step": 120016, "time": 55698.43823456764, "eval_episode/length": 207.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9951923076923077}
{"step": 120016, "time": 55700.26598286629, "eval_episode/length": 214.0, "eval_episode/score": 5.1000000312924385, "eval_episode/reward_rate": 0.9953488372093023}
{"step": 120016, "time": 55701.86528658867, "eval_episode/length": 216.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9723502304147466}
{"step": 120016, "time": 55703.54186344147, "eval_episode/length": 221.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9774774774774775}
{"step": 120504, "time": 55927.94186210632, "episode/length": 153.0, "episode/score": 3.2561684544125455, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.15616832894011168}
{"step": 120568, "time": 55958.85682344437, "episode/length": 203.0, "episode/score": 5.324324544446426, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.2243243385310052}
{"step": 120632, "time": 55989.794241666794, "episode/length": 184.0, "episode/score": 3.2979345422281767, "episode/reward_rate": 0.9675675675675676, "episode/intrinsic_return": 0.19793445156392409}
{"step": 120928, "time": 56126.97789001465, "episode/length": 147.0, "episode/score": 5.230008198246651, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.130008045649447}
{"step": 120944, "time": 56136.03531336784, "episode/length": 193.0, "episode/score": 7.296406911711529, "episode/reward_rate": 0.9845360824742269, "episode/intrinsic_return": 0.19640670696026064}
{"step": 121280, "time": 56292.59936571121, "episode/length": 250.0, "episode/score": 5.39149969965365, "episode/reward_rate": 0.9800796812749004, "episode/intrinsic_return": 0.29149954822059954}
{"step": 121304, "time": 56305.27989768982, "episode/length": 171.0, "episode/score": 4.295192627005235, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.1951924207405682}
{"step": 121312, "time": 56310.44206929207, "episode/length": 237.0, "episode/score": 4.350671409367351, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.25067127562942915}
{"step": 121359, "time": 56334.12925052643, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.006032059832317, "train/action_min": 0.0, "train/action_std": 4.062142973411374, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04293057366115291, "train/actor_opt_grad_steps": 118770.0, "train/actor_opt_loss": -11.883883613420696, "train/adv_mag": 0.5668605791359413, "train/adv_max": 0.5122811113915793, "train/adv_mean": 0.0022012842241986995, "train/adv_min": -0.4854315950376232, "train/adv_std": 0.05005566688572488, "train/cont_avg": 0.9943073551829268, "train/cont_loss_mean": 3.2783825733764474e-05, "train/cont_loss_std": 0.0009946711538591944, "train/cont_neg_acc": 0.997502334854182, "train/cont_neg_loss": 0.004789513836664239, "train/cont_pos_acc": 0.9999999825547381, "train/cont_pos_loss": 4.4459249146373665e-06, "train/cont_pred": 0.9943173739968276, "train/cont_rate": 0.9943073551829268, "train/dyn_loss_mean": 3.064487293289929, "train/dyn_loss_std": 7.7996056207796425, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0739191398388002, "train/extr_critic_critic_opt_grad_steps": 118770.0, "train/extr_critic_critic_opt_loss": 15362.737514291159, "train/extr_critic_mag": 11.879436399878525, "train/extr_critic_max": 11.879436399878525, "train/extr_critic_mean": 2.666879079400039, "train/extr_critic_min": -0.6420275600945077, "train/extr_critic_std": 2.877874373226631, "train/extr_return_normed_mag": 1.4107694916608857, "train/extr_return_normed_max": 1.4107694916608857, "train/extr_return_normed_mean": 0.3239509890719158, "train/extr_return_normed_min": -0.08520379990521, "train/extr_return_normed_std": 0.32824340738901275, "train/extr_return_rate": 0.6834835852064738, "train/extr_return_raw_mag": 12.339646069596453, "train/extr_return_raw_max": 12.339646069596453, "train/extr_return_raw_mean": 2.686242273958718, "train/extr_return_raw_min": -0.9545991282637526, "train/extr_return_raw_std": 2.925502649749198, "train/extr_reward_mag": 1.0214693999871975, "train/extr_reward_max": 1.0214693999871975, "train/extr_reward_mean": 0.029173539179127392, "train/extr_reward_min": -0.6719525500041682, "train/extr_reward_std": 0.16927912809499882, "train/image_loss_mean": 1.6055563066063858, "train/image_loss_std": 4.910951884199934, "train/model_loss_mean": 3.515896301734738, "train/model_loss_std": 8.677375449203863, "train/model_opt_grad_norm": 32.88350752388559, "train/model_opt_grad_steps": 118674.54146341463, "train/model_opt_loss": 8602.658723561357, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2457.317073170732, "train/policy_entropy_mag": 2.643903215920053, "train/policy_entropy_max": 2.643903215920053, "train/policy_entropy_mean": 0.5526683305821768, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6721256616638928, "train/policy_logprob_mag": 7.438384032830959, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5529795684465548, "train/policy_logprob_min": -7.438384032830959, "train/policy_logprob_std": 1.1301263239325547, "train/policy_randomness_mag": 0.9331818097975196, "train/policy_randomness_max": 0.9331818097975196, "train/policy_randomness_mean": 0.19506766788843202, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.23723086329495036, "train/post_ent_mag": 45.78394291575362, "train/post_ent_max": 45.78394291575362, "train/post_ent_mean": 25.894367580879024, "train/post_ent_min": 12.848612241047185, "train/post_ent_std": 4.6388073897943265, "train/prior_ent_mag": 75.81404333347227, "train/prior_ent_max": 75.81404333347227, "train/prior_ent_mean": 28.89186582797911, "train/prior_ent_min": 14.27305169454435, "train/prior_ent_std": 8.889927317456502, "train/rep_loss_mean": 3.064487293289929, "train/rep_loss_std": 7.7996056207796425, "train/reward_avg": 0.019829517239477575, "train/reward_loss_mean": 0.07161485265667845, "train/reward_loss_std": 0.15396793753635593, "train/reward_max_data": 1.010030518508539, "train/reward_max_pred": 1.0106131007031696, "train/reward_neg_acc": 0.9992522768858002, "train/reward_neg_loss": 0.05090782015425403, "train/reward_pos_acc": 0.9289216826601726, "train/reward_pos_loss": 0.7117716137955828, "train/reward_pred": 0.019687226646375365, "train/reward_rate": 0.031311928353658536, "train_stats/sum_log_reward": 4.599999984105428, "train_stats/max_log_achievement_collect_drink": 2.9166666666666665, "train_stats/max_log_achievement_collect_sapling": 2.3333333333333335, "train_stats/max_log_achievement_collect_wood": 3.0833333333333335, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.08333333333333333, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.08333333333333333, "train_stats/max_log_achievement_place_plant": 1.5833333333333333, "train_stats/max_log_achievement_place_table": 1.1666666666666667, "train_stats/max_log_achievement_wake_up": 2.3333333333333335, "train_stats/mean_log_entropy": 0.5227073679367701, "eval_stats/sum_log_reward": 3.600000038743019, "eval_stats/max_log_achievement_collect_drink": 6.125, "eval_stats/max_log_achievement_collect_sapling": 0.875, "eval_stats/max_log_achievement_collect_wood": 2.625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.25, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 0.625, "eval_stats/max_log_achievement_place_table": 0.875, "eval_stats/max_log_achievement_wake_up": 2.375, "eval_stats/mean_log_entropy": 0.0, "eval_stats/max_log_achievement_collect_stone": 0.3333333333333333, "train_stats/max_log_achievement_collect_stone": 0.0, "report/cont_avg": 0.9912109375, "report/cont_loss_mean": 7.713236414019775e-07, "report/cont_loss_std": 2.5461242785240756e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 1.938996501849033e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 6.062322199795744e-07, "report/cont_pred": 0.9912105798721313, "report/cont_rate": 0.9912109375, "report/dyn_loss_mean": 3.813713312149048, "report/dyn_loss_std": 8.805768966674805, "report/image_loss_mean": 3.3871312141418457, "report/image_loss_std": 8.41237735748291, "report/model_loss_mean": 5.757809162139893, "report/model_loss_std": 12.111980438232422, "report/post_ent_mag": 43.84288787841797, "report/post_ent_max": 43.84288787841797, "report/post_ent_mean": 26.76557159423828, "report/post_ent_min": 12.112260818481445, "report/post_ent_std": 4.63856315612793, "report/prior_ent_mag": 75.42217254638672, "report/prior_ent_max": 75.42217254638672, "report/prior_ent_mean": 30.096464157104492, "report/prior_ent_min": 13.343162536621094, "report/prior_ent_std": 9.233288764953613, "report/rep_loss_mean": 3.813713312149048, "report/rep_loss_std": 8.805768966674805, "report/reward_avg": 0.018533019348978996, "report/reward_loss_mean": 0.08244934678077698, "report/reward_loss_std": 0.18392127752304077, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0028302669525146, "report/reward_neg_acc": 0.9989888072013855, "report/reward_neg_loss": 0.05949316918849945, "report/reward_pos_acc": 0.9714285731315613, "report/reward_pos_loss": 0.7311252951622009, "report/reward_pred": 0.01784220151603222, "report/reward_rate": 0.0341796875, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.005100450944155455, "eval/cont_loss_std": 0.1629321426153183, "eval/cont_neg_acc": 0.75, "eval/cont_neg_loss": 1.3056082725524902, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 4.212117232782475e-07, "eval/cont_pred": 0.9970706105232239, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 24.173709869384766, "eval/dyn_loss_std": 14.218181610107422, "eval/image_loss_mean": 32.303009033203125, "eval/image_loss_std": 34.670711517333984, "eval/model_loss_mean": 46.91706848144531, "eval/model_loss_std": 40.92915725708008, "eval/post_ent_mag": 43.472686767578125, "eval/post_ent_max": 43.472686767578125, "eval/post_ent_mean": 29.135276794433594, "eval/post_ent_min": 18.159513473510742, "eval/post_ent_std": 3.059643507003784, "eval/prior_ent_mag": 75.42217254638672, "eval/prior_ent_max": 75.42217254638672, "eval/prior_ent_mean": 40.007286071777344, "eval/prior_ent_min": 19.49453353881836, "eval/prior_ent_std": 7.630944728851318, "eval/rep_loss_mean": 24.173709869384766, "eval/rep_loss_std": 14.218181610107422, "eval/reward_avg": 0.0224609375, "eval/reward_loss_mean": 0.10473689436912537, "eval/reward_loss_std": 0.778053343296051, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 1.0024304389953613, "eval/reward_neg_acc": 0.9959920048713684, "eval/reward_neg_loss": 0.040691643953323364, "eval/reward_pos_acc": 0.7307692766189575, "eval/reward_pos_loss": 2.563089370727539, "eval/reward_pred": 0.016926847398281097, "eval/reward_rate": 0.025390625, "replay/size": 120855.0, "replay/inserts": 2059.0, "replay/samples": 32944.0, "replay/insert_wait_avg": 2.6074354367212164e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.015652314269931e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 25608.0, "eval_replay/inserts": 1776.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2561276152327253e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.344650268554688e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3826553821564, "timer/env.step_count": 257.0, "timer/env.step_total": 25.29168725013733, "timer/env.step_frac": 0.02528201295180957, "timer/env.step_avg": 0.09841123443633203, "timer/env.step_min": 0.02387380599975586, "timer/env.step_max": 1.7375590801239014, "timer/replay._sample_count": 32944.0, "timer/replay._sample_total": 16.637141942977905, "timer/replay._sample_frac": 0.01663077808623376, "timer/replay._sample_avg": 0.0005050128078854391, "timer/replay._sample_min": 0.00037598609924316406, "timer/replay._sample_max": 0.011152505874633789, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 479.0, "timer/agent.policy_total": 9.101497650146484, "timer/agent.policy_frac": 0.009098016245263288, "timer/agent.policy_avg": 0.01900103893558765, "timer/agent.policy_min": 0.010153055191040039, "timer/agent.policy_max": 0.1315004825592041, "timer/dataset_train_count": 2059.0, "timer/dataset_train_total": 0.41774678230285645, "timer/dataset_train_frac": 0.0004175869903934639, "timer/dataset_train_avg": 0.00020288818955942518, "timer/dataset_train_min": 0.00010347366333007812, "timer/dataset_train_max": 0.0007138252258300781, "timer/agent.train_count": 2059.0, "timer/agent.train_total": 924.7087225914001, "timer/agent.train_frac": 0.9243550131705872, "timer/agent.train_avg": 0.4491057419093736, "timer/agent.train_min": 0.43796324729919434, "timer/agent.train_max": 0.5859701633453369, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4712488651275635, "timer/agent.report_frac": 0.0004710686081892749, "timer/agent.report_avg": 0.23562443256378174, "timer/agent.report_min": 0.2254350185394287, "timer/agent.report_max": 0.24581384658813477, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8371810913085938e-05, "timer/dataset_eval_frac": 2.8360958439695873e-08, "timer/dataset_eval_avg": 2.8371810913085938e-05, "timer/dataset_eval_min": 2.8371810913085938e-05, "timer/dataset_eval_max": 2.8371810913085938e-05, "fps": 2.05818527434607}
{"step": 121936, "time": 56599.33416366577, "episode/length": 178.0, "episode/score": 3.286133460354904, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.18613328156425268}
{"step": 122280, "time": 56758.081233501434, "episode/length": 205.0, "episode/score": 6.332634668047831, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.23263447214412736}
{"step": 122288, "time": 56763.264807224274, "episode/length": 214.0, "episode/score": 5.35439098824645, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.2543908524130529}
{"step": 122352, "time": 56794.01922941208, "episode/length": 175.0, "episode/score": 3.27400734594994, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.17400725179322762}
{"step": 122488, "time": 56857.51704907417, "episode/length": 194.0, "episode/score": 5.291887067924108, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.19188704710904858}
{"step": 122544, "time": 56884.7795817852, "episode/length": 154.0, "episode/score": 5.2638158191157345, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.16381572653062904}
{"step": 122592, "time": 56908.08019280434, "episode/length": 159.0, "episode/score": 4.272995628685749, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.17299547213042388}
{"step": 122608, "time": 56916.80279827118, "episode/length": 165.0, "episode/score": 3.2670335102993704, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.16703338599108974}
{"step": 122616, "time": 56922.0153734684, "episode/length": 84.0, "episode/score": 0.19554337907902664, "episode/reward_rate": 0.9529411764705882, "episode/intrinsic_return": 0.09554335477150744}
{"step": 123514, "time": 57334.18548536301, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.123647054036458, "train/action_min": 0.0, "train/action_std": 4.070368678481491, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04494205038753097, "train/actor_opt_grad_steps": 120875.0, "train/actor_opt_loss": -11.39569151373925, "train/adv_mag": 0.6209913115534518, "train/adv_max": 0.550116706777502, "train/adv_mean": 0.0025127522469311453, "train/adv_min": -0.5293272655043337, "train/adv_std": 0.051713414783417073, "train/cont_avg": 0.9944209346064815, "train/cont_loss_mean": 8.994970246242226e-06, "train/cont_loss_std": 0.00026915323005554184, "train/cont_neg_acc": 1.0, "train/cont_neg_loss": 0.0012487197627495806, "train/cont_pos_acc": 0.9999999806836799, "train/cont_pos_loss": 1.9630220341418884e-06, "train/cont_pred": 0.9944247862807026, "train/cont_rate": 0.9944209346064815, "train/dyn_loss_mean": 3.069756399702143, "train/dyn_loss_std": 7.8437144954999285, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0909296265906758, "train/extr_critic_critic_opt_grad_steps": 120875.0, "train/extr_critic_critic_opt_loss": 15482.984899450232, "train/extr_critic_mag": 13.31140571170383, "train/extr_critic_max": 13.31140571170383, "train/extr_critic_mean": 2.848585974838999, "train/extr_critic_min": -0.6349118843122765, "train/extr_critic_std": 3.1333516394650496, "train/extr_return_normed_mag": 1.5003645320733388, "train/extr_return_normed_max": 1.5003645320733388, "train/extr_return_normed_mean": 0.3294357253169572, "train/extr_return_normed_min": -0.08399213590072813, "train/extr_return_normed_std": 0.342082596556456, "train/extr_return_rate": 0.6753891538138743, "train/extr_return_raw_mag": 13.763673274605363, "train/extr_return_raw_max": 13.763673274605363, "train/extr_return_raw_mean": 2.8719331660756358, "train/extr_return_raw_min": -0.9774782458941141, "train/extr_return_raw_std": 3.189190101844293, "train/extr_reward_mag": 1.0200358033180237, "train/extr_reward_max": 1.0200358033180237, "train/extr_reward_mean": 0.030626183431768032, "train/extr_reward_min": -0.6798939467580231, "train/extr_reward_std": 0.172458841016999, "train/image_loss_mean": 1.6073278547437102, "train/image_loss_std": 5.0754817249598325, "train/model_loss_mean": 3.520204081579491, "train/model_loss_std": 8.866283825150242, "train/model_opt_grad_norm": 32.787504805458916, "train/model_opt_grad_steps": 120777.31018518518, "train/model_opt_loss": 6810.305191605179, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1944.4444444444443, "train/policy_entropy_mag": 2.6597145718556865, "train/policy_entropy_max": 2.6597145718556865, "train/policy_entropy_mean": 0.5879711058956606, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.7052838682300515, "train/policy_logprob_mag": 7.438384067129205, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5885301796650445, "train/policy_logprob_min": -7.438384067129205, "train/policy_logprob_std": 1.1534465220239427, "train/policy_randomness_mag": 0.9387625270971546, "train/policy_randomness_max": 0.9387625270971546, "train/policy_randomness_mean": 0.20752799911079584, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.24893425315342568, "train/post_ent_mag": 45.583636619426585, "train/post_ent_max": 45.583636619426585, "train/post_ent_mean": 26.151439172250253, "train/post_ent_min": 13.126902041611848, "train/post_ent_std": 4.627623129774023, "train/prior_ent_mag": 75.87470697473597, "train/prior_ent_max": 75.87470697473597, "train/prior_ent_mean": 29.136751148435806, "train/prior_ent_min": 14.704612025508174, "train/prior_ent_std": 8.838185957184544, "train/rep_loss_mean": 3.069756399702143, "train/rep_loss_std": 7.8437144954999285, "train/reward_avg": 0.019727305065047135, "train/reward_loss_mean": 0.07101342218272665, "train/reward_loss_std": 0.15527024709930023, "train/reward_max_data": 1.0091204008570425, "train/reward_max_pred": 1.009407991612399, "train/reward_neg_acc": 0.9992392902021054, "train/reward_neg_loss": 0.0506037592853385, "train/reward_pos_acc": 0.9314621982199175, "train/reward_pos_loss": 0.7137896490317804, "train/reward_pred": 0.019607238350781025, "train/reward_rate": 0.030815972222222224, "train_stats/sum_log_reward": 3.8777777469820447, "train_stats/max_log_achievement_collect_drink": 3.111111111111111, "train_stats/max_log_achievement_collect_sapling": 1.2222222222222223, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 3.0, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.1111111111111111, "train_stats/max_log_achievement_place_plant": 1.1111111111111112, "train_stats/max_log_achievement_place_table": 1.2222222222222223, "train_stats/max_log_achievement_wake_up": 1.7777777777777777, "train_stats/mean_log_entropy": 0.48583922286828357, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.00032625425956211984, "report/cont_loss_std": 0.010412223637104034, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.06668684631586075, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 6.380369654834794e-07, "report/cont_pred": 0.9953935146331787, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 2.855746030807495, "report/dyn_loss_std": 7.835987091064453, "report/image_loss_mean": 2.0909342765808105, "report/image_loss_std": 3.9737813472747803, "report/model_loss_mean": 3.879998207092285, "report/model_loss_std": 7.725331783294678, "report/post_ent_mag": 48.51190948486328, "report/post_ent_max": 48.51190948486328, "report/post_ent_mean": 24.830320358276367, "report/post_ent_min": 12.18435001373291, "report/post_ent_std": 4.458787441253662, "report/prior_ent_mag": 75.76681518554688, "report/prior_ent_max": 75.76681518554688, "report/prior_ent_mean": 27.684307098388672, "report/prior_ent_min": 13.23956298828125, "report/prior_ent_std": 8.694502830505371, "report/rep_loss_mean": 2.855746030807495, "report/rep_loss_std": 7.835987091064453, "report/reward_avg": 0.016268257051706314, "report/reward_loss_mean": 0.07529027760028839, "report/reward_loss_std": 0.14030058681964874, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0030157566070557, "report/reward_neg_acc": 0.9999999403953552, "report/reward_neg_loss": 0.05451291799545288, "report/reward_pos_acc": 0.9705882668495178, "report/reward_pos_loss": 0.680277943611145, "report/reward_pred": 0.01600509136915207, "report/reward_rate": 0.033203125, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.00030245358357205987, "eval/cont_loss_std": 0.009646016173064709, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.07724007219076157, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 7.374479196187167e-07, "eval/cont_pred": 0.9963526725769043, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 26.199399948120117, "eval/dyn_loss_std": 14.666061401367188, "eval/image_loss_mean": 40.08868408203125, "eval/image_loss_std": 39.839988708496094, "eval/model_loss_mean": 56.0106201171875, "eval/model_loss_std": 46.06330108642578, "eval/post_ent_mag": 45.83060073852539, "eval/post_ent_max": 45.83060073852539, "eval/post_ent_mean": 29.49011993408203, "eval/post_ent_min": 14.657537460327148, "eval/post_ent_std": 4.560847282409668, "eval/prior_ent_mag": 75.76681518554688, "eval/prior_ent_max": 75.76681518554688, "eval/prior_ent_mean": 40.423980712890625, "eval/prior_ent_min": 16.47693634033203, "eval/prior_ent_std": 8.535164833068848, "eval/rep_loss_mean": 26.199399948120117, "eval/rep_loss_std": 14.666061401367188, "eval/reward_avg": 0.02353515475988388, "eval/reward_loss_mean": 0.20199793577194214, "eval/reward_loss_std": 1.1190769672393799, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.001838207244873, "eval/reward_neg_acc": 0.9939759969711304, "eval/reward_neg_loss": 0.11896281689405441, "eval/reward_pos_acc": 0.7500000596046448, "eval/reward_pos_loss": 3.1556754112243652, "eval/reward_pred": 0.02045692689716816, "eval/reward_rate": 0.02734375, "replay/size": 123010.0, "replay/inserts": 2155.0, "replay/samples": 34480.0, "replay/insert_wait_avg": 2.5364196494117965e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.783246427566988e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 25608.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 9.5367431640625e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0458443164825, "timer/env.step_count": 270.0, "timer/env.step_total": 20.778979778289795, "timer/env.step_frac": 0.020778027223833862, "timer/env.step_avg": 0.07695918436403627, "timer/env.step_min": 0.023180007934570312, "timer/env.step_max": 1.7709174156188965, "timer/replay._sample_count": 34480.0, "timer/replay._sample_total": 16.88489866256714, "timer/replay._sample_frac": 0.016884124621414465, "timer/replay._sample_avg": 0.0004897012373134321, "timer/replay._sample_min": 0.00034809112548828125, "timer/replay._sample_max": 0.03733015060424805, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 270.0, "timer/agent.policy_total": 4.368642330169678, "timer/agent.policy_frac": 0.004368442061929255, "timer/agent.policy_avg": 0.016180156778406212, "timer/agent.policy_min": 0.014679193496704102, "timer/agent.policy_max": 0.04256391525268555, "timer/dataset_train_count": 2155.0, "timer/dataset_train_total": 0.4112517833709717, "timer/dataset_train_frac": 0.00041123293067834964, "timer/dataset_train_avg": 0.00019083609437168058, "timer/dataset_train_min": 9.870529174804688e-05, "timer/dataset_train_max": 0.0011599063873291016, "timer/agent.train_count": 2155.0, "timer/agent.train_total": 963.4605565071106, "timer/agent.train_frac": 0.9634163893412532, "timer/agent.train_avg": 0.44708146473647825, "timer/agent.train_min": 0.43691349029541016, "timer/agent.train_max": 0.6193697452545166, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47429633140563965, "timer/agent.report_frac": 0.00047427458861129974, "timer/agent.report_avg": 0.23714816570281982, "timer/agent.report_min": 0.23015427589416504, "timer/agent.report_max": 0.2441420555114746, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.743171691894531e-05, "timer/dataset_eval_frac": 3.743000096613508e-08, "timer/dataset_eval_avg": 3.743171691894531e-05, "timer/dataset_eval_min": 3.743171691894531e-05, "timer/dataset_eval_max": 3.743171691894531e-05, "fps": 2.154870359571683}
{"step": 123736, "time": 57435.72308468819, "episode/length": 172.0, "episode/score": 4.285301371088281, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.18530117541740765}
{"step": 123784, "time": 57458.939366817474, "episode/length": 187.0, "episode/score": 1.262993807966268, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.16299374093432561}
{"step": 123824, "time": 57478.6163623333, "episode/length": 159.0, "episode/score": 5.273742886132823, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.17374270454820362}
{"step": 123904, "time": 57516.41159296036, "episode/length": 176.0, "episode/score": 3.30039357600981, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.2003934806889447}
{"step": 123912, "time": 57521.616443157196, "episode/length": 161.0, "episode/score": 3.269190570768842, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.16919044646056136}
{"step": 123984, "time": 57555.93049955368, "episode/length": 211.0, "episode/score": 4.322024257999146, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.2220240482420195}
{"step": 124104, "time": 57612.27359318733, "episode/length": 39.0, "episode/score": 0.14489587215939537, "episode/reward_rate": 0.9, "episode/intrinsic_return": 0.04489583260146901}
{"step": 124136, "time": 57628.48986697197, "episode/length": 192.0, "episode/score": 4.313452471244091, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.21345226148696383}
{"step": 124336, "time": 57720.8188700676, "episode/length": 53.0, "episode/score": 1.1605814589220245, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.06058131317877269}
{"step": 124456, "time": 57777.43147754669, "episode/length": 230.0, "episode/score": 4.366094853809045, "episode/reward_rate": 0.9783549783549783, "episode/intrinsic_return": 0.2660947031909018}
{"step": 125224, "time": 58127.66995668411, "episode/length": 174.0, "episode/score": 3.2813129226797173, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.1813128428420896}
{"step": 125232, "time": 58132.72546553612, "episode/length": 140.0, "episode/score": 3.2462009124355973, "episode/reward_rate": 0.9645390070921985, "episode/intrinsic_return": 0.14620082060719142}
{"step": 125312, "time": 58170.50919151306, "episode/length": 165.0, "episode/score": 5.28716937223362, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.18716920589940855}
{"step": 125424, "time": 58222.829739809036, "episode/length": 188.0, "episode/score": 6.28992399298113, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.1899238019668701}
{"step": 125632, "time": 58318.77735686302, "episode/length": 186.0, "episode/score": 4.290747973049292, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.19074791748425923}
{"step": 125662, "time": 58334.48201036453, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.280211550690407, "train/action_min": 0.0, "train/action_std": 4.1718123214189395, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04054788261825262, "train/actor_opt_grad_steps": 123030.0, "train/actor_opt_loss": -12.482264544243037, "train/adv_mag": 0.5787262504877047, "train/adv_max": 0.5147211318792299, "train/adv_mean": 0.0019058125330724748, "train/adv_min": -0.463641686079114, "train/adv_std": 0.048421242296002635, "train/cont_avg": 0.9943313953488372, "train/cont_loss_mean": 4.735074838077803e-05, "train/cont_loss_std": 0.0014598402452821934, "train/cont_neg_acc": 0.9984496124955111, "train/cont_neg_loss": 0.013619578180530584, "train/cont_pos_acc": 0.9999999833661456, "train/cont_pos_loss": 5.556666569196581e-06, "train/cont_pred": 0.9943338560503583, "train/cont_rate": 0.9943313953488372, "train/dyn_loss_mean": 3.1059123017067134, "train/dyn_loss_std": 7.825766281748927, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.058990089006202, "train/extr_critic_critic_opt_grad_steps": 123030.0, "train/extr_critic_critic_opt_loss": 15106.46050599564, "train/extr_critic_mag": 10.593862365012946, "train/extr_critic_max": 10.593862365012946, "train/extr_critic_mean": 2.7303788013236465, "train/extr_critic_min": -0.6429819489634314, "train/extr_critic_std": 2.690896530484044, "train/extr_return_normed_mag": 1.4615903477336085, "train/extr_return_normed_max": 1.4615903477336085, "train/extr_return_normed_mean": 0.3782070348429125, "train/extr_return_normed_min": -0.10655094918816589, "train/extr_return_normed_std": 0.34819120362747547, "train/extr_return_rate": 0.6980965708577356, "train/extr_return_raw_mag": 11.213196878655012, "train/extr_return_raw_max": 11.213196878655012, "train/extr_return_raw_mean": 2.7451676291088725, "train/extr_return_raw_min": -1.0387253051580385, "train/extr_return_raw_std": 2.720214021483133, "train/extr_reward_mag": 1.016805901638297, "train/extr_reward_max": 1.016805901638297, "train/extr_reward_mean": 0.03408952701923459, "train/extr_reward_min": -0.6994570604590482, "train/extr_reward_std": 0.18106222651725593, "train/image_loss_mean": 1.5822274859561476, "train/image_loss_std": 4.862519810920538, "train/model_loss_mean": 3.517463460079459, "train/model_loss_std": 8.666809505640074, "train/model_opt_grad_norm": 33.08369908443717, "train/model_opt_grad_steps": 122930.4046511628, "train/model_opt_loss": 6764.985733103198, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1918.6046511627908, "train/policy_entropy_mag": 2.6634120098380154, "train/policy_entropy_max": 2.6634120098380154, "train/policy_entropy_mean": 0.5651521015998929, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6911824621433436, "train/policy_logprob_mag": 7.438384076051934, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5646652543267539, "train/policy_logprob_min": -7.438384076051934, "train/policy_logprob_std": 1.1361490756966346, "train/policy_randomness_mag": 0.9400675565697426, "train/policy_randomness_max": 0.9400675565697426, "train/policy_randomness_mean": 0.19947388944930808, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.24395707526872323, "train/post_ent_mag": 46.283778097463205, "train/post_ent_max": 46.283778097463205, "train/post_ent_mean": 26.222646447115167, "train/post_ent_min": 13.280516096603039, "train/post_ent_std": 4.607402468836585, "train/prior_ent_mag": 75.95504817519077, "train/prior_ent_max": 75.95504817519077, "train/prior_ent_mean": 29.255017400342364, "train/prior_ent_min": 14.711411014823026, "train/prior_ent_std": 8.878020033725472, "train/rep_loss_mean": 3.1059123017067134, "train/rep_loss_std": 7.825766281748927, "train/reward_avg": 0.020690582943863646, "train/reward_loss_mean": 0.0716412580810314, "train/reward_loss_std": 0.15610657265019973, "train/reward_max_data": 1.0072965416797373, "train/reward_max_pred": 1.0068493909614031, "train/reward_neg_acc": 0.9991740526154984, "train/reward_neg_loss": 0.05036606604969779, "train/reward_pos_acc": 0.9318000050478203, "train/reward_pos_loss": 0.7181052013885143, "train/reward_pred": 0.02057624670546935, "train/reward_rate": 0.03190406976744186, "train_stats/sum_log_reward": 3.433333243926366, "train_stats/max_log_achievement_collect_drink": 2.3333333333333335, "train_stats/max_log_achievement_collect_sapling": 2.2666666666666666, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 3.4, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.13333333333333333, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.06666666666666667, "train_stats/max_log_achievement_place_plant": 1.4, "train_stats/max_log_achievement_place_table": 1.5333333333333334, "train_stats/max_log_achievement_wake_up": 1.5333333333333334, "train_stats/mean_log_entropy": 0.4963613669077555, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 3.801279433446325e-07, "report/cont_loss_std": 1.2877350172857405e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 1.0581082278804388e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 3.2000446026358986e-07, "report/cont_pred": 0.9941405057907104, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 3.3146700859069824, "report/dyn_loss_std": 7.713230133056641, "report/image_loss_mean": 1.8375298976898193, "report/image_loss_std": 5.005212306976318, "report/model_loss_mean": 3.9069952964782715, "report/model_loss_std": 8.671907424926758, "report/post_ent_mag": 48.2276611328125, "report/post_ent_max": 48.2276611328125, "report/post_ent_mean": 26.814926147460938, "report/post_ent_min": 13.576171875, "report/post_ent_std": 4.67434024810791, "report/prior_ent_mag": 75.74651336669922, "report/prior_ent_max": 75.74651336669922, "report/prior_ent_mean": 30.323843002319336, "report/prior_ent_min": 14.6876220703125, "report/prior_ent_std": 9.116941452026367, "report/rep_loss_mean": 3.3146700859069824, "report/rep_loss_std": 7.713230133056641, "report/reward_avg": 0.025712108239531517, "report/reward_loss_mean": 0.0806628167629242, "report/reward_loss_std": 0.19354991614818573, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0030229091644287, "report/reward_neg_acc": 0.9989848136901855, "report/reward_neg_loss": 0.055462948977947235, "report/reward_pos_acc": 0.8717948794364929, "report/reward_pos_loss": 0.7171208262443542, "report/reward_pred": 0.02638436108827591, "report/reward_rate": 0.0380859375, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.002596733160316944, "eval/cont_loss_std": 0.07927306741476059, "eval/cont_neg_acc": 0.8333333730697632, "eval/cont_neg_loss": 0.443128764629364, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.7797662482953456e-07, "eval/cont_pred": 0.9951540231704712, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 23.121170043945312, "eval/dyn_loss_std": 13.076302528381348, "eval/image_loss_mean": 31.68097496032715, "eval/image_loss_std": 32.16987609863281, "eval/model_loss_mean": 45.73767852783203, "eval/model_loss_std": 37.028587341308594, "eval/post_ent_mag": 46.15859603881836, "eval/post_ent_max": 46.15859603881836, "eval/post_ent_mean": 29.21131706237793, "eval/post_ent_min": 15.004796028137207, "eval/post_ent_std": 3.7848222255706787, "eval/prior_ent_mag": 75.74651336669922, "eval/prior_ent_max": 75.74651336669922, "eval/prior_ent_mean": 39.44886016845703, "eval/prior_ent_min": 16.25193977355957, "eval/prior_ent_std": 8.522976875305176, "eval/rep_loss_mean": 23.121170043945312, "eval/rep_loss_std": 13.076302528381348, "eval/reward_avg": 0.01904296875, "eval/reward_loss_mean": 0.18140482902526855, "eval/reward_loss_std": 1.1152167320251465, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0024218559265137, "eval/reward_neg_acc": 0.9939939975738525, "eval/reward_neg_loss": 0.08727359771728516, "eval/reward_pos_acc": 0.6399999856948853, "eval/reward_pos_loss": 3.9428887367248535, "eval/reward_pred": 0.016117848455905914, "eval/reward_rate": 0.0244140625, "replay/size": 125158.0, "replay/inserts": 2148.0, "replay/samples": 34368.0, "replay/insert_wait_avg": 2.478199076164146e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.696505254429368e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 25608.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 7.599592208862305e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2840874195099, "timer/env.step_count": 268.0, "timer/env.step_total": 29.581440687179565, "timer/env.step_frac": 0.029573039358741077, "timer/env.step_avg": 0.11037851002678942, "timer/env.step_min": 0.023421287536621094, "timer/env.step_max": 1.7154197692871094, "timer/replay._sample_count": 34368.0, "timer/replay._sample_total": 16.46151614189148, "timer/replay._sample_frac": 0.016456840960409752, "timer/replay._sample_avg": 0.00047897800692188897, "timer/replay._sample_min": 0.00036144256591796875, "timer/replay._sample_max": 0.029049158096313477, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 268.0, "timer/agent.policy_total": 4.173973560333252, "timer/agent.policy_frac": 0.004172788123723022, "timer/agent.policy_avg": 0.015574528210198701, "timer/agent.policy_min": 0.014626026153564453, "timer/agent.policy_max": 0.035845041275024414, "timer/dataset_train_count": 2148.0, "timer/dataset_train_total": 0.37966179847717285, "timer/dataset_train_frac": 0.00037955397196871155, "timer/dataset_train_avg": 0.00017675130282922386, "timer/dataset_train_min": 8.96453857421875e-05, "timer/dataset_train_max": 0.0006279945373535156, "timer/agent.train_count": 2148.0, "timer/agent.train_total": 955.9616146087646, "timer/agent.train_frac": 0.9556901150701232, "timer/agent.train_avg": 0.4450473066148811, "timer/agent.train_min": 0.4354126453399658, "timer/agent.train_max": 0.9776015281677246, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4768822193145752, "timer/agent.report_frac": 0.00047674678155164453, "timer/agent.report_avg": 0.2384411096572876, "timer/agent.report_min": 0.23170876502990723, "timer/agent.report_max": 0.24517345428466797, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.075599670410156e-05, "timer/dataset_eval_frac": 3.074726179384155e-08, "timer/dataset_eval_avg": 3.075599670410156e-05, "timer/dataset_eval_min": 3.075599670410156e-05, "timer/dataset_eval_max": 3.075599670410156e-05, "fps": 2.147361202249204}
{"step": 125720, "time": 58361.06704688072, "episode/length": 36.0, "episode/score": 1.1381280693167355, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.038127975625684485}
{"step": 125808, "time": 58402.656058073044, "episode/length": 183.0, "episode/score": 3.2663229146137382, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.16632276015388925}
{"step": 126048, "time": 58514.12227725983, "episode/length": 198.0, "episode/score": 3.2946355451485942, "episode/reward_rate": 0.964824120603015, "episode/intrinsic_return": 0.1946354603051077}
{"step": 126152, "time": 58563.39295721054, "episode/length": 114.0, "episode/score": 3.2089550428800067, "episode/reward_rate": 0.9478260869565217, "episode/intrinsic_return": 0.10895498050467722}
{"step": 126336, "time": 58649.84534430504, "episode/length": 138.0, "episode/score": 5.237921632761754, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.13792157975785813}
{"step": 126552, "time": 58750.81261920929, "episode/length": 351.0, "episode/score": 3.47649395013741, "episode/reward_rate": 0.9971590909090909, "episode/intrinsic_return": 0.3764938172143957}
{"step": 126720, "time": 58829.82108807564, "episode/length": 175.0, "episode/score": 4.27260000813385, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.17259980186918256}
{"step": 127120, "time": 59015.45890045166, "episode/length": 174.0, "episode/score": 5.28650392641066, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.18650370582690812}
{"step": 127224, "time": 59064.80928730965, "episode/length": 146.0, "episode/score": 5.25513407580911, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.1551338880253752}
{"step": 127400, "time": 59147.46463179588, "episode/length": 220.0, "episode/score": 5.344521532277213, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.2445213024966506}
{"step": 127408, "time": 59152.63031220436, "episode/length": 199.0, "episode/score": 5.307113108477097, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.2071131000893729}
{"step": 127488, "time": 59191.05336070061, "episode/length": 166.0, "episode/score": 5.282097673973112, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.182097577575405}
{"step": 127796, "time": 59334.8750474453, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.36800273483348, "train/action_min": 0.0, "train/action_std": 4.264856993312567, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04116595265381213, "train/actor_opt_grad_steps": 125170.0, "train/actor_opt_loss": -11.224795180998148, "train/adv_mag": 0.6470059751065125, "train/adv_max": 0.5790740602732825, "train/adv_mean": 0.002372653484009891, "train/adv_min": -0.5304520585587327, "train/adv_std": 0.04909602514175182, "train/cont_avg": 0.9943882042253521, "train/cont_loss_mean": 7.628838791224275e-06, "train/cont_loss_std": 0.00022152404159598337, "train/cont_neg_acc": 0.9993293095082744, "train/cont_neg_loss": 0.0006666717740320868, "train/cont_pos_acc": 0.9999999818107892, "train/cont_pos_loss": 3.0689719928267776e-06, "train/cont_pred": 0.9943885447833459, "train/cont_rate": 0.9943882042253521, "train/dyn_loss_mean": 3.083268367068868, "train/dyn_loss_std": 7.823145805949896, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0417135064031038, "train/extr_critic_critic_opt_grad_steps": 125170.0, "train/extr_critic_critic_opt_loss": 14963.052986539025, "train/extr_critic_mag": 12.390831472728173, "train/extr_critic_max": 12.390831472728173, "train/extr_critic_mean": 2.7099372377977686, "train/extr_critic_min": -0.6363645545753515, "train/extr_critic_std": 2.795835597974034, "train/extr_return_normed_mag": 1.5493289131513783, "train/extr_return_normed_max": 1.5493289131513783, "train/extr_return_normed_mean": 0.35442847755033646, "train/extr_return_normed_min": -0.09302375105345193, "train/extr_return_normed_std": 0.34178368943118154, "train/extr_return_rate": 0.6921896755415509, "train/extr_return_raw_mag": 12.675002523431196, "train/extr_return_raw_max": 12.675002523431196, "train/extr_return_raw_mean": 2.7295876808569464, "train/extr_return_raw_min": -0.9841635974360184, "train/extr_return_raw_std": 2.8416061748361363, "train/extr_reward_mag": 1.0163700435083236, "train/extr_reward_max": 1.0163700435083236, "train/extr_reward_mean": 0.03272391477940788, "train/extr_reward_min": -0.6814896718996791, "train/extr_reward_std": 0.17824450009305712, "train/image_loss_mean": 1.6182740736455425, "train/image_loss_std": 4.954497438081553, "train/model_loss_mean": 3.53943948790501, "train/model_loss_std": 8.732805822936582, "train/model_opt_grad_norm": 32.84904305364044, "train/model_opt_grad_steps": 125068.5868544601, "train/model_opt_loss": 8294.179762003008, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2329.81220657277, "train/policy_entropy_mag": 2.6568373839060464, "train/policy_entropy_max": 2.6568373839060464, "train/policy_entropy_mean": 0.5866168361034751, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.705393931395571, "train/policy_logprob_mag": 7.438384029227243, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.586527257458145, "train/policy_logprob_min": -7.438384029227243, "train/policy_logprob_std": 1.1498218156362363, "train/policy_randomness_mag": 0.9377470041664553, "train/policy_randomness_max": 0.9377470041664553, "train/policy_randomness_mean": 0.20705000129244136, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.24897310130752867, "train/post_ent_mag": 45.915778827219505, "train/post_ent_max": 45.915778827219505, "train/post_ent_mean": 26.635353885346177, "train/post_ent_min": 13.14554647436724, "train/post_ent_std": 4.6815093906832415, "train/prior_ent_mag": 75.9776513901115, "train/prior_ent_max": 75.9776513901115, "train/prior_ent_mean": 29.627209238043413, "train/prior_ent_min": 14.45891861624561, "train/prior_ent_std": 8.82713340481682, "train/rep_loss_mean": 3.083268367068868, "train/rep_loss_std": 7.823145805949896, "train/reward_avg": 0.019653139095928328, "train/reward_loss_mean": 0.07119676587937024, "train/reward_loss_std": 0.1539161990575947, "train/reward_max_data": 1.0068838327703342, "train/reward_max_pred": 1.0080786702778417, "train/reward_neg_acc": 0.9991953205054914, "train/reward_neg_loss": 0.0507690236322197, "train/reward_pos_acc": 0.919370732396981, "train/reward_pos_loss": 0.7167060999243472, "train/reward_pred": 0.019507105180232878, "train/reward_rate": 0.030699823943661973, "train_stats/sum_log_reward": 4.01666659116745, "train_stats/max_log_achievement_collect_drink": 3.0833333333333335, "train_stats/max_log_achievement_collect_sapling": 1.5833333333333333, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 3.0833333333333335, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.5833333333333333, "train_stats/max_log_achievement_place_table": 1.25, "train_stats/max_log_achievement_wake_up": 2.3333333333333335, "train_stats/mean_log_entropy": 0.54779635121425, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 1.71850160768372e-07, "report/cont_loss_std": 2.7073014052803046e-07, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 1.3647235164171434e-06, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.68345124507141e-07, "report/cont_pred": 0.9970701932907104, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 3.136359214782715, "report/dyn_loss_std": 7.918698787689209, "report/image_loss_mean": 1.1337560415267944, "report/image_loss_std": 4.308098793029785, "report/model_loss_mean": 3.0742788314819336, "report/model_loss_std": 8.38902759552002, "report/post_ent_mag": 44.2637939453125, "report/post_ent_max": 44.2637939453125, "report/post_ent_mean": 27.426586151123047, "report/post_ent_min": 16.751028060913086, "report/post_ent_std": 4.61378812789917, "report/prior_ent_mag": 76.10636138916016, "report/prior_ent_max": 76.10636138916016, "report/prior_ent_mean": 30.649009704589844, "report/prior_ent_min": 19.095813751220703, "report/prior_ent_std": 8.304582595825195, "report/rep_loss_mean": 3.136359214782715, "report/rep_loss_std": 7.918698787689209, "report/reward_avg": 0.013378233648836613, "report/reward_loss_mean": 0.05870721861720085, "report/reward_loss_std": 0.10840372741222382, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0036213397979736, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.04521055892109871, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6734187006950378, "report/reward_pred": 0.013597163371741772, "report/reward_rate": 0.021484375, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.001841330318711698, "eval/cont_loss_std": 0.05888743698596954, "eval/cont_neg_acc": 0.800000011920929, "eval/cont_neg_loss": 0.3770679235458374, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.7938495489033812e-07, "eval/cont_pred": 0.995945394039154, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 23.761493682861328, "eval/dyn_loss_std": 13.730225563049316, "eval/image_loss_mean": 34.58889389038086, "eval/image_loss_std": 44.929893493652344, "eval/model_loss_mean": 48.94676208496094, "eval/model_loss_std": 49.547203063964844, "eval/post_ent_mag": 47.611087799072266, "eval/post_ent_max": 47.611087799072266, "eval/post_ent_mean": 29.51936149597168, "eval/post_ent_min": 16.997419357299805, "eval/post_ent_std": 4.132923126220703, "eval/prior_ent_mag": 76.10636138916016, "eval/prior_ent_max": 76.10636138916016, "eval/prior_ent_mean": 40.622135162353516, "eval/prior_ent_min": 16.25826644897461, "eval/prior_ent_std": 7.828711986541748, "eval/rep_loss_mean": 23.761493682861328, "eval/rep_loss_std": 13.730225563049316, "eval/reward_avg": 0.02226562611758709, "eval/reward_loss_mean": 0.0991322249174118, "eval/reward_loss_std": 0.8560635447502136, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0053980350494385, "eval/reward_neg_acc": 0.9949899911880493, "eval/reward_neg_loss": 0.02175566926598549, "eval/reward_pos_acc": 0.7307692766189575, "eval/reward_pos_loss": 3.069201707839966, "eval/reward_pred": 0.017388351261615753, "eval/reward_rate": 0.025390625, "replay/size": 127292.0, "replay/inserts": 2134.0, "replay/samples": 34144.0, "replay/insert_wait_avg": 2.608415448118172e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.944818736239919e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 25608.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 9.5367431640625e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3750908374786, "timer/env.step_count": 267.0, "timer/env.step_total": 25.202393054962158, "timer/env.step_frac": 0.02519294341271893, "timer/env.step_avg": 0.09439098522457737, "timer/env.step_min": 0.023720264434814453, "timer/env.step_max": 1.5969033241271973, "timer/replay._sample_count": 34144.0, "timer/replay._sample_total": 16.74041724205017, "timer/replay._sample_frac": 0.016734140419305807, "timer/replay._sample_avg": 0.0004902886961706353, "timer/replay._sample_min": 0.0003521442413330078, "timer/replay._sample_max": 0.033220529556274414, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 267.0, "timer/agent.policy_total": 4.236071348190308, "timer/agent.policy_frac": 0.004234483032403394, "timer/agent.policy_avg": 0.01586543576101239, "timer/agent.policy_min": 0.014634132385253906, "timer/agent.policy_max": 0.019087553024291992, "timer/dataset_train_count": 2134.0, "timer/dataset_train_total": 0.444169282913208, "timer/dataset_train_frac": 0.0004440027415530361, "timer/dataset_train_avg": 0.0002081393078318688, "timer/dataset_train_min": 9.5367431640625e-05, "timer/dataset_train_max": 0.025186538696289062, "timer/agent.train_count": 2134.0, "timer/agent.train_total": 959.0352818965912, "timer/agent.train_frac": 0.9586756914286229, "timer/agent.train_avg": 0.44940734859259196, "timer/agent.train_min": 0.4283761978149414, "timer/agent.train_max": 0.5729289054870605, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48129749298095703, "timer/agent.report_frac": 0.0004811170303911024, "timer/agent.report_avg": 0.24064874649047852, "timer/agent.report_min": 0.23462939262390137, "timer/agent.report_max": 0.24666810035705566, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9802322387695312e-05, "timer/dataset_eval_frac": 2.979114800104215e-08, "timer/dataset_eval_avg": 2.9802322387695312e-05, "timer/dataset_eval_min": 2.9802322387695312e-05, "timer/dataset_eval_max": 2.9802322387695312e-05, "fps": 2.133168895446901}
{"step": 127816, "time": 59344.24036669731, "episode/length": 157.0, "episode/score": 3.2635761485171315, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.163576053196266}
{"step": 127928, "time": 59397.31936240196, "episode/length": 198.0, "episode/score": 4.301818735615598, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.20181852585847082}
{"step": 128120, "time": 59486.930352926254, "episode/length": 174.0, "episode/score": 3.3033115472644567, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.20331150421407074}
{"step": 128376, "time": 59605.89545416832, "episode/length": 31.0, "episode/score": 1.1400000359863043, "episode/reward_rate": 0.84375, "episode/intrinsic_return": 0.03999999910593033}
{"step": 128584, "time": 59702.9343149662, "episode/length": 169.0, "episode/score": 6.284992931745364, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.1849927563307574}
{"step": 128632, "time": 59726.64950585365, "episode/length": 87.0, "episode/score": 2.1812065871267805, "episode/reward_rate": 0.9545454545454546, "episode/intrinsic_return": 0.0812065200948382}
{"step": 128800, "time": 59805.63914036751, "episode/length": 209.0, "episode/score": 5.295801554045283, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.19580156108258961}
{"step": 128816, "time": 59814.579496860504, "episode/length": 176.0, "episode/score": 1.298008301378104, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.1980082633335769}
{"step": 128896, "time": 59852.93404507637, "episode/length": 185.0, "episode/score": 5.2772221067762075, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.17722193124518526}
{"step": 129000, "time": 59902.29587674141, "episode/length": 188.0, "episode/score": 4.320278779669934, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.2202786545467461}
{"step": 129256, "time": 60021.961683273315, "episode/length": 179.0, "episode/score": 3.2778300193235737, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.17782990258228892}
{"step": 129872, "time": 60306.15246582031, "episode/length": 186.0, "episode/score": 5.285010956974929, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.18501077479368178}
{"step": 129920, "time": 60329.696915864944, "episode/length": 166.0, "episode/score": 5.283450054610967, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.18344993792788955}
{"step": 129927, "time": 60334.976204156876, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.369883649226086, "train/action_min": 0.0, "train/action_std": 4.262081736130334, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.039388176193679444, "train/actor_opt_grad_steps": 127300.0, "train/actor_opt_loss": -11.36268399759445, "train/adv_mag": 0.5819587990151884, "train/adv_max": 0.5279735361046635, "train/adv_mean": 0.001929401578667572, "train/adv_min": -0.4761445719591329, "train/adv_std": 0.0471297004413157, "train/cont_avg": 0.9943515258215962, "train/cont_loss_mean": 6.0914545001987535e-06, "train/cont_loss_std": 0.00016261086479355905, "train/cont_neg_acc": 1.0, "train/cont_neg_loss": 0.00038028882412289477, "train/cont_pos_acc": 0.9999999840494612, "train/cont_pos_loss": 3.773926170997306e-06, "train/cont_pred": 0.9943503219756722, "train/cont_rate": 0.9943515258215962, "train/dyn_loss_mean": 3.1007537203775324, "train/dyn_loss_std": 7.834928145431017, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0556427469835594, "train/extr_critic_critic_opt_grad_steps": 127300.0, "train/extr_critic_critic_opt_loss": 15137.667551533157, "train/extr_critic_mag": 12.512038562219468, "train/extr_critic_max": 12.512038562219468, "train/extr_critic_mean": 2.854481233117726, "train/extr_critic_min": -0.6678821676773644, "train/extr_critic_std": 2.887104266126391, "train/extr_return_normed_mag": 1.4958443003641049, "train/extr_return_normed_max": 1.4958443003641049, "train/extr_return_normed_mean": 0.35513011299668346, "train/extr_return_normed_min": -0.09443122162505495, "train/extr_return_normed_std": 0.3346047532250624, "train/extr_return_rate": 0.7247741625342571, "train/extr_return_raw_mag": 12.839205952317503, "train/extr_return_raw_max": 12.839205952317503, "train/extr_return_raw_mean": 2.8714148511349316, "train/extr_return_raw_min": -1.058039407215208, "train/extr_return_raw_std": 2.924409672687871, "train/extr_reward_mag": 1.0193765913376787, "train/extr_reward_max": 1.0193765913376787, "train/extr_reward_mean": 0.03371104034004917, "train/extr_reward_min": -0.6958970844465802, "train/extr_reward_std": 0.18101902061225103, "train/image_loss_mean": 1.568014682738434, "train/image_loss_std": 4.927870572452814, "train/model_loss_mean": 3.500138626412047, "train/model_loss_std": 8.735726208753988, "train/model_opt_grad_norm": 30.769349362368875, "train/model_opt_grad_steps": 127196.77464788733, "train/model_opt_loss": 7735.499326034331, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2224.1784037558687, "train/policy_entropy_mag": 2.6848017117227188, "train/policy_entropy_max": 2.6848017117227188, "train/policy_entropy_mean": 0.6033434015764317, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.7161251305134644, "train/policy_logprob_mag": 7.438384033704588, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.6039769477407697, "train/policy_logprob_min": -7.438384033704588, "train/policy_logprob_std": 1.1608122033132633, "train/policy_randomness_mag": 0.9476171838285777, "train/policy_randomness_max": 0.9476171838285777, "train/policy_randomness_mean": 0.21295374401018652, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.25276074485040045, "train/post_ent_mag": 46.18038705816851, "train/post_ent_max": 46.18038705816851, "train/post_ent_mean": 26.789603712413232, "train/post_ent_min": 13.393022770053344, "train/post_ent_std": 4.698128165213714, "train/prior_ent_mag": 76.04549493923993, "train/prior_ent_max": 76.04549493923993, "train/prior_ent_mean": 29.796565490149558, "train/prior_ent_min": 14.797455921979017, "train/prior_ent_std": 8.834310473410737, "train/rep_loss_mean": 3.1007537203775324, "train/rep_loss_std": 7.834928145431017, "train/reward_avg": 0.019772619369741475, "train/reward_loss_mean": 0.07166561599768384, "train/reward_loss_std": 0.15836808060956115, "train/reward_max_data": 1.0097007348503866, "train/reward_max_pred": 1.0098035671341588, "train/reward_neg_acc": 0.9993609911958936, "train/reward_neg_loss": 0.05068804981283179, "train/reward_pos_acc": 0.9299214154901639, "train/reward_pos_loss": 0.7232273761095576, "train/reward_pred": 0.01958264131973467, "train/reward_rate": 0.03120873679577465, "train_stats/sum_log_reward": 3.715384556696965, "train_stats/max_log_achievement_collect_drink": 3.769230769230769, "train_stats/max_log_achievement_collect_sapling": 2.4615384615384617, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 2.076923076923077, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.07692307692307693, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 2.230769230769231, "train_stats/max_log_achievement_place_table": 0.6923076923076923, "train_stats/max_log_achievement_wake_up": 2.3846153846153846, "train_stats/mean_log_entropy": 0.5078368083788798, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 3.737138740689261e-07, "report/cont_loss_std": 2.714702759476495e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 2.6513491320656613e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.196484274463728e-07, "report/cont_pred": 0.994140625, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 2.7701520919799805, "report/dyn_loss_std": 7.632270336151123, "report/image_loss_mean": 0.8411585092544556, "report/image_loss_std": 4.293678283691406, "report/model_loss_mean": 2.572950839996338, "report/model_loss_std": 8.083805084228516, "report/post_ent_mag": 48.926448822021484, "report/post_ent_max": 48.926448822021484, "report/post_ent_mean": 27.064971923828125, "report/post_ent_min": 16.436748504638672, "report/post_ent_std": 4.100563049316406, "report/prior_ent_mag": 75.80842590332031, "report/prior_ent_max": 75.80842590332031, "report/prior_ent_mean": 29.855836868286133, "report/prior_ent_min": 18.93395233154297, "report/prior_ent_std": 8.266218185424805, "report/rep_loss_mean": 2.7701520919799805, "report/rep_loss_std": 7.632270336151123, "report/reward_avg": 0.02326325513422489, "report/reward_loss_mean": 0.06970047950744629, "report/reward_loss_std": 0.14251329004764557, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0026426315307617, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.050428979098796844, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6870102286338806, "report/reward_pred": 0.023104093968868256, "report/reward_rate": 0.0302734375, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 6.035950718796812e-06, "eval/cont_loss_std": 0.00013607127766590565, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0003978067252319306, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 4.113621344004059e-06, "eval/cont_pred": 0.9951151013374329, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 26.196346282958984, "eval/dyn_loss_std": 14.417895317077637, "eval/image_loss_mean": 35.31406021118164, "eval/image_loss_std": 40.30128860473633, "eval/model_loss_mean": 51.179595947265625, "eval/model_loss_std": 46.64276123046875, "eval/post_ent_mag": 48.926448822021484, "eval/post_ent_max": 48.926448822021484, "eval/post_ent_mean": 29.90517807006836, "eval/post_ent_min": 15.910497665405273, "eval/post_ent_std": 3.753584146499634, "eval/prior_ent_mag": 75.80842590332031, "eval/prior_ent_max": 75.80842590332031, "eval/prior_ent_mean": 42.193939208984375, "eval/prior_ent_min": 19.28848648071289, "eval/prior_ent_std": 7.9633870124816895, "eval/rep_loss_mean": 26.196346282958984, "eval/rep_loss_std": 14.417895317077637, "eval/reward_avg": 0.0244140625, "eval/reward_loss_mean": 0.1477208286523819, "eval/reward_loss_std": 0.9123284816741943, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0048203468322754, "eval/reward_neg_acc": 0.9989949464797974, "eval/reward_neg_loss": 0.0824754610657692, "eval/reward_pos_acc": 0.7586206793785095, "eval/reward_pos_loss": 2.3863120079040527, "eval/reward_pred": 0.020048445090651512, "eval/reward_rate": 0.0283203125, "replay/size": 129423.0, "replay/inserts": 2131.0, "replay/samples": 34096.0, "replay/insert_wait_avg": 2.6706013529583747e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.94950028307166e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 25608.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 7.301568984985352e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.088721036911, "timer/env.step_count": 266.0, "timer/env.step_total": 26.955858945846558, "timer/env.step_frac": 0.026953467606252182, "timer/env.step_avg": 0.10133781558588932, "timer/env.step_min": 0.02406597137451172, "timer/env.step_max": 1.6178271770477295, "timer/replay._sample_count": 34096.0, "timer/replay._sample_total": 16.786696195602417, "timer/replay._sample_frac": 0.016785206994633088, "timer/replay._sample_avg": 0.0004923362328602305, "timer/replay._sample_min": 0.0003707408905029297, "timer/replay._sample_max": 0.03421926498413086, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 266.0, "timer/agent.policy_total": 4.256119728088379, "timer/agent.policy_frac": 0.00425574215423163, "timer/agent.policy_avg": 0.01600045010559541, "timer/agent.policy_min": 0.014739990234375, "timer/agent.policy_max": 0.023768186569213867, "timer/dataset_train_count": 2131.0, "timer/dataset_train_total": 0.4265260696411133, "timer/dataset_train_frac": 0.00042648823116301417, "timer/dataset_train_avg": 0.00020015301250169557, "timer/dataset_train_min": 9.942054748535156e-05, "timer/dataset_train_max": 0.0010285377502441406, "timer/agent.train_count": 2131.0, "timer/agent.train_total": 956.6832804679871, "timer/agent.train_frac": 0.9565984100651387, "timer/agent.train_avg": 0.44893631181041155, "timer/agent.train_min": 0.4373323917388916, "timer/agent.train_max": 0.5805630683898926, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4776589870452881, "timer/agent.report_frac": 0.0004776166124041897, "timer/agent.report_avg": 0.23882949352264404, "timer/agent.report_min": 0.23067092895507812, "timer/agent.report_max": 0.24698805809020996, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.2901763916015625e-05, "timer/dataset_eval_frac": 3.28988450963655e-08, "timer/dataset_eval_avg": 3.2901763916015625e-05, "timer/dataset_eval_min": 3.2901763916015625e-05, "timer/dataset_eval_max": 3.2901763916015625e-05, "fps": 2.130779894807443}
{"step": 130000, "time": 60384.55640244484, "eval_episode/length": 75.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.9605263157894737}
{"step": 130000, "time": 60389.89581871033, "eval_episode/length": 163.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9939024390243902}
{"step": 130000, "time": 60391.98425936699, "eval_episode/length": 174.0, "eval_episode/score": 5.099999979138374, "eval_episode/reward_rate": 0.9942857142857143}
{"step": 130000, "time": 60393.721665382385, "eval_episode/length": 177.0, "eval_episode/score": 3.0999999716877937, "eval_episode/reward_rate": 0.9943820224719101}
{"step": 130000, "time": 60395.23303747177, "eval_episode/length": 178.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.994413407821229}
{"step": 130000, "time": 60397.11767530441, "eval_episode/length": 186.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9732620320855615}
{"step": 130000, "time": 60398.832362651825, "eval_episode/length": 190.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9738219895287958}
{"step": 130000, "time": 60400.66824102402, "eval_episode/length": 198.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9748743718592965}
{"step": 130008, "time": 60404.36922740936, "episode/length": 171.0, "episode/score": 4.2952205917686115, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.19522038201148462}
{"step": 130112, "time": 60453.186725854874, "episode/length": 163.0, "episode/score": 3.2657637867896483, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.1657636393147186}
{"step": 130272, "time": 60527.907051324844, "episode/length": 158.0, "episode/score": 3.2667483804398216, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.1667482678894885}
{"step": 130368, "time": 60573.42321443558, "episode/length": 193.0, "episode/score": 7.289569863313318, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.18956962328820737}
{"step": 130392, "time": 60586.051070690155, "episode/length": 34.0, "episode/score": 0.13931548487744294, "episode/reward_rate": 0.8857142857142857, "episode/intrinsic_return": 0.03931547547108494}
{"step": 130512, "time": 60642.47394490242, "episode/length": 201.0, "episode/score": 4.316351822315482, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.21635171998059377}
{"step": 131128, "time": 60927.17573070526, "episode/length": 233.0, "episode/score": 5.367924273676181, "episode/reward_rate": 0.9786324786324786, "episode/intrinsic_return": 0.2679241222431301}
{"step": 131464, "time": 61082.126388311386, "episode/length": 192.0, "episode/score": 4.287070385711559, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.18707022920716554}
{"step": 131536, "time": 61116.4949991703, "episode/length": 190.0, "episode/score": 6.309365752436861, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.20936559314577607}
{"step": 131744, "time": 61212.9941675663, "episode/length": 153.0, "episode/score": 4.261136690991407, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.16113653533830075}
{"step": 131784, "time": 61232.68345808983, "episode/length": 188.0, "episode/score": 6.296241965315858, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.19624179839956923}
{"step": 131880, "time": 61278.05529499054, "episode/length": 188.0, "episode/score": 5.278937038894583, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.17893696406281379}
{"step": 132000, "time": 61335.17222046852, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.277761606069712, "train/action_min": 0.0, "train/action_std": 4.1930808413487215, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03981103613757743, "train/actor_opt_grad_steps": 129405.0, "train/actor_opt_loss": -16.638089376313683, "train/adv_mag": 0.6152451718942478, "train/adv_max": 0.5455124209133478, "train/adv_mean": 0.0004627255335050834, "train/adv_min": -0.49571594746353537, "train/adv_std": 0.04832414279763515, "train/cont_avg": 0.9939669095552884, "train/cont_loss_mean": 2.151412893873601e-05, "train/cont_loss_std": 0.0006543450867421568, "train/cont_neg_acc": 0.9993990384615384, "train/cont_neg_loss": 0.0008640406881721236, "train/cont_pos_acc": 0.9999952516876734, "train/cont_pos_loss": 1.4979970007578968e-05, "train/cont_pred": 0.9939642479786506, "train/cont_rate": 0.9939669095552884, "train/dyn_loss_mean": 3.122147003045449, "train/dyn_loss_std": 7.893685157482441, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0271564300816793, "train/extr_critic_critic_opt_grad_steps": 129405.0, "train/extr_critic_critic_opt_loss": 14936.858576847957, "train/extr_critic_mag": 11.616530588039986, "train/extr_critic_max": 11.616530588039986, "train/extr_critic_mean": 2.4938903170136304, "train/extr_critic_min": -0.6616110142606956, "train/extr_critic_std": 2.6060975113740334, "train/extr_return_normed_mag": 1.5447245240211487, "train/extr_return_normed_max": 1.5447245240211487, "train/extr_return_normed_mean": 0.35328105457413655, "train/extr_return_normed_min": -0.11197973100038675, "train/extr_return_normed_std": 0.3389380866518387, "train/extr_return_rate": 0.6891232594274558, "train/extr_return_raw_mag": 11.753217046077435, "train/extr_return_raw_max": 11.753217046077435, "train/extr_return_raw_mean": 2.497045643054522, "train/extr_return_raw_min": -1.1014460454193444, "train/extr_return_raw_std": 2.6266337145979586, "train/extr_reward_mag": 1.0182132457311337, "train/extr_reward_max": 1.0182132457311337, "train/extr_reward_mean": 0.032618987624748394, "train/extr_reward_min": -0.6933072352638612, "train/extr_reward_std": 0.17834393923672345, "train/image_loss_mean": 1.6067395771925266, "train/image_loss_std": 5.0598288373305245, "train/model_loss_mean": 3.5520854271375217, "train/model_loss_std": 8.895268777242073, "train/model_opt_grad_norm": 30.813784428840673, "train/model_opt_grad_steps": 129300.01442307692, "train/model_opt_loss": 9182.520460862379, "train/model_opt_model_opt_grad_overflow": 0.004807692307692308, "train/model_opt_model_opt_grad_scale": 2572.1153846153848, "train/policy_entropy_mag": 2.700176564546732, "train/policy_entropy_max": 2.700176564546732, "train/policy_entropy_mean": 0.6064250585264884, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.7326533035016977, "train/policy_logprob_mag": 7.438384062968767, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.6062108188007886, "train/policy_logprob_min": -7.438384062968767, "train/policy_logprob_std": 1.1646431727478137, "train/policy_randomness_mag": 0.9530438333749771, "train/policy_randomness_max": 0.9530438333749771, "train/policy_randomness_mean": 0.21404143444334084, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.25859446365099686, "train/post_ent_mag": 46.211517352324265, "train/post_ent_max": 46.211517352324265, "train/post_ent_mean": 27.044422323887165, "train/post_ent_min": 13.344399993236248, "train/post_ent_std": 4.7308536389699345, "train/prior_ent_mag": 75.98252072701088, "train/prior_ent_max": 75.98252072701088, "train/prior_ent_mean": 30.066234515263485, "train/prior_ent_min": 14.813071860716892, "train/prior_ent_std": 8.854879069786806, "train/rep_loss_mean": 3.122147003045449, "train/rep_loss_std": 7.893685157482441, "train/reward_avg": 0.01987904648726376, "train/reward_loss_mean": 0.0720361486936991, "train/reward_loss_std": 0.15767590676505977, "train/reward_max_data": 1.0075000301003456, "train/reward_max_pred": 1.0083613292529032, "train/reward_neg_acc": 0.9992879789609176, "train/reward_neg_loss": 0.051405075418118104, "train/reward_pos_acc": 0.9293502514752058, "train/reward_pos_loss": 0.7154421376494261, "train/reward_pred": 0.019767727667035963, "train/reward_rate": 0.0311279296875, "eval_stats/sum_log_reward": 4.224999964237213, "eval_stats/max_log_achievement_collect_drink": 4.25, "eval_stats/max_log_achievement_collect_sapling": 1.125, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 1.875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.125, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 1.125, "eval_stats/max_log_achievement_place_table": 0.75, "eval_stats/max_log_achievement_wake_up": 2.625, "eval_stats/mean_log_entropy": 0.0, "train_stats/sum_log_reward": 4.349999935676654, "train_stats/max_log_achievement_collect_drink": 2.75, "train_stats/max_log_achievement_collect_sapling": 1.25, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 4.083333333333333, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.08333333333333333, "train_stats/max_log_achievement_make_wood_sword": 0.25, "train_stats/max_log_achievement_place_plant": 1.1666666666666667, "train_stats/max_log_achievement_place_table": 1.6666666666666667, "train_stats/max_log_achievement_wake_up": 2.3333333333333335, "train_stats/mean_log_entropy": 0.49226926639676094, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 8.954051509135752e-07, "report/cont_loss_std": 1.4007990102982149e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 8.682032785145566e-06, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 8.340931003658625e-07, "report/cont_pred": 0.9921869039535522, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 3.2819104194641113, "report/dyn_loss_std": 7.26511287689209, "report/image_loss_mean": 1.6467173099517822, "report/image_loss_std": 4.237452507019043, "report/model_loss_mean": 3.6949727535247803, "report/model_loss_std": 7.603957176208496, "report/post_ent_mag": 45.923301696777344, "report/post_ent_max": 45.923301696777344, "report/post_ent_mean": 27.6865234375, "report/post_ent_min": 13.999374389648438, "report/post_ent_std": 4.804516792297363, "report/prior_ent_mag": 75.75115966796875, "report/prior_ent_max": 75.75115966796875, "report/prior_ent_mean": 31.094528198242188, "report/prior_ent_min": 14.533849716186523, "report/prior_ent_std": 9.146181106567383, "report/rep_loss_mean": 3.2819104194641113, "report/rep_loss_std": 7.26511287689209, "report/reward_avg": 0.02267853356897831, "report/reward_loss_mean": 0.07910817861557007, "report/reward_loss_std": 0.1739022582769394, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0045537948608398, "report/reward_neg_acc": 0.9999998807907104, "report/reward_neg_loss": 0.053893350064754486, "report/reward_pos_acc": 0.9428571462631226, "report/reward_pos_loss": 0.7916072607040405, "report/reward_pred": 0.021049583330750465, "report/reward_rate": 0.0341796875, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.0024010452907532454, "eval/cont_loss_std": 0.07673726975917816, "eval/cont_neg_acc": 0.800000011920929, "eval/cont_neg_loss": 0.4915972352027893, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 6.719437806168571e-07, "eval/cont_pred": 0.9960107207298279, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 21.170684814453125, "eval/dyn_loss_std": 14.292146682739258, "eval/image_loss_mean": 27.331029891967773, "eval/image_loss_std": 33.885677337646484, "eval/model_loss_mean": 40.209720611572266, "eval/model_loss_std": 40.387001037597656, "eval/post_ent_mag": 42.668373107910156, "eval/post_ent_max": 42.668373107910156, "eval/post_ent_mean": 29.992366790771484, "eval/post_ent_min": 17.222753524780273, "eval/post_ent_std": 4.147733688354492, "eval/prior_ent_mag": 75.75115966796875, "eval/prior_ent_max": 75.75115966796875, "eval/prior_ent_mean": 39.144287109375, "eval/prior_ent_min": 18.105911254882812, "eval/prior_ent_std": 8.501523971557617, "eval/rep_loss_mean": 21.170684814453125, "eval/rep_loss_std": 14.292146682739258, "eval/reward_avg": 0.02958984300494194, "eval/reward_loss_mean": 0.17388099431991577, "eval/reward_loss_std": 0.9625176787376404, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 1.0047831535339355, "eval/reward_neg_acc": 0.9979776740074158, "eval/reward_neg_loss": 0.1016608476638794, "eval/reward_pos_acc": 0.7428571581840515, "eval/reward_pos_loss": 2.214616298675537, "eval/reward_pred": 0.023302918300032616, "eval/reward_rate": 0.0341796875, "replay/size": 131496.0, "replay/inserts": 2073.0, "replay/samples": 33168.0, "replay/insert_wait_avg": 2.5885610032990193e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.832849652538309e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 27200.0, "eval_replay/inserts": 1592.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1943393017179404e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.450580596923828e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1788623332977, "timer/env.step_count": 259.0, "timer/env.step_total": 25.248805046081543, "timer/env.step_frac": 0.02524428979350663, "timer/env.step_avg": 0.0974857337686546, "timer/env.step_min": 0.023868799209594727, "timer/env.step_max": 1.788597822189331, "timer/replay._sample_count": 33168.0, "timer/replay._sample_total": 16.212709426879883, "timer/replay._sample_frac": 0.016209810102422652, "timer/replay._sample_avg": 0.000488805759372886, "timer/replay._sample_min": 0.0003504753112792969, "timer/replay._sample_max": 0.028886795043945312, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 458.0, "timer/agent.policy_total": 7.45122766494751, "timer/agent.policy_frac": 0.007449895159316491, "timer/agent.policy_avg": 0.016269056037003297, "timer/agent.policy_min": 0.010095596313476562, "timer/agent.policy_max": 0.031978607177734375, "timer/dataset_train_count": 2073.0, "timer/dataset_train_total": 0.39708518981933594, "timer/dataset_train_frac": 0.000397014178936939, "timer/dataset_train_avg": 0.00019155098399389095, "timer/dataset_train_min": 9.5367431640625e-05, "timer/dataset_train_max": 0.0012350082397460938, "timer/agent.train_count": 2073.0, "timer/agent.train_total": 927.3396701812744, "timer/agent.train_frac": 0.9271738337060051, "timer/agent.train_avg": 0.44734185729921583, "timer/agent.train_min": 0.43474745750427246, "timer/agent.train_max": 0.5753636360168457, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47452330589294434, "timer/agent.report_frac": 0.0004744384467253569, "timer/agent.report_avg": 0.23726165294647217, "timer/agent.report_min": 0.23076295852661133, "timer/agent.report_max": 0.243760347366333, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0517578125e-05, "timer/dataset_eval_frac": 3.051212065590562e-08, "timer/dataset_eval_avg": 3.0517578125e-05, "timer/dataset_eval_min": 3.0517578125e-05, "timer/dataset_eval_max": 3.0517578125e-05, "fps": 2.0725996451688964}
{"step": 132024, "time": 61346.56623506546, "episode/length": 34.0, "episode/score": 2.136208455252927, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.03620833292370662}
{"step": 132056, "time": 61362.92594599724, "episode/length": 272.0, "episode/score": 5.392364284609357, "episode/reward_rate": 0.9963369963369964, "episode/intrinsic_return": 0.29236412104728515}
{"step": 132152, "time": 61408.67620110512, "episode/length": 219.0, "episode/score": 1.3381620275740715, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.23816196054212924}
{"step": 132280, "time": 61468.8711335659, "episode/length": 143.0, "episode/score": 4.218703518028633, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.11870345137504046}
{"step": 132968, "time": 61788.2459936142, "episode/length": 178.0, "episode/score": 5.30339198958427, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.2033917778480827}
{"step": 133136, "time": 61867.15615415573, "episode/length": 208.0, "episode/score": 5.308100716338231, "episode/reward_rate": 0.9712918660287081, "episode/intrinsic_return": 0.2081005827167246}
{"step": 133264, "time": 61927.584171295166, "episode/length": 138.0, "episode/score": 4.232004243031042, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.13200407285512483}
{"step": 133320, "time": 61954.942464351654, "episode/length": 161.0, "episode/score": 3.259525016376756, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.15952489448409324}
{"step": 133336, "time": 61963.90010070801, "episode/length": 193.0, "episode/score": 5.298715611643274, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.19871547336515505}
{"step": 133440, "time": 62013.166412353516, "episode/length": 172.0, "episode/score": 5.295564657597424, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.19556446367278113}
{"step": 133496, "time": 62040.45050048828, "episode/length": 201.0, "episode/score": 3.311485894706493, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.21148577039821248}
{"step": 133576, "time": 62078.875238657, "episode/length": 161.0, "episode/score": 4.2721546354468956, "episode/reward_rate": 0.9567901234567902, "episode/intrinsic_return": 0.17215453360677202}
{"step": 134132, "time": 62335.28521347046, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.939868049442488, "train/action_min": 0.0, "train/action_std": 4.011155038932119, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.040763465635163684, "train/actor_opt_grad_steps": 131510.0, "train/actor_opt_loss": -15.420750832683604, "train/adv_mag": 0.6671259604709249, "train/adv_max": 0.6046171883742014, "train/adv_mean": 0.0018259405840521388, "train/adv_min": -0.4908206476152223, "train/adv_std": 0.05110578898322974, "train/cont_avg": 0.9945715962441315, "train/cont_loss_mean": 0.00011596988202932836, "train/cont_loss_std": 0.0036588529130825087, "train/cont_neg_acc": 0.998390342428091, "train/cont_neg_loss": 0.020397099298183726, "train/cont_pos_acc": 0.9999999846091293, "train/cont_pos_loss": 2.920708403785967e-06, "train/cont_pred": 0.9945787946942827, "train/cont_rate": 0.9945715962441315, "train/dyn_loss_mean": 3.047380635436152, "train/dyn_loss_std": 7.74415343468178, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0408929222626306, "train/extr_critic_critic_opt_grad_steps": 131510.0, "train/extr_critic_critic_opt_loss": 15238.51592301203, "train/extr_critic_mag": 10.223691313479428, "train/extr_critic_max": 10.223691313479428, "train/extr_critic_mean": 2.200316889185301, "train/extr_critic_min": -0.6619731607571454, "train/extr_critic_std": 2.277578501074527, "train/extr_return_normed_mag": 1.6130803375736649, "train/extr_return_normed_max": 1.6130803375736649, "train/extr_return_normed_mean": 0.36273978398719303, "train/extr_return_normed_min": -0.11694270671463348, "train/extr_return_normed_std": 0.34162972559671445, "train/extr_return_rate": 0.6921346570964151, "train/extr_return_raw_mag": 10.682043471806486, "train/extr_return_raw_max": 10.682043471806486, "train/extr_return_raw_mean": 2.212724039812043, "train/extr_return_raw_min": -1.0370109223983657, "train/extr_return_raw_std": 2.314904054005941, "train/extr_reward_mag": 1.0218917405661283, "train/extr_reward_max": 1.0218917405661283, "train/extr_reward_mean": 0.03365319288672416, "train/extr_reward_min": -0.6953008712177545, "train/extr_reward_std": 0.18036529491764838, "train/image_loss_mean": 1.5123449636736945, "train/image_loss_std": 4.658982894790005, "train/model_loss_mean": 3.412090754844773, "train/model_loss_std": 8.444198722570714, "train/model_opt_grad_norm": 31.058329978079165, "train/model_opt_grad_steps": 131402.91549295775, "train/model_opt_loss": 7451.251835066388, "train/model_opt_model_opt_grad_overflow": 0.004694835680751174, "train/model_opt_model_opt_grad_scale": 2153.755868544601, "train/policy_entropy_mag": 2.656738624886168, "train/policy_entropy_max": 2.656738624886168, "train/policy_entropy_mean": 0.5573849412197238, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.690606865104935, "train/policy_logprob_mag": 7.4383840672846695, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5567723358740829, "train/policy_logprob_min": -7.4383840672846695, "train/policy_logprob_std": 1.1342188707539733, "train/policy_randomness_mag": 0.9377121466426223, "train/policy_randomness_max": 0.9377121466426223, "train/policy_randomness_mean": 0.19673242619339848, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.24375391706054758, "train/post_ent_mag": 46.348653838108405, "train/post_ent_max": 46.348653838108405, "train/post_ent_mean": 27.278827649326953, "train/post_ent_min": 13.48758912870022, "train/post_ent_std": 4.7759958388100205, "train/prior_ent_mag": 75.98822608911935, "train/prior_ent_max": 75.98822608911935, "train/prior_ent_mean": 30.238063382430816, "train/prior_ent_min": 14.828337794738196, "train/prior_ent_std": 8.760962114647521, "train/rep_loss_mean": 3.047380635436152, "train/rep_loss_std": 7.74415343468178, "train/reward_avg": 0.02011970750235476, "train/reward_loss_mean": 0.07120144183576947, "train/reward_loss_std": 0.15599154719444508, "train/reward_max_data": 1.0111091858904127, "train/reward_max_pred": 1.0114653703752259, "train/reward_neg_acc": 0.9991434264071111, "train/reward_neg_loss": 0.050452199777666955, "train/reward_pos_acc": 0.9400481998640606, "train/reward_pos_loss": 0.7170484379423616, "train/reward_pred": 0.020034060181673842, "train/reward_rate": 0.031034514377934273, "train_stats/sum_log_reward": 3.9333332677682242, "train_stats/max_log_achievement_collect_drink": 4.25, "train_stats/max_log_achievement_collect_sapling": 1.5, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 3.1666666666666665, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.4166666666666667, "train_stats/max_log_achievement_place_table": 1.0833333333333333, "train_stats/max_log_achievement_wake_up": 2.25, "train_stats/mean_log_entropy": 0.5349189154803753, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 1.0633691090333741e-05, "report/cont_loss_std": 0.0002976822142954916, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 1.2430809874786064e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.0619539352774154e-05, "report/cont_pred": 0.9921770095825195, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 2.695565938949585, "report/dyn_loss_std": 7.690438270568848, "report/image_loss_mean": 1.7683106660842896, "report/image_loss_std": 3.6433651447296143, "report/model_loss_mean": 3.4546432495117188, "report/model_loss_std": 7.005651473999023, "report/post_ent_mag": 48.05699920654297, "report/post_ent_max": 48.05699920654297, "report/post_ent_mean": 27.092994689941406, "report/post_ent_min": 11.887811660766602, "report/post_ent_std": 5.66802978515625, "report/prior_ent_mag": 76.00588989257812, "report/prior_ent_max": 76.00588989257812, "report/prior_ent_mean": 29.80815887451172, "report/prior_ent_min": 12.560354232788086, "report/prior_ent_std": 9.367063522338867, "report/rep_loss_mean": 2.695565938949585, "report/rep_loss_std": 7.690438270568848, "report/reward_avg": 0.017962880432605743, "report/reward_loss_mean": 0.06898217648267746, "report/reward_loss_std": 0.1320066601037979, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0012238025665283, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.052491020411252975, "report/reward_pos_acc": 0.9259259104728699, "report/reward_pos_loss": 0.677933394908905, "report/reward_pred": 0.01778089813888073, "report/reward_rate": 0.0263671875, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 5.445614533527987e-06, "eval/cont_loss_std": 7.656746311113238e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0009232472511939704, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.7488420073495945e-06, "eval/cont_pred": 0.9970702528953552, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 26.417871475219727, "eval/dyn_loss_std": 13.90169906616211, "eval/image_loss_mean": 42.488948822021484, "eval/image_loss_std": 44.07482147216797, "eval/model_loss_mean": 58.48119354248047, "eval/model_loss_std": 49.99983596801758, "eval/post_ent_mag": 48.05699920654297, "eval/post_ent_max": 48.05699920654297, "eval/post_ent_mean": 29.486042022705078, "eval/post_ent_min": 15.61934757232666, "eval/post_ent_std": 3.9228146076202393, "eval/prior_ent_mag": 76.00588989257812, "eval/prior_ent_max": 76.00588989257812, "eval/prior_ent_mean": 41.61039352416992, "eval/prior_ent_min": 17.457008361816406, "eval/prior_ent_std": 7.997832298278809, "eval/rep_loss_mean": 26.417871475219727, "eval/rep_loss_std": 13.90169906616211, "eval/reward_avg": 0.02880859375, "eval/reward_loss_mean": 0.14152097702026367, "eval/reward_loss_std": 1.0121418237686157, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0042190551757812, "eval/reward_neg_acc": 0.9949647784233093, "eval/reward_neg_loss": 0.06432700902223587, "eval/reward_pos_acc": 0.8064515590667725, "eval/reward_pos_loss": 2.614217758178711, "eval/reward_pred": 0.025588717311620712, "eval/reward_rate": 0.0302734375, "replay/size": 133628.0, "replay/inserts": 2132.0, "replay/samples": 34112.0, "replay/insert_wait_avg": 2.582905216467537e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.844077489613144e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 27200.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 7.152557373046875e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0964593887329, "timer/env.step_count": 267.0, "timer/env.step_total": 25.470056533813477, "timer/env.step_frac": 0.025467599944690316, "timer/env.step_avg": 0.09539347016409541, "timer/env.step_min": 0.02373504638671875, "timer/env.step_max": 1.7217621803283691, "timer/replay._sample_count": 34112.0, "timer/replay._sample_total": 16.77254295349121, "timer/replay._sample_frac": 0.016770925240294048, "timer/replay._sample_avg": 0.0004916904008410885, "timer/replay._sample_min": 0.00033736228942871094, "timer/replay._sample_max": 0.023615360260009766, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 267.0, "timer/agent.policy_total": 4.331436395645142, "timer/agent.policy_frac": 0.004331018628235671, "timer/agent.policy_avg": 0.016222608223390042, "timer/agent.policy_min": 0.014505147933959961, "timer/agent.policy_max": 0.047039031982421875, "timer/dataset_train_count": 2132.0, "timer/dataset_train_total": 0.40186381340026855, "timer/dataset_train_frac": 0.0004018250536012206, "timer/dataset_train_avg": 0.00018849146969993834, "timer/dataset_train_min": 8.845329284667969e-05, "timer/dataset_train_max": 0.0011680126190185547, "timer/agent.train_count": 2132.0, "timer/agent.train_total": 958.4921643733978, "timer/agent.train_frac": 0.9583997177224646, "timer/agent.train_avg": 0.4495741859162279, "timer/agent.train_min": 0.43772387504577637, "timer/agent.train_max": 0.5826163291931152, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4746851921081543, "timer/agent.report_frac": 0.0004746394086809244, "timer/agent.report_avg": 0.23734259605407715, "timer/agent.report_min": 0.2287580966949463, "timer/agent.report_max": 0.245927095413208, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.5987625122070312e-05, "timer/dataset_eval_frac": 2.598511861341271e-08, "timer/dataset_eval_avg": 2.5987625122070312e-05, "timer/dataset_eval_min": 2.5987625122070312e-05, "timer/dataset_eval_max": 2.5987625122070312e-05, "fps": 2.131755711589872}
{"step": 134544, "time": 62522.61674785614, "episode/length": 175.0, "episode/score": 4.293255878395939, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.19325576113078569}
{"step": 134672, "time": 62582.13327598572, "episode/length": 212.0, "episode/score": 5.324881168034153, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.22488119005993212}
{"step": 134696, "time": 62594.517362594604, "episode/length": 156.0, "episode/score": 5.248050424640496, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.14805036322559317}
{"step": 134736, "time": 62614.14464712143, "episode/length": 174.0, "episode/score": 4.288743316906221, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.18874321660860005}
{"step": 134744, "time": 62619.287222862244, "episode/length": 177.0, "episode/score": 5.303179713520876, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.20317963292654895}
{"step": 134856, "time": 62671.97646975517, "episode/length": 169.0, "episode/score": 4.259017358754136, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.15901718900022388}
{"step": 134856, "time": 62671.98336291313, "episode/length": 38.0, "episode/score": 1.1353482669801451, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.035348145465832204}
{"step": 134872, "time": 62682.39735198021, "episode/length": 200.0, "episode/score": 4.3167588328424245, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.21675883612533653}
{"step": 134912, "time": 62702.04426622391, "episode/length": 166.0, "episode/score": 5.240042273392646, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.1400420285654036}
{"step": 135640, "time": 63033.355506420135, "episode/length": 95.0, "episode/score": 4.188530714985973, "episode/reward_rate": 0.9583333333333334, "episode/intrinsic_return": 0.08853056320367614}
{"step": 135984, "time": 63190.79963231087, "episode/length": 140.0, "episode/score": 4.255331536228823, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.15533136011572424}
{"step": 136008, "time": 63203.09841775894, "episode/length": 166.0, "episode/score": 5.272188436514625, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.172188365000693}
{"step": 136112, "time": 63251.585505485535, "episode/length": 176.0, "episode/score": 6.289196269310651, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.18919615617824093}
{"step": 136136, "time": 63264.01196217537, "episode/length": 174.0, "episode/score": 5.272517592695749, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.17251753772370648}
{"step": 136224, "time": 63305.19930267334, "episode/length": 170.0, "episode/score": 4.270898720166315, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.17089859737143342}
{"step": 136272, "time": 63328.50386476517, "episode/length": 169.0, "episode/score": 5.270805515244319, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.17080538310710836}
{"step": 136283, "time": 63335.630417346954, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.054531931322674, "train/action_min": 0.0, "train/action_std": 4.06392199826795, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.042305766808432205, "train/actor_opt_grad_steps": 133650.0, "train/actor_opt_loss": -13.840956778685714, "train/adv_mag": 0.645999425649643, "train/adv_max": 0.5800443561964257, "train/adv_mean": 0.0022805788888797186, "train/adv_min": -0.5003243091494538, "train/adv_std": 0.051988016172896986, "train/cont_avg": 0.9942632630813953, "train/cont_loss_mean": 9.554649080803566e-06, "train/cont_loss_std": 0.00028270349200956686, "train/cont_neg_acc": 0.9993355484895928, "train/cont_neg_loss": 0.0012151090781741046, "train/cont_pos_acc": 0.999999985306762, "train/cont_pos_loss": 2.4480707665805652e-06, "train/cont_pred": 0.9942665640697923, "train/cont_rate": 0.9942632630813953, "train/dyn_loss_mean": 3.087165364553762, "train/dyn_loss_std": 7.841328836041828, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0278453829676606, "train/extr_critic_critic_opt_grad_steps": 133650.0, "train/extr_critic_critic_opt_loss": 15306.221752361918, "train/extr_critic_mag": 10.62366525960523, "train/extr_critic_max": 10.62366525960523, "train/extr_critic_mean": 2.1972535072371016, "train/extr_critic_min": -0.6802448732908382, "train/extr_critic_std": 2.3260679339253625, "train/extr_return_normed_mag": 1.613419361447179, "train/extr_return_normed_max": 1.613419361447179, "train/extr_return_normed_mean": 0.3556797566108925, "train/extr_return_normed_min": -0.12189258726876835, "train/extr_return_normed_std": 0.34358956287073533, "train/extr_return_rate": 0.68108348985051, "train/extr_return_raw_mag": 10.872502085219981, "train/extr_return_raw_max": 10.872502085219981, "train/extr_return_raw_mean": 2.2129627222238586, "train/extr_return_raw_min": -1.0715191999147105, "train/extr_return_raw_std": 2.363895282080007, "train/extr_reward_mag": 1.0184361613074013, "train/extr_reward_max": 1.0184361613074013, "train/extr_reward_mean": 0.03345131719874781, "train/extr_reward_min": -0.7130468579225762, "train/extr_reward_std": 0.18170001201851424, "train/image_loss_mean": 1.614841899206472, "train/image_loss_std": 4.939350390988727, "train/model_loss_mean": 3.539376476199128, "train/model_loss_std": 8.761147390409958, "train/model_opt_grad_norm": 32.669509491073754, "train/model_opt_grad_steps": 133541.18139534883, "train/model_opt_loss": 6284.681485056322, "train/model_opt_model_opt_grad_overflow": 0.004651162790697674, "train/model_opt_model_opt_grad_scale": 1790.6976744186047, "train/policy_entropy_mag": 2.643207222916359, "train/policy_entropy_max": 2.643207222916359, "train/policy_entropy_mean": 0.5391993126203848, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6712618392567302, "train/policy_logprob_mag": 7.438384080487628, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5390968938206517, "train/policy_logprob_min": -7.438384080487628, "train/policy_logprob_std": 1.123339552103087, "train/policy_randomness_mag": 0.9329361552415892, "train/policy_randomness_max": 0.9329361552415892, "train/policy_randomness_mean": 0.19031369575234347, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.23692597109217978, "train/post_ent_mag": 47.08244832948197, "train/post_ent_max": 47.08244832948197, "train/post_ent_mean": 27.41310823130053, "train/post_ent_min": 13.306866477256598, "train/post_ent_std": 4.8208555033040605, "train/prior_ent_mag": 76.03340184411337, "train/prior_ent_max": 76.03340184411337, "train/prior_ent_mean": 30.404652688669604, "train/prior_ent_min": 14.750751047356184, "train/prior_ent_std": 8.81796122484429, "train/rep_loss_mean": 3.087165364553762, "train/rep_loss_std": 7.841328836041828, "train/reward_avg": 0.02008260665461421, "train/reward_loss_mean": 0.07222581639192825, "train/reward_loss_std": 0.16006361672351527, "train/reward_max_data": 1.0091570072395857, "train/reward_max_pred": 1.009318409409634, "train/reward_neg_acc": 0.9993013783942821, "train/reward_neg_loss": 0.05130020151304644, "train/reward_pos_acc": 0.9276236398275508, "train/reward_pos_loss": 0.7188761126163394, "train/reward_pred": 0.019920724838279013, "train/reward_rate": 0.03135446947674419, "train_stats/sum_log_reward": 4.474999971687794, "train_stats/max_log_achievement_collect_drink": 3.125, "train_stats/max_log_achievement_collect_sapling": 1.6875, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 5.6875, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0625, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.5, "train_stats/max_log_achievement_place_table": 2.5, "train_stats/max_log_achievement_wake_up": 1.5, "train_stats/mean_log_entropy": 0.3945870567113161, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 2.595135697447404e-07, "report/cont_loss_std": 5.327766530172084e-07, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 4.8945894377538934e-06, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.3219483580305678e-07, "report/cont_pred": 0.9941405057907104, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 3.1790714263916016, "report/dyn_loss_std": 7.517562389373779, "report/image_loss_mean": 1.2361931800842285, "report/image_loss_std": 4.850745677947998, "report/model_loss_mean": 3.220987319946289, "report/model_loss_std": 8.548385620117188, "report/post_ent_mag": 49.2081298828125, "report/post_ent_max": 49.2081298828125, "report/post_ent_mean": 27.803855895996094, "report/post_ent_min": 12.246278762817383, "report/post_ent_std": 4.411120891571045, "report/prior_ent_mag": 76.42352294921875, "report/prior_ent_max": 76.42352294921875, "report/prior_ent_mean": 31.033649444580078, "report/prior_ent_min": 14.635635375976562, "report/prior_ent_std": 8.817269325256348, "report/rep_loss_mean": 3.1790714263916016, "report/rep_loss_std": 7.517562389373779, "report/reward_avg": 0.0291744414716959, "report/reward_loss_mean": 0.07735127210617065, "report/reward_loss_std": 0.14798106253147125, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0028059482574463, "report/reward_neg_acc": 0.9999999403953552, "report/reward_neg_loss": 0.05025769770145416, "report/reward_pos_acc": 0.8604651093482971, "report/reward_pos_loss": 0.6954627633094788, "report/reward_pred": 0.028512977063655853, "report/reward_rate": 0.0419921875, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 3.6381774748406315e-07, "eval/cont_loss_std": 4.828997134609381e-06, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 6.32191076874733e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.7913033900640585e-07, "eval/cont_pred": 0.9970703721046448, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 22.316877365112305, "eval/dyn_loss_std": 13.370295524597168, "eval/image_loss_mean": 31.46285629272461, "eval/image_loss_std": 32.42318344116211, "eval/model_loss_mean": 44.98794937133789, "eval/model_loss_std": 37.896358489990234, "eval/post_ent_mag": 49.2081298828125, "eval/post_ent_max": 49.2081298828125, "eval/post_ent_mean": 30.491409301757812, "eval/post_ent_min": 15.740453720092773, "eval/post_ent_std": 4.402987480163574, "eval/prior_ent_mag": 76.42352294921875, "eval/prior_ent_max": 76.42352294921875, "eval/prior_ent_mean": 40.896820068359375, "eval/prior_ent_min": 15.248722076416016, "eval/prior_ent_std": 8.773543357849121, "eval/rep_loss_mean": 22.316877365112305, "eval/rep_loss_std": 13.370295524597168, "eval/reward_avg": 0.02109374850988388, "eval/reward_loss_mean": 0.13496625423431396, "eval/reward_loss_std": 0.9855800867080688, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0018360614776611, "eval/reward_neg_acc": 0.9989989995956421, "eval/reward_neg_loss": 0.05116038769483566, "eval/reward_pos_acc": 0.7199999690055847, "eval/reward_pos_loss": 3.483849048614502, "eval/reward_pred": 0.013640409335494041, "eval/reward_rate": 0.0244140625, "replay/size": 135779.0, "replay/inserts": 2151.0, "replay/samples": 34416.0, "replay/insert_wait_avg": 2.504226386630219e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.817948601623848e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 27200.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 6.705522537231445e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3325471878052, "timer/env.step_count": 269.0, "timer/env.step_total": 30.969899654388428, "timer/env.step_frac": 0.030959604125101063, "timer/env.step_avg": 0.11512973849215029, "timer/env.step_min": 0.02311110496520996, "timer/env.step_max": 3.1441078186035156, "timer/replay._sample_count": 34416.0, "timer/replay._sample_total": 16.36118197441101, "timer/replay._sample_frac": 0.01635574291809913, "timer/replay._sample_avg": 0.00047539464128344407, "timer/replay._sample_min": 0.000339508056640625, "timer/replay._sample_max": 0.010472536087036133, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 269.0, "timer/agent.policy_total": 4.127694368362427, "timer/agent.policy_frac": 0.004126322171528307, "timer/agent.policy_avg": 0.015344588729971846, "timer/agent.policy_min": 0.014297723770141602, "timer/agent.policy_max": 0.023674488067626953, "timer/dataset_train_count": 2151.0, "timer/dataset_train_total": 0.36833739280700684, "timer/dataset_train_frac": 0.00036821494396288416, "timer/dataset_train_avg": 0.00017124007103998457, "timer/dataset_train_min": 8.559226989746094e-05, "timer/dataset_train_max": 0.0004961490631103516, "timer/agent.train_count": 2151.0, "timer/agent.train_total": 954.7294206619263, "timer/agent.train_frac": 0.9544120336241372, "timer/agent.train_avg": 0.4438537520511047, "timer/agent.train_min": 0.43189239501953125, "timer/agent.train_max": 0.6163425445556641, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.477982759475708, "timer/agent.report_frac": 0.0004778238604946343, "timer/agent.report_avg": 0.238991379737854, "timer/agent.report_min": 0.23317956924438477, "timer/agent.report_max": 0.24480319023132324, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.86102294921875e-05, "timer/dataset_eval_frac": 2.8600718403713136e-08, "timer/dataset_eval_avg": 2.86102294921875e-05, "timer/dataset_eval_min": 2.86102294921875e-05, "timer/dataset_eval_max": 2.86102294921875e-05, "fps": 2.150255831120111}
{"step": 136304, "time": 63345.399884939194, "episode/length": 194.0, "episode/score": 5.290424604483178, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.1904244178344925}
{"step": 137176, "time": 63743.24309754372, "episode/length": 191.0, "episode/score": 5.292711704933026, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.19271148318512132}
{"step": 137384, "time": 63839.321674346924, "episode/length": 138.0, "episode/score": 2.2498790012468817, "episode/reward_rate": 0.9640287769784173, "episode/intrinsic_return": 0.14987895234662574}
{"step": 137416, "time": 63855.369034051895, "episode/length": 178.0, "episode/score": 5.287408812535432, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.18740863095081295}
{"step": 137416, "time": 63855.37772536278, "episode/length": 162.0, "episode/score": 5.254724523409095, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.15472435853007482}
{"step": 137488, "time": 63891.13115978241, "episode/length": 168.0, "episode/score": 5.262149204569141, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.1621490424258809}
{"step": 137528, "time": 63910.85079407692, "episode/length": 189.0, "episode/score": 5.299297383156954, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.19929722168308217}
{"step": 137672, "time": 63977.703830718994, "episode/length": 170.0, "episode/score": 5.271072846519019, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.17107267925348424}
{"step": 137696, "time": 63990.084980010986, "episode/length": 183.0, "episode/score": 3.2751745023033436, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.17517440814663132}
{"step": 138452, "time": 64335.86076450348, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.111968290970622, "train/action_min": 0.0, "train/action_std": 4.114532216902702, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.043774383803529125, "train/actor_opt_grad_steps": 135810.0, "train/actor_opt_loss": -15.189468328785237, "train/adv_mag": 0.6128628473677393, "train/adv_max": 0.5521236589427367, "train/adv_mean": 0.001733460265707599, "train/adv_min": -0.5127237215294816, "train/adv_std": 0.051530147426276714, "train/cont_avg": 0.9940956221198156, "train/cont_loss_mean": 1.5057188504628282e-05, "train/cont_loss_std": 0.0004422141881205058, "train/cont_neg_acc": 0.9994239631336406, "train/cont_neg_loss": 0.0016064795252957757, "train/cont_pos_acc": 0.9999999799486678, "train/cont_pos_loss": 3.014385424937082e-06, "train/cont_pred": 0.9940984776492492, "train/cont_rate": 0.9940956221198156, "train/dyn_loss_mean": 3.0972970191234817, "train/dyn_loss_std": 7.853738294768443, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0452088331846598, "train/extr_critic_critic_opt_grad_steps": 135810.0, "train/extr_critic_critic_opt_loss": 15360.50581437212, "train/extr_critic_mag": 10.38062987789031, "train/extr_critic_max": 10.38062987789031, "train/extr_critic_mean": 2.1774461055131553, "train/extr_critic_min": -0.6957768009554955, "train/extr_critic_std": 2.36095252619361, "train/extr_return_normed_mag": 1.542847444384878, "train/extr_return_normed_max": 1.542847444384878, "train/extr_return_normed_mean": 0.34464160033634733, "train/extr_return_normed_min": -0.14303958173927075, "train/extr_return_normed_std": 0.3369434191609308, "train/extr_return_rate": 0.6705264493067693, "train/extr_return_raw_mag": 10.723841157377041, "train/extr_return_raw_max": 10.723841157377041, "train/extr_return_raw_mean": 2.1897977233482395, "train/extr_return_raw_min": -1.2741509118387777, "train/extr_return_raw_std": 2.3946365101546188, "train/extr_reward_mag": 1.0174975790735763, "train/extr_reward_max": 1.0174975790735763, "train/extr_reward_mean": 0.03181650711884422, "train/extr_reward_min": -0.7131791839951195, "train/extr_reward_std": 0.17754935613974998, "train/image_loss_mean": 1.575071138171007, "train/image_loss_std": 4.854820387704032, "train/model_loss_mean": 3.505248345537669, "train/model_loss_std": 8.685014480819351, "train/model_opt_grad_norm": 31.33750205765122, "train/model_opt_grad_steps": 135699.72811059907, "train/model_opt_loss": 8969.00941235239, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2557.6036866359445, "train/policy_entropy_mag": 2.6627842501011862, "train/policy_entropy_max": 2.6627842501011862, "train/policy_entropy_mean": 0.5600837562490718, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6876230934797893, "train/policy_logprob_mag": 7.4383841110264655, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5597925177916953, "train/policy_logprob_min": -7.4383841110264655, "train/policy_logprob_std": 1.1348410861283404, "train/policy_randomness_mag": 0.9398459866299608, "train/policy_randomness_max": 0.9398459866299608, "train/policy_randomness_mean": 0.19768498659408587, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.24270077619684458, "train/post_ent_mag": 47.30035379295525, "train/post_ent_max": 47.30035379295525, "train/post_ent_mean": 27.641761349093528, "train/post_ent_min": 13.398578604245515, "train/post_ent_std": 4.8149989728004705, "train/prior_ent_mag": 76.12513768068656, "train/prior_ent_max": 76.12513768068656, "train/prior_ent_mean": 30.650600758565737, "train/prior_ent_min": 14.729308607391498, "train/prior_ent_std": 8.819715455929805, "train/rep_loss_mean": 3.0972970191234817, "train/rep_loss_std": 7.853738294768443, "train/reward_avg": 0.01965002431684444, "train/reward_loss_mean": 0.07178394427771942, "train/reward_loss_std": 0.15627548376673378, "train/reward_max_data": 1.0067799838457239, "train/reward_max_pred": 1.0077509418610604, "train/reward_neg_acc": 0.9992754011659578, "train/reward_neg_loss": 0.051103177673531015, "train/reward_pos_acc": 0.9350540008962429, "train/reward_pos_loss": 0.7160355720651864, "train/reward_pred": 0.01954937533557003, "train/reward_rate": 0.03109248991935484, "train_stats/sum_log_reward": 4.544444349077013, "train_stats/max_log_achievement_collect_drink": 5.0, "train_stats/max_log_achievement_collect_sapling": 1.2222222222222223, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 5.0, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.3333333333333333, "train_stats/max_log_achievement_place_plant": 1.2222222222222223, "train_stats/max_log_achievement_place_table": 2.111111111111111, "train_stats/max_log_achievement_wake_up": 2.2222222222222223, "train_stats/mean_log_entropy": 0.459772656361262, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 1.0805922556755831e-06, "report/cont_loss_std": 7.60882858230616e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 7.96564418124035e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 6.174734039632312e-07, "report/cont_pred": 0.9941405057907104, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 2.7983431816101074, "report/dyn_loss_std": 7.948469638824463, "report/image_loss_mean": 1.3016941547393799, "report/image_loss_std": 3.865299940109253, "report/model_loss_mean": 3.043607711791992, "report/model_loss_std": 8.02163314819336, "report/post_ent_mag": 48.49627685546875, "report/post_ent_max": 48.49627685546875, "report/post_ent_mean": 27.827411651611328, "report/post_ent_min": 13.48748779296875, "report/post_ent_std": 4.834789276123047, "report/prior_ent_mag": 76.05612182617188, "report/prior_ent_max": 76.05612182617188, "report/prior_ent_mean": 30.58386993408203, "report/prior_ent_min": 14.230963706970215, "report/prior_ent_std": 8.715692520141602, "report/rep_loss_mean": 2.7983431816101074, "report/rep_loss_std": 7.948469638824463, "report/reward_avg": 0.01697552017867565, "report/reward_loss_mean": 0.0629068911075592, "report/reward_loss_std": 0.1346331089735031, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0011935234069824, "report/reward_neg_acc": 0.9980000257492065, "report/reward_neg_loss": 0.04627425596117973, "report/reward_pos_acc": 0.9166666865348816, "report/reward_pos_loss": 0.7559337019920349, "report/reward_pred": 0.01618712581694126, "report/reward_rate": 0.0234375, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 2.1007250325055793e-05, "eval/cont_loss_std": 0.0005363232921808958, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.008540241047739983, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 4.335564426583005e-06, "eval/cont_pred": 0.998059093952179, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 24.860315322875977, "eval/dyn_loss_std": 14.495776176452637, "eval/image_loss_mean": 43.598121643066406, "eval/image_loss_std": 48.68935775756836, "eval/model_loss_mean": 58.71056365966797, "eval/model_loss_std": 54.717857360839844, "eval/post_ent_mag": 48.49627685546875, "eval/post_ent_max": 48.49627685546875, "eval/post_ent_mean": 30.24231719970703, "eval/post_ent_min": 16.902454376220703, "eval/post_ent_std": 4.338712215423584, "eval/prior_ent_mag": 76.05612182617188, "eval/prior_ent_max": 76.05612182617188, "eval/prior_ent_mean": 40.527706146240234, "eval/prior_ent_min": 14.923629760742188, "eval/prior_ent_std": 8.989501953125, "eval/rep_loss_mean": 24.860315322875977, "eval/rep_loss_std": 14.495776176452637, "eval/reward_avg": 0.0244140587747097, "eval/reward_loss_mean": 0.19623178243637085, "eval/reward_loss_std": 1.1541622877120972, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 1.04295015335083, "eval/reward_neg_acc": 0.9959879517555237, "eval/reward_neg_loss": 0.08435690402984619, "eval/reward_pos_acc": 0.5555555820465088, "eval/reward_pos_loss": 4.327315330505371, "eval/reward_pred": 0.01539908442646265, "eval/reward_rate": 0.0263671875, "replay/size": 137948.0, "replay/inserts": 2169.0, "replay/samples": 34704.0, "replay/insert_wait_avg": 2.554563291065151e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.820739455902395e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 27200.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 8.493661880493164e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2194640636444, "timer/env.step_count": 271.0, "timer/env.step_total": 20.931981325149536, "timer/env.step_frac": 0.020927388515424476, "timer/env.step_avg": 0.07723978348763666, "timer/env.step_min": 0.023107290267944336, "timer/env.step_max": 3.2230610847473145, "timer/replay._sample_count": 34704.0, "timer/replay._sample_total": 16.54604959487915, "timer/replay._sample_frac": 0.016542419128354732, "timer/replay._sample_avg": 0.0004767764406085509, "timer/replay._sample_min": 0.00034999847412109375, "timer/replay._sample_max": 0.020560264587402344, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 271.0, "timer/agent.policy_total": 4.20097017288208, "timer/agent.policy_frac": 0.004200048413189818, "timer/agent.policy_avg": 0.015501734955284428, "timer/agent.policy_min": 0.014360666275024414, "timer/agent.policy_max": 0.03586006164550781, "timer/dataset_train_count": 2169.0, "timer/dataset_train_total": 0.3750019073486328, "timer/dataset_train_frac": 0.0003749196259639787, "timer/dataset_train_avg": 0.00017289161242445034, "timer/dataset_train_min": 8.678436279296875e-05, "timer/dataset_train_max": 0.0008070468902587891, "timer/agent.train_count": 2169.0, "timer/agent.train_total": 964.2988924980164, "timer/agent.train_frac": 0.9640873099792603, "timer/agent.train_avg": 0.4445822464260103, "timer/agent.train_min": 0.4340031147003174, "timer/agent.train_max": 0.5626497268676758, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47118401527404785, "timer/agent.report_frac": 0.00047108063000468283, "timer/agent.report_avg": 0.23559200763702393, "timer/agent.report_min": 0.2288200855255127, "timer/agent.report_max": 0.24236392974853516, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.6226043701171875e-05, "timer/dataset_eval_frac": 2.6220289289934374e-08, "timer/dataset_eval_avg": 2.6226043701171875e-05, "timer/dataset_eval_min": 2.6226043701171875e-05, "timer/dataset_eval_max": 2.6226043701171875e-05, "fps": 2.168496030277395}
{"step": 138624, "time": 64413.929352760315, "episode/length": 118.0, "episode/score": 4.200499183901229, "episode/reward_rate": 0.957983193277311, "episode/intrinsic_return": 0.100499066883458}
{"step": 138736, "time": 64466.203469991684, "episode/length": 155.0, "episode/score": 2.256913557500411, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.15691346066614642}
{"step": 138896, "time": 64540.44282245636, "episode/length": 184.0, "episode/score": 5.287143789228139, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.18714366058338783}
{"step": 138944, "time": 64563.70844101906, "episode/length": 176.0, "episode/score": 3.258625861004475, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.15862584001479263}
{"step": 139048, "time": 64612.65656661987, "episode/length": 203.0, "episode/score": 3.288210563474422, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.18821060924892663}
{"step": 139176, "time": 64672.25324225426, "episode/length": 249.0, "episode/score": 4.358684130578695, "episode/reward_rate": 0.996, "episode/intrinsic_return": 0.2586840192507225}
{"step": 139176, "time": 64672.315027713776, "episode/length": 223.0, "episode/score": 5.355196318843809, "episode/reward_rate": 0.9776785714285714, "episode/intrinsic_return": 0.2551961674107588}
{"step": 139176, "time": 64672.32116961479, "episode/length": 68.0, "episode/score": 2.1816667432140093, "episode/reward_rate": 0.927536231884058, "episode/intrinsic_return": 0.08166666512261145}
{"step": 139280, "time": 64725.17737555504, "episode/length": 197.0, "episode/score": 4.3137373642093735, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.21373719321854878}
{"step": 139880, "time": 64998.972534418106, "episode/length": 103.0, "episode/score": 1.2016419261062765, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.10164188806174934}
{"step": 140088, "time": 65109.951726436615, "eval_episode/length": 61.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9193548387096774}
{"step": 140088, "time": 65115.04170846939, "eval_episode/length": 149.0, "eval_episode/score": 4.099999971687794, "eval_episode/reward_rate": 0.9933333333333333}
{"step": 140088, "time": 65116.6521821022, "eval_episode/length": 152.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9607843137254902}
{"step": 140088, "time": 65116.65906739235, "eval_episode/length": 152.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9934640522875817}
{"step": 140088, "time": 65120.215487957, "eval_episode/length": 165.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9759036144578314}
{"step": 140088, "time": 65122.635518312454, "eval_episode/length": 185.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.956989247311828}
{"step": 140088, "time": 65125.11784386635, "eval_episode/length": 145.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9931506849315068}
{"step": 140088, "time": 65126.759649038315, "eval_episode/length": 210.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.995260663507109}
{"step": 140384, "time": 65260.74724531174, "episode/length": 179.0, "episode/score": 3.2650976905551943, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.16509753958780493}
{"step": 140392, "time": 65265.84622645378, "episode/length": 186.0, "episode/score": 3.276678787320634, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.17667863169663178}
{"step": 140512, "time": 65321.836689949036, "episode/length": 153.0, "episode/score": 3.230695846200433, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.1306958331269925}
{"step": 140520, "time": 65327.08139324188, "episode/length": 222.0, "episode/score": 5.326555081515835, "episode/reward_rate": 0.9775784753363229, "episode/intrinsic_return": 0.22655495054277708}
{"step": 140535, "time": 65336.072838544846, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.03383049598107, "train/action_min": 0.0, "train/action_std": 4.070053042127536, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04300328436343429, "train/actor_opt_grad_steps": 137935.0, "train/actor_opt_loss": -13.415080288425088, "train/adv_mag": 0.6633743394452792, "train/adv_max": 0.5946816055533978, "train/adv_mean": 0.0028446945107746683, "train/adv_min": -0.5138184335082769, "train/adv_std": 0.05327875602345627, "train/cont_avg": 0.9943378155048077, "train/cont_loss_mean": 5.608200838535228e-05, "train/cont_loss_std": 0.0017259307201758116, "train/cont_neg_acc": 0.9979967950628355, "train/cont_neg_loss": 0.011539183220899819, "train/cont_pos_acc": 0.999999976502015, "train/cont_pos_loss": 6.5947112264716716e-06, "train/cont_pred": 0.9943427566725475, "train/cont_rate": 0.9943378155048077, "train/dyn_loss_mean": 3.0781595443303766, "train/dyn_loss_std": 7.810984540444154, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0209449506722963, "train/extr_critic_critic_opt_grad_steps": 137935.0, "train/extr_critic_critic_opt_loss": 15128.509573129508, "train/extr_critic_mag": 10.091931744263722, "train/extr_critic_max": 10.091931744263722, "train/extr_critic_mean": 2.199335905794914, "train/extr_critic_min": -0.67733511615258, "train/extr_critic_std": 2.2424944066084347, "train/extr_return_normed_mag": 1.6806083057935421, "train/extr_return_normed_max": 1.6806083057935421, "train/extr_return_normed_mean": 0.3757500499486923, "train/extr_return_normed_min": -0.12384641838546556, "train/extr_return_normed_std": 0.3496213382683121, "train/extr_return_rate": 0.7187043382571294, "train/extr_return_raw_mag": 10.74198838380667, "train/extr_return_raw_max": 10.74198838380667, "train/extr_return_raw_mean": 2.2178980135000668, "train/extr_return_raw_min": -1.0434712971059175, "train/extr_return_raw_std": 2.283160752401902, "train/extr_reward_mag": 1.0211480661080434, "train/extr_reward_max": 1.0211480661080434, "train/extr_reward_mean": 0.03435815155255394, "train/extr_reward_min": -0.6797472851780745, "train/extr_reward_std": 0.18360893363849476, "train/image_loss_mean": 1.493696337995621, "train/image_loss_std": 4.673674857387176, "train/model_loss_mean": 3.412671222136571, "train/model_loss_std": 8.507438751367422, "train/model_opt_grad_norm": 31.742448371190292, "train/model_opt_grad_steps": 137822.64423076922, "train/model_opt_loss": 8799.718998835637, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2572.1153846153848, "train/policy_entropy_mag": 2.637573526455806, "train/policy_entropy_max": 2.637573526455806, "train/policy_entropy_mean": 0.5147446765062901, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6403517165722755, "train/policy_logprob_mag": 7.4383840675537405, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5136173729999707, "train/policy_logprob_min": -7.4383840675537405, "train/policy_logprob_std": 1.102059417619155, "train/policy_randomness_mag": 0.9309477083958112, "train/policy_randomness_max": 0.9309477083958112, "train/policy_randomness_mean": 0.18168228223490027, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.22601605407320535, "train/post_ent_mag": 46.87188550142142, "train/post_ent_max": 46.87188550142142, "train/post_ent_mean": 27.74177697071662, "train/post_ent_min": 13.360030935360836, "train/post_ent_std": 4.837385869943178, "train/prior_ent_mag": 76.15257002757146, "train/prior_ent_max": 76.15257002757146, "train/prior_ent_mean": 30.721450548905594, "train/prior_ent_min": 15.016128517114199, "train/prior_ent_std": 8.76549169421196, "train/rep_loss_mean": 3.0781595443303766, "train/rep_loss_std": 7.810984540444154, "train/reward_avg": 0.02057413555135449, "train/reward_loss_mean": 0.07202309036913973, "train/reward_loss_std": 0.15725314119257605, "train/reward_max_data": 1.0089423381365263, "train/reward_max_pred": 1.0095614790916443, "train/reward_neg_acc": 0.9992381930351257, "train/reward_neg_loss": 0.05082992122222025, "train/reward_pos_acc": 0.9391115210377253, "train/reward_pos_loss": 0.7172832832886622, "train/reward_pred": 0.020443571077731367, "train/reward_rate": 0.03183687650240385, "train_stats/sum_log_reward": 3.457142804350172, "train_stats/max_log_achievement_collect_drink": 3.7142857142857144, "train_stats/max_log_achievement_collect_sapling": 1.5, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 2.2142857142857144, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.2142857142857142, "train_stats/max_log_achievement_place_table": 0.7142857142857143, "train_stats/max_log_achievement_wake_up": 2.142857142857143, "train_stats/mean_log_entropy": 0.4936681645257132, "eval_stats/sum_log_reward": 3.5999999940395355, "eval_stats/max_log_achievement_collect_drink": 2.375, "eval_stats/max_log_achievement_collect_sapling": 0.625, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 2.5, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.125, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 0.625, "eval_stats/max_log_achievement_place_table": 1.0, "eval_stats/max_log_achievement_wake_up": 1.875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 4.791849050889141e-07, "report/cont_loss_std": 1.828791937441565e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 1.8188343346992042e-06, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 4.69964106741827e-07, "report/cont_pred": 0.9931636452674866, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 3.06929349899292, "report/dyn_loss_std": 7.783782005310059, "report/image_loss_mean": 1.0549428462982178, "report/image_loss_std": 3.337366819381714, "report/model_loss_mean": 2.9767277240753174, "report/model_loss_std": 7.466769695281982, "report/post_ent_mag": 47.84233474731445, "report/post_ent_max": 47.84233474731445, "report/post_ent_mean": 27.84123992919922, "report/post_ent_min": 15.244728088378906, "report/post_ent_std": 4.478744983673096, "report/prior_ent_mag": 75.72645568847656, "report/prior_ent_max": 75.72645568847656, "report/prior_ent_mean": 30.61296844482422, "report/prior_ent_min": 15.85598087310791, "report/prior_ent_std": 8.79991626739502, "report/rep_loss_mean": 3.06929349899292, "report/rep_loss_std": 7.783782005310059, "report/reward_avg": 0.026372458785772324, "report/reward_loss_mean": 0.08020824193954468, "report/reward_loss_std": 0.16927993297576904, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.001800298690796, "report/reward_neg_acc": 0.9959267377853394, "report/reward_neg_loss": 0.05183925852179527, "report/reward_pos_acc": 0.8333333730697632, "report/reward_pos_loss": 0.7435021996498108, "report/reward_pred": 0.026297282427549362, "report/reward_rate": 0.041015625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.008126226253807545, "eval/cont_loss_std": 0.2057860791683197, "eval/cont_neg_acc": 0.5, "eval/cont_neg_loss": 2.080228328704834, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 3.354024613599904e-07, "eval/cont_pred": 0.9979206323623657, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 25.385234832763672, "eval/dyn_loss_std": 12.733464241027832, "eval/image_loss_mean": 38.2529182434082, "eval/image_loss_std": 43.196109771728516, "eval/model_loss_mean": 53.731971740722656, "eval/model_loss_std": 48.290489196777344, "eval/post_ent_mag": 43.03508377075195, "eval/post_ent_max": 43.03508377075195, "eval/post_ent_mean": 30.829242706298828, "eval/post_ent_min": 19.23590850830078, "eval/post_ent_std": 3.5822646617889404, "eval/prior_ent_mag": 75.72645568847656, "eval/prior_ent_max": 75.72645568847656, "eval/prior_ent_mean": 42.07671356201172, "eval/prior_ent_min": 19.79939842224121, "eval/prior_ent_std": 7.330542087554932, "eval/rep_loss_mean": 25.385234832763672, "eval/rep_loss_std": 12.733464241027832, "eval/reward_avg": 0.02373046800494194, "eval/reward_loss_mean": 0.2397858202457428, "eval/reward_loss_std": 1.2247228622436523, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.001230239868164, "eval/reward_neg_acc": 0.991959810256958, "eval/reward_neg_loss": 0.1639387458562851, "eval/reward_pos_acc": 0.6896551847457886, "eval/reward_pos_loss": 2.842125654220581, "eval/reward_pred": 0.019294438883662224, "eval/reward_rate": 0.0283203125, "replay/size": 140031.0, "replay/inserts": 2083.0, "replay/samples": 33328.0, "replay/insert_wait_avg": 2.568579612874779e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.738016341892046e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 28888.0, "eval_replay/inserts": 1688.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1584770058003647e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.599592208862305e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1955587863922, "timer/env.step_count": 260.0, "timer/env.step_total": 28.428227186203003, "timer/env.step_frac": 0.028422668883570104, "timer/env.step_avg": 0.10933933533155, "timer/env.step_min": 0.0233156681060791, "timer/env.step_max": 4.990517854690552, "timer/replay._sample_count": 33328.0, "timer/replay._sample_total": 15.9024178981781, "timer/replay._sample_frac": 0.015899308648674292, "timer/replay._sample_avg": 0.00047714888076626563, "timer/replay._sample_min": 0.0003418922424316406, "timer/replay._sample_max": 0.022101402282714844, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 471.0, "timer/agent.policy_total": 7.346721172332764, "timer/agent.policy_frac": 0.00734528473736382, "timer/agent.policy_avg": 0.015598134123848756, "timer/agent.policy_min": 0.009419679641723633, "timer/agent.policy_max": 0.04910731315612793, "timer/dataset_train_count": 2083.0, "timer/dataset_train_total": 0.35877370834350586, "timer/dataset_train_frac": 0.00035870356071049874, "timer/dataset_train_avg": 0.00017223893823500042, "timer/dataset_train_min": 8.487701416015625e-05, "timer/dataset_train_max": 0.0006911754608154297, "timer/agent.train_count": 2083.0, "timer/agent.train_total": 925.30664229393, "timer/agent.train_frac": 0.9251257258297266, "timer/agent.train_avg": 0.4442182632232021, "timer/agent.train_min": 0.43273115158081055, "timer/agent.train_max": 0.5740587711334229, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4736149311065674, "timer/agent.report_frac": 0.00047352232965445053, "timer/agent.report_avg": 0.2368074655532837, "timer/agent.report_min": 0.2309260368347168, "timer/agent.report_max": 0.24268889427185059, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8848648071289062e-05, "timer/dataset_eval_frac": 2.8843007567733214e-08, "timer/dataset_eval_avg": 2.8848648071289062e-05, "timer/dataset_eval_min": 2.8848648071289062e-05, "timer/dataset_eval_max": 2.8848648071289062e-05, "fps": 2.0825670103869425}
{"step": 140720, "time": 65420.3156106472, "episode/length": 192.0, "episode/score": 5.317030985854217, "episode/reward_rate": 0.9689119170984456, "episode/intrinsic_return": 0.21703089129005093}
{"step": 140736, "time": 65429.10696554184, "episode/length": 194.0, "episode/score": 3.3107160151103017, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.21071592095358938}
{"step": 140760, "time": 65441.50721693039, "episode/length": 197.0, "episode/score": 3.3265862012767684, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.2265860792967942}
{"step": 141504, "time": 65782.24937224388, "episode/length": 139.0, "episode/score": 3.217718223848351, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.11771801257782499}
{"step": 141584, "time": 65820.24410009384, "episode/length": 212.0, "episode/score": 5.32162792172312, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.2216278155465261}
{"step": 141696, "time": 65873.03062200546, "episode/length": 147.0, "episode/score": 5.24787324804538, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.1478731152678847}
{"step": 141832, "time": 65937.03526711464, "episode/length": 179.0, "episode/score": 4.276319468292968, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.17631940143564862}
{"step": 142144, "time": 66081.15769219398, "episode/length": 202.0, "episode/score": 3.317746043808256, "episode/reward_rate": 0.9704433497536946, "episode/intrinsic_return": 0.21774592299243523}
{"step": 142216, "time": 66115.6105709076, "episode/length": 186.0, "episode/score": 5.293444696803817, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.1934446185377965}
{"step": 142320, "time": 66164.80232405663, "episode/length": 197.0, "episode/score": 4.309639390226948, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.20963921411384945}
{"step": 142690, "time": 66336.1023812294, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.007704840766059, "train/action_min": 0.0, "train/action_std": 3.986239460883317, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04272178939060756, "train/actor_opt_grad_steps": 140055.0, "train/actor_opt_loss": -14.736725774145237, "train/adv_mag": 0.7114373148867378, "train/adv_max": 0.6516732976392463, "train/adv_mean": 0.00196123967297926, "train/adv_min": -0.5079239526142677, "train/adv_std": 0.051307843808360676, "train/cont_avg": 0.9942446108217593, "train/cont_loss_mean": 9.074152624058932e-05, "train/cont_loss_std": 0.002830950652163511, "train/cont_neg_acc": 0.9967592595903961, "train/cont_neg_loss": 0.018354633136511284, "train/cont_pos_acc": 0.9999999842709966, "train/cont_pos_loss": 4.747212174504722e-06, "train/cont_pred": 0.9942569616768095, "train/cont_rate": 0.9942446108217593, "train/dyn_loss_mean": 3.1107712101053306, "train/dyn_loss_std": 7.81254964404636, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9835412863779951, "train/extr_critic_critic_opt_grad_steps": 140055.0, "train/extr_critic_critic_opt_loss": 14931.247554072628, "train/extr_critic_mag": 11.015821902840226, "train/extr_critic_max": 11.015821902840226, "train/extr_critic_mean": 2.2349805583556495, "train/extr_critic_min": -0.669376927945349, "train/extr_critic_std": 2.2816232249692634, "train/extr_return_normed_mag": 1.6962719118153606, "train/extr_return_normed_max": 1.6962719118153606, "train/extr_return_normed_mean": 0.3628726353937829, "train/extr_return_normed_min": -0.1198319834139612, "train/extr_return_normed_std": 0.34078322826988167, "train/extr_return_rate": 0.7172975504287967, "train/extr_return_raw_mag": 11.31856773296992, "train/extr_return_raw_max": 11.31856773296992, "train/extr_return_raw_mean": 2.2483682935988463, "train/extr_return_raw_min": -1.032125813541589, "train/extr_return_raw_std": 2.3170743358355983, "train/extr_reward_mag": 1.0135291980372534, "train/extr_reward_max": 1.0135291980372534, "train/extr_reward_mean": 0.033780951915239846, "train/extr_reward_min": -0.6882272528277503, "train/extr_reward_std": 0.18111978629948916, "train/image_loss_mean": 1.5631952948040433, "train/image_loss_std": 4.873442482065271, "train/model_loss_mean": 3.5012582341829934, "train/model_loss_std": 8.679190010936171, "train/model_opt_grad_norm": 31.88034571100164, "train/model_opt_grad_steps": 139940.57407407407, "train/model_opt_loss": 8926.21465838397, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2546.296296296296, "train/policy_entropy_mag": 2.642969850036833, "train/policy_entropy_max": 2.642969850036833, "train/policy_entropy_mean": 0.5155875710425554, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6415902249239109, "train/policy_logprob_mag": 7.43838409141258, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5159264045457045, "train/policy_logprob_min": -7.43838409141258, "train/policy_logprob_std": 1.1057643250182823, "train/policy_randomness_mag": 0.9328523733549647, "train/policy_randomness_max": 0.9328523733549647, "train/policy_randomness_mean": 0.1819797879498866, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.2264531940497734, "train/post_ent_mag": 47.28918412879661, "train/post_ent_max": 47.28918412879661, "train/post_ent_mean": 28.183717330296833, "train/post_ent_min": 13.534606302226031, "train/post_ent_std": 4.863952135598218, "train/prior_ent_mag": 76.09139428315339, "train/prior_ent_max": 76.09139428315339, "train/prior_ent_mean": 31.20185335477193, "train/prior_ent_min": 15.022793540248164, "train/prior_ent_std": 8.75243086947335, "train/rep_loss_mean": 3.1107712101053306, "train/rep_loss_std": 7.81254964404636, "train/reward_avg": 0.019802922947780677, "train/reward_loss_mean": 0.0715094759232468, "train/reward_loss_std": 0.15307639618576677, "train/reward_max_data": 1.0054166962703068, "train/reward_max_pred": 1.0060784551832411, "train/reward_neg_acc": 0.9991458519189446, "train/reward_neg_loss": 0.05084736771122725, "train/reward_pos_acc": 0.9377268091947945, "train/reward_pos_loss": 0.7139826405931402, "train/reward_pred": 0.019732004887407163, "train/reward_rate": 0.03117766203703704, "train_stats/sum_log_reward": 4.099999928474427, "train_stats/max_log_achievement_collect_drink": 3.9, "train_stats/max_log_achievement_collect_sapling": 2.2, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 1.5, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.1, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.8, "train_stats/max_log_achievement_place_table": 0.5, "train_stats/max_log_achievement_wake_up": 2.0, "train_stats/mean_log_entropy": 0.5335062712430954, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 1.2854570741183124e-06, "report/cont_loss_std": 2.1902326352574164e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 2.4936263798736036e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.1694080512825167e-06, "report/cont_pred": 0.995116114616394, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 3.279712677001953, "report/dyn_loss_std": 8.068286895751953, "report/image_loss_mean": 1.6198217868804932, "report/image_loss_std": 6.02557373046875, "report/model_loss_mean": 3.654630184173584, "report/model_loss_std": 10.14112377166748, "report/post_ent_mag": 50.070777893066406, "report/post_ent_max": 50.070777893066406, "report/post_ent_mean": 28.30714988708496, "report/post_ent_min": 14.135903358459473, "report/post_ent_std": 5.067483425140381, "report/prior_ent_mag": 75.97096252441406, "report/prior_ent_max": 75.97096252441406, "report/prior_ent_mean": 31.545211791992188, "report/prior_ent_min": 17.233394622802734, "report/prior_ent_std": 8.593510627746582, "report/rep_loss_mean": 3.279712677001953, "report/rep_loss_std": 8.068286895751953, "report/reward_avg": 0.012075860984623432, "report/reward_loss_mean": 0.06697935611009598, "report/reward_loss_std": 0.1309768706560135, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0018062591552734, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.05048733577132225, "report/reward_pos_acc": 0.9199999570846558, "report/reward_pos_loss": 0.7260004878044128, "report/reward_pred": 0.011339283548295498, "report/reward_rate": 0.0244140625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.003838674630969763, "eval/cont_loss_std": 0.1220351904630661, "eval/cont_neg_acc": 0.75, "eval/cont_neg_loss": 0.9804007411003113, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 9.01926432561595e-06, "eval/cont_pred": 0.9970558285713196, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 21.94829559326172, "eval/dyn_loss_std": 13.26762866973877, "eval/image_loss_mean": 30.609426498413086, "eval/image_loss_std": 35.242496490478516, "eval/model_loss_mean": 43.90862274169922, "eval/model_loss_std": 40.82343673706055, "eval/post_ent_mag": 50.070777893066406, "eval/post_ent_max": 50.070777893066406, "eval/post_ent_mean": 29.884519577026367, "eval/post_ent_min": 15.339622497558594, "eval/post_ent_std": 4.75156831741333, "eval/prior_ent_mag": 75.97096252441406, "eval/prior_ent_max": 75.97096252441406, "eval/prior_ent_mean": 39.55677032470703, "eval/prior_ent_min": 14.698450088500977, "eval/prior_ent_std": 9.149801254272461, "eval/rep_loss_mean": 21.94829559326172, "eval/rep_loss_std": 13.26762866973877, "eval/reward_avg": 0.02382812649011612, "eval/reward_loss_mean": 0.12637996673583984, "eval/reward_loss_std": 0.8567660450935364, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0018150806427002, "eval/reward_neg_acc": 0.9979920387268066, "eval/reward_neg_loss": 0.07511349022388458, "eval/reward_pos_acc": 0.8571429252624512, "eval/reward_pos_loss": 1.9500023126602173, "eval/reward_pred": 0.019482219591736794, "eval/reward_rate": 0.02734375, "replay/size": 142186.0, "replay/inserts": 2155.0, "replay/samples": 34480.0, "replay/insert_wait_avg": 2.628468028907156e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.945188513488061e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 28888.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 6.854534149169922e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0175538063049, "timer/env.step_count": 270.0, "timer/env.step_total": 22.64580011367798, "timer/env.step_frac": 0.02264540260066703, "timer/env.step_avg": 0.08387333375436289, "timer/env.step_min": 0.023212194442749023, "timer/env.step_max": 1.7827043533325195, "timer/replay._sample_count": 34480.0, "timer/replay._sample_total": 16.651867389678955, "timer/replay._sample_frac": 0.016651575091155134, "timer/replay._sample_avg": 0.0004829427897238676, "timer/replay._sample_min": 0.00034117698669433594, "timer/replay._sample_max": 0.026007652282714844, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 270.0, "timer/agent.policy_total": 4.264167070388794, "timer/agent.policy_frac": 0.00426409221933991, "timer/agent.policy_avg": 0.015793211371810348, "timer/agent.policy_min": 0.01454615592956543, "timer/agent.policy_max": 0.04717516899108887, "timer/dataset_train_count": 2155.0, "timer/dataset_train_total": 0.4214146137237549, "timer/dataset_train_frac": 0.0004214072164231023, "timer/dataset_train_avg": 0.00019555202492981666, "timer/dataset_train_min": 8.7738037109375e-05, "timer/dataset_train_max": 0.02999114990234375, "timer/agent.train_count": 2155.0, "timer/agent.train_total": 961.3243594169617, "timer/agent.train_frac": 0.9613074848115738, "timer/agent.train_avg": 0.446090189984669, "timer/agent.train_min": 0.4350404739379883, "timer/agent.train_max": 0.5899899005889893, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47266507148742676, "timer/agent.report_frac": 0.0004726567745619574, "timer/agent.report_avg": 0.23633253574371338, "timer/agent.report_min": 0.22896528244018555, "timer/agent.report_max": 0.2436997890472412, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7179718017578125e-05, "timer/dataset_eval_frac": 2.7179240918447528e-08, "timer/dataset_eval_avg": 2.7179718017578125e-05, "timer/dataset_eval_min": 2.7179718017578125e-05, "timer/dataset_eval_max": 2.7179718017578125e-05, "fps": 2.154932011530872}
{"step": 142752, "time": 66364.60226559639, "episode/length": 145.0, "episode/score": 5.238521100738126, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.13852102130795174}
{"step": 142904, "time": 66435.89889764786, "episode/length": 174.0, "episode/score": 4.312329688676982, "episode/reward_rate": 0.9657142857142857, "episode/intrinsic_return": 0.21232954095466994}
{"step": 143064, "time": 66510.55899381638, "episode/length": 170.0, "episode/score": 4.273401124014981, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.1734010044506249}
{"step": 143120, "time": 66537.6909134388, "episode/length": 160.0, "episode/score": 5.251449515327749, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.15144935316629926}
{"step": 143120, "time": 66537.70224285126, "episode/length": 294.0, "episode/score": 6.418248118392967, "episode/reward_rate": 0.9864406779661017, "episode/intrinsic_return": 0.3182479537758809}
{"step": 143368, "time": 66654.4764573574, "episode/length": 143.0, "episode/score": 5.245262701688262, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.1452625325309782}
{"step": 143672, "time": 66795.11078763008, "episode/length": 190.0, "episode/score": 4.295417233264288, "episode/reward_rate": 0.9685863874345549, "episode/intrinsic_return": 0.19541716506819284}
{"step": 143776, "time": 66844.08609580994, "episode/length": 181.0, "episode/score": 5.281669916422288, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.18166987060703832}
{"step": 144280, "time": 67076.10576581955, "episode/length": 190.0, "episode/score": 4.299657145390938, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.19965696860845128}
{"step": 144336, "time": 67103.15963101387, "episode/length": 151.0, "episode/score": 5.2491322600649255, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.14913218431638597}
{"step": 144352, "time": 67112.0135769844, "episode/length": 180.0, "episode/score": 4.28519896591024, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.18519884823763277}
{"step": 144456, "time": 67161.06512188911, "episode/length": 173.0, "episode/score": 5.278668331266999, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.1786682590145574}
{"step": 144800, "time": 67318.81571054459, "episode/length": 178.0, "episode/score": 5.269891836295756, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.16989172786179552}
{"step": 144834, "time": 67336.52326583862, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.988605249707944, "train/action_min": 0.0, "train/action_std": 4.005286319233547, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04395350927017003, "train/actor_opt_grad_steps": 142205.0, "train/actor_opt_loss": -15.617419248986467, "train/adv_mag": 0.927494056731741, "train/adv_max": 0.8184723972438652, "train/adv_mean": 0.001811799430389524, "train/adv_min": -0.6735741711944063, "train/adv_std": 0.05564125561129267, "train/cont_avg": 0.9942592727803738, "train/cont_loss_mean": 6.809328409265035e-05, "train/cont_loss_std": 0.0020860600199817127, "train/cont_neg_acc": 0.9982866046027602, "train/cont_neg_loss": 0.010114122668191982, "train/cont_pos_acc": 0.9999907969314361, "train/cont_pos_loss": 1.4386024247680375e-05, "train/cont_pred": 0.9942585764644302, "train/cont_rate": 0.9942592727803738, "train/dyn_loss_mean": 3.091588102768515, "train/dyn_loss_std": 7.8532705151032065, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.006025676972398, "train/extr_critic_critic_opt_grad_steps": 142205.0, "train/extr_critic_critic_opt_loss": 15055.459928993867, "train/extr_critic_mag": 13.449099883854947, "train/extr_critic_max": 13.449099883854947, "train/extr_critic_mean": 2.2563052840321975, "train/extr_critic_min": -0.6311790157701368, "train/extr_critic_std": 2.3691248236415543, "train/extr_return_normed_mag": 1.9880030767939916, "train/extr_return_normed_max": 1.9880030767939916, "train/extr_return_normed_mean": 0.35643639840255276, "train/extr_return_normed_min": -0.11200884637361933, "train/extr_return_normed_std": 0.34772781122510676, "train/extr_return_rate": 0.7079743841819675, "train/extr_return_raw_mag": 13.592053386652582, "train/extr_return_raw_max": 13.592053386652582, "train/extr_return_raw_mean": 2.2688190647374804, "train/extr_return_raw_min": -0.9802172323253667, "train/extr_return_raw_std": 2.4128698578504757, "train/extr_reward_mag": 1.0166922284063893, "train/extr_reward_max": 1.0166922284063893, "train/extr_reward_mean": 0.03475678577218379, "train/extr_reward_min": -0.6874434095676815, "train/extr_reward_std": 0.18324186597193512, "train/image_loss_mean": 1.5284414099198635, "train/image_loss_std": 4.890552446106884, "train/model_loss_mean": 3.4551588842801957, "train/model_loss_std": 8.729108834935126, "train/model_opt_grad_norm": 32.08241148084124, "train/model_opt_grad_steps": 142088.06542056074, "train/model_opt_loss": 5735.037303318487, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1676.4018691588785, "train/policy_entropy_mag": 2.640734282609458, "train/policy_entropy_max": 2.640734282609458, "train/policy_entropy_mean": 0.5107644378581894, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6416371063651326, "train/policy_logprob_mag": 7.438384114024795, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.51118890328385, "train/policy_logprob_min": -7.438384114024795, "train/policy_logprob_std": 1.102793692428375, "train/policy_randomness_mag": 0.932063315237794, "train/policy_randomness_max": 0.932063315237794, "train/policy_randomness_mean": 0.18027743195818963, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.2264697414553054, "train/post_ent_mag": 47.505091907822084, "train/post_ent_max": 47.505091907822084, "train/post_ent_mean": 28.215498229053534, "train/post_ent_min": 13.858431735885478, "train/post_ent_std": 4.785585683082866, "train/prior_ent_mag": 76.22765418079412, "train/prior_ent_max": 76.22765418079412, "train/prior_ent_mean": 31.211166372923092, "train/prior_ent_min": 15.611497518058135, "train/prior_ent_std": 8.715622683551825, "train/rep_loss_mean": 3.091588102768515, "train/rep_loss_std": 7.8532705151032065, "train/reward_avg": 0.020353704562549976, "train/reward_loss_mean": 0.07169652221915877, "train/reward_loss_std": 0.15400434337625993, "train/reward_max_data": 1.0073247964137069, "train/reward_max_pred": 1.008320816209383, "train/reward_neg_acc": 0.9991895979809984, "train/reward_neg_loss": 0.050811917877921435, "train/reward_pos_acc": 0.9408988005647035, "train/reward_pos_loss": 0.7126395242793537, "train/reward_pred": 0.02025439925317731, "train/reward_rate": 0.031560309579439255, "train_stats/sum_log_reward": 4.792307596940261, "train_stats/max_log_achievement_collect_drink": 2.6153846153846154, "train_stats/max_log_achievement_collect_sapling": 2.769230769230769, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 4.923076923076923, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.07692307692307693, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.07692307692307693, "train_stats/max_log_achievement_place_plant": 2.5384615384615383, "train_stats/max_log_achievement_place_table": 2.0, "train_stats/max_log_achievement_wake_up": 1.8461538461538463, "train_stats/mean_log_entropy": 0.4127045159156506, "report/cont_avg": 0.9912109375, "report/cont_loss_mean": 2.844785285560647e-06, "report/cont_loss_std": 2.5453531634411775e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 4.9552782002137974e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.430625727356528e-06, "report/cont_pred": 0.9912089705467224, "report/cont_rate": 0.9912109375, "report/dyn_loss_mean": 2.855478286743164, "report/dyn_loss_std": 7.821244716644287, "report/image_loss_mean": 1.5896327495574951, "report/image_loss_std": 4.211638450622559, "report/model_loss_mean": 3.3803133964538574, "report/model_loss_std": 8.053720474243164, "report/post_ent_mag": 49.46025466918945, "report/post_ent_max": 49.46025466918945, "report/post_ent_mean": 27.86817169189453, "report/post_ent_min": 13.200626373291016, "report/post_ent_std": 5.406548976898193, "report/prior_ent_mag": 76.22395324707031, "report/prior_ent_max": 76.22395324707031, "report/prior_ent_mean": 30.698278427124023, "report/prior_ent_min": 13.407184600830078, "report/prior_ent_std": 9.284553527832031, "report/rep_loss_mean": 2.855478286743164, "report/rep_loss_std": 7.821244716644287, "report/reward_avg": 0.021424710750579834, "report/reward_loss_mean": 0.07739102840423584, "report/reward_loss_std": 0.14255361258983612, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0024311542510986, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.054419711232185364, "report/reward_pos_acc": 0.9473684430122375, "report/reward_pos_loss": 0.6734364032745361, "report/reward_pred": 0.02149822562932968, "report/reward_rate": 0.037109375, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 8.08550976216793e-06, "eval/cont_loss_std": 0.00020694301929324865, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0022179260849952698, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.5923449154797709e-06, "eval/cont_pred": 0.9970752000808716, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 22.19016456604004, "eval/dyn_loss_std": 13.416024208068848, "eval/image_loss_mean": 32.19891357421875, "eval/image_loss_std": 34.09962844848633, "eval/model_loss_mean": 45.63821029663086, "eval/model_loss_std": 39.77264404296875, "eval/post_ent_mag": 49.46025466918945, "eval/post_ent_max": 49.46025466918945, "eval/post_ent_mean": 30.873821258544922, "eval/post_ent_min": 16.315258026123047, "eval/post_ent_std": 3.8994107246398926, "eval/prior_ent_mag": 76.22395324707031, "eval/prior_ent_max": 76.22395324707031, "eval/prior_ent_mean": 40.794654846191406, "eval/prior_ent_min": 18.74992561340332, "eval/prior_ent_std": 8.07600212097168, "eval/rep_loss_mean": 22.19016456604004, "eval/rep_loss_std": 13.416024208068848, "eval/reward_avg": 0.02353515475988388, "eval/reward_loss_mean": 0.12519153952598572, "eval/reward_loss_std": 0.8611631989479065, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.003023386001587, "eval/reward_neg_acc": 0.9909729361534119, "eval/reward_neg_loss": 0.05902509763836861, "eval/reward_pos_acc": 0.7777777910232544, "eval/reward_pos_loss": 2.568448305130005, "eval/reward_pred": 0.023026462644338608, "eval/reward_rate": 0.0263671875, "replay/size": 144330.0, "replay/inserts": 2144.0, "replay/samples": 34304.0, "replay/insert_wait_avg": 2.6931068790492725e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.929725211058089e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 28888.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 7.599592208862305e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4084753990173, "timer/env.step_count": 268.0, "timer/env.step_total": 27.239556789398193, "timer/env.step_frac": 0.027228434643692494, "timer/env.step_avg": 0.10164013727387386, "timer/env.step_min": 0.024323463439941406, "timer/env.step_max": 3.4037978649139404, "timer/replay._sample_count": 34304.0, "timer/replay._sample_total": 16.565468788146973, "timer/replay._sample_frac": 0.016558704964529377, "timer/replay._sample_avg": 0.00048290195860969487, "timer/replay._sample_min": 0.00034546852111816406, "timer/replay._sample_max": 0.010805368423461914, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 268.0, "timer/agent.policy_total": 4.211097717285156, "timer/agent.policy_frac": 0.004209378289808612, "timer/agent.policy_avg": 0.015713051183899835, "timer/agent.policy_min": 0.01441502571105957, "timer/agent.policy_max": 0.030675888061523438, "timer/dataset_train_count": 2144.0, "timer/dataset_train_total": 0.43148279190063477, "timer/dataset_train_frac": 0.00043130661375948053, "timer/dataset_train_avg": 0.00020125130219246024, "timer/dataset_train_min": 8.893013000488281e-05, "timer/dataset_train_max": 0.03466057777404785, "timer/agent.train_count": 2144.0, "timer/agent.train_total": 957.0814571380615, "timer/agent.train_frac": 0.9566906725338621, "timer/agent.train_avg": 0.4463999333666332, "timer/agent.train_min": 0.42101502418518066, "timer/agent.train_max": 0.7237207889556885, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47599053382873535, "timer/agent.report_frac": 0.000475796182793118, "timer/agent.report_avg": 0.23799526691436768, "timer/agent.report_min": 0.22864294052124023, "timer/agent.report_max": 0.24734759330749512, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7418136596679688e-05, "timer/dataset_eval_frac": 2.7406941535300212e-08, "timer/dataset_eval_avg": 2.7418136596679688e-05, "timer/dataset_eval_min": 2.7418136596679688e-05, "timer/dataset_eval_max": 2.7418136596679688e-05, "fps": 2.143095544337728}
{"step": 144848, "time": 67343.11598181725, "episode/length": 133.0, "episode/score": 5.229240311236481, "episode/reward_rate": 0.9925373134328358, "episode/intrinsic_return": 0.12924020861055396}
{"step": 144888, "time": 67362.85492897034, "episode/length": 220.0, "episode/score": 5.319678765345088, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.2196786139120377}
{"step": 145376, "time": 67588.72546625137, "episode/length": 212.0, "episode/score": 4.324971963503685, "episode/reward_rate": 0.9812206572769953, "episode/intrinsic_return": 0.224971779241514}
{"step": 145536, "time": 67664.11597800255, "episode/length": 156.0, "episode/score": 5.258942016101173, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.1589419113506665}
{"step": 145904, "time": 67834.98128819466, "episode/length": 193.0, "episode/score": 5.289595634959369, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.18959550691124605}
{"step": 145920, "time": 67843.81304645538, "episode/length": 197.0, "episode/score": 6.298558267576027, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.19855812111973137}
{"step": 145968, "time": 67867.35467600822, "episode/length": 145.0, "episode/score": 4.2597106839989465, "episode/reward_rate": 0.9657534246575342, "episode/intrinsic_return": 0.1597105333808031}
{"step": 146080, "time": 67920.39731144905, "episode/length": 202.0, "episode/score": 4.310010849781975, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.21001067486213287}
{"step": 146264, "time": 68006.4593873024, "episode/length": 176.0, "episode/score": 4.272087854212259, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.17208774573646224}
{"step": 146560, "time": 68144.28997707367, "episode/length": 208.0, "episode/score": 4.307705361141416, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.2077053217581124}
{"step": 146824, "time": 68267.4032664299, "episode/length": 160.0, "episode/score": 5.285975988745577, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.18597588035709123}
{"step": 146970, "time": 68336.54218888283, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.910574084130403, "train/action_min": 0.0, "train/action_std": 3.956931121995516, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04274049682420827, "train/actor_opt_grad_steps": 144345.0, "train/actor_opt_loss": -14.429975307015615, "train/adv_mag": 0.7877382601254455, "train/adv_max": 0.7206495096471822, "train/adv_mean": 0.0022185686358876136, "train/adv_min": -0.5791535413014555, "train/adv_std": 0.05382201879798809, "train/cont_avg": 0.9944463712032711, "train/cont_loss_mean": 7.58193462503605e-05, "train/cont_loss_std": 0.0023663923323619346, "train/cont_neg_acc": 0.9985536275623, "train/cont_neg_loss": 0.0110553165214127, "train/cont_pos_acc": 0.9999953878817157, "train/cont_pos_loss": 6.8475426099262135e-06, "train/cont_pred": 0.9944521957468764, "train/cont_rate": 0.9944463712032711, "train/dyn_loss_mean": 3.1370857073881915, "train/dyn_loss_std": 7.841218464842466, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0322303212134638, "train/extr_critic_critic_opt_grad_steps": 144345.0, "train/extr_critic_critic_opt_loss": 15015.851138106016, "train/extr_critic_mag": 11.704609821890003, "train/extr_critic_max": 11.704609821890003, "train/extr_critic_mean": 2.076273383381211, "train/extr_critic_min": -0.6639999023107724, "train/extr_critic_std": 2.11455296300282, "train/extr_return_normed_mag": 1.858400062422886, "train/extr_return_normed_max": 1.858400062422886, "train/extr_return_normed_mean": 0.35682545741584815, "train/extr_return_normed_min": -0.12981145350245116, "train/extr_return_normed_std": 0.3336885120963382, "train/extr_return_rate": 0.7288177587161554, "train/extr_return_raw_mag": 11.786017792247167, "train/extr_return_raw_max": 11.786017792247167, "train/extr_return_raw_mean": 2.0905450861030648, "train/extr_return_raw_min": -1.046534744935615, "train/extr_return_raw_std": 2.152876624994189, "train/extr_reward_mag": 1.0133825373426777, "train/extr_reward_max": 1.0133825373426777, "train/extr_reward_mean": 0.03430695436616367, "train/extr_reward_min": -0.6845079899948334, "train/extr_reward_std": 0.18214160301417948, "train/image_loss_mean": 1.6544428155801008, "train/image_loss_std": 5.470651670594082, "train/model_loss_mean": 3.6089013001629127, "train/model_loss_std": 9.26057606099922, "train/model_opt_grad_norm": 34.20367142418834, "train/model_opt_grad_steps": 144226.3551401869, "train/model_opt_loss": 5293.069572092217, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1471.96261682243, "train/policy_entropy_mag": 2.6400831258185558, "train/policy_entropy_max": 2.6400831258185558, "train/policy_entropy_mean": 0.49158861885003957, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.623903918071328, "train/policy_logprob_mag": 7.438384122937639, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.4911880532157755, "train/policy_logprob_min": -7.438384122937639, "train/policy_logprob_std": 1.0888598655985895, "train/policy_randomness_mag": 0.931833483348383, "train/policy_randomness_max": 0.931833483348383, "train/policy_randomness_mean": 0.1735092101740503, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.22021070331613593, "train/post_ent_mag": 47.767338547751166, "train/post_ent_max": 47.767338547751166, "train/post_ent_mean": 28.462052416578633, "train/post_ent_min": 13.51444164169169, "train/post_ent_std": 4.952383788946633, "train/prior_ent_mag": 76.2255207667841, "train/prior_ent_max": 76.2255207667841, "train/prior_ent_mean": 31.505065017771496, "train/prior_ent_min": 15.134887984979933, "train/prior_ent_std": 8.752189778835975, "train/rep_loss_mean": 3.1370857073881915, "train/rep_loss_std": 7.841218464842466, "train/reward_avg": 0.02081627890937657, "train/reward_loss_mean": 0.07213124594538012, "train/reward_loss_std": 0.1602228283882141, "train/reward_max_data": 1.0045210574274865, "train/reward_max_pred": 1.0057399930240951, "train/reward_neg_acc": 0.9992256476500324, "train/reward_neg_loss": 0.05067157586949451, "train/reward_pos_acc": 0.9379605561773353, "train/reward_pos_loss": 0.7212088007793248, "train/reward_pred": 0.020682093733051254, "train/reward_rate": 0.03203946407710281, "train_stats/sum_log_reward": 4.736363540996205, "train_stats/max_log_achievement_collect_drink": 4.545454545454546, "train_stats/max_log_achievement_collect_sapling": 1.6363636363636365, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 3.8181818181818183, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.09090909090909091, "train_stats/max_log_achievement_make_wood_sword": 0.18181818181818182, "train_stats/max_log_achievement_place_plant": 1.5454545454545454, "train_stats/max_log_achievement_place_table": 1.4545454545454546, "train_stats/max_log_achievement_wake_up": 2.090909090909091, "train_stats/mean_log_entropy": 0.49774381247433747, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 3.7663068042093073e-07, "report/cont_loss_std": 3.6086216823605355e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 4.8073139623738825e-05, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 1.8958553482661955e-07, "report/cont_pred": 0.99609375, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 3.147152900695801, "report/dyn_loss_std": 7.64793586730957, "report/image_loss_mean": 1.3761773109436035, "report/image_loss_std": 4.948662757873535, "report/model_loss_mean": 3.3358654975891113, "report/model_loss_std": 8.824555397033691, "report/post_ent_mag": 48.729278564453125, "report/post_ent_max": 48.729278564453125, "report/post_ent_mean": 29.613422393798828, "report/post_ent_min": 18.42888641357422, "report/post_ent_std": 4.094915866851807, "report/prior_ent_mag": 75.87340545654297, "report/prior_ent_max": 75.87340545654297, "report/prior_ent_mean": 32.93708038330078, "report/prior_ent_min": 21.53504753112793, "report/prior_ent_std": 7.940885543823242, "report/rep_loss_mean": 3.147152900695801, "report/rep_loss_std": 7.64793586730957, "report/reward_avg": 0.029808800667524338, "report/reward_loss_mean": 0.07139623165130615, "report/reward_loss_std": 0.15093694627285004, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0030174255371094, "report/reward_neg_acc": 0.9979715943336487, "report/reward_neg_loss": 0.048125702887773514, "report/reward_pos_acc": 0.9210526347160339, "report/reward_pos_loss": 0.675205409526825, "report/reward_pred": 0.030243251472711563, "report/reward_rate": 0.037109375, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 5.179470917937579e-06, "eval/cont_loss_std": 0.00015482482558581978, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 6.221792864380404e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 5.011874236515723e-06, "eval/cont_pred": 0.997065544128418, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 22.971149444580078, "eval/dyn_loss_std": 13.978254318237305, "eval/image_loss_mean": 32.14604568481445, "eval/image_loss_std": 41.4515380859375, "eval/model_loss_mean": 46.05349349975586, "eval/model_loss_std": 47.197723388671875, "eval/post_ent_mag": 48.729278564453125, "eval/post_ent_max": 48.729278564453125, "eval/post_ent_mean": 31.280357360839844, "eval/post_ent_min": 16.775344848632812, "eval/post_ent_std": 4.052680492401123, "eval/prior_ent_mag": 75.87340545654297, "eval/prior_ent_max": 75.87340545654297, "eval/prior_ent_mean": 42.389869689941406, "eval/prior_ent_min": 20.46334457397461, "eval/prior_ent_std": 7.5573883056640625, "eval/rep_loss_mean": 22.971149444580078, "eval/rep_loss_std": 13.978254318237305, "eval/reward_avg": 0.01767578162252903, "eval/reward_loss_mean": 0.12475478649139404, "eval/reward_loss_std": 0.772163987159729, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.002427339553833, "eval/reward_neg_acc": 0.9920239448547363, "eval/reward_neg_loss": 0.07101418077945709, "eval/reward_pos_acc": 0.761904776096344, "eval/reward_pos_loss": 2.6915078163146973, "eval/reward_pred": 0.015901511535048485, "eval/reward_rate": 0.0205078125, "replay/size": 146466.0, "replay/inserts": 2136.0, "replay/samples": 34176.0, "replay/insert_wait_avg": 2.6737259568346574e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.989910546313511e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 28888.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 7.748603820800781e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0051851272583, "timer/env.step_count": 267.0, "timer/env.step_total": 24.150257110595703, "timer/env.step_frac": 0.024150131889088555, "timer/env.step_avg": 0.09045040116327979, "timer/env.step_min": 0.02395915985107422, "timer/env.step_max": 1.723339319229126, "timer/replay._sample_count": 34176.0, "timer/replay._sample_total": 17.398250102996826, "timer/replay._sample_frac": 0.01739815989132373, "timer/replay._sample_avg": 0.0005090780109725195, "timer/replay._sample_min": 0.0003693103790283203, "timer/replay._sample_max": 0.34496450424194336, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 267.0, "timer/agent.policy_total": 4.342965364456177, "timer/agent.policy_frac": 0.004342942845744846, "timer/agent.policy_avg": 0.01626578788185834, "timer/agent.policy_min": 0.014654874801635742, "timer/agent.policy_max": 0.038546085357666016, "timer/dataset_train_count": 2136.0, "timer/dataset_train_total": 0.40967750549316406, "timer/dataset_train_frac": 0.00040967538127417756, "timer/dataset_train_avg": 0.00019179658496870977, "timer/dataset_train_min": 9.107589721679688e-05, "timer/dataset_train_max": 0.0008826255798339844, "timer/agent.train_count": 2136.0, "timer/agent.train_total": 959.3375308513641, "timer/agent.train_frac": 0.9593325565899752, "timer/agent.train_avg": 0.4491280575146836, "timer/agent.train_min": 0.4336113929748535, "timer/agent.train_max": 0.9148626327514648, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4797675609588623, "timer/agent.report_frac": 0.0004797650733159031, "timer/agent.report_avg": 0.23988378047943115, "timer/agent.report_min": 0.23270082473754883, "timer/agent.report_max": 0.24706673622131348, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7418136596679688e-05, "timer/dataset_eval_frac": 2.7417994430889395e-08, "timer/dataset_eval_avg": 2.7418136596679688e-05, "timer/dataset_eval_min": 2.7418136596679688e-05, "timer/dataset_eval_max": 2.7418136596679688e-05, "fps": 2.1359597023422228}
{"step": 147304, "time": 68490.31779313087, "episode/length": 174.0, "episode/score": 5.257901190635039, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.15790102899563863}
{"step": 147384, "time": 68528.71588683128, "episode/length": 182.0, "episode/score": 4.290320827920368, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.19032066496220068}
{"step": 147456, "time": 68564.38811469078, "episode/length": 259.0, "episode/score": 5.360379885743441, "episode/reward_rate": 0.9846153846153847, "episode/intrinsic_return": 0.2603799605635686}
{"step": 147520, "time": 68595.27908444405, "episode/length": 179.0, "episode/score": 5.2928319935922445, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.19283178534851686}
{"step": 147592, "time": 68629.81715583801, "episode/length": 165.0, "episode/score": 4.27695582342858, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.17695570063369814}
{"step": 147680, "time": 68671.68630695343, "episode/length": 213.0, "episode/score": 3.336190043701663, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.236189998235659}
{"step": 147944, "time": 68794.21994185448, "episode/length": 172.0, "episode/score": 4.280187195279723, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.18018698086598306}
{"step": 148712, "time": 69148.47971105576, "episode/length": 235.0, "episode/score": 3.3608780080321594, "episode/reward_rate": 0.9788135593220338, "episode/intrinsic_return": 0.2608779138754471}
{"step": 148720, "time": 69153.70539617538, "episode/length": 166.0, "episode/score": 3.254495193847106, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.1544950707029784}
{"step": 149016, "time": 69290.99991607666, "episode/length": 177.0, "episode/score": 5.296760534387431, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.19676026933302637}
{"step": 149040, "time": 69303.58391737938, "episode/length": 197.0, "episode/score": 5.292058818444275, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.19205859576504736}
{"step": 149108, "time": 69336.8838186264, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.04307792556118, "train/action_min": 0.0, "train/action_std": 4.148534337119877, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04250375510241504, "train/actor_opt_grad_steps": 146480.0, "train/actor_opt_loss": -17.984428961791902, "train/adv_mag": 0.6484748747706973, "train/adv_max": 0.5852310387461398, "train/adv_mean": 0.00128563055818311, "train/adv_min": -0.5134669688525894, "train/adv_std": 0.051750776371066, "train/cont_avg": 0.994424882629108, "train/cont_loss_mean": 8.8941483015083e-06, "train/cont_loss_std": 0.00025965939414885204, "train/cont_neg_acc": 1.0, "train/cont_neg_loss": 0.0005125587614402919, "train/cont_pos_acc": 0.9999953676277483, "train/cont_pos_loss": 6.337774411095734e-06, "train/cont_pred": 0.9944221444532905, "train/cont_rate": 0.994424882629108, "train/dyn_loss_mean": 3.106377743779214, "train/dyn_loss_std": 7.8090780508909985, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9717717324624039, "train/extr_critic_critic_opt_grad_steps": 146480.0, "train/extr_critic_critic_opt_loss": 14704.081265588322, "train/extr_critic_mag": 9.746221260285713, "train/extr_critic_max": 9.746221260285713, "train/extr_critic_mean": 2.0235185416091777, "train/extr_critic_min": -0.654982630075983, "train/extr_critic_std": 2.091489035198946, "train/extr_return_normed_mag": 1.6152785994077512, "train/extr_return_normed_max": 1.6152785994077512, "train/extr_return_normed_mean": 0.35279693779811055, "train/extr_return_normed_min": -0.12334505592783292, "train/extr_return_normed_std": 0.335071517967842, "train/extr_return_rate": 0.6835201248316698, "train/extr_return_raw_mag": 10.030295488420228, "train/extr_return_raw_max": 10.030295488420228, "train/extr_return_raw_mean": 2.031651298764726, "train/extr_return_raw_min": -0.9861039396183032, "train/extr_return_raw_std": 2.1239513097234735, "train/extr_reward_mag": 1.0146931370659054, "train/extr_reward_max": 1.0146931370659054, "train/extr_reward_mean": 0.03263470461425927, "train/extr_reward_min": -0.6754428394523585, "train/extr_reward_std": 0.17791681516338403, "train/image_loss_mean": 1.5738765166399065, "train/image_loss_std": 4.764307812345979, "train/model_loss_mean": 3.5092034037684052, "train/model_loss_std": 8.563497653029893, "train/model_opt_grad_norm": 28.912467495376514, "train/model_opt_grad_steps": 146359.86384976527, "train/model_opt_loss": 7123.657243755501, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2024.6478873239437, "train/policy_entropy_mag": 2.618900629276401, "train/policy_entropy_max": 2.618900629276401, "train/policy_entropy_mean": 0.5133799429230846, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6389156521206171, "train/policy_logprob_mag": 7.438384107580767, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5129061442025951, "train/policy_logprob_min": -7.438384107580767, "train/policy_logprob_std": 1.100324230294832, "train/policy_randomness_mag": 0.924356995054254, "train/policy_randomness_max": 0.924356995054254, "train/policy_randomness_mean": 0.18120059035193753, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.22550918735528777, "train/post_ent_mag": 48.17310523091348, "train/post_ent_max": 48.17310523091348, "train/post_ent_mean": 28.683374395952537, "train/post_ent_min": 13.797368649585707, "train/post_ent_std": 4.9695804678778135, "train/prior_ent_mag": 76.2525151570638, "train/prior_ent_max": 76.2525151570638, "train/prior_ent_mean": 31.696849214079233, "train/prior_ent_min": 15.479997943824445, "train/prior_ent_std": 8.727119291332405, "train/rep_loss_mean": 3.106377743779214, "train/rep_loss_std": 7.8090780508909985, "train/reward_avg": 0.019896896256509942, "train/reward_loss_mean": 0.07149135010063368, "train/reward_loss_std": 0.15437358103587595, "train/reward_max_data": 1.005475381730308, "train/reward_max_pred": 1.0065123631920614, "train/reward_neg_acc": 0.9993419546476552, "train/reward_neg_loss": 0.05079338543921569, "train/reward_pos_acc": 0.9321803604493119, "train/reward_pos_loss": 0.7146850387815019, "train/reward_pred": 0.019744444583835598, "train/reward_rate": 0.03118581279342723, "train_stats/sum_log_reward": 4.281818129799583, "train_stats/max_log_achievement_collect_drink": 3.6363636363636362, "train_stats/max_log_achievement_collect_sapling": 2.6363636363636362, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 3.090909090909091, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 2.5454545454545454, "train_stats/max_log_achievement_place_table": 1.4545454545454546, "train_stats/max_log_achievement_wake_up": 2.3636363636363638, "train_stats/mean_log_entropy": 0.516753844239495, "report/cont_avg": 0.990234375, "report/cont_loss_mean": 4.467991061574139e-07, "report/cont_loss_std": 1.7984203850573977e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 1.6499347111675888e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.884899856780976e-07, "report/cont_pred": 0.990234375, "report/cont_rate": 0.990234375, "report/dyn_loss_mean": 3.0969185829162598, "report/dyn_loss_std": 7.809753894805908, "report/image_loss_mean": 1.6954569816589355, "report/image_loss_std": 5.19279146194458, "report/model_loss_mean": 3.634890556335449, "report/model_loss_std": 8.958945274353027, "report/post_ent_mag": 49.93221664428711, "report/post_ent_max": 49.93221664428711, "report/post_ent_mean": 29.400362014770508, "report/post_ent_min": 14.841451644897461, "report/post_ent_std": 4.539060115814209, "report/prior_ent_mag": 76.08426666259766, "report/prior_ent_max": 76.08426666259766, "report/prior_ent_mean": 32.45746612548828, "report/prior_ent_min": 15.665139198303223, "report/prior_ent_std": 8.958647727966309, "report/rep_loss_mean": 3.0969185829162598, "report/rep_loss_std": 7.809753894805908, "report/reward_avg": 0.02306731417775154, "report/reward_loss_mean": 0.08128178119659424, "report/reward_loss_std": 0.18432797491550446, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0078041553497314, "report/reward_neg_acc": 1.0000001192092896, "report/reward_neg_loss": 0.05649019032716751, "report/reward_pos_acc": 0.949999988079071, "report/reward_pos_loss": 0.6911550164222717, "report/reward_pred": 0.023339582607150078, "report/reward_rate": 0.0390625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.01128007099032402, "eval/cont_loss_std": 0.3606637120246887, "eval/cont_neg_acc": 0.75, "eval/cont_neg_loss": 2.8876266479492188, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 2.8330583745628246e-07, "eval/cont_pred": 0.9970736503601074, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 23.15499496459961, "eval/dyn_loss_std": 13.8817720413208, "eval/image_loss_mean": 40.24231719970703, "eval/image_loss_std": 47.67271041870117, "eval/model_loss_mean": 54.29510498046875, "eval/model_loss_std": 53.200660705566406, "eval/post_ent_mag": 49.93221664428711, "eval/post_ent_max": 49.93221664428711, "eval/post_ent_mean": 30.79342269897461, "eval/post_ent_min": 16.20378875732422, "eval/post_ent_std": 4.6258039474487305, "eval/prior_ent_mag": 76.08426666259766, "eval/prior_ent_max": 76.08426666259766, "eval/prior_ent_mean": 40.81013107299805, "eval/prior_ent_min": 15.098520278930664, "eval/prior_ent_std": 9.04595947265625, "eval/rep_loss_mean": 23.15499496459961, "eval/rep_loss_std": 13.8817720413208, "eval/reward_avg": 0.01796874962747097, "eval/reward_loss_mean": 0.1485150158405304, "eval/reward_loss_std": 0.9737735986709595, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.002159595489502, "eval/reward_neg_acc": 0.9930139780044556, "eval/reward_neg_loss": 0.06760136783123016, "eval/reward_pos_acc": 0.6363636255264282, "eval/reward_pos_loss": 3.833763837814331, "eval/reward_pred": 0.013692745938897133, "eval/reward_rate": 0.021484375, "replay/size": 148604.0, "replay/inserts": 2138.0, "replay/samples": 34208.0, "replay/insert_wait_avg": 2.5409755581890564e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.9912878398699e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 28888.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 9.685754776000977e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3284182548523, "timer/env.step_count": 267.0, "timer/env.step_total": 24.173972606658936, "timer/env.step_frac": 0.02416603603927622, "timer/env.step_avg": 0.09053922324591361, "timer/env.step_min": 0.024536848068237305, "timer/env.step_max": 1.6348388195037842, "timer/replay._sample_count": 34208.0, "timer/replay._sample_total": 17.09480881690979, "timer/replay._sample_frac": 0.017089196412847056, "timer/replay._sample_avg": 0.0004997313148067642, "timer/replay._sample_min": 0.0003643035888671875, "timer/replay._sample_max": 0.014015913009643555, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 267.0, "timer/agent.policy_total": 4.307073593139648, "timer/agent.policy_frac": 0.004305659535948864, "timer/agent.policy_avg": 0.01613136177205861, "timer/agent.policy_min": 0.014844655990600586, "timer/agent.policy_max": 0.023613691329956055, "timer/dataset_train_count": 2138.0, "timer/dataset_train_total": 0.4212782382965088, "timer/dataset_train_frac": 0.0004211399282562223, "timer/dataset_train_avg": 0.00019704314232764676, "timer/dataset_train_min": 9.250640869140625e-05, "timer/dataset_train_max": 0.007487773895263672, "timer/agent.train_count": 2138.0, "timer/agent.train_total": 959.4383080005646, "timer/agent.train_frac": 0.9591233143954627, "timer/agent.train_avg": 0.44875505519203207, "timer/agent.train_min": 0.436948299407959, "timer/agent.train_max": 0.6886529922485352, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4763782024383545, "timer/agent.report_frac": 0.00047622180250505317, "timer/agent.report_avg": 0.23818910121917725, "timer/agent.report_min": 0.23088335990905762, "timer/agent.report_max": 0.24549484252929688, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.075599670410156e-05, "timer/dataset_eval_frac": 3.074589918954587e-08, "timer/dataset_eval_avg": 3.075599670410156e-05, "timer/dataset_eval_min": 3.075599670410156e-05, "timer/dataset_eval_max": 3.075599670410156e-05, "fps": 2.1372694115593855}
{"step": 149272, "time": 69412.43830943108, "episode/length": 218.0, "episode/score": 5.351949439074815, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.25194923083108733}
{"step": 149336, "time": 69443.33005952835, "episode/length": 173.0, "episode/score": 5.2514208291377145, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.1514206398405804}
{"step": 149536, "time": 69536.87583637238, "episode/length": 278.0, "episode/score": 5.4070280185223965, "episode/reward_rate": 0.996415770609319, "episode/intrinsic_return": 0.3070278195918945}
{"step": 149576, "time": 69556.88694405556, "episode/length": 236.0, "episode/score": 4.315822311655211, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.21582211014901986}
{"step": 150056, "time": 69778.78975629807, "episode/length": 167.0, "episode/score": 5.265499229521993, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.16549911767469894}
{"step": 150072, "time": 69806.82964515686, "eval_episode/length": 142.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.972027972027972}
{"step": 150072, "time": 69808.97923398018, "eval_episode/length": 157.0, "eval_episode/score": 5.0999999940395355, "eval_episode/reward_rate": 0.9936708860759493}
{"step": 150072, "time": 69810.56987094879, "eval_episode/length": 159.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.99375}
{"step": 150072, "time": 69812.70748138428, "eval_episode/length": 172.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9710982658959537}
{"step": 150072, "time": 69814.87503647804, "eval_episode/length": 187.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9946808510638298}
{"step": 150072, "time": 69816.7015068531, "eval_episode/length": 195.0, "eval_episode/score": 5.0999999940395355, "eval_episode/reward_rate": 0.9948979591836735}
{"step": 150072, "time": 69819.02928757668, "eval_episode/length": 212.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9624413145539906}
{"step": 150072, "time": 69823.47176933289, "eval_episode/length": 274.0, "eval_episode/score": 6.099999979138374, "eval_episode/reward_rate": 0.9963636363636363}
{"step": 150376, "time": 69962.52959728241, "episode/length": 166.0, "episode/score": 5.281436811628737, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.18143667719232326}
{"step": 150664, "time": 70096.41831064224, "episode/length": 173.0, "episode/score": 6.27980102967922, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.17980084925875417}
{"step": 150680, "time": 70105.24995088577, "episode/length": 142.0, "episode/score": 5.244164438661755, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.14416425320632698}
{"step": 150752, "time": 70139.82034397125, "episode/length": 176.0, "episode/score": 5.258293604680148, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.15829345752536028}
{"step": 150776, "time": 70152.48056554794, "episode/length": 149.0, "episode/score": 4.2562624126312585, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.15626225852065545}
{"step": 150920, "time": 70220.13801503181, "episode/length": 237.0, "episode/score": 5.3530233298215535, "episode/reward_rate": 0.9789915966386554, "episode/intrinsic_return": 0.2530231482369345}
{"step": 151000, "time": 70258.26896929741, "episode/length": 284.0, "episode/score": 3.4232435947997146, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.3232435064637684}
{"step": 151167, "time": 70336.9570980072, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.932065797083586, "train/action_min": 0.0, "train/action_std": 4.03115476566611, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04313890890950717, "train/actor_opt_grad_steps": 148575.0, "train/actor_opt_loss": -16.597156267432332, "train/adv_mag": 0.6181488505844931, "train/adv_max": 0.5507664398371594, "train/adv_mean": 0.0021599008297873068, "train/adv_min": -0.4921882035373484, "train/adv_std": 0.05297614547234137, "train/cont_avg": 0.9942022527305825, "train/cont_loss_mean": 3.3373290941940957e-05, "train/cont_loss_std": 0.0010349223120053655, "train/cont_neg_acc": 0.9987864077669902, "train/cont_neg_loss": 0.0016052179939480674, "train/cont_pos_acc": 0.999990453997862, "train/cont_pos_loss": 2.6062110460614602e-05, "train/cont_pred": 0.9941974915925739, "train/cont_rate": 0.9942022527305825, "train/dyn_loss_mean": 3.16569981297243, "train/dyn_loss_std": 7.885253605333347, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.988042509092868, "train/extr_critic_critic_opt_grad_steps": 148575.0, "train/extr_critic_critic_opt_loss": 15120.216711544295, "train/extr_critic_mag": 9.127418231038215, "train/extr_critic_max": 9.127418231038215, "train/extr_critic_mean": 1.9957918455299821, "train/extr_critic_min": -0.6731792318010793, "train/extr_critic_std": 2.0206751453066336, "train/extr_return_normed_mag": 1.5588535382909683, "train/extr_return_normed_max": 1.5588535382909683, "train/extr_return_normed_mean": 0.3500812248263544, "train/extr_return_normed_min": -0.1311041092120328, "train/extr_return_normed_std": 0.32718685052348573, "train/extr_return_rate": 0.6800800567691766, "train/extr_return_raw_mag": 9.600693667976602, "train/extr_return_raw_max": 9.600693667976602, "train/extr_return_raw_mean": 2.0093449024320806, "train/extr_return_raw_min": -1.0149491385927478, "train/extr_return_raw_std": 2.0571682464729233, "train/extr_reward_mag": 1.0159192675525703, "train/extr_reward_max": 1.0159192675525703, "train/extr_reward_mean": 0.03550582986722872, "train/extr_reward_min": -0.6877904933633157, "train/extr_reward_std": 0.185227937851716, "train/image_loss_mean": 1.5947732219418276, "train/image_loss_std": 4.900002685565393, "train/model_loss_mean": 3.566276094288502, "train/model_loss_std": 8.733216431534405, "train/model_opt_grad_norm": 30.550989350068917, "train/model_opt_grad_steps": 148453.08737864078, "train/model_opt_loss": 6773.307748739002, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1893.2038834951456, "train/policy_entropy_mag": 2.6085755350520308, "train/policy_entropy_max": 2.6085755350520308, "train/policy_entropy_mean": 0.5101721458932729, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6405728394256055, "train/policy_logprob_mag": 7.4383841301631, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5103454707027639, "train/policy_logprob_min": -7.4383841301631, "train/policy_logprob_std": 1.1003788891926551, "train/policy_randomness_mag": 0.9207126920663037, "train/policy_randomness_max": 0.9207126920663037, "train/policy_randomness_mean": 0.18006837906912693, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.22609410131151236, "train/post_ent_mag": 47.57601506501726, "train/post_ent_max": 47.57601506501726, "train/post_ent_mean": 28.925194212533896, "train/post_ent_min": 14.033756682016318, "train/post_ent_std": 4.80368216292372, "train/prior_ent_mag": 76.1918173484432, "train/prior_ent_max": 76.1918173484432, "train/prior_ent_mean": 31.978152710257223, "train/prior_ent_min": 15.905740548106072, "train/prior_ent_std": 8.644187860118533, "train/rep_loss_mean": 3.16569981297243, "train/rep_loss_std": 7.885253605333347, "train/reward_avg": 0.02075591625067071, "train/reward_loss_mean": 0.07204959490924205, "train/reward_loss_std": 0.15437452950813238, "train/reward_max_data": 1.0075607097264632, "train/reward_max_pred": 1.0085153718596522, "train/reward_neg_acc": 0.9993300119650017, "train/reward_neg_loss": 0.0510244491030869, "train/reward_pos_acc": 0.9352254971717168, "train/reward_pos_loss": 0.7108949419942875, "train/reward_pred": 0.02067268512989349, "train/reward_rate": 0.03187575849514563, "train_stats/sum_log_reward": 4.8499999443689985, "train_stats/max_log_achievement_collect_drink": 3.9166666666666665, "train_stats/max_log_achievement_collect_sapling": 1.6666666666666667, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 4.333333333333333, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.16666666666666666, "train_stats/max_log_achievement_place_plant": 1.4166666666666667, "train_stats/max_log_achievement_place_table": 1.5, "train_stats/max_log_achievement_wake_up": 1.9166666666666667, "train_stats/mean_log_entropy": 0.5617267166574796, "eval_stats/sum_log_reward": 4.975000023841858, "eval_stats/max_log_achievement_collect_drink": 3.25, "eval_stats/max_log_achievement_collect_sapling": 2.25, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 4.625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.125, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.0, "eval_stats/max_log_achievement_place_table": 2.0, "eval_stats/max_log_achievement_wake_up": 2.0, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 9.908569609251572e-07, "report/cont_loss_std": 1.741244523145724e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00014057934458833188, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.6813503123103146e-07, "report/cont_pred": 0.9941413402557373, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 3.929525375366211, "report/dyn_loss_std": 8.457088470458984, "report/image_loss_mean": 2.563708782196045, "report/image_loss_std": 4.803398609161377, "report/model_loss_mean": 4.992605209350586, "report/model_loss_std": 8.799922943115234, "report/post_ent_mag": 49.68611145019531, "report/post_ent_max": 49.68611145019531, "report/post_ent_mean": 28.740596771240234, "report/post_ent_min": 12.223701477050781, "report/post_ent_std": 5.801824569702148, "report/prior_ent_mag": 76.31953430175781, "report/prior_ent_max": 76.31953430175781, "report/prior_ent_mean": 32.618804931640625, "report/prior_ent_min": 13.530845642089844, "report/prior_ent_std": 9.828817367553711, "report/rep_loss_mean": 3.929525375366211, "report/rep_loss_std": 8.457088470458984, "report/reward_avg": 0.01239539310336113, "report/reward_loss_mean": 0.07117979228496552, "report/reward_loss_std": 0.14865367114543915, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.002432107925415, "report/reward_neg_acc": 0.9989979863166809, "report/reward_neg_loss": 0.052865371108055115, "report/reward_pos_acc": 0.7692307829856873, "report/reward_pos_loss": 0.7741720080375671, "report/reward_pred": 0.012263372540473938, "report/reward_rate": 0.025390625, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.008518015034496784, "eval/cont_loss_std": 0.26629704236984253, "eval/cont_neg_acc": 0.800000011920929, "eval/cont_neg_loss": 1.7441877126693726, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.482656898588175e-06, "eval/cont_pred": 0.9962674379348755, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 22.5638370513916, "eval/dyn_loss_std": 13.080443382263184, "eval/image_loss_mean": 35.26887512207031, "eval/image_loss_std": 36.895172119140625, "eval/model_loss_mean": 48.934608459472656, "eval/model_loss_std": 42.3341064453125, "eval/post_ent_mag": 50.19761657714844, "eval/post_ent_max": 50.19761657714844, "eval/post_ent_mean": 31.962167739868164, "eval/post_ent_min": 18.992630004882812, "eval/post_ent_std": 3.8177695274353027, "eval/prior_ent_mag": 76.31953430175781, "eval/prior_ent_max": 76.31953430175781, "eval/prior_ent_mean": 43.09587860107422, "eval/prior_ent_min": 25.887630462646484, "eval/prior_ent_std": 7.003222465515137, "eval/rep_loss_mean": 22.5638370513916, "eval/rep_loss_std": 13.080443382263184, "eval/reward_avg": 0.02314453199505806, "eval/reward_loss_mean": 0.11891305446624756, "eval/reward_loss_std": 0.7135842442512512, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 1.001835584640503, "eval/reward_neg_acc": 0.9899699091911316, "eval/reward_neg_loss": 0.07121648639440536, "eval/reward_pos_acc": 0.8518518805503845, "eval/reward_pos_loss": 1.880152940750122, "eval/reward_pred": 0.023337800055742264, "eval/reward_rate": 0.0263671875, "replay/size": 150663.0, "replay/inserts": 2059.0, "replay/samples": 32944.0, "replay/insert_wait_avg": 2.564244504227344e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.025205268507852e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 31088.0, "eval_replay/inserts": 2200.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1898170817982066e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.152557373046875e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0575022697449, "timer/env.step_count": 257.0, "timer/env.step_total": 25.759196758270264, "timer/env.step_frac": 0.02575771563115803, "timer/env.step_avg": 0.10023033758081815, "timer/env.step_min": 0.02398991584777832, "timer/env.step_max": 1.713829755783081, "timer/replay._sample_count": 32944.0, "timer/replay._sample_total": 16.430410146713257, "timer/replay._sample_frac": 0.01642946541516119, "timer/replay._sample_avg": 0.0004987375590915874, "timer/replay._sample_min": 0.0003542900085449219, "timer/replay._sample_max": 0.020254850387573242, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 532.0, "timer/agent.policy_total": 8.902442216873169, "timer/agent.policy_frac": 0.008901930335673757, "timer/agent.policy_avg": 0.01673391394149092, "timer/agent.policy_min": 0.00991368293762207, "timer/agent.policy_max": 0.04196810722351074, "timer/dataset_train_count": 2059.0, "timer/dataset_train_total": 0.40338802337646484, "timer/dataset_train_frac": 0.0004033648289832631, "timer/dataset_train_avg": 0.000195914532965743, "timer/dataset_train_min": 9.584426879882812e-05, "timer/dataset_train_max": 0.0008602142333984375, "timer/agent.train_count": 2059.0, "timer/agent.train_total": 922.4224650859833, "timer/agent.train_frac": 0.9223694267504019, "timer/agent.train_avg": 0.4479953691529788, "timer/agent.train_min": 0.4350755214691162, "timer/agent.train_max": 0.5859599113464355, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47447967529296875, "timer/agent.report_frac": 0.0004744523932034737, "timer/agent.report_avg": 0.23723983764648438, "timer/agent.report_min": 0.2302083969116211, "timer/agent.report_max": 0.24427127838134766, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.409385681152344e-05, "timer/dataset_eval_frac": 3.409189645009765e-08, "timer/dataset_eval_avg": 3.409385681152344e-05, "timer/dataset_eval_min": 3.409385681152344e-05, "timer/dataset_eval_max": 3.409385681152344e-05, "fps": 2.058853765219403}
{"step": 151352, "time": 70421.94084501266, "episode/length": 161.0, "episode/score": 3.271516884765333, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.17151677477613703}
{"step": 151784, "time": 70621.76064157486, "episode/length": 175.0, "episode/score": 4.2694189489520795, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.1694189088375424}
{"step": 151840, "time": 70649.02687263489, "episode/length": 146.0, "episode/score": 4.25755781290718, "episode/reward_rate": 0.9659863945578231, "episode/intrinsic_return": 0.15755778784296126}
{"step": 152040, "time": 70742.39274549484, "episode/length": 160.0, "episode/score": 4.260580422244857, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.16058039322251716}
{"step": 152088, "time": 70766.17283082008, "episode/length": 175.0, "episode/score": 5.290169840804083, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.19016966154777037}
{"step": 152328, "time": 70877.81380724907, "episode/length": 35.0, "episode/score": 2.137560931065309, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.037560764093541366}
{"step": 152496, "time": 70956.3283162117, "episode/length": 214.0, "episode/score": 5.332041528526133, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.23204143893872242}
{"step": 152680, "time": 71042.4175772667, "episode/length": 165.0, "episode/score": 3.2645624975921237, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.1645623369331588}
{"step": 152696, "time": 71051.3477628231, "episode/length": 221.0, "episode/score": 5.3325464904201, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.23254634131535568}
{"step": 152728, "time": 71067.60684227943, "episode/length": 215.0, "episode/score": 6.340001162358021, "episode/reward_rate": 0.9907407407407407, "episode/intrinsic_return": 0.2400009942775796}
{"step": 153048, "time": 71215.74810004234, "episode/length": 157.0, "episode/score": 5.260678993111014, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.16067894959496698}
{"step": 153240, "time": 71305.3691380024, "episode/length": 174.0, "episode/score": 5.2894261844494395, "episode/reward_rate": 0.9885714285714285, "episode/intrinsic_return": 0.18942600682294142}
{"step": 153305, "time": 71337.232380867, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.025369234174211, "train/action_min": 0.0, "train/action_std": 4.12674005900588, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04527683402890357, "train/actor_opt_grad_steps": 150675.0, "train/actor_opt_loss": -14.169625584036112, "train/adv_mag": 0.740589506297468, "train/adv_max": 0.6939493871737863, "train/adv_mean": 0.0024186091404602016, "train/adv_min": -0.5458589752561578, "train/adv_std": 0.054387273005793026, "train/cont_avg": 0.994405300817757, "train/cont_loss_mean": 4.0911906963428725e-05, "train/cont_loss_std": 0.001258696661352853, "train/cont_neg_acc": 0.9988317757009346, "train/cont_neg_loss": 0.009408370161258334, "train/cont_pos_acc": 0.9999999813387327, "train/cont_pos_loss": 4.309701804283798e-06, "train/cont_pred": 0.9944072106731272, "train/cont_rate": 0.994405300817757, "train/dyn_loss_mean": 3.107690173888875, "train/dyn_loss_std": 7.86837148889203, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9854832464289442, "train/extr_critic_critic_opt_grad_steps": 150675.0, "train/extr_critic_critic_opt_loss": 15045.939772561333, "train/extr_critic_mag": 10.856562322545274, "train/extr_critic_max": 10.856562322545274, "train/extr_critic_mean": 2.0765364688133525, "train/extr_critic_min": -0.671466841318897, "train/extr_critic_std": 2.080656422632877, "train/extr_return_normed_mag": 1.7779173188120405, "train/extr_return_normed_max": 1.7779173188120405, "train/extr_return_normed_mean": 0.36018213163190915, "train/extr_return_normed_min": -0.1334524033330033, "train/extr_return_normed_std": 0.33307589096165147, "train/extr_return_rate": 0.6964226560057881, "train/extr_return_raw_mag": 11.11714947780716, "train/extr_return_raw_max": 11.11714947780716, "train/extr_return_raw_mean": 2.091891718244998, "train/extr_return_raw_min": -1.0493381340927053, "train/extr_return_raw_std": 2.1198689530943042, "train/extr_reward_mag": 1.021139735373381, "train/extr_reward_max": 1.021139735373381, "train/extr_reward_mean": 0.035152753928206236, "train/extr_reward_min": -0.6947165967148041, "train/extr_reward_std": 0.18389694754765412, "train/image_loss_mean": 1.5196632455999606, "train/image_loss_std": 4.880447064604715, "train/model_loss_mean": 3.456010098769286, "train/model_loss_std": 8.726524992523906, "train/model_opt_grad_norm": 31.71147879484658, "train/model_opt_grad_steps": 150551.51401869158, "train/model_opt_loss": 6698.963036653037, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1927.5700934579438, "train/policy_entropy_mag": 2.647590319686961, "train/policy_entropy_max": 2.647590319686961, "train/policy_entropy_mean": 0.5095800275557509, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6441803141453556, "train/policy_logprob_mag": 7.438384105111951, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5086466351123614, "train/policy_logprob_min": -7.438384105111951, "train/policy_logprob_std": 1.0998501150964577, "train/policy_randomness_mag": 0.9344831969693442, "train/policy_randomness_max": 0.9344831969693442, "train/policy_randomness_mean": 0.17985938680923988, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.2273673811387793, "train/post_ent_mag": 47.50481550270152, "train/post_ent_max": 47.50481550270152, "train/post_ent_mean": 28.903342924385427, "train/post_ent_min": 13.528375460722737, "train/post_ent_std": 4.875561591620757, "train/prior_ent_mag": 76.26894118407063, "train/prior_ent_max": 76.26894118407063, "train/prior_ent_mean": 31.917190542844967, "train/prior_ent_min": 15.156244616642176, "train/prior_ent_std": 8.654909579553337, "train/rep_loss_mean": 3.107690173888875, "train/rep_loss_std": 7.86837148889203, "train/reward_avg": 0.02052218181290011, "train/reward_loss_mean": 0.07169184382900456, "train/reward_loss_std": 0.15839979393738451, "train/reward_max_data": 1.0096612455688905, "train/reward_max_pred": 1.0100904625152873, "train/reward_neg_acc": 0.9992178555960968, "train/reward_neg_loss": 0.050733785449622947, "train/reward_pos_acc": 0.9365016990732924, "train/reward_pos_loss": 0.7144755899349106, "train/reward_pred": 0.020391991235768406, "train/reward_rate": 0.0315876898364486, "train_stats/sum_log_reward": 4.3499999443689985, "train_stats/max_log_achievement_collect_drink": 1.5833333333333333, "train_stats/max_log_achievement_collect_sapling": 1.5, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 4.916666666666667, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.16666666666666666, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.08333333333333333, "train_stats/max_log_achievement_place_plant": 1.4166666666666667, "train_stats/max_log_achievement_place_table": 1.9166666666666667, "train_stats/max_log_achievement_wake_up": 2.25, "train_stats/mean_log_entropy": 0.4124404713511467, "report/cont_avg": 0.9912109375, "report/cont_loss_mean": 1.1863004374390584e-06, "report/cont_loss_std": 3.03474189422559e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 2.1150617612875067e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.009277070807002e-06, "report/cont_pred": 0.9912100434303284, "report/cont_rate": 0.9912109375, "report/dyn_loss_mean": 3.437681198120117, "report/dyn_loss_std": 7.817837715148926, "report/image_loss_mean": 2.1097068786621094, "report/image_loss_std": 7.142624378204346, "report/model_loss_mean": 4.246265411376953, "report/model_loss_std": 10.553096771240234, "report/post_ent_mag": 53.561119079589844, "report/post_ent_max": 53.561119079589844, "report/post_ent_mean": 29.452598571777344, "report/post_ent_min": 11.519622802734375, "report/post_ent_std": 5.805795669555664, "report/prior_ent_mag": 76.04707336425781, "report/prior_ent_max": 76.04707336425781, "report/prior_ent_mean": 33.210487365722656, "report/prior_ent_min": 13.703328132629395, "report/prior_ent_std": 9.70161247253418, "report/rep_loss_mean": 3.437681198120117, "report/rep_loss_std": 7.817837715148926, "report/reward_avg": 0.012797903269529343, "report/reward_loss_mean": 0.07394909858703613, "report/reward_loss_std": 0.14809547364711761, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.003554105758667, "report/reward_neg_acc": 0.9989979863166809, "report/reward_neg_loss": 0.057902656495571136, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.689885675907135, "report/reward_pred": 0.01274071354418993, "report/reward_rate": 0.025390625, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.005291256122291088, "eval/cont_loss_std": 0.169002503156662, "eval/cont_neg_acc": 0.8333333730697632, "eval/cont_neg_loss": 0.9027687311172485, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.604877638783364e-06, "eval/cont_pred": 0.9951169490814209, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 19.4674015045166, "eval/dyn_loss_std": 13.028339385986328, "eval/image_loss_mean": 22.490795135498047, "eval/image_loss_std": 35.424644470214844, "eval/model_loss_mean": 34.36750793457031, "eval/model_loss_std": 39.99214172363281, "eval/post_ent_mag": 53.79587936401367, "eval/post_ent_max": 53.79587936401367, "eval/post_ent_mean": 32.04747772216797, "eval/post_ent_min": 17.250844955444336, "eval/post_ent_std": 4.3939995765686035, "eval/prior_ent_mag": 76.04707336425781, "eval/prior_ent_max": 76.04707336425781, "eval/prior_ent_mean": 41.25543975830078, "eval/prior_ent_min": 18.306705474853516, "eval/prior_ent_std": 7.784151554107666, "eval/rep_loss_mean": 19.4674015045166, "eval/rep_loss_std": 13.028339385986328, "eval/reward_avg": 0.015429687686264515, "eval/reward_loss_mean": 0.1909787803888321, "eval/reward_loss_std": 1.1977672576904297, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0035295486450195, "eval/reward_neg_acc": 0.9940179586410522, "eval/reward_neg_loss": 0.14644835889339447, "eval/reward_pos_acc": 0.761904776096344, "eval/reward_pos_loss": 2.3178369998931885, "eval/reward_pred": 0.01532677374780178, "eval/reward_rate": 0.0205078125, "replay/size": 152801.0, "replay/inserts": 2138.0, "replay/samples": 34208.0, "replay/insert_wait_avg": 2.6933047345467434e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.886603349162888e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 31088.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 8.493661880493164e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.260479927063, "timer/env.step_count": 268.0, "timer/env.step_total": 25.780200481414795, "timer/env.step_frac": 0.02577348700539947, "timer/env.step_avg": 0.09619477791572685, "timer/env.step_min": 0.023964643478393555, "timer/env.step_max": 1.722771406173706, "timer/replay._sample_count": 34208.0, "timer/replay._sample_total": 17.105639696121216, "timer/replay._sample_frac": 0.017101185180652668, "timer/replay._sample_avg": 0.0005000479331186043, "timer/replay._sample_min": 0.0003325939178466797, "timer/replay._sample_max": 0.029066801071166992, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 268.0, "timer/agent.policy_total": 4.332814693450928, "timer/agent.policy_frac": 0.0043316863760996215, "timer/agent.policy_avg": 0.01616721900541391, "timer/agent.policy_min": 0.014943838119506836, "timer/agent.policy_max": 0.03643083572387695, "timer/dataset_train_count": 2138.0, "timer/dataset_train_total": 0.42574191093444824, "timer/dataset_train_frac": 0.00042563104259151825, "timer/dataset_train_avg": 0.00019913092185895614, "timer/dataset_train_min": 9.846687316894531e-05, "timer/dataset_train_max": 0.0007054805755615234, "timer/agent.train_count": 2138.0, "timer/agent.train_total": 957.8674337863922, "timer/agent.train_frac": 0.9576179935212856, "timer/agent.train_avg": 0.4480203151479851, "timer/agent.train_min": 0.43682265281677246, "timer/agent.train_max": 0.5770251750946045, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4774436950683594, "timer/agent.report_frac": 0.000477319362955511, "timer/agent.report_avg": 0.2387218475341797, "timer/agent.report_min": 0.23149442672729492, "timer/agent.report_max": 0.24594926834106445, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.86102294921875e-05, "timer/dataset_eval_frac": 2.860277904238874e-08, "timer/dataset_eval_avg": 2.86102294921875e-05, "timer/dataset_eval_min": 2.86102294921875e-05, "timer/dataset_eval_max": 2.86102294921875e-05, "fps": 2.1374090466853732}
{"step": 153616, "time": 71480.54231381416, "episode/length": 160.0, "episode/score": 5.243867212808254, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.14386709720201907}
{"step": 153784, "time": 71559.29811930656, "episode/length": 211.0, "episode/score": 6.31576291732199, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.21576271908998024}
{"step": 153928, "time": 71627.32051801682, "episode/length": 155.0, "episode/score": 5.2559395061443865, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.1559392677490905}
{"step": 154240, "time": 71772.60537338257, "episode/length": 192.0, "episode/score": 5.265133227133447, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.165133002082257}
{"step": 154280, "time": 71792.66099333763, "episode/length": 193.0, "episode/score": 7.302183204850735, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.20218299730549916}
{"step": 154376, "time": 71838.22198033333, "episode/length": 165.0, "episode/score": 5.26911530146117, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.16911507738495857}
{"step": 154392, "time": 71847.2001824379, "episode/length": 236.0, "episode/score": 5.329600192293583, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.22959996762074297}
{"step": 154472, "time": 71885.7613954544, "episode/length": 153.0, "episode/score": 5.276672193846025, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.1766720424129744}
{"step": 154584, "time": 71938.76129364967, "episode/length": 37.0, "episode/score": 2.1353055616418715, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.035305409161082935}
{"step": 154832, "time": 72054.2801322937, "episode/length": 151.0, "episode/score": 4.258262410253337, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.1582622593441556}
{"step": 155240, "time": 72242.3387002945, "episode/length": 163.0, "episode/score": 1.2639200745652488, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.16392003768487484}
{"step": 155444, "time": 72337.59762406349, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.051750682224737, "train/action_min": 0.0, "train/action_std": 4.1903483622542055, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04943890906174049, "train/actor_opt_grad_steps": 152815.0, "train/actor_opt_loss": -15.753176996014385, "train/adv_mag": 0.8772345805001036, "train/adv_max": 0.8078608386148917, "train/adv_mean": 0.0023369141555700038, "train/adv_min": -0.6203989948485499, "train/adv_std": 0.05916684082596101, "train/cont_avg": 0.9942683995327103, "train/cont_loss_mean": 2.762083687165376e-05, "train/cont_loss_std": 0.0007987905798119891, "train/cont_neg_acc": 0.9993324435759927, "train/cont_neg_loss": 0.0013301403040008426, "train/cont_pos_acc": 0.9999908103007022, "train/cont_pos_loss": 1.8753104351326244e-05, "train/cont_pred": 0.994259582780232, "train/cont_rate": 0.9942683995327103, "train/dyn_loss_mean": 3.116814704698937, "train/dyn_loss_std": 7.863785095303972, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9932709425409264, "train/extr_critic_critic_opt_grad_steps": 152815.0, "train/extr_critic_critic_opt_loss": 15200.711991639895, "train/extr_critic_mag": 12.397718665755798, "train/extr_critic_max": 12.397718665755798, "train/extr_critic_mean": 2.087142595620913, "train/extr_critic_min": -0.6436997117283189, "train/extr_critic_std": 2.10315009143865, "train/extr_return_normed_mag": 1.9786604587162766, "train/extr_return_normed_max": 1.9786604587162766, "train/extr_return_normed_mean": 0.35655474488701777, "train/extr_return_normed_min": -0.12245958754531691, "train/extr_return_normed_std": 0.33717141822676794, "train/extr_return_rate": 0.6848724435701549, "train/extr_return_raw_mag": 12.455706926149743, "train/extr_return_raw_max": 12.455706926149743, "train/extr_return_raw_mean": 2.102064956571454, "train/extr_return_raw_min": -0.9513075747222544, "train/extr_return_raw_std": 2.1500977127351493, "train/extr_reward_mag": 1.0213688244329435, "train/extr_reward_max": 1.0213688244329435, "train/extr_reward_mean": 0.033768695944519804, "train/extr_reward_min": -0.6890121648244769, "train/extr_reward_std": 0.179948056830424, "train/image_loss_mean": 1.5260733485778915, "train/image_loss_std": 4.752354008015071, "train/model_loss_mean": 3.46799445820746, "train/model_loss_std": 8.603743083009096, "train/model_opt_grad_norm": 30.164234985815032, "train/model_opt_grad_steps": 152690.29906542055, "train/model_opt_loss": 6649.235969899971, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1915.8878504672898, "train/policy_entropy_mag": 2.636966990533276, "train/policy_entropy_max": 2.636966990533276, "train/policy_entropy_mean": 0.508861062264888, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6356555446286067, "train/policy_logprob_mag": 7.438384129622272, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.508283424182473, "train/policy_logprob_min": -7.438384129622272, "train/policy_logprob_std": 1.096219567773498, "train/policy_randomness_mag": 0.9307336258554013, "train/policy_randomness_max": 0.9307336258554013, "train/policy_randomness_mean": 0.17960562497795185, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.22435851422982794, "train/post_ent_mag": 47.92685621029863, "train/post_ent_max": 47.92685621029863, "train/post_ent_mean": 29.11067788846025, "train/post_ent_min": 13.782484264017265, "train/post_ent_std": 4.88328997554066, "train/prior_ent_mag": 76.3604342023903, "train/prior_ent_max": 76.3604342023903, "train/prior_ent_mean": 32.131289446465324, "train/prior_ent_min": 15.578254944810244, "train/prior_ent_std": 8.67625683490361, "train/rep_loss_mean": 3.116814704698937, "train/rep_loss_std": 7.863785095303972, "train/reward_avg": 0.020683648604377408, "train/reward_loss_mean": 0.07180467352410343, "train/reward_loss_std": 0.15532723640170054, "train/reward_max_data": 1.0115304048930374, "train/reward_max_pred": 1.012074703368071, "train/reward_neg_acc": 0.9992225440306084, "train/reward_neg_loss": 0.05058113419424708, "train/reward_pos_acc": 0.9401426053492823, "train/reward_pos_loss": 0.7169577587987775, "train/reward_pred": 0.020492094351309484, "train/reward_rate": 0.031820422021028034, "train_stats/sum_log_reward": 4.645454460924322, "train_stats/max_log_achievement_collect_drink": 2.6363636363636362, "train_stats/max_log_achievement_collect_sapling": 1.6363636363636365, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 4.0, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.09090909090909091, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.18181818181818182, "train_stats/max_log_achievement_place_plant": 1.5454545454545454, "train_stats/max_log_achievement_place_table": 1.4545454545454546, "train_stats/max_log_achievement_wake_up": 1.7272727272727273, "train_stats/mean_log_entropy": 0.4461591297929937, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 1.0272586905557546e-06, "report/cont_loss_std": 1.055304551300651e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 4.693519713327987e-06, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.0092692264151992e-06, "report/cont_pred": 0.9951161742210388, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 2.8610105514526367, "report/dyn_loss_std": 8.291865348815918, "report/image_loss_mean": 1.4947962760925293, "report/image_loss_std": 3.536684036254883, "report/model_loss_mean": 3.280642509460449, "report/model_loss_std": 7.930731296539307, "report/post_ent_mag": 43.78980255126953, "report/post_ent_max": 43.78980255126953, "report/post_ent_mean": 26.30449676513672, "report/post_ent_min": 10.895991325378418, "report/post_ent_std": 5.3101911544799805, "report/prior_ent_mag": 76.38278198242188, "report/prior_ent_max": 76.38278198242188, "report/prior_ent_mean": 29.086246490478516, "report/prior_ent_min": 13.416101455688477, "report/prior_ent_std": 9.013853073120117, "report/rep_loss_mean": 2.8610105514526367, "report/rep_loss_std": 8.291865348815918, "report/reward_avg": 0.01602287031710148, "report/reward_loss_mean": 0.06923863291740417, "report/reward_loss_std": 0.1927076280117035, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0017688274383545, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.050283823162317276, "report/reward_pos_acc": 0.9166666865348816, "report/reward_pos_loss": 0.8590223789215088, "report/reward_pred": 0.015110904350876808, "report/reward_rate": 0.0234375, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.0032638355623930693, "eval/cont_loss_std": 0.10352616757154465, "eval/cont_neg_acc": 0.75, "eval/cont_neg_loss": 0.8352915644645691, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 9.817968020797707e-07, "eval/cont_pred": 0.9970595836639404, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 24.175989151000977, "eval/dyn_loss_std": 12.838592529296875, "eval/image_loss_mean": 29.934667587280273, "eval/image_loss_std": 29.188541412353516, "eval/model_loss_mean": 44.58027648925781, "eval/model_loss_std": 34.394195556640625, "eval/post_ent_mag": 42.792667388916016, "eval/post_ent_max": 42.792667388916016, "eval/post_ent_mean": 31.190073013305664, "eval/post_ent_min": 13.256427764892578, "eval/post_ent_std": 4.013351917266846, "eval/prior_ent_mag": 76.38278198242188, "eval/prior_ent_max": 76.38278198242188, "eval/prior_ent_mean": 43.046409606933594, "eval/prior_ent_min": 14.950304985046387, "eval/prior_ent_std": 7.9619035720825195, "eval/rep_loss_mean": 24.175989151000977, "eval/rep_loss_std": 12.838592529296875, "eval/reward_avg": 0.01884765550494194, "eval/reward_loss_mean": 0.13675178587436676, "eval/reward_loss_std": 0.8638483285903931, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0006451606750488, "eval/reward_neg_acc": 0.9930069446563721, "eval/reward_neg_loss": 0.06566757708787918, "eval/reward_pos_acc": 0.6521739363670349, "eval/reward_pos_loss": 3.230459451675415, "eval/reward_pred": 0.01459601428359747, "eval/reward_rate": 0.0224609375, "replay/size": 154940.0, "replay/inserts": 2139.0, "replay/samples": 34224.0, "replay/insert_wait_avg": 2.549819268596234e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.897963753477777e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 31088.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 8.195638656616211e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3489258289337, "timer/env.step_count": 267.0, "timer/env.step_total": 24.93655776977539, "timer/env.step_frac": 0.024927859795632657, "timer/env.step_avg": 0.09339534745234229, "timer/env.step_min": 0.023993492126464844, "timer/env.step_max": 1.7267100811004639, "timer/replay._sample_count": 34224.0, "timer/replay._sample_total": 16.91403841972351, "timer/replay._sample_frac": 0.016908138733400233, "timer/replay._sample_avg": 0.0004942157088512013, "timer/replay._sample_min": 0.0003376007080078125, "timer/replay._sample_max": 0.014643430709838867, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 267.0, "timer/agent.policy_total": 4.2725584506988525, "timer/agent.policy_frac": 0.004271068164699052, "timer/agent.policy_avg": 0.016002091575651134, "timer/agent.policy_min": 0.014569759368896484, "timer/agent.policy_max": 0.022687673568725586, "timer/dataset_train_count": 2139.0, "timer/dataset_train_total": 0.46163296699523926, "timer/dataset_train_frac": 0.0004614719475134235, "timer/dataset_train_avg": 0.0002158171888710796, "timer/dataset_train_min": 9.918212890625e-05, "timer/dataset_train_max": 0.03684377670288086, "timer/agent.train_count": 2139.0, "timer/agent.train_total": 958.9813952445984, "timer/agent.train_frac": 0.9586468985808563, "timer/agent.train_avg": 0.44833164808069115, "timer/agent.train_min": 0.43570947647094727, "timer/agent.train_max": 0.6102070808410645, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4759087562561035, "timer/agent.report_frac": 0.00047574275732014635, "timer/agent.report_avg": 0.23795437812805176, "timer/agent.report_min": 0.23230361938476562, "timer/agent.report_max": 0.2436051368713379, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.695487976074219e-05, "timer/dataset_eval_frac": 3.6941989746347485e-08, "timer/dataset_eval_avg": 3.695487976074219e-05, "timer/dataset_eval_min": 3.695487976074219e-05, "timer/dataset_eval_max": 3.695487976074219e-05, "fps": 2.1382225422501953}
{"step": 155600, "time": 72409.08988308907, "episode/length": 226.0, "episode/score": 5.34416238931226, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.24416217595262424}
{"step": 155760, "time": 72484.46910214424, "episode/length": 189.0, "episode/score": 4.29322677764867, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.19322659804311115}
{"step": 155792, "time": 72500.64019584656, "episode/length": 150.0, "episode/score": 6.264227445994038, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.1642273236066103}
{"step": 155792, "time": 72500.6482887268, "episode/length": 176.0, "episode/score": 4.313083499320783, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.21308332902844995}
{"step": 155864, "time": 72536.7481315136, "episode/length": 183.0, "episode/score": 5.308022878634802, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.20802265071688453}
{"step": 156032, "time": 72614.61144757271, "episode/length": 194.0, "episode/score": 5.297944876612746, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.19794472750800196}
{"step": 156136, "time": 72663.53896212578, "episode/length": 162.0, "episode/score": 5.250093091442977, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.15009304419163527}
{"step": 156240, "time": 72712.33956837654, "episode/length": 79.0, "episode/score": 3.195500120113138, "episode/reward_rate": 0.9375, "episode/intrinsic_return": 0.0954999981331639}
{"step": 156400, "time": 72786.73701786995, "episode/length": 144.0, "episode/score": 5.226076945860768, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.1260768113343147}
{"step": 157048, "time": 73082.78555822372, "episode/length": 156.0, "episode/score": 5.263781902320261, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.16378178185368597}
{"step": 157336, "time": 73215.06919622421, "episode/length": 136.0, "episode/score": 5.239942705269641, "episode/reward_rate": 0.9635036496350365, "episode/intrinsic_return": 0.13994259918035823}
{"step": 157480, "time": 73281.98216223717, "episode/length": 214.0, "episode/score": 4.3467959147619695, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.24679573515641096}
{"step": 157536, "time": 73309.01015329361, "episode/length": 174.0, "episode/score": 5.276587050448143, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.1765868688635237}
{"step": 157595, "time": 73338.03881192207, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.974345362463663, "train/action_min": 0.0, "train/action_std": 4.077031363997349, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04905576823755752, "train/actor_opt_grad_steps": 154960.0, "train/actor_opt_loss": -17.167623278429343, "train/adv_mag": 0.8166421069655307, "train/adv_max": 0.7497079601121504, "train/adv_mean": 0.002409058492007399, "train/adv_min": -0.6149019274600717, "train/adv_std": 0.058694610294214515, "train/cont_avg": 0.9942587209302326, "train/cont_loss_mean": 4.6394643441037136e-05, "train/cont_loss_std": 0.0013930859357287773, "train/cont_neg_acc": 0.9977408644764922, "train/cont_neg_loss": 0.00711174924992287, "train/cont_pos_acc": 0.9999999817027602, "train/cont_pos_loss": 6.282591766648693e-06, "train/cont_pred": 0.9942668252213057, "train/cont_rate": 0.9942587209302326, "train/dyn_loss_mean": 3.1288174340891284, "train/dyn_loss_std": 7.843597458684167, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.974740257374076, "train/extr_critic_critic_opt_grad_steps": 154960.0, "train/extr_critic_critic_opt_loss": 15048.399423146802, "train/extr_critic_mag": 11.53510506208553, "train/extr_critic_max": 11.53510506208553, "train/extr_critic_mean": 2.1154205028400863, "train/extr_critic_min": -0.6493515729904175, "train/extr_critic_std": 2.201576354891755, "train/extr_return_normed_mag": 1.8656323804411776, "train/extr_return_normed_max": 1.8656323804411776, "train/extr_return_normed_mean": 0.3628408814585486, "train/extr_return_normed_min": -0.12024186551570892, "train/extr_return_normed_std": 0.3516186688528504, "train/extr_return_rate": 0.6665307403996933, "train/extr_return_raw_mag": 11.735414185634879, "train/extr_return_raw_max": 11.735414185634879, "train/extr_return_raw_mean": 2.1307929271875428, "train/extr_return_raw_min": -0.9505699554155039, "train/extr_return_raw_std": 2.244092304207558, "train/extr_reward_mag": 1.0176955467046693, "train/extr_reward_max": 1.0176955467046693, "train/extr_reward_mean": 0.034647144749760626, "train/extr_reward_min": -0.6874547969463259, "train/extr_reward_std": 0.18199796558812606, "train/image_loss_mean": 1.5397185120471688, "train/image_loss_std": 4.887536163108293, "train/model_loss_mean": 3.4898320009542068, "train/model_loss_std": 8.70239377132682, "train/model_opt_grad_norm": 31.810833760830157, "train/model_opt_grad_steps": 154833.63720930234, "train/model_opt_loss": 6948.911379224201, "train/model_opt_model_opt_grad_overflow": 0.009302325581395349, "train/model_opt_model_opt_grad_scale": 1970.9302325581396, "train/policy_entropy_mag": 2.6569834065991778, "train/policy_entropy_max": 2.6569834065991778, "train/policy_entropy_mean": 0.5136815030907476, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6470994978450065, "train/policy_logprob_mag": 7.438384118191031, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5138294842354086, "train/policy_logprob_min": -7.438384118191031, "train/policy_logprob_std": 1.103735935133557, "train/policy_randomness_mag": 0.9377985455269038, "train/policy_randomness_max": 0.9377985455269038, "train/policy_randomness_mean": 0.18130702864985132, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.22839772479478704, "train/post_ent_mag": 48.2070584851642, "train/post_ent_max": 48.2070584851642, "train/post_ent_mean": 29.29909526026526, "train/post_ent_min": 14.07708318843398, "train/post_ent_std": 4.798117898231329, "train/prior_ent_mag": 76.28536742454351, "train/prior_ent_max": 76.28536742454351, "train/prior_ent_mean": 32.339643762278, "train/prior_ent_min": 15.760397290074549, "train/prior_ent_std": 8.596126811448919, "train/rep_loss_mean": 3.1288174340891284, "train/rep_loss_std": 7.843597458684167, "train/reward_avg": 0.021211199170021816, "train/reward_loss_mean": 0.07277661884246871, "train/reward_loss_std": 0.15888628644305605, "train/reward_max_data": 1.006831425289775, "train/reward_max_pred": 1.0079620095186455, "train/reward_neg_acc": 0.9992392631464226, "train/reward_neg_loss": 0.051281013928873596, "train/reward_pos_acc": 0.9289966026017832, "train/reward_pos_loss": 0.7108915500862654, "train/reward_pred": 0.021109017144975276, "train/reward_rate": 0.03253088662790698, "train_stats/sum_log_reward": 4.792307596940261, "train_stats/max_log_achievement_collect_drink": 3.6153846153846154, "train_stats/max_log_achievement_collect_sapling": 2.3846153846153846, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 3.230769230769231, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.07692307692307693, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.07692307692307693, "train_stats/max_log_achievement_place_plant": 2.1538461538461537, "train_stats/max_log_achievement_place_table": 1.0769230769230769, "train_stats/max_log_achievement_wake_up": 1.5384615384615385, "train_stats/mean_log_entropy": 0.44101187472160047, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 3.123147507722024e-06, "report/cont_loss_std": 7.290760095202131e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 5.6498931371606886e-05, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 2.7557621251617093e-06, "report/cont_pred": 0.9931617379188538, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 2.815361499786377, "report/dyn_loss_std": 7.953749179840088, "report/image_loss_mean": 1.3615463972091675, "report/image_loss_std": 4.250823020935059, "report/model_loss_mean": 3.117492198944092, "report/model_loss_std": 8.050738334655762, "report/post_ent_mag": 49.52973175048828, "report/post_ent_max": 49.52973175048828, "report/post_ent_mean": 27.753299713134766, "report/post_ent_min": 12.625032424926758, "report/post_ent_std": 5.437564373016357, "report/prior_ent_mag": 76.64822387695312, "report/prior_ent_max": 76.64822387695312, "report/prior_ent_mean": 30.61667251586914, "report/prior_ent_min": 13.324663162231445, "report/prior_ent_std": 9.172158241271973, "report/rep_loss_mean": 2.815361499786377, "report/rep_loss_std": 7.953749179840088, "report/reward_avg": 0.020235296338796616, "report/reward_loss_mean": 0.06672586500644684, "report/reward_loss_std": 0.13386176526546478, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0060150623321533, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.04784037917852402, "report/reward_pos_acc": 0.9655172228813171, "report/reward_pos_loss": 0.7146931290626526, "report/reward_pred": 0.020251616835594177, "report/reward_rate": 0.0283203125, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.00011882805119967088, "eval/cont_loss_std": 0.0036970144137740135, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.02370930276811123, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 3.0749986308364896e-06, "eval/cont_pred": 0.9952234029769897, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 23.727521896362305, "eval/dyn_loss_std": 13.353008270263672, "eval/image_loss_mean": 33.8167724609375, "eval/image_loss_std": 42.205467224121094, "eval/model_loss_mean": 48.212158203125, "eval/model_loss_std": 47.152400970458984, "eval/post_ent_mag": 45.92728042602539, "eval/post_ent_max": 45.92728042602539, "eval/post_ent_mean": 31.7072811126709, "eval/post_ent_min": 15.609086990356445, "eval/post_ent_std": 4.61332368850708, "eval/prior_ent_mag": 76.64822387695312, "eval/prior_ent_max": 76.64822387695312, "eval/prior_ent_mean": 43.143943786621094, "eval/prior_ent_min": 17.468862533569336, "eval/prior_ent_std": 8.350990295410156, "eval/rep_loss_mean": 23.727521896362305, "eval/rep_loss_std": 13.353008270263672, "eval/reward_avg": 0.01494140550494194, "eval/reward_loss_mean": 0.15874987840652466, "eval/reward_loss_std": 0.9683464169502258, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0018203258514404, "eval/reward_neg_acc": 0.9950199723243713, "eval/reward_neg_loss": 0.09968765825033188, "eval/reward_pos_acc": 0.75, "eval/reward_pos_loss": 3.123673439025879, "eval/reward_pred": 0.013503792695701122, "eval/reward_rate": 0.01953125, "replay/size": 157091.0, "replay/inserts": 2151.0, "replay/samples": 34416.0, "replay/insert_wait_avg": 2.6588493144994333e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.681683682663836e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 31088.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 8.195638656616211e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4283473491669, "timer/env.step_count": 269.0, "timer/env.step_total": 27.491256952285767, "timer/env.step_frac": 0.027479486187221003, "timer/env.step_avg": 0.10219798123526307, "timer/env.step_min": 0.02440810203552246, "timer/env.step_max": 3.2636516094207764, "timer/replay._sample_count": 34416.0, "timer/replay._sample_total": 16.609532594680786, "timer/replay._sample_frac": 0.016602420991659258, "timer/replay._sample_avg": 0.0004826107797152716, "timer/replay._sample_min": 0.0003452301025390625, "timer/replay._sample_max": 0.022652864456176758, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 269.0, "timer/agent.policy_total": 4.230550527572632, "timer/agent.policy_frac": 0.004228739158363829, "timer/agent.policy_avg": 0.015726953634099004, "timer/agent.policy_min": 0.014383792877197266, "timer/agent.policy_max": 0.03171944618225098, "timer/dataset_train_count": 2151.0, "timer/dataset_train_total": 0.4127471446990967, "timer/dataset_train_frac": 0.00041257042125280837, "timer/dataset_train_avg": 0.00019188616675922673, "timer/dataset_train_min": 9.489059448242188e-05, "timer/dataset_train_max": 0.0011110305786132812, "timer/agent.train_count": 2151.0, "timer/agent.train_total": 956.5296075344086, "timer/agent.train_frac": 0.9561200560429173, "timer/agent.train_avg": 0.44469065901181243, "timer/agent.train_min": 0.434154748916626, "timer/agent.train_max": 0.6420352458953857, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4767477512359619, "timer/agent.report_frac": 0.0004765436250374148, "timer/agent.report_avg": 0.23837387561798096, "timer/agent.report_min": 0.23224401473999023, "timer/agent.report_max": 0.24450373649597168, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0040740966796875e-05, "timer/dataset_eval_frac": 3.002787860459549e-08, "timer/dataset_eval_avg": 3.0040740966796875e-05, "timer/dataset_eval_min": 3.0040740966796875e-05, "timer/dataset_eval_max": 3.0040740966796875e-05, "fps": 2.150050440660482}
{"step": 157616, "time": 73347.84403562546, "episode/length": 218.0, "episode/score": 6.3320961204663035, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.2320959484859486}
{"step": 157632, "time": 73356.69992756844, "episode/length": 229.0, "episode/score": 3.3370735421376594, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.2370734155010723}
{"step": 157824, "time": 73446.27375745773, "episode/length": 223.0, "episode/score": 5.350213299193456, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.2502131528826794}
{"step": 157944, "time": 73502.9187078476, "episode/length": 192.0, "episode/score": 4.279711042534473, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.17971091857543797}
{"step": 158376, "time": 73703.66021728516, "episode/length": 53.0, "episode/score": 2.1535398275591433, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.05353976087644696}
{"step": 158448, "time": 73738.38454651833, "episode/length": 138.0, "episode/score": 5.243681823658335, "episode/reward_rate": 0.9712230215827338, "episode/intrinsic_return": 0.1436816409095627}
{"step": 158576, "time": 73798.5323972702, "episode/length": 190.0, "episode/score": 4.305777751718779, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.20577760110063537}
{"step": 158680, "time": 73848.22135400772, "episode/length": 149.0, "episode/score": 5.262967189511073, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.1629670307147535}
{"step": 158984, "time": 73989.42958545685, "episode/length": 168.0, "episode/score": 2.267442915510401, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.16744282216859574}
{"step": 159056, "time": 74024.11376810074, "episode/length": 189.0, "episode/score": 5.297107885146943, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.19710770356232388}
{"step": 159064, "time": 74029.43947410583, "episode/length": 154.0, "episode/score": 5.272657174892629, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.1726569666489013}
{"step": 159288, "time": 74133.4549279213, "episode/length": 208.0, "episode/score": 6.323220124781983, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.2232199231739287}
{"step": 159600, "time": 74277.9914033413, "episode/length": 152.0, "episode/score": 5.234169199588905, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.134169013034807}
{"step": 159727, "time": 74338.24399662018, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.979663257867518, "train/action_min": 0.0, "train/action_std": 4.173381749453119, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04588812139287521, "train/actor_opt_grad_steps": 157100.0, "train/actor_opt_loss": -14.898627214588469, "train/adv_mag": 0.7486064890180955, "train/adv_max": 0.6815205208012756, "train/adv_mean": 0.0025337788231386375, "train/adv_min": -0.5369417789116712, "train/adv_std": 0.054219850561988185, "train/cont_avg": 0.9943973738262911, "train/cont_loss_mean": 3.5438072608407603e-05, "train/cont_loss_std": 0.001092293026638793, "train/cont_neg_acc": 0.9987424550481805, "train/cont_neg_loss": 0.004363555793206444, "train/cont_pos_acc": 0.999999978172947, "train/cont_pos_loss": 2.6687927416379937e-06, "train/cont_pred": 0.9944036449065231, "train/cont_rate": 0.9943973738262911, "train/dyn_loss_mean": 3.1647612578432325, "train/dyn_loss_std": 7.887988218119447, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0166059830379037, "train/extr_critic_critic_opt_grad_steps": 157100.0, "train/extr_critic_critic_opt_loss": 15330.644104863557, "train/extr_critic_mag": 11.147409277902522, "train/extr_critic_max": 11.147409277902522, "train/extr_critic_mean": 2.0478653141030683, "train/extr_critic_min": -0.6723245555806048, "train/extr_critic_std": 2.1556351106491447, "train/extr_return_normed_mag": 1.7455001313921432, "train/extr_return_normed_max": 1.7455001313921432, "train/extr_return_normed_mean": 0.34048951280788636, "train/extr_return_normed_min": -0.12418432503134152, "train/extr_return_normed_std": 0.33054475521257787, "train/extr_return_rate": 0.6681014376347054, "train/extr_return_raw_mag": 11.398013336557737, "train/extr_return_raw_max": 11.398013336557737, "train/extr_return_raw_mean": 2.0646780152835755, "train/extr_return_raw_min": -1.0225855862030961, "train/extr_return_raw_std": 2.197036273602589, "train/extr_reward_mag": 1.021180297287417, "train/extr_reward_max": 1.021180297287417, "train/extr_reward_mean": 0.03553825479542985, "train/extr_reward_min": -0.674533508193325, "train/extr_reward_std": 0.1846149873005952, "train/image_loss_mean": 1.5639798031166685, "train/image_loss_std": 4.9893471444716475, "train/model_loss_mean": 3.5352647192601308, "train/model_loss_std": 8.810937420303272, "train/model_opt_grad_norm": 30.673767868901642, "train/model_opt_grad_steps": 156972.15023474177, "train/model_opt_loss": 9159.512544014084, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2593.8967136150236, "train/policy_entropy_mag": 2.64819116771501, "train/policy_entropy_max": 2.64819116771501, "train/policy_entropy_mean": 0.5117409478330837, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.641077416463637, "train/policy_logprob_mag": 7.438384112058111, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5113403797149658, "train/policy_logprob_min": -7.438384112058111, "train/policy_logprob_std": 1.099168596693048, "train/policy_randomness_mag": 0.9346952709793485, "train/policy_randomness_max": 0.9346952709793485, "train/policy_randomness_mean": 0.18062209799675874, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.22627219494799494, "train/post_ent_mag": 48.302151657605954, "train/post_ent_max": 48.302151657605954, "train/post_ent_mean": 29.369439711593127, "train/post_ent_min": 13.600812813485732, "train/post_ent_std": 4.908194961682172, "train/prior_ent_mag": 76.43556048612639, "train/prior_ent_max": 76.43556048612639, "train/prior_ent_mean": 32.440049319200114, "train/prior_ent_min": 15.556342957724988, "train/prior_ent_std": 8.6417755073225, "train/rep_loss_mean": 3.1647612578432325, "train/rep_loss_std": 7.887988218119447, "train/reward_avg": 0.02079795712403988, "train/reward_loss_mean": 0.07239273274448556, "train/reward_loss_std": 0.15471617496209525, "train/reward_max_data": 1.0097007348503866, "train/reward_max_pred": 1.0107056467745785, "train/reward_neg_acc": 0.9992420905632592, "train/reward_neg_loss": 0.051207180506606616, "train/reward_pos_acc": 0.9371616182752618, "train/reward_pos_loss": 0.7101694823990405, "train/reward_pred": 0.02069375582231742, "train/reward_rate": 0.03213945129107981, "train_stats/sum_log_reward": 4.484615307587844, "train_stats/max_log_achievement_collect_drink": 3.6923076923076925, "train_stats/max_log_achievement_collect_sapling": 1.6923076923076923, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 3.769230769230769, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.07692307692307693, "train_stats/max_log_achievement_make_wood_sword": 0.15384615384615385, "train_stats/max_log_achievement_place_plant": 1.5384615384615385, "train_stats/max_log_achievement_place_table": 1.4615384615384615, "train_stats/max_log_achievement_wake_up": 1.5384615384615385, "train_stats/mean_log_entropy": 0.5096838027238846, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 8.995078815132729e-07, "report/cont_loss_std": 6.504621069325367e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 5.3161827963776886e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 5.914785106142517e-07, "report/cont_pred": 0.9941403865814209, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 3.135115623474121, "report/dyn_loss_std": 8.072508811950684, "report/image_loss_mean": 1.341313362121582, "report/image_loss_std": 5.120964050292969, "report/model_loss_mean": 3.28767728805542, "report/model_loss_std": 9.064579010009766, "report/post_ent_mag": 44.321041107177734, "report/post_ent_max": 44.321041107177734, "report/post_ent_mean": 30.24795913696289, "report/post_ent_min": 15.757461547851562, "report/post_ent_std": 4.431731700897217, "report/prior_ent_mag": 76.39717864990234, "report/prior_ent_max": 76.39717864990234, "report/prior_ent_mean": 33.23286437988281, "report/prior_ent_min": 18.729320526123047, "report/prior_ent_std": 8.359021186828613, "report/rep_loss_mean": 3.135115623474121, "report/rep_loss_std": 8.072508811950684, "report/reward_avg": 0.016577746719121933, "report/reward_loss_mean": 0.06529367715120316, "report/reward_loss_std": 0.12925811111927032, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.001812219619751, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.04918309673666954, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7365678548812866, "report/reward_pred": 0.015678727999329567, "report/reward_rate": 0.0234375, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 1.9725299353012815e-05, "eval/cont_loss_std": 0.0005740757333114743, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0037592214066535234, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.3764490631729132e-06, "eval/cont_pred": 0.9951340556144714, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 23.767444610595703, "eval/dyn_loss_std": 14.055258750915527, "eval/image_loss_mean": 32.10629653930664, "eval/image_loss_std": 34.35746383666992, "eval/model_loss_mean": 46.549652099609375, "eval/model_loss_std": 39.479679107666016, "eval/post_ent_mag": 49.89598083496094, "eval/post_ent_max": 49.89598083496094, "eval/post_ent_mean": 30.897647857666016, "eval/post_ent_min": 14.593348503112793, "eval/post_ent_std": 4.905811309814453, "eval/prior_ent_mag": 76.39717864990234, "eval/prior_ent_max": 76.39717864990234, "eval/prior_ent_mean": 42.47936248779297, "eval/prior_ent_min": 13.841964721679688, "eval/prior_ent_std": 9.0625638961792, "eval/rep_loss_mean": 23.767444610595703, "eval/rep_loss_std": 14.055258750915527, "eval/reward_avg": 0.02871093899011612, "eval/reward_loss_mean": 0.18286791443824768, "eval/reward_loss_std": 1.0209929943084717, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0053153038024902, "eval/reward_neg_acc": 0.9949494004249573, "eval/reward_neg_loss": 0.10124842822551727, "eval/reward_pos_acc": 0.7647058963775635, "eval/reward_pos_loss": 2.5594351291656494, "eval/reward_pred": 0.024191712960600853, "eval/reward_rate": 0.033203125, "replay/size": 159223.0, "replay/inserts": 2132.0, "replay/samples": 34112.0, "replay/insert_wait_avg": 2.6146645393872575e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.024051645683303e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 31088.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 8.642673492431641e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.190936088562, "timer/env.step_count": 266.0, "timer/env.step_total": 27.080289363861084, "timer/env.step_frac": 0.027075119746399357, "timer/env.step_avg": 0.10180559911225971, "timer/env.step_min": 0.024422645568847656, "timer/env.step_max": 1.6763691902160645, "timer/replay._sample_count": 34112.0, "timer/replay._sample_total": 17.16315507888794, "timer/replay._sample_frac": 0.017159878638780452, "timer/replay._sample_avg": 0.0005031412722469494, "timer/replay._sample_min": 0.0003402233123779297, "timer/replay._sample_max": 0.04099845886230469, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 266.0, "timer/agent.policy_total": 4.309437036514282, "timer/agent.policy_frac": 0.004308614366540013, "timer/agent.policy_avg": 0.016200891114715347, "timer/agent.policy_min": 0.01500248908996582, "timer/agent.policy_max": 0.023650169372558594, "timer/dataset_train_count": 2132.0, "timer/dataset_train_total": 0.42595410346984863, "timer/dataset_train_frac": 0.0004258727889852948, "timer/dataset_train_avg": 0.0001997908552860453, "timer/dataset_train_min": 9.989738464355469e-05, "timer/dataset_train_max": 0.0008368492126464844, "timer/agent.train_count": 2132.0, "timer/agent.train_total": 956.5383422374725, "timer/agent.train_frac": 0.9563557394133151, "timer/agent.train_avg": 0.44865775902320476, "timer/agent.train_min": 0.43577003479003906, "timer/agent.train_max": 0.594027042388916, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4819798469543457, "timer/agent.report_frac": 0.0004818878371755898, "timer/agent.report_avg": 0.24098992347717285, "timer/agent.report_min": 0.23265981674194336, "timer/agent.report_max": 0.24932003021240234, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 4.100799560546875e-05, "timer/dataset_eval_frac": 4.1000167193914356e-08, "timer/dataset_eval_avg": 4.100799560546875e-05, "timer/dataset_eval_min": 4.100799560546875e-05, "timer/dataset_eval_max": 4.100799560546875e-05, "fps": 2.131560896231477}
{"step": 160056, "time": 74509.95687055588, "eval_episode/length": 151.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.993421052631579}
{"step": 160056, "time": 74512.35642027855, "eval_episode/length": 154.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9935483870967742}
{"step": 160056, "time": 74514.481153965, "eval_episode/length": 166.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9700598802395209}
{"step": 160056, "time": 74516.37698793411, "eval_episode/length": 172.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9710982658959537}
{"step": 160056, "time": 74518.04698634148, "eval_episode/length": 174.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 160056, "time": 74520.72027564049, "eval_episode/length": 198.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9748743718592965}
{"step": 160056, "time": 74523.95972251892, "eval_episode/length": 236.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9789029535864979}
{"step": 160056, "time": 74525.90446591377, "eval_episode/length": 79.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9375}
{"step": 160208, "time": 74595.5989947319, "episode/length": 75.0, "episode/score": 2.181911375155323, "episode/reward_rate": 0.9868421052631579, "episode/intrinsic_return": 0.08191125399025623}
{"step": 160296, "time": 74637.52697873116, "episode/length": 230.0, "episode/score": 5.368568038958983, "episode/reward_rate": 0.9783549783549783, "episode/intrinsic_return": 0.268567871693449}
{"step": 160328, "time": 74653.84692406654, "episode/length": 158.0, "episode/score": 2.244668614260263, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.14466854874171986}
{"step": 160544, "time": 74755.1346859932, "episode/length": 156.0, "episode/score": 5.26688473518152, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.16688459690340096}
{"step": 160640, "time": 74800.82022476196, "episode/length": 257.0, "episode/score": 6.3796077757015155, "episode/reward_rate": 0.9961240310077519, "episode/intrinsic_return": 0.27960760028690856}
{"step": 160872, "time": 74909.00325417519, "episode/length": 225.0, "episode/score": 5.352166466136623, "episode/reward_rate": 0.9778761061946902, "episode/intrinsic_return": 0.2521663517818524}
{"step": 161712, "time": 75296.95458436012, "episode/length": 187.0, "episode/score": 4.308756227637787, "episode/reward_rate": 0.9574468085106383, "episode/intrinsic_return": 0.20875611532028415}
{"step": 161760, "time": 75320.55181765556, "episode/length": 182.0, "episode/score": 3.2885910877230344, "episode/reward_rate": 0.9672131147540983, "episode/intrinsic_return": 0.18859096923551988}
{"step": 161794, "time": 75338.31831622124, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.939544235450634, "train/action_min": 0.0, "train/action_std": 4.111781744565365, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04648812399538243, "train/actor_opt_grad_steps": 159200.0, "train/actor_opt_loss": -15.187395956061312, "train/adv_mag": 0.8401034589550921, "train/adv_max": 0.7719071554964867, "train/adv_mean": 0.002880768709636635, "train/adv_min": -0.6015715351427234, "train/adv_std": 0.058065495971176356, "train/cont_avg": 0.9940792949879227, "train/cont_loss_mean": 8.37904211298359e-05, "train/cont_loss_std": 0.0026236477788877757, "train/cont_neg_acc": 0.9981692358491502, "train/cont_neg_loss": 0.006127436413183771, "train/cont_pos_acc": 0.999990457497933, "train/cont_pos_loss": 3.512310704036721e-05, "train/cont_pred": 0.994079715963723, "train/cont_rate": 0.9940792949879227, "train/dyn_loss_mean": 3.1749602642612182, "train/dyn_loss_std": 7.869521486586419, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0157581161761629, "train/extr_critic_critic_opt_grad_steps": 159200.0, "train/extr_critic_critic_opt_loss": 15298.604921497585, "train/extr_critic_mag": 11.764309689618539, "train/extr_critic_max": 11.764309689618539, "train/extr_critic_mean": 2.1118058357837697, "train/extr_critic_min": -0.6737925280695376, "train/extr_critic_std": 2.132543702632333, "train/extr_return_normed_mag": 1.9391295961711719, "train/extr_return_normed_max": 1.9391295961711719, "train/extr_return_normed_mean": 0.37092536097563406, "train/extr_return_normed_min": -0.12808870441383785, "train/extr_return_normed_std": 0.3475363752692218, "train/extr_return_rate": 0.691391818045418, "train/extr_return_raw_mag": 11.947625544911997, "train/extr_return_raw_max": 11.947625544911997, "train/extr_return_raw_mean": 2.1298851943822297, "train/extr_return_raw_min": -0.9943856280207058, "train/extr_return_raw_std": 2.1759198621851237, "train/extr_reward_mag": 1.021245409325125, "train/extr_reward_max": 1.021245409325125, "train/extr_reward_mean": 0.0354473731674002, "train/extr_reward_min": -0.6716671306729892, "train/extr_reward_std": 0.18393009721081038, "train/image_loss_mean": 1.5832408692525781, "train/image_loss_std": 4.85741300744135, "train/model_loss_mean": 3.5610189933131857, "train/model_loss_std": 8.683502849173431, "train/model_opt_grad_norm": 30.46266652535701, "train/model_opt_grad_steps": 159069.78743961352, "train/model_opt_loss": 5624.222607893645, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1576.0869565217392, "train/policy_entropy_mag": 2.6467625392231966, "train/policy_entropy_max": 2.6467625392231966, "train/policy_entropy_mean": 0.4891905439072761, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6200681096977658, "train/policy_logprob_mag": 7.43838413901951, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.48906358788554793, "train/policy_logprob_min": -7.43838413901951, "train/policy_logprob_std": 1.0845278944946142, "train/policy_randomness_mag": 0.9341910259735181, "train/policy_randomness_max": 0.9341910259735181, "train/policy_randomness_mean": 0.1726627944820169, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.21885683376719986, "train/post_ent_mag": 48.55578104654948, "train/post_ent_max": 48.55578104654948, "train/post_ent_mean": 29.65964829633777, "train/post_ent_min": 14.05976180293134, "train/post_ent_std": 4.892307464627252, "train/prior_ent_mag": 76.41918661513766, "train/prior_ent_max": 76.41918661513766, "train/prior_ent_mean": 32.73376066788383, "train/prior_ent_min": 15.81010133402359, "train/prior_ent_std": 8.64461308400988, "train/rep_loss_mean": 3.1749602642612182, "train/rep_loss_std": 7.869521486586419, "train/reward_avg": 0.021058349035554317, "train/reward_loss_mean": 0.07271818075203089, "train/reward_loss_std": 0.15879051920008544, "train/reward_max_data": 1.0075302233442591, "train/reward_max_pred": 1.0080902541893115, "train/reward_neg_acc": 0.9992394093154133, "train/reward_neg_loss": 0.05113348602384761, "train/reward_pos_acc": 0.937260639552333, "train/reward_pos_loss": 0.7178674553327514, "train/reward_pred": 0.020961116000578022, "train/reward_rate": 0.03245301177536232, "eval_stats/sum_log_reward": 4.599999845027924, "eval_stats/max_log_achievement_collect_drink": 2.625, "eval_stats/max_log_achievement_collect_sapling": 1.375, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 5.75, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 1.375, "eval_stats/max_log_achievement_place_table": 2.25, "eval_stats/max_log_achievement_wake_up": 1.5, "eval_stats/mean_log_entropy": 0.0, "train_stats/sum_log_reward": 4.0999999940395355, "train_stats/max_log_achievement_collect_drink": 2.125, "train_stats/max_log_achievement_collect_sapling": 2.375, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 3.25, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.25, "train_stats/max_log_achievement_place_plant": 1.625, "train_stats/max_log_achievement_place_table": 1.125, "train_stats/max_log_achievement_wake_up": 2.125, "train_stats/mean_log_entropy": 0.45808166824281216, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 1.5874767996137962e-05, "report/cont_loss_std": 0.00046164507512003183, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 3.450511576374993e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.5764964700792916e-05, "report/cont_pred": 0.994125247001648, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 3.156968116760254, "report/dyn_loss_std": 7.469856262207031, "report/image_loss_mean": 2.0188589096069336, "report/image_loss_std": 4.5857415199279785, "report/model_loss_mean": 3.9892022609710693, "report/model_loss_std": 7.992190837860107, "report/post_ent_mag": 46.71923828125, "report/post_ent_max": 46.71923828125, "report/post_ent_mean": 28.915191650390625, "report/post_ent_min": 12.716424942016602, "report/post_ent_std": 5.642816543579102, "report/prior_ent_mag": 76.30001068115234, "report/prior_ent_max": 76.30001068115234, "report/prior_ent_mean": 32.11328887939453, "report/prior_ent_min": 14.585044860839844, "report/prior_ent_std": 9.33508014678955, "report/rep_loss_mean": 3.156968116760254, "report/rep_loss_std": 7.469856262207031, "report/reward_avg": 0.02433830313384533, "report/reward_loss_mean": 0.07614623755216599, "report/reward_loss_std": 0.1546182632446289, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0018219947814941, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.05250274017453194, "report/reward_pos_acc": 0.9487179517745972, "report/reward_pos_loss": 0.6732960343360901, "report/reward_pred": 0.02464628964662552, "report/reward_rate": 0.0380859375, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 3.0102705750323366e-06, "eval/cont_loss_std": 4.043033914058469e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0004821558832190931, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 1.131267936216318e-06, "eval/cont_pred": 0.9960944652557373, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 24.076595306396484, "eval/dyn_loss_std": 13.64971923828125, "eval/image_loss_mean": 39.443603515625, "eval/image_loss_std": 43.48833084106445, "eval/model_loss_mean": 54.04353332519531, "eval/model_loss_std": 48.30027389526367, "eval/post_ent_mag": 49.439327239990234, "eval/post_ent_max": 49.439327239990234, "eval/post_ent_mean": 32.05729293823242, "eval/post_ent_min": 20.315658569335938, "eval/post_ent_std": 3.9668493270874023, "eval/prior_ent_mag": 76.30001068115234, "eval/prior_ent_max": 76.30001068115234, "eval/prior_ent_mean": 43.732383728027344, "eval/prior_ent_min": 27.978595733642578, "eval/prior_ent_std": 7.12340784072876, "eval/rep_loss_mean": 24.076595306396484, "eval/rep_loss_std": 13.64971923828125, "eval/reward_avg": 0.02021484449505806, "eval/reward_loss_mean": 0.15396876633167267, "eval/reward_loss_std": 0.9776469469070435, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.000645637512207, "eval/reward_neg_acc": 0.9930000305175781, "eval/reward_neg_loss": 0.07609584927558899, "eval/reward_pos_acc": 0.7083333730697632, "eval/reward_pos_loss": 3.3986740112304688, "eval/reward_pred": 0.01877404749393463, "eval/reward_rate": 0.0234375, "replay/size": 161290.0, "replay/inserts": 2067.0, "replay/samples": 33072.0, "replay/insert_wait_avg": 2.6190286681567867e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.861570050073927e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 33064.0, "eval_replay/inserts": 1976.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2614707715115567e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 6.705522537231445e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0600214004517, "timer/env.step_count": 259.0, "timer/env.step_total": 19.279114484786987, "timer/env.step_frac": 0.019277957394786306, "timer/env.step_avg": 0.07443673546249802, "timer/env.step_min": 0.024593353271484375, "timer/env.step_max": 1.593597650527954, "timer/replay._sample_count": 33072.0, "timer/replay._sample_total": 16.473888158798218, "timer/replay._sample_frac": 0.016472899432304792, "timer/replay._sample_avg": 0.0004981219206216201, "timer/replay._sample_min": 0.00037384033203125, "timer/replay._sample_max": 0.026563644409179688, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 506.0, "timer/agent.policy_total": 8.87001347541809, "timer/agent.policy_frac": 0.008869481116740184, "timer/agent.policy_avg": 0.01752967090003575, "timer/agent.policy_min": 0.009900569915771484, "timer/agent.policy_max": 0.11469864845275879, "timer/dataset_train_count": 2067.0, "timer/dataset_train_total": 0.40212178230285645, "timer/dataset_train_frac": 0.00040209764783891486, "timer/dataset_train_avg": 0.00019454367794042402, "timer/dataset_train_min": 9.632110595703125e-05, "timer/dataset_train_max": 0.0008106231689453125, "timer/agent.train_count": 2067.0, "timer/agent.train_total": 928.466527223587, "timer/agent.train_frac": 0.9284108027070141, "timer/agent.train_avg": 0.4491855477617741, "timer/agent.train_min": 0.437222957611084, "timer/agent.train_max": 0.6441946029663086, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47002172470092773, "timer/agent.report_frac": 0.0004699935150319523, "timer/agent.report_avg": 0.23501086235046387, "timer/agent.report_min": 0.22505950927734375, "timer/agent.report_max": 0.24496221542358398, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.647804260253906e-05, "timer/dataset_eval_frac": 3.647585327074308e-08, "timer/dataset_eval_avg": 3.647804260253906e-05, "timer/dataset_eval_min": 3.647804260253906e-05, "timer/dataset_eval_max": 3.647804260253906e-05, "fps": 2.066848729366685}
{"step": 161880, "time": 75378.14007854462, "episode/length": 154.0, "episode/score": 3.268509665838792, "episode/reward_rate": 0.9612903225806452, "episode/intrinsic_return": 0.1685095775028458}
{"step": 161936, "time": 75405.20612764359, "episode/length": 173.0, "episode/score": 3.2954766439615923, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.19547654910638812}
{"step": 162072, "time": 75469.49472808838, "episode/length": 149.0, "episode/score": 5.2500589665651205, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.15005876064969925}
{"step": 162080, "time": 75474.6707611084, "episode/length": 424.0, "episode/score": 4.561504334488745, "episode/reward_rate": 0.7552941176470588, "episode/intrinsic_return": 0.46150421373113204}
{"step": 162256, "time": 75557.32807159424, "episode/length": 61.0, "episode/score": 4.163334787992426, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.06333466403339116}
{"step": 162368, "time": 75610.33950281143, "episode/length": 422.0, "episode/score": 5.5201073113239545, "episode/reward_rate": 0.640661938534279, "episode/intrinsic_return": 0.4201071920215327}
{"step": 162544, "time": 75692.93238520622, "episode/length": 103.0, "episode/score": 4.204887866833815, "episode/reward_rate": 0.9519230769230769, "episode/intrinsic_return": 0.10488784369044879}
{"step": 162640, "time": 75738.66404485703, "episode/length": 288.0, "episode/score": 5.407426262929221, "episode/reward_rate": 0.986159169550173, "episode/intrinsic_return": 0.3074261593283154}
{"step": 163456, "time": 76114.97740650177, "episode/length": 196.0, "episode/score": 4.295442496146279, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.19544238650632906}
{"step": 163464, "time": 76120.18576145172, "episode/length": 150.0, "episode/score": 4.264274258876867, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.1642741360819855}
{"step": 163584, "time": 76176.64668178558, "episode/length": 188.0, "episode/score": 5.302614776695918, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.2026145939471462}
{"step": 163584, "time": 76176.65542340279, "episode/length": 187.0, "episode/score": 4.3160963884874946, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.2160962123743957}
{"step": 163927, "time": 76338.54161930084, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.991771429357394, "train/action_min": 0.0, "train/action_std": 4.130984252607319, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04569007191334812, "train/actor_opt_grad_steps": 161300.0, "train/actor_opt_loss": -17.384447498430667, "train/adv_mag": 0.7103166175840047, "train/adv_max": 0.6639315638463822, "train/adv_mean": 0.0015134817561443122, "train/adv_min": -0.5289142393450222, "train/adv_std": 0.05476074637801435, "train/cont_avg": 0.9941543794014085, "train/cont_loss_mean": 2.9758966884411835e-05, "train/cont_loss_std": 0.0008518635837002558, "train/cont_neg_acc": 0.998390342428091, "train/cont_neg_loss": 0.003569902895931574, "train/cont_pos_acc": 0.9999999843292953, "train/cont_pos_loss": 1.040283056245201e-05, "train/cont_pred": 0.9941574959128116, "train/cont_rate": 0.9941543794014085, "train/dyn_loss_mean": 3.2253392168054, "train/dyn_loss_std": 7.961204582536724, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9744660146359546, "train/extr_critic_critic_opt_grad_steps": 161300.0, "train/extr_critic_critic_opt_loss": 14996.842177413439, "train/extr_critic_mag": 11.688143313770563, "train/extr_critic_max": 11.688143313770563, "train/extr_critic_mean": 2.1019420914806672, "train/extr_critic_min": -0.6586869831935901, "train/extr_critic_std": 2.129011610304246, "train/extr_return_normed_mag": 1.8523174876898107, "train/extr_return_normed_max": 1.8523174876898107, "train/extr_return_normed_mean": 0.36189707735894433, "train/extr_return_normed_min": -0.13170482067854752, "train/extr_return_normed_std": 0.33995382242919137, "train/extr_return_rate": 0.6796212085815663, "train/extr_return_raw_mag": 11.598533482618734, "train/extr_return_raw_max": 11.598533482618734, "train/extr_return_raw_mean": 2.1115713304197286, "train/extr_return_raw_min": -1.027817812044296, "train/extr_return_raw_std": 2.1629024777613894, "train/extr_reward_mag": 1.0168133151363319, "train/extr_reward_max": 1.0168133151363319, "train/extr_reward_mean": 0.03456781617422619, "train/extr_reward_min": -0.6863242376578246, "train/extr_reward_std": 0.18204363452996447, "train/image_loss_mean": 1.6724594568422702, "train/image_loss_std": 5.1201358445933165, "train/model_loss_mean": 3.680375029783294, "train/model_loss_std": 8.996755470132603, "train/model_opt_grad_norm": 31.848798984652955, "train/model_opt_grad_steps": 161168.70892018778, "train/model_opt_loss": 8312.55117210424, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2271.1267605633802, "train/policy_entropy_mag": 2.633540650488625, "train/policy_entropy_max": 2.633540650488625, "train/policy_entropy_mean": 0.4949634875490072, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6244363009649823, "train/policy_logprob_mag": 7.438384134444832, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.49523158070626955, "train/policy_logprob_min": -7.438384134444832, "train/policy_logprob_std": 1.0898531602581902, "train/policy_randomness_mag": 0.929524280935386, "train/policy_randomness_max": 0.929524280935386, "train/policy_randomness_mean": 0.17470038951562603, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.22039861193565136, "train/post_ent_mag": 48.59608411117339, "train/post_ent_max": 48.59608411117339, "train/post_ent_mean": 29.796597127063734, "train/post_ent_min": 13.841962706874794, "train/post_ent_std": 4.938163808813677, "train/prior_ent_mag": 76.47568966861063, "train/prior_ent_max": 76.47568966861063, "train/prior_ent_mean": 32.9354178468946, "train/prior_ent_min": 15.604582052275608, "train/prior_ent_std": 8.639544795936262, "train/rep_loss_mean": 3.2253392168054, "train/rep_loss_std": 7.961204582536724, "train/reward_avg": 0.020306344141860104, "train/reward_loss_mean": 0.07268229261600355, "train/reward_loss_std": 0.15563971419849307, "train/reward_max_data": 1.0101702185303951, "train/reward_max_pred": 1.010244604567407, "train/reward_neg_acc": 0.999370449585534, "train/reward_neg_loss": 0.051605408477811185, "train/reward_pos_acc": 0.931841470266172, "train/reward_pos_loss": 0.7133888565878354, "train/reward_pred": 0.020174814563052194, "train/reward_rate": 0.03181393045774648, "train_stats/sum_log_reward": 4.266666611035665, "train_stats/max_log_achievement_collect_drink": 3.5833333333333335, "train_stats/max_log_achievement_collect_sapling": 1.5, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 3.5833333333333335, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.5, "train_stats/max_log_achievement_place_table": 1.25, "train_stats/max_log_achievement_wake_up": 2.4166666666666665, "train_stats/mean_log_entropy": 0.462748646736145, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 3.8073244468250778e-06, "report/cont_loss_std": 6.078141086618416e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 6.847102667961735e-06, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 3.786401293837116e-06, "report/cont_pred": 0.9931602478027344, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 3.4174880981445312, "report/dyn_loss_std": 8.234837532043457, "report/image_loss_mean": 1.2680671215057373, "report/image_loss_std": 3.111710786819458, "report/model_loss_mean": 3.3939754962921143, "report/model_loss_std": 7.301119327545166, "report/post_ent_mag": 43.303260803222656, "report/post_ent_max": 43.303260803222656, "report/post_ent_mean": 29.499231338500977, "report/post_ent_min": 11.233915328979492, "report/post_ent_std": 5.3775105476379395, "report/prior_ent_mag": 76.11679077148438, "report/prior_ent_max": 76.11679077148438, "report/prior_ent_mean": 32.66813659667969, "report/prior_ent_min": 11.985383987426758, "report/prior_ent_std": 9.519342422485352, "report/rep_loss_mean": 3.4174880981445312, "report/rep_loss_std": 8.234837532043457, "report/reward_avg": 0.019758649170398712, "report/reward_loss_mean": 0.0754116028547287, "report/reward_loss_std": 0.1809348315000534, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.002295732498169, "report/reward_neg_acc": 0.9989908933639526, "report/reward_neg_loss": 0.053350646048784256, "report/reward_pos_acc": 0.9696969389915466, "report/reward_pos_loss": 0.7379088997840881, "report/reward_pred": 0.020826023072004318, "report/reward_rate": 0.0322265625, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 0.002932551084086299, "eval/cont_loss_std": 0.09377070516347885, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 3.002129554748535, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 7.8501852840418e-07, "eval/cont_pred": 0.9999505281448364, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 21.614852905273438, "eval/dyn_loss_std": 13.306309700012207, "eval/image_loss_mean": 33.80669403076172, "eval/image_loss_std": 40.11567306518555, "eval/model_loss_mean": 46.9150390625, "eval/model_loss_std": 45.50428009033203, "eval/post_ent_mag": 50.2401237487793, "eval/post_ent_max": 50.2401237487793, "eval/post_ent_mean": 32.671966552734375, "eval/post_ent_min": 20.877513885498047, "eval/post_ent_std": 3.9898319244384766, "eval/prior_ent_mag": 76.11679077148438, "eval/prior_ent_max": 76.11679077148438, "eval/prior_ent_mean": 42.83029556274414, "eval/prior_ent_min": 21.223918914794922, "eval/prior_ent_std": 6.895044803619385, "eval/rep_loss_mean": 21.614852905273438, "eval/rep_loss_std": 13.306309700012207, "eval/reward_avg": 0.02568359300494194, "eval/reward_loss_mean": 0.13650235533714294, "eval/reward_loss_std": 0.8757054209709167, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0018365383148193, "eval/reward_neg_acc": 0.9949748516082764, "eval/reward_neg_loss": 0.07500575482845306, "eval/reward_pos_acc": 0.8275861740112305, "eval/reward_pos_loss": 2.246471643447876, "eval/reward_pred": 0.02302447333931923, "eval/reward_rate": 0.0283203125, "replay/size": 163423.0, "replay/inserts": 2133.0, "replay/samples": 34128.0, "replay/insert_wait_avg": 2.604943734628183e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.829501826719561e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 33064.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 7.599592208862305e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2105896472931, "timer/env.step_count": 266.0, "timer/env.step_total": 25.561756372451782, "timer/env.step_frac": 0.0255563744645672, "timer/env.step_avg": 0.09609682846786384, "timer/env.step_min": 0.023752450942993164, "timer/env.step_max": 3.1829917430877686, "timer/replay._sample_count": 34128.0, "timer/replay._sample_total": 16.996530055999756, "timer/replay._sample_frac": 0.01699295151633346, "timer/replay._sample_avg": 0.000498023032583209, "timer/replay._sample_min": 0.00037288665771484375, "timer/replay._sample_max": 0.028055191040039062, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 266.0, "timer/agent.policy_total": 4.248608350753784, "timer/agent.policy_frac": 0.004247713826197323, "timer/agent.policy_avg": 0.01597221184493904, "timer/agent.policy_min": 0.014612913131713867, "timer/agent.policy_max": 0.025495529174804688, "timer/dataset_train_count": 2133.0, "timer/dataset_train_total": 0.40823841094970703, "timer/dataset_train_frac": 0.00040815245826747866, "timer/dataset_train_avg": 0.0001913916600795626, "timer/dataset_train_min": 9.417533874511719e-05, "timer/dataset_train_max": 0.0011997222900390625, "timer/agent.train_count": 2133.0, "timer/agent.train_total": 958.3027412891388, "timer/agent.train_frac": 0.9581009751427123, "timer/agent.train_avg": 0.44927460913696143, "timer/agent.train_min": 0.43535327911376953, "timer/agent.train_max": 0.5845499038696289, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4770658016204834, "timer/agent.report_frac": 0.000476965357654044, "timer/agent.report_avg": 0.2385329008102417, "timer/agent.report_min": 0.2327895164489746, "timer/agent.report_max": 0.2442762851715088, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.123283386230469e-05, "timer/dataset_eval_frac": 3.1226257935659735e-08, "timer/dataset_eval_avg": 3.123283386230469e-05, "timer/dataset_eval_min": 3.123283386230469e-05, "timer/dataset_eval_max": 3.123283386230469e-05, "fps": 2.132521806222964}
{"step": 163936, "time": 76342.93422842026, "episode/length": 195.0, "episode/score": 6.301184024021495, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.20118378713959828}
{"step": 164096, "time": 76417.80368995667, "episode/length": 181.0, "episode/score": 4.292180773491964, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.19218070838087442}
{"step": 164104, "time": 76423.145996809, "episode/length": 194.0, "episode/score": 5.3192397629782135, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.21923961154516292}
{"step": 164216, "time": 76475.97101736069, "episode/length": 284.0, "episode/score": 4.432470198014926, "episode/reward_rate": 0.9964912280701754, "episode/intrinsic_return": 0.3324700536832097}
{"step": 164800, "time": 76744.88940358162, "episode/length": 166.0, "episode/score": 4.261299979504656, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.16129981654648873}
{"step": 164824, "time": 76757.43591356277, "episode/length": 154.0, "episode/score": 5.247552736351281, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.14755266795145872}
{"step": 165000, "time": 76839.28817486763, "episode/length": 176.0, "episode/score": 5.307962497292465, "episode/reward_rate": 0.9661016949152542, "episode/intrinsic_return": 0.20796234935187385}
{"step": 165272, "time": 76964.9851360321, "episode/length": 145.0, "episode/score": 6.244665007470758, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.1446647404372925}
{"step": 165296, "time": 76977.48186540604, "episode/length": 169.0, "episode/score": 4.2709373045163375, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.170937154771309}
{"step": 165416, "time": 77033.99654483795, "episode/length": 244.0, "episode/score": 6.357335961338322, "episode/reward_rate": 0.9836734693877551, "episode/intrinsic_return": 0.25733571979981207}
{"step": 165640, "time": 77138.03051495552, "episode/length": 192.0, "episode/score": 5.306884545409957, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.20688447506017837}
{"step": 165736, "time": 77183.59163117409, "episode/length": 189.0, "episode/score": 6.309692705152884, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.20969252624581713}
{"step": 165960, "time": 77287.50894093513, "episode/length": 141.0, "episode/score": 4.254515216631262, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.1545150598140026}
{"step": 165976, "time": 77296.50470614433, "episode/length": 146.0, "episode/score": 5.256589145688849, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.1565890208566998}
{"step": 166064, "time": 77338.79386997223, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.018365307389018, "train/action_min": 0.0, "train/action_std": 4.171873091537262, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04365995597686166, "train/actor_opt_grad_steps": 163435.0, "train/actor_opt_loss": -16.825239082502428, "train/adv_mag": 0.5504484495548444, "train/adv_max": 0.49991037870678945, "train/adv_mean": 0.0016257692524543068, "train/adv_min": -0.4346842785304952, "train/adv_std": 0.05112026102632006, "train/cont_avg": 0.9943733571845794, "train/cont_loss_mean": 1.4408517768512406e-05, "train/cont_loss_std": 0.00043689331326676403, "train/cont_neg_acc": 0.9984423676940882, "train/cont_neg_loss": 0.0014912431384544523, "train/cont_pos_acc": 0.9999954006939291, "train/cont_pos_loss": 8.265803996472234e-06, "train/cont_pred": 0.994371787409916, "train/cont_rate": 0.9943733571845794, "train/dyn_loss_mean": 3.2219633655013324, "train/dyn_loss_std": 7.919206937896871, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9797781257428856, "train/extr_critic_critic_opt_grad_steps": 163435.0, "train/extr_critic_critic_opt_loss": 15060.772287529206, "train/extr_critic_mag": 8.565773810181662, "train/extr_critic_max": 8.565773810181662, "train/extr_critic_mean": 2.009921187552336, "train/extr_critic_min": -0.6710879039541583, "train/extr_critic_std": 2.0359599785269977, "train/extr_return_normed_mag": 1.512415238072939, "train/extr_return_normed_max": 1.512415238072939, "train/extr_return_normed_mean": 0.3632683005427646, "train/extr_return_normed_min": -0.1434125153121547, "train/extr_return_normed_std": 0.33479556705907126, "train/extr_return_rate": 0.6803340134776641, "train/extr_return_raw_mag": 9.106169691709715, "train/extr_return_raw_max": 9.106169691709715, "train/extr_return_raw_mean": 2.0199596519782164, "train/extr_return_raw_min": -1.1051535698297983, "train/extr_return_raw_std": 2.064691795366947, "train/extr_reward_mag": 1.0196956552077676, "train/extr_reward_max": 1.0196956552077676, "train/extr_reward_mean": 0.03554771664752581, "train/extr_reward_min": -0.6786692220473958, "train/extr_reward_std": 0.18432007353996563, "train/image_loss_mean": 1.6463061328803268, "train/image_loss_std": 5.2135516828465684, "train/model_loss_mean": 3.6522946591689207, "train/model_loss_std": 9.035336536781811, "train/model_opt_grad_norm": 31.091435664168028, "train/model_opt_grad_steps": 163301.59813084113, "train/model_opt_loss": 7008.67198794356, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1915.8878504672898, "train/policy_entropy_mag": 2.6320731628721004, "train/policy_entropy_max": 2.6320731628721004, "train/policy_entropy_mean": 0.49466459724669143, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6255144279136836, "train/policy_logprob_mag": 7.438384149676171, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.49553845711400574, "train/policy_logprob_min": -7.438384149676171, "train/policy_logprob_std": 1.0907664986971384, "train/policy_randomness_mag": 0.9290063214079242, "train/policy_randomness_max": 0.9290063214079242, "train/policy_randomness_mean": 0.17459489377302545, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.22077914456201492, "train/post_ent_mag": 48.776948394062366, "train/post_ent_max": 48.776948394062366, "train/post_ent_mean": 29.86474537180963, "train/post_ent_min": 13.993955634464728, "train/post_ent_std": 4.942986577470726, "train/prior_ent_mag": 76.5277239719284, "train/prior_ent_max": 76.5277239719284, "train/prior_ent_mean": 32.988473526785306, "train/prior_ent_min": 15.85675900896019, "train/prior_ent_std": 8.616184782759051, "train/rep_loss_mean": 3.2219633655013324, "train/rep_loss_std": 7.919206937896871, "train/reward_avg": 0.021036610908144824, "train/reward_loss_mean": 0.07279610005424958, "train/reward_loss_std": 0.16025721253914255, "train/reward_max_data": 1.0082593760757803, "train/reward_max_pred": 1.0089412192317928, "train/reward_neg_acc": 0.9992076579098389, "train/reward_neg_loss": 0.05132816885119287, "train/reward_pos_acc": 0.931158491941256, "train/reward_pos_loss": 0.7169822707911518, "train/reward_pred": 0.020880738708460442, "train/reward_rate": 0.032203745619158876, "train_stats/sum_log_reward": 5.028571333203997, "train_stats/max_log_achievement_collect_drink": 3.5, "train_stats/max_log_achievement_collect_sapling": 1.7857142857142858, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 5.5, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.07142857142857142, "train_stats/max_log_achievement_make_wood_sword": 0.35714285714285715, "train_stats/max_log_achievement_place_plant": 1.3571428571428572, "train_stats/max_log_achievement_place_table": 2.2142857142857144, "train_stats/max_log_achievement_wake_up": 1.6428571428571428, "train_stats/mean_log_entropy": 0.49377488238470896, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 1.0697709740270511e-07, "report/cont_loss_std": 1.5796399566170294e-07, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 1.5858623783060466e-06, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 9.533233225056392e-08, "report/cont_pred": 0.9921875, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 3.282508134841919, "report/dyn_loss_std": 8.021988868713379, "report/image_loss_mean": 1.8188645839691162, "report/image_loss_std": 5.223576545715332, "report/model_loss_mean": 3.869931221008301, "report/model_loss_std": 8.961565971374512, "report/post_ent_mag": 51.619361877441406, "report/post_ent_max": 51.619361877441406, "report/post_ent_mean": 30.256582260131836, "report/post_ent_min": 11.48825454711914, "report/post_ent_std": 4.7659010887146, "report/prior_ent_mag": 76.88594818115234, "report/prior_ent_max": 76.88594818115234, "report/prior_ent_mean": 33.29297637939453, "report/prior_ent_min": 13.203826904296875, "report/prior_ent_std": 8.626103401184082, "report/rep_loss_mean": 3.282508134841919, "report/rep_loss_std": 8.021988868713379, "report/reward_avg": 0.023706987500190735, "report/reward_loss_mean": 0.08156168460845947, "report/reward_loss_std": 0.18373259902000427, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0024292469024658, "report/reward_neg_acc": 0.9989848136901855, "report/reward_neg_loss": 0.05812125653028488, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.673582911491394, "report/reward_pred": 0.024065222591161728, "report/reward_rate": 0.0380859375, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.0007476350292563438, "eval/cont_loss_std": 0.023909322917461395, "eval/cont_neg_acc": 0.75, "eval/cont_neg_loss": 0.19136981666088104, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 9.73225908751374e-08, "eval/cont_pred": 0.9966161251068115, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 22.73883056640625, "eval/dyn_loss_std": 12.75633430480957, "eval/image_loss_mean": 34.998443603515625, "eval/image_loss_std": 36.24953842163086, "eval/model_loss_mean": 48.839481353759766, "eval/model_loss_std": 41.448020935058594, "eval/post_ent_mag": 45.17802047729492, "eval/post_ent_max": 45.17802047729492, "eval/post_ent_mean": 31.384784698486328, "eval/post_ent_min": 13.893569946289062, "eval/post_ent_std": 4.582662105560303, "eval/prior_ent_mag": 76.88594818115234, "eval/prior_ent_max": 76.88594818115234, "eval/prior_ent_mean": 41.38677978515625, "eval/prior_ent_min": 13.731781005859375, "eval/prior_ent_std": 8.626387596130371, "eval/rep_loss_mean": 22.73883056640625, "eval/rep_loss_std": 12.75633430480957, "eval/reward_avg": 0.01835937425494194, "eval/reward_loss_mean": 0.1969929039478302, "eval/reward_loss_std": 1.1691359281539917, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0024290084838867, "eval/reward_neg_acc": 0.9950099587440491, "eval/reward_neg_loss": 0.14052627980709076, "eval/reward_pos_acc": 0.7727273106575012, "eval/reward_pos_loss": 2.7687911987304688, "eval/reward_pred": 0.017088282853364944, "eval/reward_rate": 0.021484375, "replay/size": 165560.0, "replay/inserts": 2137.0, "replay/samples": 34192.0, "replay/insert_wait_avg": 2.6251704100420055e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.80780403537063e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 33064.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 9.08970832824707e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2398357391357, "timer/env.step_count": 267.0, "timer/env.step_total": 28.183634519577026, "timer/env.step_frac": 0.028176876697527737, "timer/env.step_avg": 0.10555668359392145, "timer/env.step_min": 0.023911476135253906, "timer/env.step_max": 1.6084396839141846, "timer/replay._sample_count": 34192.0, "timer/replay._sample_total": 16.916552543640137, "timer/replay._sample_frac": 0.01691249632258398, "timer/replay._sample_avg": 0.0004947517706960732, "timer/replay._sample_min": 0.00036454200744628906, "timer/replay._sample_max": 0.011139392852783203, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 267.0, "timer/agent.policy_total": 4.352895259857178, "timer/agent.policy_frac": 0.0043518515303287925, "timer/agent.policy_avg": 0.016302978501337745, "timer/agent.policy_min": 0.014575481414794922, "timer/agent.policy_max": 0.046453237533569336, "timer/dataset_train_count": 2137.0, "timer/dataset_train_total": 0.4913625717163086, "timer/dataset_train_frac": 0.0004912447536677162, "timer/dataset_train_avg": 0.00022993101156589077, "timer/dataset_train_min": 9.512901306152344e-05, "timer/dataset_train_max": 0.04658007621765137, "timer/agent.train_count": 2137.0, "timer/agent.train_total": 955.6797969341278, "timer/agent.train_frac": 0.9554506457223033, "timer/agent.train_avg": 0.4472062690379634, "timer/agent.train_min": 0.42527270317077637, "timer/agent.train_max": 0.5825629234313965, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4812753200531006, "timer/agent.report_frac": 0.0004811599207078751, "timer/agent.report_avg": 0.2406376600265503, "timer/agent.report_min": 0.23514151573181152, "timer/agent.report_max": 0.24613380432128906, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 4.100799560546875e-05, "timer/dataset_eval_frac": 4.099816278079501e-08, "timer/dataset_eval_avg": 4.100799560546875e-05, "timer/dataset_eval_min": 4.100799560546875e-05, "timer/dataset_eval_max": 4.100799560546875e-05, "fps": 2.1364584796293804}
{"step": 166464, "time": 77522.23590803146, "episode/length": 148.0, "episode/score": 3.23169013415918, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.13169004000246787}
{"step": 166624, "time": 77597.17575478554, "episode/length": 202.0, "episode/score": 5.3122436791491054, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.21224368644834612}
{"step": 166776, "time": 77668.42790532112, "episode/length": 169.0, "episode/score": 5.286334422402433, "episode/reward_rate": 0.9647058823529412, "episode/intrinsic_return": 0.18633425327425357}
{"step": 166872, "time": 77714.12447285652, "episode/length": 113.0, "episode/score": 4.196987784774592, "episode/reward_rate": 0.9912280701754386, "episode/intrinsic_return": 0.09698760749733992}
{"step": 166960, "time": 77756.742800951, "episode/length": 164.0, "episode/score": 5.263142879944553, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.16314268133419318}
{"step": 167040, "time": 77794.96659255028, "episode/length": 162.0, "episode/score": 1.2495852262177323, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.14958515858916144}
{"step": 167160, "time": 77851.59247589111, "episode/length": 232.0, "episode/score": 6.337572352746065, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.23757217280581244}
{"step": 167192, "time": 77867.77265930176, "episode/length": 151.0, "episode/score": 5.26665714899309, "episode/reward_rate": 0.9605263157894737, "episode/intrinsic_return": 0.16665696407608266}
{"step": 168217, "time": 78338.83943271637, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.956061500726745, "train/action_min": 0.0, "train/action_std": 4.08940739077191, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04431950680391733, "train/actor_opt_grad_steps": 165580.0, "train/actor_opt_loss": -15.15145001106484, "train/adv_mag": 0.5629742417224618, "train/adv_max": 0.5088828804881074, "train/adv_mean": 0.002616995801745784, "train/adv_min": -0.46408085732959037, "train/adv_std": 0.05197415889002556, "train/cont_avg": 0.9944040697674419, "train/cont_loss_mean": 9.682364335906927e-05, "train/cont_loss_std": 0.002879840095100042, "train/cont_neg_acc": 0.998449612772742, "train/cont_neg_loss": 0.011916423718994179, "train/cont_pos_acc": 0.9999908364096354, "train/cont_pos_loss": 2.659531428682866e-05, "train/cont_pred": 0.9944029425465784, "train/cont_rate": 0.9944040697674419, "train/dyn_loss_mean": 3.1977719462195107, "train/dyn_loss_std": 7.873040245854577, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9831833140794621, "train/extr_critic_critic_opt_grad_steps": 165580.0, "train/extr_critic_critic_opt_loss": 15114.362073037792, "train/extr_critic_mag": 8.84345803815265, "train/extr_critic_max": 8.84345803815265, "train/extr_critic_mean": 2.040568114990412, "train/extr_critic_min": -0.6641194160594497, "train/extr_critic_std": 2.0578024814295213, "train/extr_return_normed_mag": 1.5410484408223353, "train/extr_return_normed_max": 1.5410484408223353, "train/extr_return_normed_mean": 0.36397358407807906, "train/extr_return_normed_min": -0.12219063286171403, "train/extr_return_normed_std": 0.3376834048088207, "train/extr_return_rate": 0.6729690844236418, "train/extr_return_raw_mag": 9.360757756787677, "train/extr_return_raw_max": 9.360757756787677, "train/extr_return_raw_mean": 2.0567726767340373, "train/extr_return_raw_min": -0.9543931132139162, "train/extr_return_raw_std": 2.0926360318827073, "train/extr_reward_mag": 1.0221007968104163, "train/extr_reward_max": 1.0221007968104163, "train/extr_reward_mean": 0.03724215635380079, "train/extr_reward_min": -0.6808345949927042, "train/extr_reward_std": 0.18791337630083393, "train/image_loss_mean": 1.6331462563470354, "train/image_loss_std": 5.028325114139291, "train/model_loss_mean": 3.624478276940279, "train/model_loss_std": 8.836569750586222, "train/model_opt_grad_norm": 31.241910136023233, "train/model_opt_grad_steps": 165444.91627906976, "train/model_opt_loss": 6167.707243595567, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1709.3023255813953, "train/policy_entropy_mag": 2.6313430675240452, "train/policy_entropy_max": 2.6313430675240452, "train/policy_entropy_mean": 0.48727750570275064, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6181544553401859, "train/policy_logprob_mag": 7.438384131498115, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.48677044108856554, "train/policy_logprob_min": -7.438384131498115, "train/policy_logprob_std": 1.0816893724508063, "train/policy_randomness_mag": 0.928748628427816, "train/policy_randomness_max": 0.928748628427816, "train/policy_randomness_mean": 0.1719875759510107, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.21818139629308567, "train/post_ent_mag": 48.82149257216343, "train/post_ent_max": 48.82149257216343, "train/post_ent_mean": 30.027968375627385, "train/post_ent_min": 13.993326954508937, "train/post_ent_std": 4.858790263464284, "train/prior_ent_mag": 76.5800972162291, "train/prior_ent_max": 76.5800972162291, "train/prior_ent_mean": 33.12069757151049, "train/prior_ent_min": 15.936953256296556, "train/prior_ent_std": 8.559909534454345, "train/rep_loss_mean": 3.1977719462195107, "train/rep_loss_std": 7.873040245854577, "train/reward_avg": 0.02158220992098714, "train/reward_loss_mean": 0.07257202614185422, "train/reward_loss_std": 0.15564755922140078, "train/reward_max_data": 1.0096221236295477, "train/reward_max_pred": 1.0107614395230315, "train/reward_neg_acc": 0.9991828397262928, "train/reward_neg_loss": 0.050933194281749944, "train/reward_pos_acc": 0.9322871366212534, "train/reward_pos_loss": 0.7144534044487532, "train/reward_pred": 0.021411633549994508, "train/reward_rate": 0.032553597383720934, "train_stats/sum_log_reward": 4.349999979138374, "train_stats/max_log_achievement_collect_drink": 3.75, "train_stats/max_log_achievement_collect_sapling": 1.75, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 2.875, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.5, "train_stats/max_log_achievement_place_plant": 1.625, "train_stats/max_log_achievement_place_table": 1.125, "train_stats/max_log_achievement_wake_up": 2.0, "train_stats/mean_log_entropy": 0.399929977953434, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 5.828237590321805e-07, "report/cont_loss_std": 5.277303444017889e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 2.7649140974972397e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 3.6970314454265463e-07, "report/cont_pred": 0.9921874403953552, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 3.3484063148498535, "report/dyn_loss_std": 8.124464988708496, "report/image_loss_mean": 1.7107223272323608, "report/image_loss_std": 5.992417335510254, "report/model_loss_mean": 3.7945923805236816, "report/model_loss_std": 9.87378978729248, "report/post_ent_mag": 50.13800048828125, "report/post_ent_max": 50.13800048828125, "report/post_ent_mean": 30.067209243774414, "report/post_ent_min": 9.1671142578125, "report/post_ent_std": 5.08861780166626, "report/prior_ent_mag": 76.61495971679688, "report/prior_ent_max": 76.61495971679688, "report/prior_ent_mean": 33.42301559448242, "report/prior_ent_min": 9.727550506591797, "report/prior_ent_std": 9.067351341247559, "report/rep_loss_mean": 3.3484063148498535, "report/rep_loss_std": 8.124464988708496, "report/reward_avg": 0.02630874142050743, "report/reward_loss_mean": 0.07482563704252243, "report/reward_loss_std": 0.13885866105556488, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0018296241760254, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.051666274666786194, "report/reward_pos_acc": 0.9736841917037964, "report/reward_pos_loss": 0.6757502555847168, "report/reward_pred": 0.026352424174547195, "report/reward_rate": 0.037109375, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 1.8816517695086077e-06, "eval/cont_loss_std": 4.463233199203387e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00038956088246777654, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 3.613409376157506e-07, "eval/cont_pred": 0.9960950016975403, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 20.553085327148438, "eval/dyn_loss_std": 13.772268295288086, "eval/image_loss_mean": 26.925979614257812, "eval/image_loss_std": 36.422950744628906, "eval/model_loss_mean": 39.37070083618164, "eval/model_loss_std": 42.01408004760742, "eval/post_ent_mag": 46.59330749511719, "eval/post_ent_max": 46.59330749511719, "eval/post_ent_mean": 32.57817840576172, "eval/post_ent_min": 19.298473358154297, "eval/post_ent_std": 4.539612770080566, "eval/prior_ent_mag": 76.61495971679688, "eval/prior_ent_max": 76.61495971679688, "eval/prior_ent_mean": 42.58890151977539, "eval/prior_ent_min": 17.484878540039062, "eval/prior_ent_std": 8.489831924438477, "eval/rep_loss_mean": 20.553085327148438, "eval/rep_loss_std": 13.772268295288086, "eval/reward_avg": 0.0185546875, "eval/reward_loss_mean": 0.11286701261997223, "eval/reward_loss_std": 0.8564139008522034, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0018272399902344, "eval/reward_neg_acc": 0.9960039854049683, "eval/reward_neg_loss": 0.05469520762562752, "eval/reward_pos_acc": 0.782608687877655, "eval/reward_pos_loss": 2.6446049213409424, "eval/reward_pred": 0.016842205077409744, "eval/reward_rate": 0.0224609375, "replay/size": 167713.0, "replay/inserts": 2153.0, "replay/samples": 34448.0, "replay/insert_wait_avg": 2.6114198478277043e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.948001151964158e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 33064.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 7.897615432739258e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0310754776001, "timer/env.step_count": 270.0, "timer/env.step_total": 19.497562170028687, "timer/env.step_frac": 0.01949695629280014, "timer/env.step_avg": 0.07221319322232847, "timer/env.step_min": 0.024053573608398438, "timer/env.step_max": 1.6100027561187744, "timer/replay._sample_count": 34448.0, "timer/replay._sample_total": 16.89957046508789, "timer/replay._sample_frac": 0.01689904531918361, "timer/replay._sample_avg": 0.0004905820501941446, "timer/replay._sample_min": 0.0003466606140136719, "timer/replay._sample_max": 0.009684562683105469, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 270.0, "timer/agent.policy_total": 4.276304244995117, "timer/agent.policy_frac": 0.004276171360927777, "timer/agent.policy_avg": 0.015838163870352286, "timer/agent.policy_min": 0.01475834846496582, "timer/agent.policy_max": 0.02743816375732422, "timer/dataset_train_count": 2153.0, "timer/dataset_train_total": 0.4020707607269287, "timer/dataset_train_frac": 0.00040205826657427183, "timer/dataset_train_avg": 0.00018674907604594924, "timer/dataset_train_min": 9.322166442871094e-05, "timer/dataset_train_max": 0.0011625289916992188, "timer/agent.train_count": 2153.0, "timer/agent.train_total": 964.3055534362793, "timer/agent.train_frac": 0.9642755881118406, "timer/agent.train_avg": 0.44788924915758443, "timer/agent.train_min": 0.43528294563293457, "timer/agent.train_max": 1.1150474548339844, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4814784526824951, "timer/agent.report_frac": 0.0004814634909745661, "timer/agent.report_avg": 0.24073922634124756, "timer/agent.report_min": 0.23430442810058594, "timer/agent.report_max": 0.24717402458190918, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9087066650390625e-05, "timer/dataset_eval_frac": 2.908616278399056e-08, "timer/dataset_eval_avg": 2.9087066650390625e-05, "timer/dataset_eval_min": 2.9087066650390625e-05, "timer/dataset_eval_max": 2.9087066650390625e-05, "fps": 2.1529036724995128}
{"step": 168232, "time": 78345.93194198608, "episode/length": 200.0, "episode/score": 5.318063296277614, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.21806317748450965}
{"step": 168248, "time": 78354.82208323479, "episode/length": 183.0, "episode/score": 4.276184284954979, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.17618417531502928}
{"step": 168440, "time": 78444.22084903717, "episode/length": 184.0, "episode/score": 6.291903450674454, "episode/reward_rate": 0.9621621621621622, "episode/intrinsic_return": 0.19190321961332302}
{"step": 168456, "time": 78452.99573135376, "episode/length": 248.0, "episode/score": 7.3635998491827195, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.2635996138142218}
{"step": 168544, "time": 78494.95239925385, "episode/length": 172.0, "episode/score": 4.29224873603016, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.19224860182657721}
{"step": 168720, "time": 78577.23401379585, "episode/length": 230.0, "episode/score": 5.35911483645441, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.25911471598783464}
{"step": 168856, "time": 78641.08782601357, "episode/length": 226.0, "episode/score": 5.316102370435601, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.21610222412482472}
{"step": 169152, "time": 78778.74058842659, "episode/length": 244.0, "episode/score": 5.353174086575564, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.2531739155556352}
{"step": 169696, "time": 79029.11078095436, "episode/length": 182.0, "episode/score": 6.287233196912439, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.18723301684121907}
{"step": 169800, "time": 79078.24225783348, "episode/length": 156.0, "episode/score": 5.290416811942123, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.19041666283737868}
{"step": 169856, "time": 79105.39899158478, "episode/length": 200.0, "episode/score": 5.320751696790012, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.22075155298216487}
{"step": 169864, "time": 79110.5021982193, "episode/length": 175.0, "episode/score": 6.288438980115643, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.18843879888027004}
{"step": 169912, "time": 79133.88196015358, "episode/length": 183.0, "episode/score": 4.3053572487019665, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.20535708574379896}
{"step": 170040, "time": 79210.02541089058, "eval_episode/length": 86.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9310344827586207}
{"step": 170040, "time": 79213.9742000103, "eval_episode/length": 138.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9928057553956835}
{"step": 170040, "time": 79216.44947528839, "eval_episode/length": 162.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9693251533742331}
{"step": 170040, "time": 79218.1874203682, "eval_episode/length": 167.0, "eval_episode/score": 4.1000000312924385, "eval_episode/reward_rate": 0.9940476190476191}
{"step": 170040, "time": 79219.9259300232, "eval_episode/length": 172.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9710982658959537}
{"step": 170040, "time": 79221.46193146706, "eval_episode/length": 173.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9942528735632183}
{"step": 170040, "time": 79223.32215237617, "eval_episode/length": 179.0, "eval_episode/score": 3.0999999716877937, "eval_episode/reward_rate": 0.9944444444444445}
{"step": 170040, "time": 79224.8813033104, "eval_episode/length": 180.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9723756906077348}
{"step": 170056, "time": 79232.129083395, "episode/length": 149.0, "episode/score": 5.264733456705017, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.16473331959105053}
{"step": 170286, "time": 79338.85973572731, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.841310362884964, "train/action_min": 0.0, "train/action_std": 3.934930890078706, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.045017119371084775, "train/actor_opt_grad_steps": 167690.0, "train/actor_opt_loss": -15.099673777332772, "train/adv_mag": 0.6102779653049322, "train/adv_max": 0.5337797139865764, "train/adv_mean": 0.002248309101028791, "train/adv_min": -0.48134086774167234, "train/adv_std": 0.05180181841847401, "train/cont_avg": 0.9944048158212561, "train/cont_loss_mean": 2.9807160152992638e-05, "train/cont_loss_std": 0.0009111154128280417, "train/cont_neg_acc": 0.9983896941378496, "train/cont_neg_loss": 0.004615557818582698, "train/cont_pos_acc": 0.9999952422823883, "train/cont_pos_loss": 1.4779689153631561e-05, "train/cont_pred": 0.9944005968490085, "train/cont_rate": 0.9944048158212561, "train/dyn_loss_mean": 3.1405425624570986, "train/dyn_loss_std": 7.827795940896739, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.970282889218722, "train/extr_critic_critic_opt_grad_steps": 167690.0, "train/extr_critic_critic_opt_loss": 15097.980718787741, "train/extr_critic_mag": 9.717904844145844, "train/extr_critic_max": 9.717904844145844, "train/extr_critic_mean": 2.0809910452884175, "train/extr_critic_min": -0.659990882528001, "train/extr_critic_std": 2.114960377343035, "train/extr_return_normed_mag": 1.6246916764024375, "train/extr_return_normed_max": 1.6246916764024375, "train/extr_return_normed_mean": 0.36411050336372447, "train/extr_return_normed_min": -0.12951924831826905, "train/extr_return_normed_std": 0.3406361112560051, "train/extr_return_rate": 0.6733626811112758, "train/extr_return_raw_mag": 10.041655890607604, "train/extr_return_raw_max": 10.041655890607604, "train/extr_return_raw_mean": 2.0951581652037765, "train/extr_return_raw_min": -1.0142167040691283, "train/extr_return_raw_std": 2.1461123458429237, "train/extr_reward_mag": 1.0199264604688267, "train/extr_reward_max": 1.0199264604688267, "train/extr_reward_mean": 0.03779344139215739, "train/extr_reward_min": -0.6775372494821963, "train/extr_reward_std": 0.18997849128096575, "train/image_loss_mean": 1.5404260573179827, "train/image_loss_std": 4.812637856617066, "train/model_loss_mean": 3.497694692749908, "train/model_loss_std": 8.634872293702646, "train/model_opt_grad_norm": 31.188370032011022, "train/model_opt_grad_steps": 167553.79710144928, "train/model_opt_loss": 7355.870054678065, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2113.526570048309, "train/policy_entropy_mag": 2.6305964327088875, "train/policy_entropy_max": 2.6305964327088875, "train/policy_entropy_mean": 0.4909880123852532, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6222463587056035, "train/policy_logprob_mag": 7.438384122894582, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.4916813311657468, "train/policy_logprob_min": -7.438384122894582, "train/policy_logprob_std": 1.086401937376474, "train/policy_randomness_mag": 0.9284851006839586, "train/policy_randomness_max": 0.9284851006839586, "train/policy_randomness_mean": 0.17329722272169187, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.21962565788324329, "train/post_ent_mag": 48.60130064959687, "train/post_ent_max": 48.60130064959687, "train/post_ent_mean": 30.24140251085954, "train/post_ent_min": 14.142861596628087, "train/post_ent_std": 4.890355354345939, "train/prior_ent_mag": 76.58763738070134, "train/prior_ent_max": 76.58763738070134, "train/prior_ent_mean": 33.28102309922665, "train/prior_ent_min": 15.92390615583042, "train/prior_ent_std": 8.547538681306701, "train/rep_loss_mean": 3.1405425624570986, "train/rep_loss_std": 7.827795940896739, "train/reward_avg": 0.02166987767955963, "train/reward_loss_mean": 0.07291330830846432, "train/reward_loss_std": 0.15708085844194256, "train/reward_max_data": 1.0075302233442591, "train/reward_max_pred": 1.0082213118456411, "train/reward_neg_acc": 0.999214468082944, "train/reward_neg_loss": 0.0509724244295399, "train/reward_pos_acc": 0.9354625445057229, "train/reward_pos_loss": 0.7186501570369886, "train/reward_pred": 0.021502401405306543, "train/reward_rate": 0.03289647493961353, "train_stats/sum_log_reward": 5.242857047489712, "train_stats/max_log_achievement_collect_drink": 2.0, "train_stats/max_log_achievement_collect_sapling": 1.8571428571428572, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 6.071428571428571, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.07142857142857142, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.5714285714285714, "train_stats/max_log_achievement_place_plant": 1.7857142857142858, "train_stats/max_log_achievement_place_table": 2.142857142857143, "train_stats/max_log_achievement_wake_up": 2.4285714285714284, "train_stats/mean_log_entropy": 0.5390597709587642, "eval_stats/sum_log_reward": 4.599999964237213, "eval_stats/max_log_achievement_collect_drink": 4.5, "eval_stats/max_log_achievement_collect_sapling": 2.125, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 4.125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.125, "eval_stats/max_log_achievement_place_plant": 1.5, "eval_stats/max_log_achievement_place_table": 1.375, "eval_stats/max_log_achievement_wake_up": 1.5, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 5.7155311878887005e-06, "report/cont_loss_std": 1.965222691069357e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 5.075499211670831e-05, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 5.538905497814994e-06, "report/cont_pred": 0.9960883855819702, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 2.8998217582702637, "report/dyn_loss_std": 7.844079494476318, "report/image_loss_mean": 1.1325300931930542, "report/image_loss_std": 4.156707286834717, "report/model_loss_mean": 2.9367165565490723, "report/model_loss_std": 8.279618263244629, "report/post_ent_mag": 51.15599822998047, "report/post_ent_max": 51.15599822998047, "report/post_ent_mean": 30.173189163208008, "report/post_ent_min": 14.98098373413086, "report/post_ent_std": 4.760104656219482, "report/prior_ent_mag": 76.37705993652344, "report/prior_ent_max": 76.37705993652344, "report/prior_ent_mean": 32.87736129760742, "report/prior_ent_min": 17.765735626220703, "report/prior_ent_std": 8.11252212524414, "report/rep_loss_mean": 2.8998217582702637, "report/rep_loss_std": 7.844079494476318, "report/reward_avg": 0.020805884152650833, "report/reward_loss_mean": 0.06428766250610352, "report/reward_loss_std": 0.1372038573026657, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.001241683959961, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.04776638373732567, "report/reward_pos_acc": 0.9629629850387573, "report/reward_pos_loss": 0.6743510365486145, "report/reward_pred": 0.02111516334116459, "report/reward_rate": 0.0263671875, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.002624975051730871, "eval/cont_loss_std": 0.07740702480077744, "eval/cont_neg_acc": 0.800000011920929, "eval/cont_neg_loss": 0.5364819765090942, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 5.460954071168089e-06, "eval/cont_pred": 0.9961931109428406, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 20.996570587158203, "eval/dyn_loss_std": 12.47849178314209, "eval/image_loss_mean": 34.84919357299805, "eval/image_loss_std": 40.53091812133789, "eval/model_loss_mean": 47.62657165527344, "eval/model_loss_std": 44.935768127441406, "eval/post_ent_mag": 51.15599822998047, "eval/post_ent_max": 51.15599822998047, "eval/post_ent_mean": 32.45132064819336, "eval/post_ent_min": 16.441247940063477, "eval/post_ent_std": 4.340935230255127, "eval/prior_ent_mag": 76.37705993652344, "eval/prior_ent_max": 76.37705993652344, "eval/prior_ent_mean": 42.81230926513672, "eval/prior_ent_min": 17.38982391357422, "eval/prior_ent_std": 8.046209335327148, "eval/rep_loss_mean": 20.996570587158203, "eval/rep_loss_std": 12.47849178314209, "eval/reward_avg": 0.02871093712747097, "eval/reward_loss_mean": 0.17680947482585907, "eval/reward_loss_std": 1.1293152570724487, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0012426376342773, "eval/reward_neg_acc": 0.9959595203399658, "eval/reward_neg_loss": 0.07566875964403152, "eval/reward_pos_acc": 0.7647058963775635, "eval/reward_pos_loss": 3.1217892169952393, "eval/reward_pred": 0.024431444704532623, "eval/reward_rate": 0.033203125, "replay/size": 169782.0, "replay/inserts": 2069.0, "replay/samples": 33104.0, "replay/insert_wait_avg": 2.6450749466879003e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.893294168014121e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 34512.0, "eval_replay/inserts": 1448.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1718404885813677e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.238719940185547e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0050668716431, "timer/env.step_count": 258.0, "timer/env.step_total": 28.472964763641357, "timer/env.step_frac": 0.02847282049551459, "timer/env.step_avg": 0.11036032854124557, "timer/env.step_min": 0.02453303337097168, "timer/env.step_max": 1.6463713645935059, "timer/replay._sample_count": 33104.0, "timer/replay._sample_total": 16.261117219924927, "timer/replay._sample_frac": 0.016261034827348673, "timer/replay._sample_avg": 0.0004912130624675243, "timer/replay._sample_min": 0.0003848075866699219, "timer/replay._sample_max": 0.026060104370117188, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 439.0, "timer/agent.policy_total": 6.997731447219849, "timer/agent.policy_frac": 0.006997695990792466, "timer/agent.policy_avg": 0.01594016274993132, "timer/agent.policy_min": 0.009397745132446289, "timer/agent.policy_max": 0.047718048095703125, "timer/dataset_train_count": 2069.0, "timer/dataset_train_total": 0.38190460205078125, "timer/dataset_train_frac": 0.00038190266699898744, "timer/dataset_train_avg": 0.0001845841479220789, "timer/dataset_train_min": 9.083747863769531e-05, "timer/dataset_train_max": 0.0006024837493896484, "timer/agent.train_count": 2069.0, "timer/agent.train_total": 924.9356942176819, "timer/agent.train_frac": 0.9249310077109871, "timer/agent.train_avg": 0.44704480145852193, "timer/agent.train_min": 0.4358093738555908, "timer/agent.train_max": 0.589414119720459, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4775080680847168, "timer/agent.report_frac": 0.00047750564862488636, "timer/agent.report_avg": 0.2387540340423584, "timer/agent.report_min": 0.2322676181793213, "timer/agent.report_max": 0.2452404499053955, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7418136596679688e-05, "timer/dataset_eval_frac": 2.7417997673204767e-08, "timer/dataset_eval_avg": 2.7418136596679688e-05, "timer/dataset_eval_min": 2.7418136596679688e-05, "timer/dataset_eval_max": 2.7418136596679688e-05, "fps": 2.0689606116998567}
{"step": 170648, "time": 79505.31598305702, "episode/length": 186.0, "episode/score": 6.29274952250762, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.19274930754090747}
{"step": 171120, "time": 79723.51809477806, "episode/length": 150.0, "episode/score": 5.257141648594825, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.15714154366969524}
{"step": 171168, "time": 79747.22669816017, "episode/length": 305.0, "episode/score": 8.451330856882578, "episode/reward_rate": 0.9869281045751634, "episode/intrinsic_return": 0.3513305882192981}
{"step": 171168, "time": 79747.23624658585, "episode/length": 170.0, "episode/score": 4.255255123458483, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.15525497911221464}
{"step": 171224, "time": 79776.21280694008, "episode/length": 169.0, "episode/score": 6.299193613319403, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.19919339424905047}
{"step": 171448, "time": 79880.93519544601, "episode/length": 218.0, "episode/score": 5.33761160334916, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.23761139859789182}
{"step": 171448, "time": 79880.94515538216, "episode/length": 198.0, "episode/score": 5.314873178792368, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.21487297404109995}
{"step": 171656, "time": 79979.70739483833, "episode/length": 199.0, "episode/score": 5.275292467673353, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.1752922463692812}
{"step": 172016, "time": 80146.40882897377, "episode/length": 170.0, "episode/score": 4.277743781403387, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.17774369615244723}
{"step": 172431, "time": 80339.14640951157, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.8997711891351745, "train/action_min": 0.0, "train/action_std": 3.9077719810397125, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0443343749919603, "train/actor_opt_grad_steps": 169800.0, "train/actor_opt_loss": -14.754827365279198, "train/adv_mag": 0.5985302280548007, "train/adv_max": 0.536168909072876, "train/adv_mean": 0.002473878115407113, "train/adv_min": -0.4687395411868428, "train/adv_std": 0.05179325654063114, "train/cont_avg": 0.9944404069767442, "train/cont_loss_mean": 4.707914279323589e-05, "train/cont_loss_std": 0.0014680138248242952, "train/cont_neg_acc": 0.9975077883105412, "train/cont_neg_loss": 0.003731447912478216, "train/cont_pos_acc": 0.9999954096106596, "train/cont_pos_loss": 3.168568412132667e-05, "train/cont_pred": 0.9944415605345438, "train/cont_rate": 0.9944404069767442, "train/dyn_loss_mean": 3.194542411316273, "train/dyn_loss_std": 7.868433943460154, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9869965032089588, "train/extr_critic_critic_opt_grad_steps": 169800.0, "train/extr_critic_critic_opt_loss": 15019.591783248547, "train/extr_critic_mag": 9.507696400132291, "train/extr_critic_max": 9.507696400132291, "train/extr_critic_mean": 2.1573496990425642, "train/extr_critic_min": -0.6581645666166793, "train/extr_critic_std": 2.109433073221251, "train/extr_return_normed_mag": 1.5728139001269674, "train/extr_return_normed_max": 1.5728139001269674, "train/extr_return_normed_mean": 0.3695739188166552, "train/extr_return_normed_min": -0.12260582185415335, "train/extr_return_normed_std": 0.33554336754388586, "train/extr_return_rate": 0.7103400911009589, "train/extr_return_raw_mag": 9.86085160055826, "train/extr_return_raw_max": 9.86085160055826, "train/extr_return_raw_mean": 2.1731467435526293, "train/extr_return_raw_min": -0.9726531699646351, "train/extr_return_raw_std": 2.1448146271151165, "train/extr_reward_mag": 1.0158539073411808, "train/extr_reward_max": 1.0158539073411808, "train/extr_reward_mean": 0.03744569417349128, "train/extr_reward_min": -0.6782991126526233, "train/extr_reward_std": 0.188243097898572, "train/image_loss_mean": 1.587870622512906, "train/image_loss_std": 4.929910345964654, "train/model_loss_mean": 3.577014778935632, "train/model_loss_std": 8.742027941415476, "train/model_opt_grad_norm": 30.885379059370173, "train/model_opt_grad_steps": 169661.57674418605, "train/model_opt_loss": 6882.726059456759, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1930.2325581395348, "train/policy_entropy_mag": 2.6146720897319704, "train/policy_entropy_max": 2.6146720897319704, "train/policy_entropy_mean": 0.49032339162604754, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6232237214265868, "train/policy_logprob_mag": 7.438384115973184, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.4907584269379461, "train/policy_logprob_min": -7.438384115973184, "train/policy_logprob_std": 1.0849102466605431, "train/policy_randomness_mag": 0.9228645069654597, "train/policy_randomness_max": 0.9228645069654597, "train/policy_randomness_mean": 0.17306264063646626, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.21997062577757726, "train/post_ent_mag": 48.416538362724836, "train/post_ent_max": 48.416538362724836, "train/post_ent_mean": 30.44051144622093, "train/post_ent_min": 14.314971112096032, "train/post_ent_std": 4.893363790733869, "train/prior_ent_mag": 76.58708570613418, "train/prior_ent_max": 76.58708570613418, "train/prior_ent_mean": 33.52172346780466, "train/prior_ent_min": 16.17566028417543, "train/prior_ent_std": 8.53471875523412, "train/rep_loss_mean": 3.194542411316273, "train/rep_loss_std": 7.868433943460154, "train/reward_avg": 0.021457464390889157, "train/reward_loss_mean": 0.07237163322956063, "train/reward_loss_std": 0.15428341103847637, "train/reward_max_data": 1.0072965416797373, "train/reward_max_pred": 1.0078896334004956, "train/reward_neg_acc": 0.999234193147615, "train/reward_neg_loss": 0.05087730990246285, "train/reward_pos_acc": 0.9367086571316386, "train/reward_pos_loss": 0.7105610747670018, "train/reward_pred": 0.02130928696674663, "train/reward_rate": 0.032589934593023256, "train_stats/sum_log_reward": 5.433333290947808, "train_stats/max_log_achievement_collect_drink": 2.6666666666666665, "train_stats/max_log_achievement_collect_sapling": 2.7777777777777777, "train_stats/max_log_achievement_collect_stone": 0.3333333333333333, "train_stats/max_log_achievement_collect_wood": 7.0, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.1111111111111111, "train_stats/max_log_achievement_make_wood_pickaxe": 0.1111111111111111, "train_stats/max_log_achievement_make_wood_sword": 0.5555555555555556, "train_stats/max_log_achievement_place_plant": 2.4444444444444446, "train_stats/max_log_achievement_place_table": 3.0, "train_stats/max_log_achievement_wake_up": 2.0, "train_stats/mean_log_entropy": 0.48501329951816136, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 8.416964192292653e-07, "report/cont_loss_std": 1.6838468582136557e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0001602094416739419, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 2.1672475725154072e-07, "report/cont_pred": 0.9960942268371582, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 2.9292521476745605, "report/dyn_loss_std": 7.374244213104248, "report/image_loss_mean": 1.3670661449432373, "report/image_loss_std": 4.278738021850586, "report/model_loss_mean": 3.1896510124206543, "report/model_loss_std": 7.918124198913574, "report/post_ent_mag": 50.20457458496094, "report/post_ent_max": 50.20457458496094, "report/post_ent_mean": 31.00279426574707, "report/post_ent_min": 16.373817443847656, "report/post_ent_std": 4.349221706390381, "report/prior_ent_mag": 76.58425903320312, "report/prior_ent_max": 76.58425903320312, "report/prior_ent_mean": 33.920753479003906, "report/prior_ent_min": 16.523651123046875, "report/prior_ent_std": 7.549431324005127, "report/rep_loss_mean": 2.9292521476745605, "report/rep_loss_std": 7.374244213104248, "report/reward_avg": 0.013229047879576683, "report/reward_loss_mean": 0.06503306329250336, "report/reward_loss_std": 0.15598440170288086, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0056805610656738, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.04845023527741432, "report/reward_pos_acc": 0.9545454978942871, "report/reward_pos_loss": 0.8203057646751404, "report/reward_pred": 0.011961473152041435, "report/reward_rate": 0.021484375, "eval/cont_avg": 0.9931640625, "eval/cont_loss_mean": 0.0060757361352443695, "eval/cont_loss_std": 0.1459961235523224, "eval/cont_neg_acc": 0.7142857313156128, "eval/cont_neg_loss": 0.8868262767791748, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 1.3539553037844598e-05, "eval/cont_pred": 0.9950746297836304, "eval/cont_rate": 0.9931640625, "eval/dyn_loss_mean": 23.229530334472656, "eval/dyn_loss_std": 13.2725830078125, "eval/image_loss_mean": 31.30316162109375, "eval/image_loss_std": 31.34196662902832, "eval/model_loss_mean": 45.38653564453125, "eval/model_loss_std": 35.871917724609375, "eval/post_ent_mag": 50.20457458496094, "eval/post_ent_max": 50.20457458496094, "eval/post_ent_mean": 32.923744201660156, "eval/post_ent_min": 18.781517028808594, "eval/post_ent_std": 4.327302932739258, "eval/prior_ent_mag": 76.58425903320312, "eval/prior_ent_max": 76.58425903320312, "eval/prior_ent_mean": 44.98586654663086, "eval/prior_ent_min": 27.380123138427734, "eval/prior_ent_std": 6.841663837432861, "eval/rep_loss_mean": 23.229530334472656, "eval/rep_loss_std": 13.2725830078125, "eval/reward_avg": 0.02490234375, "eval/reward_loss_mean": 0.13957950472831726, "eval/reward_loss_std": 0.9268695712089539, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0018370151519775, "eval/reward_neg_acc": 0.9959717988967896, "eval/reward_neg_loss": 0.0560917891561985, "eval/reward_pos_acc": 0.7096773982048035, "eval/reward_pos_loss": 2.8138794898986816, "eval/reward_pred": 0.02020259201526642, "eval/reward_rate": 0.0302734375, "replay/size": 171927.0, "replay/inserts": 2145.0, "replay/samples": 34320.0, "replay/insert_wait_avg": 2.583034666546019e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.944993483714568e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 34512.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 6.854534149169922e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2729196548462, "timer/env.step_count": 268.0, "timer/env.step_total": 21.11009907722473, "timer/env.step_frac": 0.021104339288230432, "timer/env.step_avg": 0.07876902640755497, "timer/env.step_min": 0.024120807647705078, "timer/env.step_max": 3.202735662460327, "timer/replay._sample_count": 34320.0, "timer/replay._sample_total": 17.052358627319336, "timer/replay._sample_frac": 0.017047705973289185, "timer/replay._sample_avg": 0.0004968635963671135, "timer/replay._sample_min": 0.00038170814514160156, "timer/replay._sample_max": 0.025702476501464844, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 268.0, "timer/agent.policy_total": 4.281846523284912, "timer/agent.policy_frac": 0.004280678242056583, "timer/agent.policy_avg": 0.01597703926598848, "timer/agent.policy_min": 0.014740467071533203, "timer/agent.policy_max": 0.01853656768798828, "timer/dataset_train_count": 2145.0, "timer/dataset_train_total": 0.4103243350982666, "timer/dataset_train_frac": 0.00041021238007708235, "timer/dataset_train_avg": 0.00019129339631620822, "timer/dataset_train_min": 9.632110595703125e-05, "timer/dataset_train_max": 0.0012161731719970703, "timer/agent.train_count": 2145.0, "timer/agent.train_total": 962.8436403274536, "timer/agent.train_frac": 0.9625809330714382, "timer/agent.train_avg": 0.44887815399881287, "timer/agent.train_min": 0.43652844429016113, "timer/agent.train_max": 0.5720205307006836, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4786660671234131, "timer/agent.report_frac": 0.0004785354653893674, "timer/agent.report_avg": 0.23933303356170654, "timer/agent.report_min": 0.23181557655334473, "timer/agent.report_max": 0.24685049057006836, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.86102294921875e-05, "timer/dataset_eval_frac": 2.860242332868487e-08, "timer/dataset_eval_avg": 2.86102294921875e-05, "timer/dataset_eval_min": 2.86102294921875e-05, "timer/dataset_eval_max": 2.86102294921875e-05, "fps": 2.144381761365261}
{"step": 172448, "time": 80347.1793255806, "episode/length": 165.0, "episode/score": 4.28133755072804, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.1813374638472851}
{"step": 172552, "time": 80396.37062811852, "episode/length": 165.0, "episode/score": 5.261164794856086, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.1611646554138133}
{"step": 172552, "time": 80396.42669796944, "episode/length": 172.0, "episode/score": 5.263770294083315, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.1637701124986961}
{"step": 172600, "time": 80421.52450680733, "episode/length": 178.0, "episode/score": 3.2754371785877083, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.17543716870841308}
{"step": 172616, "time": 80430.3305990696, "episode/length": 145.0, "episode/score": 6.275708523578942, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.17570832977071404}
{"step": 172952, "time": 80585.3033425808, "episode/length": 187.0, "episode/score": 5.301269289302127, "episode/reward_rate": 0.9627659574468085, "episode/intrinsic_return": 0.20126923021553011}
{"step": 173016, "time": 80616.0737566948, "episode/length": 169.0, "episode/score": 4.273189842070678, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.17318972556222434}
{"step": 173656, "time": 80910.02199697495, "episode/length": 204.0, "episode/score": 6.326953045256687, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.22695286402131387}
{"step": 173672, "time": 80918.82588481903, "episode/length": 131.0, "episode/score": 5.213680076265064, "episode/reward_rate": 0.9924242424242424, "episode/intrinsic_return": 0.11367993292287792}
{"step": 173808, "time": 80982.43193531036, "episode/length": 169.0, "episode/score": 6.257434600194756, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.15743447105523956}
{"step": 174144, "time": 81137.14467763901, "episode/length": 198.0, "episode/score": 5.326619067724096, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.22661889079608954}
{"step": 174256, "time": 81189.66005063057, "episode/length": 154.0, "episode/score": 6.24710341617083, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.1471032141989781}
{"step": 174352, "time": 81235.15754270554, "episode/length": 224.0, "episode/score": 3.3194246512168775, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.21942462248557604}
{"step": 174352, "time": 81235.16695094109, "episode/length": 218.0, "episode/score": 5.328715200305396, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.22871502414136557}
{"step": 174568, "time": 81336.85486268997, "episode/length": 201.0, "episode/score": 5.347185741804424, "episode/reward_rate": 0.9603960396039604, "episode/intrinsic_return": 0.24718560084875207}
{"step": 174569, "time": 81339.42797708511, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.962604361520687, "train/action_min": 0.0, "train/action_std": 3.9726146185342137, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04437466338276863, "train/actor_opt_grad_steps": 171940.0, "train/actor_opt_loss": -13.982249223220517, "train/adv_mag": 0.5987417233382033, "train/adv_max": 0.5492518720492511, "train/adv_mean": 0.002039010547266966, "train/adv_min": -0.4705136943031365, "train/adv_std": 0.05083381101279191, "train/cont_avg": 0.9943102626173709, "train/cont_loss_mean": 2.0966596153938097e-05, "train/cont_loss_std": 0.0006552413448096659, "train/cont_neg_acc": 0.9993293095082744, "train/cont_neg_loss": 0.0025738849509314675, "train/cont_pos_acc": 0.999999980131785, "train/cont_pos_loss": 3.396107466391348e-06, "train/cont_pred": 0.9943149722238102, "train/cont_rate": 0.9943102626173709, "train/dyn_loss_mean": 3.1992785527672565, "train/dyn_loss_std": 7.891516499676055, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9711031130222088, "train/extr_critic_critic_opt_grad_steps": 171940.0, "train/extr_critic_critic_opt_loss": 14945.443171398181, "train/extr_critic_mag": 10.036488349448907, "train/extr_critic_max": 10.036488349448907, "train/extr_critic_mean": 2.22805779752597, "train/extr_critic_min": -0.6561884012580478, "train/extr_critic_std": 2.2339360893052507, "train/extr_return_normed_mag": 1.5715974709237686, "train/extr_return_normed_max": 1.5715974709237686, "train/extr_return_normed_mean": 0.3628397997416241, "train/extr_return_normed_min": -0.128186807683516, "train/extr_return_normed_std": 0.33839145988365854, "train/extr_return_rate": 0.6965434006961858, "train/extr_return_raw_mag": 10.344989187840564, "train/extr_return_raw_max": 10.344989187840564, "train/extr_return_raw_mean": 2.2417437285884447, "train/extr_return_raw_min": -1.0484849057846786, "train/extr_return_raw_std": 2.2677792764045823, "train/extr_reward_mag": 1.0147945153321458, "train/extr_reward_max": 1.0147945153321458, "train/extr_reward_mean": 0.03638300948509588, "train/extr_reward_min": -0.677558957690924, "train/extr_reward_std": 0.18606898846200934, "train/image_loss_mean": 1.6555996321736368, "train/image_loss_std": 5.270818746145902, "train/model_loss_mean": 3.648490052827647, "train/model_loss_std": 9.0597057767877, "train/model_opt_grad_norm": 30.489640240378222, "train/model_opt_grad_steps": 171799.4882629108, "train/model_opt_loss": 7086.792423158744, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1924.8826291079813, "train/policy_entropy_mag": 2.633380627967942, "train/policy_entropy_max": 2.633380627967942, "train/policy_entropy_mean": 0.5106227350346919, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.644527835185539, "train/policy_logprob_mag": 7.438384152354209, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5105725614957406, "train/policy_logprob_min": -7.438384152354209, "train/policy_logprob_std": 1.098747152957558, "train/policy_randomness_mag": 0.929467798678528, "train/policy_randomness_max": 0.929467798678528, "train/policy_randomness_mean": 0.1802274181809224, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.22749004243685048, "train/post_ent_mag": 48.7258916147438, "train/post_ent_max": 48.7258916147438, "train/post_ent_mean": 30.607714926133134, "train/post_ent_min": 14.210535524036963, "train/post_ent_std": 4.933974133970592, "train/prior_ent_mag": 76.61561312250129, "train/prior_ent_max": 76.61561312250129, "train/prior_ent_mean": 33.70058019396285, "train/prior_ent_min": 15.883871794866284, "train/prior_ent_std": 8.546632612255257, "train/rep_loss_mean": 3.1992785527672565, "train/rep_loss_std": 7.891516499676055, "train/reward_avg": 0.021773331319834565, "train/reward_loss_mean": 0.07330230857844644, "train/reward_loss_std": 0.1612500429783069, "train/reward_max_data": 1.0082922838103603, "train/reward_max_pred": 1.008078182247323, "train/reward_neg_acc": 0.9990755507084126, "train/reward_neg_loss": 0.0512759139140447, "train/reward_pos_acc": 0.9333530723209112, "train/reward_pos_loss": 0.7179961140166986, "train/reward_pred": 0.02159375400706566, "train/reward_rate": 0.033038072183098594, "train_stats/sum_log_reward": 4.966666603088379, "train_stats/max_log_achievement_collect_drink": 3.6666666666666665, "train_stats/max_log_achievement_collect_sapling": 2.0, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 3.8, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.5333333333333333, "train_stats/max_log_achievement_place_plant": 1.8666666666666667, "train_stats/max_log_achievement_place_table": 1.4, "train_stats/max_log_achievement_wake_up": 1.8666666666666667, "train_stats/mean_log_entropy": 0.5167647778987885, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 2.434703390008508e-07, "report/cont_loss_std": 1.486674136685906e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 8.2025580923073e-06, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.0441692072381556e-07, "report/cont_pred": 0.9951171278953552, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 3.0779058933258057, "report/dyn_loss_std": 7.815930366516113, "report/image_loss_mean": 1.453006625175476, "report/image_loss_std": 4.915712356567383, "report/model_loss_mean": 3.37197208404541, "report/model_loss_std": 8.650613784790039, "report/post_ent_mag": 50.39196014404297, "report/post_ent_max": 50.39196014404297, "report/post_ent_mean": 29.944507598876953, "report/post_ent_min": 12.724149703979492, "report/post_ent_std": 5.154130935668945, "report/prior_ent_mag": 76.45716857910156, "report/prior_ent_max": 76.45716857910156, "report/prior_ent_mean": 33.135868072509766, "report/prior_ent_min": 16.46459197998047, "report/prior_ent_std": 8.589286804199219, "report/rep_loss_mean": 3.0779058933258057, "report/rep_loss_std": 7.815930366516113, "report/reward_avg": 0.017122464254498482, "report/reward_loss_mean": 0.07222176343202591, "report/reward_loss_std": 0.13487201929092407, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0015218257904053, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.05284445360302925, "report/reward_pos_acc": 0.96875, "report/reward_pos_loss": 0.6729183197021484, "report/reward_pred": 0.017260156571865082, "report/reward_rate": 0.03125, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.010033464059233665, "eval/cont_loss_std": 0.22657480835914612, "eval/cont_neg_acc": 0.5, "eval/cont_neg_loss": 2.5685269832611084, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 1.5952883813952212e-07, "eval/cont_pred": 0.9980711936950684, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 23.70880126953125, "eval/dyn_loss_std": 13.390533447265625, "eval/image_loss_mean": 33.42967224121094, "eval/image_loss_std": 41.487449645996094, "eval/model_loss_mean": 47.823638916015625, "eval/model_loss_std": 46.9924201965332, "eval/post_ent_mag": 50.39196014404297, "eval/post_ent_max": 50.39196014404297, "eval/post_ent_mean": 32.84815216064453, "eval/post_ent_min": 18.20231819152832, "eval/post_ent_std": 3.751708984375, "eval/prior_ent_mag": 76.45716857910156, "eval/prior_ent_max": 76.45716857910156, "eval/prior_ent_mean": 45.270992279052734, "eval/prior_ent_min": 29.127317428588867, "eval/prior_ent_std": 6.851829528808594, "eval/rep_loss_mean": 23.70880126953125, "eval/rep_loss_std": 13.390533447265625, "eval/reward_avg": 0.02578124962747097, "eval/reward_loss_mean": 0.1586507260799408, "eval/reward_loss_std": 0.9268930554389954, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0012402534484863, "eval/reward_neg_acc": 0.9919435977935791, "eval/reward_neg_loss": 0.07787280529737473, "eval/reward_pos_acc": 0.7096773982048035, "eval/reward_pos_loss": 2.746149778366089, "eval/reward_pred": 0.022302884608507156, "eval/reward_rate": 0.0302734375, "replay/size": 174065.0, "replay/inserts": 2138.0, "replay/samples": 34208.0, "replay/insert_wait_avg": 2.576325740403835e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.629492106674095e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 34512.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 7.301568984985352e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2696118354797, "timer/env.step_count": 268.0, "timer/env.step_total": 30.243515729904175, "timer/env.step_frac": 0.03023536391794186, "timer/env.step_avg": 0.11284893929068722, "timer/env.step_min": 0.02359771728515625, "timer/env.step_max": 3.1652064323425293, "timer/replay._sample_count": 34208.0, "timer/replay._sample_total": 16.755257606506348, "timer/replay._sample_frac": 0.01675074140836959, "timer/replay._sample_avg": 0.0004898052387308918, "timer/replay._sample_min": 0.0003514289855957031, "timer/replay._sample_max": 0.04142427444458008, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 268.0, "timer/agent.policy_total": 4.226226329803467, "timer/agent.policy_frac": 0.004225087196289413, "timer/agent.policy_avg": 0.01576950123060995, "timer/agent.policy_min": 0.014664411544799805, "timer/agent.policy_max": 0.025548219680786133, "timer/dataset_train_count": 2138.0, "timer/dataset_train_total": 0.38508105278015137, "timer/dataset_train_frac": 0.0003849772583549083, "timer/dataset_train_avg": 0.0001801127468569464, "timer/dataset_train_min": 9.107589721679688e-05, "timer/dataset_train_max": 0.0028657913208007812, "timer/agent.train_count": 2138.0, "timer/agent.train_total": 954.4576344490051, "timer/agent.train_frac": 0.9542003707356357, "timer/agent.train_avg": 0.4464254604532297, "timer/agent.train_min": 0.4353139400482178, "timer/agent.train_max": 0.5773069858551025, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4780843257904053, "timer/agent.report_frac": 0.00047795546334065644, "timer/agent.report_avg": 0.23904216289520264, "timer/agent.report_min": 0.23163509368896484, "timer/agent.report_max": 0.24644923210144043, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8848648071289062e-05, "timer/dataset_eval_frac": 2.8840872230790083e-08, "timer/dataset_eval_avg": 2.8848648071289062e-05, "timer/dataset_eval_min": 2.8848648071289062e-05, "timer/dataset_eval_max": 2.8848648071289062e-05, "fps": 2.137395212974844}
{"step": 174992, "time": 81532.39037132263, "episode/length": 79.0, "episode/score": 4.185244151436564, "episode/reward_rate": 0.9375, "episode/intrinsic_return": 0.08524402864168223}
{"step": 175160, "time": 81610.14863944054, "episode/length": 185.0, "episode/score": 5.294590340886543, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.19459027909329052}
{"step": 175328, "time": 81688.38737559319, "episode/length": 189.0, "episode/score": 3.2914833099350744, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.19148318562679378}
{"step": 175432, "time": 81737.46126437187, "episode/length": 221.0, "episode/score": 7.297212790830599, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.19721259495599952}
{"step": 175632, "time": 81830.125893116, "episode/length": 159.0, "episode/score": 4.287560284072242, "episode/reward_rate": 0.95625, "episode/intrinsic_return": 0.1875601381107117}
{"step": 175680, "time": 81853.62249135971, "episode/length": 191.0, "episode/score": 4.282028867148256, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.1820287779391947}
{"step": 175744, "time": 81884.28163027763, "episode/length": 185.0, "episode/score": 7.323625225108117, "episode/reward_rate": 0.9623655913978495, "episode/intrinsic_return": 0.2236249955603853}
{"step": 175960, "time": 81984.22454619408, "episode/length": 40.0, "episode/score": 2.144579911517212, "episode/reward_rate": 0.8780487804878049, "episode/intrinsic_return": 0.04457986031775363}
{"step": 176192, "time": 82091.24807500839, "episode/length": 202.0, "episode/score": 5.290586882937987, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.19058681153319412}
{"step": 176416, "time": 82195.08600854874, "episode/length": 156.0, "episode/score": 6.25935919263793, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.15935907863240573}
{"step": 176727, "time": 82339.51783275604, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.8923681753653065, "train/action_min": 0.0, "train/action_std": 3.971631403322573, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04403671770598049, "train/actor_opt_grad_steps": 174085.0, "train/actor_opt_loss": -16.53702902297179, "train/adv_mag": 0.542061462170548, "train/adv_max": 0.4932496131018356, "train/adv_mean": 0.0015409791625205361, "train/adv_min": -0.4433514413044409, "train/adv_std": 0.051517284768461076, "train/cont_avg": 0.9941180193865741, "train/cont_loss_mean": 2.4781874482030468e-05, "train/cont_loss_std": 0.0007450833316231038, "train/cont_neg_acc": 0.9994832041651703, "train/cont_neg_loss": 0.0019127927207010058, "train/cont_pos_acc": 0.9999954350016735, "train/cont_pos_loss": 8.563004052530442e-06, "train/cont_pred": 0.9941170210087741, "train/cont_rate": 0.9941180193865741, "train/dyn_loss_mean": 3.2160364676404884, "train/dyn_loss_std": 7.913878209061092, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9884130778136077, "train/extr_critic_critic_opt_grad_steps": 174085.0, "train/extr_critic_critic_opt_loss": 15080.65037254051, "train/extr_critic_mag": 9.393237449504712, "train/extr_critic_max": 9.393237449504712, "train/extr_critic_mean": 2.1511060418906034, "train/extr_critic_min": -0.6443046568720429, "train/extr_critic_std": 2.13616125009678, "train/extr_return_normed_mag": 1.5197801479586848, "train/extr_return_normed_max": 1.5197801479586848, "train/extr_return_normed_mean": 0.35774466298796515, "train/extr_return_normed_min": -0.1219075011882793, "train/extr_return_normed_std": 0.3319080738281762, "train/extr_return_rate": 0.7071319572903492, "train/extr_return_raw_mag": 9.752390929946193, "train/extr_return_raw_max": 9.752390929946193, "train/extr_return_raw_mean": 2.161094476227407, "train/extr_return_raw_min": -0.9661012554058322, "train/extr_return_raw_std": 2.1656735947838537, "train/extr_reward_mag": 1.0136253226686407, "train/extr_reward_max": 1.0136253226686407, "train/extr_reward_mean": 0.03657643815192083, "train/extr_reward_min": -0.667321257017277, "train/extr_reward_std": 0.186502477981978, "train/image_loss_mean": 1.5859755448721073, "train/image_loss_std": 4.982052248937112, "train/model_loss_mean": 3.589127124459655, "train/model_loss_std": 8.83582721595411, "train/model_opt_grad_norm": 29.955485825185423, "train/model_opt_grad_steps": 173943.0185185185, "train/model_opt_loss": 6960.137204770689, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1932.8703703703704, "train/policy_entropy_mag": 2.6384284993012748, "train/policy_entropy_max": 2.6384284993012748, "train/policy_entropy_mean": 0.49282969989710385, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6311722744118284, "train/policy_logprob_mag": 7.438384148809645, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.49252462166327016, "train/policy_logprob_min": -7.438384148809645, "train/policy_logprob_std": 1.0877725998008694, "train/policy_randomness_mag": 0.9312494777970843, "train/policy_randomness_max": 0.9312494777970843, "train/policy_randomness_mean": 0.17394725581700052, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.2227761148026696, "train/post_ent_mag": 48.62711765148021, "train/post_ent_max": 48.62711765148021, "train/post_ent_mean": 30.73234392095495, "train/post_ent_min": 14.108707697303206, "train/post_ent_std": 4.928740109558459, "train/prior_ent_mag": 76.63066906399197, "train/prior_ent_max": 76.63066906399197, "train/prior_ent_mean": 33.8486262957255, "train/prior_ent_min": 15.918571719416866, "train/prior_ent_std": 8.573102332927563, "train/rep_loss_mean": 3.2160364676404884, "train/rep_loss_std": 7.913878209061092, "train/reward_avg": 0.022251667482864664, "train/reward_loss_mean": 0.07350492686102236, "train/reward_loss_std": 0.1588759249145234, "train/reward_max_data": 1.0077315116370167, "train/reward_max_pred": 1.0086837521305791, "train/reward_neg_acc": 0.9992513066088712, "train/reward_neg_loss": 0.05118682675270571, "train/reward_pos_acc": 0.9333923941961041, "train/reward_pos_loss": 0.7119445006052653, "train/reward_pred": 0.022135581042945246, "train/reward_rate": 0.03368688512731482, "train_stats/sum_log_reward": 4.799999928474426, "train_stats/max_log_achievement_collect_drink": 2.9, "train_stats/max_log_achievement_collect_sapling": 2.2, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 4.0, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.1, "train_stats/max_log_achievement_make_wood_pickaxe": 0.1, "train_stats/max_log_achievement_make_wood_sword": 0.4, "train_stats/max_log_achievement_place_plant": 1.9, "train_stats/max_log_achievement_place_table": 1.3, "train_stats/max_log_achievement_wake_up": 1.4, "train_stats/mean_log_entropy": 0.5254539579153061, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 2.7013487851945683e-05, "report/cont_loss_std": 8.224139310186729e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 7.62540366849862e-06, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.7127758585265838e-05, "report/cont_pred": 0.9941137433052063, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 3.0407490730285645, "report/dyn_loss_std": 7.96028470993042, "report/image_loss_mean": 1.4306315183639526, "report/image_loss_std": 3.9538989067077637, "report/model_loss_mean": 3.334495782852173, "report/model_loss_std": 7.996756076812744, "report/post_ent_mag": 50.970821380615234, "report/post_ent_max": 50.970821380615234, "report/post_ent_mean": 29.850723266601562, "report/post_ent_min": 13.414639472961426, "report/post_ent_std": 5.3322858810424805, "report/prior_ent_mag": 77.03056335449219, "report/prior_ent_max": 77.03056335449219, "report/prior_ent_mean": 32.76300048828125, "report/prior_ent_min": 13.870759963989258, "report/prior_ent_std": 8.938203811645508, "report/rep_loss_mean": 3.0407490730285645, "report/rep_loss_std": 7.96028470993042, "report/reward_avg": 0.014164025895297527, "report/reward_loss_mean": 0.07938800752162933, "report/reward_loss_std": 0.15218797326087952, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0012423992156982, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.05632759630680084, "report/reward_pos_acc": 0.9722222089767456, "report/reward_pos_loss": 0.7122681736946106, "report/reward_pred": 0.013622910715639591, "report/reward_rate": 0.03515625, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.00016822476754896343, "eval/cont_loss_std": 0.004323686007410288, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.04932738095521927, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.378064345975872e-05, "eval/cont_pred": 0.9971821904182434, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 21.59209442138672, "eval/dyn_loss_std": 13.011823654174805, "eval/image_loss_mean": 27.034912109375, "eval/image_loss_std": 34.41405487060547, "eval/model_loss_mean": 40.16923522949219, "eval/model_loss_std": 39.471778869628906, "eval/post_ent_mag": 50.970821380615234, "eval/post_ent_max": 50.970821380615234, "eval/post_ent_mean": 32.17673110961914, "eval/post_ent_min": 19.35116958618164, "eval/post_ent_std": 4.220479488372803, "eval/prior_ent_mag": 77.03056335449219, "eval/prior_ent_max": 77.03056335449219, "eval/prior_ent_mean": 42.94664764404297, "eval/prior_ent_min": 16.24335479736328, "eval/prior_ent_std": 8.389693260192871, "eval/rep_loss_mean": 21.59209442138672, "eval/rep_loss_std": 13.011823654174805, "eval/reward_avg": 0.015332031063735485, "eval/reward_loss_mean": 0.17890030145645142, "eval/reward_loss_std": 1.2095937728881836, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.001502275466919, "eval/reward_neg_acc": 0.991044819355011, "eval/reward_neg_loss": 0.10686156898736954, "eval/reward_pos_acc": 0.6842105388641357, "eval/reward_pos_loss": 3.989370346069336, "eval/reward_pred": 0.014124983921647072, "eval/reward_rate": 0.0185546875, "replay/size": 176223.0, "replay/inserts": 2158.0, "replay/samples": 34528.0, "replay/insert_wait_avg": 2.53377742961781e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.740662979571437e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 34512.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 8.046627044677734e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0741519927979, "timer/env.step_count": 269.0, "timer/env.step_total": 22.70987105369568, "timer/env.step_frac": 0.02270818719636224, "timer/env.step_avg": 0.08442331246727018, "timer/env.step_min": 0.023628711700439453, "timer/env.step_max": 1.7679293155670166, "timer/replay._sample_count": 34528.0, "timer/replay._sample_total": 16.658939599990845, "timer/replay._sample_frac": 0.016657704398014294, "timer/replay._sample_avg": 0.0004824762395734142, "timer/replay._sample_min": 0.0003509521484375, "timer/replay._sample_max": 0.024626731872558594, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 269.0, "timer/agent.policy_total": 4.318131446838379, "timer/agent.policy_frac": 0.004317811272527996, "timer/agent.policy_avg": 0.016052533259622227, "timer/agent.policy_min": 0.014545202255249023, "timer/agent.policy_max": 0.04447007179260254, "timer/dataset_train_count": 2158.0, "timer/dataset_train_total": 0.3768625259399414, "timer/dataset_train_frac": 0.00037683458290466387, "timer/dataset_train_avg": 0.00017463509079700714, "timer/dataset_train_min": 8.702278137207031e-05, "timer/dataset_train_max": 0.0005004405975341797, "timer/agent.train_count": 2158.0, "timer/agent.train_total": 962.0337047576904, "timer/agent.train_frac": 0.9619623733307114, "timer/agent.train_avg": 0.44579875104619576, "timer/agent.train_min": 0.43477344512939453, "timer/agent.train_max": 0.5916357040405273, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47450947761535645, "timer/agent.report_frac": 0.0004744742944008953, "timer/agent.report_avg": 0.23725473880767822, "timer/agent.report_min": 0.2299964427947998, "timer/agent.report_max": 0.24451303482055664, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0040740966796875e-05, "timer/dataset_eval_frac": 3.0038513551156373e-08, "timer/dataset_eval_avg": 3.0040740966796875e-05, "timer/dataset_eval_min": 3.0040740966796875e-05, "timer/dataset_eval_max": 3.0040740966796875e-05, "fps": 2.157809684587853}
{"step": 176744, "time": 82347.55525994301, "episode/length": 218.0, "episode/score": 6.339746560843878, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.2397464456742}
{"step": 176872, "time": 82407.58814239502, "episode/length": 179.0, "episode/score": 4.271006002448075, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.17100587965319392}
{"step": 176912, "time": 82427.2997148037, "episode/length": 197.0, "episode/score": 5.306451449655015, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.20645123791882725}
{"step": 176976, "time": 82458.29297995567, "episode/length": 161.0, "episode/score": 7.2731634124415905, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.17316328448805507}
{"step": 177064, "time": 82500.2724583149, "episode/length": 164.0, "episode/score": 5.265606082891281, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.16560601076616877}
{"step": 177496, "time": 82700.2774553299, "episode/length": 191.0, "episode/score": 5.300585654874112, "episode/reward_rate": 0.9583333333333334, "episode/intrinsic_return": 0.20058556374419823}
{"step": 177624, "time": 82760.95032119751, "episode/length": 178.0, "episode/score": 5.2785493653216236, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.17854934514684828}
{"step": 177976, "time": 82924.3813650608, "episode/length": 194.0, "episode/score": 6.320222073559989, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.22022189348876964}
{"step": 178016, "time": 82944.28205394745, "episode/length": 137.0, "episode/score": 4.253233863635387, "episode/reward_rate": 0.9927536231884058, "episode/intrinsic_return": 0.1532337224468847}
{"step": 178024, "time": 82949.66926980019, "episode/length": 143.0, "episode/score": 3.2369709728081943, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.13697079168923665}
{"step": 178168, "time": 83017.24390530586, "episode/length": 177.0, "episode/score": 4.288235043185068, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.188235025917038}
{"step": 178656, "time": 83242.98119497299, "episode/length": 198.0, "episode/score": 5.299163302595389, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.19916312962550364}
{"step": 178776, "time": 83299.58810329437, "episode/length": 159.0, "episode/score": 5.241423152760717, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.14142298190813563}
{"step": 178859, "time": 83339.83924174309, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.824550861484008, "train/action_min": 0.0, "train/action_std": 4.023299911212473, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.043699060509882065, "train/actor_opt_grad_steps": 176230.0, "train/actor_opt_loss": -13.365846111530988, "train/adv_mag": 0.5129283760355112, "train/adv_max": 0.4649471676965275, "train/adv_mean": 0.002688879971225413, "train/adv_min": -0.4208188345174834, "train/adv_std": 0.05016903131500656, "train/cont_avg": 0.9944615610328639, "train/cont_loss_mean": 0.00010731674129514209, "train/cont_loss_std": 0.0033530173329300132, "train/cont_neg_acc": 0.9978761465896463, "train/cont_neg_loss": 0.012165056590272354, "train/cont_pos_acc": 0.9999907360949987, "train/cont_pos_loss": 2.6993128085824354e-05, "train/cont_pred": 0.9944616424645616, "train/cont_rate": 0.9944615610328639, "train/dyn_loss_mean": 3.177903908519118, "train/dyn_loss_std": 7.867103196085899, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9810440347228252, "train/extr_critic_critic_opt_grad_steps": 176230.0, "train/extr_critic_critic_opt_loss": 15012.12148345804, "train/extr_critic_mag": 8.896271360871937, "train/extr_critic_max": 8.896271360871937, "train/extr_critic_mean": 2.2396811353208874, "train/extr_critic_min": -0.6522273994947263, "train/extr_critic_std": 2.1868582594562582, "train/extr_return_normed_mag": 1.4641967843955672, "train/extr_return_normed_max": 1.4641967843955672, "train/extr_return_normed_mean": 0.37347063380227963, "train/extr_return_normed_min": -0.11741324388225313, "train/extr_return_normed_std": 0.3395407094222279, "train/extr_return_rate": 0.7150458240173232, "train/extr_return_raw_mag": 9.393699984035582, "train/extr_return_raw_max": 9.393699984035582, "train/extr_return_raw_mean": 2.257232669933301, "train/extr_return_raw_min": -0.953549646435769, "train/extr_return_raw_std": 2.2208129441794093, "train/extr_reward_mag": 1.0161544593846854, "train/extr_reward_max": 1.0161544593846854, "train/extr_reward_mean": 0.03601983910155408, "train/extr_reward_min": -0.6701403072742229, "train/extr_reward_std": 0.18539436952049185, "train/image_loss_mean": 1.5446861937572138, "train/image_loss_std": 4.899760828331603, "train/model_loss_mean": 3.524316920920717, "train/model_loss_std": 8.71339938562241, "train/model_opt_grad_norm": 30.088164728012444, "train/model_opt_grad_steps": 176086.39436619717, "train/model_opt_loss": 9021.385604643487, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2558.6854460093896, "train/policy_entropy_mag": 2.6162195854903385, "train/policy_entropy_max": 2.6162195854903385, "train/policy_entropy_mean": 0.4782576600150883, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6140697633436588, "train/policy_logprob_mag": 7.4383841814569465, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.47856113090761393, "train/policy_logprob_min": -7.4383841814569465, "train/policy_logprob_std": 1.0783876857847114, "train/policy_randomness_mag": 0.9234107030389455, "train/policy_randomness_max": 0.9234107030389455, "train/policy_randomness_mean": 0.16880396631122196, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.21673968035570332, "train/post_ent_mag": 48.864408125899764, "train/post_ent_max": 48.864408125899764, "train/post_ent_mean": 30.772594756363702, "train/post_ent_min": 14.373386150234742, "train/post_ent_std": 4.858385962499699, "train/prior_ent_mag": 76.6631309258546, "train/prior_ent_max": 76.6631309258546, "train/prior_ent_mean": 33.856046390085716, "train/prior_ent_min": 16.338614714537428, "train/prior_ent_std": 8.472795656589275, "train/rep_loss_mean": 3.177903908519118, "train/rep_loss_std": 7.867103196085899, "train/reward_avg": 0.021509176644850785, "train/reward_loss_mean": 0.07278105740745862, "train/reward_loss_std": 0.15906189301623985, "train/reward_max_data": 1.007353316450343, "train/reward_max_pred": 1.0078284214360054, "train/reward_neg_acc": 0.9990758719578595, "train/reward_neg_loss": 0.05132479974431611, "train/reward_pos_acc": 0.9422569210540521, "train/reward_pos_loss": 0.7107005284425798, "train/reward_pred": 0.021498340409371496, "train/reward_rate": 0.032529159330985914, "train_stats/sum_log_reward": 5.023076864389273, "train_stats/max_log_achievement_collect_drink": 4.0, "train_stats/max_log_achievement_collect_sapling": 2.230769230769231, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 5.384615384615385, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.07692307692307693, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.3076923076923077, "train_stats/max_log_achievement_place_plant": 1.8461538461538463, "train_stats/max_log_achievement_place_table": 2.3076923076923075, "train_stats/max_log_achievement_wake_up": 2.0, "train_stats/mean_log_entropy": 0.4208343785542708, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 1.6059777863119962e-06, "report/cont_loss_std": 7.298247510334477e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 7.467693649232388e-05, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 1.3194248822401278e-06, "report/cont_pred": 0.9960927367210388, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 2.6923723220825195, "report/dyn_loss_std": 7.61881160736084, "report/image_loss_mean": 1.390015721321106, "report/image_loss_std": 5.052168369293213, "report/model_loss_mean": 3.070775032043457, "report/model_loss_std": 8.689419746398926, "report/post_ent_mag": 50.16447830200195, "report/post_ent_max": 50.16447830200195, "report/post_ent_mean": 31.245075225830078, "report/post_ent_min": 13.662095069885254, "report/post_ent_std": 4.677717208862305, "report/prior_ent_mag": 76.7342529296875, "report/prior_ent_max": 76.7342529296875, "report/prior_ent_mean": 33.79279327392578, "report/prior_ent_min": 15.090381622314453, "report/prior_ent_std": 8.001646995544434, "report/rep_loss_mean": 2.6923723220825195, "report/rep_loss_std": 7.61881160736084, "report/reward_avg": 0.01883508637547493, "report/reward_loss_mean": 0.06533420085906982, "report/reward_loss_std": 0.1621297001838684, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0029807090759277, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.045724011957645416, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7894584536552429, "report/reward_pred": 0.01739443838596344, "report/reward_rate": 0.0263671875, "eval/cont_avg": 0.9921875, "eval/cont_loss_mean": 0.0007880203775130212, "eval/cont_loss_std": 0.024577677249908447, "eval/cont_neg_acc": 0.875, "eval/cont_neg_loss": 0.09943997114896774, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.1233436453039758e-05, "eval/cont_pred": 0.9927168488502502, "eval/cont_rate": 0.9921875, "eval/dyn_loss_mean": 22.779253005981445, "eval/dyn_loss_std": 13.385909080505371, "eval/image_loss_mean": 37.78733444213867, "eval/image_loss_std": 42.65907287597656, "eval/model_loss_mean": 51.61648178100586, "eval/model_loss_std": 48.07328796386719, "eval/post_ent_mag": 48.432655334472656, "eval/post_ent_max": 48.432655334472656, "eval/post_ent_mean": 32.137779235839844, "eval/post_ent_min": 20.39276885986328, "eval/post_ent_std": 4.513695240020752, "eval/prior_ent_mag": 76.7342529296875, "eval/prior_ent_max": 76.7342529296875, "eval/prior_ent_mean": 42.81909942626953, "eval/prior_ent_min": 22.72088623046875, "eval/prior_ent_std": 8.132452964782715, "eval/rep_loss_mean": 22.779253005981445, "eval/rep_loss_std": 13.385909080505371, "eval/reward_avg": 0.01318359375, "eval/reward_loss_mean": 0.16080926358699799, "eval/reward_loss_std": 0.8294277191162109, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0017826557159424, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.10677458345890045, "eval/reward_pos_acc": 0.699999988079071, "eval/reward_pos_loss": 2.8733513355255127, "eval/reward_pred": 0.006348630879074335, "eval/reward_rate": 0.01953125, "replay/size": 178355.0, "replay/inserts": 2132.0, "replay/samples": 34112.0, "replay/insert_wait_avg": 2.5935289336413874e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.710442310426293e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 34512.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 8.642673492431641e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3043878078461, "timer/env.step_count": 267.0, "timer/env.step_total": 27.468384981155396, "timer/env.step_frac": 0.02746002648389057, "timer/env.step_avg": 0.10287784637136853, "timer/env.step_min": 0.02442145347595215, "timer/env.step_max": 1.74009370803833, "timer/replay._sample_count": 34112.0, "timer/replay._sample_total": 16.754154443740845, "timer/replay._sample_frac": 0.016749056235229914, "timer/replay._sample_avg": 0.0004911513380552546, "timer/replay._sample_min": 0.00036787986755371094, "timer/replay._sample_max": 0.029103755950927734, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 267.0, "timer/agent.policy_total": 4.3232421875, "timer/agent.policy_frac": 0.004321926645722637, "timer/agent.policy_avg": 0.016191918305243445, "timer/agent.policy_min": 0.014731168746948242, "timer/agent.policy_max": 0.02395319938659668, "timer/dataset_train_count": 2132.0, "timer/dataset_train_total": 0.4087526798248291, "timer/dataset_train_frac": 0.0004086282983528696, "timer/dataset_train_avg": 0.0001917226453212144, "timer/dataset_train_min": 9.584426879882812e-05, "timer/dataset_train_max": 0.0009479522705078125, "timer/agent.train_count": 2132.0, "timer/agent.train_total": 956.292298078537, "timer/agent.train_frac": 0.9560013029376379, "timer/agent.train_avg": 0.4485423536953738, "timer/agent.train_min": 0.4362609386444092, "timer/agent.train_max": 0.6035692691802979, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4750332832336426, "timer/agent.report_frac": 0.0004748887328932664, "timer/agent.report_avg": 0.2375166416168213, "timer/agent.report_min": 0.23040080070495605, "timer/agent.report_max": 0.24463248252868652, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.1948089599609375e-05, "timer/dataset_eval_frac": 3.193836794980295e-08, "timer/dataset_eval_avg": 3.1948089599609375e-05, "timer/dataset_eval_min": 3.1948089599609375e-05, "timer/dataset_eval_max": 3.1948089599609375e-05, "fps": 2.131320177450952}
{"step": 179008, "time": 83408.37894749641, "episode/length": 253.0, "episode/score": 5.366909139486097, "episode/reward_rate": 0.9803149606299213, "episode/intrinsic_return": 0.26690903408803024}
{"step": 179096, "time": 83450.32089042664, "episode/length": 139.0, "episode/score": 4.205291548481455, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.10529138977244656}
{"step": 179192, "time": 83495.85794210434, "episode/length": 146.0, "episode/score": 4.272508125790182, "episode/reward_rate": 0.9659863945578231, "episode/intrinsic_return": 0.1725079728437322}
{"step": 179200, "time": 83501.22916841507, "episode/length": 146.0, "episode/score": 5.244420698662907, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.1444207580143484}
{"step": 179624, "time": 83697.56294465065, "episode/length": 249.0, "episode/score": 6.36290364097249, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.26290355630362683}
{"step": 179672, "time": 83721.16487765312, "episode/length": 187.0, "episode/score": 4.317463225179154, "episode/reward_rate": 0.9680851063829787, "episode/intrinsic_return": 0.21746307908665585}
{"step": 180024, "time": 83902.89004540443, "eval_episode/length": 140.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9574468085106383}
{"step": 180024, "time": 83905.33638119698, "eval_episode/length": 161.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9691358024691358}
{"step": 180024, "time": 83906.88815617561, "eval_episode/length": 163.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9695121951219512}
{"step": 180024, "time": 83908.45311236382, "eval_episode/length": 164.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9757575757575757}
{"step": 180024, "time": 83908.46035051346, "eval_episode/length": 164.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9636363636363636}
{"step": 180024, "time": 83912.08896398544, "eval_episode/length": 176.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9774011299435028}
{"step": 180024, "time": 83914.70063757896, "eval_episode/length": 201.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9702970297029703}
{"step": 180024, "time": 83916.26036167145, "eval_episode/length": 202.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9753694581280788}
{"step": 180216, "time": 84004.27467346191, "episode/length": 150.0, "episode/score": 4.255048023016343, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.15504786890573996}
{"step": 180672, "time": 84216.02959084511, "episode/length": 184.0, "episode/score": 3.2566209042338414, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.15662078225386722}
{"step": 180752, "time": 84254.4449493885, "episode/length": 193.0, "episode/score": 5.258178909952676, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.1581787272039037}
{"step": 180934, "time": 84339.89711904526, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.904905759371244, "train/action_min": 0.0, "train/action_std": 4.063982972731957, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04717659703993167, "train/actor_opt_grad_steps": 178335.0, "train/actor_opt_loss": -13.911430576959482, "train/adv_mag": 0.69344236372182, "train/adv_max": 0.6359199309864869, "train/adv_mean": 0.0027730695502179094, "train/adv_min": -0.5410569257174547, "train/adv_std": 0.05468445065288016, "train/cont_avg": 0.9942110501802884, "train/cont_loss_mean": 3.817907624994796e-05, "train/cont_loss_std": 0.001192212757825354, "train/cont_neg_acc": 0.9995192309411672, "train/cont_neg_loss": 0.002925207656239501, "train/cont_pos_acc": 0.9999952545532813, "train/cont_pos_loss": 1.0581669576126274e-05, "train/cont_pred": 0.99420924570698, "train/cont_rate": 0.9942110501802884, "train/dyn_loss_mean": 3.1961379945278168, "train/dyn_loss_std": 7.8561620597655955, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0101112207541099, "train/extr_critic_critic_opt_grad_steps": 178335.0, "train/extr_critic_critic_opt_loss": 15081.355604905348, "train/extr_critic_mag": 11.221724739441505, "train/extr_critic_max": 11.221724739441505, "train/extr_critic_mean": 2.4236092813886128, "train/extr_critic_min": -0.6583933692712051, "train/extr_critic_std": 2.4015011873382788, "train/extr_return_normed_mag": 1.7079962572226157, "train/extr_return_normed_max": 1.7079962572226157, "train/extr_return_normed_mean": 0.3811593666815987, "train/extr_return_normed_min": -0.11530162761202799, "train/extr_return_normed_std": 0.35344579400351417, "train/extr_return_rate": 0.7287153598780816, "train/extr_return_raw_mag": 11.643865913152695, "train/extr_return_raw_max": 11.643865913152695, "train/extr_return_raw_mean": 2.4428684344658484, "train/extr_return_raw_min": -0.9904849572250476, "train/extr_return_raw_std": 2.4476727596842327, "train/extr_reward_mag": 1.020913567680579, "train/extr_reward_max": 1.020913567680579, "train/extr_reward_mean": 0.037877132811655216, "train/extr_reward_min": -0.680258778998485, "train/extr_reward_std": 0.1902279265654775, "train/image_loss_mean": 1.5312833373363202, "train/image_loss_std": 4.806428226140829, "train/model_loss_mean": 3.5223082258151126, "train/model_loss_std": 8.616079110365648, "train/model_opt_grad_norm": 30.602403943355267, "train/model_opt_grad_steps": 178189.33653846153, "train/model_opt_loss": 8941.652940016527, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2536.0576923076924, "train/policy_entropy_mag": 2.624643299442071, "train/policy_entropy_max": 2.624643299442071, "train/policy_entropy_mean": 0.481931561174301, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6120996187226131, "train/policy_logprob_mag": 7.438384184470544, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.4824685730899756, "train/policy_logprob_min": -7.438384184470544, "train/policy_logprob_std": 1.079226698153294, "train/policy_randomness_mag": 0.926383904253061, "train/policy_randomness_max": 0.926383904253061, "train/policy_randomness_mean": 0.1701006919790346, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.21604430446257958, "train/post_ent_mag": 49.2662361401778, "train/post_ent_max": 49.2662361401778, "train/post_ent_mean": 30.97714277414175, "train/post_ent_min": 14.388407895198235, "train/post_ent_std": 4.920266188108004, "train/prior_ent_mag": 76.59661564460167, "train/prior_ent_max": 76.59661564460167, "train/prior_ent_mean": 34.074107518562904, "train/prior_ent_min": 16.483381972863125, "train/prior_ent_std": 8.516887208590141, "train/rep_loss_mean": 3.1961379945278168, "train/rep_loss_std": 7.8561620597655955, "train/reward_avg": 0.022271450886574503, "train/reward_loss_mean": 0.07330392447945017, "train/reward_loss_std": 0.1592827524918203, "train/reward_max_data": 1.0075000301003456, "train/reward_max_pred": 1.008157024016747, "train/reward_neg_acc": 0.9992327220164813, "train/reward_neg_loss": 0.05103731764337191, "train/reward_pos_acc": 0.9347865770642574, "train/reward_pos_loss": 0.7156457562859242, "train/reward_pred": 0.02214885439025238, "train/reward_rate": 0.033517690805288464, "train_stats/sum_log_reward": 4.544444296095106, "train_stats/max_log_achievement_collect_drink": 3.6666666666666665, "train_stats/max_log_achievement_collect_sapling": 2.7777777777777777, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 3.3333333333333335, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.1111111111111111, "train_stats/max_log_achievement_place_plant": 2.5555555555555554, "train_stats/max_log_achievement_place_table": 1.2222222222222223, "train_stats/max_log_achievement_wake_up": 1.7777777777777777, "train_stats/mean_log_entropy": 0.5341705878575643, "eval_stats/sum_log_reward": 4.599999904632568, "eval_stats/max_log_achievement_collect_drink": 4.0, "eval_stats/max_log_achievement_collect_sapling": 1.125, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 3.0, "eval_stats/max_log_achievement_defeat_skeleton": 0.125, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.25, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.125, "eval_stats/max_log_achievement_place_plant": 1.125, "eval_stats/max_log_achievement_place_table": 1.375, "eval_stats/max_log_achievement_wake_up": 1.75, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 1.2464510064091883e-06, "report/cont_loss_std": 2.66400402324507e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 4.686536613007775e-06, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.2295713531784713e-06, "report/cont_pred": 0.9951160550117493, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 3.1022796630859375, "report/dyn_loss_std": 7.710511684417725, "report/image_loss_mean": 1.7524099349975586, "report/image_loss_std": 8.381031036376953, "report/model_loss_mean": 3.6821694374084473, "report/model_loss_std": 11.864269256591797, "report/post_ent_mag": 47.896942138671875, "report/post_ent_max": 47.896942138671875, "report/post_ent_mean": 29.90909767150879, "report/post_ent_min": 15.994762420654297, "report/post_ent_std": 4.784456729888916, "report/prior_ent_mag": 77.10067749023438, "report/prior_ent_max": 77.10067749023438, "report/prior_ent_mean": 33.106658935546875, "report/prior_ent_min": 20.483308792114258, "report/prior_ent_std": 8.301562309265137, "report/rep_loss_mean": 3.1022796630859375, "report/rep_loss_std": 7.710511684417725, "report/reward_avg": 0.0216046255081892, "report/reward_loss_mean": 0.06839045882225037, "report/reward_loss_std": 0.14256905019283295, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0018219947814941, "report/reward_neg_acc": 0.9989939332008362, "report/reward_neg_loss": 0.04898763820528984, "report/reward_pos_acc": 0.9666666984558105, "report/reward_pos_loss": 0.7112705111503601, "report/reward_pred": 0.02151447720825672, "report/reward_rate": 0.029296875, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 5.7039422244997695e-05, "eval/cont_loss_std": 0.001378693850710988, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.01917656511068344, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 8.60599300267495e-07, "eval/cont_pred": 0.9971247911453247, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 24.818504333496094, "eval/dyn_loss_std": 14.724844932556152, "eval/image_loss_mean": 42.03071594238281, "eval/image_loss_std": 63.83707046508789, "eval/model_loss_mean": 57.09307098388672, "eval/model_loss_std": 69.7071762084961, "eval/post_ent_mag": 44.989402770996094, "eval/post_ent_max": 44.989402770996094, "eval/post_ent_mean": 32.69276428222656, "eval/post_ent_min": 20.42765998840332, "eval/post_ent_std": 4.360940933227539, "eval/prior_ent_mag": 77.10067749023438, "eval/prior_ent_max": 77.10067749023438, "eval/prior_ent_mean": 45.3741340637207, "eval/prior_ent_min": 26.331968307495117, "eval/prior_ent_std": 7.422733306884766, "eval/rep_loss_mean": 24.818504333496094, "eval/rep_loss_std": 14.724844932556152, "eval/reward_avg": 0.0244140625, "eval/reward_loss_mean": 0.17119406163692474, "eval/reward_loss_std": 1.0738142728805542, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0016586780548096, "eval/reward_neg_acc": 0.9979899525642395, "eval/reward_neg_loss": 0.05366711691021919, "eval/reward_pos_acc": 0.517241358757019, "eval/reward_pos_loss": 4.203583717346191, "eval/reward_pred": 0.011454153805971146, "eval/reward_rate": 0.0283203125, "replay/size": 180430.0, "replay/inserts": 2075.0, "replay/samples": 33200.0, "replay/insert_wait_avg": 2.5866405073418676e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.569359009524426e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 36136.0, "eval_replay/inserts": 1624.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2129398402322102e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.599592208862305e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0445084571838, "timer/env.step_count": 259.0, "timer/env.step_total": 21.17508101463318, "timer/env.step_frac": 0.021174138586392503, "timer/env.step_avg": 0.08175706955456825, "timer/env.step_min": 0.023911476135253906, "timer/env.step_max": 1.7152752876281738, "timer/replay._sample_count": 33200.0, "timer/replay._sample_total": 16.31003212928772, "timer/replay._sample_frac": 0.016309306227229807, "timer/replay._sample_avg": 0.000491266027990594, "timer/replay._sample_min": 0.00035500526428222656, "timer/replay._sample_max": 0.019427776336669922, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 462.0, "timer/agent.policy_total": 7.512019157409668, "timer/agent.policy_frac": 0.007511684823907305, "timer/agent.policy_avg": 0.016259781725994953, "timer/agent.policy_min": 0.009569406509399414, "timer/agent.policy_max": 0.04079246520996094, "timer/dataset_train_count": 2075.0, "timer/dataset_train_total": 0.4047238826751709, "timer/dataset_train_frac": 0.000404705869841291, "timer/dataset_train_avg": 0.00019504765430128717, "timer/dataset_train_min": 0.00010013580322265625, "timer/dataset_train_max": 0.000522613525390625, "timer/agent.train_count": 2075.0, "timer/agent.train_total": 930.8754470348358, "timer/agent.train_frac": 0.9308340170488427, "timer/agent.train_avg": 0.44861467326980037, "timer/agent.train_min": 0.4388391971588135, "timer/agent.train_max": 0.5997657775878906, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4771242141723633, "timer/agent.report_frac": 0.00047710297905484775, "timer/agent.report_avg": 0.23856210708618164, "timer/agent.report_min": 0.2317514419555664, "timer/agent.report_max": 0.24537277221679688, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8133392333984375e-05, "timer/dataset_eval_frac": 2.8132140215826088e-08, "timer/dataset_eval_avg": 2.8133392333984375e-05, "timer/dataset_eval_min": 2.8133392333984375e-05, "timer/dataset_eval_max": 2.8133392333984375e-05, "fps": 2.0748793545599296}
{"step": 180992, "time": 84366.75349736214, "episode/length": 236.0, "episode/score": 5.336482856708926, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.23648264699545507}
{"step": 181008, "time": 84375.63948774338, "episode/length": 278.0, "episode/score": 5.399584810682654, "episode/reward_rate": 0.985663082437276, "episode/intrinsic_return": 0.2995847233362383}
{"step": 181200, "time": 84465.44768357277, "episode/length": 190.0, "episode/score": 5.287769658939396, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.18776947738388117}
{"step": 181256, "time": 84492.5763771534, "episode/length": 203.0, "episode/score": 5.285953106828174, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.18595311035846862}
{"step": 181328, "time": 84527.34070849419, "episode/length": 138.0, "episode/score": 3.233072923071404, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.13307276736009044}
{"step": 181696, "time": 84697.79247188568, "episode/length": 379.0, "episode/score": 4.519201590602961, "episode/reward_rate": 0.9921052631578947, "episode/intrinsic_return": 0.41920145826202315}
{"step": 182296, "time": 84975.2507174015, "episode/length": 160.0, "episode/score": 4.265848038666263, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.16584787842930382}
{"step": 182344, "time": 84998.67915391922, "episode/length": 198.0, "episode/score": 5.300867804529389, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.20086765309633847}
{"step": 182400, "time": 85025.82981967926, "episode/length": 149.0, "episode/score": 4.239995213069051, "episode/reward_rate": 0.96, "episode/intrinsic_return": 0.13999508742199396}
{"step": 182480, "time": 85063.94458222389, "episode/length": 225.0, "episode/score": 6.348799291556361, "episode/reward_rate": 0.9778761061946902, "episode/intrinsic_return": 0.24879914085454402}
{"step": 182528, "time": 85087.44683432579, "episode/length": 149.0, "episode/score": 2.2744858514288353, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.17448575575872383}
{"step": 182656, "time": 85147.39935731888, "episode/length": 174.0, "episode/score": 5.292930813512157, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.19293075177711216}
{"step": 182792, "time": 85211.04992723465, "episode/length": 224.0, "episode/score": 5.334622084397552, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.2346218749896707}
{"step": 182952, "time": 85285.97243714333, "episode/length": 58.0, "episode/score": 3.157231278180234, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.057231296306099466}
{"step": 183066, "time": 85340.30003714561, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.986481142715669, "train/action_min": 0.0, "train/action_std": 4.117074458252096, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.045280996202862876, "train/actor_opt_grad_steps": 180440.0, "train/actor_opt_loss": -15.106947079091006, "train/adv_mag": 0.5699286302770248, "train/adv_max": 0.5072021084212361, "train/adv_mean": 0.0017336830298343112, "train/adv_min": -0.48050526078318206, "train/adv_std": 0.04997247291352827, "train/cont_avg": 0.994264414612676, "train/cont_loss_mean": 1.1694465612009841e-05, "train/cont_loss_std": 0.00035409737593804203, "train/cont_neg_acc": 1.0, "train/cont_neg_loss": 0.0002231628878316426, "train/cont_pos_acc": 0.9999953695865864, "train/cont_pos_loss": 1.0503145393364533e-05, "train/cont_pred": 0.9942600637534414, "train/cont_rate": 0.994264414612676, "train/dyn_loss_mean": 3.1880348724938337, "train/dyn_loss_std": 7.889577429059526, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0115564630624834, "train/extr_critic_critic_opt_grad_steps": 180440.0, "train/extr_critic_critic_opt_loss": 15173.341916079813, "train/extr_critic_mag": 10.648485819498697, "train/extr_critic_max": 10.648485819498697, "train/extr_critic_mean": 2.4092664449987278, "train/extr_critic_min": -0.6652529637018839, "train/extr_critic_std": 2.484414511443304, "train/extr_return_normed_mag": 1.5293059304286616, "train/extr_return_normed_max": 1.5293059304286616, "train/extr_return_normed_mean": 0.3599440202186925, "train/extr_return_normed_min": -0.10912542940585267, "train/extr_return_normed_std": 0.34530496303464325, "train/extr_return_rate": 0.6912607947985331, "train/extr_return_raw_mag": 10.953270056997667, "train/extr_return_raw_max": 10.953270056997667, "train/extr_return_raw_mean": 2.421911044299882, "train/extr_return_raw_min": -0.9852037678861842, "train/extr_return_raw_std": 2.511945581771958, "train/extr_reward_mag": 1.025235910370876, "train/extr_reward_max": 1.025235910370876, "train/extr_reward_mean": 0.03503455199790952, "train/extr_reward_min": -0.6871035759437811, "train/extr_reward_std": 0.18331857053606723, "train/image_loss_mean": 1.5861857063333753, "train/image_loss_std": 4.921524850415512, "train/model_loss_mean": 3.572658881335191, "train/model_loss_std": 8.758005195940045, "train/model_opt_grad_norm": 29.79218970553976, "train/model_opt_grad_steps": 180292.25352112675, "train/model_opt_loss": 8974.82850783084, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2523.474178403756, "train/policy_entropy_mag": 2.613144253341245, "train/policy_entropy_max": 2.613144253341245, "train/policy_entropy_mean": 0.507657849732699, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6378364999529341, "train/policy_logprob_mag": 7.438384138922176, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5081094862989417, "train/policy_logprob_min": -7.438384138922176, "train/policy_logprob_std": 1.0977468845989782, "train/policy_randomness_mag": 0.9223252478899531, "train/policy_randomness_max": 0.9223252478899531, "train/policy_randomness_mean": 0.17918094202106546, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.22512829436662612, "train/post_ent_mag": 49.60422435276945, "train/post_ent_max": 49.60422435276945, "train/post_ent_mean": 31.058193860479363, "train/post_ent_min": 14.206033648459565, "train/post_ent_std": 4.964347466616563, "train/prior_ent_mag": 76.71203047344942, "train/prior_ent_max": 76.71203047344942, "train/prior_ent_mean": 34.14630184263131, "train/prior_ent_min": 16.26785555467919, "train/prior_ent_std": 8.53286376693439, "train/rep_loss_mean": 3.1880348724938337, "train/rep_loss_std": 7.889577429059526, "train/reward_avg": 0.02128773180007095, "train/reward_loss_mean": 0.07364055003638559, "train/reward_loss_std": 0.16076713044878463, "train/reward_max_data": 1.0125176369304387, "train/reward_max_pred": 1.0121372216184374, "train/reward_neg_acc": 0.9992123559607027, "train/reward_neg_loss": 0.05168137192166467, "train/reward_pos_acc": 0.9321292437298198, "train/reward_pos_loss": 0.7176600915725242, "train/reward_pred": 0.021109816884980516, "train/reward_rate": 0.032950960974178406, "train_stats/sum_log_reward": 4.457142795835223, "train_stats/max_log_achievement_collect_drink": 2.357142857142857, "train_stats/max_log_achievement_collect_sapling": 1.7142857142857142, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 5.071428571428571, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.5714285714285714, "train_stats/max_log_achievement_place_plant": 1.4285714285714286, "train_stats/max_log_achievement_place_table": 2.0, "train_stats/max_log_achievement_wake_up": 2.357142857142857, "train_stats/mean_log_entropy": 0.5222376052822385, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.0005556161049753428, "report/cont_loss_std": 0.017743483185768127, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 7.13628287485335e-06, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0005577670526690781, "report/cont_pred": 0.9956698417663574, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 3.9973249435424805, "report/dyn_loss_std": 8.04744815826416, "report/image_loss_mean": 1.9368969202041626, "report/image_loss_std": 3.808053731918335, "report/model_loss_mean": 4.407131195068359, "report/model_loss_std": 7.739348888397217, "report/post_ent_mag": 50.82962417602539, "report/post_ent_max": 50.82962417602539, "report/post_ent_mean": 31.952720642089844, "report/post_ent_min": 11.628236770629883, "report/post_ent_std": 5.81305456161499, "report/prior_ent_mag": 76.51377868652344, "report/prior_ent_max": 76.51377868652344, "report/prior_ent_mean": 35.83230972290039, "report/prior_ent_min": 13.71613883972168, "report/prior_ent_std": 9.199214935302734, "report/rep_loss_mean": 3.9973249435424805, "report/rep_loss_std": 8.04744815826416, "report/reward_avg": 0.015470183454453945, "report/reward_loss_mean": 0.071283720433712, "report/reward_loss_std": 0.2062845081090927, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.001814365386963, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.05209462717175484, "report/reward_pos_acc": 0.8799999952316284, "report/reward_pos_loss": 0.8380796909332275, "report/reward_pred": 0.014751503244042397, "report/reward_rate": 0.0244140625, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.0016973194433376193, "eval/cont_loss_std": 0.04772279039025307, "eval/cont_neg_acc": 0.800000011920929, "eval/cont_neg_loss": 0.34739434719085693, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.062914293470385e-06, "eval/cont_pred": 0.9960748553276062, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 21.614931106567383, "eval/dyn_loss_std": 12.9251127243042, "eval/image_loss_mean": 33.10169982910156, "eval/image_loss_std": 42.23988342285156, "eval/model_loss_mean": 46.24481964111328, "eval/model_loss_std": 46.97846603393555, "eval/post_ent_mag": 50.82962417602539, "eval/post_ent_max": 50.82962417602539, "eval/post_ent_mean": 33.82883071899414, "eval/post_ent_min": 18.753955841064453, "eval/post_ent_std": 4.7264604568481445, "eval/prior_ent_mag": 76.51377868652344, "eval/prior_ent_max": 76.51377868652344, "eval/prior_ent_mean": 44.165794372558594, "eval/prior_ent_min": 19.813596725463867, "eval/prior_ent_std": 8.21049690246582, "eval/rep_loss_mean": 21.614931106567383, "eval/rep_loss_std": 12.9251127243042, "eval/reward_avg": 0.02119140699505806, "eval/reward_loss_mean": 0.17246557772159576, "eval/reward_loss_std": 1.1144027709960938, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 1.0028116703033447, "eval/reward_neg_acc": 0.9979940056800842, "eval/reward_neg_loss": 0.0471419133245945, "eval/reward_pos_acc": 0.5555555820465088, "eval/reward_pos_loss": 4.8001580238342285, "eval/reward_pred": 0.011338751763105392, "eval/reward_rate": 0.0263671875, "replay/size": 182562.0, "replay/inserts": 2132.0, "replay/samples": 34112.0, "replay/insert_wait_avg": 2.5397393761611566e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.496150752169554e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 36136.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 7.599592208862305e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3932092189789, "timer/env.step_count": 267.0, "timer/env.step_total": 28.610081672668457, "timer/env.step_frac": 0.028598836346564918, "timer/env.step_avg": 0.10715386394257849, "timer/env.step_min": 0.02360844612121582, "timer/env.step_max": 1.8235046863555908, "timer/replay._sample_count": 34112.0, "timer/replay._sample_total": 16.849116563796997, "timer/replay._sample_frac": 0.01684249393990923, "timer/replay._sample_avg": 0.0004939351713120602, "timer/replay._sample_min": 0.00036597251892089844, "timer/replay._sample_max": 0.039650678634643555, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 267.0, "timer/agent.policy_total": 4.264416694641113, "timer/agent.policy_frac": 0.004262740545760405, "timer/agent.policy_avg": 0.01597159810727009, "timer/agent.policy_min": 0.014743804931640625, "timer/agent.policy_max": 0.048096418380737305, "timer/dataset_train_count": 2132.0, "timer/dataset_train_total": 0.41818881034851074, "timer/dataset_train_frac": 0.0004180244392852253, "timer/dataset_train_avg": 0.0001961485977244422, "timer/dataset_train_min": 0.00010037422180175781, "timer/dataset_train_max": 0.0008099079132080078, "timer/agent.train_count": 2132.0, "timer/agent.train_total": 955.3426847457886, "timer/agent.train_frac": 0.9549671828456714, "timer/agent.train_avg": 0.4480969440646288, "timer/agent.train_min": 0.435896635055542, "timer/agent.train_max": 0.590996265411377, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4772815704345703, "timer/agent.report_frac": 0.00047709397268619086, "timer/agent.report_avg": 0.23864078521728516, "timer/agent.report_min": 0.2314927577972412, "timer/agent.report_max": 0.2457888126373291, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.5987625122070312e-05, "timer/dataset_eval_frac": 2.597741056475105e-08, "timer/dataset_eval_avg": 2.5987625122070312e-05, "timer/dataset_eval_min": 2.5987625122070312e-05, "timer/dataset_eval_max": 2.5987625122070312e-05, "fps": 2.131133634514218}
{"step": 183424, "time": 85504.66348385811, "episode/length": 215.0, "episode/score": 3.314055903860435, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.21405585821980821}
{"step": 183640, "time": 85604.77765059471, "episode/length": 154.0, "episode/score": 5.24866647452086, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.14866623612556396}
{"step": 183648, "time": 85609.89754247665, "episode/length": 168.0, "episode/score": 5.271169067606934, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.17116888602231484}
{"step": 183800, "time": 85681.33325791359, "episode/length": 181.0, "episode/score": 5.283414668794649, "episode/reward_rate": 0.967032967032967, "episode/intrinsic_return": 0.18341453691937204}
{"step": 184096, "time": 85818.60064721107, "episode/length": 162.0, "episode/score": 5.266115303775905, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.16611515234285434}
{"step": 184104, "time": 85823.71356964111, "episode/length": 180.0, "episode/score": 5.2846438506928735, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.1846436980956696}
{"step": 184224, "time": 85880.10054707527, "episode/length": 211.0, "episode/score": 6.316648056264739, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.21664778923127415}
{"step": 184592, "time": 86049.8030359745, "episode/length": 204.0, "episode/score": 5.312893673801682, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.21289354896953228}
{"step": 184816, "time": 86153.53536987305, "episode/length": 173.0, "episode/score": 4.290067140792189, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.19006701144894578}
{"step": 185222, "time": 86340.35176467896, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.823574772587529, "train/action_min": 0.0, "train/action_std": 3.9531422908659333, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0409099526565384, "train/actor_opt_grad_steps": 182585.0, "train/actor_opt_loss": -14.367756385218215, "train/adv_mag": 0.49600226970182526, "train/adv_max": 0.426252083921874, "train/adv_mean": 0.0016260564398180577, "train/adv_min": -0.4235299545581694, "train/adv_std": 0.04735558259266394, "train/cont_avg": 0.9942310474537037, "train/cont_loss_mean": 4.642178149583532e-05, "train/cont_loss_std": 0.001455724634263294, "train/cont_neg_acc": 0.9988756618565984, "train/cont_neg_loss": 0.0020971219513891506, "train/cont_pos_acc": 0.9999863124556012, "train/cont_pos_loss": 2.9862456942282206e-05, "train/cont_pred": 0.9942261402805647, "train/cont_rate": 0.9942310474537037, "train/dyn_loss_mean": 3.202865536566134, "train/dyn_loss_std": 7.925917640880302, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0073148688232456, "train/extr_critic_critic_opt_grad_steps": 182585.0, "train/extr_critic_critic_opt_loss": 15076.295247395834, "train/extr_critic_mag": 9.108397589789497, "train/extr_critic_max": 9.108397589789497, "train/extr_critic_mean": 2.3303386999501123, "train/extr_critic_min": -0.6658105232097484, "train/extr_critic_std": 2.3211429913838706, "train/extr_return_normed_mag": 1.4385747015476227, "train/extr_return_normed_max": 1.4385747015476227, "train/extr_return_normed_mean": 0.3663844617290629, "train/extr_return_normed_min": -0.12292303313949594, "train/extr_return_normed_std": 0.3372600721540274, "train/extr_return_rate": 0.6917941996620761, "train/extr_return_raw_mag": 9.795844769036329, "train/extr_return_raw_max": 9.795844769036329, "train/extr_return_raw_mean": 2.3415396053481987, "train/extr_return_raw_min": -1.062608129448361, "train/extr_return_raw_std": 2.3460643539826074, "train/extr_reward_mag": 1.0227353197556954, "train/extr_reward_max": 1.0227353197556954, "train/extr_reward_mean": 0.03607404471754476, "train/extr_reward_min": -0.6781406242538381, "train/extr_reward_std": 0.1853979730081779, "train/image_loss_mean": 1.570987187050007, "train/image_loss_std": 4.882090106054589, "train/model_loss_mean": 3.566708855054997, "train/model_loss_std": 8.746719362559142, "train/model_opt_grad_norm": 29.675455066892837, "train/model_opt_grad_steps": 182435.13888888888, "train/model_opt_loss": 9024.70979365596, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2534.722222222222, "train/policy_entropy_mag": 2.6280315121014914, "train/policy_entropy_max": 2.6280315121014914, "train/policy_entropy_mean": 0.48621520151694614, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6235914851228396, "train/policy_logprob_mag": 7.4383841554323835, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.4854297952519523, "train/policy_logprob_min": -7.4383841554323835, "train/policy_logprob_std": 1.0811205280047875, "train/policy_randomness_mag": 0.9275797958727237, "train/policy_randomness_max": 0.9275797958727237, "train/policy_randomness_mean": 0.17161262856313475, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.22010042952994505, "train/post_ent_mag": 48.93710305955675, "train/post_ent_max": 48.93710305955675, "train/post_ent_mean": 31.27591104860659, "train/post_ent_min": 14.453613020755627, "train/post_ent_std": 4.968362963861889, "train/prior_ent_mag": 76.70940123664008, "train/prior_ent_max": 76.70940123664008, "train/prior_ent_mean": 34.363652529539884, "train/prior_ent_min": 16.404365217244184, "train/prior_ent_std": 8.4967120135272, "train/rep_loss_mean": 3.202865536566134, "train/rep_loss_std": 7.925917640880302, "train/reward_avg": 0.021956827506612712, "train/reward_loss_mean": 0.07395594137617284, "train/reward_loss_std": 0.16066692369403662, "train/reward_max_data": 1.0063426224169907, "train/reward_max_pred": 1.0068869844630912, "train/reward_neg_acc": 0.9991905788580576, "train/reward_neg_loss": 0.051497677651544414, "train/reward_pos_acc": 0.9288589242431853, "train/reward_pos_loss": 0.721346599912202, "train/reward_pred": 0.02176715899258852, "train/reward_rate": 0.03356481481481482, "train_stats/sum_log_reward": 4.877777682410346, "train_stats/max_log_achievement_collect_drink": 4.222222222222222, "train_stats/max_log_achievement_collect_sapling": 1.8888888888888888, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 3.5555555555555554, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.2222222222222222, "train_stats/max_log_achievement_place_plant": 1.3333333333333333, "train_stats/max_log_achievement_place_table": 1.3333333333333333, "train_stats/max_log_achievement_wake_up": 2.0, "train_stats/mean_log_entropy": 0.48696526222758824, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 4.1126304495264776e-07, "report/cont_loss_std": 4.848456569561677e-07, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 3.3173755582538433e-06, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 3.9413467334270536e-07, "report/cont_pred": 0.9941403865814209, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 3.107386589050293, "report/dyn_loss_std": 7.63553524017334, "report/image_loss_mean": 1.0868375301361084, "report/image_loss_std": 3.814748525619507, "report/model_loss_mean": 3.020853281021118, "report/model_loss_std": 7.401947975158691, "report/post_ent_mag": 48.88038635253906, "report/post_ent_max": 48.88038635253906, "report/post_ent_mean": 31.736602783203125, "report/post_ent_min": 14.235112190246582, "report/post_ent_std": 4.761181831359863, "report/prior_ent_mag": 76.83191680908203, "report/prior_ent_max": 76.83191680908203, "report/prior_ent_mean": 34.80757141113281, "report/prior_ent_min": 17.43975067138672, "report/prior_ent_std": 8.3215913772583, "report/rep_loss_mean": 3.107386589050293, "report/rep_loss_std": 7.63553524017334, "report/reward_avg": 0.022958839312195778, "report/reward_loss_mean": 0.06958340108394623, "report/reward_loss_std": 0.13791650533676147, "report/reward_max_data": 1.0012500286102295, "report/reward_max_pred": 1.0030276775360107, "report/reward_neg_acc": 0.9959554076194763, "report/reward_neg_loss": 0.04819237440824509, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6740325689315796, "report/reward_pred": 0.023858115077018738, "report/reward_rate": 0.0341796875, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 4.4842050556326285e-05, "eval/cont_loss_std": 0.0013189763994887471, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.015130489133298397, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 5.159587885827932e-07, "eval/cont_pred": 0.9971133470535278, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 19.895668029785156, "eval/dyn_loss_std": 13.552698135375977, "eval/image_loss_mean": 23.568941116333008, "eval/image_loss_std": 25.439558029174805, "eval/model_loss_mean": 35.63531494140625, "eval/model_loss_std": 31.316728591918945, "eval/post_ent_mag": 50.934661865234375, "eval/post_ent_max": 50.934661865234375, "eval/post_ent_mean": 33.346343994140625, "eval/post_ent_min": 15.295981407165527, "eval/post_ent_std": 4.842588901519775, "eval/prior_ent_mag": 76.83191680908203, "eval/prior_ent_max": 76.83191680908203, "eval/prior_ent_mean": 42.45223617553711, "eval/prior_ent_min": 15.621983528137207, "eval/prior_ent_std": 7.88728141784668, "eval/rep_loss_mean": 19.895668029785156, "eval/rep_loss_std": 13.552698135375977, "eval/reward_avg": 0.02226562425494194, "eval/reward_loss_mean": 0.12892790138721466, "eval/reward_loss_std": 0.8551163673400879, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0012423992156982, "eval/reward_neg_acc": 0.9919840097427368, "eval/reward_neg_loss": 0.067398801445961, "eval/reward_pos_acc": 0.7307692766189575, "eval/reward_pos_loss": 2.4906985759735107, "eval/reward_pred": 0.021572614088654518, "eval/reward_rate": 0.025390625, "replay/size": 184718.0, "replay/inserts": 2156.0, "replay/samples": 34496.0, "replay/insert_wait_avg": 2.528055258274963e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.593993906187436e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 36136.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 7.599592208862305e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0037174224854, "timer/env.step_count": 269.0, "timer/env.step_total": 20.906773567199707, "timer/env.step_frac": 0.020906695848178468, "timer/env.step_avg": 0.07772034783345616, "timer/env.step_min": 0.023942947387695312, "timer/env.step_max": 1.7036035060882568, "timer/replay._sample_count": 34496.0, "timer/replay._sample_total": 16.71222686767578, "timer/replay._sample_frac": 0.01671216474149879, "timer/replay._sample_avg": 0.00048446854324199273, "timer/replay._sample_min": 0.0003407001495361328, "timer/replay._sample_max": 0.02571868896484375, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 269.0, "timer/agent.policy_total": 4.270583391189575, "timer/agent.policy_frac": 0.0042705675156858676, "timer/agent.policy_avg": 0.015875774688437084, "timer/agent.policy_min": 0.014448881149291992, "timer/agent.policy_max": 0.049050331115722656, "timer/dataset_train_count": 2156.0, "timer/dataset_train_total": 0.4044511318206787, "timer/dataset_train_frac": 0.0004044496283105362, "timer/dataset_train_avg": 0.0001875932893416877, "timer/dataset_train_min": 9.512901306152344e-05, "timer/dataset_train_max": 0.0006663799285888672, "timer/agent.train_count": 2156.0, "timer/agent.train_total": 963.2518091201782, "timer/agent.train_frac": 0.9632482283195553, "timer/agent.train_avg": 0.44677727695741104, "timer/agent.train_min": 0.43398427963256836, "timer/agent.train_max": 0.582334041595459, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48454904556274414, "timer/agent.report_frac": 0.000484547244295923, "timer/agent.report_avg": 0.24227452278137207, "timer/agent.report_min": 0.23194241523742676, "timer/agent.report_max": 0.2526066303253174, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9325485229492188e-05, "timer/dataset_eval_frac": 2.9325376214679257e-08, "timer/dataset_eval_avg": 2.9325485229492188e-05, "timer/dataset_eval_min": 2.9325485229492188e-05, "timer/dataset_eval_max": 2.9325485229492188e-05, "fps": 2.155927263546161}
