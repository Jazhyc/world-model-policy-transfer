{"step": 352, "time": 59.44428992271423, "episode/length": 43.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.9090909090909091, "episode/intrinsic_return": 0.0}
{"step": 560, "time": 60.48180818557739, "episode/length": 69.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9285714285714286, "episode/intrinsic_return": 0.0}
{"step": 728, "time": 61.37420392036438, "episode/length": 90.0, "episode/score": 0.09999996423721313, "episode/reward_rate": 0.945054945054945, "episode/intrinsic_return": 0.0}
{"step": 952, "time": 62.393126249313354, "episode/length": 118.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.957983193277311, "episode/intrinsic_return": 0.0}
{"step": 960, "time": 63.28056359291077, "episode/length": 119.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9583333333333334, "episode/intrinsic_return": 0.0}
{"step": 1104, "time": 64.20420694351196, "episode/length": 137.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.9927536231884058, "episode/intrinsic_return": 0.0}
{"step": 1152, "time": 65.111989736557, "episode/length": 143.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 1248, "time": 65.98102807998657, "episode/length": 155.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 1408, "time": 66.86109352111816, "episode/length": 37.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.868421052631579, "episode/intrinsic_return": 0.0}
{"step": 1560, "time": 69.10833215713501, "eval_episode/length": 144.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9517241379310345}
{"step": 1560, "time": 70.03349876403809, "eval_episode/length": 154.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.967741935483871}
{"step": 1560, "time": 70.97232699394226, "eval_episode/length": 157.0, "eval_episode/score": 2.0999999940395355, "eval_episode/reward_rate": 0.9936708860759493}
{"step": 1560, "time": 71.81754112243652, "eval_episode/length": 161.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9753086419753086}
{"step": 1560, "time": 72.71660089492798, "eval_episode/length": 182.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9726775956284153}
{"step": 1560, "time": 73.51777577400208, "eval_episode/length": 184.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9945945945945946}
{"step": 1560, "time": 74.39058256149292, "train_stats/sum_log_reward": 0.5444444351726108, "train_stats/max_log_achievement_collect_sapling": 0.4444444444444444, "train_stats/max_log_achievement_place_plant": 0.3333333333333333, "train_stats/max_log_achievement_collect_wood": 0.8, "train_stats/max_log_achievement_wake_up": 1.4, "eval_stats/sum_log_reward": 1.9333332479000092, "eval_stats/max_log_achievement_collect_sapling": 0.8333333333333334, "eval_stats/max_log_achievement_collect_wood": 0.16666666666666666, "eval_stats/max_log_achievement_place_plant": 0.8333333333333334, "eval_stats/max_log_achievement_wake_up": 2.0}
{"step": 1560, "time": 83.28971886634827, "eval_episode/length": 142.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.993006993006993}
{"step": 1560, "time": 84.31379914283752, "eval_episode/length": 151.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.993421052631579}
{"step": 1560, "time": 85.23777914047241, "eval_episode/length": 152.0, "eval_episode/score": 3.0999999716877937, "eval_episode/reward_rate": 0.9934640522875817}
{"step": 1560, "time": 86.25662040710449, "eval_episode/length": 164.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9696969696969697}
{"step": 1560, "time": 87.21150708198547, "eval_episode/length": 167.0, "eval_episode/score": 1.1000000014901161, "eval_episode/reward_rate": 0.9702380952380952}
{"step": 1560, "time": 88.20706415176392, "eval_episode/length": 175.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9772727272727273}
{"step": 1560, "time": 89.78224730491638, "eval_episode/length": 205.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9757281553398058}
{"step": 1560, "time": 91.06941485404968, "eval_episode/length": 224.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9955555555555555}
{"step": 1561, "time": 146.1349015235901, "eval_stats/sum_log_reward": 2.4749999344348907, "eval_stats/max_log_achievement_collect_sapling": 1.375, "eval_stats/max_log_achievement_collect_wood": 1.125, "eval_stats/max_log_achievement_place_plant": 0.5, "eval_stats/max_log_achievement_place_table": 0.25, "eval_stats/max_log_achievement_wake_up": 2.25, "eval_stats/max_log_achievement_defeat_zombie": 0.25, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 7.28997802734375, "train/action_min": 0.0, "train/action_std": 4.865596294403076, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0002835275081451982, "train/actor_opt_grad_steps": 1.0, "train/actor_opt_loss": -1.9310904741287231, "train/adv_mag": 0.0, "train/adv_max": 0.0, "train/adv_mean": 0.0, "train/adv_min": 0.0, "train/adv_std": 0.0, "train/cont_avg": 0.9931640625, "train/cont_loss_mean": 0.6888848543167114, "train/cont_loss_std": 0.2981101870536804, "train/cont_neg_acc": 0.4285714626312256, "train/cont_neg_loss": 0.7484229207038879, "train/cont_pos_acc": 0.5427728295326233, "train/cont_pos_loss": 0.6884750723838806, "train/cont_pred": 0.5235369205474854, "train/cont_rate": 0.9931640625, "train/dyn_loss_mean": 10.833194732666016, "train/dyn_loss_std": 0.5143954753875732, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 6.6970624923706055, "train/extr_critic_critic_opt_grad_steps": 1.0, "train/extr_critic_critic_opt_loss": 27707.35546875, "train/extr_critic_mag": 0.0, "train/extr_critic_max": 0.0, "train/extr_critic_mean": 0.0, "train/extr_critic_min": 0.0, "train/extr_critic_std": 0.0, "train/extr_return_normed_mag": 0.0, "train/extr_return_normed_max": 0.0, "train/extr_return_normed_mean": 0.0, "train/extr_return_normed_min": 0.0, "train/extr_return_normed_std": 0.0, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.0, "train/extr_return_raw_max": 0.0, "train/extr_return_raw_mean": 0.0, "train/extr_return_raw_min": 0.0, "train/extr_return_raw_std": 0.0, "train/extr_reward_mag": 0.0, "train/extr_reward_max": 0.0, "train/extr_reward_mean": 0.0, "train/extr_reward_min": 0.0, "train/extr_reward_std": 0.0, "train/image_loss_mean": 3717.774169921875, "train/image_loss_std": 167.73043823242188, "train/model_loss_mean": 3730.504150390625, "train/model_loss_std": 167.70169067382812, "train/model_opt_grad_norm": NaN, "train/model_opt_grad_steps": 0.0, "train/model_opt_loss": 37305040.0, "train/model_opt_model_opt_grad_overflow": 1.0, "train/model_opt_model_opt_grad_scale": 5000.0, "train/policy_entropy_mag": 2.7637155055999756, "train/policy_entropy_max": 2.7637155055999756, "train/policy_entropy_mean": 2.5768134593963623, "train/policy_entropy_min": 1.867833137512207, "train/policy_entropy_std": 0.08344589173793793, "train/policy_logprob_mag": 5.633052349090576, "train/policy_logprob_max": -0.6235857605934143, "train/policy_logprob_mean": -2.5793824195861816, "train/policy_logprob_min": -5.633052349090576, "train/policy_logprob_std": 0.6713508367538452, "train/policy_randomness_mag": 0.9754703044891357, "train/policy_randomness_max": 0.9754703044891357, "train/policy_randomness_mean": 0.9095020294189453, "train/policy_randomness_min": 0.6592631340026855, "train/policy_randomness_std": 0.029452737420797348, "train/post_ent_mag": 106.216552734375, "train/post_ent_max": 106.216552734375, "train/post_ent_mean": 105.65078735351562, "train/post_ent_min": 104.89247131347656, "train/post_ent_std": 0.21055081486701965, "train/prior_ent_mag": 106.42050170898438, "train/prior_ent_max": 106.42050170898438, "train/prior_ent_mean": 105.50148010253906, "train/prior_ent_min": 104.24893188476562, "train/prior_ent_std": 0.32131722569465637, "train/rep_loss_mean": 10.833194732666016, "train/rep_loss_std": 0.5143954753875732, "train/reward_avg": 0.008496093563735485, "train/reward_loss_mean": 5.541262626647949, "train/reward_loss_std": 9.559997806718457e-07, "train/reward_max_data": 1.0, "train/reward_max_pred": 0.0, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 5.541263103485107, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 5.541263580322266, "train/reward_pred": 0.0, "train/reward_rate": 0.0166015625, "train/params_agent/wm/model_opt": 181569923.0, "train/params_agent/task_behavior/critic/critic_opt": 9708799.0, "train/params_agent/task_behavior/ac/actor_opt": 9464849.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.686312735080719, "report/cont_loss_std": 0.30523356795310974, "report/cont_neg_acc": 0.4285714626312256, "report/cont_neg_loss": 0.9552709460258484, "report/cont_pos_acc": 0.5653883218765259, "report/cont_pos_loss": 0.6844614744186401, "report/cont_pred": 0.526311993598938, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 10.76994514465332, "report/dyn_loss_std": 0.5066691637039185, "report/image_loss_mean": 3720.8974609375, "report/image_loss_std": 166.82476806640625, "report/model_loss_mean": 3733.58740234375, "report/model_loss_std": 166.8146209716797, "report/post_ent_mag": 106.13426208496094, "report/post_ent_max": 106.13426208496094, "report/post_ent_mean": 105.66376495361328, "report/post_ent_min": 104.93396759033203, "report/post_ent_std": 0.193313866853714, "report/prior_ent_mag": 106.67959594726562, "report/prior_ent_max": 106.67959594726562, "report/prior_ent_mean": 105.57484436035156, "report/prior_ent_min": 104.68301391601562, "report/prior_ent_std": 0.2879714369773865, "report/rep_loss_mean": 10.76994514465332, "report/rep_loss_std": 0.5066691637039185, "report/reward_avg": 0.008496093563735485, "report/reward_loss_mean": 5.541262626647949, "report/reward_loss_std": 9.559997806718457e-07, "report/reward_max_data": 1.0, "report/reward_max_pred": 0.0, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 5.541263103485107, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 5.541263580322266, "report/reward_pred": 0.0, "report/reward_rate": 0.0166015625, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.7133184671401978, "eval/cont_loss_std": 0.3171515166759491, "eval/cont_neg_acc": 0.6666666865348816, "eval/cont_neg_loss": 0.6202747821807861, "eval/cont_pos_acc": 0.5377081036567688, "eval/cont_pos_loss": 0.7135918140411377, "eval/cont_pred": 0.512931764125824, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 11.012247085571289, "eval/dyn_loss_std": 0.5604727864265442, "eval/image_loss_mean": 3665.8466796875, "eval/image_loss_std": 180.19708251953125, "eval/model_loss_mean": 3678.70849609375, "eval/model_loss_std": 180.10105895996094, "eval/post_ent_mag": 106.136962890625, "eval/post_ent_max": 106.136962890625, "eval/post_ent_mean": 105.58064270019531, "eval/post_ent_min": 104.75333404541016, "eval/post_ent_std": 0.24344587326049805, "eval/prior_ent_mag": 106.3881607055664, "eval/prior_ent_max": 106.3881607055664, "eval/prior_ent_mean": 105.47604370117188, "eval/prior_ent_min": 104.52030181884766, "eval/prior_ent_std": 0.2857680916786194, "eval/rep_loss_mean": 11.012247085571289, "eval/rep_loss_std": 0.5604727864265442, "eval/reward_avg": 0.01699218712747097, "eval/reward_loss_mean": 5.541262626647949, "eval/reward_loss_std": 9.5367431640625e-07, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 5.541262626647949, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.541263580322266, "eval/reward_pred": 0.0, "eval/reward_rate": 0.01953125, "replay/size": 1057.0, "replay/inserts": 1057.0, "replay/samples": 112.0, "replay/insert_wait_avg": 6.987897427215144e-07, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.344143731253488e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 2856.0, "eval_replay/inserts": 2856.0, "eval_replay/samples": 112.0, "eval_replay/insert_wait_avg": 1.655823710251923e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.238213402884347e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 87.87805724143982, "timer/env.step_count": 196.0, "timer/env.step_total": 9.414182901382446, "timer/env.step_frac": 0.10712779955430204, "timer/env.step_avg": 0.048031545415216564, "timer/env.step_min": 0.0019092559814453125, "timer/env.step_max": 1.0576050281524658, "timer/replay._sample_count": 112.0, "timer/replay._sample_total": 27.00145125389099, "timer/replay._sample_frac": 0.3072604481879485, "timer/replay._sample_avg": 0.24108438619545527, "timer/replay._sample_min": 0.0004639625549316406, "timer/replay._sample_max": 1.3433101177215576, "timer/agent.save_count": 1.0, "timer/agent.save_total": 1.7083430290222168, "timer/agent.save_frac": 0.019439927129119895, "timer/agent.save_avg": 1.7083430290222168, "timer/agent.save_min": 1.7083430290222168, "timer/agent.save_max": 1.7083430290222168, "timer/agent.policy_count": 226.0, "timer/agent.policy_total": 9.159197568893433, "timer/agent.policy_frac": 0.1042262181983504, "timer/agent.policy_avg": 0.040527422871209876, "timer/agent.policy_min": 0.008425474166870117, "timer/agent.policy_max": 5.36821174621582, "timer/dataset_train_count": 1.0, "timer/dataset_train_total": 3.218650817871094e-05, "timer/dataset_train_frac": 3.662633106496698e-07, "timer/dataset_train_avg": 3.218650817871094e-05, "timer/dataset_train_min": 3.218650817871094e-05, "timer/dataset_train_max": 3.218650817871094e-05, "timer/agent.train_count": 1.0, "timer/agent.train_total": 44.83582305908203, "timer/agent.train_frac": 0.5102049870754224, "timer/agent.train_avg": 44.83582305908203, "timer/agent.train_min": 44.83582305908203, "timer/agent.train_max": 44.83582305908203, "timer/agent.report_count": 2.0, "timer/agent.report_total": 9.295774698257446, "timer/agent.report_frac": 0.10578038466096092, "timer/agent.report_avg": 4.647887349128723, "timer/agent.report_min": 0.2090003490447998, "timer/agent.report_max": 9.086774349212646, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.838539123535156e-05, "timer/dataset_eval_frac": 4.3680291121923586e-07, "timer/dataset_eval_avg": 3.838539123535156e-05, "timer/dataset_eval_min": 3.838539123535156e-05, "timer/dataset_eval_max": 3.838539123535156e-05}
{"step": 1696, "time": 149.31009244918823, "episode/length": 55.0, "episode/score": -0.8999999910593033, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 1872, "time": 158.22568821907043, "episode/length": 142.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 1944, "time": 160.75922012329102, "episode/length": 172.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.953757225433526, "episode/intrinsic_return": 0.0}
{"step": 1968, "time": 162.44726610183716, "episode/length": 201.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 2224, "time": 169.96015214920044, "episode/length": 158.0, "episode/score": 1.0999999940395355, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 2384, "time": 174.8932101726532, "episode/length": 153.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 2544, "time": 179.68397498130798, "episode/length": 141.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 2576, "time": 181.30482482910156, "episode/length": 201.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 3048, "time": 193.98753571510315, "episode/length": 146.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9659863945578231, "episode/intrinsic_return": 0.0}
{"step": 3208, "time": 199.2502019405365, "episode/length": 188.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 3288, "time": 202.35086512565613, "episode/length": 167.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 3480, "time": 208.19248151779175, "episode/length": 156.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 3584, "time": 211.9066982269287, "episode/length": 149.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 3680, "time": 215.26100158691406, "episode/length": 48.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.8979591836734694, "episode/intrinsic_return": 0.0}
{"step": 3816, "time": 219.78379225730896, "episode/length": 154.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9612903225806452, "episode/intrinsic_return": 0.0}
{"step": 3904, "time": 223.4712438583374, "episode/length": 241.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9958677685950413, "episode/intrinsic_return": 0.0}
{"step": 4016, "time": 227.45536637306213, "episode/length": 183.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 4080, "time": 230.16533041000366, "episode/length": 49.0, "episode/score": 0.10000000149011612, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 4184, "time": 233.72844862937927, "episode/length": 45.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.8913043478260869, "episode/intrinsic_return": 0.0}
{"step": 4480, "time": 242.69142389297485, "episode/length": 178.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 4776, "time": 251.00177669525146, "episode/length": 148.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.959731543624161, "episode/intrinsic_return": 0.0}
{"step": 4904, "time": 255.13114285469055, "episode/length": 177.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 5088, "time": 260.8496904373169, "episode/length": 234.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 5416, "time": 269.76606035232544, "episode/length": 166.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 5440, "time": 271.43237113952637, "episode/length": 191.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 5688, "time": 278.3481652736664, "episode/length": 208.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 5760, "time": 281.22313714027405, "episode/length": 196.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 6040, "time": 288.98097133636475, "episode/length": 141.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 6104, "time": 291.5902998447418, "episode/length": 165.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 6136, "time": 293.26188683509827, "episode/length": 206.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 6640, "time": 307.0065538883209, "episode/length": 152.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 6720, "time": 309.887939453125, "episode/length": 159.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 6792, "time": 312.39895248413086, "episode/length": 212.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 7040, "time": 319.7174084186554, "episode/length": 159.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 7104, "time": 322.2945907115936, "episode/length": 132.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9624060150375939, "episode/intrinsic_return": 0.0}
{"step": 7352, "time": 329.2560911178589, "episode/length": 207.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 7432, "time": 332.2034888267517, "episode/length": 165.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 7464, "time": 333.89814829826355, "episode/length": 165.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 8056, "time": 349.8906590938568, "episode/length": 166.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 8360, "time": 358.57826352119446, "episode/length": 214.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 8416, "time": 361.08378505706787, "episode/length": 202.0, "episode/score": 0.09999997913837433, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 8432, "time": 362.3191571235657, "episode/length": 165.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 8432, "time": 362.33274269104004, "episode/length": 173.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 8792, "time": 372.330931186676, "episode/length": 165.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 8840, "time": 374.4292485713959, "episode/length": 175.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9659090909090909, "episode/intrinsic_return": 0.0}
{"step": 8984, "time": 379.1182334423065, "episode/length": 77.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9487179487179487, "episode/intrinsic_return": 0.0}
{"step": 9272, "time": 387.6543757915497, "episode/length": 239.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 9496, "time": 394.4292223453522, "episode/length": 132.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9548872180451128, "episode/intrinsic_return": 0.0}
{"step": 9504, "time": 395.6883702278137, "episode/length": 180.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 9816, "time": 404.83416867256165, "episode/length": 172.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 9864, "time": 406.8392767906189, "episode/length": 127.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 9936, "time": 409.7795886993408, "episode/length": 118.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.957983193277311, "episode/intrinsic_return": 0.0}
{"step": 9992, "time": 411.8833405971527, "episode/length": 196.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 10088, "time": 418.5313642024994, "eval_episode/length": 145.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9657534246575342}
{"step": 10088, "time": 419.4292335510254, "eval_episode/length": 150.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9735099337748344}
{"step": 10088, "time": 420.69869327545166, "eval_episode/length": 167.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9702380952380952}
{"step": 10088, "time": 421.55136370658875, "eval_episode/length": 168.0, "eval_episode/score": 1.1000000014901161, "eval_episode/reward_rate": 0.9763313609467456}
{"step": 10088, "time": 422.73004841804504, "eval_episode/length": 181.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.978021978021978}
{"step": 10088, "time": 423.9361491203308, "eval_episode/length": 200.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9701492537313433}
{"step": 10088, "time": 425.01630878448486, "eval_episode/length": 210.0, "eval_episode/score": 1.0999999791383743, "eval_episode/reward_rate": 0.995260663507109}
{"step": 10088, "time": 426.15316796302795, "eval_episode/length": 224.0, "eval_episode/score": 3.0999999791383743, "eval_episode/reward_rate": 0.9955555555555555}
{"step": 10464, "time": 436.2405152320862, "episode/length": 148.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 10576, "time": 440.02504777908325, "episode/length": 222.0, "episode/score": 1.0999999791383743, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 10792, "time": 446.24130177497864, "episode/length": 161.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 10896, "time": 450.0319480895996, "episode/length": 134.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9703703703703703, "episode/intrinsic_return": 0.0}
{"step": 11032, "time": 454.2890453338623, "episode/length": 190.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 11232, "time": 460.4829227924347, "episode/length": 154.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 11304, "time": 463.0700943470001, "episode/length": 179.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 11464, "time": 468.03384733200073, "episode/length": 190.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 12056, "time": 484.21470880508423, "episode/length": 184.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 12160, "time": 487.9640004634857, "episode/length": 170.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 12512, "time": 498.1612012386322, "episode/length": 201.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 12592, "time": 501.23325419425964, "episode/length": 194.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 12920, "time": 510.3489828109741, "episode/length": 210.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.981042654028436, "episode/intrinsic_return": 0.0}
{"step": 12944, "time": 511.9980788230896, "episode/length": 204.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 13152, "time": 518.3972718715668, "episode/length": 210.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.981042654028436, "episode/intrinsic_return": 0.0}
{"step": 13224, "time": 520.99050116539, "episode/length": 344.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9739130434782609, "episode/intrinsic_return": 0.0}
{"step": 13632, "time": 532.8276052474976, "episode/length": 183.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 13832, "time": 538.8195910453796, "episode/length": 164.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 13912, "time": 541.7998549938202, "episode/length": 164.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 14296, "time": 552.6235017776489, "episode/length": 171.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 14400, "time": 556.3566682338715, "episode/length": 181.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 14408, "time": 557.217668056488, "episode/length": 293.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9965986394557823, "episode/intrinsic_return": 0.0}
{"step": 14424, "time": 558.5474789142609, "episode/length": 149.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9733333333333334, "episode/intrinsic_return": 0.0}
{"step": 14456, "time": 560.1892635822296, "episode/length": 162.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 15112, "time": 578.076278924942, "episode/length": 184.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 15400, "time": 586.199045419693, "episode/length": 185.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 15408, "time": 587.4765205383301, "episode/length": 196.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 15640, "time": 594.0749056339264, "episode/length": 153.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 15824, "time": 599.6859998703003, "episode/length": 170.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 15864, "time": 601.3377101421356, "episode/length": 195.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 15864, "time": 601.3520617485046, "episode/length": 182.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 16112, "time": 608.7285108566284, "episode/length": 210.0, "episode/score": 1.0999999791383743, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 16520, "time": 619.7493736743927, "episode/length": 138.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.0}
{"step": 16712, "time": 625.4820010662079, "episode/length": 199.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 16872, "time": 630.4468772411346, "episode/length": 183.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 16968, "time": 633.84734416008, "episode/length": 106.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9532710280373832, "episode/intrinsic_return": 0.0}
{"step": 17224, "time": 641.4253785610199, "episode/length": 169.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 17296, "time": 644.3478865623474, "episode/length": 183.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 17400, "time": 647.6016871929169, "episode/length": 219.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9863636363636363, "episode/intrinsic_return": 0.0}
{"step": 17776, "time": 658.2801837921143, "episode/length": 238.0, "episode/score": 1.0999999791383743, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.0}
{"step": 18080, "time": 667.0514135360718, "episode/length": 150.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 18120, "time": 668.7763967514038, "episode/length": 89.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9444444444444444, "episode/intrinsic_return": 0.0}
{"step": 18288, "time": 674.104927778244, "episode/length": 220.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9819004524886877, "episode/intrinsic_return": 0.0}
{"step": 18384, "time": 677.4438252449036, "episode/length": 176.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 18472, "time": 680.4237341880798, "episode/length": 219.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 18632, "time": 685.2861158847809, "episode/length": 175.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 19024, "time": 696.1923270225525, "episode/length": 155.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 19192, "time": 701.194845199585, "episode/length": 236.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9831223628691983, "episode/intrinsic_return": 0.0}
{"step": 19464, "time": 709.0175316333771, "episode/length": 172.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 19496, "time": 710.8486711978912, "episode/length": 171.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 19712, "time": 717.5149598121643, "episode/length": 165.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 19808, "time": 720.9714245796204, "episode/length": 38.0, "episode/score": 0.10000000149011612, "episode/reward_rate": 0.9230769230769231, "episode/intrinsic_return": 0.0}
{"step": 19856, "time": 723.089015007019, "episode/length": 172.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 20072, "time": 732.6620972156525, "eval_episode/length": 152.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9673202614379085}
{"step": 20072, "time": 733.5171709060669, "eval_episode/length": 156.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9745222929936306}
{"step": 20072, "time": 734.4139993190765, "eval_episode/length": 157.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9683544303797469}
{"step": 20072, "time": 735.348021030426, "eval_episode/length": 161.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9691358024691358}
{"step": 20072, "time": 736.6185872554779, "eval_episode/length": 180.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9779005524861878}
{"step": 20072, "time": 738.0658330917358, "eval_episode/length": 50.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9019607843137255}
{"step": 20072, "time": 739.0695006847382, "eval_episode/length": 220.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9819004524886877}
{"step": 20072, "time": 740.0143122673035, "eval_episode/length": 223.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9821428571428571}
{"step": 20104, "time": 741.0442817211151, "episode/length": 226.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9823788546255506, "episode/intrinsic_return": 0.0}
{"step": 20280, "time": 746.5061209201813, "episode/length": 205.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9805825242718447, "episode/intrinsic_return": 0.0}
{"step": 20520, "time": 753.7148234844208, "episode/length": 165.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 20792, "time": 761.585291147232, "episode/length": 165.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.9819277108433735, "episode/intrinsic_return": 0.0}
{"step": 20880, "time": 764.8197658061981, "episode/length": 133.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9626865671641791, "episode/intrinsic_return": 0.0}
{"step": 21016, "time": 768.8943870067596, "episode/length": 248.0, "episode/score": 0.09999997913837433, "episode/reward_rate": 0.9959839357429718, "episode/intrinsic_return": 0.0}
{"step": 21400, "time": 779.422679901123, "episode/length": 210.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.981042654028436, "episode/intrinsic_return": 0.0}
{"step": 21432, "time": 781.0598118305206, "episode/length": 51.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9038461538461539, "episode/intrinsic_return": 0.0}
{"step": 21464, "time": 782.7594118118286, "episode/length": 200.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9800995024875622, "episode/intrinsic_return": 0.0}
{"step": 21496, "time": 784.5085868835449, "episode/length": 173.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 21656, "time": 789.4294748306274, "episode/length": 171.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 21928, "time": 796.9774959087372, "episode/length": 175.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 22328, "time": 808.2219920158386, "episode/length": 49.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9, "episode/intrinsic_return": 0.0}
{"step": 22432, "time": 812.0083022117615, "episode/length": 204.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.9853658536585366, "episode/intrinsic_return": 0.0}
{"step": 22552, "time": 816.0254566669464, "episode/length": 208.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 22664, "time": 819.8014686107635, "episode/length": 149.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 22672, "time": 821.0618243217468, "episode/length": 158.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 22800, "time": 825.0610744953156, "episode/length": 170.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 22952, "time": 829.4693806171417, "episode/length": 181.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 22968, "time": 830.6720566749573, "episode/length": 163.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 23144, "time": 836.0085072517395, "episode/length": 59.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9166666666666666, "episode/intrinsic_return": 0.0}
{"step": 23816, "time": 853.9570534229279, "episode/length": 185.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 24136, "time": 862.9490094184875, "episode/length": 166.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 24136, "time": 862.9628109931946, "episode/length": 147.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 24160, "time": 864.6218249797821, "episode/length": 215.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 24224, "time": 867.0347261428833, "episode/length": 208.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9856459330143541, "episode/intrinsic_return": 0.0}
{"step": 24328, "time": 870.30890583992, "episode/length": 206.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9806763285024155, "episode/intrinsic_return": 0.0}
{"step": 24472, "time": 874.7851073741913, "episode/length": 187.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 24488, "time": 876.0838782787323, "episode/length": 83.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9523809523809523, "episode/intrinsic_return": 0.0}
{"step": 24688, "time": 882.3892951011658, "episode/length": 192.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 24856, "time": 887.3841698169708, "episode/length": 86.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9425287356321839, "episode/intrinsic_return": 0.0}
{"step": 25352, "time": 901.1588807106018, "episode/length": 151.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 25432, "time": 904.1325511932373, "episode/length": 150.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 25736, "time": 912.8870074748993, "episode/length": 199.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 25864, "time": 917.1348569393158, "episode/length": 191.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 26048, "time": 923.3927617073059, "episode/length": 148.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 26112, "time": 925.9356317520142, "episode/length": 204.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 26152, "time": 927.7008545398712, "episode/length": 51.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9230769230769231, "episode/intrinsic_return": 0.0}
{"step": 26504, "time": 937.6553535461426, "episode/length": 226.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9823788546255506, "episode/intrinsic_return": 0.0}
{"step": 26792, "time": 946.1222841739655, "episode/length": 179.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 26944, "time": 951.0230250358582, "episode/length": 306.0, "episode/score": 2.0999999791383743, "episode/reward_rate": 0.996742671009772, "episode/intrinsic_return": 0.0}
{"step": 27016, "time": 953.5679955482483, "episode/length": 197.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 27680, "time": 971.3191154003143, "episode/length": 226.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9823788546255506, "episode/intrinsic_return": 0.0}
{"step": 27704, "time": 972.5952446460724, "episode/length": 85.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9534883720930233, "episode/intrinsic_return": 0.0}
{"step": 27728, "time": 974.2665596008301, "episode/length": 209.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9809523809523809, "episode/intrinsic_return": 0.0}
{"step": 27728, "time": 974.2824697494507, "episode/length": 201.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 27784, "time": 976.5099010467529, "episode/length": 159.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 27872, "time": 979.8298268318176, "episode/length": 214.0, "episode/score": 2.099999964237213, "episode/reward_rate": 0.9674418604651163, "episode/intrinsic_return": 0.0}
{"step": 28320, "time": 992.1346213817596, "episode/length": 76.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.935064935064935, "episode/intrinsic_return": 0.0}
{"step": 28328, "time": 992.9352705478668, "episode/length": 172.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 28712, "time": 1003.6624534130096, "episode/length": 239.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9875, "episode/intrinsic_return": 0.0}
{"step": 29016, "time": 1012.3607175350189, "episode/length": 160.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9565217391304348, "episode/intrinsic_return": 0.0}
{"step": 29056, "time": 1014.4540615081787, "episode/length": 165.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 29120, "time": 1016.9453561306, "episode/length": 166.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 29208, "time": 1019.8888125419617, "episode/length": 109.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9545454545454546, "episode/intrinsic_return": 0.0}
{"step": 29280, "time": 1022.7674286365509, "episode/length": 199.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 29536, "time": 1030.3186016082764, "episode/length": 40.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 29544, "time": 1031.1892058849335, "episode/length": 52.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9245283018867925, "episode/intrinsic_return": 0.0}
{"step": 29544, "time": 1031.2053997516632, "episode/length": 208.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 29792, "time": 1038.8386046886444, "episode/length": 96.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9484536082474226, "episode/intrinsic_return": 0.0}
{"step": 29888, "time": 1042.2933375835419, "episode/length": 195.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 29896, "time": 1043.139876127243, "episode/length": 104.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9619047619047619, "episode/intrinsic_return": 0.0}
{"step": 30056, "time": 1051.0348262786865, "eval_episode/length": 136.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9635036496350365}
{"step": 30056, "time": 1052.2095341682434, "eval_episode/length": 153.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9675324675324676}
{"step": 30056, "time": 1053.1515972614288, "eval_episode/length": 155.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 30056, "time": 1054.2696018218994, "eval_episode/length": 168.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9704142011834319}
{"step": 30056, "time": 1055.3668043613434, "eval_episode/length": 180.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9779005524861878}
{"step": 30056, "time": 1056.3724858760834, "eval_episode/length": 187.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9627659574468085}
{"step": 30056, "time": 1057.2544322013855, "eval_episode/length": 188.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9735449735449735}
{"step": 30056, "time": 1058.1873626708984, "eval_episode/length": 191.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9739583333333334}
{"step": 30264, "time": 1063.6219170093536, "episode/length": 193.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 30776, "time": 1077.4197483062744, "episode/length": 153.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 30784, "time": 1078.6454882621765, "episode/length": 187.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 30968, "time": 1083.9041228294373, "episode/length": 178.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 31032, "time": 1086.361486673355, "episode/length": 185.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 31200, "time": 1091.624237537384, "episode/length": 175.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 31400, "time": 1097.2789959907532, "episode/length": 141.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9647887323943662, "episode/intrinsic_return": 0.0}
{"step": 31536, "time": 1101.792165517807, "episode/length": 205.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.970873786407767, "episode/intrinsic_return": 0.0}
{"step": 31736, "time": 1107.4474470615387, "episode/length": 229.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 32168, "time": 1119.1880626678467, "episode/length": 141.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 32336, "time": 1124.3747544288635, "episode/length": 194.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 32376, "time": 1125.9816615581512, "episode/length": 198.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 32376, "time": 1125.99454164505, "episode/length": 175.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 32488, "time": 1129.6416900157928, "episode/length": 160.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 32696, "time": 1135.6349699497223, "episode/length": 161.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 32697, "time": 1137.3121547698975, "train_stats/sum_log_reward": 0.8759562605635716, "train_stats/max_log_achievement_collect_sapling": 12.207650273224044, "train_stats/max_log_achievement_collect_wood": 0.18032786885245902, "train_stats/max_log_achievement_defeat_zombie": 0.16939890710382513, "train_stats/max_log_achievement_place_plant": 0.16393442622950818, "train_stats/max_log_achievement_place_table": 0.02185792349726776, "train_stats/max_log_achievement_wake_up": 0.4262295081967213, "train_stats/mean_log_entropy": 0.7541896246902929, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.698828313768525, "train/action_min": 0.0, "train/action_std": 1.6580828079550536, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.005653557806130566, "train/actor_opt_grad_steps": 975.0, "train/actor_opt_loss": 115.77101197577629, "train/adv_mag": 2.6360852178906273, "train/adv_max": 2.6298220698126427, "train/adv_mean": 0.016732104699574847, "train/adv_min": -0.5652155419834709, "train/adv_std": 0.1656126579964562, "train/cont_avg": 0.9940047116623711, "train/cont_loss_mean": 0.02304417187619994, "train/cont_loss_std": 0.20843956397723176, "train/cont_neg_acc": 0.2736060940420505, "train/cont_neg_loss": 2.45789132786245, "train/cont_pos_acc": 0.9975702962310043, "train/cont_pos_loss": 0.008158035350620077, "train/cont_pred": 0.9914941563434208, "train/cont_rate": 0.9940047116623711, "train/dyn_loss_mean": 5.691176919593024, "train/dyn_loss_std": 6.8986049072490525, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 4.6145871607298705, "train/extr_critic_critic_opt_grad_steps": 975.0, "train/extr_critic_critic_opt_loss": 18090.967989892073, "train/extr_critic_mag": 0.4745161963492325, "train/extr_critic_max": 0.4745161951202707, "train/extr_critic_mean": 0.03302462707017427, "train/extr_critic_min": -0.14915680393730243, "train/extr_critic_std": 0.1239240548455095, "train/extr_return_normed_mag": 3.1547545685622302, "train/extr_return_normed_max": 3.1547141643504357, "train/extr_return_normed_mean": 0.23349422148846902, "train/extr_return_normed_min": -0.3794496520740266, "train/extr_return_normed_std": 0.24108314893933, "train/extr_return_rate": 0.04207910718075264, "train/extr_return_raw_mag": 2.9716546534014845, "train/extr_return_raw_max": 2.970976685596265, "train/extr_return_raw_mean": 0.049756730850934454, "train/extr_return_raw_min": -0.5631871307411856, "train/extr_return_raw_std": 0.24108314800440697, "train/extr_reward_mag": 0.6872709731465763, "train/extr_reward_max": 0.687248107084294, "train/extr_reward_mean": 0.0063683914546701775, "train/extr_reward_min": -0.1309852587808039, "train/extr_reward_std": 0.04543281533372315, "train/image_loss_mean": 68.48544024929558, "train/image_loss_std": 36.83837356272432, "train/model_loss_mean": 72.18291135669983, "train/model_loss_std": 38.396707785498236, "train/model_opt_grad_norm": 238.113028788196, "train/model_opt_grad_steps": 965.0, "train/model_opt_loss": 1013.2096096707373, "train/model_opt_model_opt_grad_overflow": 0.005154639175257732, "train/model_opt_model_opt_grad_scale": 14.447084407216495, "train/policy_entropy_mag": 0.9266166626715783, "train/policy_entropy_max": 0.9266166626715783, "train/policy_entropy_mean": 0.6990071853488377, "train/policy_entropy_min": 0.6201233270088422, "train/policy_entropy_std": 0.04914195685060551, "train/policy_logprob_mag": 6.881251956998687, "train/policy_logprob_max": -0.3103510231576553, "train/policy_logprob_mean": -0.6992853597267387, "train/policy_logprob_min": -6.881251956998687, "train/policy_logprob_std": 0.7320180003790512, "train/policy_randomness_mag": 0.327055019144084, "train/policy_randomness_max": 0.327055019144084, "train/policy_randomness_mean": 0.2467188599817071, "train/policy_randomness_min": 0.21887632260655926, "train/policy_randomness_std": 0.0173449541630221, "train/post_ent_mag": 47.8975695973819, "train/post_ent_max": 47.8975695973819, "train/post_ent_mean": 32.45558750506529, "train/post_ent_min": 15.728971923749471, "train/post_ent_std": 5.751342542623122, "train/prior_ent_mag": 55.83500514079615, "train/prior_ent_max": 55.83500514079615, "train/prior_ent_mean": 38.59324907519154, "train/prior_ent_min": 21.295288960958263, "train/prior_ent_std": 5.619999879567893, "train/rep_loss_mean": 5.691176919593024, "train/rep_loss_std": 6.8986049072490525, "train/reward_avg": 0.007475233488877006, "train/reward_loss_mean": 0.25971990689328034, "train/reward_loss_std": 0.6061431410591536, "train/reward_max_data": 1.0, "train/reward_max_pred": 0.788817457317077, "train/reward_neg_acc": 0.9969952447512715, "train/reward_neg_loss": 0.22628092281904416, "train/reward_pos_acc": 0.5634037023890264, "train/reward_pos_loss": 2.6752323830865095, "train/reward_pred": 0.005557487860979685, "train/reward_rate": 0.012836259664948453, "train_stats/max_log_achievement_collect_drink": 0.34104046242774566, "train_stats/max_log_achievement_eat_cow": 0.2631578947368421, "eval_stats/sum_log_reward": 0.6833333168178797, "eval_stats/max_log_achievement_collect_drink": 0.0, "eval_stats/max_log_achievement_collect_sapling": 15.0, "eval_stats/max_log_achievement_collect_wood": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.2916666666666667, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_place_plant": 0.125, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 0.041666666666666664, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.990234375, "report/cont_loss_mean": 0.001341391121968627, "report/cont_loss_std": 0.023690111935138702, "report/cont_neg_acc": 0.9000000357627869, "report/cont_neg_loss": 0.07746531814336777, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0005906621809117496, "report/cont_pred": 0.990254819393158, "report/cont_rate": 0.990234375, "report/dyn_loss_mean": 7.533447265625, "report/dyn_loss_std": 6.01989221572876, "report/image_loss_mean": 16.240379333496094, "report/image_loss_std": 12.400728225708008, "report/model_loss_mean": 20.851829528808594, "report/model_loss_std": 14.360353469848633, "report/post_ent_mag": 39.09502410888672, "report/post_ent_max": 39.09502410888672, "report/post_ent_mean": 31.18140411376953, "report/post_ent_min": 14.318283081054688, "report/post_ent_std": 3.2556803226470947, "report/prior_ent_mag": 58.50941848754883, "report/prior_ent_max": 58.50941848754883, "report/prior_ent_mean": 39.3426513671875, "report/prior_ent_min": 19.208192825317383, "report/prior_ent_std": 3.835146427154541, "report/rep_loss_mean": 7.533447265625, "report/rep_loss_std": 6.01989221572876, "report/reward_avg": 0.006054687313735485, "report/reward_loss_mean": 0.09003810584545135, "report/reward_loss_std": 0.4142712950706482, "report/reward_max_data": 1.0, "report/reward_max_pred": 0.9944530725479126, "report/reward_neg_acc": 0.9990108609199524, "report/reward_neg_loss": 0.08021798729896545, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.8537406325340271, "report/reward_pred": 0.006995584815740585, "report/reward_rate": 0.0126953125, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 0.015964165329933167, "eval/cont_loss_std": 0.37959024310112, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 10.914080619812012, "eval/cont_pos_acc": 0.9990224838256836, "eval/cont_pos_loss": 0.0053110672160983086, "eval/cont_pred": 0.9989533424377441, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 10.66381549835205, "eval/dyn_loss_std": 6.85122537612915, "eval/image_loss_mean": 46.593624114990234, "eval/image_loss_std": 39.7138671875, "eval/model_loss_mean": 53.15303039550781, "eval/model_loss_std": 41.51170349121094, "eval/post_ent_mag": 46.87871551513672, "eval/post_ent_max": 46.87871551513672, "eval/post_ent_mean": 30.724748611450195, "eval/post_ent_min": 11.249923706054688, "eval/post_ent_std": 6.824024200439453, "eval/prior_ent_mag": 54.36628723144531, "eval/prior_ent_max": 54.36628723144531, "eval/prior_ent_mean": 38.774688720703125, "eval/prior_ent_min": 17.972965240478516, "eval/prior_ent_std": 7.994736194610596, "eval/rep_loss_mean": 10.66381549835205, "eval/rep_loss_std": 6.85122537612915, "eval/reward_avg": 0.01943359524011612, "eval/reward_loss_mean": 0.1451532244682312, "eval/reward_loss_std": 0.8279208540916443, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9957516193389893, "eval/reward_neg_acc": 0.9970059990882874, "eval/reward_neg_loss": 0.07818543910980225, "eval/reward_pos_acc": 0.6818181872367859, "eval/reward_pos_loss": 3.1952314376831055, "eval/reward_pred": 0.011908350512385368, "eval/reward_rate": 0.021484375, "replay/size": 32193.0, "replay/inserts": 31136.0, "replay/samples": 31136.0, "replay/insert_wait_avg": 1.2712160705417424e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 6.604522374771605e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 7984.0, "eval_replay/inserts": 5128.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2072032773736487e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 6.258487701416016e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 991.1674563884735, "timer/env.step_count": 3892.0, "timer/env.step_total": 165.99104142189026, "timer/env.step_frac": 0.16747022952782714, "timer/env.step_avg": 0.04264929121836852, "timer/env.step_min": 0.0023355484008789062, "timer/env.step_max": 0.995919942855835, "timer/replay._sample_count": 31136.0, "timer/replay._sample_total": 2829.8065547943115, "timer/replay._sample_frac": 2.8550236759238494, "timer/replay._sample_avg": 0.09088535954503826, "timer/replay._sample_min": 0.00041174888610839844, "timer/replay._sample_max": 0.12810063362121582, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4533.0, "timer/agent.policy_total": 46.94506216049194, "timer/agent.policy_frac": 0.04736340146956209, "timer/agent.policy_avg": 0.010356289909660699, "timer/agent.policy_min": 0.007817745208740234, "timer/agent.policy_max": 0.06174969673156738, "timer/dataset_train_count": 1946.0, "timer/dataset_train_total": 0.15868926048278809, "timer/dataset_train_frac": 0.00016010338057406131, "timer/dataset_train_avg": 8.15463825708058e-05, "timer/dataset_train_min": 5.1021575927734375e-05, "timer/dataset_train_max": 0.00021219253540039062, "timer/agent.train_count": 1946.0, "timer/agent.train_total": 742.3220264911652, "timer/agent.train_frac": 0.7489370456087926, "timer/agent.train_avg": 0.38146044526781353, "timer/agent.train_min": 0.3521840572357178, "timer/agent.train_max": 0.5870532989501953, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.40007495880126953, "timer/agent.report_frac": 0.000403640127833723, "timer/agent.report_avg": 0.20003747940063477, "timer/agent.report_min": 0.19172120094299316, "timer/agent.report_max": 0.20835375785827637, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.409385681152344e-05, "timer/dataset_eval_frac": 3.439767578301204e-08, "timer/dataset_eval_avg": 3.409385681152344e-05, "timer/dataset_eval_min": 3.409385681152344e-05, "timer/dataset_eval_max": 3.409385681152344e-05, "fps": 31.413153352471355}
{"step": 32784, "time": 1139.4632368087769, "episode/length": 155.0, "episode/score": 0.09999997913837433, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 33000, "time": 1145.584719657898, "episode/length": 157.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 33272, "time": 1153.425353527069, "episode/length": 97.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9489795918367347, "episode/intrinsic_return": 0.0}
{"step": 33400, "time": 1157.6242141723633, "episode/length": 153.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 33664, "time": 1165.4426035881042, "episode/length": 165.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 33704, "time": 1167.2026801109314, "episode/length": 165.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 33728, "time": 1168.9339392185211, "episode/length": 128.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9922480620155039, "episode/intrinsic_return": 0.0}
{"step": 33896, "time": 1173.8952317237854, "episode/length": 189.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 34008, "time": 1177.5523059368134, "episode/length": 152.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9738562091503268, "episode/intrinsic_return": 0.0}
{"step": 34240, "time": 1184.56321310997, "episode/length": 42.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.8837209302325582, "episode/intrinsic_return": 0.0}
{"step": 34384, "time": 1189.126169681549, "episode/length": 172.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 34832, "time": 1201.398577451706, "episode/length": 137.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9710144927536232, "episode/intrinsic_return": 0.0}
{"step": 34840, "time": 1202.2874674797058, "episode/length": 195.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 34840, "time": 1202.2996425628662, "episode/length": 179.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 35008, "time": 1207.8638887405396, "episode/length": 167.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 35216, "time": 1214.0219039916992, "episode/length": 46.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.8936170212765957, "episode/intrinsic_return": 0.0}
{"step": 35216, "time": 1214.034080505371, "episode/length": 150.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 35448, "time": 1220.6619007587433, "episode/length": 150.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 35456, "time": 1221.9010381698608, "episode/length": 218.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9817351598173516, "episode/intrinsic_return": 0.0}
{"step": 35656, "time": 1227.8609211444855, "episode/length": 80.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9506172839506173, "episode/intrinsic_return": 0.0}
{"step": 36056, "time": 1238.6377019882202, "episode/length": 151.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 36208, "time": 1243.4677684307098, "episode/length": 227.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 36592, "time": 1253.9678769111633, "episode/length": 219.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 36600, "time": 1254.8760614395142, "episode/length": 172.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 36760, "time": 1259.9936077594757, "episode/length": 162.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 37016, "time": 1267.2259571552277, "episode/length": 195.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 37400, "time": 1277.621094942093, "episode/length": 148.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 37648, "time": 1284.8923890590668, "episode/length": 248.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9839357429718876, "episode/intrinsic_return": 0.0}
{"step": 37880, "time": 1291.4516623020172, "episode/length": 160.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 37928, "time": 1293.5328011512756, "episode/length": 165.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 37992, "time": 1295.9428119659424, "episode/length": 153.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 38072, "time": 1299.063261270523, "episode/length": 356.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9971988795518207, "episode/intrinsic_return": 0.0}
{"step": 38128, "time": 1301.5823380947113, "episode/length": 258.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9845559845559846, "episode/intrinsic_return": 0.0}
{"step": 38608, "time": 1314.4983792304993, "episode/length": 198.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 38624, "time": 1315.6909184455872, "episode/length": 152.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 39240, "time": 1331.9956917762756, "episode/length": 169.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 39344, "time": 1335.6443717479706, "episode/length": 176.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 39536, "time": 1341.3483839035034, "episode/length": 192.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 39576, "time": 1343.0174984931946, "episode/length": 180.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 39768, "time": 1348.5882630348206, "episode/length": 264.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9886792452830189, "episode/intrinsic_return": 0.0}
{"step": 39832, "time": 1351.1003739833832, "episode/length": 150.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 39840, "time": 1352.276219367981, "episode/length": 220.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 39856, "time": 1353.5114119052887, "episode/length": 155.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 40040, "time": 1360.5283834934235, "eval_episode/length": 49.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.92}
{"step": 40040, "time": 1361.6104843616486, "eval_episode/length": 64.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9230769230769231}
{"step": 40040, "time": 1363.965410709381, "eval_episode/length": 153.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9675324675324676}
{"step": 40040, "time": 1364.8684952259064, "eval_episode/length": 155.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.967948717948718}
{"step": 40040, "time": 1365.7326564788818, "eval_episode/length": 157.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9873417721518988}
{"step": 40040, "time": 1366.7939476966858, "eval_episode/length": 163.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.975609756097561}
{"step": 40040, "time": 1367.6667776107788, "eval_episode/length": 164.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9757575757575757}
{"step": 40040, "time": 1369.248318195343, "eval_episode/length": 51.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9230769230769231}
{"step": 40480, "time": 1380.4654054641724, "episode/length": 112.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9646017699115044, "episode/intrinsic_return": 0.0}
{"step": 40760, "time": 1388.095652103424, "episode/length": 152.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 40808, "time": 1390.1220133304596, "episode/length": 40.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8780487804878049, "episode/intrinsic_return": 0.0}
{"step": 40816, "time": 1391.3719489574432, "episode/length": 183.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 40840, "time": 1392.5716104507446, "episode/length": 199.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 41160, "time": 1401.5299668312073, "episode/length": 162.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 41368, "time": 1407.5899081230164, "episode/length": 199.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 41520, "time": 1412.3966250419617, "episode/length": 210.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 41720, "time": 1418.0994412899017, "episode/length": 234.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9829787234042553, "episode/intrinsic_return": 0.0}
{"step": 41992, "time": 1425.6976952552795, "episode/length": 153.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.961038961038961, "episode/intrinsic_return": 0.0}
{"step": 42128, "time": 1430.0832002162933, "episode/length": 164.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 42272, "time": 1434.5983493328094, "episode/length": 181.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 42408, "time": 1438.6824350357056, "episode/length": 195.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 42544, "time": 1443.0934641361237, "episode/length": 51.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9038461538461539, "episode/intrinsic_return": 0.0}
{"step": 42680, "time": 1447.2778470516205, "episode/length": 163.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 42816, "time": 1451.6865060329437, "episode/length": 161.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 42960, "time": 1456.255518913269, "episode/length": 224.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9822222222222222, "episode/intrinsic_return": 0.0}
{"step": 43104, "time": 1460.7118256092072, "episode/length": 138.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9640287769784173, "episode/intrinsic_return": 0.0}
{"step": 43136, "time": 1462.3616847991943, "episode/length": 176.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 43576, "time": 1473.9906253814697, "episode/length": 128.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9534883720930233, "episode/intrinsic_return": 0.0}
{"step": 43664, "time": 1477.3310151100159, "episode/length": 156.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 43888, "time": 1483.811640739441, "episode/length": 201.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 43960, "time": 1486.3072032928467, "episode/length": 142.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.965034965034965, "episode/intrinsic_return": 0.0}
{"step": 43976, "time": 1487.567254781723, "episode/length": 161.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 44168, "time": 1493.220047712326, "episode/length": 62.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9206349206349206, "episode/intrinsic_return": 0.0}
{"step": 44584, "time": 1504.8185737133026, "episode/length": 184.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 44592, "time": 1506.080230474472, "episode/length": 203.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 44928, "time": 1515.5706408023834, "episode/length": 168.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 44960, "time": 1517.2488017082214, "episode/length": 227.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 45048, "time": 1520.1603837013245, "episode/length": 133.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9626865671641791, "episode/intrinsic_return": 0.0}
{"step": 45112, "time": 1522.7844307422638, "episode/length": 152.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 45272, "time": 1527.7585201263428, "episode/length": 163.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 45776, "time": 1541.932065486908, "episode/length": 147.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 45824, "time": 1544.018722295761, "episode/length": 154.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 45888, "time": 1546.5592670440674, "episode/length": 214.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9813953488372092, "episode/intrinsic_return": 0.0}
{"step": 45928, "time": 1548.4482407569885, "episode/length": 101.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9411764705882353, "episode/intrinsic_return": 0.0}
{"step": 46256, "time": 1557.936672449112, "episode/length": 161.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 46336, "time": 1560.8753399848938, "episode/length": 160.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 47032, "time": 1579.2725884914398, "episode/length": 156.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9617834394904459, "episode/intrinsic_return": 0.0}
{"step": 47056, "time": 1580.8821229934692, "episode/length": 265.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9887218045112782, "episode/intrinsic_return": 0.0}
{"step": 47152, "time": 1584.2074790000916, "episode/length": 157.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 47576, "time": 1595.490788936615, "episode/length": 205.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9805825242718447, "episode/intrinsic_return": 0.0}
{"step": 47592, "time": 1596.779845237732, "episode/length": 289.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 47760, "time": 1602.1844081878662, "episode/length": 187.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 47952, "time": 1607.9244647026062, "episode/length": 265.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9887218045112782, "episode/intrinsic_return": 0.0}
{"step": 48304, "time": 1617.8871266841888, "episode/length": 245.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9796747967479674, "episode/intrinsic_return": 0.0}
{"step": 48408, "time": 1621.1655571460724, "episode/length": 156.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 48576, "time": 1626.4279980659485, "episode/length": 192.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 48600, "time": 1627.660335302353, "episode/length": 125.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9603174603174603, "episode/intrinsic_return": 0.0}
{"step": 48832, "time": 1634.590345621109, "episode/length": 221.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 48920, "time": 1637.560176372528, "episode/length": 167.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 48976, "time": 1640.0054347515106, "episode/length": 151.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 49168, "time": 1645.6633658409119, "episode/length": 151.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 49520, "time": 1655.5791161060333, "episode/length": 151.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 49576, "time": 1657.7284643650055, "episode/length": 145.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9657534246575342, "episode/intrinsic_return": 0.0}
{"step": 49760, "time": 1663.4946978092194, "episode/length": 97.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9489795918367347, "episode/intrinsic_return": 0.0}
{"step": 49904, "time": 1668.0739300251007, "episode/length": 162.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 49976, "time": 1670.5110676288605, "episode/length": 174.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 50024, "time": 1676.0086178779602, "eval_episode/length": 153.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9675324675324676}
{"step": 50024, "time": 1676.942177772522, "eval_episode/length": 159.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9625}
{"step": 50024, "time": 1676.9539654254913, "eval_episode/length": 159.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.96875}
{"step": 50024, "time": 1677.938051700592, "eval_episode/length": 163.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9695121951219512}
{"step": 50024, "time": 1678.9080426692963, "eval_episode/length": 169.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9705882352941176}
{"step": 50024, "time": 1679.9825994968414, "eval_episode/length": 33.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.8529411764705882}
{"step": 50024, "time": 1681.0459561347961, "eval_episode/length": 202.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9753694581280788}
{"step": 50024, "time": 1681.966434955597, "eval_episode/length": 203.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9950980392156863}
{"step": 50032, "time": 1682.3955793380737, "episode/length": 33.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.8529411764705882, "episode/intrinsic_return": 0.0}
{"step": 50216, "time": 1687.8445596694946, "episode/length": 161.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 50296, "time": 1690.6890926361084, "episode/length": 48.0, "episode/score": -0.8999999910593033, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 50680, "time": 1701.364872455597, "episode/length": 230.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9826839826839827, "episode/intrinsic_return": 0.0}
{"step": 50776, "time": 1704.619281053543, "episode/length": 200.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9800995024875622, "episode/intrinsic_return": 0.0}
{"step": 51256, "time": 1717.8714623451233, "episode/length": 209.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 51320, "time": 1720.3349130153656, "episode/length": 160.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 51344, "time": 1721.9936616420746, "episode/length": 170.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 51352, "time": 1722.851222038269, "episode/length": 228.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9868995633187773, "episode/intrinsic_return": 0.0}
{"step": 51560, "time": 1729.0174496173859, "episode/length": 157.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 51920, "time": 1739.2055513858795, "episode/length": 212.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 52056, "time": 1743.3410713672638, "episode/length": 171.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 52216, "time": 1748.2898499965668, "episode/length": 179.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 52544, "time": 1758.3280930519104, "episode/length": 152.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 52576, "time": 1760.1158528327942, "episode/length": 152.0, "episode/score": 4.099999964237213, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 52720, "time": 1765.1778013706207, "episode/length": 182.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 52800, "time": 1768.0900938510895, "episode/length": 181.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 52944, "time": 1772.6799170970917, "episode/length": 172.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 53704, "time": 1792.9746384620667, "episode/length": 222.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9775784753363229, "episode/intrinsic_return": 0.0}
{"step": 53816, "time": 1796.7170870304108, "episode/length": 219.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 53832, "time": 1798.1324574947357, "episode/length": 201.0, "episode/score": 0.09999997913837433, "episode/reward_rate": 0.9900990099009901, "episode/intrinsic_return": 0.0}
{"step": 54248, "time": 1809.9157218933105, "episode/length": 212.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9812206572769953, "episode/intrinsic_return": 0.0}
{"step": 54280, "time": 1811.650286436081, "episode/length": 166.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 54296, "time": 1812.930834531784, "episode/length": 214.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 54312, "time": 1814.183357000351, "episode/length": 198.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 54440, "time": 1818.3287463188171, "episode/length": 204.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 54816, "time": 1828.7603192329407, "episode/length": 122.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.959349593495935, "episode/intrinsic_return": 0.0}
{"step": 55448, "time": 1845.5309998989105, "episode/length": 203.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 55640, "time": 1851.4301750659943, "episode/length": 167.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 55704, "time": 1853.940541267395, "episode/length": 249.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.988, "episode/intrinsic_return": 0.0}
{"step": 56112, "time": 1865.1797049045563, "episode/length": 232.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9828326180257511, "episode/intrinsic_return": 0.0}
{"step": 56136, "time": 1866.4033753871918, "episode/length": 53.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9074074074074074, "episode/intrinsic_return": 0.0}
{"step": 56272, "time": 1870.8897545337677, "episode/length": 228.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.982532751091703, "episode/intrinsic_return": 0.0}
{"step": 56272, "time": 1870.9048864841461, "episode/length": 244.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9836734693877551, "episode/intrinsic_return": 0.0}
{"step": 56400, "time": 1875.1197299957275, "episode/length": 264.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9849056603773585, "episode/intrinsic_return": 0.0}
{"step": 56432, "time": 1876.8036301136017, "episode/length": 122.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.959349593495935, "episode/intrinsic_return": 0.0}
{"step": 56872, "time": 1888.3796136379242, "episode/length": 74.0, "episode/score": 1.100000023841858, "episode/reward_rate": 0.9866666666666667, "episode/intrinsic_return": 0.0}
{"step": 57544, "time": 1906.5295987129211, "episode/length": 158.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 57584, "time": 1908.573403120041, "episode/length": 183.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 57584, "time": 1908.5868756771088, "episode/length": 180.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 57648, "time": 1911.1687421798706, "episode/length": 155.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 57688, "time": 1912.793875694275, "episode/length": 255.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.98046875, "episode/intrinsic_return": 0.0}
{"step": 58088, "time": 1924.2375514507294, "episode/length": 408.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9779951100244498, "episode/intrinsic_return": 0.0}
{"step": 58280, "time": 1930.3480379581451, "episode/length": 230.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9783549783549783, "episode/intrinsic_return": 0.0}
{"step": 58384, "time": 1934.4092257022858, "episode/length": 188.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 58832, "time": 1947.3235795497894, "episode/length": 155.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 58840, "time": 1948.2180497646332, "episode/length": 148.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.959731543624161, "episode/intrinsic_return": 0.0}
{"step": 58920, "time": 1951.3063759803772, "episode/length": 171.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 59088, "time": 1956.7624700069427, "episode/length": 174.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 59376, "time": 1965.0764734745026, "episode/length": 223.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 59376, "time": 1965.0925889015198, "episode/length": 160.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 59600, "time": 1971.7764098644257, "episode/length": 164.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9636363636363636, "episode/intrinsic_return": 0.0}
{"step": 59752, "time": 1976.3646249771118, "episode/length": 170.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9590643274853801, "episode/intrinsic_return": 0.0}
{"step": 60008, "time": 1986.469473361969, "eval_episode/length": 103.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9519230769230769}
{"step": 60008, "time": 1988.030705690384, "eval_episode/length": 151.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9671052631578947}
{"step": 60008, "time": 1989.1112697124481, "eval_episode/length": 165.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9698795180722891}
{"step": 60008, "time": 1990.0980348587036, "eval_episode/length": 168.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9704142011834319}
{"step": 60008, "time": 1990.11084151268, "eval_episode/length": 168.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9822485207100592}
{"step": 60008, "time": 1990.1224579811096, "eval_episode/length": 168.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9704142011834319}
{"step": 60008, "time": 1991.3570301532745, "eval_episode/length": 185.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9731182795698925}
{"step": 60008, "time": 1993.061526298523, "eval_episode/length": 64.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9384615384615385}
{"step": 60032, "time": 1993.9859113693237, "episode/length": 138.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.0}
{"step": 60160, "time": 1998.0283460617065, "episode/length": 165.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.963855421686747, "episode/intrinsic_return": 0.0}
{"step": 60448, "time": 2006.2612404823303, "episode/length": 169.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 60688, "time": 2013.2825944423676, "episode/length": 230.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9826839826839827, "episode/intrinsic_return": 0.0}
{"step": 60848, "time": 2018.2012674808502, "episode/length": 183.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 61200, "time": 2027.9583280086517, "episode/length": 180.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 61432, "time": 2034.4785387516022, "episode/length": 228.0, "episode/score": 2.0999999791383743, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 61688, "time": 2041.906804561615, "episode/length": 154.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 61720, "time": 2043.585833311081, "episode/length": 292.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9931740614334471, "episode/intrinsic_return": 0.0}
{"step": 61784, "time": 2046.069875717163, "episode/length": 43.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 61872, "time": 2049.368246078491, "episode/length": 147.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 62384, "time": 2063.2654390335083, "episode/length": 277.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9820143884892086, "episode/intrinsic_return": 0.0}
{"step": 62504, "time": 2066.8807373046875, "episode/length": 206.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 62872, "time": 2077.115144968033, "episode/length": 208.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9712918660287081, "episode/intrinsic_return": 0.0}
{"step": 63088, "time": 2083.681670188904, "episode/length": 170.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 63112, "time": 2085.107561349869, "episode/length": 177.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 63328, "time": 2091.570859670639, "episode/length": 192.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 63376, "time": 2093.6127455234528, "episode/length": 417.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9784688995215312, "episode/intrinsic_return": 0.0}
{"step": 63624, "time": 2100.5068571567535, "episode/length": 139.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 64040, "time": 2111.7576706409454, "episode/length": 270.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.985239852398524, "episode/intrinsic_return": 0.0}
{"step": 64056, "time": 2113.050037622452, "episode/length": 208.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 64168, "time": 2116.695930480957, "episode/length": 161.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 64920, "time": 2136.4258856773376, "episode/length": 192.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 64921, "time": 2138.135187625885, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.581741786239171, "train/action_min": 0.0, "train/action_std": 2.588350037241926, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0351719735559113, "train/actor_opt_grad_steps": 2955.0, "train/actor_opt_loss": 36.44255660046445, "train/adv_mag": 1.6914923359261882, "train/adv_max": 1.6885357835505268, "train/adv_mean": 0.020199492599726233, "train/adv_min": -0.5930709176429427, "train/adv_std": 0.1332821433275643, "train/cont_avg": 0.9939665841584159, "train/cont_loss_mean": 0.0007602162726547393, "train/cont_loss_std": 0.019552141661914012, "train/cont_neg_acc": 0.9785733957691948, "train/cont_neg_loss": 0.06941506659068812, "train/cont_pos_acc": 0.9998783345269685, "train/cont_pos_loss": 0.0003318266951861132, "train/cont_pred": 0.9939446691239234, "train/cont_rate": 0.9939665841584159, "train/dyn_loss_mean": 6.99933385612941, "train/dyn_loss_std": 6.057076815331336, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.3526203180893812, "train/extr_critic_critic_opt_grad_steps": 2955.0, "train/extr_critic_critic_opt_loss": 15476.664816676981, "train/extr_critic_mag": 1.6936168906712297, "train/extr_critic_max": 1.6936168906712297, "train/extr_critic_mean": 0.47503257122370274, "train/extr_critic_min": -0.21739495921843122, "train/extr_critic_std": 0.6209808745891741, "train/extr_return_normed_mag": 2.5104140308823917, "train/extr_return_normed_max": 2.5104140308823917, "train/extr_return_normed_mean": 0.37962186476676774, "train/extr_return_normed_min": -0.20119896310607507, "train/extr_return_normed_std": 0.39203573674848763, "train/extr_return_rate": 0.3582463321266788, "train/extr_return_raw_mag": 4.281188400665132, "train/extr_return_raw_max": 4.281188400665132, "train/extr_return_raw_mean": 0.5081215680456987, "train/extr_return_raw_min": -0.5120954322490362, "train/extr_return_raw_std": 0.6950958452307352, "train/extr_reward_mag": 0.9978975329068628, "train/extr_reward_max": 0.9978975329068628, "train/extr_reward_mean": 0.014035960967136123, "train/extr_reward_min": -0.2861693495571023, "train/extr_reward_std": 0.09729605942669481, "train/image_loss_mean": 14.718006747784, "train/image_loss_std": 16.26656695167617, "train/model_loss_mean": 18.97634490645758, "train/model_loss_std": 18.10189102191736, "train/model_opt_grad_norm": 127.39487536590879, "train/model_opt_grad_steps": 2945.0, "train/model_opt_loss": 1113.5394439697266, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 56.756652227722775, "train/policy_entropy_mag": 1.8883814292378944, "train/policy_entropy_max": 1.8883814292378944, "train/policy_entropy_mean": 0.315370734301534, "train/policy_entropy_min": 0.07952983588865488, "train/policy_entropy_std": 0.2948697002069785, "train/policy_logprob_mag": 7.437354477325289, "train/policy_logprob_max": -0.009477479323412818, "train/policy_logprob_mean": -0.31509453618880545, "train/policy_logprob_min": -7.437354477325289, "train/policy_logprob_std": 0.9274526377125542, "train/policy_randomness_mag": 0.6665157752461953, "train/policy_randomness_max": 0.6665157752461953, "train/policy_randomness_mean": 0.1113120293484466, "train/policy_randomness_min": 0.028070542002373404, "train/policy_randomness_std": 0.10407606359239262, "train/post_ent_mag": 41.52423790657874, "train/post_ent_max": 41.52423790657874, "train/post_ent_mean": 31.756092014879282, "train/post_ent_min": 14.495668024119764, "train/post_ent_std": 4.312679085401025, "train/prior_ent_mag": 53.460901128183494, "train/prior_ent_max": 53.460901128183494, "train/prior_ent_mean": 38.845086730352726, "train/prior_ent_min": 17.77584179321138, "train/prior_ent_std": 4.866681192180898, "train/rep_loss_mean": 6.99933385612941, "train/rep_loss_std": 6.057076815331336, "train/reward_avg": 0.007860361215759917, "train/reward_loss_mean": 0.05797758987081228, "train/reward_loss_std": 0.31574376591361397, "train/reward_max_data": 1.0004950496229794, "train/reward_max_pred": 0.9959224952329503, "train/reward_neg_acc": 0.9957009232280278, "train/reward_neg_loss": 0.04034169255709737, "train/reward_pos_acc": 0.8547316788151713, "train/reward_pos_loss": 1.382552353757443, "train/reward_pred": 0.006879305337915326, "train/reward_rate": 0.013275448638613862, "train_stats/sum_log_reward": 2.229943428251703, "train_stats/max_log_achievement_collect_drink": 13.76271186440678, "train_stats/max_log_achievement_collect_sapling": 3.0847457627118646, "train_stats/max_log_achievement_collect_wood": 0.2542372881355932, "train_stats/max_log_achievement_defeat_zombie": 0.1638418079096045, "train_stats/max_log_achievement_eat_cow": 0.07909604519774012, "train_stats/max_log_achievement_place_plant": 1.7231638418079096, "train_stats/max_log_achievement_place_table": 0.0, "train_stats/max_log_achievement_wake_up": 1.4858757062146892, "train_stats/mean_log_entropy": 0.28364352839814744, "eval_stats/sum_log_reward": 1.3916666160027187, "eval_stats/max_log_achievement_collect_drink": 2.3333333333333335, "eval_stats/max_log_achievement_collect_sapling": 1.875, "eval_stats/max_log_achievement_collect_wood": 0.375, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.16666666666666666, "eval_stats/max_log_achievement_place_plant": 1.4583333333333333, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 0.8333333333333334, "eval_stats/mean_log_entropy": 0.0, "train_stats/max_log_achievement_defeat_skeleton": 0.024390243902439025, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.00036378015647642314, "report/cont_loss_std": 0.010857718996703625, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 2.2351237930706702e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.00036545548937283456, "report/cont_pred": 0.9948064088821411, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 7.029263973236084, "report/dyn_loss_std": 6.1101765632629395, "report/image_loss_mean": 13.574957847595215, "report/image_loss_std": 13.2422513961792, "report/model_loss_mean": 17.842819213867188, "report/model_loss_std": 15.108787536621094, "report/post_ent_mag": 43.15202331542969, "report/post_ent_max": 43.15202331542969, "report/post_ent_mean": 32.96868133544922, "report/post_ent_min": 16.749488830566406, "report/post_ent_std": 4.528013229370117, "report/prior_ent_mag": 60.30377197265625, "report/prior_ent_max": 60.30377197265625, "report/prior_ent_mean": 39.99458312988281, "report/prior_ent_min": 22.657310485839844, "report/prior_ent_std": 4.475266456604004, "report/rep_loss_mean": 7.029263973236084, "report/rep_loss_std": 6.1101765632629395, "report/reward_avg": 0.005859375, "report/reward_loss_mean": 0.049939826130867004, "report/reward_loss_std": 0.2724035084247589, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0011310577392578, "report/reward_neg_acc": 0.9911155700683594, "report/reward_neg_loss": 0.039506301283836365, "report/reward_pos_acc": 0.9090909361839294, "report/reward_pos_loss": 1.0107725858688354, "report/reward_pred": 0.006595072336494923, "report/reward_rate": 0.0107421875, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 9.924397454597056e-05, "eval/cont_loss_std": 0.0021366479340940714, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.012508276849985123, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 5.058110036770813e-05, "eval/cont_pred": 0.9960920810699463, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 11.258301734924316, "eval/dyn_loss_std": 7.53494930267334, "eval/image_loss_mean": 27.869365692138672, "eval/image_loss_std": 24.566730499267578, "eval/model_loss_mean": 34.71485900878906, "eval/model_loss_std": 27.152389526367188, "eval/post_ent_mag": 43.54228210449219, "eval/post_ent_max": 43.54228210449219, "eval/post_ent_mean": 30.926237106323242, "eval/post_ent_min": 14.751470565795898, "eval/post_ent_std": 5.515580177307129, "eval/prior_ent_mag": 55.816619873046875, "eval/prior_ent_max": 55.816619873046875, "eval/prior_ent_mean": 40.298370361328125, "eval/prior_ent_min": 17.64278793334961, "eval/prior_ent_std": 7.271125793457031, "eval/rep_loss_mean": 11.258301734924316, "eval/rep_loss_std": 7.53494930267334, "eval/reward_avg": 0.0078125, "eval/reward_loss_mean": 0.09041567891836166, "eval/reward_loss_std": 0.7248483300209045, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0011742115020752, "eval/reward_neg_acc": 0.9990118741989136, "eval/reward_neg_loss": 0.03616877645254135, "eval/reward_pos_acc": 0.4166666865348816, "eval/reward_pos_loss": 4.665237903594971, "eval/reward_pred": 0.0007474981248378754, "eval/reward_rate": 0.01171875, "replay/size": 64417.0, "replay/inserts": 32224.0, "replay/samples": 32224.0, "replay/insert_wait_avg": 1.307462213529494e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 6.732380141567924e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 13112.0, "eval_replay/inserts": 5128.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2901941439290873e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.301568984985352e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.8140225410461, "timer/env.step_count": 4028.0, "timer/env.step_total": 161.54059600830078, "timer/env.step_frac": 0.16140920527687305, "timer/env.step_avg": 0.04010441807554637, "timer/env.step_min": 0.002296924591064453, "timer/env.step_max": 1.0101792812347412, "timer/replay._sample_count": 32224.0, "timer/replay._sample_total": 2939.465006828308, "timer/replay._sample_frac": 2.937074162255508, "timer/replay._sample_avg": 0.0912197432605607, "timer/replay._sample_min": 0.0003666877746582031, "timer/replay._sample_max": 0.1412506103515625, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4669.0, "timer/agent.policy_total": 47.70700478553772, "timer/agent.policy_frac": 0.047668201794785627, "timer/agent.policy_avg": 0.01021782068655766, "timer/agent.policy_min": 0.007876873016357422, "timer/agent.policy_max": 0.0646507740020752, "timer/dataset_train_count": 2014.0, "timer/dataset_train_total": 0.16274452209472656, "timer/dataset_train_frac": 0.00016261215213743865, "timer/dataset_train_avg": 8.080661474415421e-05, "timer/dataset_train_min": 5.626678466796875e-05, "timer/dataset_train_max": 0.0001671314239501953, "timer/agent.train_count": 2014.0, "timer/agent.train_total": 761.1289060115814, "timer/agent.train_frac": 0.7605098338641287, "timer/agent.train_avg": 0.37791901986672366, "timer/agent.train_min": 0.35419464111328125, "timer/agent.train_max": 0.660017728805542, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4205772876739502, "timer/agent.report_frac": 0.0004202352067431201, "timer/agent.report_avg": 0.2102886438369751, "timer/agent.report_min": 0.20850849151611328, "timer/agent.report_max": 0.21206879615783691, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.457069396972656e-05, "timer/dataset_eval_frac": 3.45425755346156e-08, "timer/dataset_eval_avg": 3.457069396972656e-05, "timer/dataset_eval_min": 3.457069396972656e-05, "timer/dataset_eval_max": 3.457069396972656e-05, "fps": 32.197470309243904}
{"step": 64976, "time": 2139.3786902427673, "episode/length": 168.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 65120, "time": 2144.639663219452, "episode/length": 253.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9881889763779528, "episode/intrinsic_return": 0.0}
{"step": 65192, "time": 2147.16073513031, "episode/length": 33.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 65312, "time": 2151.252614736557, "episode/length": 247.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9959677419354839, "episode/intrinsic_return": 0.0}
{"step": 65440, "time": 2155.3235051631927, "episode/length": 158.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 65632, "time": 2161.043068408966, "episode/length": 39.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 65992, "time": 2170.9384825229645, "episode/length": 243.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9795081967213115, "episode/intrinsic_return": 0.0}
{"step": 66480, "time": 2184.412976026535, "episode/length": 169.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 66600, "time": 2188.202300310135, "episode/length": 435.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9793577981651376, "episode/intrinsic_return": 0.0}
{"step": 66736, "time": 2192.78289604187, "episode/length": 192.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 66792, "time": 2194.849145889282, "episode/length": 144.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 66832, "time": 2196.8657908439636, "episode/length": 173.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 67048, "time": 2202.943021774292, "episode/length": 258.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9652509652509652, "episode/intrinsic_return": 0.0}
{"step": 67072, "time": 2204.594587802887, "episode/length": 376.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9761273209549072, "episode/intrinsic_return": 0.0}
{"step": 67248, "time": 2209.787700176239, "episode/length": 51.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9038461538461539, "episode/intrinsic_return": 0.0}
{"step": 67384, "time": 2213.7821559906006, "episode/length": 112.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9557522123893806, "episode/intrinsic_return": 0.0}
{"step": 67800, "time": 2225.148269176483, "episode/length": 225.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9823008849557522, "episode/intrinsic_return": 0.0}
{"step": 67968, "time": 2230.375988006592, "episode/length": 170.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9649122807017544, "episode/intrinsic_return": 0.0}
{"step": 68256, "time": 2238.5009138584137, "episode/length": 182.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 68392, "time": 2242.735742330551, "episode/length": 164.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 68568, "time": 2247.985333442688, "episode/length": 38.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8717948717948718, "episode/intrinsic_return": 0.0}
{"step": 68696, "time": 2252.0195429325104, "episode/length": 205.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 68784, "time": 2255.288430452347, "episode/length": 255.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.98046875, "episode/intrinsic_return": 0.0}
{"step": 68952, "time": 2260.1919980049133, "episode/length": 31.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.875, "episode/intrinsic_return": 0.0}
{"step": 68976, "time": 2261.7737741470337, "episode/length": 215.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 69048, "time": 2264.290210723877, "episode/length": 59.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9166666666666666, "episode/intrinsic_return": 0.0}
{"step": 69088, "time": 2266.3583014011383, "episode/length": 139.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.0}
{"step": 69280, "time": 2272.0475606918335, "episode/length": 37.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 69312, "time": 2273.6420516967773, "episode/length": 44.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.8888888888888888, "episode/intrinsic_return": 0.0}
{"step": 69408, "time": 2276.861752271652, "episode/length": 39.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 69424, "time": 2278.140676498413, "episode/length": 254.0, "episode/score": 5.099999964237213, "episode/reward_rate": 0.996078431372549, "episode/intrinsic_return": 0.0}
{"step": 69464, "time": 2279.812874317169, "episode/length": 207.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 70040, "time": 2295.102168560028, "episode/length": 205.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 70096, "time": 2299.073748111725, "eval_episode/length": 35.0, "eval_episode/score": 1.0999999716877937, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 70096, "time": 2301.2017500400543, "eval_episode/length": 108.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9541284403669725}
{"step": 70096, "time": 2302.8671412467957, "eval_episode/length": 151.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9539473684210527}
{"step": 70096, "time": 2304.0476615428925, "eval_episode/length": 169.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9764705882352941}
{"step": 70096, "time": 2304.899432659149, "eval_episode/length": 170.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9707602339181286}
{"step": 70096, "time": 2305.8592627048492, "eval_episode/length": 176.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9774011299435028}
{"step": 70096, "time": 2306.97820687294, "eval_episode/length": 187.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.973404255319149}
{"step": 70096, "time": 2307.9148099422455, "eval_episode/length": 154.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.967741935483871}
{"step": 70280, "time": 2312.5781915187836, "episode/length": 153.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 70384, "time": 2316.2112448215485, "episode/length": 199.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 70520, "time": 2320.196545600891, "episode/length": 138.0, "episode/score": 3.100000023841858, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.0}
{"step": 70528, "time": 2321.464209318161, "episode/length": 155.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 70544, "time": 2322.7260320186615, "episode/length": 32.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 70904, "time": 2332.416166305542, "episode/length": 198.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 70992, "time": 2335.7178478240967, "episode/length": 195.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 71536, "time": 2350.362412929535, "episode/length": 186.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 71568, "time": 2352.024646282196, "episode/length": 262.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9847908745247148, "episode/intrinsic_return": 0.0}
{"step": 71776, "time": 2358.1350848674774, "episode/length": 155.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 72272, "time": 2371.469506263733, "episode/length": 235.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9915254237288136, "episode/intrinsic_return": 0.0}
{"step": 72328, "time": 2373.51912856102, "episode/length": 177.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 72472, "time": 2378.0217633247375, "episode/length": 243.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9795081967213115, "episode/intrinsic_return": 0.0}
{"step": 72816, "time": 2387.8546340465546, "episode/length": 227.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9780701754385965, "episode/intrinsic_return": 0.0}
{"step": 73024, "time": 2394.025390148163, "episode/length": 185.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 73072, "time": 2396.1615841388702, "episode/length": 31.0, "episode/score": 0.10000000149011612, "episode/reward_rate": 0.875, "episode/intrinsic_return": 0.0}
{"step": 73536, "time": 2408.7484765052795, "episode/length": 373.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9973262032085561, "episode/intrinsic_return": 0.0}
{"step": 73760, "time": 2415.2442104816437, "episode/length": 273.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9854014598540146, "episode/intrinsic_return": 0.0}
{"step": 73824, "time": 2417.6669890880585, "episode/length": 193.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 73864, "time": 2419.3111407756805, "episode/length": 191.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 74016, "time": 2424.1354365348816, "episode/length": 192.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 74384, "time": 2434.0037343502045, "episode/length": 169.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 74768, "time": 2444.585295677185, "episode/length": 112.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9469026548672567, "episode/intrinsic_return": 0.0}
{"step": 74792, "time": 2445.8432302474976, "episode/length": 128.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9534883720930233, "episode/intrinsic_return": 0.0}
{"step": 74800, "time": 2447.017498254776, "episode/length": 215.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 74928, "time": 2451.121463537216, "episode/length": 173.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 74984, "time": 2453.169524908066, "episode/length": 400.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9775561097256857, "episode/intrinsic_return": 0.0}
{"step": 75224, "time": 2460.0942561626434, "episode/length": 174.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 75232, "time": 2461.4026584625244, "episode/length": 37.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 75240, "time": 2462.2622299194336, "episode/length": 152.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 76032, "time": 2483.2555508613586, "episode/length": 153.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 76080, "time": 2485.3570148944855, "episode/length": 211.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 76104, "time": 2486.6128673553467, "episode/length": 163.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 76368, "time": 2494.2405791282654, "episode/length": 172.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9595375722543352, "episode/intrinsic_return": 0.0}
{"step": 76376, "time": 2495.15345454216, "episode/length": 36.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 76416, "time": 2497.099857568741, "episode/length": 147.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 76696, "time": 2504.797789812088, "episode/length": 183.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 76760, "time": 2507.2275474071503, "episode/length": 248.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9879518072289156, "episode/intrinsic_return": 0.0}
{"step": 76992, "time": 2513.8938794136047, "episode/length": 218.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 77272, "time": 2521.4370517730713, "episode/length": 34.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 77328, "time": 2523.981885910034, "episode/length": 113.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9649122807017544, "episode/intrinsic_return": 0.0}
{"step": 77400, "time": 2526.4526171684265, "episode/length": 170.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 77904, "time": 2539.905280828476, "episode/length": 150.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 78256, "time": 2549.6528499126434, "episode/length": 268.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9851301115241635, "episode/intrinsic_return": 0.0}
{"step": 78328, "time": 2552.1828215122223, "episode/length": 243.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9795081967213115, "episode/intrinsic_return": 0.0}
{"step": 78520, "time": 2557.9008100032806, "episode/length": 155.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 78544, "time": 2559.5738246440887, "episode/length": 271.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9852941176470589, "episode/intrinsic_return": 0.0}
{"step": 78648, "time": 2562.841025352478, "episode/length": 235.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9788135593220338, "episode/intrinsic_return": 0.0}
{"step": 78816, "time": 2568.0044691562653, "episode/length": 185.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 78864, "time": 2570.0564546585083, "episode/length": 42.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.8837209302325582, "episode/intrinsic_return": 0.0}
{"step": 79136, "time": 2577.7342340946198, "episode/length": 153.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 79320, "time": 2583.0582127571106, "episode/length": 239.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 79408, "time": 2586.2915029525757, "episode/length": 73.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9324324324324325, "episode/intrinsic_return": 0.0}
{"step": 79488, "time": 2589.0742330551147, "episode/length": 77.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9358974358974359, "episode/intrinsic_return": 0.0}
{"step": 79728, "time": 2596.1672286987305, "episode/length": 50.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9019607843137255, "episode/intrinsic_return": 0.0}
{"step": 79816, "time": 2598.944301366806, "episode/length": 185.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 80024, "time": 2604.872777223587, "episode/length": 171.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 80080, "time": 2610.7924683094025, "eval_episode/length": 154.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.967741935483871}
{"step": 80080, "time": 2611.9356026649475, "eval_episode/length": 170.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9766081871345029}
{"step": 80080, "time": 2613.0036232471466, "eval_episode/length": 179.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 80080, "time": 2614.0887730121613, "eval_episode/length": 38.0, "eval_episode/score": -0.9000000283122063, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 80080, "time": 2615.6438031196594, "eval_episode/length": 233.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9786324786324786}
{"step": 80080, "time": 2616.6465876102448, "eval_episode/length": 240.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.975103734439834}
{"step": 80080, "time": 2618.0533328056335, "eval_episode/length": 36.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.972972972972973}
{"step": 80080, "time": 2619.2872643470764, "eval_episode/length": 294.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9864406779661017}
{"step": 80120, "time": 2620.2306950092316, "episode/length": 48.0, "episode/score": -0.8999999910593033, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 80560, "time": 2632.2297129631042, "episode/length": 287.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9861111111111112, "episode/intrinsic_return": 0.0}
{"step": 80848, "time": 2640.3367414474487, "episode/length": 213.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9813084112149533, "episode/intrinsic_return": 0.0}
{"step": 81048, "time": 2646.1183807849884, "episode/length": 127.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9609375, "episode/intrinsic_return": 0.0}
{"step": 81072, "time": 2647.8046629428864, "episode/length": 197.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 81736, "time": 2665.3020508289337, "episode/length": 239.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 81960, "time": 2671.9504628181458, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 82040, "time": 2674.7909150123596, "episode/length": 239.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 82104, "time": 2677.201737880707, "episode/length": 156.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 82152, "time": 2679.249737262726, "episode/length": 342.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9941690962099126, "episode/intrinsic_return": 0.0}
{"step": 82272, "time": 2683.416396379471, "episode/length": 465.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9914163090128756, "episode/intrinsic_return": 0.0}
{"step": 82344, "time": 2686.007755756378, "episode/length": 158.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 82648, "time": 2694.4554402828217, "episode/length": 199.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 83184, "time": 2709.0789580345154, "episode/length": 142.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.972027972027972, "episode/intrinsic_return": 0.0}
{"step": 83288, "time": 2712.299889564514, "episode/length": 193.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 83360, "time": 2715.0728046894073, "episode/length": 156.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9808917197452229, "episode/intrinsic_return": 0.0}
{"step": 83480, "time": 2718.713706970215, "episode/length": 103.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9519230769230769, "episode/intrinsic_return": 0.0}
{"step": 83648, "time": 2723.8699519634247, "episode/length": 35.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 83800, "time": 2728.309365749359, "episode/length": 190.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 84072, "time": 2735.8398327827454, "episode/length": 239.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 84240, "time": 2741.173315048218, "episode/length": 284.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9859649122807017, "episode/intrinsic_return": 0.0}
{"step": 84408, "time": 2746.1364941596985, "episode/length": 20.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9523809523809523, "episode/intrinsic_return": 0.0}
{"step": 84528, "time": 2750.258700609207, "episode/length": 272.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.989010989010989, "episode/intrinsic_return": 0.0}
{"step": 84680, "time": 2754.783355951309, "episode/length": 149.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 85344, "time": 2772.2608988285065, "episode/length": 192.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 85360, "time": 2773.460611104965, "episode/length": 213.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9813084112149533, "episode/intrinsic_return": 0.0}
{"step": 85544, "time": 2778.652396917343, "episode/length": 281.0, "episode/score": 1.0999999791383743, "episode/reward_rate": 0.9964539007092199, "episode/intrinsic_return": 0.0}
{"step": 85592, "time": 2780.8109691143036, "episode/length": 300.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9867109634551495, "episode/intrinsic_return": 0.0}
{"step": 85928, "time": 2790.264710187912, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 86168, "time": 2797.238983631134, "episode/length": 261.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9809160305343512, "episode/intrinsic_return": 0.0}
{"step": 86280, "time": 2800.8975880146027, "episode/length": 199.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 86408, "time": 2805.001822948456, "episode/length": 249.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 86816, "time": 2816.10599899292, "episode/length": 181.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 86832, "time": 2817.4064934253693, "episode/length": 154.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 86984, "time": 2821.9501490592957, "episode/length": 204.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 87024, "time": 2823.9191648960114, "episode/length": 184.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 87072, "time": 2825.993683576584, "episode/length": 142.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 87640, "time": 2840.828759908676, "episode/length": 102.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9514563106796117, "episode/intrinsic_return": 0.0}
{"step": 87784, "time": 2845.279606819153, "episode/length": 171.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 88000, "time": 2851.726333141327, "episode/length": 228.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9781659388646288, "episode/intrinsic_return": 0.0}
{"step": 88160, "time": 2856.445737838745, "episode/length": 234.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9829787234042553, "episode/intrinsic_return": 0.0}
{"step": 88456, "time": 2864.6092953681946, "episode/length": 178.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 88728, "time": 2872.397806406021, "episode/length": 206.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 88840, "time": 2876.0058546066284, "episode/length": 149.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.96, "episode/intrinsic_return": 0.0}
{"step": 88848, "time": 2877.320806980133, "episode/length": 232.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 89392, "time": 2892.0798230171204, "episode/length": 200.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9800995024875622, "episode/intrinsic_return": 0.0}
{"step": 89536, "time": 2896.415774822235, "episode/length": 191.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 89608, "time": 2898.814831972122, "episode/length": 180.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 89672, "time": 2901.210780620575, "episode/length": 151.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 90008, "time": 2910.243773460388, "episode/length": 144.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 90032, "time": 2911.8313376903534, "episode/length": 399.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9975, "episode/intrinsic_return": 0.0}
{"step": 90064, "time": 2916.468379020691, "eval_episode/length": 143.0, "eval_episode/score": 4.099999979138374, "eval_episode/reward_rate": 0.9930555555555556}
{"step": 90064, "time": 2917.542791366577, "eval_episode/length": 157.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9746835443037974}
{"step": 90064, "time": 2918.824458837509, "eval_episode/length": 185.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.9731182795698925}
{"step": 90064, "time": 2919.931533575058, "eval_episode/length": 199.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.97}
{"step": 90064, "time": 2920.976109266281, "eval_episode/length": 211.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9764150943396226}
{"step": 90064, "time": 2922.1727228164673, "eval_episode/length": 226.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9779735682819384}
{"step": 90064, "time": 2922.9668352603912, "eval_episode/length": 227.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 90064, "time": 2924.101539373398, "eval_episode/length": 242.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9753086419753086}
{"step": 90216, "time": 2928.0544452667236, "episode/length": 171.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 90264, "time": 2930.035626411438, "episode/length": 191.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 90976, "time": 2948.7614736557007, "episode/length": 170.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 91096, "time": 2952.3768203258514, "episode/length": 212.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9812206572769953, "episode/intrinsic_return": 0.0}
{"step": 91368, "time": 2960.056876897812, "episode/length": 228.0, "episode/score": 5.100000016391277, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 91408, "time": 2962.0027062892914, "episode/length": 216.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 91472, "time": 2964.4290504455566, "episode/length": 150.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9735099337748344, "episode/intrinsic_return": 0.0}
{"step": 91624, "time": 2968.8957641124725, "episode/length": 201.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 91648, "time": 2970.555475950241, "episode/length": 178.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 91784, "time": 2974.5561304092407, "episode/length": 218.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9817351598173516, "episode/intrinsic_return": 0.0}
{"step": 92232, "time": 2986.737904548645, "episode/length": 156.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9617834394904459, "episode/intrinsic_return": 0.0}
{"step": 92608, "time": 2996.9859895706177, "episode/length": 188.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 92688, "time": 2999.7844984531403, "episode/length": 164.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 92800, "time": 3003.356261730194, "episode/length": 165.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 92816, "time": 3004.646569252014, "episode/length": 148.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 93080, "time": 3011.8601546287537, "episode/length": 208.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9808612440191388, "episode/intrinsic_return": 0.0}
{"step": 93104, "time": 3013.4890909194946, "episode/length": 181.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 93224, "time": 3017.0497064590454, "episode/length": 179.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 93912, "time": 3035.0645403862, "episode/length": 162.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9570552147239264, "episode/intrinsic_return": 0.0}
{"step": 94280, "time": 3044.961884498596, "episode/length": 149.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.96, "episode/intrinsic_return": 0.0}
{"step": 94352, "time": 3047.7057886123657, "episode/length": 155.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 94424, "time": 3050.1036751270294, "episode/length": 200.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 94624, "time": 3056.0041904449463, "episode/length": 174.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 94712, "time": 3058.991735458374, "episode/length": 238.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9748953974895398, "episode/intrinsic_return": 0.0}
{"step": 94712, "time": 3059.003779411316, "episode/length": 252.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9802371541501976, "episode/intrinsic_return": 0.0}
{"step": 95416, "time": 3077.4258937835693, "episode/length": 397.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9773869346733668, "episode/intrinsic_return": 0.0}
{"step": 95504, "time": 3080.7263655662537, "episode/length": 198.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 95632, "time": 3084.7029888629913, "episode/length": 168.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 95664, "time": 3086.3671085834503, "episode/length": 163.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 95920, "time": 3093.720278739929, "episode/length": 161.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 96064, "time": 3098.096767425537, "episode/length": 168.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 96296, "time": 3104.6013617515564, "episode/length": 233.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9786324786324786, "episode/intrinsic_return": 0.0}
{"step": 96416, "time": 3108.508880853653, "episode/length": 212.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9812206572769953, "episode/intrinsic_return": 0.0}
{"step": 97000, "time": 3123.8457391262054, "episode/length": 170.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 97000, "time": 3123.8586757183075, "episode/length": 197.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 97024, "time": 3125.505708694458, "episode/length": 119.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9416666666666667, "episode/intrinsic_return": 0.0}
{"step": 97056, "time": 3127.1365003585815, "episode/length": 193.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 97280, "time": 3133.588423728943, "episode/length": 169.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 97417, "time": 3138.3105368614197, "train_stats/sum_log_reward": 3.1055865298602834, "train_stats/max_log_achievement_collect_drink": 18.23463687150838, "train_stats/max_log_achievement_collect_sapling": 2.4134078212290504, "train_stats/max_log_achievement_collect_wood": 1.4692737430167597, "train_stats/max_log_achievement_defeat_skeleton": 0.0111731843575419, "train_stats/max_log_achievement_defeat_zombie": 0.1452513966480447, "train_stats/max_log_achievement_eat_cow": 0.0335195530726257, "train_stats/max_log_achievement_place_plant": 1.7374301675977655, "train_stats/max_log_achievement_place_table": 0.0223463687150838, "train_stats/max_log_achievement_wake_up": 1.553072625698324, "train_stats/mean_log_entropy": 0.624107313888699, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 3.93040188192734, "train/action_min": 0.0, "train/action_std": 2.5778079355878782, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.043910388490689796, "train/actor_opt_grad_steps": 4980.0, "train/actor_opt_loss": 9.335750016966477, "train/adv_mag": 1.119139962008434, "train/adv_max": 1.1169771566766824, "train/adv_mean": 0.005852306898896356, "train/adv_min": -0.5601110631609197, "train/adv_std": 0.09188284543274071, "train/cont_avg": 0.9941694889162561, "train/cont_loss_mean": 0.0006164267900543914, "train/cont_loss_std": 0.016951401849342497, "train/cont_neg_acc": 0.9831591806388253, "train/cont_neg_loss": 0.060780973786542944, "train/cont_pos_acc": 0.9999224223526828, "train/cont_pos_loss": 0.00023374405791294525, "train/cont_pred": 0.9941724961614374, "train/cont_rate": 0.9941694889162561, "train/dyn_loss_mean": 8.772338629943397, "train/dyn_loss_std": 7.159164064623452, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1711348491936482, "train/extr_critic_critic_opt_grad_steps": 4980.0, "train/extr_critic_critic_opt_loss": 13667.104126577895, "train/extr_critic_mag": 2.202666763014394, "train/extr_critic_max": 2.202666763014394, "train/extr_critic_mean": 0.5603641377294005, "train/extr_critic_min": -0.17077823930186004, "train/extr_critic_std": 0.6826096030291665, "train/extr_return_normed_mag": 2.0893932193370874, "train/extr_return_normed_max": 2.0893932193370874, "train/extr_return_normed_mean": 0.3388412777573017, "train/extr_return_normed_min": -0.20345339002867638, "train/extr_return_normed_std": 0.36640898318126286, "train/extr_return_rate": 0.34640581942544196, "train/extr_return_raw_mag": 4.00281306440607, "train/extr_return_raw_max": 4.00281306440607, "train/extr_return_raw_mean": 0.5720966768088599, "train/extr_return_raw_min": -0.49430105824188647, "train/extr_return_raw_std": 0.7203288486438432, "train/extr_reward_mag": 1.0025333911914545, "train/extr_reward_max": 1.0025333911914545, "train/extr_reward_mean": 0.012014963222539117, "train/extr_reward_min": -0.2970884956162551, "train/extr_reward_std": 0.09420069167619856, "train/image_loss_mean": 17.605497021980472, "train/image_loss_std": 22.209861621480858, "train/model_loss_mean": 22.921817746655694, "train/model_loss_std": 24.83245283042269, "train/model_opt_grad_norm": 116.67168939524683, "train/model_opt_grad_steps": 4970.0, "train/model_opt_loss": 5194.752672918911, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 229.75677339901478, "train/policy_entropy_mag": 2.202947385205424, "train/policy_entropy_max": 2.202947385205424, "train/policy_entropy_mean": 0.6219232158707868, "train/policy_entropy_min": 0.07942382070084511, "train/policy_entropy_std": 0.3936140088024985, "train/policy_logprob_mag": 7.437680455851438, "train/policy_logprob_max": -0.009462914347024681, "train/policy_logprob_mean": -0.6218834680876708, "train/policy_logprob_min": -7.437680455851438, "train/policy_logprob_std": 1.0852692315143904, "train/policy_randomness_mag": 0.7775437535323533, "train/policy_randomness_max": 0.7775437535323533, "train/policy_randomness_mean": 0.2195116025693898, "train/policy_randomness_min": 0.02803312323693865, "train/policy_randomness_std": 0.1389284705734018, "train/post_ent_mag": 45.83717879873191, "train/post_ent_max": 45.83717879873191, "train/post_ent_mean": 33.62912095356457, "train/post_ent_min": 17.13087971692015, "train/post_ent_std": 4.972898900215261, "train/prior_ent_mag": 58.01881393658117, "train/prior_ent_max": 58.01881393658117, "train/prior_ent_mean": 42.487120999491275, "train/prior_ent_min": 19.211208226058282, "train/prior_ent_std": 6.221422456168189, "train/rep_loss_mean": 8.772338629943397, "train/rep_loss_std": 7.159164064623452, "train/reward_avg": 0.010645012250238929, "train/reward_loss_mean": 0.05230116719389197, "train/reward_loss_std": 0.28505879391003125, "train/reward_max_data": 1.003448276684202, "train/reward_max_pred": 1.0007332868763965, "train/reward_neg_acc": 0.9947293935150936, "train/reward_neg_loss": 0.03402376035457762, "train/reward_pos_acc": 0.8956139854022435, "train/reward_pos_loss": 1.1963336699701883, "train/reward_pred": 0.00960127021222756, "train/reward_rate": 0.015879964593596058, "train_stats/max_log_achievement_make_wood_pickaxe": 0.006024096385542169, "eval_stats/sum_log_reward": 3.2666666147609553, "eval_stats/max_log_achievement_collect_drink": 25.291666666666668, "eval_stats/max_log_achievement_collect_sapling": 2.1666666666666665, "eval_stats/max_log_achievement_collect_wood": 2.0833333333333335, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.125, "eval_stats/max_log_achievement_eat_cow": 0.16666666666666666, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_place_plant": 1.7083333333333333, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 1.375, "eval_stats/mean_log_entropy": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.01639344262295082, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 1.591267755429726e-05, "report/cont_loss_std": 0.00016018247697502375, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0015567189548164606, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 5.307325864123413e-06, "report/cont_pred": 0.9931694269180298, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 9.602712631225586, "report/dyn_loss_std": 8.20999526977539, "report/image_loss_mean": 14.689702987670898, "report/image_loss_std": 18.525684356689453, "report/model_loss_mean": 20.509668350219727, "report/model_loss_std": 22.03982162475586, "report/post_ent_mag": 44.709110260009766, "report/post_ent_max": 44.709110260009766, "report/post_ent_mean": 34.62826156616211, "report/post_ent_min": 18.799633026123047, "report/post_ent_std": 4.59561014175415, "report/prior_ent_mag": 59.741355895996094, "report/prior_ent_max": 59.741355895996094, "report/prior_ent_mean": 44.778446197509766, "report/prior_ent_min": 19.447296142578125, "report/prior_ent_std": 6.9654459953308105, "report/rep_loss_mean": 9.602712631225586, "report/rep_loss_std": 8.20999526977539, "report/reward_avg": 0.01533203013241291, "report/reward_loss_mean": 0.058320797979831696, "report/reward_loss_std": 0.27446597814559937, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0000255107879639, "report/reward_neg_acc": 0.9930069446563721, "report/reward_neg_loss": 0.0329677015542984, "report/reward_pos_acc": 0.95652174949646, "report/reward_pos_loss": 1.1617316007614136, "report/reward_pred": 0.011687546968460083, "report/reward_rate": 0.0224609375, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 7.941658623167314e-06, "eval/cont_loss_std": 0.0001173963537439704, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.001322957337833941, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 5.36824154551141e-06, "eval/cont_pred": 0.9980441331863403, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 13.101305961608887, "eval/dyn_loss_std": 7.829711437225342, "eval/image_loss_mean": 27.770896911621094, "eval/image_loss_std": 23.76648712158203, "eval/model_loss_mean": 35.65906524658203, "eval/model_loss_std": 26.74859046936035, "eval/post_ent_mag": 45.61760711669922, "eval/post_ent_max": 45.61760711669922, "eval/post_ent_mean": 31.49446678161621, "eval/post_ent_min": 17.877363204956055, "eval/post_ent_std": 4.394515514373779, "eval/prior_ent_mag": 59.14596176147461, "eval/prior_ent_max": 59.14596176147461, "eval/prior_ent_mean": 42.538848876953125, "eval/prior_ent_min": 20.821557998657227, "eval/prior_ent_std": 7.506595611572266, "eval/rep_loss_mean": 13.101305961608887, "eval/rep_loss_std": 7.829711437225342, "eval/reward_avg": 0.01210937462747097, "eval/reward_loss_mean": 0.027380002662539482, "eval/reward_loss_std": 0.19726824760437012, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9992400407791138, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.009019220247864723, "eval/reward_pos_acc": 0.9333333969116211, "eval/reward_pos_loss": 1.2624486684799194, "eval/reward_pred": 0.0072747208178043365, "eval/reward_rate": 0.0146484375, "replay/size": 96913.0, "replay/inserts": 32496.0, "replay/samples": 32496.0, "replay/insert_wait_avg": 1.2453144727112448e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 5.983942427229024e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 18944.0, "eval_replay/inserts": 5832.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2394332100825054e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.5497207641601562e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1650404930115, "timer/env.step_count": 4062.0, "timer/env.step_total": 162.61788249015808, "timer/env.step_frac": 0.16259104838337363, "timer/env.step_avg": 0.04003394448305221, "timer/env.step_min": 0.0022444725036621094, "timer/env.step_max": 0.9320142269134521, "timer/replay._sample_count": 32496.0, "timer/replay._sample_total": 2899.3950538635254, "timer/replay._sample_frac": 2.8989166152361476, "timer/replay._sample_avg": 0.08922313681263926, "timer/replay._sample_min": 0.000385284423828125, "timer/replay._sample_max": 0.1277475357055664, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4791.0, "timer/agent.policy_total": 48.27125906944275, "timer/agent.policy_frac": 0.04826329367166082, "timer/agent.policy_avg": 0.010075403688048998, "timer/agent.policy_min": 0.007636070251464844, "timer/agent.policy_max": 0.01854109764099121, "timer/dataset_train_count": 2031.0, "timer/dataset_train_total": 0.15861725807189941, "timer/dataset_train_frac": 0.00015859108412118883, "timer/dataset_train_avg": 7.809810835642512e-05, "timer/dataset_train_min": 6.580352783203125e-05, "timer/dataset_train_max": 0.00024318695068359375, "timer/agent.train_count": 2031.0, "timer/agent.train_total": 756.0468573570251, "timer/agent.train_frac": 0.7559220996010287, "timer/agent.train_avg": 0.3722534994372354, "timer/agent.train_min": 0.35237646102905273, "timer/agent.train_max": 0.7415528297424316, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4078855514526367, "timer/agent.report_frac": 0.00040781824492843463, "timer/agent.report_avg": 0.20394277572631836, "timer/agent.report_min": 0.2037806510925293, "timer/agent.report_max": 0.20410490036010742, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.24249267578125e-05, "timer/dataset_eval_frac": 3.241957621497076e-08, "timer/dataset_eval_avg": 3.24249267578125e-05, "timer/dataset_eval_min": 3.24249267578125e-05, "timer/dataset_eval_max": 3.24249267578125e-05, "fps": 32.49030393452369}
{"step": 97552, "time": 3141.5935282707214, "episode/length": 156.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 97744, "time": 3147.2695922851562, "episode/length": 165.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 98120, "time": 3157.3387036323547, "episode/length": 306.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.990228013029316, "episode/intrinsic_return": 0.0}
{"step": 98488, "time": 3167.2810032367706, "episode/length": 182.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 98488, "time": 3167.2942237854004, "episode/length": 178.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 98576, "time": 3170.5469632148743, "episode/length": 161.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9567901234567902, "episode/intrinsic_return": 0.0}
{"step": 98584, "time": 3171.4031732082367, "episode/length": 197.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 98632, "time": 3173.383644104004, "episode/length": 134.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9703703703703703, "episode/intrinsic_return": 0.0}
{"step": 98992, "time": 3183.3019518852234, "episode/length": 51.0, "episode/score": 2.100000023841858, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 99368, "time": 3193.2946581840515, "episode/length": 202.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9802955665024631, "episode/intrinsic_return": 0.0}
{"step": 99480, "time": 3196.979402780533, "episode/length": 169.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9588235294117647, "episode/intrinsic_return": 0.0}
{"step": 99784, "time": 3205.130037546158, "episode/length": 51.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 99816, "time": 3206.769385099411, "episode/length": 165.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 99960, "time": 3211.1978788375854, "episode/length": 165.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 100048, "time": 3217.459018468857, "eval_episode/length": 138.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9928057553956835}
{"step": 100048, "time": 3218.5754516124725, "eval_episode/length": 152.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9738562091503268}
{"step": 100048, "time": 3219.448275089264, "eval_episode/length": 156.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9681528662420382}
{"step": 100048, "time": 3220.416450023651, "eval_episode/length": 163.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9695121951219512}
{"step": 100048, "time": 3221.374890565872, "eval_episode/length": 169.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9705882352941176}
{"step": 100048, "time": 3222.4231417179108, "eval_episode/length": 178.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9720670391061452}
{"step": 100048, "time": 3223.5330147743225, "eval_episode/length": 34.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 100048, "time": 3225.2363963127136, "eval_episode/length": 235.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9788135593220338}
{"step": 100064, "time": 3225.8848688602448, "episode/length": 184.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9621621621621622, "episode/intrinsic_return": 0.0}
{"step": 100088, "time": 3227.091073036194, "episode/length": 199.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 100272, "time": 3232.6853675842285, "episode/length": 408.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9779951100244498, "episode/intrinsic_return": 0.0}
{"step": 100552, "time": 3240.2609338760376, "episode/length": 194.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9692307692307692, "episode/intrinsic_return": 0.0}
{"step": 100896, "time": 3249.807160139084, "episode/length": 176.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 101152, "time": 3256.9330611228943, "episode/length": 166.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 101168, "time": 3258.172087907791, "episode/length": 172.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 101392, "time": 3264.7303075790405, "episode/length": 162.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 101480, "time": 3267.531806707382, "episode/length": 189.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 101680, "time": 3273.592289686203, "episode/length": 201.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 101936, "time": 3280.8085057735443, "episode/length": 207.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9711538461538461, "episode/intrinsic_return": 0.0}
{"step": 101976, "time": 3282.563636779785, "episode/length": 177.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 102120, "time": 3287.1001534461975, "episode/length": 54.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9090909090909091, "episode/intrinsic_return": 0.0}
{"step": 102160, "time": 3289.071038007736, "episode/length": 157.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 102440, "time": 3296.7376527786255, "episode/length": 158.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 102808, "time": 3306.64266037941, "episode/length": 206.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.966183574879227, "episode/intrinsic_return": 0.0}
{"step": 102856, "time": 3308.6600267887115, "episode/length": 171.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 102912, "time": 3311.2214715480804, "episode/length": 189.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 103272, "time": 3321.0478398799896, "episode/length": 161.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 103288, "time": 3322.3714060783386, "episode/length": 140.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.0}
{"step": 103448, "time": 3327.223837852478, "episode/length": 165.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 103456, "time": 3328.4088175296783, "episode/length": 189.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9842105263157894, "episode/intrinsic_return": 0.0}
{"step": 103960, "time": 3341.569667339325, "episode/length": 189.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 104160, "time": 3347.695779323578, "episode/length": 168.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 104296, "time": 3351.7068169116974, "episode/length": 179.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 104824, "time": 3365.562789440155, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 104840, "time": 3366.7574265003204, "episode/length": 193.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 105032, "time": 3372.4746675491333, "episode/length": 219.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 105144, "time": 3375.9812281131744, "episode/length": 278.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.985663082437276, "episode/intrinsic_return": 0.0}
{"step": 105560, "time": 3387.240455389023, "episode/length": 157.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 105640, "time": 3390.064819574356, "episode/length": 101.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9509803921568627, "episode/intrinsic_return": 0.0}
{"step": 105640, "time": 3390.078134536743, "episode/length": 184.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 105704, "time": 3392.460402727127, "episode/length": 217.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.981651376146789, "episode/intrinsic_return": 0.0}
{"step": 106296, "time": 3407.901380300522, "episode/length": 181.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 106608, "time": 3416.803202867508, "episode/length": 394.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9772151898734177, "episode/intrinsic_return": 0.0}
{"step": 106696, "time": 3419.589255809784, "episode/length": 193.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9845360824742269, "episode/intrinsic_return": 0.0}
{"step": 106760, "time": 3422.02050447464, "episode/length": 215.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 106824, "time": 3424.411415576935, "episode/length": 147.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 106968, "time": 3428.773312330246, "episode/length": 157.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 107096, "time": 3432.806576728821, "episode/length": 191.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 107264, "time": 3438.082765340805, "episode/length": 202.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 107688, "time": 3449.253135204315, "episode/length": 123.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9516129032258065, "episode/intrinsic_return": 0.0}
{"step": 108000, "time": 3458.1203804016113, "episode/length": 212.0, "episode/score": 2.0999999791383743, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 108248, "time": 3464.838889360428, "episode/length": 159.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 108312, "time": 3467.2080273628235, "episode/length": 151.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 108336, "time": 3468.794774055481, "episode/length": 215.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 108368, "time": 3470.4112462997437, "episode/length": 192.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 108448, "time": 3473.2825360298157, "episode/length": 147.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9594594594594594, "episode/intrinsic_return": 0.0}
{"step": 108672, "time": 3479.617815256119, "episode/length": 238.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9790794979079498, "episode/intrinsic_return": 0.0}
{"step": 108992, "time": 3488.6331300735474, "episode/length": 39.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 109288, "time": 3496.6786353588104, "episode/length": 199.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 109304, "time": 3497.8802301883698, "episode/length": 123.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9596774193548387, "episode/intrinsic_return": 0.0}
{"step": 109504, "time": 3503.9046726226807, "episode/length": 141.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9577464788732394, "episode/intrinsic_return": 0.0}
{"step": 109632, "time": 3507.8739087581635, "episode/length": 203.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 110032, "time": 3520.375509262085, "eval_episode/length": 36.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.972972972972973}
{"step": 110032, "time": 3523.3184685707092, "eval_episode/length": 162.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9693251533742331}
{"step": 110032, "time": 3524.445334672928, "eval_episode/length": 178.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9720670391061452}
{"step": 110032, "time": 3525.692682504654, "eval_episode/length": 201.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9752475247524752}
{"step": 110032, "time": 3526.5514986515045, "eval_episode/length": 203.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9803921568627451}
{"step": 110032, "time": 3528.058064699173, "eval_episode/length": 235.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9830508474576272}
{"step": 110032, "time": 3528.927878379822, "eval_episode/length": 199.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.97}
{"step": 110032, "time": 3530.385081768036, "eval_episode/length": 269.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9851851851851852}
{"step": 110328, "time": 3537.743162870407, "episode/length": 166.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 110408, "time": 3540.5669600963593, "episode/length": 258.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9806949806949807, "episode/intrinsic_return": 0.0}
{"step": 110576, "time": 3545.765222787857, "episode/length": 290.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9896907216494846, "episode/intrinsic_return": 0.0}
{"step": 110704, "time": 3549.852509021759, "episode/length": 176.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 110960, "time": 3557.127061367035, "episode/length": 313.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9904458598726115, "episode/intrinsic_return": 0.0}
{"step": 111144, "time": 3562.513955116272, "episode/length": 54.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 111424, "time": 3570.6052706241608, "episode/length": 223.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9866071428571429, "episode/intrinsic_return": 0.0}
{"step": 111440, "time": 3571.8185374736786, "episode/length": 266.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9850187265917603, "episode/intrinsic_return": 0.0}
{"step": 111680, "time": 3578.5829799175262, "episode/length": 271.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9742647058823529, "episode/intrinsic_return": 0.0}
{"step": 111896, "time": 3584.645912885666, "episode/length": 195.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9693877551020408, "episode/intrinsic_return": 0.0}
{"step": 112112, "time": 3591.0672373771667, "episode/length": 191.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 112608, "time": 3604.3738017082214, "episode/length": 182.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 112608, "time": 3604.387850999832, "episode/length": 274.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9854545454545455, "episode/intrinsic_return": 0.0}
{"step": 112648, "time": 3606.1004350185394, "episode/length": 150.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9735099337748344, "episode/intrinsic_return": 0.0}
{"step": 112744, "time": 3609.307048559189, "episode/length": 164.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 113232, "time": 3622.504312515259, "episode/length": 283.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9894366197183099, "episode/intrinsic_return": 0.0}
{"step": 113360, "time": 3626.4648509025574, "episode/length": 182.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 113552, "time": 3632.0719122886658, "episode/length": 233.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9786324786324786, "episode/intrinsic_return": 0.0}
{"step": 113680, "time": 3636.112463951111, "episode/length": 133.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9626865671641791, "episode/intrinsic_return": 0.0}
{"step": 113984, "time": 3644.3872525691986, "episode/length": 233.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9829059829059829, "episode/intrinsic_return": 0.0}
{"step": 114024, "time": 3646.0000081062317, "episode/length": 176.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 114416, "time": 3656.6834030151367, "episode/length": 131.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9621212121212122, "episode/intrinsic_return": 0.0}
{"step": 114480, "time": 3659.0745294094086, "episode/length": 228.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9737991266375546, "episode/intrinsic_return": 0.0}
{"step": 114496, "time": 3660.355493783951, "episode/length": 218.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9726027397260274, "episode/intrinsic_return": 0.0}
{"step": 114592, "time": 3663.519191503525, "episode/length": 129.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9923076923076923, "episode/intrinsic_return": 0.0}
{"step": 114704, "time": 3667.178632736206, "episode/length": 35.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.8888888888888888, "episode/intrinsic_return": 0.0}
{"step": 114840, "time": 3671.19842004776, "episode/length": 42.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 114880, "time": 3673.1728258132935, "episode/length": 205.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 115456, "time": 3688.1931381225586, "episode/length": 178.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 115544, "time": 3690.9709067344666, "episode/length": 232.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9785407725321889, "episode/intrinsic_return": 0.0}
{"step": 115816, "time": 3698.66051030159, "episode/length": 228.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9781659388646288, "episode/intrinsic_return": 0.0}
{"step": 115896, "time": 3701.606439113617, "episode/length": 176.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 116544, "time": 3718.6564853191376, "episode/length": 212.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9812206572769953, "episode/intrinsic_return": 0.0}
{"step": 116624, "time": 3721.434845685959, "episode/length": 239.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 117048, "time": 3732.645434856415, "episode/length": 198.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 117056, "time": 3733.840550661087, "episode/length": 271.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9852941176470589, "episode/intrinsic_return": 0.0}
{"step": 117216, "time": 3738.6610658168793, "episode/length": 174.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 117264, "time": 3740.753732442856, "episode/length": 333.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9880239520958084, "episode/intrinsic_return": 0.0}
{"step": 117672, "time": 3751.5005192756653, "episode/length": 130.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9618320610687023, "episode/intrinsic_return": 0.0}
{"step": 117728, "time": 3753.942669391632, "episode/length": 272.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9963369963369964, "episode/intrinsic_return": 0.0}
{"step": 117752, "time": 3755.2305285930634, "episode/length": 150.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 118248, "time": 3768.3084123134613, "episode/length": 293.0, "episode/score": 2.0999999791383743, "episode/reward_rate": 0.9965986394557823, "episode/intrinsic_return": 0.0}
{"step": 118304, "time": 3770.742475271225, "episode/length": 155.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 118536, "time": 3777.0647621154785, "episode/length": 28.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 118896, "time": 3786.8622677326202, "episode/length": 142.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.972027972027972, "episode/intrinsic_return": 0.0}
{"step": 119048, "time": 3791.1614153385162, "episode/length": 249.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.996, "episode/intrinsic_return": 0.0}
{"step": 119080, "time": 3792.7873225212097, "episode/length": 168.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 119224, "time": 3797.223566055298, "episode/length": 244.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 119328, "time": 3800.844058275223, "episode/length": 263.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9848484848484849, "episode/intrinsic_return": 0.0}
{"step": 119776, "time": 3812.717664718628, "episode/length": 262.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9847908745247148, "episode/intrinsic_return": 0.0}
{"step": 119872, "time": 3816.0342659950256, "episode/length": 202.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 119944, "time": 3818.4726126194, "episode/length": 175.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 119960, "time": 3819.718018054962, "episode/length": 91.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9565217391304348, "episode/intrinsic_return": 0.0}
{"step": 120016, "time": 3823.9243261814117, "eval_episode/length": 58.0, "eval_episode/score": 2.100000001490116, "eval_episode/reward_rate": 0.9830508474576272}
{"step": 120016, "time": 3826.1907646656036, "eval_episode/length": 141.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9647887323943662}
{"step": 120016, "time": 3827.4897105693817, "eval_episode/length": 166.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9700598802395209}
{"step": 120016, "time": 3828.3463757038116, "eval_episode/length": 168.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9704142011834319}
{"step": 120016, "time": 3829.337738752365, "eval_episode/length": 177.0, "eval_episode/score": 3.100000001490116, "eval_episode/reward_rate": 0.9775280898876404}
{"step": 120016, "time": 3830.9478108882904, "eval_episode/length": 216.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9769585253456221}
{"step": 120016, "time": 3832.115907430649, "eval_episode/length": 233.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9786324786324786}
{"step": 120016, "time": 3833.005308866501, "eval_episode/length": 234.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9702127659574468}
{"step": 120312, "time": 3840.465829849243, "episode/length": 176.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9661016949152542, "episode/intrinsic_return": 0.0}
{"step": 120400, "time": 3843.6564366817474, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 120616, "time": 3849.625654220581, "episode/length": 160.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 120952, "time": 3858.7907938957214, "episode/length": 237.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9789915966386554, "episode/intrinsic_return": 0.0}
{"step": 121160, "time": 3864.729566335678, "episode/length": 172.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 121240, "time": 3867.554368019104, "episode/length": 35.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 121552, "time": 3876.2364752292633, "episode/length": 154.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 121784, "time": 3882.6483211517334, "episode/length": 77.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9487179487179487, "episode/intrinsic_return": 0.0}
{"step": 121824, "time": 3884.6161937713623, "episode/length": 234.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9829787234042553, "episode/intrinsic_return": 0.0}
{"step": 121872, "time": 3886.5937678813934, "episode/length": 156.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 121976, "time": 3889.8464257717133, "episode/length": 262.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9809885931558935, "episode/intrinsic_return": 0.0}
{"step": 122208, "time": 3896.5951657295227, "episode/length": 225.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 122216, "time": 3897.4264669418335, "episode/length": 281.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9858156028368794, "episode/intrinsic_return": 0.0}
{"step": 122648, "time": 3908.8174018859863, "episode/length": 175.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 122720, "time": 3911.6936469078064, "episode/length": 145.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 122960, "time": 3918.561901807785, "episode/length": 38.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.9230769230769231, "episode/intrinsic_return": 0.0}
{"step": 123048, "time": 3921.395536661148, "episode/length": 157.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 123224, "time": 3926.568750143051, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 123320, "time": 3929.805340051651, "episode/length": 167.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 123320, "time": 3929.8191788196564, "episode/length": 138.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9712230215827338, "episode/intrinsic_return": 0.0}
{"step": 123352, "time": 3931.554370164871, "episode/length": 190.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 123792, "time": 3943.393811225891, "episode/length": 196.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 124000, "time": 3949.2636363506317, "episode/length": 159.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 124232, "time": 3955.649271965027, "episode/length": 158.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 124480, "time": 3962.7991433143616, "episode/length": 144.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 124536, "time": 3964.842849254608, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 124576, "time": 3966.811322450638, "episode/length": 156.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 124776, "time": 3972.4790275096893, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 124912, "time": 3976.8672380447388, "episode/length": 210.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.981042654028436, "episode/intrinsic_return": 0.0}
{"step": 125208, "time": 3984.8259863853455, "episode/length": 176.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9661016949152542, "episode/intrinsic_return": 0.0}
{"step": 125216, "time": 3986.00399851799, "episode/length": 151.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 125856, "time": 4002.736606359482, "episode/length": 171.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 125864, "time": 4003.584498167038, "episode/length": 160.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 126408, "time": 4018.0640420913696, "episode/length": 186.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 126544, "time": 4022.5259766578674, "episode/length": 288.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9826989619377162, "episode/intrinsic_return": 0.0}
{"step": 126632, "time": 4025.3312034606934, "episode/length": 231.0, "episode/score": 5.099999964237213, "episode/reward_rate": 0.9741379310344828, "episode/intrinsic_return": 0.0}
{"step": 126848, "time": 4031.8752253055573, "episode/length": 288.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.986159169550173, "episode/intrinsic_return": 0.0}
{"step": 127088, "time": 4038.6676964759827, "episode/length": 153.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 127328, "time": 4045.593192100525, "episode/length": 263.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9810606060606061, "episode/intrinsic_return": 0.0}
{"step": 127328, "time": 4045.606142282486, "episode/length": 182.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9672131147540983, "episode/intrinsic_return": 0.0}
{"step": 128088, "time": 4065.1589906215668, "episode/length": 181.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 128128, "time": 4067.233764410019, "episode/length": 214.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 128216, "time": 4070.0788798332214, "episode/length": 170.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 128288, "time": 4072.9033896923065, "episode/length": 384.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9974025974025974, "episode/intrinsic_return": 0.0}
{"step": 128440, "time": 4077.4110493659973, "episode/length": 236.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9704641350210971, "episode/intrinsic_return": 0.0}
{"step": 128480, "time": 4079.4083709716797, "episode/length": 143.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 128976, "time": 4092.702234983444, "episode/length": 235.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 129096, "time": 4096.302589416504, "episode/length": 100.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9603960396039604, "episode/intrinsic_return": 0.0}
{"step": 129728, "time": 4113.127828359604, "episode/length": 299.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.99, "episode/intrinsic_return": 0.0}
{"step": 129768, "time": 4114.864228248596, "episode/length": 165.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 129808, "time": 4116.926894426346, "episode/length": 209.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9809523809523809, "episode/intrinsic_return": 0.0}
{"step": 129984, "time": 4122.097559213638, "episode/length": 220.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9819004524886877, "episode/intrinsic_return": 0.0}
{"step": 130000, "time": 4123.31732583046, "episode/length": 238.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9790794979079498, "episode/intrinsic_return": 0.0}
{"step": 130000, "time": 4124.896717309952, "eval_episode/length": 38.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 130000, "time": 4126.909529685974, "eval_episode/length": 109.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9636363636363636}
{"step": 130000, "time": 4127.954352617264, "eval_episode/length": 119.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9583333333333334}
{"step": 130000, "time": 4129.971708536148, "eval_episode/length": 189.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9631578947368421}
{"step": 130000, "time": 4130.900808572769, "eval_episode/length": 192.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9740932642487047}
{"step": 130000, "time": 4131.939418077469, "eval_episode/length": 201.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9752475247524752}
{"step": 130000, "time": 4133.219180583954, "eval_episode/length": 184.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9783783783783784}
{"step": 130000, "time": 4134.432324647903, "eval_episode/length": 243.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9713114754098361}
{"step": 130105, "time": 4138.694222211838, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.047182868508732, "train/action_min": 0.0, "train/action_std": 2.540582735164493, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04427445967517355, "train/actor_opt_grad_steps": 7015.0, "train/actor_opt_loss": 4.0477420443705485, "train/adv_mag": 0.8829528458562552, "train/adv_max": 0.8769474494106629, "train/adv_mean": 0.004599423308780958, "train/adv_min": -0.5153274376894913, "train/adv_std": 0.0800716632648426, "train/cont_avg": 0.9940496706495098, "train/cont_loss_mean": 0.0006065499658248262, "train/cont_loss_std": 0.016494190494501806, "train/cont_neg_acc": 0.9806392027759084, "train/cont_neg_loss": 0.07401559153720538, "train/cont_pos_acc": 0.99990360993965, "train/cont_pos_loss": 0.00019352131019715487, "train/cont_pred": 0.9940903946465137, "train/cont_rate": 0.9940496706495098, "train/dyn_loss_mean": 10.978143383474912, "train/dyn_loss_std": 8.223621952767466, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.078713177465925, "train/extr_critic_critic_opt_grad_steps": 7015.0, "train/extr_critic_critic_opt_loss": 14174.45525045956, "train/extr_critic_mag": 2.949338544817532, "train/extr_critic_max": 2.949338544817532, "train/extr_critic_mean": 0.657257005572319, "train/extr_critic_min": -0.2437964584313187, "train/extr_critic_std": 0.8171180717500985, "train/extr_return_normed_mag": 1.9331530975360496, "train/extr_return_normed_max": 1.9331530975360496, "train/extr_return_normed_mean": 0.3308788202702999, "train/extr_return_normed_min": -0.18513533104138047, "train/extr_return_normed_std": 0.3561597042808346, "train/extr_return_rate": 0.39348896505201564, "train/extr_return_raw_mag": 4.505090790636399, "train/extr_return_raw_max": 4.505090790636399, "train/extr_return_raw_mean": 0.6683296558319354, "train/extr_return_raw_min": -0.5660538785890037, "train/extr_return_raw_std": 0.8531942452285805, "train/extr_reward_mag": 1.004332178363613, "train/extr_reward_max": 1.004332178363613, "train/extr_reward_mean": 0.0129945175448323, "train/extr_reward_min": -0.3009531521329693, "train/extr_reward_std": 0.10150230829330052, "train/image_loss_mean": 15.154537621666403, "train/image_loss_std": 18.32316173759161, "train/model_loss_mean": 21.79327317312652, "train/model_loss_std": 21.828993442011814, "train/model_opt_grad_norm": 86.97979624131146, "train/model_opt_grad_steps": 7004.53431372549, "train/model_opt_loss": 14022.08283547794, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 643.3823529411765, "train/policy_entropy_mag": 2.279043261911355, "train/policy_entropy_max": 2.279043261911355, "train/policy_entropy_mean": 0.7171046380318847, "train/policy_entropy_min": 0.07938413833286248, "train/policy_entropy_std": 0.4662763213410097, "train/policy_logprob_mag": 7.438195378172631, "train/policy_logprob_max": -0.0094574207951333, "train/policy_logprob_mean": -0.7165632773848141, "train/policy_logprob_min": -7.438195378172631, "train/policy_logprob_std": 1.147179180500554, "train/policy_randomness_mag": 0.8044022602193496, "train/policy_randomness_max": 0.8044022602193496, "train/policy_randomness_mean": 0.2531064684484519, "train/policy_randomness_min": 0.028019117136650225, "train/policy_randomness_std": 0.16457507898117982, "train/post_ent_mag": 49.19877308490229, "train/post_ent_max": 49.19877308490229, "train/post_ent_mean": 35.51367892471014, "train/post_ent_min": 19.591982252457562, "train/post_ent_std": 5.248649812212177, "train/prior_ent_mag": 60.77735399732403, "train/prior_ent_max": 60.77735399732403, "train/prior_ent_mean": 46.617868012073, "train/prior_ent_min": 23.17884007622214, "train/prior_ent_std": 6.702929227959876, "train/rep_loss_mean": 10.978143383474912, "train/rep_loss_std": 8.223621952767466, "train/reward_avg": 0.012218998804718129, "train/reward_loss_mean": 0.05124309004795756, "train/reward_loss_std": 0.27047654398370025, "train/reward_max_data": 1.0078431391248517, "train/reward_max_pred": 1.0013464402918721, "train/reward_neg_acc": 0.9941994103730893, "train/reward_neg_loss": 0.03315427178498723, "train/reward_pos_acc": 0.9217036091813854, "train/reward_pos_loss": 1.0803862217010236, "train/reward_pred": 0.011441569599578632, "train/reward_rate": 0.017468022365196078, "train_stats/sum_log_reward": 3.7494252212773795, "train_stats/max_log_achievement_collect_drink": 9.10344827586207, "train_stats/max_log_achievement_collect_sapling": 2.2873563218390807, "train_stats/max_log_achievement_collect_wood": 2.3275862068965516, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.21264367816091953, "train_stats/max_log_achievement_eat_cow": 0.04597701149425287, "train_stats/max_log_achievement_make_wood_pickaxe": 0.005747126436781609, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.9310344827586208, "train_stats/max_log_achievement_place_table": 0.6666666666666666, "train_stats/max_log_achievement_wake_up": 1.735632183908046, "train_stats/mean_log_entropy": 0.7033750298379482, "eval_stats/sum_log_reward": 3.5687499046325684, "eval_stats/max_log_achievement_collect_drink": 8.5, "eval_stats/max_log_achievement_collect_sapling": 2.0, "eval_stats/max_log_achievement_collect_wood": 2.40625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.09375, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 1.8125, "eval_stats/max_log_achievement_place_table": 0.75, "eval_stats/max_log_achievement_wake_up": 1.375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 1.1614541790549993e-06, "report/cont_loss_std": 2.5715982701512985e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00013588917499873787, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 3.673810624604812e-07, "report/cont_pred": 0.9941411018371582, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 10.50869369506836, "report/dyn_loss_std": 8.055907249450684, "report/image_loss_mean": 11.22694206237793, "report/image_loss_std": 12.60173511505127, "report/model_loss_mean": 17.5804500579834, "report/model_loss_std": 16.001256942749023, "report/post_ent_mag": 47.2019157409668, "report/post_ent_max": 47.2019157409668, "report/post_ent_mean": 36.37821960449219, "report/post_ent_min": 19.30315399169922, "report/post_ent_std": 5.573315143585205, "report/prior_ent_mag": 60.80017852783203, "report/prior_ent_max": 60.80017852783203, "report/prior_ent_mean": 47.38485336303711, "report/prior_ent_min": 20.737895965576172, "report/prior_ent_std": 6.734455585479736, "report/rep_loss_mean": 10.50869369506836, "report/rep_loss_std": 8.055907249450684, "report/reward_avg": 0.006054687313735485, "report/reward_loss_mean": 0.0482914000749588, "report/reward_loss_std": 0.21751676499843597, "report/reward_max_data": 1.0, "report/reward_max_pred": 0.9986310005187988, "report/reward_neg_acc": 0.9950543642044067, "report/reward_neg_loss": 0.036999959498643875, "report/reward_pos_acc": 0.9230769872665405, "report/reward_pos_loss": 0.926417887210846, "report/reward_pred": 0.005139144603163004, "report/reward_rate": 0.0126953125, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 3.589445896068355e-08, "eval/cont_loss_std": 8.402054874068199e-08, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 3.589445896068355e-08, "eval/cont_pred": 1.0, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 15.181868553161621, "eval/dyn_loss_std": 8.603022575378418, "eval/image_loss_mean": 18.036609649658203, "eval/image_loss_std": 15.891642570495605, "eval/model_loss_mean": 27.23501968383789, "eval/model_loss_std": 19.323875427246094, "eval/post_ent_mag": 50.16986846923828, "eval/post_ent_max": 50.16986846923828, "eval/post_ent_mean": 33.103736877441406, "eval/post_ent_min": 19.9798583984375, "eval/post_ent_std": 5.067634582519531, "eval/prior_ent_mag": 60.736656188964844, "eval/prior_ent_max": 60.736656188964844, "eval/prior_ent_mean": 45.838104248046875, "eval/prior_ent_min": 23.198867797851562, "eval/prior_ent_std": 7.547622203826904, "eval/rep_loss_mean": 15.181868553161621, "eval/rep_loss_std": 8.603022575378418, "eval/reward_avg": 0.01972656324505806, "eval/reward_loss_mean": 0.08929027616977692, "eval/reward_loss_std": 0.6544567346572876, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0016453266143799, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.018937909975647926, "eval/reward_pos_acc": 0.5652173757553101, "eval/reward_pos_loss": 3.1511476039886475, "eval/reward_pred": 0.007482915185391903, "eval/reward_rate": 0.0224609375, "replay/size": 129601.0, "replay/inserts": 32688.0, "replay/samples": 32688.0, "replay/insert_wait_avg": 1.2133396319530785e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 5.650479479624954e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 26824.0, "eval_replay/inserts": 7880.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2092481409837751e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.748603820800781e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3687679767609, "timer/env.step_count": 4086.0, "timer/env.step_total": 154.55685186386108, "timer/env.step_frac": 0.15449987725671532, "timer/env.step_avg": 0.03782595493486566, "timer/env.step_min": 0.0022652149200439453, "timer/env.step_max": 0.9315407276153564, "timer/replay._sample_count": 32688.0, "timer/replay._sample_total": 2892.9983365535736, "timer/replay._sample_frac": 2.8919318846835287, "timer/replay._sample_avg": 0.0885033754452268, "timer/replay._sample_min": 0.00037407875061035156, "timer/replay._sample_max": 0.12858891487121582, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5071.0, "timer/agent.policy_total": 51.470369815826416, "timer/agent.policy_frac": 0.05145139618855244, "timer/agent.policy_avg": 0.010149944747747271, "timer/agent.policy_min": 0.007822990417480469, "timer/agent.policy_max": 0.023775100708007812, "timer/dataset_train_count": 2043.0, "timer/dataset_train_total": 0.15779852867126465, "timer/dataset_train_frac": 0.00015774035907819385, "timer/dataset_train_avg": 7.723863371084906e-05, "timer/dataset_train_min": 5.459785461425781e-05, "timer/dataset_train_max": 0.00014257431030273438, "timer/agent.train_count": 2043.0, "timer/agent.train_total": 754.1910548210144, "timer/agent.train_frac": 0.7539130358361354, "timer/agent.train_avg": 0.3691586171419552, "timer/agent.train_min": 0.3488788604736328, "timer/agent.train_max": 0.6161670684814453, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.409743070602417, "timer/agent.report_frac": 0.0004095920261796253, "timer/agent.report_avg": 0.2048715353012085, "timer/agent.report_min": 0.2041921615600586, "timer/agent.report_max": 0.2055509090423584, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.170967102050781e-05, "timer/dataset_eval_frac": 3.169798181988469e-08, "timer/dataset_eval_avg": 3.170967102050781e-05, "timer/dataset_eval_min": 3.170967102050781e-05, "timer/dataset_eval_max": 3.170967102050781e-05, "fps": 32.67547382936108}
{"step": 130152, "time": 4139.574423789978, "episode/length": 146.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 130256, "time": 4144.481454372406, "episode/length": 144.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 130336, "time": 4147.266743898392, "episode/length": 231.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.978448275862069, "episode/intrinsic_return": 0.0}
{"step": 131040, "time": 4165.474568843842, "episode/length": 158.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 131312, "time": 4173.10080909729, "episode/length": 165.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 131448, "time": 4177.27852845192, "episode/length": 214.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9720930232558139, "episode/intrinsic_return": 0.0}
{"step": 131464, "time": 4178.529741287231, "episode/length": 140.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9574468085106383, "episode/intrinsic_return": 0.0}
{"step": 131536, "time": 4181.30003452301, "episode/length": 172.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 131592, "time": 4183.363709688187, "episode/length": 166.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 131752, "time": 4188.1443383693695, "episode/length": 242.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9835390946502057, "episode/intrinsic_return": 0.0}
{"step": 132168, "time": 4199.332598686218, "episode/length": 270.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.985239852398524, "episode/intrinsic_return": 0.0}
{"step": 132600, "time": 4211.018172979355, "episode/length": 160.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 132736, "time": 4215.380831718445, "episode/length": 158.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 132752, "time": 4216.656592130661, "episode/length": 213.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 132784, "time": 4218.336625814438, "episode/length": 155.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 133096, "time": 4226.843363046646, "episode/length": 205.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 133120, "time": 4228.43857049942, "episode/length": 190.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9685863874345549, "episode/intrinsic_return": 0.0}
{"step": 133688, "time": 4243.275582790375, "episode/length": 241.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9834710743801653, "episode/intrinsic_return": 0.0}
{"step": 133848, "time": 4248.023643732071, "episode/length": 155.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 133896, "time": 4250.074261188507, "episode/length": 215.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 134176, "time": 4258.026803970337, "episode/length": 173.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 134296, "time": 4261.72874045372, "episode/length": 192.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 134376, "time": 4264.615691661835, "episode/length": 156.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 134608, "time": 4271.315107584, "episode/length": 188.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 134776, "time": 4276.174956083298, "episode/length": 254.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9882352941176471, "episode/intrinsic_return": 0.0}
{"step": 135216, "time": 4287.966400384903, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 135568, "time": 4297.4643433094025, "episode/length": 173.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 135568, "time": 4297.478533029556, "episode/length": 208.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9808612440191388, "episode/intrinsic_return": 0.0}
{"step": 135696, "time": 4301.445014953613, "episode/length": 164.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 135712, "time": 4302.708612442017, "episode/length": 176.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 135904, "time": 4308.417421579361, "episode/length": 276.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9855595667870036, "episode/intrinsic_return": 0.0}
{"step": 136168, "time": 4315.652833223343, "episode/length": 173.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 136184, "time": 4316.901337146759, "episode/length": 196.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 136448, "time": 4324.511125326157, "episode/length": 32.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 136704, "time": 4331.841077327728, "episode/length": 185.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 136840, "time": 4335.952394485474, "episode/length": 140.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.0}
{"step": 136912, "time": 4338.71463394165, "episode/length": 167.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 137072, "time": 4343.476833820343, "episode/length": 145.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 137160, "time": 4346.3258056640625, "episode/length": 182.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 137560, "time": 4357.455560207367, "episode/length": 173.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 137608, "time": 4359.571538925171, "episode/length": 254.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.996078431372549, "episode/intrinsic_return": 0.0}
{"step": 137912, "time": 4368.080478668213, "episode/length": 37.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 137936, "time": 4369.649809837341, "episode/length": 153.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 138120, "time": 4375.077343702316, "episode/length": 208.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 138168, "time": 4377.147339820862, "episode/length": 165.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 138856, "time": 4395.197071075439, "episode/length": 222.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9820627802690582, "episode/intrinsic_return": 0.0}
{"step": 139008, "time": 4400.118185758591, "episode/length": 180.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 139168, "time": 4404.954100847244, "episode/length": 250.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9800796812749004, "episode/intrinsic_return": 0.0}
{"step": 139248, "time": 4407.749950408936, "episode/length": 163.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 139360, "time": 4411.393977165222, "episode/length": 305.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9869281045751634, "episode/intrinsic_return": 0.0}
{"step": 139416, "time": 4413.515650033951, "episode/length": 50.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 139456, "time": 4415.59473156929, "episode/length": 74.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9866666666666667, "episode/intrinsic_return": 0.0}
{"step": 139512, "time": 4417.722743272781, "episode/length": 199.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 139696, "time": 4423.274214029312, "episode/length": 196.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 139904, "time": 4429.528707027435, "episode/length": 216.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 140088, "time": 4438.091391324997, "eval_episode/length": 152.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9738562091503268}
{"step": 140088, "time": 4439.008132457733, "eval_episode/length": 154.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9935483870967742}
{"step": 140088, "time": 4439.88618683815, "eval_episode/length": 159.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.96875}
{"step": 140088, "time": 4441.24541592598, "eval_episode/length": 189.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9947368421052631}
{"step": 140088, "time": 4442.271857738495, "eval_episode/length": 194.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9692307692307692}
{"step": 140088, "time": 4443.150760173798, "eval_episode/length": 196.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9746192893401016}
{"step": 140088, "time": 4444.2984709739685, "eval_episode/length": 210.0, "eval_episode/score": 4.100000023841858, "eval_episode/reward_rate": 0.995260663507109}
{"step": 140088, "time": 4445.583678007126, "eval_episode/length": 233.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9829059829059829}
{"step": 140544, "time": 4457.419154882431, "episode/length": 161.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 140744, "time": 4463.194197654724, "episode/length": 196.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 140792, "time": 4465.226779699326, "episode/length": 171.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9593023255813954, "episode/intrinsic_return": 0.0}
{"step": 141040, "time": 4472.405757904053, "episode/length": 197.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 141160, "time": 4476.090043544769, "episode/length": 205.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 141160, "time": 4476.1046488285065, "episode/length": 224.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9822222222222222, "episode/intrinsic_return": 0.0}
{"step": 141232, "time": 4478.990771055222, "episode/length": 191.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 141928, "time": 4497.549170970917, "episode/length": 172.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.953757225433526, "episode/intrinsic_return": 0.0}
{"step": 142080, "time": 4502.320292234421, "episode/length": 160.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 142296, "time": 4508.3245260715485, "episode/length": 298.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9832775919732442, "episode/intrinsic_return": 0.0}
{"step": 142352, "time": 4510.808894634247, "episode/length": 163.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 142352, "time": 4510.822772264481, "episode/length": 139.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.95, "episode/intrinsic_return": 0.0}
{"step": 142448, "time": 4514.053749322891, "episode/length": 212.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9812206572769953, "episode/intrinsic_return": 0.0}
{"step": 142640, "time": 4519.778479337692, "episode/length": 184.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 142664, "time": 4521.01021695137, "episode/length": 38.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8717948717948718, "episode/intrinsic_return": 0.0}
{"step": 142664, "time": 4521.024768590927, "episode/length": 187.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 142992, "time": 4530.139938354492, "episode/length": 40.0, "episode/score": 0.10000002384185791, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 143168, "time": 4535.30979514122, "episode/length": 154.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 143656, "time": 4548.0898196697235, "episode/length": 169.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 143736, "time": 4550.945090293884, "episode/length": 172.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9653179190751445, "episode/intrinsic_return": 0.0}
{"step": 143808, "time": 4553.859270095825, "episode/length": 215.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 143864, "time": 4555.891704320908, "episode/length": 86.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9310344827586207, "episode/intrinsic_return": 0.0}
{"step": 144088, "time": 4562.342609405518, "episode/length": 180.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 144176, "time": 4565.551747560501, "episode/length": 188.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 144432, "time": 4572.63854265213, "episode/length": 247.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9758064516129032, "episode/intrinsic_return": 0.0}
{"step": 144840, "time": 4583.536544799805, "episode/length": 93.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9468085106382979, "episode/intrinsic_return": 0.0}
{"step": 144928, "time": 4586.851110935211, "episode/length": 148.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 145224, "time": 4594.984645843506, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 145456, "time": 4602.227775335312, "episode/length": 224.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 145568, "time": 4605.855597734451, "episode/length": 321.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.984472049689441, "episode/intrinsic_return": 0.0}
{"step": 145664, "time": 4609.17862200737, "episode/length": 231.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 145680, "time": 4610.425826311111, "episode/length": 187.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 146192, "time": 4624.029978990555, "episode/length": 219.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 146280, "time": 4627.014145612717, "episode/length": 168.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 146512, "time": 4633.800127744675, "episode/length": 39.0, "episode/score": 2.100000023841858, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 146800, "time": 4641.72939157486, "episode/length": 167.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 146872, "time": 4644.203005075455, "episode/length": 162.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 146936, "time": 4646.704379081726, "episode/length": 156.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 147024, "time": 4649.940489530563, "episode/length": 272.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9963369963369964, "episode/intrinsic_return": 0.0}
{"step": 147200, "time": 4655.117530584335, "episode/length": 246.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.979757085020243, "episode/intrinsic_return": 0.0}
{"step": 147216, "time": 4656.352502584457, "episode/length": 193.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9639175257731959, "episode/intrinsic_return": 0.0}
{"step": 147528, "time": 4664.874858617783, "episode/length": 90.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.989010989010989, "episode/intrinsic_return": 0.0}
{"step": 147560, "time": 4666.493603467941, "episode/length": 130.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9541984732824428, "episode/intrinsic_return": 0.0}
{"step": 147656, "time": 4669.626680135727, "episode/length": 54.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 148064, "time": 4680.749136686325, "episode/length": 129.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 148264, "time": 4686.441210746765, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.963855421686747, "episode/intrinsic_return": 0.0}
{"step": 148440, "time": 4691.721209049225, "episode/length": 195.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 148552, "time": 4695.319373369217, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 148592, "time": 4697.279374837875, "episode/length": 288.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.986159169550173, "episode/intrinsic_return": 0.0}
{"step": 148832, "time": 4704.040283918381, "episode/length": 146.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 148912, "time": 4706.921654224396, "episode/length": 172.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 148936, "time": 4708.217348575592, "episode/length": 171.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 148952, "time": 4709.411175251007, "episode/length": 85.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9418604651162791, "episode/intrinsic_return": 0.0}
{"step": 149336, "time": 4719.915310144424, "episode/length": 158.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 149960, "time": 4736.268289089203, "episode/length": 189.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 150072, "time": 4742.456462621689, "eval_episode/length": 119.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9583333333333334}
{"step": 150072, "time": 4743.789363145828, "eval_episode/length": 146.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9931972789115646}
{"step": 150072, "time": 4744.891220569611, "eval_episode/length": 161.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9753086419753086}
{"step": 150072, "time": 4745.882599115372, "eval_episode/length": 168.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9644970414201184}
{"step": 150072, "time": 4746.857036828995, "eval_episode/length": 177.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9775280898876404}
{"step": 150072, "time": 4748.019542694092, "eval_episode/length": 193.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9742268041237113}
{"step": 150072, "time": 4748.930775642395, "eval_episode/length": 194.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 150072, "time": 4750.394833564758, "eval_episode/length": 227.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9780701754385965}
{"step": 150184, "time": 4753.367484331131, "episode/length": 203.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 150224, "time": 4755.307802438736, "episode/length": 173.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 150384, "time": 4760.134393453598, "episode/length": 178.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 150560, "time": 4765.317420244217, "episode/length": 202.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 150832, "time": 4772.7687022686005, "episode/length": 186.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 151112, "time": 4780.344329595566, "episode/length": 314.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9936507936507937, "episode/intrinsic_return": 0.0}
{"step": 151200, "time": 4783.601101875305, "episode/length": 285.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 151232, "time": 4785.24311041832, "episode/length": 158.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 151480, "time": 4791.914032936096, "episode/length": 156.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 151792, "time": 4800.5841364860535, "episode/length": 38.0, "episode/score": 1.0999999940395355, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 151800, "time": 4801.486816644669, "episode/length": 176.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 151848, "time": 4803.592399120331, "episode/length": 207.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 152064, "time": 4809.962614536285, "episode/length": 187.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9680851063829787, "episode/intrinsic_return": 0.0}
{"step": 152176, "time": 4813.493621110916, "episode/length": 46.0, "episode/score": 1.0999999940395355, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 152232, "time": 4815.586447715759, "episode/length": 139.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.0}
{"step": 152440, "time": 4821.488085508347, "episode/length": 150.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 152640, "time": 4827.50005030632, "episode/length": 179.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 152936, "time": 4835.4995238780975, "episode/length": 262.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.973384030418251, "episode/intrinsic_return": 0.0}
{"step": 153296, "time": 4845.425794363022, "episode/length": 180.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 153464, "time": 4850.203001976013, "episode/length": 160.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 153560, "time": 4853.463401794434, "episode/length": 165.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 153576, "time": 4854.746622562408, "episode/length": 222.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9775784753363229, "episode/intrinsic_return": 0.0}
{"step": 153824, "time": 4861.9264624118805, "episode/length": 172.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9653179190751445, "episode/intrinsic_return": 0.0}
{"step": 153976, "time": 4866.33823466301, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 154168, "time": 4871.93721985817, "episode/length": 75.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9868421052631579, "episode/intrinsic_return": 0.0}
{"step": 154216, "time": 4873.93573474884, "episode/length": 268.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9814126394052045, "episode/intrinsic_return": 0.0}
{"step": 154240, "time": 4875.517104625702, "episode/length": 96.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9896907216494846, "episode/intrinsic_return": 0.0}
{"step": 154440, "time": 4881.131196022034, "episode/length": 187.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 155184, "time": 4900.451375961304, "episode/length": 200.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 155576, "time": 4910.819056272507, "episode/length": 284.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9964912280701754, "episode/intrinsic_return": 0.0}
{"step": 155680, "time": 4914.507594347, "episode/length": 188.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 155688, "time": 4915.37273478508, "episode/length": 155.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 155912, "time": 4921.763391256332, "episode/length": 260.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9961685823754789, "episode/intrinsic_return": 0.0}
{"step": 155920, "time": 4922.980020046234, "episode/length": 209.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 156072, "time": 4927.500545024872, "episode/length": 231.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.978448275862069, "episode/intrinsic_return": 0.0}
{"step": 157040, "time": 4952.852980136871, "episode/length": 231.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 157168, "time": 4956.852424144745, "episode/length": 398.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9774436090225563, "episode/intrinsic_return": 0.0}
{"step": 157368, "time": 4962.510768413544, "episode/length": 161.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 157376, "time": 4963.77201628685, "episode/length": 211.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 157400, "time": 4964.985427618027, "episode/length": 213.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9813084112149533, "episode/intrinsic_return": 0.0}
{"step": 157712, "time": 4973.79421377182, "episode/length": 224.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 157760, "time": 4975.875052690506, "episode/length": 229.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 157800, "time": 4977.465173482895, "episode/length": 277.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9820143884892086, "episode/intrinsic_return": 0.0}
{"step": 158168, "time": 4987.475691080093, "episode/length": 140.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.0}
{"step": 158528, "time": 4997.582004308701, "episode/length": 44.0, "episode/score": -0.8999999910593033, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 158616, "time": 5000.358579158783, "episode/length": 180.0, "episode/score": 4.100000023841858, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 158616, "time": 5000.37380862236, "episode/length": 151.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 158784, "time": 5005.594342947006, "episode/length": 175.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 158856, "time": 5008.074443817139, "episode/length": 142.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.972027972027972, "episode/intrinsic_return": 0.0}
{"step": 159128, "time": 5015.591840267181, "episode/length": 42.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 159176, "time": 5017.650712490082, "episode/length": 176.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 159320, "time": 5021.948230981827, "episode/length": 189.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 159496, "time": 5027.115393877029, "episode/length": 39.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 159896, "time": 5037.725655794144, "episode/length": 159.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 159984, "time": 5040.992440700531, "episode/length": 326.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9969418960244648, "episode/intrinsic_return": 0.0}
{"step": 160056, "time": 5044.932347536087, "eval_episode/length": 41.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9761904761904762}
{"step": 160056, "time": 5045.820355176926, "eval_episode/length": 43.0, "eval_episode/score": 0.10000000149011612, "eval_episode/reward_rate": 0.9772727272727273}
{"step": 160056, "time": 5047.353653907776, "eval_episode/length": 86.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9310344827586207}
{"step": 160056, "time": 5049.450185537338, "eval_episode/length": 154.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.967741935483871}
{"step": 160056, "time": 5050.699153184891, "eval_episode/length": 177.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9719101123595506}
{"step": 160056, "time": 5051.937212467194, "eval_episode/length": 199.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.975}
{"step": 160056, "time": 5052.860279798508, "eval_episode/length": 203.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9754901960784313}
{"step": 160056, "time": 5053.8748478889465, "eval_episode/length": 212.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9953051643192489}
{"step": 160112, "time": 5055.59992980957, "episode/length": 76.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.987012987012987, "episode/intrinsic_return": 0.0}
{"step": 160448, "time": 5064.846716403961, "episode/length": 164.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 160592, "time": 5069.15155673027, "episode/length": 216.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9815668202764977, "episode/intrinsic_return": 0.0}
{"step": 160608, "time": 5070.3812646865845, "episode/length": 259.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 160712, "time": 5073.651789426804, "episode/length": 261.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9961832061068703, "episode/intrinsic_return": 0.0}
{"step": 160744, "time": 5075.240262269974, "episode/length": 36.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 161440, "time": 5093.463855743408, "episode/length": 264.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9849056603773585, "episode/intrinsic_return": 0.0}
{"step": 161464, "time": 5094.719807624817, "episode/length": 195.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 161792, "time": 5103.669474840164, "episode/length": 225.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 161824, "time": 5105.274949789047, "episode/length": 153.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 162016, "time": 5110.9530873298645, "episode/length": 175.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9659090909090909, "episode/intrinsic_return": 0.0}
{"step": 162128, "time": 5114.575576782227, "episode/length": 176.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 162144, "time": 5115.8892986774445, "episode/length": 253.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9803149606299213, "episode/intrinsic_return": 0.0}
{"step": 162144, "time": 5115.904475688934, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 162976, "time": 5137.612034320831, "episode/length": 191.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 162977, "time": 5138.892383813858, "train_stats/sum_log_reward": 4.338888812851574, "train_stats/max_log_achievement_collect_drink": 6.6722222222222225, "train_stats/max_log_achievement_collect_sapling": 2.6944444444444446, "train_stats/max_log_achievement_collect_wood": 2.683333333333333, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.16111111111111112, "train_stats/max_log_achievement_eat_cow": 0.1111111111111111, "train_stats/max_log_achievement_make_wood_pickaxe": 0.011111111111111112, "train_stats/max_log_achievement_make_wood_sword": 0.011111111111111112, "train_stats/max_log_achievement_place_plant": 2.3777777777777778, "train_stats/max_log_achievement_place_table": 0.9777777777777777, "train_stats/max_log_achievement_wake_up": 1.761111111111111, "train_stats/mean_log_entropy": 0.5867296286755138, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.161434117759146, "train/action_min": 0.0, "train/action_std": 2.82258520940455, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04661045639616687, "train/actor_opt_grad_steps": 9060.0, "train/actor_opt_loss": 2.303236419543987, "train/adv_mag": 0.8861801246317421, "train/adv_max": 0.8829502624709432, "train/adv_mean": 0.004969274145572322, "train/adv_min": -0.5007739716913642, "train/adv_std": 0.08148050500852305, "train/cont_avg": 0.9941930259146341, "train/cont_loss_mean": 0.0005546751483676395, "train/cont_loss_std": 0.015824614948437888, "train/cont_neg_acc": 0.9873499832502226, "train/cont_neg_loss": 0.04301035078625296, "train/cont_pos_acc": 0.9998993440372188, "train/cont_pos_loss": 0.0002783638689728185, "train/cont_pred": 0.9941583889286693, "train/cont_rate": 0.9941930259146341, "train/dyn_loss_mean": 12.602026488141316, "train/dyn_loss_std": 8.843840091984447, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0767674626373662, "train/extr_critic_critic_opt_grad_steps": 9060.0, "train/extr_critic_critic_opt_loss": 14814.243630907013, "train/extr_critic_mag": 3.317079390549078, "train/extr_critic_max": 3.317079390549078, "train/extr_critic_mean": 0.7327369910914724, "train/extr_critic_min": -0.2861174199639297, "train/extr_critic_std": 0.871375631704563, "train/extr_return_normed_mag": 1.8875354010884355, "train/extr_return_normed_max": 1.8875354010884355, "train/extr_return_normed_mean": 0.3485437151862354, "train/extr_return_normed_min": -0.18468277745130585, "train/extr_return_normed_std": 0.3530757270208219, "train/extr_return_rate": 0.4485651905216822, "train/extr_return_raw_mag": 4.7012222255148535, "train/extr_return_raw_max": 4.7012222255148535, "train/extr_return_raw_mean": 0.7455387977565208, "train/extr_return_raw_min": -0.6247567684185215, "train/extr_return_raw_std": 0.9074512426446124, "train/extr_reward_mag": 1.006480108237848, "train/extr_reward_max": 1.006480108237848, "train/extr_reward_mean": 0.01543244682252407, "train/extr_reward_min": -0.3398311039296592, "train/extr_reward_std": 0.11217666744458966, "train/image_loss_mean": 12.983128315064965, "train/image_loss_std": 16.06763937415146, "train/model_loss_mean": 20.59507968251298, "train/model_loss_std": 19.884308749873465, "train/model_opt_grad_norm": 87.52661834344632, "train/model_opt_grad_steps": 9047.980487804878, "train/model_opt_loss": 17903.150057164636, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 875.0, "train/policy_entropy_mag": 2.2738021571461746, "train/policy_entropy_max": 2.2738021571461746, "train/policy_entropy_mean": 0.6316156489093129, "train/policy_entropy_min": 0.07937946770249343, "train/policy_entropy_std": 0.45288909164870655, "train/policy_logprob_mag": 7.438343671473061, "train/policy_logprob_max": -0.009456711167060747, "train/policy_logprob_mean": -0.6323032678627386, "train/policy_logprob_min": -7.438343671473061, "train/policy_logprob_std": 1.1007622933969265, "train/policy_randomness_mag": 0.8025523773053798, "train/policy_randomness_max": 0.8025523773053798, "train/policy_randomness_mean": 0.22293260482753197, "train/policy_randomness_min": 0.028017468632357878, "train/policy_randomness_std": 0.15984997502187404, "train/post_ent_mag": 52.16810077574195, "train/post_ent_max": 52.16810077574195, "train/post_ent_mean": 36.82229316525343, "train/post_ent_min": 20.475102820047518, "train/post_ent_std": 5.735644505663616, "train/prior_ent_mag": 62.603637081239285, "train/prior_ent_max": 62.603637081239285, "train/prior_ent_mean": 49.5672584905857, "train/prior_ent_min": 25.411777384688214, "train/prior_ent_std": 6.7714295782694, "train/rep_loss_mean": 12.602026488141316, "train/rep_loss_std": 8.843840091984447, "train/reward_avg": 0.014611756773495183, "train/reward_loss_mean": 0.050180884187177914, "train/reward_loss_std": 0.25748131358768883, "train/reward_max_data": 1.011219514870062, "train/reward_max_pred": 1.0033284274543204, "train/reward_neg_acc": 0.9944101493533065, "train/reward_neg_loss": 0.031093711246986216, "train/reward_pos_acc": 0.9407400977320788, "train/reward_pos_loss": 0.9954124991486712, "train/reward_pred": 0.013834156700205512, "train/reward_rate": 0.019769435975609755, "eval_stats/sum_log_reward": 4.099999908357859, "eval_stats/max_log_achievement_collect_drink": 5.958333333333333, "eval_stats/max_log_achievement_collect_sapling": 2.125, "eval_stats/max_log_achievement_collect_wood": 2.75, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.20833333333333334, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.041666666666666664, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 1.8333333333333333, "eval_stats/max_log_achievement_place_table": 0.9583333333333334, "eval_stats/max_log_achievement_wake_up": 1.7083333333333333, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 4.539944347925484e-05, "report/cont_loss_std": 0.0002924880536738783, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00249475403688848, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 3.338101669214666e-05, "report/cont_pred": 0.9950960874557495, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 13.112415313720703, "report/dyn_loss_std": 9.304567337036133, "report/image_loss_mean": 13.91641616821289, "report/image_loss_std": 14.521203994750977, "report/model_loss_mean": 21.836444854736328, "report/model_loss_std": 18.495391845703125, "report/post_ent_mag": 51.676048278808594, "report/post_ent_max": 51.676048278808594, "report/post_ent_mean": 36.68409729003906, "report/post_ent_min": 21.351810455322266, "report/post_ent_std": 6.037033557891846, "report/prior_ent_mag": 63.81412887573242, "report/prior_ent_max": 63.81412887573242, "report/prior_ent_mean": 49.90789794921875, "report/prior_ent_min": 28.1936092376709, "report/prior_ent_std": 7.094043731689453, "report/rep_loss_mean": 13.112415313720703, "report/rep_loss_std": 9.304567337036133, "report/reward_avg": 0.02177734300494194, "report/reward_loss_mean": 0.05253319442272186, "report/reward_loss_std": 0.2971007227897644, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0031776428222656, "report/reward_neg_acc": 0.9909819960594177, "report/reward_neg_loss": 0.03431125357747078, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7519755959510803, "report/reward_pred": 0.025975340977311134, "report/reward_rate": 0.025390625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.0013665008591488004, "eval/cont_loss_std": 0.03206510841846466, "eval/cont_neg_acc": 0.75, "eval/cont_neg_loss": 0.3408014178276062, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 3.5383251088205725e-05, "eval/cont_pred": 0.9969925880432129, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 15.494230270385742, "eval/dyn_loss_std": 8.748321533203125, "eval/image_loss_mean": 14.431061744689941, "eval/image_loss_std": 14.21843433380127, "eval/model_loss_mean": 23.79936981201172, "eval/model_loss_std": 17.74772834777832, "eval/post_ent_mag": 47.829551696777344, "eval/post_ent_max": 47.829551696777344, "eval/post_ent_mean": 34.640167236328125, "eval/post_ent_min": 21.009130477905273, "eval/post_ent_std": 4.986817836761475, "eval/prior_ent_mag": 63.81412887573242, "eval/prior_ent_max": 63.81412887573242, "eval/prior_ent_mean": 47.654937744140625, "eval/prior_ent_min": 26.982990264892578, "eval/prior_ent_std": 7.425319671630859, "eval/rep_loss_mean": 15.494230270385742, "eval/rep_loss_std": 8.748321533203125, "eval/reward_avg": 0.01347656175494194, "eval/reward_loss_mean": 0.07040462642908096, "eval/reward_loss_std": 0.614319920539856, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0015907287597656, "eval/reward_neg_acc": 0.9970179796218872, "eval/reward_neg_loss": 0.012447431683540344, "eval/reward_pos_acc": 0.6111111044883728, "eval/reward_pos_loss": 3.30956768989563, "eval/reward_pred": 0.00530731026083231, "eval/reward_rate": 0.017578125, "replay/size": 162473.0, "replay/inserts": 32872.0, "replay/samples": 32864.0, "replay/insert_wait_avg": 1.2237809817847269e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 5.641475160258886e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 32224.0, "eval_replay/inserts": 5400.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.209312015109592e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.301568984985352e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1815507411957, "timer/env.step_count": 4109.0, "timer/env.step_total": 158.62405800819397, "timer/env.step_frac": 0.15859526492029757, "timer/env.step_avg": 0.03860405402973813, "timer/env.step_min": 0.0022673606872558594, "timer/env.step_max": 0.9231574535369873, "timer/replay._sample_count": 32864.0, "timer/replay._sample_total": 2907.5201740264893, "timer/replay._sample_frac": 2.9069924074002755, "timer/replay._sample_avg": 0.08847128085523641, "timer/replay._sample_min": 0.004826784133911133, "timer/replay._sample_max": 0.12719464302062988, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4784.0, "timer/agent.policy_total": 47.48454976081848, "timer/agent.policy_frac": 0.047475930470452614, "timer/agent.policy_avg": 0.009925700200839984, "timer/agent.policy_min": 0.0067822933197021484, "timer/agent.policy_max": 0.019315719604492188, "timer/dataset_train_count": 2054.0, "timer/dataset_train_total": 0.16019296646118164, "timer/dataset_train_frac": 0.00016016388858849562, "timer/dataset_train_avg": 7.79907334280339e-05, "timer/dataset_train_min": 5.6743621826171875e-05, "timer/dataset_train_max": 0.00016450881958007812, "timer/agent.train_count": 2054.0, "timer/agent.train_total": 760.6309168338776, "timer/agent.train_frac": 0.7604928487935051, "timer/agent.train_avg": 0.3703169020612841, "timer/agent.train_min": 0.35292863845825195, "timer/agent.train_max": 0.8360781669616699, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4083373546600342, "timer/agent.report_frac": 0.00040826323416726817, "timer/agent.report_avg": 0.2041686773300171, "timer/agent.report_min": 0.20278000831604004, "timer/agent.report_max": 0.20555734634399414, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.3855438232421875e-05, "timer/dataset_eval_frac": 3.38492928682127e-08, "timer/dataset_eval_avg": 3.3855438232421875e-05, "timer/dataset_eval_min": 3.3855438232421875e-05, "timer/dataset_eval_max": 3.3855438232421875e-05, "fps": 32.86549069891741}
{"step": 163112, "time": 5142.111196041107, "episode/length": 160.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 163136, "time": 5143.695524215698, "episode/length": 208.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 163456, "time": 5152.387959718704, "episode/length": 179.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 163528, "time": 5154.733374595642, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 163864, "time": 5163.847365856171, "episode/length": 258.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9961389961389961, "episode/intrinsic_return": 0.0}
{"step": 163872, "time": 5165.105553150177, "episode/length": 217.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.981651376146789, "episode/intrinsic_return": 0.0}
{"step": 164064, "time": 5170.767257452011, "episode/length": 239.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9875, "episode/intrinsic_return": 0.0}
{"step": 164136, "time": 5173.237432718277, "episode/length": 144.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 164424, "time": 5181.36083483696, "episode/length": 160.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 164760, "time": 5190.448051452637, "episode/length": 162.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 164760, "time": 5190.462984323502, "episode/length": 205.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 165152, "time": 5201.213858366013, "episode/length": 159.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 165472, "time": 5209.973684310913, "episode/length": 175.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 165472, "time": 5209.98936009407, "episode/length": 200.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 165648, "time": 5215.1374089717865, "episode/length": 188.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 165896, "time": 5221.975720405579, "episode/length": 295.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9864864864864865, "episode/intrinsic_return": 0.0}
{"step": 166088, "time": 5227.533598184586, "episode/length": 165.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 166160, "time": 5230.274695634842, "episode/length": 216.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 166984, "time": 5251.223642587662, "episode/length": 166.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 167144, "time": 5256.011478662491, "episode/length": 297.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9832214765100671, "episode/intrinsic_return": 0.0}
{"step": 167176, "time": 5257.672900438309, "episode/length": 212.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 167272, "time": 5260.831606388092, "episode/length": 224.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 167576, "time": 5269.104446411133, "episode/length": 176.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 167680, "time": 5272.7966132164, "episode/length": 222.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 167816, "time": 5276.887793540955, "episode/length": 215.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 168448, "time": 5293.716598033905, "episode/length": 411.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 168504, "time": 5295.916087627411, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 168528, "time": 5297.5789387226105, "episode/length": 172.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 168536, "time": 5298.408339738846, "episode/length": 193.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 169200, "time": 5316.116665840149, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 169224, "time": 5317.339334964752, "episode/length": 192.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9585492227979274, "episode/intrinsic_return": 0.0}
{"step": 169520, "time": 5325.774127483368, "episode/length": 36.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 169640, "time": 5329.3353703022, "episode/length": 148.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9731543624161074, "episode/intrinsic_return": 0.0}
{"step": 169872, "time": 5336.123769044876, "episode/length": 83.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9880952380952381, "episode/intrinsic_return": 0.0}
{"step": 169992, "time": 5339.713899612427, "episode/length": 181.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 170040, "time": 5343.357618093491, "eval_episode/length": 39.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.975}
{"step": 170040, "time": 5344.933985948563, "eval_episode/length": 41.0, "eval_episode/score": 1.0999999940395355, "eval_episode/reward_rate": 0.9761904761904762}
{"step": 170040, "time": 5346.971187829971, "eval_episode/length": 151.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 170040, "time": 5346.987570524216, "eval_episode/length": 151.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9605263157894737}
{"step": 170040, "time": 5347.977785110474, "eval_episode/length": 157.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9683544303797469}
{"step": 170040, "time": 5348.799437522888, "eval_episode/length": 158.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9748427672955975}
{"step": 170040, "time": 5349.9061822891235, "eval_episode/length": 170.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9649122807017544}
{"step": 170040, "time": 5350.9315094947815, "eval_episode/length": 180.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9779005524861878}
{"step": 170056, "time": 5351.518725633621, "episode/length": 193.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 170128, "time": 5354.327147245407, "episode/length": 199.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 170552, "time": 5365.623867273331, "episode/length": 409.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9780487804878049, "episode/intrinsic_return": 0.0}
{"step": 170832, "time": 5373.569283723831, "episode/length": 406.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9778869778869779, "episode/intrinsic_return": 0.0}
{"step": 171096, "time": 5380.732256412506, "episode/length": 196.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 171288, "time": 5386.461310625076, "episode/length": 205.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 171416, "time": 5390.650139808655, "episode/length": 192.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 171520, "time": 5394.274455547333, "episode/length": 173.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 172136, "time": 5410.23672246933, "episode/length": 259.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9769230769230769, "episode/intrinsic_return": 0.0}
{"step": 172176, "time": 5412.194611787796, "episode/length": 272.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9963369963369964, "episode/intrinsic_return": 0.0}
{"step": 172208, "time": 5413.853727579117, "episode/length": 171.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 172448, "time": 5420.659076452255, "episode/length": 236.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9831223628691983, "episode/intrinsic_return": 0.0}
{"step": 172512, "time": 5423.068859100342, "episode/length": 176.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 172624, "time": 5426.729730844498, "episode/length": 51.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 173064, "time": 5438.232564210892, "episode/length": 192.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 173296, "time": 5444.9271721839905, "episode/length": 234.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 173408, "time": 5448.504573583603, "episode/length": 158.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9559748427672956, "episode/intrinsic_return": 0.0}
{"step": 173824, "time": 5459.52965092659, "episode/length": 94.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9894736842105263, "episode/intrinsic_return": 0.0}
{"step": 173944, "time": 5463.129003286362, "episode/length": 178.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9664804469273743, "episode/intrinsic_return": 0.0}
{"step": 173952, "time": 5464.325171470642, "episode/length": 332.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.990990990990991, "episode/intrinsic_return": 0.0}
{"step": 174016, "time": 5466.701080799103, "episode/length": 173.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 174384, "time": 5476.7393181324005, "episode/length": 241.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9958677685950413, "episode/intrinsic_return": 0.0}
{"step": 174600, "time": 5482.869681119919, "episode/length": 162.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 174608, "time": 5484.1060791015625, "episode/length": 149.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 175120, "time": 5497.552580833435, "episode/length": 63.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.953125, "episode/intrinsic_return": 0.0}
{"step": 175352, "time": 5504.0517036914825, "episode/length": 174.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 175360, "time": 5505.292519807816, "episode/length": 397.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9773869346733668, "episode/intrinsic_return": 0.0}
{"step": 175416, "time": 5507.3343760967255, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 175488, "time": 5510.265909671783, "episode/length": 192.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 175792, "time": 5518.6772882938385, "episode/length": 148.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9731543624161074, "episode/intrinsic_return": 0.0}
{"step": 175944, "time": 5523.106001377106, "episode/length": 264.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9849056603773585, "episode/intrinsic_return": 0.0}
{"step": 176336, "time": 5533.779989004135, "episode/length": 243.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 176416, "time": 5536.65602517128, "episode/length": 131.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9621212121212122, "episode/intrinsic_return": 0.0}
{"step": 177104, "time": 5554.630326986313, "episode/length": 163.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 177120, "time": 5555.8242127895355, "episode/length": 212.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 177224, "time": 5559.119409561157, "episode/length": 262.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9809885931558935, "episode/intrinsic_return": 0.0}
{"step": 177320, "time": 5562.335054636002, "episode/length": 245.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 177584, "time": 5570.001721382141, "episode/length": 204.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 177632, "time": 5571.96289730072, "episode/length": 161.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9876543209876543, "episode/intrinsic_return": 0.0}
{"step": 177664, "time": 5573.626444578171, "episode/length": 54.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 177864, "time": 5579.353947401047, "episode/length": 296.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9865319865319865, "episode/intrinsic_return": 0.0}
{"step": 177952, "time": 5582.680958986282, "episode/length": 39.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 178160, "time": 5588.597553014755, "episode/length": 36.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 178240, "time": 5591.5515286922455, "episode/length": 141.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 178352, "time": 5595.129832267761, "episode/length": 49.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 178488, "time": 5599.136003494263, "episode/length": 258.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9806949806949807, "episode/intrinsic_return": 0.0}
{"step": 178512, "time": 5600.819684267044, "episode/length": 173.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 179008, "time": 5613.983488559723, "episode/length": 210.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 179392, "time": 5624.483562707901, "episode/length": 225.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9778761061946902, "episode/intrinsic_return": 0.0}
{"step": 179432, "time": 5626.186095952988, "episode/length": 134.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9555555555555556, "episode/intrinsic_return": 0.0}
{"step": 179528, "time": 5629.359171390533, "episode/length": 170.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 179680, "time": 5634.3809633255005, "episode/length": 179.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 179720, "time": 5636.0398144721985, "episode/length": 88.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9325842696629213, "episode/intrinsic_return": 0.0}
{"step": 179784, "time": 5638.36906003952, "episode/length": 264.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9849056603773585, "episode/intrinsic_return": 0.0}
{"step": 180024, "time": 5648.551867246628, "eval_episode/length": 150.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9668874172185431}
{"step": 180024, "time": 5649.556226968765, "eval_episode/length": 159.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.975}
{"step": 180024, "time": 5650.682215213776, "eval_episode/length": 178.0, "eval_episode/score": 4.099999964237213, "eval_episode/reward_rate": 0.9720670391061452}
{"step": 180024, "time": 5651.986160993576, "eval_episode/length": 203.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9754901960784313}
{"step": 180024, "time": 5652.002103567123, "eval_episode/length": 203.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9754901960784313}
{"step": 180024, "time": 5653.187945365906, "eval_episode/length": 219.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9954545454545455}
{"step": 180024, "time": 5654.023421049118, "eval_episode/length": 220.0, "eval_episode/score": 6.100000023841858, "eval_episode/reward_rate": 0.995475113122172}
{"step": 180024, "time": 5656.183182477951, "eval_episode/length": 289.0, "eval_episode/score": 5.099999979138374, "eval_episode/reward_rate": 0.996551724137931}
{"step": 180384, "time": 5665.788462877274, "episode/length": 236.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 180464, "time": 5668.536589860916, "episode/length": 243.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 180832, "time": 5678.443961143494, "episode/length": 174.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 180968, "time": 5682.606079339981, "episode/length": 179.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 181096, "time": 5686.670196533203, "episode/length": 212.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 181272, "time": 5691.992017507553, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 181528, "time": 5699.403473377228, "episode/length": 225.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 181856, "time": 5708.745010137558, "episode/length": 183.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 181864, "time": 5709.639000892639, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 182016, "time": 5714.511371612549, "episode/length": 291.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9828767123287672, "episode/intrinsic_return": 0.0}
{"step": 182600, "time": 5729.889138698578, "episode/length": 165.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 182600, "time": 5729.90510392189, "episode/length": 203.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 182856, "time": 5737.036106824875, "episode/length": 252.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9802371541501976, "episode/intrinsic_return": 0.0}
{"step": 182888, "time": 5738.689005374908, "episode/length": 223.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 182904, "time": 5739.90421962738, "episode/length": 171.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 182960, "time": 5742.385426044464, "episode/length": 136.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9562043795620438, "episode/intrinsic_return": 0.0}
{"step": 183240, "time": 5749.955154657364, "episode/length": 172.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 183384, "time": 5754.40287733078, "episode/length": 170.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 183656, "time": 5762.087753295898, "episode/length": 131.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9621212121212122, "episode/intrinsic_return": 0.0}
{"step": 184088, "time": 5773.491961479187, "episode/length": 149.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.96, "episode/intrinsic_return": 0.0}
{"step": 184104, "time": 5774.687816143036, "episode/length": 155.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 184336, "time": 5781.693086147308, "episode/length": 216.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9723502304147466, "episode/intrinsic_return": 0.0}
{"step": 184448, "time": 5785.209857702255, "episode/length": 185.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 184552, "time": 5788.347450733185, "episode/length": 205.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 184584, "time": 5789.95219707489, "episode/length": 167.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 184720, "time": 5794.416285991669, "episode/length": 166.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 184920, "time": 5800.111794471741, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 185720, "time": 5820.755920410156, "episode/length": 158.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 185720, "time": 5820.772347688675, "episode/length": 203.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 185752, "time": 5822.412987709045, "episode/length": 149.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 185848, "time": 5825.656105518341, "episode/length": 157.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 186024, "time": 5830.946527004242, "episode/length": 37.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 186104, "time": 5833.91796875, "episode/length": 220.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 186160, "time": 5836.284550189972, "episode/length": 179.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 186184, "time": 5837.57741522789, "episode/length": 259.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9730769230769231, "episode/intrinsic_return": 0.0}
{"step": 186464, "time": 5845.700971126556, "episode/length": 192.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 187360, "time": 5868.920057296753, "episode/length": 146.0, "episode/score": 5.100000016391277, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 187360, "time": 5868.936666250229, "episode/length": 156.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 187456, "time": 5872.1179184913635, "episode/length": 216.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9723502304147466, "episode/intrinsic_return": 0.0}
{"step": 187472, "time": 5873.36984539032, "episode/length": 202.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9802955665024631, "episode/intrinsic_return": 0.0}
{"step": 187496, "time": 5874.6404366493225, "episode/length": 217.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 187672, "time": 5879.915216207504, "episode/length": 188.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9682539682539683, "episode/intrinsic_return": 0.0}
{"step": 187784, "time": 5883.514426231384, "episode/length": 40.0, "episode/score": 1.0999999940395355, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 187864, "time": 5886.372048377991, "episode/length": 229.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 188728, "time": 5908.857441663742, "episode/length": 170.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 189104, "time": 5919.202002763748, "episode/length": 200.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 189136, "time": 5920.820857286453, "episode/length": 182.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 189144, "time": 5921.749658346176, "episode/length": 334.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9940298507462687, "episode/intrinsic_return": 0.0}
{"step": 189224, "time": 5924.7349972724915, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 189312, "time": 5927.889328718185, "episode/length": 229.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 189456, "time": 5932.2868757247925, "episode/length": 261.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9847328244274809, "episode/intrinsic_return": 0.0}
{"step": 189816, "time": 5941.938700675964, "episode/length": 84.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9882352941176471, "episode/intrinsic_return": 0.0}
{"step": 189848, "time": 5943.542006015778, "episode/length": 257.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9844961240310077, "episode/intrinsic_return": 0.0}
{"step": 189904, "time": 5945.934870958328, "episode/length": 146.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9659863945578231, "episode/intrinsic_return": 0.0}
{"step": 190008, "time": 5952.444491147995, "eval_episode/length": 162.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9693251533742331}
{"step": 190008, "time": 5953.290381193161, "eval_episode/length": 163.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9634146341463414}
{"step": 190008, "time": 5954.317961931229, "eval_episode/length": 174.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 190008, "time": 5955.294976472855, "eval_episode/length": 182.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9726775956284153}
{"step": 190008, "time": 5956.369756937027, "eval_episode/length": 194.0, "eval_episode/score": 4.099999979138374, "eval_episode/reward_rate": 0.9948717948717949}
{"step": 190008, "time": 5957.3576600551605, "eval_episode/length": 201.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9702970297029703}
{"step": 190008, "time": 5958.765746116638, "eval_episode/length": 229.0, "eval_episode/score": 6.100000023841858, "eval_episode/reward_rate": 0.9956521739130435}
{"step": 190008, "time": 5960.827915906906, "eval_episode/length": 294.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9864406779661017}
{"step": 190568, "time": 5974.871225357056, "episode/length": 177.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 190728, "time": 5979.745168209076, "episode/length": 202.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 190768, "time": 5981.76079082489, "episode/length": 192.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 190880, "time": 5985.4277222156525, "episode/length": 195.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 191200, "time": 5994.262827396393, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 191248, "time": 5996.355955839157, "episode/length": 45.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 191272, "time": 5997.657686948776, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9649122807017544, "episode/intrinsic_return": 0.0}
{"step": 191392, "time": 6001.832753658295, "episode/length": 241.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9793388429752066, "episode/intrinsic_return": 0.0}
{"step": 191448, "time": 6003.927644968033, "episode/length": 203.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 191616, "time": 6009.270164728165, "episode/length": 45.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 191712, "time": 6012.599902868271, "episode/length": 142.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.965034965034965, "episode/intrinsic_return": 0.0}
{"step": 192232, "time": 6026.90326666832, "episode/length": 182.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 192664, "time": 6038.523304700851, "episode/length": 182.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 192848, "time": 6044.118660211563, "episode/length": 196.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 192936, "time": 6046.924666404724, "episode/length": 275.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9746376811594203, "episode/intrinsic_return": 0.0}
{"step": 193024, "time": 6050.063315868378, "episode/length": 175.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 193152, "time": 6054.092213392258, "episode/length": 179.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 193160, "time": 6054.974043607712, "episode/length": 213.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9719626168224299, "episode/intrinsic_return": 0.0}
{"step": 193448, "time": 6062.990469694138, "episode/length": 35.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 193496, "time": 6065.041712999344, "episode/length": 262.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9847908745247148, "episode/intrinsic_return": 0.0}
{"step": 193760, "time": 6072.560334205627, "episode/length": 38.0, "episode/score": -0.9000000283122063, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 193976, "time": 6078.572460174561, "episode/length": 217.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 194192, "time": 6084.938632011414, "episode/length": 167.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 194304, "time": 6088.633934736252, "episode/length": 159.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 194360, "time": 6090.690495014191, "episode/length": 211.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 194400, "time": 6092.697275400162, "episode/length": 182.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 194464, "time": 6095.148313760757, "episode/length": 163.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 195168, "time": 6113.51220035553, "episode/length": 208.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9808612440191388, "episode/intrinsic_return": 0.0}
{"step": 195608, "time": 6124.936481952667, "episode/length": 230.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9783549783549783, "episode/intrinsic_return": 0.0}
{"step": 195656, "time": 6126.914974451065, "episode/length": 161.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 195688, "time": 6128.553472280502, "episode/length": 186.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9679144385026738, "episode/intrinsic_return": 0.0}
{"step": 195728, "time": 6130.594925403595, "episode/length": 218.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 195752, "time": 6131.88108754158, "episode/length": 180.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 195977, "time": 6138.994950532913, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.219144222241093, "train/action_min": 0.0, "train/action_std": 2.7414438021931673, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04374013510015276, "train/actor_opt_grad_steps": 11120.0, "train/actor_opt_loss": -2.1367793732507216, "train/adv_mag": 0.7792971635210342, "train/adv_max": 0.7735489362103928, "train/adv_mean": 0.0036245472005213154, "train/adv_min": -0.4851424868268091, "train/adv_std": 0.07627141903995892, "train/cont_avg": 0.9945086050724637, "train/cont_loss_mean": 0.00031875235398967357, "train/cont_loss_std": 0.008849083228396273, "train/cont_neg_acc": 0.9898069737038174, "train/cont_neg_loss": 0.025718036305545026, "train/cont_pos_acc": 0.999938232023359, "train/cont_pos_loss": 0.00018562034408224002, "train/cont_pred": 0.9944938677520567, "train/cont_rate": 0.9945086050724637, "train/dyn_loss_mean": 13.677743017961438, "train/dyn_loss_std": 9.203615345240792, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9853490078506838, "train/extr_critic_critic_opt_grad_steps": 11120.0, "train/extr_critic_critic_opt_loss": 14697.158420138889, "train/extr_critic_mag": 3.533181241169068, "train/extr_critic_max": 3.533181241169068, "train/extr_critic_mean": 0.7394465655808288, "train/extr_critic_min": -0.2778807216220432, "train/extr_critic_std": 0.914165849271028, "train/extr_return_normed_mag": 1.7942960596314952, "train/extr_return_normed_max": 1.7942960596314952, "train/extr_return_normed_mean": 0.3194010634929086, "train/extr_return_normed_min": -0.1661645742358217, "train/extr_return_normed_std": 0.3442967223084491, "train/extr_return_rate": 0.4220552389028568, "train/extr_return_raw_mag": 4.803399832352348, "train/extr_return_raw_max": 4.803399832352348, "train/extr_return_raw_mean": 0.7494283599266107, "train/extr_return_raw_min": -0.5842773524171488, "train/extr_return_raw_std": 0.9459121878020429, "train/extr_reward_mag": 1.0087559257728467, "train/extr_reward_max": 1.0087559257728467, "train/extr_reward_mean": 0.01738508455545286, "train/extr_reward_min": -0.3383981548069756, "train/extr_reward_std": 0.1202298002542505, "train/image_loss_mean": 11.714769798776377, "train/image_loss_std": 14.60429981250118, "train/model_loss_mean": 19.971918373292194, "train/model_loss_std": 18.56221159875105, "train/model_opt_grad_norm": 78.52190830396569, "train/model_opt_grad_steps": 11106.516908212561, "train/model_opt_loss": 14030.984757133152, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 700.4830917874397, "train/policy_entropy_mag": 2.3007602668614777, "train/policy_entropy_max": 2.3007602668614777, "train/policy_entropy_mean": 0.5897571731016832, "train/policy_entropy_min": 0.07937670949000668, "train/policy_entropy_std": 0.48107280981713446, "train/policy_logprob_mag": 7.4383726672849795, "train/policy_logprob_max": -0.009456196610910305, "train/policy_logprob_mean": -0.5902307256696305, "train/policy_logprob_min": -7.4383726672849795, "train/policy_logprob_std": 1.0936347234652237, "train/policy_randomness_mag": 0.8120674082046546, "train/policy_randomness_max": 0.8120674082046546, "train/policy_randomness_mean": 0.2081584011874913, "train/policy_randomness_min": 0.02801649509096779, "train/policy_randomness_std": 0.16979759110920672, "train/post_ent_mag": 54.22736131972161, "train/post_ent_max": 54.22736131972161, "train/post_ent_mean": 37.56619388009039, "train/post_ent_min": 20.99407526836303, "train/post_ent_std": 6.061155252410594, "train/prior_ent_mag": 63.9226564232278, "train/prior_ent_max": 63.9226564232278, "train/prior_ent_mean": 51.37494340610965, "train/prior_ent_min": 27.64543428282807, "train/prior_ent_std": 6.661174389475209, "train/rep_loss_mean": 13.677743017961438, "train/rep_loss_std": 9.203615345240792, "train/reward_avg": 0.01653692994496205, "train/reward_loss_mean": 0.050184105131505195, "train/reward_loss_std": 0.2549480834732885, "train/reward_max_data": 1.0101449299549712, "train/reward_max_pred": 1.0034981850840619, "train/reward_neg_acc": 0.9942075016993831, "train/reward_neg_loss": 0.03053978427902656, "train/reward_pos_acc": 0.9520954541538073, "train/reward_pos_loss": 0.9396401934577647, "train/reward_pred": 0.015987341758988544, "train/reward_rate": 0.021531551932367148, "train_stats/sum_log_reward": 4.7022726566276765, "train_stats/max_log_achievement_collect_drink": 5.244318181818182, "train_stats/max_log_achievement_collect_sapling": 3.289772727272727, "train_stats/max_log_achievement_collect_wood": 3.8238636363636362, "train_stats/max_log_achievement_defeat_skeleton": 0.011363636363636364, "train_stats/max_log_achievement_defeat_zombie": 0.3181818181818182, "train_stats/max_log_achievement_eat_cow": 0.06818181818181818, "train_stats/max_log_achievement_make_wood_pickaxe": 0.022727272727272728, "train_stats/max_log_achievement_make_wood_sword": 0.005681818181818182, "train_stats/max_log_achievement_place_plant": 2.8238636363636362, "train_stats/max_log_achievement_place_table": 1.5511363636363635, "train_stats/max_log_achievement_wake_up": 1.9261363636363635, "train_stats/mean_log_entropy": 0.5237835838713429, "eval_stats/sum_log_reward": 4.266666541496913, "eval_stats/max_log_achievement_collect_drink": 4.041666666666667, "eval_stats/max_log_achievement_collect_sapling": 3.3333333333333335, "eval_stats/max_log_achievement_collect_wood": 3.2083333333333335, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.25, "eval_stats/max_log_achievement_eat_cow": 0.041666666666666664, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 3.2083333333333335, "eval_stats/max_log_achievement_place_table": 1.4583333333333333, "eval_stats/max_log_achievement_wake_up": 1.875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.00012462827726267278, "report/cont_loss_std": 0.0038501827511936426, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.025239676237106323, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.394505716234562e-06, "report/cont_pred": 0.9952319860458374, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 13.567605972290039, "report/dyn_loss_std": 8.979909896850586, "report/image_loss_mean": 9.654682159423828, "report/image_loss_std": 12.02402400970459, "report/model_loss_mean": 17.843242645263672, "report/model_loss_std": 15.84782600402832, "report/post_ent_mag": 56.26333999633789, "report/post_ent_max": 56.26333999633789, "report/post_ent_mean": 38.050357818603516, "report/post_ent_min": 21.371253967285156, "report/post_ent_std": 6.4267683029174805, "report/prior_ent_mag": 64.17437744140625, "report/prior_ent_max": 64.17437744140625, "report/prior_ent_mean": 52.21454620361328, "report/prior_ent_min": 27.057947158813477, "report/prior_ent_std": 5.914968013763428, "report/rep_loss_mean": 13.567605972290039, "report/rep_loss_std": 8.979909896850586, "report/reward_avg": 0.01591796800494194, "report/reward_loss_mean": 0.047872163355350494, "report/reward_loss_std": 0.27581629157066345, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0015432834625244, "report/reward_neg_acc": 0.9910269379615784, "report/reward_neg_loss": 0.024106735363602638, "report/reward_pos_acc": 0.8571428656578064, "report/reward_pos_loss": 1.18295419216156, "report/reward_pred": 0.014971038326621056, "report/reward_rate": 0.0205078125, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 3.333654603920877e-05, "eval/cont_loss_std": 0.0009142113849520683, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.006686550565063953, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 6.90748152010201e-07, "eval/cont_pred": 0.995148777961731, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 15.784040451049805, "eval/dyn_loss_std": 9.421558380126953, "eval/image_loss_mean": 15.418312072753906, "eval/image_loss_std": 18.034008026123047, "eval/model_loss_mean": 24.96021270751953, "eval/model_loss_std": 21.83723258972168, "eval/post_ent_mag": 54.859619140625, "eval/post_ent_max": 54.859619140625, "eval/post_ent_mean": 35.72425842285156, "eval/post_ent_min": 21.297653198242188, "eval/post_ent_std": 4.900994300842285, "eval/prior_ent_mag": 64.17437744140625, "eval/prior_ent_max": 64.17437744140625, "eval/prior_ent_mean": 49.39955139160156, "eval/prior_ent_min": 29.608234405517578, "eval/prior_ent_std": 6.5628437995910645, "eval/rep_loss_mean": 15.784040451049805, "eval/rep_loss_std": 9.421558380126953, "eval/reward_avg": 0.01582031324505806, "eval/reward_loss_mean": 0.07144202291965485, "eval/reward_loss_std": 0.5092872381210327, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0009546279907227, "eval/reward_neg_acc": 0.999002993106842, "eval/reward_neg_loss": 0.03642736002802849, "eval/reward_pos_acc": 0.761904776096344, "eval/reward_pos_loss": 1.7438089847564697, "eval/reward_pred": 0.009091217070817947, "eval/reward_rate": 0.0205078125, "replay/size": 195473.0, "replay/inserts": 33000.0, "replay/samples": 33008.0, "replay/insert_wait_avg": 1.2235063495058003e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 5.6377384076694e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 38352.0, "eval_replay/inserts": 6128.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.209600787249931e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 6.407499313354492e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0887305736542, "timer/env.step_count": 4125.0, "timer/env.step_total": 155.9193150997162, "timer/env.step_frac": 0.15590548151690536, "timer/env.step_avg": 0.03779862184235544, "timer/env.step_min": 0.0022580623626708984, "timer/env.step_max": 0.9274215698242188, "timer/replay._sample_count": 33008.0, "timer/replay._sample_total": 2919.8744039535522, "timer/replay._sample_frac": 2.919615344809158, "timer/replay._sample_avg": 0.0884595977930669, "timer/replay._sample_min": 0.0003917217254638672, "timer/replay._sample_max": 0.12415623664855957, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4891.0, "timer/agent.policy_total": 49.03675699234009, "timer/agent.policy_frac": 0.04903240631879978, "timer/agent.policy_avg": 0.01002591637545289, "timer/agent.policy_min": 0.007253170013427734, "timer/agent.policy_max": 0.019459962844848633, "timer/dataset_train_count": 2063.0, "timer/dataset_train_total": 0.1626603603363037, "timer/dataset_train_frac": 0.00016264592866975034, "timer/dataset_train_avg": 7.884651494731154e-05, "timer/dataset_train_min": 6.151199340820312e-05, "timer/dataset_train_max": 0.0001773834228515625, "timer/agent.train_count": 2063.0, "timer/agent.train_total": 764.3022711277008, "timer/agent.train_frac": 0.764234460165644, "timer/agent.train_avg": 0.3704809845505094, "timer/agent.train_min": 0.3533034324645996, "timer/agent.train_max": 0.5563497543334961, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.40723752975463867, "timer/agent.report_frac": 0.0004072013985409533, "timer/agent.report_avg": 0.20361876487731934, "timer/agent.report_min": 0.2032794952392578, "timer/agent.report_max": 0.20395803451538086, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.3855438232421875e-05, "timer/dataset_eval_frac": 3.38524344864903e-08, "timer/dataset_eval_avg": 3.3855438232421875e-05, "timer/dataset_eval_min": 3.3855438232421875e-05, "timer/dataset_eval_max": 3.3855438232421875e-05, "fps": 32.99660061309311}
{"step": 196008, "time": 6139.439306020737, "episode/length": 192.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 196040, "time": 6142.70365190506, "episode/length": 53.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 196104, "time": 6145.065021276474, "episode/length": 212.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 196600, "time": 6158.1885051727295, "episode/length": 178.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 196760, "time": 6162.990960597992, "episode/length": 125.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9603174603174603, "episode/intrinsic_return": 0.0}
{"step": 196920, "time": 6167.763354063034, "episode/length": 157.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 196936, "time": 6169.0378267765045, "episode/length": 150.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9602649006622517, "episode/intrinsic_return": 0.0}
{"step": 197312, "time": 6179.348806619644, "episode/length": 158.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9559748427672956, "episode/intrinsic_return": 0.0}
{"step": 197528, "time": 6185.3516726493835, "episode/length": 229.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9739130434782609, "episode/intrinsic_return": 0.0}
{"step": 197672, "time": 6189.804592847824, "episode/length": 195.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9693877551020408, "episode/intrinsic_return": 0.0}
{"step": 197976, "time": 6198.172098636627, "episode/length": 171.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 198232, "time": 6205.513589143753, "episode/length": 277.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9784172661870504, "episode/intrinsic_return": 0.0}
{"step": 198616, "time": 6215.895519256592, "episode/length": 231.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 198688, "time": 6218.694119691849, "episode/length": 144.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9724137931034482, "episode/intrinsic_return": 0.0}
{"step": 198848, "time": 6223.515443325043, "episode/length": 146.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9659863945578231, "episode/intrinsic_return": 0.0}
{"step": 198864, "time": 6224.812925577164, "episode/length": 240.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.995850622406639, "episode/intrinsic_return": 0.0}
{"step": 198904, "time": 6226.421676397324, "episode/length": 198.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 199024, "time": 6230.456309080124, "episode/length": 262.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9809885931558935, "episode/intrinsic_return": 0.0}
{"step": 199200, "time": 6235.645226716995, "episode/length": 36.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 199368, "time": 6240.647398233414, "episode/length": 173.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 199880, "time": 6254.273037672043, "episode/length": 205.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9805825242718447, "episode/intrinsic_return": 0.0}
{"step": 200088, "time": 6260.20020532608, "episode/length": 174.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 200096, "time": 6262.5577800273895, "eval_episode/length": 12.0, "eval_episode/score": 1.100000023841858, "eval_episode/reward_rate": 0.9230769230769231}
{"step": 200096, "time": 6266.016470909119, "eval_episode/length": 165.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9759036144578314}
{"step": 200096, "time": 6266.861925125122, "eval_episode/length": 167.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9583333333333334}
{"step": 200096, "time": 6267.7833778858185, "eval_episode/length": 171.0, "eval_episode/score": 4.099999971687794, "eval_episode/reward_rate": 0.9941860465116279}
{"step": 200096, "time": 6269.0308628082275, "eval_episode/length": 178.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9720670391061452}
{"step": 200096, "time": 6269.9966776371, "eval_episode/length": 198.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9748743718592965}
{"step": 200096, "time": 6271.262212753296, "eval_episode/length": 219.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9772727272727273}
{"step": 200096, "time": 6272.21205997467, "eval_episode/length": 224.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9822222222222222}
{"step": 200200, "time": 6274.865659952164, "episode/length": 166.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 200312, "time": 6278.493107557297, "episode/length": 211.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 200360, "time": 6280.580879449844, "episode/length": 188.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 200664, "time": 6289.003530025482, "episode/length": 182.0, "episode/score": 6.100000016391277, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 200952, "time": 6297.083736658096, "episode/length": 197.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 201440, "time": 6310.250612020493, "episode/length": 154.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 201504, "time": 6312.697283983231, "episode/length": 309.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9870967741935484, "episode/intrinsic_return": 0.0}
{"step": 201728, "time": 6319.094493150711, "episode/length": 230.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9826839826839827, "episode/intrinsic_return": 0.0}
{"step": 201920, "time": 6324.666290283203, "episode/length": 200.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 202144, "time": 6331.01905632019, "episode/length": 222.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9820627802690582, "episode/intrinsic_return": 0.0}
{"step": 202224, "time": 6333.785318136215, "episode/length": 266.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 202368, "time": 6338.210773229599, "episode/length": 212.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 202552, "time": 6343.463994503021, "episode/length": 50.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 202560, "time": 6344.752960920334, "episode/length": 200.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 202944, "time": 6355.307886362076, "episode/length": 187.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 203304, "time": 6364.807824134827, "episode/length": 196.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 203560, "time": 6371.9709758758545, "episode/length": 204.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9804878048780488, "episode/intrinsic_return": 0.0}
{"step": 203592, "time": 6373.584327220917, "episode/length": 170.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 203688, "time": 6376.838931798935, "episode/length": 272.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9853479853479854, "episode/intrinsic_return": 0.0}
{"step": 203944, "time": 6384.002425909042, "episode/length": 173.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 204112, "time": 6389.1999390125275, "episode/length": 217.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 204128, "time": 6390.42395401001, "episode/length": 195.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9693877551020408, "episode/intrinsic_return": 0.0}
{"step": 204384, "time": 6397.777221441269, "episode/length": 102.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9514563106796117, "episode/intrinsic_return": 0.0}
{"step": 204440, "time": 6399.814879894257, "episode/length": 186.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 204800, "time": 6409.817494153976, "episode/length": 186.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 204856, "time": 6411.954176664352, "episode/length": 145.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9657534246575342, "episode/intrinsic_return": 0.0}
{"step": 204904, "time": 6413.957562208176, "episode/length": 163.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 205152, "time": 6421.301202774048, "episode/length": 150.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 205792, "time": 6438.098423242569, "episode/length": 207.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 205872, "time": 6440.967903614044, "episode/length": 219.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 205904, "time": 6442.635442495346, "episode/length": 182.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9617486338797814, "episode/intrinsic_return": 0.0}
{"step": 206168, "time": 6449.87690448761, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 206392, "time": 6456.318846940994, "episode/length": 154.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.0}
{"step": 206488, "time": 6459.468991994858, "episode/length": 197.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 206832, "time": 6469.255884885788, "episode/length": 246.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.979757085020243, "episode/intrinsic_return": 0.0}
{"step": 207056, "time": 6475.793217897415, "episode/length": 147.0, "episode/score": 4.099999964237213, "episode/reward_rate": 0.9527027027027027, "episode/intrinsic_return": 0.0}
{"step": 207200, "time": 6480.1285927295685, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 207216, "time": 6481.3639578819275, "episode/length": 177.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 207528, "time": 6489.870610237122, "episode/length": 141.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9647887323943662, "episode/intrinsic_return": 0.0}
{"step": 207648, "time": 6493.997260570526, "episode/length": 407.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9975490196078431, "episode/intrinsic_return": 0.0}
{"step": 208024, "time": 6504.032211065292, "episode/length": 191.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 208192, "time": 6509.215862989426, "episode/length": 169.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 208600, "time": 6520.200114250183, "episode/length": 192.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 208704, "time": 6523.799829006195, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 209136, "time": 6535.4003138542175, "episode/length": 53.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9259259259259259, "episode/intrinsic_return": 0.0}
{"step": 209152, "time": 6536.59502530098, "episode/length": 243.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9795081967213115, "episode/intrinsic_return": 0.0}
{"step": 209296, "time": 6541.0079073905945, "episode/length": 158.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 209352, "time": 6543.031527042389, "episode/length": 212.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9671361502347418, "episode/intrinsic_return": 0.0}
{"step": 209360, "time": 6544.290078163147, "episode/length": 228.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.982532751091703, "episode/intrinsic_return": 0.0}
{"step": 209408, "time": 6546.34965467453, "episode/length": 404.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 209544, "time": 6550.399553775787, "episode/length": 168.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9644970414201184, "episode/intrinsic_return": 0.0}
{"step": 210080, "time": 6568.029888153076, "eval_episode/length": 157.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9620253164556962}
{"step": 210080, "time": 6568.993350982666, "eval_episode/length": 162.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9570552147239264}
{"step": 210080, "time": 6569.0103640556335, "eval_episode/length": 162.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9693251533742331}
{"step": 210080, "time": 6570.019231081009, "eval_episode/length": 170.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9707602339181286}
{"step": 210080, "time": 6570.946342945099, "eval_episode/length": 174.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9657142857142857}
{"step": 210080, "time": 6572.015738725662, "eval_episode/length": 184.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9783783783783784}
{"step": 210080, "time": 6574.786746263504, "eval_episode/length": 254.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9764705882352941}
{"step": 210080, "time": 6575.917130470276, "eval_episode/length": 267.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9776119402985075}
{"step": 210456, "time": 6585.47235584259, "episode/length": 162.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 210576, "time": 6589.485248088837, "episode/length": 152.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 210824, "time": 6596.204074859619, "episode/length": 182.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 210848, "time": 6597.842846870422, "episode/length": 193.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 210920, "time": 6600.254052877426, "episode/length": 222.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9775784753363229, "episode/intrinsic_return": 0.0}
{"step": 210984, "time": 6602.816277742386, "episode/length": 297.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9832214765100671, "episode/intrinsic_return": 0.0}
{"step": 211088, "time": 6606.470546722412, "episode/length": 192.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9637305699481865, "episode/intrinsic_return": 0.0}
{"step": 211784, "time": 6624.353288650513, "episode/length": 150.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 211808, "time": 6625.913619995117, "episode/length": 168.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 211960, "time": 6630.328552246094, "episode/length": 318.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9905956112852664, "episode/intrinsic_return": 0.0}
{"step": 212144, "time": 6635.900637149811, "episode/length": 41.0, "episode/score": 2.100000023841858, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 212208, "time": 6638.350767612457, "episode/length": 169.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9647058823529412, "episode/intrinsic_return": 0.0}
{"step": 212240, "time": 6640.009608507156, "episode/length": 164.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 212336, "time": 6643.211057901382, "episode/length": 155.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 212352, "time": 6644.449769735336, "episode/length": 190.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 213096, "time": 6663.4114356040955, "episode/length": 163.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9634146341463414, "episode/intrinsic_return": 0.0}
{"step": 213232, "time": 6667.726995229721, "episode/length": 280.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.99644128113879, "episode/intrinsic_return": 0.0}
{"step": 213456, "time": 6674.067904472351, "episode/length": 186.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 213488, "time": 6675.708719968796, "episode/length": 155.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 213584, "time": 6678.940406322479, "episode/length": 171.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9651162790697675, "episode/intrinsic_return": 0.0}
{"step": 213616, "time": 6680.575341701508, "episode/length": 157.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 213952, "time": 6689.746580123901, "episode/length": 225.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9778761061946902, "episode/intrinsic_return": 0.0}
{"step": 213968, "time": 6691.0117955207825, "episode/length": 203.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 214312, "time": 6700.251602888107, "episode/length": 106.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9532710280373832, "episode/intrinsic_return": 0.0}
{"step": 214424, "time": 6703.846617937088, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.963855421686747, "episode/intrinsic_return": 0.0}
{"step": 214664, "time": 6710.720685720444, "episode/length": 178.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 215032, "time": 6720.912435531616, "episode/length": 192.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 215040, "time": 6722.143069028854, "episode/length": 181.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9835164835164835, "episode/intrinsic_return": 0.0}
{"step": 215184, "time": 6726.660323858261, "episode/length": 153.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 215400, "time": 6732.771480321884, "episode/length": 178.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 215448, "time": 6734.847285270691, "episode/length": 228.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9737991266375546, "episode/intrinsic_return": 0.0}
{"step": 215824, "time": 6745.259385585785, "episode/length": 144.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9586206896551724, "episode/intrinsic_return": 0.0}
{"step": 215848, "time": 6746.480946302414, "episode/length": 191.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 215856, "time": 6747.718926668167, "episode/length": 178.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9832402234636871, "episode/intrinsic_return": 0.0}
{"step": 216336, "time": 6760.5703728199005, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 216672, "time": 6769.774661064148, "episode/length": 158.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 216816, "time": 6774.176236629486, "episode/length": 221.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 217000, "time": 6779.489630460739, "episode/length": 40.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 217120, "time": 6783.453515529633, "episode/length": 37.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 217176, "time": 6785.468663692474, "episode/length": 248.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9799196787148594, "episode/intrinsic_return": 0.0}
{"step": 217216, "time": 6787.515117883682, "episode/length": 220.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9683257918552036, "episode/intrinsic_return": 0.0}
{"step": 217496, "time": 6795.069808721542, "episode/length": 144.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 217536, "time": 6797.105916500092, "episode/length": 209.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 217568, "time": 6798.806493282318, "episode/length": 214.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.986046511627907, "episode/intrinsic_return": 0.0}
{"step": 217664, "time": 6801.9901032447815, "episode/length": 229.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 218432, "time": 6821.925754308701, "episode/length": 178.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 218520, "time": 6824.832699775696, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 218808, "time": 6832.811750650406, "episode/length": 158.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 218832, "time": 6834.40754699707, "episode/length": 166.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 219000, "time": 6839.238396406174, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 219264, "time": 6846.732387065887, "episode/length": 255.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.98046875, "episode/intrinsic_return": 0.0}
{"step": 219344, "time": 6849.6303169727325, "episode/length": 221.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9819819819819819, "episode/intrinsic_return": 0.0}
{"step": 219504, "time": 6854.513548612595, "episode/length": 290.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9862542955326461, "episode/intrinsic_return": 0.0}
{"step": 219824, "time": 6863.323848247528, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 219824, "time": 6863.342589139938, "episode/length": 173.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 220064, "time": 6873.270181179047, "eval_episode/length": 153.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.961038961038961}
{"step": 220064, "time": 6874.475580215454, "eval_episode/length": 172.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9710982658959537}
{"step": 220064, "time": 6875.394813776016, "eval_episode/length": 175.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9829545454545454}
{"step": 220064, "time": 6876.300648450851, "eval_episode/length": 176.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9717514124293786}
{"step": 220064, "time": 6877.401731967926, "eval_episode/length": 188.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9735449735449735}
{"step": 220064, "time": 6878.626391649246, "eval_episode/length": 209.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9952380952380953}
{"step": 220064, "time": 6879.59943318367, "eval_episode/length": 216.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9723502304147466}
{"step": 220064, "time": 6880.651477575302, "eval_episode/length": 227.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 220128, "time": 6882.485074996948, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 220312, "time": 6887.615572452545, "episode/length": 163.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 220472, "time": 6892.372817516327, "episode/length": 207.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 220696, "time": 6898.935972452164, "episode/length": 178.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 220728, "time": 6900.546182632446, "episode/length": 152.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 220808, "time": 6903.404594421387, "episode/length": 182.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 221080, "time": 6910.957377195358, "episode/length": 156.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 221752, "time": 6928.502428531647, "episode/length": 240.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.979253112033195, "episode/intrinsic_return": 0.0}
{"step": 221768, "time": 6929.796701192856, "episode/length": 181.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9835164835164835, "episode/intrinsic_return": 0.0}
{"step": 221856, "time": 6933.088280916214, "episode/length": 172.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 221984, "time": 6937.075068235397, "episode/length": 160.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 222016, "time": 6938.722057342529, "episode/length": 235.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 222064, "time": 6940.7534992694855, "episode/length": 166.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 222136, "time": 6943.257595539093, "episode/length": 165.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 222312, "time": 6948.526008844376, "episode/length": 153.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9805194805194806, "episode/intrinsic_return": 0.0}
{"step": 223056, "time": 6968.141729593277, "episode/length": 149.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 223416, "time": 6977.765330076218, "episode/length": 178.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 223448, "time": 6979.418232679367, "episode/length": 163.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 223528, "time": 6982.226632595062, "episode/length": 182.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 223544, "time": 6983.465538263321, "episode/length": 153.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9545454545454546, "episode/intrinsic_return": 0.0}
{"step": 223648, "time": 6987.035274267197, "episode/length": 234.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 223712, "time": 6989.529703617096, "episode/length": 211.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 223960, "time": 6996.685153007507, "episode/length": 275.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9818840579710145, "episode/intrinsic_return": 0.0}
{"step": 224840, "time": 7020.301015377045, "episode/length": 173.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 224984, "time": 7024.94825387001, "episode/length": 179.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 225016, "time": 7026.559106826782, "episode/length": 185.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.0}
{"step": 225080, "time": 7028.974920034409, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9590643274853801, "episode/intrinsic_return": 0.0}
{"step": 225256, "time": 7034.169029951096, "episode/length": 200.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 225456, "time": 7040.169771671295, "episode/length": 299.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9866666666666667, "episode/intrinsic_return": 0.0}
{"step": 225552, "time": 7043.410776615143, "episode/length": 198.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9798994974874372, "episode/intrinsic_return": 0.0}
{"step": 225880, "time": 7052.2754778862, "episode/length": 307.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9837662337662337, "episode/intrinsic_return": 0.0}
{"step": 226080, "time": 7058.219915390015, "episode/length": 154.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 226384, "time": 7066.683811426163, "episode/length": 162.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 226416, "time": 7068.34149646759, "episode/length": 178.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 226776, "time": 7077.91685295105, "episode/length": 189.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 226816, "time": 7079.959411859512, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9647058823529412, "episode/intrinsic_return": 0.0}
{"step": 227256, "time": 7091.5128536224365, "episode/length": 279.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 227392, "time": 7095.825070858002, "episode/length": 163.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9573170731707317, "episode/intrinsic_return": 0.0}
{"step": 227456, "time": 7098.254440307617, "episode/length": 196.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 227744, "time": 7106.346477031708, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 227792, "time": 7108.381241321564, "episode/length": 175.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 227808, "time": 7109.63827586174, "episode/length": 281.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9822695035460993, "episode/intrinsic_return": 0.0}
{"step": 228072, "time": 7116.768946886063, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 228168, "time": 7120.025362253189, "episode/length": 168.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 228873, "time": 7139.375953197479, "train_stats/sum_log_reward": 4.873255760170693, "train_stats/max_log_achievement_collect_drink": 4.034883720930233, "train_stats/max_log_achievement_collect_sapling": 2.7093023255813953, "train_stats/max_log_achievement_collect_wood": 5.151162790697675, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.4418604651162791, "train_stats/max_log_achievement_eat_cow": 0.06976744186046512, "train_stats/max_log_achievement_make_wood_pickaxe": 0.023255813953488372, "train_stats/max_log_achievement_make_wood_sword": 0.03488372093023256, "train_stats/max_log_achievement_place_plant": 2.4244186046511627, "train_stats/max_log_achievement_place_table": 2.127906976744186, "train_stats/max_log_achievement_wake_up": 1.9069767441860466, "train_stats/mean_log_entropy": 0.5112521379839542, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 3.9632029463605183, "train/action_min": 0.0, "train/action_std": 2.7417952537536623, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04360774792730808, "train/actor_opt_grad_steps": 13180.0, "train/actor_opt_loss": 1.5548754645193494, "train/adv_mag": 0.7154145163733785, "train/adv_max": 0.7072246795747338, "train/adv_mean": 0.004360498292350335, "train/adv_min": -0.4593072231222944, "train/adv_std": 0.07360750576708375, "train/cont_avg": 0.9944455030487804, "train/cont_loss_mean": 0.00029891800641191767, "train/cont_loss_std": 0.008456111949961757, "train/cont_neg_acc": 0.9865118093606903, "train/cont_neg_loss": 0.03886818200612097, "train/cont_pos_acc": 0.9999808043968387, "train/cont_pos_loss": 0.00010083981209511879, "train/cont_pred": 0.9944537601819853, "train/cont_rate": 0.9944455030487804, "train/dyn_loss_mean": 13.937890843647283, "train/dyn_loss_std": 9.352641403384325, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9685398401283636, "train/extr_critic_critic_opt_grad_steps": 13180.0, "train/extr_critic_critic_opt_loss": 15119.03799542683, "train/extr_critic_mag": 3.9430397336075944, "train/extr_critic_max": 3.9430397336075944, "train/extr_critic_mean": 0.8304952656350485, "train/extr_critic_min": -0.2723175915276132, "train/extr_critic_std": 1.0209495096671872, "train/extr_return_normed_mag": 1.7816636475121104, "train/extr_return_normed_max": 1.7816636475121104, "train/extr_return_normed_mean": 0.31458272323375797, "train/extr_return_normed_min": -0.1466989977512418, "train/extr_return_normed_std": 0.34367589986905817, "train/extr_return_rate": 0.44592418423513086, "train/extr_return_raw_mag": 5.361404309621672, "train/extr_return_raw_max": 5.361404309621672, "train/extr_return_raw_mean": 0.843952068032288, "train/extr_return_raw_min": -0.5755580903553381, "train/extr_return_raw_std": 1.0584753295270408, "train/extr_reward_mag": 1.0081034183502198, "train/extr_reward_max": 1.0081034183502198, "train/extr_reward_mean": 0.020059517241741827, "train/extr_reward_min": -0.3247367725139711, "train/extr_reward_std": 0.12990933242367536, "train/image_loss_mean": 10.502444595243873, "train/image_loss_std": 13.569436259386016, "train/model_loss_mean": 18.916552901849514, "train/model_loss_std": 17.550678322954877, "train/model_opt_grad_norm": 69.97332589684463, "train/model_opt_grad_steps": 13164.985365853658, "train/model_opt_loss": 15160.249480754574, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 801.829268292683, "train/policy_entropy_mag": 2.389892330402281, "train/policy_entropy_max": 2.389892330402281, "train/policy_entropy_mean": 0.6021333415333817, "train/policy_entropy_min": 0.07937571820689411, "train/policy_entropy_std": 0.5377252811338843, "train/policy_logprob_mag": 7.438374884535627, "train/policy_logprob_max": -0.009455912941839636, "train/policy_logprob_mean": -0.6019127329675162, "train/policy_logprob_min": -7.438374884535627, "train/policy_logprob_std": 1.1045879230266664, "train/policy_randomness_mag": 0.843527117589625, "train/policy_randomness_max": 0.843527117589625, "train/policy_randomness_mean": 0.21252664698333276, "train/policy_randomness_min": 0.028016145245694533, "train/policy_randomness_std": 0.1897934270341222, "train/post_ent_mag": 55.49716547524057, "train/post_ent_max": 55.49716547524057, "train/post_ent_mean": 38.16371532533227, "train/post_ent_min": 20.935781985957448, "train/post_ent_std": 6.390534121815751, "train/prior_ent_mag": 64.7621050392709, "train/prior_ent_max": 64.7621050392709, "train/prior_ent_mean": 52.27750798667349, "train/prior_ent_min": 29.76313964099419, "train/prior_ent_std": 6.253519355960009, "train/rep_loss_mean": 13.937890843647283, "train/rep_loss_std": 9.352641403384325, "train/reward_avg": 0.018049256796607883, "train/reward_loss_mean": 0.051074978336691855, "train/reward_loss_std": 0.256328829541439, "train/reward_max_data": 1.0107317098757116, "train/reward_max_pred": 1.003125077340661, "train/reward_neg_acc": 0.9939807194035227, "train/reward_neg_loss": 0.029894994962506177, "train/reward_pos_acc": 0.9496570421428215, "train/reward_pos_loss": 0.950121176824337, "train/reward_pred": 0.017189829671619142, "train/reward_rate": 0.02302782012195122, "eval_stats/sum_log_reward": 4.891666596134503, "eval_stats/max_log_achievement_collect_drink": 5.375, "eval_stats/max_log_achievement_collect_sapling": 3.125, "eval_stats/max_log_achievement_collect_wood": 5.458333333333333, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.5, "eval_stats/max_log_achievement_eat_cow": 0.08333333333333333, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.5416666666666665, "eval_stats/max_log_achievement_place_table": 2.0833333333333335, "eval_stats/max_log_achievement_wake_up": 1.7916666666666667, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 3.4054530715366127e-06, "report/cont_loss_std": 4.7729281504871324e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0004962798557244241, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 1.3003915277920441e-08, "report/cont_pred": 0.9931674003601074, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 13.494668960571289, "report/dyn_loss_std": 9.526921272277832, "report/image_loss_mean": 9.357854843139648, "report/image_loss_std": 11.50001335144043, "report/model_loss_mean": 17.504907608032227, "report/model_loss_std": 15.938899993896484, "report/post_ent_mag": 56.22821807861328, "report/post_ent_max": 56.22821807861328, "report/post_ent_mean": 37.92667770385742, "report/post_ent_min": 17.750743865966797, "report/post_ent_std": 6.26051664352417, "report/prior_ent_mag": 64.5775375366211, "report/prior_ent_max": 64.5775375366211, "report/prior_ent_mean": 51.35111999511719, "report/prior_ent_min": 31.201580047607422, "report/prior_ent_std": 6.355411529541016, "report/rep_loss_mean": 13.494668960571289, "report/rep_loss_std": 9.526921272277832, "report/reward_avg": 0.02060546725988388, "report/reward_loss_mean": 0.0502493754029274, "report/reward_loss_std": 0.18083161115646362, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0079782009124756, "report/reward_neg_acc": 0.99698805809021, "report/reward_neg_loss": 0.03078651800751686, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7425709366798401, "report/reward_pred": 0.020106863230466843, "report/reward_rate": 0.02734375, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.0005261901533231139, "eval/cont_loss_std": 0.011814350262284279, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.002909435424953699, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.000512143480591476, "eval/cont_pred": 0.9937121272087097, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 13.535513877868652, "eval/dyn_loss_std": 7.976267337799072, "eval/image_loss_mean": 7.048287391662598, "eval/image_loss_std": 8.961377143859863, "eval/model_loss_mean": 15.241437911987305, "eval/model_loss_std": 12.202370643615723, "eval/post_ent_mag": 52.64714050292969, "eval/post_ent_max": 52.64714050292969, "eval/post_ent_mean": 38.738853454589844, "eval/post_ent_min": 16.394954681396484, "eval/post_ent_std": 5.017481327056885, "eval/prior_ent_mag": 64.5775375366211, "eval/prior_ent_max": 64.5775375366211, "eval/prior_ent_mean": 49.44059371948242, "eval/prior_ent_min": 31.273757934570312, "eval/prior_ent_std": 4.365642070770264, "eval/rep_loss_mean": 13.535513877868652, "eval/rep_loss_std": 7.976267337799072, "eval/reward_avg": 0.01396484300494194, "eval/reward_loss_mean": 0.07131584733724594, "eval/reward_loss_std": 0.6266390085220337, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9980405569076538, "eval/reward_neg_acc": 0.9990060329437256, "eval/reward_neg_loss": 0.016409719362854958, "eval/reward_pos_acc": 0.6111111044883728, "eval/reward_pos_loss": 3.139958381652832, "eval/reward_pred": 0.005928749684244394, "eval/reward_rate": 0.017578125, "replay/size": 228369.0, "replay/inserts": 32896.0, "replay/samples": 32896.0, "replay/insert_wait_avg": 1.2240695118440265e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 5.631928661917898e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 44120.0, "eval_replay/inserts": 5768.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1979624236340992e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.301568984985352e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3688790798187, "timer/env.step_count": 4112.0, "timer/env.step_total": 156.78506779670715, "timer/env.step_frac": 0.15672725439132476, "timer/env.step_avg": 0.038128664347448236, "timer/env.step_min": 0.0022995471954345703, "timer/env.step_max": 0.9396440982818604, "timer/replay._sample_count": 32896.0, "timer/replay._sample_total": 2913.147624015808, "timer/replay._sample_frac": 2.9120734210518857, "timer/replay._sample_avg": 0.08855628720865176, "timer/replay._sample_min": 0.00043272972106933594, "timer/replay._sample_max": 0.11926937103271484, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4833.0, "timer/agent.policy_total": 48.90596628189087, "timer/agent.policy_frac": 0.048887932546318943, "timer/agent.policy_avg": 0.010119173656505456, "timer/agent.policy_min": 0.007649421691894531, "timer/agent.policy_max": 0.5992491245269775, "timer/dataset_train_count": 2056.0, "timer/dataset_train_total": 0.1627960205078125, "timer/dataset_train_frac": 0.0001627359906053446, "timer/dataset_train_avg": 7.918094382675705e-05, "timer/dataset_train_min": 6.127357482910156e-05, "timer/dataset_train_max": 0.00017881393432617188, "timer/agent.train_count": 2056.0, "timer/agent.train_total": 761.6096177101135, "timer/agent.train_frac": 0.7613287794505104, "timer/agent.train_avg": 0.37043269343877117, "timer/agent.train_min": 0.34799933433532715, "timer/agent.train_max": 0.5862410068511963, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.40802550315856934, "timer/agent.report_frac": 0.0004078750465867034, "timer/agent.report_avg": 0.20401275157928467, "timer/agent.report_min": 0.2038121223449707, "timer/agent.report_max": 0.20421338081359863, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.457069396972656e-05, "timer/dataset_eval_frac": 3.4557946266307423e-08, "timer/dataset_eval_avg": 3.457069396972656e-05, "timer/dataset_eval_min": 3.457069396972656e-05, "timer/dataset_eval_max": 3.457069396972656e-05, "fps": 32.883499813166594}
{"step": 228888, "time": 7139.405722141266, "episode/length": 186.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 228904, "time": 7142.450471162796, "episode/length": 205.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 228968, "time": 7144.9516723155975, "episode/length": 188.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 229104, "time": 7149.282678365707, "episode/length": 169.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9647058823529412, "episode/intrinsic_return": 0.0}
{"step": 229144, "time": 7150.93868470192, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 229632, "time": 7163.957247495651, "episode/length": 194.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 229768, "time": 7167.899085044861, "episode/length": 199.0, "episode/score": 6.100000016391277, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 229888, "time": 7172.094772100449, "episode/length": 261.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9961832061068703, "episode/intrinsic_return": 0.0}
{"step": 230048, "time": 7178.4103100299835, "eval_episode/length": 33.0, "eval_episode/score": 1.0999999716877937, "eval_episode/reward_rate": 0.9705882352941176}
{"step": 230048, "time": 7180.990250587463, "eval_episode/length": 133.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9626865671641791}
{"step": 230048, "time": 7182.61085152626, "eval_episode/length": 176.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9717514124293786}
{"step": 230048, "time": 7183.777690410614, "eval_episode/length": 193.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9690721649484536}
{"step": 230048, "time": 7184.765984535217, "eval_episode/length": 200.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9751243781094527}
{"step": 230048, "time": 7185.7881009578705, "eval_episode/length": 172.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9710982658959537}
{"step": 230048, "time": 7186.937378406525, "eval_episode/length": 220.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9773755656108597}
{"step": 230048, "time": 7187.975923061371, "eval_episode/length": 233.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9829059829059829}
{"step": 230200, "time": 7191.725106239319, "episode/length": 136.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9927007299270073, "episode/intrinsic_return": 0.0}
{"step": 230208, "time": 7192.955011606216, "episode/length": 162.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 230328, "time": 7196.710822105408, "episode/length": 169.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 230704, "time": 7207.1147401332855, "episode/length": 46.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 231000, "time": 7215.146252155304, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 231008, "time": 7216.359185695648, "episode/length": 100.0, "episode/score": 4.099999964237213, "episode/reward_rate": 0.9405940594059405, "episode/intrinsic_return": 0.0}
{"step": 231088, "time": 7219.172851800919, "episode/length": 242.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9794238683127572, "episode/intrinsic_return": 0.0}
{"step": 231224, "time": 7223.177485942841, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 231296, "time": 7225.983182191849, "episode/length": 175.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 231528, "time": 7232.585494279861, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 231656, "time": 7236.587454080582, "episode/length": 44.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 232168, "time": 7250.188700199127, "episode/length": 409.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 232256, "time": 7253.45955991745, "episode/length": 155.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 232280, "time": 7254.693467378616, "episode/length": 148.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 232288, "time": 7255.945777654648, "episode/length": 197.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9646464646464646, "episode/intrinsic_return": 0.0}
{"step": 232384, "time": 7259.099927186966, "episode/length": 172.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 232560, "time": 7264.293813705444, "episode/length": 166.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 233136, "time": 7279.539031505585, "episode/length": 184.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 233184, "time": 7281.547163724899, "episode/length": 206.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 233488, "time": 7289.799132823944, "episode/length": 37.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 233608, "time": 7293.411769866943, "episode/length": 152.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9738562091503268, "episode/intrinsic_return": 0.0}
{"step": 233744, "time": 7297.738626003265, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 233880, "time": 7301.7463529109955, "episode/length": 213.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 234160, "time": 7309.692227363586, "episode/length": 233.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9871794871794872, "episode/intrinsic_return": 0.0}
{"step": 234272, "time": 7313.259212970734, "episode/length": 213.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 234736, "time": 7325.547437667847, "episode/length": 199.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 234880, "time": 7329.990581274033, "episode/length": 173.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 235176, "time": 7337.916450977325, "episode/length": 195.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 235224, "time": 7339.954447746277, "episode/length": 167.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 235424, "time": 7346.074788808823, "episode/length": 392.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9770992366412213, "episode/intrinsic_return": 0.0}
{"step": 235560, "time": 7350.086152791977, "episode/length": 226.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9779735682819384, "episode/intrinsic_return": 0.0}
{"step": 235704, "time": 7354.593543767929, "episode/length": 192.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9689119170984456, "episode/intrinsic_return": 0.0}
{"step": 236344, "time": 7371.404628038406, "episode/length": 258.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9806949806949807, "episode/intrinsic_return": 0.0}
{"step": 236528, "time": 7376.922840595245, "episode/length": 223.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 236536, "time": 7377.813489198685, "episode/length": 206.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.966183574879227, "episode/intrinsic_return": 0.0}
{"step": 236712, "time": 7383.100836992264, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 236840, "time": 7387.241283655167, "episode/length": 207.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 236928, "time": 7390.4557156562805, "episode/length": 152.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 237080, "time": 7394.96043753624, "episode/length": 206.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.966183574879227, "episode/intrinsic_return": 0.0}
{"step": 237128, "time": 7396.93256187439, "episode/length": 195.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 237424, "time": 7405.430130720139, "episode/length": 36.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 237608, "time": 7410.639787435532, "episode/length": 157.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9556962025316456, "episode/intrinsic_return": 0.0}
{"step": 238096, "time": 7423.811561346054, "episode/length": 156.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 238400, "time": 7432.1228120327, "episode/length": 232.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9828326180257511, "episode/intrinsic_return": 0.0}
{"step": 238464, "time": 7434.601294994354, "episode/length": 191.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 238592, "time": 7438.570339202881, "episode/length": 234.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 238968, "time": 7448.662182807922, "episode/length": 192.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 239000, "time": 7450.361342668533, "episode/length": 308.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9967637540453075, "episode/intrinsic_return": 0.0}
{"step": 239072, "time": 7453.190150737762, "episode/length": 248.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9839357429718876, "episode/intrinsic_return": 0.0}
{"step": 239592, "time": 7466.834477901459, "episode/length": 186.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 239688, "time": 7470.055339336395, "episode/length": 136.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9927007299270073, "episode/intrinsic_return": 0.0}
{"step": 239832, "time": 7474.433966398239, "episode/length": 170.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 240032, "time": 7483.750617742538, "eval_episode/length": 159.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.975}
{"step": 240032, "time": 7484.87890124321, "eval_episode/length": 177.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9719101123595506}
{"step": 240032, "time": 7485.757212877274, "eval_episode/length": 178.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9720670391061452}
{"step": 240032, "time": 7486.6402378082275, "eval_episode/length": 180.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9723756906077348}
{"step": 240032, "time": 7487.508437156677, "eval_episode/length": 181.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.978021978021978}
{"step": 240032, "time": 7488.867137908936, "eval_episode/length": 209.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9761904761904762}
{"step": 240032, "time": 7489.759661197662, "eval_episode/length": 212.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9765258215962441}
{"step": 240032, "time": 7490.657360076904, "eval_episode/length": 35.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 240120, "time": 7492.960221529007, "episode/length": 214.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 240144, "time": 7494.549560308456, "episode/length": 316.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9905362776025236, "episode/intrinsic_return": 0.0}
{"step": 240360, "time": 7500.663480997086, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 240768, "time": 7511.917835712433, "episode/length": 211.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 240992, "time": 7518.278801441193, "episode/length": 174.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 241200, "time": 7524.268569231033, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9649122807017544, "episode/intrinsic_return": 0.0}
{"step": 241216, "time": 7525.491316318512, "episode/length": 190.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9581151832460733, "episode/intrinsic_return": 0.0}
{"step": 241264, "time": 7527.525661230087, "episode/length": 286.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9790940766550522, "episode/intrinsic_return": 0.0}
{"step": 241520, "time": 7534.788570165634, "episode/length": 174.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 241832, "time": 7543.3804523944855, "episode/length": 210.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 241968, "time": 7547.753991127014, "episode/length": 200.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9701492537313433, "episode/intrinsic_return": 0.0}
{"step": 242088, "time": 7551.337442874908, "episode/length": 164.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 242288, "time": 7557.517090797424, "episode/length": 161.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 242568, "time": 7565.095978975296, "episode/length": 168.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9822485207100592, "episode/intrinsic_return": 0.0}
{"step": 242848, "time": 7573.156322002411, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 242920, "time": 7575.618938922882, "episode/length": 214.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9720930232558139, "episode/intrinsic_return": 0.0}
{"step": 242944, "time": 7577.227251052856, "episode/length": 209.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 243296, "time": 7586.767919063568, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 243624, "time": 7595.522532939911, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 243664, "time": 7597.569455385208, "episode/length": 196.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 243728, "time": 7600.072239160538, "episode/length": 144.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 243968, "time": 7606.903888463974, "episode/length": 266.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9850187265917603, "episode/intrinsic_return": 0.0}
{"step": 244048, "time": 7609.67259645462, "episode/length": 39.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 244712, "time": 7626.758524417877, "episode/length": 176.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 244816, "time": 7630.3894193172455, "episode/length": 233.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9786324786324786, "episode/intrinsic_return": 0.0}
{"step": 244896, "time": 7633.277402877808, "episode/length": 115.0, "episode/score": 4.100000023841858, "episode/reward_rate": 0.9913793103448276, "episode/intrinsic_return": 0.0}
{"step": 244936, "time": 7635.012945652008, "episode/length": 260.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 245112, "time": 7640.180988550186, "episode/length": 185.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9623655913978495, "episode/intrinsic_return": 0.0}
{"step": 245160, "time": 7642.194020748138, "episode/length": 186.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 245448, "time": 7650.2001304626465, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 245744, "time": 7658.713876724243, "episode/length": 36.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 246192, "time": 7670.623256444931, "episode/length": 161.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 246216, "time": 7671.83251786232, "episode/length": 174.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9657142857142857, "episode/intrinsic_return": 0.0}
{"step": 246304, "time": 7675.214980602264, "episode/length": 422.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 246336, "time": 7676.9183876514435, "episode/length": 202.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 246344, "time": 7677.841058969498, "episode/length": 175.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 246424, "time": 7680.897909879684, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 246472, "time": 7682.957591056824, "episode/length": 90.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9340659340659341, "episode/intrinsic_return": 0.0}
{"step": 246552, "time": 7685.751639127731, "episode/length": 179.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 247432, "time": 7708.609112739563, "episode/length": 151.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 247584, "time": 7713.481912136078, "episode/length": 173.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 247584, "time": 7713.50207567215, "episode/length": 159.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 247768, "time": 7718.806924343109, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 247888, "time": 7722.922174453735, "episode/length": 176.0, "episode/score": 4.100000023841858, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 248144, "time": 7730.342118263245, "episode/length": 214.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 248160, "time": 7731.600661277771, "episode/length": 227.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 248384, "time": 7738.033329248428, "episode/length": 228.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9737991266375546, "episode/intrinsic_return": 0.0}
{"step": 248920, "time": 7751.988831520081, "episode/length": 166.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9640718562874252, "episode/intrinsic_return": 0.0}
{"step": 249136, "time": 7758.4313452243805, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 249216, "time": 7761.182524681091, "episode/length": 203.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 249248, "time": 7762.833165407181, "episode/length": 169.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9823529411764705, "episode/intrinsic_return": 0.0}
{"step": 249616, "time": 7772.616744041443, "episode/length": 272.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9963369963369964, "episode/intrinsic_return": 0.0}
{"step": 249688, "time": 7775.078424453735, "episode/length": 190.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 249968, "time": 7782.986427783966, "episode/length": 197.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 250016, "time": 7788.6392827034, "eval_episode/length": 170.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9941520467836257}
{"step": 250016, "time": 7789.563813924789, "eval_episode/length": 175.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9659090909090909}
{"step": 250016, "time": 7790.481422901154, "eval_episode/length": 179.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 250016, "time": 7791.394709587097, "eval_episode/length": 183.0, "eval_episode/score": 6.099999964237213, "eval_episode/reward_rate": 0.9728260869565217}
{"step": 250016, "time": 7792.323691368103, "eval_episode/length": 190.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9790575916230366}
{"step": 250016, "time": 7793.342222213745, "eval_episode/length": 197.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9646464646464646}
{"step": 250016, "time": 7794.285776615143, "eval_episode/length": 203.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9803921568627451}
{"step": 250016, "time": 7795.371088504791, "eval_episode/length": 210.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9715639810426541}
{"step": 250352, "time": 7803.739228487015, "episode/length": 178.0, "episode/score": 6.1000000312924385, "episode/reward_rate": 0.9608938547486033, "episode/intrinsic_return": 0.0}
{"step": 250584, "time": 7810.183130264282, "episode/length": 180.0, "episode/score": 6.100000016391277, "episode/reward_rate": 0.9834254143646409, "episode/intrinsic_return": 0.0}
{"step": 250600, "time": 7811.412183046341, "episode/length": 168.0, "episode/score": 6.100000016391277, "episode/reward_rate": 0.9822485207100592, "episode/intrinsic_return": 0.0}
{"step": 250744, "time": 7815.86953163147, "episode/length": 190.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 250744, "time": 7815.89127779007, "episode/length": 48.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 251128, "time": 7826.420920848846, "episode/length": 188.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 251680, "time": 7841.0149538517, "episode/length": 248.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9799196787148594, "episode/intrinsic_return": 0.0}
{"step": 251808, "time": 7845.14194726944, "episode/length": 152.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9738562091503268, "episode/intrinsic_return": 0.0}
{"step": 251912, "time": 7848.37229514122, "episode/length": 145.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 252048, "time": 7852.809236764908, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9631901840490797, "episode/intrinsic_return": 0.0}
{"step": 252088, "time": 7854.472900867462, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 252168, "time": 7857.301728487015, "episode/length": 502.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9900596421471173, "episode/intrinsic_return": 0.0}
{"step": 252208, "time": 7859.332443237305, "episode/length": 279.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9892857142857143, "episode/intrinsic_return": 0.0}
{"step": 252760, "time": 7873.943737983704, "episode/length": 203.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 253120, "time": 7883.997186422348, "episode/length": 163.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 253160, "time": 7885.632392406464, "episode/length": 184.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 253296, "time": 7890.217205286026, "episode/length": 172.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9653179190751445, "episode/intrinsic_return": 0.0}
{"step": 253368, "time": 7892.682910442352, "episode/length": 159.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 253400, "time": 7894.347059726715, "episode/length": 168.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 253504, "time": 7897.931606292725, "episode/length": 166.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 254032, "time": 7912.093234062195, "episode/length": 227.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9780701754385965, "episode/intrinsic_return": 0.0}
{"step": 254144, "time": 7915.717979192734, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 254456, "time": 7924.064489126205, "episode/length": 166.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 254832, "time": 7934.405517339706, "episode/length": 165.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 254896, "time": 7936.806329965591, "episode/length": 216.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9723502304147466, "episode/intrinsic_return": 0.0}
{"step": 255120, "time": 7943.184299230576, "episode/length": 218.0, "episode/score": 6.100000016391277, "episode/reward_rate": 0.9863013698630136, "episode/intrinsic_return": 0.0}
{"step": 255248, "time": 7947.279701709747, "episode/length": 243.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 255296, "time": 7949.330356121063, "episode/length": 236.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9704641350210971, "episode/intrinsic_return": 0.0}
{"step": 255544, "time": 7956.150193691254, "episode/length": 188.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 255776, "time": 7962.955986738205, "episode/length": 203.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9852941176470589, "episode/intrinsic_return": 0.0}
{"step": 256240, "time": 7975.210154294968, "episode/length": 175.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 256408, "time": 7979.998397350311, "episode/length": 243.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 256512, "time": 7983.660091876984, "episode/length": 173.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 256744, "time": 7990.041349172592, "episode/length": 180.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 256912, "time": 7995.162382364273, "episode/length": 49.0, "episode/score": 3.100000023841858, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 256960, "time": 7997.188263893127, "episode/length": 257.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 257168, "time": 8003.265871524811, "episode/length": 202.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9802955665024631, "episode/intrinsic_return": 0.0}
{"step": 257192, "time": 8004.499691724777, "episode/length": 242.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9958847736625515, "episode/intrinsic_return": 0.0}
{"step": 257368, "time": 8009.6757798194885, "episode/length": 50.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 257552, "time": 8015.191441059113, "episode/length": 163.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 257864, "time": 8023.574780702591, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.967032967032967, "episode/intrinsic_return": 0.0}
{"step": 257896, "time": 8025.197639942169, "episode/length": 264.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 258240, "time": 8034.703183889389, "episode/length": 42.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 258296, "time": 8036.751130580902, "episode/length": 193.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 258504, "time": 8042.857327222824, "episode/length": 166.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9580838323353293, "episode/intrinsic_return": 0.0}
{"step": 258528, "time": 8044.526584148407, "episode/length": 201.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9653465346534653, "episode/intrinsic_return": 0.0}
{"step": 258560, "time": 8046.2127776145935, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 258880, "time": 8055.091737508774, "episode/length": 39.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 259080, "time": 8060.744386911392, "episode/length": 190.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9685863874345549, "episode/intrinsic_return": 0.0}
{"step": 259096, "time": 8061.969079256058, "episode/length": 215.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 259112, "time": 8063.186489343643, "episode/length": 28.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.8620689655172413, "episode/intrinsic_return": 0.0}
{"step": 259384, "time": 8070.891909599304, "episode/length": 35.0, "episode/score": -0.9000000283122063, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 259472, "time": 8074.131263256073, "episode/length": 200.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9800995024875622, "episode/intrinsic_return": 0.0}
{"step": 259632, "time": 8079.006939411163, "episode/length": 173.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9597701149425287, "episode/intrinsic_return": 0.0}
{"step": 259752, "time": 8082.6359322071075, "episode/length": 181.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 260000, "time": 8091.670868396759, "eval_episode/length": 41.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9761904761904762}
{"step": 260000, "time": 8094.613845348358, "eval_episode/length": 166.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9820359281437125}
{"step": 260000, "time": 8095.5248301029205, "eval_episode/length": 171.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9709302325581395}
{"step": 260000, "time": 8096.3786680698395, "eval_episode/length": 172.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9710982658959537}
{"step": 260000, "time": 8097.414850473404, "eval_episode/length": 182.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.994535519125683}
{"step": 260000, "time": 8098.4041357040405, "eval_episode/length": 191.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9739583333333334}
{"step": 260000, "time": 8099.67969083786, "eval_episode/length": 214.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9720930232558139}
{"step": 260000, "time": 8100.590222835541, "eval_episode/length": 178.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9664804469273743}
{"step": 260424, "time": 8111.159072399139, "episode/length": 236.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9789029535864979, "episode/intrinsic_return": 0.0}
{"step": 260528, "time": 8114.783613920212, "episode/length": 252.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9960474308300395, "episode/intrinsic_return": 0.0}
{"step": 260544, "time": 8115.954562425613, "episode/length": 144.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 260760, "time": 8121.951109886169, "episode/length": 205.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9805825242718447, "episode/intrinsic_return": 0.0}
{"step": 260776, "time": 8123.147468805313, "episode/length": 142.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 260800, "time": 8124.825755596161, "episode/length": 214.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 261168, "time": 8134.8505210876465, "episode/length": 176.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 261305, "time": 8139.731235265732, "train_stats/sum_log_reward": 5.003409037874504, "train_stats/max_log_achievement_collect_drink": 3.9204545454545454, "train_stats/max_log_achievement_collect_sapling": 2.4886363636363638, "train_stats/max_log_achievement_collect_wood": 6.670454545454546, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.4318181818181818, "train_stats/max_log_achievement_eat_cow": 0.09659090909090909, "train_stats/max_log_achievement_make_wood_pickaxe": 0.011363636363636364, "train_stats/max_log_achievement_make_wood_sword": 0.028409090909090908, "train_stats/max_log_achievement_place_plant": 2.2954545454545454, "train_stats/max_log_achievement_place_table": 2.659090909090909, "train_stats/max_log_achievement_wake_up": 1.8295454545454546, "train_stats/mean_log_entropy": 0.5206351913511753, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 3.9627279648052647, "train/action_min": 0.0, "train/action_std": 2.8021982796673703, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04376849683524646, "train/actor_opt_grad_steps": 15220.0, "train/actor_opt_loss": 0.38705923936783976, "train/adv_mag": 0.7094805294950607, "train/adv_max": 0.6973089756343165, "train/adv_mean": 0.00466397582535621, "train/adv_min": -0.4746353477973656, "train/adv_std": 0.07200430742845747, "train/cont_avg": 0.9947034713669951, "train/cont_loss_mean": 0.00031071081648383704, "train/cont_loss_std": 0.008763278756970546, "train/cont_neg_acc": 0.9896141220196127, "train/cont_neg_loss": 0.03241732307136819, "train/cont_pos_acc": 0.9999612972066907, "train/cont_pos_loss": 0.0001314925210946345, "train/cont_pred": 0.9947029469635686, "train/cont_rate": 0.9947034713669951, "train/dyn_loss_mean": 14.256946963042461, "train/dyn_loss_std": 9.441468511308942, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9202094307086738, "train/extr_critic_critic_opt_grad_steps": 15220.0, "train/extr_critic_critic_opt_loss": 15319.095481834975, "train/extr_critic_mag": 4.40951585299863, "train/extr_critic_max": 4.40951585299863, "train/extr_critic_mean": 0.8823537459514411, "train/extr_critic_min": -0.2684826504420764, "train/extr_critic_std": 1.066352865672464, "train/extr_return_normed_mag": 1.7853933502300618, "train/extr_return_normed_max": 1.7853933502300618, "train/extr_return_normed_mean": 0.2996442552857798, "train/extr_return_normed_min": -0.13835309089845038, "train/extr_return_normed_std": 0.3305166045139576, "train/extr_return_rate": 0.4599070823544939, "train/extr_return_raw_mag": 5.8677685202048915, "train/extr_return_raw_max": 5.8677685202048915, "train/extr_return_raw_mean": 0.8979634889240923, "train/extr_return_raw_min": -0.56711702613995, "train/extr_return_raw_std": 1.1061275207937644, "train/extr_reward_mag": 1.009652818952288, "train/extr_reward_max": 1.009652818952288, "train/extr_reward_mean": 0.02204930921328332, "train/extr_reward_min": -0.327959691362428, "train/extr_reward_std": 0.13662868840941067, "train/image_loss_mean": 9.814241125078624, "train/image_loss_std": 12.925134625928155, "train/model_loss_mean": 18.420862719343212, "train/model_loss_std": 16.948688770162647, "train/model_opt_grad_norm": 66.9203159257109, "train/model_opt_grad_steps": 15203.413793103447, "train/model_opt_loss": 14350.252542429957, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 778.9408866995074, "train/policy_entropy_mag": 2.47404868731945, "train/policy_entropy_max": 2.47404868731945, "train/policy_entropy_mean": 0.620463954110451, "train/policy_entropy_min": 0.07937539523017817, "train/policy_entropy_std": 0.5675547899577418, "train/policy_logprob_mag": 7.43837984911914, "train/policy_logprob_max": -0.009455869639558452, "train/policy_logprob_mean": -0.6206687985382644, "train/policy_logprob_min": -7.43837984911914, "train/policy_logprob_std": 1.1285383460556933, "train/policy_randomness_mag": 0.8732306167409924, "train/policy_randomness_max": 0.8732306167409924, "train/policy_randomness_mean": 0.21899654815349673, "train/policy_randomness_min": 0.028016031210498858, "train/policy_randomness_std": 0.20032193515394708, "train/post_ent_mag": 56.61301688960033, "train/post_ent_max": 56.61301688960033, "train/post_ent_mean": 38.87294229967841, "train/post_ent_min": 20.99712474240458, "train/post_ent_std": 6.75283911662736, "train/prior_ent_mag": 65.43292164919998, "train/prior_ent_max": 65.43292164919998, "train/prior_ent_mean": 53.23847439018964, "train/prior_ent_min": 32.54706548117652, "train/prior_ent_std": 5.790918413641418, "train/rep_loss_mean": 14.256946963042461, "train/rep_loss_std": 9.441468511308942, "train/reward_avg": 0.018771647771572687, "train/reward_loss_mean": 0.05214275779395268, "train/reward_loss_std": 0.2627832265249614, "train/reward_max_data": 1.009359608142834, "train/reward_max_pred": 1.0049424735196117, "train/reward_neg_acc": 0.9938032970639873, "train/reward_neg_loss": 0.029713809389272348, "train/reward_pos_acc": 0.9424839671609437, "train/reward_pos_loss": 0.9813499074851351, "train/reward_pred": 0.017844808145696892, "train/reward_rate": 0.023639547413793104, "eval_stats/sum_log_reward": 4.756249941885471, "eval_stats/max_log_achievement_collect_drink": 3.40625, "eval_stats/max_log_achievement_collect_sapling": 2.3125, "eval_stats/max_log_achievement_collect_wood": 5.6875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.3125, "eval_stats/max_log_achievement_eat_cow": 0.03125, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.15625, "eval_stats/max_log_achievement_place_table": 2.46875, "eval_stats/max_log_achievement_wake_up": 1.71875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.00019719100964721292, "report/cont_loss_std": 0.0051485649310052395, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.04014277830719948, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.1871526339746197e-06, "report/cont_pred": 0.9952993988990784, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 12.00497817993164, "report/dyn_loss_std": 9.007616996765137, "report/image_loss_mean": 7.1075663566589355, "report/image_loss_std": 10.138899803161621, "report/model_loss_mean": 14.33846378326416, "report/model_loss_std": 14.067293167114258, "report/post_ent_mag": 57.39360809326172, "report/post_ent_max": 57.39360809326172, "report/post_ent_mean": 39.28281021118164, "report/post_ent_min": 20.90787696838379, "report/post_ent_std": 6.359721660614014, "report/prior_ent_mag": 66.43494415283203, "report/prior_ent_max": 66.43494415283203, "report/prior_ent_mean": 51.66084289550781, "report/prior_ent_min": 31.53437042236328, "report/prior_ent_std": 5.936160087585449, "report/rep_loss_mean": 12.00497817993164, "report/rep_loss_std": 9.007616996765137, "report/reward_avg": 0.01699218526482582, "report/reward_loss_mean": 0.02771308645606041, "report/reward_loss_std": 0.13712579011917114, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0095276832580566, "report/reward_neg_acc": 0.9960119724273682, "report/reward_neg_loss": 0.013262028805911541, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7179232239723206, "report/reward_pred": 0.017439015209674835, "report/reward_rate": 0.0205078125, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 4.501240255194716e-06, "eval/cont_loss_std": 8.859899389790371e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0011378005146980286, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.2834333321952727e-06, "eval/cont_pred": 0.9980468153953552, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 14.873344421386719, "eval/dyn_loss_std": 9.499491691589355, "eval/image_loss_mean": 15.003737449645996, "eval/image_loss_std": 18.50864028930664, "eval/model_loss_mean": 23.990524291992188, "eval/model_loss_std": 22.3474178314209, "eval/post_ent_mag": 49.75005340576172, "eval/post_ent_max": 49.75005340576172, "eval/post_ent_mean": 39.070899963378906, "eval/post_ent_min": 18.412071228027344, "eval/post_ent_std": 5.187382221221924, "eval/prior_ent_mag": 66.43494415283203, "eval/prior_ent_max": 66.43494415283203, "eval/prior_ent_mean": 51.176055908203125, "eval/prior_ent_min": 29.3225040435791, "eval/prior_ent_std": 5.7260260581970215, "eval/rep_loss_mean": 14.873344421386719, "eval/rep_loss_std": 9.499491691589355, "eval/reward_avg": 0.02070312574505806, "eval/reward_loss_mean": 0.06277668476104736, "eval/reward_loss_std": 0.49148043990135193, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9994305372238159, "eval/reward_neg_acc": 0.9960000514984131, "eval/reward_neg_loss": 0.029348812997341156, "eval/reward_pos_acc": 0.875, "eval/reward_pos_loss": 1.4556045532226562, "eval/reward_pred": 0.021017303690314293, "eval/reward_rate": 0.0234375, "replay/size": 260801.0, "replay/inserts": 32432.0, "replay/samples": 32432.0, "replay/insert_wait_avg": 1.2170874431442614e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 5.625684565961449e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 51160.0, "eval_replay/inserts": 7040.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2002885341644287e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.301568984985352e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3383431434631, "timer/env.step_count": 4054.0, "timer/env.step_total": 159.0848138332367, "timer/env.step_frac": 0.1590310067824938, "timer/env.step_avg": 0.03924144396478458, "timer/env.step_min": 0.002209901809692383, "timer/env.step_max": 0.9460256099700928, "timer/replay._sample_count": 32432.0, "timer/replay._sample_total": 2871.260863304138, "timer/replay._sample_frac": 2.870289720457469, "timer/replay._sample_avg": 0.0885317237081937, "timer/replay._sample_min": 0.0659949779510498, "timer/replay._sample_max": 0.1319289207458496, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4934.0, "timer/agent.policy_total": 49.57740235328674, "timer/agent.policy_frac": 0.049560633852637016, "timer/agent.policy_avg": 0.010048115596531565, "timer/agent.policy_min": 0.007428407669067383, "timer/agent.policy_max": 0.050492048263549805, "timer/dataset_train_count": 2027.0, "timer/dataset_train_total": 0.1605825424194336, "timer/dataset_train_frac": 0.0001605282287938889, "timer/dataset_train_avg": 7.922177721728347e-05, "timer/dataset_train_min": 5.841255187988281e-05, "timer/dataset_train_max": 0.00014853477478027344, "timer/agent.train_count": 2027.0, "timer/agent.train_total": 750.5236024856567, "timer/agent.train_frac": 0.7502697538586909, "timer/agent.train_avg": 0.37026324740288935, "timer/agent.train_min": 0.3524024486541748, "timer/agent.train_max": 0.6189367771148682, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4053523540496826, "timer/agent.report_frac": 0.000405215252247458, "timer/agent.report_avg": 0.2026761770248413, "timer/agent.report_min": 0.20244669914245605, "timer/agent.report_max": 0.20290565490722656, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.504753112792969e-05, "timer/dataset_eval_frac": 3.503567704682431e-08, "timer/dataset_eval_avg": 3.504753112792969e-05, "timer/dataset_eval_min": 3.504753112792969e-05, "timer/dataset_eval_max": 3.504753112792969e-05, "fps": 32.420495114056415}
{"step": 261456, "time": 8143.462749242783, "episode/length": 247.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9798387096774194, "episode/intrinsic_return": 0.0}
{"step": 262080, "time": 8159.929510593414, "episode/length": 191.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 262144, "time": 8162.332627058029, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 262528, "time": 8172.960709095001, "episode/length": 215.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 262568, "time": 8174.604161024094, "episode/length": 138.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9640287769784173, "episode/intrinsic_return": 0.0}
{"step": 262752, "time": 8180.422896146774, "episode/length": 197.0, "episode/score": 4.099999964237213, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 262928, "time": 8185.536429166794, "episode/length": 270.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.985239852398524, "episode/intrinsic_return": 0.0}
{"step": 263464, "time": 8199.419315099716, "episode/length": 164.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9636363636363636, "episode/intrinsic_return": 0.0}
{"step": 263616, "time": 8204.363139629364, "episode/length": 385.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9896373056994818, "episode/intrinsic_return": 0.0}
{"step": 263800, "time": 8209.589245080948, "episode/length": 421.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9786729857819905, "episode/intrinsic_return": 0.0}
{"step": 263856, "time": 8211.964237451553, "episode/length": 221.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 263888, "time": 8213.559713840485, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 264144, "time": 8220.78162407875, "episode/length": 42.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 264296, "time": 8225.249425888062, "episode/length": 215.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 264368, "time": 8228.244641542435, "episode/length": 201.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 264752, "time": 8238.685739278793, "episode/length": 160.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 264856, "time": 8241.897438764572, "episode/length": 154.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.0}
{"step": 265072, "time": 8248.295179128647, "episode/length": 267.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9888059701492538, "episode/intrinsic_return": 0.0}
{"step": 265256, "time": 8253.568388462067, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 265416, "time": 8258.344948530197, "episode/length": 194.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 265496, "time": 8261.294550180435, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 265504, "time": 8262.51454782486, "episode/length": 150.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 265608, "time": 8265.72622179985, "episode/length": 154.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 266280, "time": 8283.219914197922, "episode/length": 190.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 266472, "time": 8289.058334112167, "episode/length": 174.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 266608, "time": 8293.333501815796, "episode/length": 168.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 266648, "time": 8294.959053516388, "episode/length": 223.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9776785714285714, "episode/intrinsic_return": 0.0}
{"step": 266704, "time": 8297.393233537674, "episode/length": 160.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 266904, "time": 8303.030350923538, "episode/length": 161.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 267352, "time": 8315.043206691742, "episode/length": 230.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9826839826839827, "episode/intrinsic_return": 0.0}
{"step": 267464, "time": 8318.634043455124, "episode/length": 147.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 267888, "time": 8330.015798330307, "episode/length": 298.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9866220735785953, "episode/intrinsic_return": 0.0}
{"step": 267936, "time": 8332.064133405685, "episode/length": 160.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 268136, "time": 8337.668207883835, "episode/length": 207.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9711538461538461, "episode/intrinsic_return": 0.0}
{"step": 268152, "time": 8338.98758149147, "episode/length": 192.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 268392, "time": 8345.611748456955, "episode/length": 29.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.8666666666666667, "episode/intrinsic_return": 0.0}
{"step": 268504, "time": 8349.247680425644, "episode/length": 224.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 268720, "time": 8355.624374866486, "episode/length": 226.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 268784, "time": 8358.037214040756, "episode/length": 34.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 268920, "time": 8362.064828395844, "episode/length": 128.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9922480620155039, "episode/intrinsic_return": 0.0}
{"step": 268992, "time": 8364.861497163773, "episode/length": 190.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 269216, "time": 8371.220460653305, "episode/length": 232.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 269336, "time": 8374.739587545395, "episode/length": 42.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 269512, "time": 8380.029950857162, "episode/length": 171.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 269712, "time": 8386.053031682968, "episode/length": 221.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 269936, "time": 8392.376334190369, "episode/length": 126.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.968503937007874, "episode/intrinsic_return": 0.0}
{"step": 270088, "time": 8398.467348337173, "eval_episode/length": 38.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.8717948717948718}
{"step": 270088, "time": 8399.2890458107, "eval_episode/length": 40.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.975609756097561}
{"step": 270088, "time": 8400.84722828865, "eval_episode/length": 39.0, "eval_episode/score": -0.8999999910593033, "eval_episode/reward_rate": 0.975}
{"step": 270088, "time": 8402.966280937195, "eval_episode/length": 156.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9681528662420382}
{"step": 270088, "time": 8403.88994717598, "eval_episode/length": 161.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9691358024691358}
{"step": 270088, "time": 8404.841564893723, "eval_episode/length": 168.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9704142011834319}
{"step": 270088, "time": 8406.046867370605, "eval_episode/length": 185.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.978494623655914}
{"step": 270088, "time": 8407.275200843811, "eval_episode/length": 205.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.970873786407767}
{"step": 270240, "time": 8411.439028978348, "episode/length": 189.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 270256, "time": 8412.735864400864, "episode/length": 39.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 270504, "time": 8419.55138516426, "episode/length": 263.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9962121212121212, "episode/intrinsic_return": 0.0}
{"step": 270624, "time": 8423.491264343262, "episode/length": 175.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 270632, "time": 8424.32251739502, "episode/length": 230.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9826839826839827, "episode/intrinsic_return": 0.0}
{"step": 270784, "time": 8429.105805397034, "episode/length": 180.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 271376, "time": 8444.649424791336, "episode/length": 207.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9711538461538461, "episode/intrinsic_return": 0.0}
{"step": 271552, "time": 8449.840554475784, "episode/length": 254.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9882352941176471, "episode/intrinsic_return": 0.0}
{"step": 271640, "time": 8452.753013134003, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 271856, "time": 8459.120989084244, "episode/length": 199.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.97, "episode/intrinsic_return": 0.0}
{"step": 271960, "time": 8462.329453706741, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 272064, "time": 8465.917909145355, "episode/length": 194.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 272176, "time": 8469.633297681808, "episode/length": 39.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 272424, "time": 8476.510134935379, "episode/length": 204.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 272480, "time": 8478.908395051956, "episode/length": 231.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.978448275862069, "episode/intrinsic_return": 0.0}
{"step": 272800, "time": 8487.717458486557, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 272824, "time": 8488.990347623825, "episode/length": 147.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 273328, "time": 8502.927176952362, "episode/length": 221.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 273344, "time": 8504.136902809143, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9653179190751445, "episode/intrinsic_return": 0.0}
{"step": 273384, "time": 8505.822399616241, "episode/length": 164.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 273640, "time": 8513.113366365433, "episode/length": 36.0, "episode/score": -0.9000000283122063, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 273864, "time": 8519.44580245018, "episode/length": 172.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 273880, "time": 8520.664930582047, "episode/length": 131.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 273960, "time": 8523.470473766327, "episode/length": 191.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 274008, "time": 8525.404594898224, "episode/length": 228.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9694323144104804, "episode/intrinsic_return": 0.0}
{"step": 274024, "time": 8526.667918205261, "episode/length": 79.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9875, "episode/intrinsic_return": 0.0}
{"step": 274176, "time": 8531.481545209885, "episode/length": 171.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 274816, "time": 8547.925204515457, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 275280, "time": 8560.269040107727, "episode/length": 156.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 275488, "time": 8566.21594285965, "episode/length": 184.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 275544, "time": 8568.257949590683, "episode/length": 197.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 275576, "time": 8569.849267959595, "episode/length": 211.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 275640, "time": 8572.268941879272, "episode/length": 102.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.941747572815534, "episode/intrinsic_return": 0.0}
{"step": 275672, "time": 8573.893875837326, "episode/length": 225.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9734513274336283, "episode/intrinsic_return": 0.0}
{"step": 275744, "time": 8576.690518140793, "episode/length": 195.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 275832, "time": 8579.512523889542, "episode/length": 68.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9420289855072463, "episode/intrinsic_return": 0.0}
{"step": 275960, "time": 8583.484130859375, "episode/length": 289.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9862068965517241, "episode/intrinsic_return": 0.0}
{"step": 276976, "time": 8609.64897441864, "episode/length": 178.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 277096, "time": 8613.304896593094, "episode/length": 181.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 277128, "time": 8614.985736846924, "episode/length": 204.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 277144, "time": 8616.236973762512, "episode/length": 163.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9634146341463414, "episode/intrinsic_return": 0.0}
{"step": 277160, "time": 8617.50504207611, "episode/length": 176.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 277232, "time": 8620.38118815422, "episode/length": 158.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 277720, "time": 8633.184610128403, "episode/length": 255.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.99609375, "episode/intrinsic_return": 0.0}
{"step": 277800, "time": 8635.99238705635, "episode/length": 277.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9892086330935251, "episode/intrinsic_return": 0.0}
{"step": 278304, "time": 8649.571913003922, "episode/length": 150.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 278344, "time": 8651.190734386444, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 278504, "time": 8655.922431468964, "episode/length": 169.0, "episode/score": 3.099999964237213, "episode/reward_rate": 0.9647058823529412, "episode/intrinsic_return": 0.0}
{"step": 278544, "time": 8657.91080212593, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 278800, "time": 8665.164185285568, "episode/length": 208.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9712918660287081, "episode/intrinsic_return": 0.0}
{"step": 279128, "time": 8673.9422249794, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 279144, "time": 8675.144822597504, "episode/length": 177.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 279264, "time": 8679.113584280014, "episode/length": 94.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9473684210526315, "episode/intrinsic_return": 0.0}
{"step": 279336, "time": 8681.509171009064, "episode/length": 262.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.973384030418251, "episode/intrinsic_return": 0.0}
{"step": 279528, "time": 8687.065651655197, "episode/length": 49.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 280072, "time": 8701.310831308365, "episode/length": 190.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9685863874345549, "episode/intrinsic_return": 0.0}
{"step": 280072, "time": 8703.63344335556, "eval_episode/length": 94.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9894736842105263}
{"step": 280072, "time": 8705.638223171234, "eval_episode/length": 162.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9754601226993865}
{"step": 280072, "time": 8706.596999645233, "eval_episode/length": 170.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9707602339181286}
{"step": 280072, "time": 8707.532142877579, "eval_episode/length": 177.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9943820224719101}
{"step": 280072, "time": 8708.937076807022, "eval_episode/length": 204.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.975609756097561}
{"step": 280072, "time": 8710.155303239822, "eval_episode/length": 131.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9621212121212122}
{"step": 280072, "time": 8711.054114103317, "eval_episode/length": 228.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9956331877729258}
{"step": 280072, "time": 8712.954077482224, "eval_episode/length": 283.0, "eval_episode/score": 6.0999999940395355, "eval_episode/reward_rate": 0.9964788732394366}
{"step": 280104, "time": 8714.768769264221, "episode/length": 219.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 280112, "time": 8715.984338760376, "episode/length": 163.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 280176, "time": 8718.363148450851, "episode/length": 233.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 280624, "time": 8730.37369275093, "episode/length": 169.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 280752, "time": 8734.315654039383, "episode/length": 176.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.96045197740113, "episode/intrinsic_return": 0.0}
{"step": 280984, "time": 8740.841101646423, "episode/length": 44.0, "episode/score": 2.0999999940395355, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 281216, "time": 8747.67456126213, "episode/length": 138.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9568345323741008, "episode/intrinsic_return": 0.0}
{"step": 281368, "time": 8752.062990188599, "episode/length": 148.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 281520, "time": 8756.926486492157, "episode/length": 296.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9865319865319865, "episode/intrinsic_return": 0.0}
{"step": 281776, "time": 8764.07896566391, "episode/length": 207.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 281840, "time": 8766.505977869034, "episode/length": 288.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9965397923875432, "episode/intrinsic_return": 0.0}
{"step": 281888, "time": 8768.489884614944, "episode/length": 226.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 282536, "time": 8785.440907716751, "episode/length": 222.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9775784753363229, "episode/intrinsic_return": 0.0}
{"step": 282576, "time": 8787.512797832489, "episode/length": 198.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 282624, "time": 8789.515584230423, "episode/length": 97.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9897959183673469, "episode/intrinsic_return": 0.0}
{"step": 282744, "time": 8793.215347528458, "episode/length": 190.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 282920, "time": 8798.404746294022, "episode/length": 174.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9657142857142857, "episode/intrinsic_return": 0.0}
{"step": 283280, "time": 8808.464000463486, "episode/length": 187.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 283368, "time": 8811.454666376114, "episode/length": 184.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 283728, "time": 8822.360649824142, "episode/length": 294.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9864406779661017, "episode/intrinsic_return": 0.0}
{"step": 283944, "time": 8828.460397481918, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 284224, "time": 8836.447518348694, "episode/length": 184.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 284296, "time": 8838.95869231224, "episode/length": 171.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9825581395348837, "episode/intrinsic_return": 0.0}
{"step": 284312, "time": 8840.178417682648, "episode/length": 221.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 284528, "time": 8846.706357955933, "episode/length": 243.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9795081967213115, "episode/intrinsic_return": 0.0}
{"step": 284584, "time": 8848.792850732803, "episode/length": 162.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 284720, "time": 8853.168658971786, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 285040, "time": 8862.108109474182, "episode/length": 163.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9573170731707317, "episode/intrinsic_return": 0.0}
{"step": 285440, "time": 8872.791336774826, "episode/length": 140.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.0}
{"step": 285960, "time": 8886.429631471634, "episode/length": 216.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 286080, "time": 8890.494402647018, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 286160, "time": 8893.289407491684, "episode/length": 196.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 286320, "time": 8898.049195766449, "episode/length": 296.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 286512, "time": 8903.675508260727, "episode/length": 247.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9959677419354839, "episode/intrinsic_return": 0.0}
{"step": 287000, "time": 8916.50584602356, "episode/length": 194.0, "episode/score": 6.100000016391277, "episode/reward_rate": 0.9846153846153847, "episode/intrinsic_return": 0.0}
{"step": 287176, "time": 8921.829008579254, "episode/length": 151.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 287392, "time": 8928.29225230217, "episode/length": 293.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9965986394557823, "episode/intrinsic_return": 0.0}
{"step": 287688, "time": 8936.351655960083, "episode/length": 190.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9685863874345549, "episode/intrinsic_return": 0.0}
{"step": 287704, "time": 8937.541876792908, "episode/length": 172.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 287720, "time": 8938.788642644882, "episode/length": 150.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 288256, "time": 8953.202003955841, "episode/length": 494.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9878787878787879, "episode/intrinsic_return": 0.0}
{"step": 288520, "time": 8960.505234718323, "episode/length": 167.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 288616, "time": 8963.782146930695, "episode/length": 44.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 288664, "time": 8965.8019490242, "episode/length": 207.0, "episode/score": 6.100000016391277, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 288816, "time": 8970.640160560608, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 289088, "time": 8978.285455703735, "episode/length": 170.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9590643274853801, "episode/intrinsic_return": 0.0}
{"step": 289088, "time": 8978.307817459106, "episode/length": 174.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 289400, "time": 8986.757716417313, "episode/length": 211.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 289464, "time": 8989.13223695755, "episode/length": 422.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 290056, "time": 9007.833755016327, "eval_episode/length": 133.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9626865671641791}
{"step": 290056, "time": 9009.119866609573, "eval_episode/length": 157.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9683544303797469}
{"step": 290056, "time": 9010.314964532852, "eval_episode/length": 174.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 290056, "time": 9010.336961746216, "eval_episode/length": 174.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.9771428571428571}
{"step": 290056, "time": 9011.359744787216, "eval_episode/length": 183.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9728260869565217}
{"step": 290056, "time": 9012.719972610474, "eval_episode/length": 209.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9952380952380953}
{"step": 290056, "time": 9013.937444925308, "eval_episode/length": 226.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.973568281938326}
{"step": 290056, "time": 9014.815342664719, "eval_episode/length": 70.0, "eval_episode/score": 4.100000023841858, "eval_episode/reward_rate": 0.9859154929577465}
{"step": 290304, "time": 9021.296201467514, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 290336, "time": 9022.940348386765, "episode/length": 214.0, "episode/score": 6.1000000312924385, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 290336, "time": 9022.96188545227, "episode/length": 226.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.973568281938326, "episode/intrinsic_return": 0.0}
{"step": 290368, "time": 9024.636050462723, "episode/length": 159.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 290544, "time": 9029.823110103607, "episode/length": 181.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 290832, "time": 9037.914308309555, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 290872, "time": 9039.542428731918, "episode/length": 40.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 291248, "time": 9049.887076616287, "episode/length": 230.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 291632, "time": 9060.27379822731, "episode/length": 161.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 291760, "time": 9064.26985502243, "episode/length": 181.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 291784, "time": 9065.52119922638, "episode/length": 180.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 291992, "time": 9071.792747020721, "episode/length": 202.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 292368, "time": 9082.225241184235, "episode/length": 191.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 292696, "time": 9091.056933879852, "episode/length": 227.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 292872, "time": 9096.457515001297, "episode/length": 202.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 292960, "time": 9099.732148647308, "episode/length": 536.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9962756052141527, "episode/intrinsic_return": 0.0}
{"step": 293032, "time": 9102.164327383041, "episode/length": 174.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 293328, "time": 9110.626939296722, "episode/length": 192.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 293440, "time": 9114.286756753922, "episode/length": 209.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9857142857142858, "episode/intrinsic_return": 0.0}
{"step": 293480, "time": 9115.998274087906, "episode/length": 55.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 293560, "time": 9118.90885257721, "episode/length": 195.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 294008, "time": 9130.869843006134, "episode/length": 163.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 294048, "time": 9132.84614276886, "episode/length": 209.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 294265, "time": 9139.892055273056, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.180345257509102, "train/action_min": 0.0, "train/action_std": 3.0753605192147413, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.043691089087464274, "train/actor_opt_grad_steps": 17265.0, "train/actor_opt_loss": -5.240999170009372, "train/adv_mag": 0.6621757985897434, "train/adv_max": 0.6465834583182937, "train/adv_mean": 0.00329369347366206, "train/adv_min": -0.4551747802970479, "train/adv_std": 0.06946643544993933, "train/cont_avg": 0.9946668310072816, "train/cont_loss_mean": 0.00024825301558519956, "train/cont_loss_std": 0.006829169052255044, "train/cont_neg_acc": 0.9890603344995998, "train/cont_neg_loss": 0.02840061203501655, "train/cont_pos_acc": 0.9999665866777735, "train/cont_pos_loss": 9.996866546709395e-05, "train/cont_pred": 0.9946825151304597, "train/cont_rate": 0.9946668310072816, "train/dyn_loss_mean": 14.454666744158105, "train/dyn_loss_std": 9.311173883456629, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8867936255862412, "train/extr_critic_critic_opt_grad_steps": 17265.0, "train/extr_critic_critic_opt_loss": 15505.262804346177, "train/extr_critic_mag": 4.758006047276617, "train/extr_critic_max": 4.758006047276617, "train/extr_critic_mean": 0.9435005792715017, "train/extr_critic_min": -0.25407658792236476, "train/extr_critic_std": 1.153481883042067, "train/extr_return_normed_mag": 1.7600262089840417, "train/extr_return_normed_max": 1.7600262089840417, "train/extr_return_normed_mean": 0.2975690207869104, "train/extr_return_normed_min": -0.12667983377949127, "train/extr_return_normed_std": 0.3359190667572531, "train/extr_return_rate": 0.4567765447410565, "train/extr_return_raw_mag": 6.127352728427035, "train/extr_return_raw_max": 6.127352728427035, "train/extr_return_raw_mean": 0.9550931479745698, "train/extr_return_raw_min": -0.5446864868541366, "train/extr_return_raw_std": 1.1881076137996414, "train/extr_reward_mag": 1.0090943731150581, "train/extr_reward_max": 1.0090943731150581, "train/extr_reward_mean": 0.02436598077940854, "train/extr_reward_min": -0.3504918570657378, "train/extr_reward_std": 0.1441957596870302, "train/image_loss_mean": 9.098375642183916, "train/image_loss_std": 12.35920312798139, "train/model_loss_mean": 17.823352017448943, "train/model_loss_std": 16.263660185545394, "train/model_opt_grad_norm": 67.44508036826421, "train/model_opt_grad_steps": 17246.59223300971, "train/model_opt_loss": 11880.983758722694, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 667.4757281553398, "train/policy_entropy_mag": 2.5350696322987383, "train/policy_entropy_max": 2.5350696322987383, "train/policy_entropy_mean": 0.6810824020395001, "train/policy_entropy_min": 0.07937532930987552, "train/policy_entropy_std": 0.6254072613218455, "train/policy_logprob_mag": 7.43838049833057, "train/policy_logprob_max": -0.00945588608172912, "train/policy_logprob_mean": -0.6806998478556142, "train/policy_logprob_min": -7.43838049833057, "train/policy_logprob_std": 1.173125774536318, "train/policy_randomness_mag": 0.8947683318147381, "train/policy_randomness_max": 0.8947683318147381, "train/policy_randomness_mean": 0.2403921997084201, "train/policy_randomness_min": 0.028016007984581502, "train/policy_randomness_std": 0.22074131870154037, "train/post_ent_mag": 57.3419808508123, "train/post_ent_max": 57.3419808508123, "train/post_ent_mean": 39.30609495662949, "train/post_ent_min": 21.17577932413342, "train/post_ent_std": 6.883443406484659, "train/prior_ent_mag": 66.05016012099183, "train/prior_ent_max": 66.05016012099183, "train/prior_ent_mean": 53.8940183769152, "train/prior_ent_min": 34.56978517365687, "train/prior_ent_std": 5.4837234251707505, "train/rep_loss_mean": 14.454666744158105, "train/rep_loss_std": 9.311173883456629, "train/reward_avg": 0.020137097875280216, "train/reward_loss_mean": 0.05192817772006236, "train/reward_loss_std": 0.2523576057362325, "train/reward_max_data": 1.0106796141967034, "train/reward_max_pred": 1.0045661995711836, "train/reward_neg_acc": 0.9935836661787867, "train/reward_neg_loss": 0.029518208900484646, "train/reward_pos_acc": 0.9510196270873246, "train/reward_pos_loss": 0.928553089933488, "train/reward_pred": 0.019389039484187236, "train/reward_rate": 0.02500663683252427, "train_stats/sum_log_reward": 4.9448275125917345, "train_stats/max_log_achievement_collect_drink": 3.528735632183908, "train_stats/max_log_achievement_collect_sapling": 2.3850574712643677, "train_stats/max_log_achievement_collect_wood": 7.2298850574712645, "train_stats/max_log_achievement_defeat_skeleton": 0.017241379310344827, "train_stats/max_log_achievement_defeat_zombie": 0.39080459770114945, "train_stats/max_log_achievement_eat_cow": 0.07471264367816093, "train_stats/max_log_achievement_make_wood_pickaxe": 0.022988505747126436, "train_stats/max_log_achievement_make_wood_sword": 0.028735632183908046, "train_stats/max_log_achievement_place_plant": 2.2413793103448274, "train_stats/max_log_achievement_place_table": 3.0229885057471266, "train_stats/max_log_achievement_wake_up": 1.8045977011494252, "train_stats/mean_log_entropy": 0.5866745508265221, "train_stats/max_log_achievement_collect_stone": 0.015384615384615385, "train_stats/max_log_achievement_place_stone": 0.007692307692307693, "eval_stats/sum_log_reward": 4.43333322306474, "eval_stats/max_log_achievement_collect_drink": 4.0, "eval_stats/max_log_achievement_collect_sapling": 1.8333333333333333, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 4.75, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.2916666666666667, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.041666666666666664, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 1.6666666666666667, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.0416666666666665, "eval_stats/max_log_achievement_wake_up": 1.5833333333333333, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9912109375, "report/cont_loss_mean": 3.1382918677991256e-05, "report/cont_loss_std": 0.0008614163380116224, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00016258866526186466, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 3.0219516702345572e-05, "report/cont_pred": 0.991182804107666, "report/cont_rate": 0.9912109375, "report/dyn_loss_mean": 15.207663536071777, "report/dyn_loss_std": 9.213205337524414, "report/image_loss_mean": 7.254340171813965, "report/image_loss_std": 9.806222915649414, "report/model_loss_mean": 16.447589874267578, "report/model_loss_std": 13.776678085327148, "report/post_ent_mag": 57.26287841796875, "report/post_ent_max": 57.26287841796875, "report/post_ent_mean": 38.60497283935547, "report/post_ent_min": 19.295324325561523, "report/post_ent_std": 6.792224407196045, "report/prior_ent_mag": 65.929931640625, "report/prior_ent_max": 65.929931640625, "report/prior_ent_mean": 53.75994110107422, "report/prior_ent_min": 34.39208221435547, "report/prior_ent_std": 5.529118537902832, "report/rep_loss_mean": 15.207663536071777, "report/rep_loss_std": 9.213205337524414, "report/reward_avg": 0.02744140475988388, "report/reward_loss_mean": 0.06862086057662964, "report/reward_loss_std": 0.24817469716072083, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0017008781433105, "report/reward_neg_acc": 0.9878664612770081, "report/reward_neg_loss": 0.045284148305654526, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7280495762825012, "report/reward_pred": 0.02897164225578308, "report/reward_rate": 0.0341796875, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.0004969770088791847, "eval/cont_loss_std": 0.015812046825885773, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.08480381965637207, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 7.980870719848099e-08, "eval/cont_pred": 0.9945310354232788, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 13.79489803314209, "eval/dyn_loss_std": 9.870524406433105, "eval/image_loss_mean": 13.997724533081055, "eval/image_loss_std": 20.993717193603516, "eval/model_loss_mean": 22.344453811645508, "eval/model_loss_std": 25.197677612304688, "eval/post_ent_mag": 55.517723083496094, "eval/post_ent_max": 55.517723083496094, "eval/post_ent_mean": 40.87748336791992, "eval/post_ent_min": 22.15243911743164, "eval/post_ent_std": 6.2527618408203125, "eval/prior_ent_mag": 65.929931640625, "eval/prior_ent_max": 65.929931640625, "eval/prior_ent_mean": 52.2054328918457, "eval/prior_ent_min": 30.37602996826172, "eval/prior_ent_std": 5.216763019561768, "eval/rep_loss_mean": 13.79489803314209, "eval/rep_loss_std": 9.870524406433105, "eval/reward_avg": 0.01015624962747097, "eval/reward_loss_mean": 0.0692921057343483, "eval/reward_loss_std": 0.5015986561775208, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.00173020362854, "eval/reward_neg_acc": 0.9950397610664368, "eval/reward_neg_loss": 0.05260033532977104, "eval/reward_pos_acc": 0.9375, "eval/reward_pos_loss": 1.1208738088607788, "eval/reward_pred": 0.01030941866338253, "eval/reward_rate": 0.015625, "replay/size": 293761.0, "replay/inserts": 32960.0, "replay/samples": 32960.0, "replay/insert_wait_avg": 1.2270961571665644e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 5.640017176137387e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 56912.0, "eval_replay/inserts": 5752.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2026625647830035e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 6.258487701416016e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.144314289093, "timer/env.step_count": 4120.0, "timer/env.step_total": 157.508207321167, "timer/env.step_frac": 0.15748547991609044, "timer/env.step_avg": 0.03823014740805024, "timer/env.step_min": 0.0022864341735839844, "timer/env.step_max": 0.9403235912322998, "timer/replay._sample_count": 32960.0, "timer/replay._sample_total": 2918.5929238796234, "timer/replay._sample_frac": 2.918171789992299, "timer/replay._sample_avg": 0.08854954259343517, "timer/replay._sample_min": 0.0004563331604003906, "timer/replay._sample_max": 0.1210780143737793, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4839.0, "timer/agent.policy_total": 48.41179418563843, "timer/agent.policy_frac": 0.04840480868008508, "timer/agent.policy_avg": 0.01000450386146692, "timer/agent.policy_min": 0.007700681686401367, "timer/agent.policy_max": 0.02101588249206543, "timer/dataset_train_count": 2060.0, "timer/dataset_train_total": 0.16317296028137207, "timer/dataset_train_frac": 0.00016314941548945978, "timer/dataset_train_avg": 7.921017489386993e-05, "timer/dataset_train_min": 6.246566772460938e-05, "timer/dataset_train_max": 0.0001544952392578125, "timer/agent.train_count": 2060.0, "timer/agent.train_total": 762.6524949073792, "timer/agent.train_frac": 0.7625424491359288, "timer/agent.train_avg": 0.3702196577220287, "timer/agent.train_min": 0.34804558753967285, "timer/agent.train_max": 1.1042275428771973, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.39171528816223145, "timer/agent.report_frac": 0.0003916587662058194, "timer/agent.report_avg": 0.19585764408111572, "timer/agent.report_min": 0.18866610527038574, "timer/agent.report_max": 0.2030491828918457, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.4332275390625e-05, "timer/dataset_eval_frac": 3.432732146763093e-08, "timer/dataset_eval_avg": 3.4332275390625e-05, "timer/dataset_eval_min": 3.4332275390625e-05, "timer/dataset_eval_max": 3.4332275390625e-05, "fps": 32.95474410714328}
{"step": 294336, "time": 9141.54184126854, "episode/length": 182.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9672131147540983, "episode/intrinsic_return": 0.0}
{"step": 294448, "time": 9145.719774484634, "episode/length": 185.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 294792, "time": 9155.006018161774, "episode/length": 97.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9897959183673469, "episode/intrinsic_return": 0.0}
{"step": 294816, "time": 9156.567369699478, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 294888, "time": 9159.062947273254, "episode/length": 180.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 295184, "time": 9167.500363349915, "episode/length": 202.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 295288, "time": 9170.702003240585, "episode/length": 225.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9778761061946902, "episode/intrinsic_return": 0.0}
{"step": 295880, "time": 9186.138800859451, "episode/length": 192.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 296232, "time": 9195.716534852982, "episode/length": 167.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 296336, "time": 9199.278022289276, "episode/length": 285.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.986013986013986, "episode/intrinsic_return": 0.0}
{"step": 296464, "time": 9203.303481578827, "episode/length": 208.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9712918660287081, "episode/intrinsic_return": 0.0}
{"step": 296520, "time": 9205.384365081787, "episode/length": 212.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 296600, "time": 9208.329975128174, "episode/length": 176.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 296624, "time": 9209.935037612915, "episode/length": 166.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 296696, "time": 9212.345462799072, "episode/length": 101.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9411764705882353, "episode/intrinsic_return": 0.0}
{"step": 296872, "time": 9217.551279067993, "episode/length": 302.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9900990099009901, "episode/intrinsic_return": 0.0}
{"step": 297160, "time": 9225.691343069077, "episode/length": 35.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 297520, "time": 9235.614816904068, "episode/length": 147.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 297800, "time": 9243.276541233063, "episode/length": 195.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 297888, "time": 9246.4868350029, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 297984, "time": 9249.727685451508, "episode/length": 189.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.968421052631579, "episode/intrinsic_return": 0.0}
{"step": 298008, "time": 9251.029988765717, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 298280, "time": 9258.603187322617, "episode/length": 48.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 298480, "time": 9264.732064962387, "episode/length": 222.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9775784753363229, "episode/intrinsic_return": 0.0}
{"step": 298920, "time": 9276.37073969841, "episode/length": 219.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 298952, "time": 9277.996228933334, "episode/length": 293.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 299232, "time": 9286.04071354866, "episode/length": 155.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 299488, "time": 9293.354007720947, "episode/length": 245.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9959349593495935, "episode/intrinsic_return": 0.0}
{"step": 299536, "time": 9295.382749557495, "episode/length": 190.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 299680, "time": 9299.836434602737, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 299896, "time": 9305.852845191956, "episode/length": 261.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9809160305343512, "episode/intrinsic_return": 0.0}
{"step": 300040, "time": 9313.466747999191, "eval_episode/length": 156.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9681528662420382}
{"step": 300040, "time": 9314.311223745346, "eval_episode/length": 157.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9936708860759493}
{"step": 300040, "time": 9315.176433563232, "eval_episode/length": 159.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.95625}
{"step": 300040, "time": 9316.395866632462, "eval_episode/length": 183.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9782608695652174}
{"step": 300040, "time": 9317.652280330658, "eval_episode/length": 205.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9757281553398058}
{"step": 300040, "time": 9318.484758377075, "eval_episode/length": 206.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9951690821256038}
{"step": 300040, "time": 9319.462007522583, "eval_episode/length": 214.0, "eval_episode/score": 5.099999971687794, "eval_episode/reward_rate": 0.9953488372093023}
{"step": 300040, "time": 9320.501013755798, "eval_episode/length": 69.0, "eval_episode/score": 3.0999999791383743, "eval_episode/reward_rate": 0.9857142857142858}
{"step": 300408, "time": 9330.218263149261, "episode/length": 240.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.975103734439834, "episode/intrinsic_return": 0.0}
{"step": 300496, "time": 9333.36626124382, "episode/length": 196.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 300856, "time": 9342.90462732315, "episode/length": 170.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 301048, "time": 9348.719634532928, "episode/length": 261.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9770992366412213, "episode/intrinsic_return": 0.0}
{"step": 301072, "time": 9350.405375003815, "episode/length": 191.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 301112, "time": 9351.963774204254, "episode/length": 178.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 301392, "time": 9359.885942935944, "episode/length": 186.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9679144385026738, "episode/intrinsic_return": 0.0}
{"step": 301968, "time": 9375.074537038803, "episode/length": 183.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967391304347826, "episode/intrinsic_return": 0.0}
{"step": 302128, "time": 9379.894589185715, "episode/length": 214.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 302328, "time": 9385.573873281479, "episode/length": 156.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 302384, "time": 9388.059623479843, "episode/length": 190.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 302656, "time": 9395.66941189766, "episode/length": 427.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9789719626168224, "episode/intrinsic_return": 0.0}
{"step": 302832, "time": 9400.919060230255, "episode/length": 214.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 303112, "time": 9408.444562673569, "episode/length": 214.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 303464, "time": 9418.003639936447, "episode/length": 141.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 303528, "time": 9420.38827419281, "episode/length": 194.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.958974358974359, "episode/intrinsic_return": 0.0}
{"step": 303656, "time": 9424.432631969452, "episode/length": 158.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9559748427672956, "episode/intrinsic_return": 0.0}
{"step": 303704, "time": 9426.460214138031, "episode/length": 196.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 303896, "time": 9432.13710141182, "episode/length": 355.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 304408, "time": 9445.587044000626, "episode/length": 161.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 304472, "time": 9447.970789432526, "episode/length": 204.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9804878048780488, "episode/intrinsic_return": 0.0}
{"step": 304944, "time": 9460.716511964798, "episode/length": 154.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.0}
{"step": 304992, "time": 9462.74929690361, "episode/length": 166.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 305176, "time": 9467.982965707779, "episode/length": 314.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9904761904761905, "episode/intrinsic_return": 0.0}
{"step": 305272, "time": 9471.279539585114, "episode/length": 171.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 305384, "time": 9474.938504457474, "episode/length": 54.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 305472, "time": 9478.077858924866, "episode/length": 36.0, "episode/score": -0.8999999910593033, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 305520, "time": 9480.106765031815, "episode/length": 248.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9879518072289156, "episode/intrinsic_return": 0.0}
{"step": 305664, "time": 9484.466173410416, "episode/length": 34.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 305704, "time": 9486.135799407959, "episode/length": 279.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9785714285714285, "episode/intrinsic_return": 0.0}
{"step": 305816, "time": 9489.672388076782, "episode/length": 175.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 305872, "time": 9492.072092533112, "episode/length": 43.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 305920, "time": 9494.12337398529, "episode/length": 180.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 306184, "time": 9501.370671987534, "episode/length": 148.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 306272, "time": 9504.629187345505, "episode/length": 49.0, "episode/score": 1.0999999791383743, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 306848, "time": 9519.734516382217, "episode/length": 196.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9847715736040609, "episode/intrinsic_return": 0.0}
{"step": 307112, "time": 9526.95463347435, "episode/length": 180.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 307248, "time": 9531.30934882164, "episode/length": 221.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 307360, "time": 9534.85855126381, "episode/length": 206.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 307368, "time": 9535.709069013596, "episode/length": 193.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9845360824742269, "episode/intrinsic_return": 0.0}
{"step": 307664, "time": 9544.163826465607, "episode/length": 217.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 307688, "time": 9545.376002550125, "episode/length": 176.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 308056, "time": 9555.18566775322, "episode/length": 233.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9786324786324786, "episode/intrinsic_return": 0.0}
{"step": 308128, "time": 9557.944062709808, "episode/length": 159.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 308576, "time": 9569.722745895386, "episode/length": 151.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 308712, "time": 9573.652776956558, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 308976, "time": 9581.18906545639, "episode/length": 32.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 309136, "time": 9585.937218427658, "episode/length": 180.0, "episode/score": 4.099999964237213, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 309272, "time": 9589.901242733002, "episode/length": 269.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9851851851851852, "episode/intrinsic_return": 0.0}
{"step": 309440, "time": 9595.110381603241, "episode/length": 221.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9819819819819819, "episode/intrinsic_return": 0.0}
{"step": 309720, "time": 9602.543110370636, "episode/length": 198.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9798994974874372, "episode/intrinsic_return": 0.0}
{"step": 309992, "time": 9610.038310527802, "episode/length": 176.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 310024, "time": 9613.946646213531, "eval_episode/length": 77.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9871794871794872}
{"step": 310024, "time": 9615.721808671951, "eval_episode/length": 132.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9548872180451128}
{"step": 310024, "time": 9617.137350082397, "eval_episode/length": 167.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9821428571428571}
{"step": 310024, "time": 9618.036813259125, "eval_episode/length": 170.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9707602339181286}
{"step": 310024, "time": 9619.090770483017, "eval_episode/length": 180.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.994475138121547}
{"step": 310024, "time": 9620.21056842804, "eval_episode/length": 193.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.979381443298969}
{"step": 310024, "time": 9621.94573020935, "eval_episode/length": 161.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9691358024691358}
{"step": 310024, "time": 9622.933073043823, "eval_episode/length": 246.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.979757085020243}
{"step": 310072, "time": 9624.410530805588, "episode/length": 251.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9801587301587301, "episode/intrinsic_return": 0.0}
{"step": 310192, "time": 9628.35105752945, "episode/length": 367.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9918478260869565, "episode/intrinsic_return": 0.0}
{"step": 310464, "time": 9635.781770944595, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 310544, "time": 9638.59118771553, "episode/length": 195.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 310760, "time": 9644.758178710938, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 311104, "time": 9654.383803844452, "episode/length": 207.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 311288, "time": 9659.635286331177, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 311312, "time": 9661.306573152542, "episode/length": 139.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.95, "episode/intrinsic_return": 0.0}
{"step": 311384, "time": 9663.729269266129, "episode/length": 207.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 311888, "time": 9677.200547933578, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 312192, "time": 9685.477964878082, "episode/length": 178.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 312248, "time": 9687.552035331726, "episode/length": 271.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9779411764705882, "episode/intrinsic_return": 0.0}
{"step": 312336, "time": 9690.702018022537, "episode/length": 233.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 312784, "time": 9702.632023096085, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 312816, "time": 9704.344369888306, "episode/length": 213.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 312880, "time": 9706.679181337357, "episode/length": 198.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 313008, "time": 9710.748924732208, "episode/length": 211.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 313312, "time": 9719.11151266098, "episode/length": 177.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 313472, "time": 9723.935478925705, "episode/length": 141.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9577464788732394, "episode/intrinsic_return": 0.0}
{"step": 313928, "time": 9735.949211120605, "episode/length": 216.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 314008, "time": 9738.75148677826, "episode/length": 219.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 314104, "time": 9741.982628583908, "episode/length": 160.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 314272, "time": 9747.297616243362, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 314344, "time": 9749.726165533066, "episode/length": 166.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 314464, "time": 9753.78158068657, "episode/length": 197.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 315032, "time": 9768.492292881012, "episode/length": 214.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9720930232558139, "episode/intrinsic_return": 0.0}
{"step": 315104, "time": 9771.284257888794, "episode/length": 203.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 315344, "time": 9778.100681781769, "episode/length": 38.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 315608, "time": 9785.256989479065, "episode/length": 199.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 315744, "time": 9789.62107682228, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 315744, "time": 9789.645246505737, "episode/length": 159.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 315824, "time": 9792.501428365707, "episode/length": 193.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 315904, "time": 9795.334264993668, "episode/length": 246.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.979757085020243, "episode/intrinsic_return": 0.0}
{"step": 316400, "time": 9808.397715806961, "episode/length": 161.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9567901234567902, "episode/intrinsic_return": 0.0}
{"step": 316624, "time": 9814.862755298615, "episode/length": 314.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9873015873015873, "episode/intrinsic_return": 0.0}
{"step": 316904, "time": 9822.465584516525, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 316952, "time": 9824.505031824112, "episode/length": 40.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 317096, "time": 9828.876514673233, "episode/length": 168.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9585798816568047, "episode/intrinsic_return": 0.0}
{"step": 317184, "time": 9832.120603084564, "episode/length": 159.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 317536, "time": 9841.625054359436, "episode/length": 213.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 317744, "time": 9847.595391273499, "episode/length": 167.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9583333333333334, "episode/intrinsic_return": 0.0}
{"step": 317872, "time": 9851.754396677017, "episode/length": 315.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9968354430379747, "episode/intrinsic_return": 0.0}
{"step": 317976, "time": 9854.988557815552, "episode/length": 278.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 318696, "time": 9873.998915672302, "episode/length": 217.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 318720, "time": 9875.655637979507, "episode/length": 191.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 318880, "time": 9880.54741191864, "episode/length": 246.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 319064, "time": 9885.77623462677, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 319072, "time": 9886.918131351471, "episode/length": 43.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8863636363636364, "episode/intrinsic_return": 0.0}
{"step": 319296, "time": 9893.336690425873, "episode/length": 219.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 319464, "time": 9898.215396165848, "episode/length": 295.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9763513513513513, "episode/intrinsic_return": 0.0}
{"step": 319584, "time": 9902.333414554596, "episode/length": 200.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 320008, "time": 9916.27235364914, "eval_episode/length": 129.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9923076923076923}
{"step": 320008, "time": 9917.866652011871, "eval_episode/length": 168.0, "eval_episode/score": 6.099999979138374, "eval_episode/reward_rate": 0.9940828402366864}
{"step": 320008, "time": 9918.76465177536, "eval_episode/length": 176.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9774011299435028}
{"step": 320008, "time": 9919.779759407043, "eval_episode/length": 186.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9786096256684492}
{"step": 320008, "time": 9920.819874286652, "eval_episode/length": 195.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.9795918367346939}
{"step": 320008, "time": 9921.877415180206, "eval_episode/length": 206.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9855072463768116}
{"step": 320008, "time": 9922.84470295906, "eval_episode/length": 211.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9764150943396226}
{"step": 320008, "time": 9923.97301697731, "eval_episode/length": 218.0, "eval_episode/score": 7.099999979138374, "eval_episode/reward_rate": 0.9954337899543378}
{"step": 320160, "time": 9927.930612564087, "episode/length": 182.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 320256, "time": 9931.194649934769, "episode/length": 171.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 320312, "time": 9933.29761314392, "episode/length": 105.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9528301886792453, "episode/intrinsic_return": 0.0}
{"step": 320392, "time": 9936.101368427277, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 320600, "time": 9942.104786396027, "episode/length": 190.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 320936, "time": 9951.186541080475, "episode/length": 204.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 321320, "time": 9961.550869464874, "episode/length": 430.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9791183294663574, "episode/intrinsic_return": 0.0}
{"step": 321544, "time": 9967.92296218872, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9653179190751445, "episode/intrinsic_return": 0.0}
{"step": 321712, "time": 9973.230823993683, "episode/length": 164.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9636363636363636, "episode/intrinsic_return": 0.0}
{"step": 322096, "time": 9983.72903418541, "episode/length": 222.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9730941704035875, "episode/intrinsic_return": 0.0}
{"step": 322136, "time": 9985.457750082016, "episode/length": 149.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.96, "episode/intrinsic_return": 0.0}
{"step": 322256, "time": 9989.48075580597, "episode/length": 206.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 322600, "time": 9998.58145904541, "episode/length": 376.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9973474801061007, "episode/intrinsic_return": 0.0}
{"step": 323000, "time": 10009.604881763458, "episode/length": 209.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 323064, "time": 10012.041169404984, "episode/length": 168.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 323136, "time": 10014.876627206802, "episode/length": 198.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 323296, "time": 10019.75313258171, "episode/length": 379.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9921052631578947, "episode/intrinsic_return": 0.0}
{"step": 323768, "time": 10031.970276594162, "episode/length": 203.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 323912, "time": 10036.406054735184, "episode/length": 206.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 323936, "time": 10038.054433584213, "episode/length": 166.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 324232, "time": 10046.044941663742, "episode/length": 39.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 324368, "time": 10050.51078915596, "episode/length": 283.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9788732394366197, "episode/intrinsic_return": 0.0}
{"step": 324496, "time": 10054.780181884766, "episode/length": 149.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 324800, "time": 10063.155379772186, "episode/length": 216.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9815668202764977, "episode/intrinsic_return": 0.0}
{"step": 325312, "time": 10076.81909942627, "episode/length": 192.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 325520, "time": 10082.79613161087, "episode/length": 314.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9904761904761905, "episode/intrinsic_return": 0.0}
{"step": 325520, "time": 10082.820967435837, "episode/length": 297.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9966442953020134, "episode/intrinsic_return": 0.0}
{"step": 325664, "time": 10087.312664747238, "episode/length": 178.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 325688, "time": 10088.537124872208, "episode/length": 218.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 326184, "time": 10101.564966201782, "episode/length": 226.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 326256, "time": 10104.45575761795, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 326304, "time": 10106.437063217163, "episode/length": 225.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 326616, "time": 10114.85423707962, "episode/length": 162.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 326816, "time": 10120.905504226685, "episode/length": 161.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 326872, "time": 10123.027611732483, "episode/length": 168.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 327016, "time": 10127.49691414833, "episode/length": 168.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 327465, "time": 10140.301047086716, "train_stats/sum_log_reward": 5.205882298420457, "train_stats/max_log_achievement_collect_drink": 4.658823529411765, "train_stats/max_log_achievement_collect_sapling": 2.652941176470588, "train_stats/max_log_achievement_collect_stone": 0.047058823529411764, "train_stats/max_log_achievement_collect_wood": 6.8352941176470585, "train_stats/max_log_achievement_defeat_skeleton": 0.0058823529411764705, "train_stats/max_log_achievement_defeat_zombie": 0.4117647058823529, "train_stats/max_log_achievement_eat_cow": 0.07647058823529412, "train_stats/max_log_achievement_make_wood_pickaxe": 0.16470588235294117, "train_stats/max_log_achievement_make_wood_sword": 0.03529411764705882, "train_stats/max_log_achievement_place_plant": 2.458823529411765, "train_stats/max_log_achievement_place_stone": 0.011764705882352941, "train_stats/max_log_achievement_place_table": 2.9705882352941178, "train_stats/max_log_achievement_wake_up": 1.7470588235294118, "train_stats/mean_log_entropy": 0.6086646860136705, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.238122206467849, "train/action_min": 0.0, "train/action_std": 2.9769887247910867, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04502109012817247, "train/actor_opt_grad_steps": 19335.0, "train/actor_opt_loss": -3.454040020131148, "train/adv_mag": 0.6747290951987872, "train/adv_max": 0.66250107723933, "train/adv_mean": 0.0038023994881873826, "train/adv_min": -0.45303650845128757, "train/adv_std": 0.07062831273875557, "train/cont_avg": 0.9943425105168269, "train/cont_loss_mean": 0.00028556907817207824, "train/cont_loss_std": 0.008239635143442187, "train/cont_neg_acc": 0.9883653668389805, "train/cont_neg_loss": 0.03146315489874359, "train/cont_pos_acc": 0.9999621679576544, "train/cont_pos_loss": 9.063385671228893e-05, "train/cont_pred": 0.9943727337970183, "train/cont_rate": 0.9943425105168269, "train/dyn_loss_mean": 14.541007734262026, "train/dyn_loss_std": 9.278120678204756, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8945822403408014, "train/extr_critic_critic_opt_grad_steps": 19335.0, "train/extr_critic_critic_opt_loss": 15601.173959585336, "train/extr_critic_mag": 4.818233469357858, "train/extr_critic_max": 4.818233469357858, "train/extr_critic_mean": 0.9423475749790668, "train/extr_critic_min": -0.25777142437604755, "train/extr_critic_std": 1.1633041544029346, "train/extr_return_normed_mag": 1.765724615408824, "train/extr_return_normed_max": 1.765724615408824, "train/extr_return_normed_mean": 0.29224835758885515, "train/extr_return_normed_min": -0.13030592961093554, "train/extr_return_normed_std": 0.3379218867765023, "train/extr_return_rate": 0.4421155321626709, "train/extr_return_raw_mag": 6.1830162199643945, "train/extr_return_raw_max": 6.1830162199643945, "train/extr_return_raw_mean": 0.9558324441313744, "train/extr_return_raw_min": -0.5433023594892942, "train/extr_return_raw_std": 1.1990065677807882, "train/extr_reward_mag": 1.0122922074336271, "train/extr_reward_max": 1.0122922074336271, "train/extr_reward_mean": 0.026097359399920188, "train/extr_reward_min": -0.34971691553409284, "train/extr_reward_std": 0.15000448562204838, "train/image_loss_mean": 8.589531937470802, "train/image_loss_std": 11.913975559748136, "train/model_loss_mean": 17.367047305290516, "train/model_loss_std": 15.780592533258291, "train/model_opt_grad_norm": 65.42004767748026, "train/model_opt_grad_steps": 19315.24519230769, "train/model_opt_loss": 18363.771165114184, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1063.701923076923, "train/policy_entropy_mag": 2.5349393968398752, "train/policy_entropy_max": 2.5349393968398752, "train/policy_entropy_mean": 0.6641148053682767, "train/policy_entropy_min": 0.07937527831213978, "train/policy_entropy_std": 0.6192045942522012, "train/policy_logprob_mag": 7.438381763604971, "train/policy_logprob_max": -0.009455811666647116, "train/policy_logprob_mean": -0.66409255277652, "train/policy_logprob_min": -7.438381763604971, "train/policy_logprob_std": 1.17463696289521, "train/policy_randomness_mag": 0.8947223659891349, "train/policy_randomness_max": 0.8947223659891349, "train/policy_randomness_mean": 0.23440338355990556, "train/policy_randomness_min": 0.028015990078879092, "train/policy_randomness_std": 0.21855204817480767, "train/post_ent_mag": 57.63396708781902, "train/post_ent_max": 57.63396708781902, "train/post_ent_mean": 39.63381250088032, "train/post_ent_min": 21.28985636967879, "train/post_ent_std": 6.999315896859536, "train/prior_ent_mag": 66.35295108648447, "train/prior_ent_max": 66.35295108648447, "train/prior_ent_mean": 54.26442944086515, "train/prior_ent_min": 36.514867608363815, "train/prior_ent_std": 5.152162937017588, "train/rep_loss_mean": 14.541007734262026, "train/rep_loss_std": 9.278120678204756, "train/reward_avg": 0.021030836653573297, "train/reward_loss_mean": 0.052625154583858184, "train/reward_loss_std": 0.24985965649382427, "train/reward_max_data": 1.0100961562532644, "train/reward_max_pred": 1.005191014936337, "train/reward_neg_acc": 0.9933768542340169, "train/reward_neg_loss": 0.030329161896728553, "train/reward_pos_acc": 0.9611685814765784, "train/reward_pos_loss": 0.8914793930374659, "train/reward_pred": 0.020389452093065932, "train/reward_rate": 0.026015061598557692, "eval_stats/sum_log_reward": 5.0583332777023315, "eval_stats/max_log_achievement_collect_drink": 4.875, "eval_stats/max_log_achievement_collect_sapling": 1.6666666666666667, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 8.208333333333334, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.25, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.041666666666666664, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 1.5, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 3.4583333333333335, "eval_stats/max_log_achievement_wake_up": 1.7916666666666667, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 1.775467535480857e-05, "report/cont_loss_std": 0.0003507958026602864, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00026538921520113945, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 1.6783556930022314e-05, "report/cont_pred": 0.9960781335830688, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 13.348456382751465, "report/dyn_loss_std": 9.22224235534668, "report/image_loss_mean": 8.62365436553955, "report/image_loss_std": 13.747692108154297, "report/model_loss_mean": 16.672117233276367, "report/model_loss_std": 17.588537216186523, "report/post_ent_mag": 59.00221252441406, "report/post_ent_max": 59.00221252441406, "report/post_ent_mean": 40.90775680541992, "report/post_ent_min": 20.394943237304688, "report/post_ent_std": 7.800389289855957, "report/prior_ent_mag": 66.772705078125, "report/prior_ent_max": 66.772705078125, "report/prior_ent_mean": 55.129364013671875, "report/prior_ent_min": 38.82766342163086, "report/prior_ent_std": 5.063814163208008, "report/rep_loss_mean": 13.348456382751465, "report/rep_loss_std": 9.22224235534668, "report/reward_avg": 0.015429687686264515, "report/reward_loss_mean": 0.03937327116727829, "report/reward_loss_std": 0.1920100450515747, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0011131763458252, "report/reward_neg_acc": 0.9960159659385681, "report/reward_neg_loss": 0.02284596674144268, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.8690441250801086, "report/reward_pred": 0.013658015988767147, "report/reward_rate": 0.01953125, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 6.841513095423579e-05, "eval/cont_loss_std": 0.0021116407588124275, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 2.1844476577825844e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 6.855196261312813e-05, "eval/cont_pred": 0.9970042705535889, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 19.62063217163086, "eval/dyn_loss_std": 11.30846881866455, "eval/image_loss_mean": 27.194177627563477, "eval/image_loss_std": 33.906471252441406, "eval/model_loss_mean": 39.052825927734375, "eval/model_loss_std": 38.56501770019531, "eval/post_ent_mag": 56.54623031616211, "eval/post_ent_max": 56.54623031616211, "eval/post_ent_mean": 39.978912353515625, "eval/post_ent_min": 21.27691078186035, "eval/post_ent_std": 6.924705982208252, "eval/prior_ent_mag": 66.772705078125, "eval/prior_ent_max": 66.772705078125, "eval/prior_ent_mean": 56.64576721191406, "eval/prior_ent_min": 40.04337692260742, "eval/prior_ent_std": 4.919285297393799, "eval/rep_loss_mean": 19.62063217163086, "eval/rep_loss_std": 11.30846881866455, "eval/reward_avg": 0.01669921912252903, "eval/reward_loss_mean": 0.08620250225067139, "eval/reward_loss_std": 0.5771346688270569, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.002507209777832, "eval/reward_neg_acc": 0.9940119981765747, "eval/reward_neg_loss": 0.0410153903067112, "eval/reward_pos_acc": 0.8181818723678589, "eval/reward_pos_loss": 2.144270420074463, "eval/reward_pred": 0.014320947229862213, "eval/reward_rate": 0.021484375, "replay/size": 326961.0, "replay/inserts": 33200.0, "replay/samples": 33200.0, "replay/insert_wait_avg": 1.2063333787113787e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 5.640035652252565e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 62456.0, "eval_replay/inserts": 5544.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1948021975430576e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 6.854534149169922e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3969790935516, "timer/env.step_count": 4150.0, "timer/env.step_total": 154.5456600189209, "timer/env.step_frac": 0.15448433296845115, "timer/env.step_avg": 0.037239918076848406, "timer/env.step_min": 0.002294778823852539, "timer/env.step_max": 0.9452335834503174, "timer/replay._sample_count": 33200.0, "timer/replay._sample_total": 2942.3943948745728, "timer/replay._sample_frac": 2.9412267893298147, "timer/replay._sample_avg": 0.08862633719501725, "timer/replay._sample_min": 0.0003695487976074219, "timer/replay._sample_max": 0.1253654956817627, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4843.0, "timer/agent.policy_total": 48.27063608169556, "timer/agent.policy_frac": 0.04825148125240545, "timer/agent.policy_avg": 0.009967093966899763, "timer/agent.policy_min": 0.007766008377075195, "timer/agent.policy_max": 0.049573659896850586, "timer/dataset_train_count": 2075.0, "timer/dataset_train_total": 0.16512107849121094, "timer/dataset_train_frac": 0.00016505555488664637, "timer/dataset_train_avg": 7.957642336925828e-05, "timer/dataset_train_min": 6.079673767089844e-05, "timer/dataset_train_max": 0.0001800060272216797, "timer/agent.train_count": 2075.0, "timer/agent.train_total": 765.0285401344299, "timer/agent.train_frac": 0.7647249603128686, "timer/agent.train_avg": 0.3686884530768337, "timer/agent.train_min": 0.34873247146606445, "timer/agent.train_max": 0.5833549499511719, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.40779829025268555, "timer/agent.report_frac": 0.0004076364670974786, "timer/agent.report_avg": 0.20389914512634277, "timer/agent.report_min": 0.20318818092346191, "timer/agent.report_max": 0.20461010932922363, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.528594970703125e-05, "timer/dataset_eval_frac": 3.5271947481292326e-08, "timer/dataset_eval_avg": 3.528594970703125e-05, "timer/dataset_eval_min": 3.528594970703125e-05, "timer/dataset_eval_max": 3.528594970703125e-05, "fps": 33.18638420361119}
{"step": 327488, "time": 10140.744274377823, "episode/length": 224.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 327496, "time": 10143.165872097015, "episode/length": 154.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 327832, "time": 10152.482062578201, "episode/length": 41.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 328136, "time": 10161.027277469635, "episode/length": 243.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 328168, "time": 10162.726596593857, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 328280, "time": 10166.400874137878, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 328456, "time": 10171.483105182648, "episode/length": 204.0, "episode/score": 6.100000016391277, "episode/reward_rate": 0.9853658536585366, "episode/intrinsic_return": 0.0}
{"step": 328576, "time": 10175.578085899353, "episode/length": 283.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9964788732394366, "episode/intrinsic_return": 0.0}
{"step": 328840, "time": 10182.7708568573, "episode/length": 277.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9748201438848921, "episode/intrinsic_return": 0.0}
{"step": 329120, "time": 10190.806025743484, "episode/length": 203.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 329184, "time": 10193.223014593124, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 329296, "time": 10196.908861637115, "episode/length": 144.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9724137931034482, "episode/intrinsic_return": 0.0}
{"step": 329784, "time": 10209.727492570877, "episode/length": 201.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 329888, "time": 10213.281351804733, "episode/length": 200.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 330008, "time": 10216.94218635559, "episode/length": 178.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 330096, "time": 10221.665291547775, "eval_episode/length": 32.0, "eval_episode/score": 1.0999999716877937, "eval_episode/reward_rate": 0.9696969696969697}
{"step": 330096, "time": 10222.595814943314, "eval_episode/length": 38.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 330096, "time": 10225.439825296402, "eval_episode/length": 153.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.974025974025974}
{"step": 330096, "time": 10226.499518871307, "eval_episode/length": 162.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9693251533742331}
{"step": 330096, "time": 10227.525933027267, "eval_episode/length": 170.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9766081871345029}
{"step": 330096, "time": 10227.551364421844, "eval_episode/length": 170.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9941520467836257}
{"step": 330096, "time": 10228.528118371964, "eval_episode/length": 175.0, "eval_episode/score": 4.099999979138374, "eval_episode/reward_rate": 0.9943181818181818}
{"step": 330096, "time": 10229.986872196198, "eval_episode/length": 169.0, "eval_episode/score": 6.099999979138374, "eval_episode/reward_rate": 0.9823529411764705}
{"step": 330416, "time": 10238.128317832947, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 330584, "time": 10243.101384401321, "episode/length": 174.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 330832, "time": 10250.363720417023, "episode/length": 191.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 330912, "time": 10253.280616044998, "episode/length": 258.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9768339768339769, "episode/intrinsic_return": 0.0}
{"step": 331160, "time": 10260.256698131561, "episode/length": 143.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9583333333333334, "episode/intrinsic_return": 0.0}
{"step": 331408, "time": 10267.43334031105, "episode/length": 202.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 331512, "time": 10270.669880867004, "episode/length": 202.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9802955665024631, "episode/intrinsic_return": 0.0}
{"step": 331672, "time": 10275.497392177582, "episode/length": 401.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 331760, "time": 10278.844684362411, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 332208, "time": 10290.651807069778, "episode/length": 202.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 332424, "time": 10296.716900348663, "episode/length": 157.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 332448, "time": 10298.35597872734, "episode/length": 201.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 332584, "time": 10302.359471082687, "episode/length": 208.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 332728, "time": 10307.050256490707, "episode/length": 164.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 333080, "time": 10316.62614941597, "episode/length": 195.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 333192, "time": 10320.176348924637, "episode/length": 178.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 333440, "time": 10327.42266535759, "episode/length": 153.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 333840, "time": 10338.288330554962, "episode/length": 270.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.974169741697417, "episode/intrinsic_return": 0.0}
{"step": 333864, "time": 10339.573119878769, "episode/length": 159.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 333936, "time": 10342.391558885574, "episode/length": 185.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 334184, "time": 10349.221665382385, "episode/length": 219.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9727272727272728, "episode/intrinsic_return": 0.0}
{"step": 334216, "time": 10350.889680862427, "episode/length": 43.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 334256, "time": 10352.97316455841, "episode/length": 190.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 334352, "time": 10356.193835258484, "episode/length": 144.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 334712, "time": 10365.893940448761, "episode/length": 203.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 334800, "time": 10369.151149988174, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 335608, "time": 10389.751713514328, "episode/length": 220.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 335640, "time": 10391.415984630585, "episode/length": 212.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 335712, "time": 10394.257478237152, "episode/length": 186.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 335784, "time": 10396.673672676086, "episode/length": 178.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 335928, "time": 10401.194035768509, "episode/length": 208.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 336040, "time": 10405.060574531555, "episode/length": 165.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 336048, "time": 10406.277371883392, "episode/length": 41.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 336104, "time": 10408.30217909813, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 336368, "time": 10415.9169485569, "episode/length": 272.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 337104, "time": 10434.993376255035, "episode/length": 164.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 337152, "time": 10437.03992342949, "episode/length": 192.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 337232, "time": 10439.924869775772, "episode/length": 162.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 337424, "time": 10445.585731267929, "episode/length": 222.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 337448, "time": 10446.809248685837, "episode/length": 175.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 337512, "time": 10449.31453537941, "episode/length": 175.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 337584, "time": 10452.113408327103, "episode/length": 151.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 337592, "time": 10452.99324631691, "episode/length": 192.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9689119170984456, "episode/intrinsic_return": 0.0}
{"step": 338016, "time": 10464.58208155632, "episode/length": 53.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 338384, "time": 10474.79720377922, "episode/length": 153.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9545454545454546, "episode/intrinsic_return": 0.0}
{"step": 338552, "time": 10479.64331126213, "episode/length": 180.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 338776, "time": 10485.985127449036, "episode/length": 192.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 338872, "time": 10489.134966373444, "episode/length": 177.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 339040, "time": 10494.25485420227, "episode/length": 180.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 339144, "time": 10497.572251081467, "episode/length": 203.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 339344, "time": 10503.556256771088, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 339368, "time": 10504.826465845108, "episode/length": 242.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9958847736625515, "episode/intrinsic_return": 0.0}
{"step": 339664, "time": 10513.093817710876, "episode/length": 159.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 340056, "time": 10523.58356666565, "episode/length": 187.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 340080, "time": 10528.726217031479, "eval_episode/length": 156.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9936305732484076}
{"step": 340080, "time": 10529.651426553726, "eval_episode/length": 161.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9938271604938271}
{"step": 340080, "time": 10530.570144414902, "eval_episode/length": 168.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9644970414201184}
{"step": 340080, "time": 10531.546831607819, "eval_episode/length": 177.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9719101123595506}
{"step": 340080, "time": 10532.834770441055, "eval_episode/length": 201.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9702970297029703}
{"step": 340080, "time": 10533.733876466751, "eval_episode/length": 206.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9951690821256038}
{"step": 340080, "time": 10533.759689331055, "eval_episode/length": 206.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9758454106280193}
{"step": 340080, "time": 10535.66958117485, "eval_episode/length": 254.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9803921568627451}
{"step": 340264, "time": 10540.270944356918, "episode/length": 185.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 340616, "time": 10549.777042627335, "episode/length": 217.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 340704, "time": 10553.006957054138, "episode/length": 194.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 340896, "time": 10558.71502161026, "episode/length": 190.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 340904, "time": 10559.55347275734, "episode/length": 194.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 340936, "time": 10561.257089138031, "episode/length": 236.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9789029535864979, "episode/intrinsic_return": 0.0}
{"step": 341120, "time": 10566.789965391159, "episode/length": 181.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 341824, "time": 10585.122440576553, "episode/length": 220.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 342008, "time": 10590.384174823761, "episode/length": 173.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 342064, "time": 10592.785237312317, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 342128, "time": 10595.232934951782, "episode/length": 232.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 342480, "time": 10604.99643778801, "episode/length": 197.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 342536, "time": 10607.036586761475, "episode/length": 176.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 342560, "time": 10608.596609830856, "episode/length": 202.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 342680, "time": 10612.221995353699, "episode/length": 221.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 343248, "time": 10627.36516737938, "episode/length": 154.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9612903225806452, "episode/intrinsic_return": 0.0}
{"step": 343360, "time": 10630.935591459274, "episode/length": 161.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 343408, "time": 10632.948551177979, "episode/length": 159.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 343488, "time": 10635.773305654526, "episode/length": 207.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 343760, "time": 10643.48582983017, "episode/length": 152.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 344056, "time": 10651.404348134995, "episode/length": 196.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9695431472081218, "episode/intrinsic_return": 0.0}
{"step": 344192, "time": 10655.80486702919, "episode/length": 203.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 344520, "time": 10664.675532341003, "episode/length": 158.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 344640, "time": 10668.779651403427, "episode/length": 244.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 344904, "time": 10676.0510866642, "episode/length": 47.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 345000, "time": 10679.289983987808, "episode/length": 204.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 345152, "time": 10684.11414217949, "episode/length": 207.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 345368, "time": 10690.405376195908, "episode/length": 45.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 345400, "time": 10692.048346996307, "episode/length": 248.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9959839357429718, "episode/intrinsic_return": 0.0}
{"step": 345544, "time": 10696.55243229866, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 346080, "time": 10711.221936941147, "episode/length": 235.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 346168, "time": 10714.14781165123, "episode/length": 190.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 346216, "time": 10716.225128412247, "episode/length": 306.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.996742671009772, "episode/intrinsic_return": 0.0}
{"step": 346336, "time": 10720.228941679, "episode/length": 178.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 346536, "time": 10725.810687541962, "episode/length": 172.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9826589595375722, "episode/intrinsic_return": 0.0}
{"step": 346800, "time": 10733.504881858826, "episode/length": 156.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 346864, "time": 10735.966364383698, "episode/length": 186.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 346872, "time": 10736.828261137009, "episode/length": 183.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 347192, "time": 10745.779576539993, "episode/length": 48.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 347384, "time": 10751.473685264587, "episode/length": 145.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.958904109589041, "episode/intrinsic_return": 0.0}
{"step": 347512, "time": 10755.583750247955, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 347544, "time": 10757.242742538452, "episode/length": 182.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 347600, "time": 10759.66771531105, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 347992, "time": 10770.054122924805, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 348048, "time": 10772.529515028, "episode/length": 146.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9523809523809523, "episode/intrinsic_return": 0.0}
{"step": 348768, "time": 10791.50628209114, "episode/length": 237.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9831932773109243, "episode/intrinsic_return": 0.0}
{"step": 348784, "time": 10792.74722313881, "episode/length": 158.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 348816, "time": 10794.388966560364, "episode/length": 178.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 348840, "time": 10795.629549264908, "episode/length": 161.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 348856, "time": 10796.905627727509, "episode/length": 156.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 348880, "time": 10798.602927684784, "episode/length": 210.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 349400, "time": 10812.520448684692, "episode/length": 168.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 350064, "time": 10833.629575252533, "eval_episode/length": 150.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9668874172185431}
{"step": 350064, "time": 10834.910989522934, "eval_episode/length": 172.0, "eval_episode/score": 7.099999979138374, "eval_episode/reward_rate": 0.976878612716763}
{"step": 350064, "time": 10835.884786128998, "eval_episode/length": 182.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9672131147540983}
{"step": 350064, "time": 10836.982388734818, "eval_episode/length": 195.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9744897959183674}
{"step": 350064, "time": 10837.982876777649, "eval_episode/length": 202.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9802955665024631}
{"step": 350064, "time": 10838.851269721985, "eval_episode/length": 204.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.975609756097561}
{"step": 350064, "time": 10839.693311691284, "eval_episode/length": 206.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9758454106280193}
{"step": 350064, "time": 10842.128384113312, "eval_episode/length": 151.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.993421052631579}
{"step": 350296, "time": 10847.73262143135, "episode/length": 176.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 350384, "time": 10851.011853218079, "episode/length": 201.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 350480, "time": 10854.310685157776, "episode/length": 211.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 350528, "time": 10856.330968856812, "episode/length": 208.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9712918660287081, "episode/intrinsic_return": 0.0}
{"step": 350592, "time": 10858.716839313507, "episode/length": 148.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9530201342281879, "episode/intrinsic_return": 0.0}
{"step": 350632, "time": 10860.387975692749, "episode/length": 329.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.996969696969697, "episode/intrinsic_return": 0.0}
{"step": 350768, "time": 10864.744768381119, "episode/length": 243.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9754098360655737, "episode/intrinsic_return": 0.0}
{"step": 351056, "time": 10872.80469417572, "episode/length": 276.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9819494584837545, "episode/intrinsic_return": 0.0}
{"step": 351680, "time": 10889.37325143814, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 351720, "time": 10891.042327404022, "episode/length": 154.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.0}
{"step": 351832, "time": 10894.619472503662, "episode/length": 154.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.0}
{"step": 351888, "time": 10897.029634952545, "episode/length": 156.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 352040, "time": 10901.46031332016, "episode/length": 188.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 352776, "time": 10920.552555322647, "episode/length": 214.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 352960, "time": 10926.306460618973, "episode/length": 159.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 353328, "time": 10936.460021972656, "episode/length": 160.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 353352, "time": 10937.703605651855, "episode/length": 182.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 353480, "time": 10941.802964687347, "episode/length": 338.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9941002949852508, "episode/intrinsic_return": 0.0}
{"step": 353744, "time": 10949.604732513428, "episode/length": 430.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9791183294663574, "episode/intrinsic_return": 0.0}
{"step": 353864, "time": 10953.28796839714, "episode/length": 47.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 353968, "time": 10956.947199344635, "episode/length": 266.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9850187265917603, "episode/intrinsic_return": 0.0}
{"step": 354032, "time": 10959.365237236023, "episode/length": 156.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9617834394904459, "episode/intrinsic_return": 0.0}
{"step": 354512, "time": 10972.19924044609, "episode/length": 193.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 354688, "time": 10977.4758913517, "episode/length": 169.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 355008, "time": 10986.44493985176, "episode/length": 142.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.986013986013986, "episode/intrinsic_return": 0.0}
{"step": 355040, "time": 10988.137637853622, "episode/length": 43.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 355080, "time": 10989.732937574387, "episode/length": 130.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9618320610687023, "episode/intrinsic_return": 0.0}
{"step": 355272, "time": 10995.438505887985, "episode/length": 443.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9797297297297297, "episode/intrinsic_return": 0.0}
{"step": 355376, "time": 10999.052748680115, "episode/length": 175.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 355728, "time": 11008.529550075531, "episode/length": 43.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 355840, "time": 11012.242060184479, "episode/length": 310.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9871382636655949, "episode/intrinsic_return": 0.0}
{"step": 356360, "time": 11026.078109264374, "episode/length": 159.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 356496, "time": 11030.516407251358, "episode/length": 181.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 356760, "time": 11037.76540350914, "episode/length": 218.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 356952, "time": 11043.315840005875, "episode/length": 152.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9738562091503268, "episode/intrinsic_return": 0.0}
{"step": 357144, "time": 11049.077662467957, "episode/length": 233.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 357256, "time": 11052.551916360855, "episode/length": 61.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9193548387096774, "episode/intrinsic_return": 0.0}
{"step": 357608, "time": 11062.161558151245, "episode/length": 386.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9870801033591732, "episode/intrinsic_return": 0.0}
{"step": 357640, "time": 11063.776316404343, "episode/length": 224.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9822222222222222, "episode/intrinsic_return": 0.0}
{"step": 357688, "time": 11065.844548463821, "episode/length": 492.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9837728194726166, "episode/intrinsic_return": 0.0}
{"step": 357824, "time": 11070.403061389923, "episode/length": 182.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 357936, "time": 11074.094886779785, "episode/length": 179.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 358480, "time": 11088.358712434769, "episode/length": 190.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 358808, "time": 11097.315707206726, "episode/length": 193.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 358808, "time": 11097.342761516571, "episode/length": 40.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 358880, "time": 11100.145567893982, "episode/length": 216.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9861751152073732, "episode/intrinsic_return": 0.0}
{"step": 359120, "time": 11107.02815246582, "episode/length": 161.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 359152, "time": 11108.641163349152, "episode/length": 42.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 359224, "time": 11111.061784744263, "episode/length": 201.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9702970297029703, "episode/intrinsic_return": 0.0}
{"step": 359336, "time": 11114.65170264244, "episode/length": 205.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 359336, "time": 11114.678154468536, "episode/length": 174.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 359520, "time": 11120.31514596939, "episode/length": 234.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 360048, "time": 11135.890158176422, "eval_episode/length": 38.0, "eval_episode/score": 2.100000001490116, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 360048, "time": 11136.820626735687, "eval_episode/length": 43.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.8863636363636364}
{"step": 360048, "time": 11138.156242132187, "eval_episode/length": 69.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9857142857142858}
{"step": 360048, "time": 11140.559255838394, "eval_episode/length": 152.0, "eval_episode/score": 5.0999999940395355, "eval_episode/reward_rate": 0.9934640522875817}
{"step": 360048, "time": 11142.153201818466, "eval_episode/length": 194.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 360048, "time": 11143.032566547394, "eval_episode/length": 195.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9693877551020408}
{"step": 360048, "time": 11143.921084880829, "eval_episode/length": 197.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9797979797979798}
{"step": 360048, "time": 11144.85673904419, "eval_episode/length": 202.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9753694581280788}
{"step": 360049, "time": 11145.593261957169, "train_stats/sum_log_reward": 5.227167566990577, "train_stats/max_log_achievement_collect_drink": 4.369942196531792, "train_stats/max_log_achievement_collect_sapling": 2.341040462427746, "train_stats/max_log_achievement_collect_stone": 0.08092485549132948, "train_stats/max_log_achievement_collect_wood": 7.069364161849711, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.23699421965317918, "train_stats/max_log_achievement_eat_cow": 0.028901734104046242, "train_stats/max_log_achievement_make_wood_pickaxe": 0.7109826589595376, "train_stats/max_log_achievement_make_wood_sword": 0.03468208092485549, "train_stats/max_log_achievement_place_plant": 2.1098265895953756, "train_stats/max_log_achievement_place_stone": 0.005780346820809248, "train_stats/max_log_achievement_place_table": 2.3236994219653178, "train_stats/max_log_achievement_wake_up": 1.5953757225433527, "train_stats/mean_log_entropy": 0.6233391094242218, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.572892513181189, "train/action_min": 0.0, "train/action_std": 3.4266078072815693, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04477664167657862, "train/actor_opt_grad_steps": 21390.0, "train/actor_opt_loss": -1.7572480210015926, "train/adv_mag": 0.6648153164997477, "train/adv_max": 0.6465640668504931, "train/adv_mean": 0.0038820372220860527, "train/adv_min": -0.47541877744820316, "train/adv_std": 0.06962898920469096, "train/cont_avg": 0.9946313115763546, "train/cont_loss_mean": 0.0001838558735675794, "train/cont_loss_std": 0.005187624563917956, "train/cont_neg_acc": 0.9958949103731239, "train/cont_neg_loss": 0.01872979893020331, "train/cont_pos_acc": 0.9999757682161378, "train/cont_pos_loss": 8.29822395981617e-05, "train/cont_pred": 0.9946337635881208, "train/cont_rate": 0.9946313115763546, "train/dyn_loss_mean": 14.514610544214108, "train/dyn_loss_std": 9.222700382101126, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8777591057598885, "train/extr_critic_critic_opt_grad_steps": 21390.0, "train/extr_critic_critic_opt_loss": 15775.541236915025, "train/extr_critic_mag": 4.950765940943375, "train/extr_critic_max": 4.950765940943375, "train/extr_critic_mean": 0.9504918977251193, "train/extr_critic_min": -0.26816963562237217, "train/extr_critic_std": 1.1668327503603668, "train/extr_return_normed_mag": 1.7613800963744741, "train/extr_return_normed_max": 1.7613800963744741, "train/extr_return_normed_mean": 0.2884896290419724, "train/extr_return_normed_min": -0.1385832241566604, "train/extr_return_normed_std": 0.3333077827844714, "train/extr_return_rate": 0.4457262381544254, "train/extr_return_raw_mag": 6.2722176777318195, "train/extr_return_raw_max": 6.2722176777318195, "train/extr_return_raw_mean": 0.9644891058870138, "train/extr_return_raw_min": -0.5746592728081595, "train/extr_return_raw_std": 1.2012259625448969, "train/extr_reward_mag": 1.01201797706153, "train/extr_reward_max": 1.01201797706153, "train/extr_reward_mean": 0.026272885441743388, "train/extr_reward_min": -0.3702025859813972, "train/extr_reward_std": 0.15012882158086804, "train/image_loss_mean": 8.437706665452477, "train/image_loss_std": 12.037704860048342, "train/model_loss_mean": 17.199304792094114, "train/model_loss_std": 15.85063949829252, "train/model_opt_grad_norm": 67.04242726969602, "train/model_opt_grad_steps": 21368.60591133005, "train/model_opt_loss": 15203.15259390394, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 886.6995073891626, "train/policy_entropy_mag": 2.5304250869844935, "train/policy_entropy_max": 2.5304250869844935, "train/policy_entropy_mean": 0.6996473527600613, "train/policy_entropy_min": 0.07937524684250648, "train/policy_entropy_std": 0.6420832264599542, "train/policy_logprob_mag": 7.438382440012664, "train/policy_logprob_max": -0.009455762441118657, "train/policy_logprob_mean": -0.6991346413866052, "train/policy_logprob_min": -7.438382440012664, "train/policy_logprob_std": 1.1892511421823737, "train/policy_randomness_mag": 0.8931290122675778, "train/policy_randomness_max": 0.8931290122675778, "train/policy_randomness_mean": 0.2469448121310455, "train/policy_randomness_min": 0.028015978753640147, "train/policy_randomness_std": 0.2266272027504268, "train/post_ent_mag": 57.9145390177008, "train/post_ent_max": 57.9145390177008, "train/post_ent_mean": 40.07188129894839, "train/post_ent_min": 21.27507873121741, "train/post_ent_std": 7.0961787735887345, "train/prior_ent_mag": 66.83703620797895, "train/prior_ent_max": 66.83703620797895, "train/prior_ent_mean": 54.63639562822915, "train/prior_ent_min": 38.18469954241673, "train/prior_ent_std": 4.969241768268529, "train/rep_loss_mean": 14.514610544214108, "train/rep_loss_std": 9.222700382101126, "train/reward_avg": 0.021006677107050502, "train/reward_loss_mean": 0.05264795452282934, "train/reward_loss_std": 0.2537770396823366, "train/reward_max_data": 1.011330051962378, "train/reward_max_pred": 1.005747928407979, "train/reward_neg_acc": 0.9933104148052009, "train/reward_neg_loss": 0.030038952327383857, "train/reward_pos_acc": 0.9561091893412209, "train/reward_pos_loss": 0.9129235312856477, "train/reward_pred": 0.02038250029032013, "train/reward_rate": 0.025910175492610838, "eval_stats/sum_log_reward": 5.006249990314245, "eval_stats/max_log_achievement_collect_drink": 2.4375, "eval_stats/max_log_achievement_collect_sapling": 1.90625, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 6.84375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.21875, "eval_stats/max_log_achievement_eat_cow": 0.15625, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.40625, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 1.78125, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.1875, "eval_stats/max_log_achievement_wake_up": 1.4375, "eval_stats/mean_log_entropy": 0.0, "eval_stats/max_log_achievement_collect_coal": 0.5, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 3.9943097362993285e-05, "report/cont_loss_std": 0.0012282619718462229, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.008157359436154366, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.1280439338179349e-07, "report/cont_pred": 0.9951561689376831, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 16.723060607910156, "report/dyn_loss_std": 8.95452880859375, "report/image_loss_mean": 9.458356857299805, "report/image_loss_std": 12.264413833618164, "report/model_loss_mean": 19.55183219909668, "report/model_loss_std": 15.97896957397461, "report/post_ent_mag": 57.894935607910156, "report/post_ent_max": 57.894935607910156, "report/post_ent_mean": 38.695465087890625, "report/post_ent_min": 20.84067153930664, "report/post_ent_std": 6.732976913452148, "report/prior_ent_mag": 67.31967163085938, "report/prior_ent_max": 67.31967163085938, "report/prior_ent_mean": 55.133121490478516, "report/prior_ent_min": 41.873565673828125, "report/prior_ent_std": 4.634294509887695, "report/rep_loss_mean": 16.723060607910156, "report/rep_loss_std": 8.95452880859375, "report/reward_avg": 0.03349609300494194, "report/reward_loss_mean": 0.0595996119081974, "report/reward_loss_std": 0.34828606247901917, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.000748872756958, "report/reward_neg_acc": 0.9949289560317993, "report/reward_neg_loss": 0.02306787669658661, "report/reward_pos_acc": 0.9210526347160339, "report/reward_pos_loss": 1.0075019598007202, "report/reward_pred": 0.030101723968982697, "report/reward_rate": 0.037109375, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 7.908688712632284e-05, "eval/cont_loss_std": 0.002482782816514373, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00024001553538255394, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 7.845579239074141e-05, "eval/cont_pred": 0.9960196018218994, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 18.27438735961914, "eval/dyn_loss_std": 10.043933868408203, "eval/image_loss_mean": 11.441828727722168, "eval/image_loss_std": 18.06840705871582, "eval/model_loss_mean": 22.48785400390625, "eval/model_loss_std": 21.488061904907227, "eval/post_ent_mag": 57.310951232910156, "eval/post_ent_max": 57.310951232910156, "eval/post_ent_mean": 38.688350677490234, "eval/post_ent_min": 22.914844512939453, "eval/post_ent_std": 6.456910133361816, "eval/prior_ent_mag": 67.31967163085938, "eval/prior_ent_max": 67.31967163085938, "eval/prior_ent_mean": 54.127952575683594, "eval/prior_ent_min": 35.409793853759766, "eval/prior_ent_std": 4.74214506149292, "eval/rep_loss_mean": 18.27438735961914, "eval/rep_loss_std": 10.043933868408203, "eval/reward_avg": 0.02031249925494194, "eval/reward_loss_mean": 0.08131344616413116, "eval/reward_loss_std": 0.46573132276535034, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0005216598510742, "eval/reward_neg_acc": 0.9929929971694946, "eval/reward_neg_loss": 0.04608648270368576, "eval/reward_pos_acc": 0.7599999904632568, "eval/reward_pos_loss": 1.4889825582504272, "eval/reward_pred": 0.013602467253804207, "eval/reward_rate": 0.0244140625, "replay/size": 359545.0, "replay/inserts": 32584.0, "replay/samples": 32576.0, "replay/insert_wait_avg": 1.2088489274910736e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 5.673858646325371e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 70216.0, "eval_replay/inserts": 7760.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.210127909158923e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 6.556510925292969e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1005.2814724445343, "timer/env.step_count": 4073.0, "timer/env.step_total": 156.8493993282318, "timer/env.step_frac": 0.15602535571139342, "timer/env.step_avg": 0.03850955053479789, "timer/env.step_min": 0.002227783203125, "timer/env.step_max": 0.93477463722229, "timer/replay._sample_count": 32576.0, "timer/replay._sample_total": 2883.672317504883, "timer/replay._sample_frac": 2.8685222960418058, "timer/replay._sample_avg": 0.08852137516898584, "timer/replay._sample_min": 0.00038504600524902344, "timer/replay._sample_max": 0.12224841117858887, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5043.0, "timer/agent.policy_total": 51.500067472457886, "timer/agent.policy_frac": 0.05122950027839031, "timer/agent.policy_avg": 0.010212188671913125, "timer/agent.policy_min": 0.0076792240142822266, "timer/agent.policy_max": 0.04969501495361328, "timer/dataset_train_count": 2036.0, "timer/dataset_train_total": 0.162886381149292, "timer/dataset_train_frac": 0.00016203062088989125, "timer/dataset_train_avg": 8.000313415977014e-05, "timer/dataset_train_min": 5.745887756347656e-05, "timer/dataset_train_max": 0.000240325927734375, "timer/agent.train_count": 2036.0, "timer/agent.train_total": 756.2597630023956, "timer/agent.train_frac": 0.7522865821483861, "timer/agent.train_avg": 0.37144389145500767, "timer/agent.train_min": 0.35161876678466797, "timer/agent.train_max": 0.6234729290008545, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.659754753112793, "timer/agent.report_frac": 0.0006562885830457743, "timer/agent.report_avg": 0.3298773765563965, "timer/agent.report_min": 0.2017378807067871, "timer/agent.report_max": 0.45801687240600586, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.552436828613281e-05, "timer/dataset_eval_frac": 3.533773302291995e-08, "timer/dataset_eval_avg": 3.552436828613281e-05, "timer/dataset_eval_min": 3.552436828613281e-05, "timer/dataset_eval_max": 3.552436828613281e-05, "fps": 32.412481691971294}
{"step": 360144, "time": 11148.032985210419, "episode/length": 123.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9516129032258065, "episode/intrinsic_return": 0.0}
{"step": 360272, "time": 11152.158634901047, "episode/length": 182.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 360472, "time": 11157.845332622528, "episode/length": 155.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 360672, "time": 11163.861688137054, "episode/length": 193.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9690721649484536, "episode/intrinsic_return": 0.0}
{"step": 360856, "time": 11169.16528058052, "episode/length": 246.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.97165991902834, "episode/intrinsic_return": 0.0}
{"step": 360856, "time": 11169.193426132202, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 360904, "time": 11171.24891114235, "episode/length": 195.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 361280, "time": 11181.56380558014, "episode/length": 125.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9603174603174603, "episode/intrinsic_return": 0.0}
{"step": 361464, "time": 11186.781800031662, "episode/length": 69.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9285714285714286, "episode/intrinsic_return": 0.0}
{"step": 361536, "time": 11189.554017066956, "episode/length": 173.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 362016, "time": 11202.24878692627, "episode/length": 334.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9880597014925373, "episode/intrinsic_return": 0.0}
{"step": 362032, "time": 11203.534011125565, "episode/length": 194.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 362032, "time": 11203.561214447021, "episode/length": 146.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9727891156462585, "episode/intrinsic_return": 0.0}
{"step": 362544, "time": 11217.229486227036, "episode/length": 210.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 362592, "time": 11219.223507165909, "episode/length": 131.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9924242424242424, "episode/intrinsic_return": 0.0}
{"step": 362624, "time": 11220.877862930298, "episode/length": 243.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 362656, "time": 11222.501829385757, "episode/length": 171.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 362856, "time": 11228.050985574722, "episode/length": 173.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 363312, "time": 11240.287184715271, "episode/length": 161.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 363448, "time": 11244.333274364471, "episode/length": 176.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9661016949152542, "episode/intrinsic_return": 0.0}
{"step": 363568, "time": 11248.339694976807, "episode/length": 88.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9438202247191011, "episode/intrinsic_return": 0.0}
{"step": 363888, "time": 11257.016535758972, "episode/length": 161.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 363936, "time": 11259.03399181366, "episode/length": 45.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 364056, "time": 11262.702768802643, "episode/length": 174.0, "episode/score": 4.099999964237213, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 364072, "time": 11263.984568119049, "episode/length": 180.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 364096, "time": 11265.621104717255, "episode/length": 193.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 364520, "time": 11276.965656042099, "episode/length": 310.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9967845659163987, "episode/intrinsic_return": 0.0}
{"step": 364864, "time": 11286.550636768341, "episode/length": 176.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.96045197740113, "episode/intrinsic_return": 0.0}
{"step": 365400, "time": 11301.48322725296, "episode/length": 182.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 365416, "time": 11302.723884344101, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9636363636363636, "episode/intrinsic_return": 0.0}
{"step": 365568, "time": 11307.50539278984, "episode/length": 188.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 365568, "time": 11307.5322265625, "episode/length": 281.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9893617021276596, "episode/intrinsic_return": 0.0}
{"step": 365648, "time": 11310.351374149323, "episode/length": 196.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 365768, "time": 11313.919088602066, "episode/length": 234.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9829787234042553, "episode/intrinsic_return": 0.0}
{"step": 365920, "time": 11318.656375408173, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 366504, "time": 11333.912947177887, "episode/length": 116.0, "episode/score": 2.100000023841858, "episode/reward_rate": 0.9914529914529915, "episode/intrinsic_return": 0.0}
{"step": 366608, "time": 11337.572935819626, "episode/length": 217.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 366744, "time": 11341.679153203964, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 366896, "time": 11346.714489459991, "episode/length": 186.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 366992, "time": 11349.847465276718, "episode/length": 177.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 367368, "time": 11359.934668302536, "episode/length": 180.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 367376, "time": 11361.19470000267, "episode/length": 200.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9651741293532339, "episode/intrinsic_return": 0.0}
{"step": 367568, "time": 11366.672001600266, "episode/length": 239.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 367696, "time": 11370.625980377197, "episode/length": 39.0, "episode/score": 3.100000023841858, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 367968, "time": 11378.294045209885, "episode/length": 182.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 368032, "time": 11380.69670009613, "episode/length": 160.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9627329192546584, "episode/intrinsic_return": 0.0}
{"step": 368256, "time": 11387.032267570496, "episode/length": 205.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 368280, "time": 11388.302824735641, "episode/length": 38.0, "episode/score": 2.100000023841858, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 368408, "time": 11392.264019966125, "episode/length": 176.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9661016949152542, "episode/intrinsic_return": 0.0}
{"step": 368888, "time": 11404.989825248718, "episode/length": 248.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9959839357429718, "episode/intrinsic_return": 0.0}
{"step": 369048, "time": 11409.860563278198, "episode/length": 168.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9644970414201184, "episode/intrinsic_return": 0.0}
{"step": 369056, "time": 11411.13527917862, "episode/length": 185.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 369392, "time": 11420.338672876358, "episode/length": 252.0, "episode/score": 6.1000000312924385, "episode/reward_rate": 0.9960474308300395, "episode/intrinsic_return": 0.0}
{"step": 369720, "time": 11429.153501033783, "episode/length": 182.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 369816, "time": 11432.365299224854, "episode/length": 191.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 369984, "time": 11437.605669736862, "episode/length": 196.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 370032, "time": 11441.648073196411, "eval_episode/length": 55.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9821428571428571}
{"step": 370032, "time": 11444.151879549026, "eval_episode/length": 152.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9673202614379085}
{"step": 370032, "time": 11445.092615365982, "eval_episode/length": 158.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9685534591194969}
{"step": 370032, "time": 11445.120033502579, "eval_episode/length": 158.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9685534591194969}
{"step": 370032, "time": 11446.124541044235, "eval_episode/length": 167.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9702380952380952}
{"step": 370032, "time": 11447.189466714859, "eval_episode/length": 177.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9719101123595506}
{"step": 370032, "time": 11448.128812074661, "eval_episode/length": 181.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.967032967032967}
{"step": 370032, "time": 11449.861314296722, "eval_episode/length": 228.0, "eval_episode/score": 6.099999979138374, "eval_episode/reward_rate": 0.9956331877729258}
{"step": 370040, "time": 11449.891894102097, "episode/length": 250.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9800796812749004, "episode/intrinsic_return": 0.0}
{"step": 370632, "time": 11465.960162639618, "episode/length": 197.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 370664, "time": 11467.64197897911, "episode/length": 200.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 370760, "time": 11470.816744327545, "episode/length": 233.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9786324786324786, "episode/intrinsic_return": 0.0}
{"step": 370952, "time": 11476.497710943222, "episode/length": 153.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 371224, "time": 11484.140252828598, "episode/length": 228.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.982532751091703, "episode/intrinsic_return": 0.0}
{"step": 371368, "time": 11488.610573291779, "episode/length": 193.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 371400, "time": 11490.262219429016, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 371696, "time": 11498.698395490646, "episode/length": 213.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 371760, "time": 11501.172566890717, "episode/length": 44.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 372056, "time": 11509.273231744766, "episode/length": 44.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 372112, "time": 11511.830332994461, "episode/length": 180.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 372248, "time": 11515.89461183548, "episode/length": 185.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 372304, "time": 11518.290593624115, "episode/length": 168.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 372416, "time": 11521.810830831528, "episode/length": 222.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 372664, "time": 11528.656903982162, "episode/length": 179.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 372904, "time": 11535.611330032349, "episode/length": 142.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.965034965034965, "episode/intrinsic_return": 0.0}
{"step": 372944, "time": 11537.638782024384, "episode/length": 196.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 373360, "time": 11548.841841220856, "episode/length": 162.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 373552, "time": 11554.452465295792, "episode/length": 179.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 373704, "time": 11558.88694524765, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 373976, "time": 11566.515974283218, "episode/length": 194.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9641025641025641, "episode/intrinsic_return": 0.0}
{"step": 374120, "time": 11571.019116640091, "episode/length": 233.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 374224, "time": 11574.599897384644, "episode/length": 194.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 374296, "time": 11577.101336956024, "episode/length": 168.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 374392, "time": 11580.38785624504, "episode/length": 33.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 374440, "time": 11582.39917254448, "episode/length": 191.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 374512, "time": 11585.203640460968, "episode/length": 143.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9583333333333334, "episode/intrinsic_return": 0.0}
{"step": 375072, "time": 11600.108032941818, "episode/length": 189.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 375160, "time": 11602.87589430809, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 375520, "time": 11612.876405239105, "episode/length": 161.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 375608, "time": 11615.790048360825, "episode/length": 203.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 375856, "time": 11623.03658914566, "episode/length": 167.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 376112, "time": 11630.212388515472, "episode/length": 214.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9720930232558139, "episode/intrinsic_return": 0.0}
{"step": 376152, "time": 11631.937936782837, "episode/length": 231.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.978448275862069, "episode/intrinsic_return": 0.0}
{"step": 376152, "time": 11631.965617895126, "episode/length": 213.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9672897196261683, "episode/intrinsic_return": 0.0}
{"step": 376488, "time": 11641.297002077103, "episode/length": 176.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 377064, "time": 11656.692904233932, "episode/length": 192.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9689119170984456, "episode/intrinsic_return": 0.0}
{"step": 377160, "time": 11659.915278673172, "episode/length": 249.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.972, "episode/intrinsic_return": 0.0}
{"step": 377184, "time": 11661.516377925873, "episode/length": 165.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 377232, "time": 11663.589757204056, "episode/length": 202.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 377440, "time": 11669.634686946869, "episode/length": 160.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 377480, "time": 11671.328221082687, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 377752, "time": 11678.842862129211, "episode/length": 204.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9658536585365853, "episode/intrinsic_return": 0.0}
{"step": 378264, "time": 11692.485020637512, "episode/length": 221.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 378472, "time": 11698.713807821274, "episode/length": 163.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 378680, "time": 11704.996134519577, "episode/length": 51.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 378792, "time": 11708.722007274628, "episode/length": 194.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 378848, "time": 11711.263932228088, "episode/length": 170.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 378904, "time": 11713.3098154068, "episode/length": 182.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 378992, "time": 11716.608058214188, "episode/length": 240.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.983402489626556, "episode/intrinsic_return": 0.0}
{"step": 379008, "time": 11717.899225234985, "episode/length": 156.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9554140127388535, "episode/intrinsic_return": 0.0}
{"step": 379128, "time": 11721.734855175018, "episode/length": 55.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 379360, "time": 11728.717243671417, "episode/length": 271.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9852941176470589, "episode/intrinsic_return": 0.0}
{"step": 379592, "time": 11735.40990781784, "episode/length": 139.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.0}
{"step": 380016, "time": 11750.744929552078, "eval_episode/length": 175.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9715909090909091}
{"step": 380016, "time": 11752.179169178009, "eval_episode/length": 207.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9759615384615384}
{"step": 380016, "time": 11753.195024251938, "eval_episode/length": 217.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9954128440366973}
{"step": 380016, "time": 11754.242648601532, "eval_episode/length": 226.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.986784140969163}
{"step": 380016, "time": 11755.130805969238, "eval_episode/length": 228.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9956331877729258}
{"step": 380016, "time": 11756.075740098953, "eval_episode/length": 234.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9787234042553191}
{"step": 380016, "time": 11756.965313911438, "eval_episode/length": 235.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9788135593220338}
{"step": 380016, "time": 11758.930085420609, "eval_episode/length": 303.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9868421052631579}
{"step": 380496, "time": 11771.037488937378, "episode/length": 198.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9899497487437185, "episode/intrinsic_return": 0.0}
{"step": 380520, "time": 11772.315498113632, "episode/length": 188.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 380816, "time": 11780.869705677032, "episode/length": 227.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 380824, "time": 11781.810241222382, "episode/length": 211.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 380928, "time": 11785.575434207916, "episode/length": 195.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9693877551020408, "episode/intrinsic_return": 0.0}
{"step": 381320, "time": 11796.114071369171, "episode/length": 308.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9838187702265372, "episode/intrinsic_return": 0.0}
{"step": 381328, "time": 11797.3406021595, "episode/length": 216.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 381624, "time": 11805.326389789581, "episode/length": 140.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9645390070921985, "episode/intrinsic_return": 0.0}
{"step": 382088, "time": 11817.782878637314, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 382136, "time": 11819.833648204803, "episode/length": 201.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 382416, "time": 11827.94052863121, "episode/length": 452.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9801324503311258, "episode/intrinsic_return": 0.0}
{"step": 382584, "time": 11832.736358880997, "episode/length": 157.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 382608, "time": 11834.375917434692, "episode/length": 223.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 382768, "time": 11839.205836772919, "episode/length": 179.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 382848, "time": 11842.003093719482, "episode/length": 152.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 382960, "time": 11845.564374923706, "episode/length": 253.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9960629921259843, "episode/intrinsic_return": 0.0}
{"step": 383456, "time": 11858.68832039833, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9649122807017544, "episode/intrinsic_return": 0.0}
{"step": 383800, "time": 11867.940467596054, "episode/length": 207.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 384072, "time": 11875.365074157715, "episode/length": 206.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 384120, "time": 11877.392647504807, "episode/length": 158.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 384224, "time": 11880.99904680252, "episode/length": 181.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 384336, "time": 11884.624388217926, "episode/length": 218.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 384368, "time": 11886.25002336502, "episode/length": 219.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 384376, "time": 11887.10484623909, "episode/length": 37.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 384568, "time": 11892.719801902771, "episode/length": 200.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 384864, "time": 11901.122774362564, "episode/length": 175.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 384992, "time": 11905.188858270645, "episode/length": 148.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 385392, "time": 11916.219586372375, "episode/length": 158.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 385496, "time": 11919.432143449783, "episode/length": 144.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 385528, "time": 11921.107575893402, "episode/length": 162.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9631901840490797, "episode/intrinsic_return": 0.0}
{"step": 386072, "time": 11935.353682279587, "episode/length": 211.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 386376, "time": 11943.738916873932, "episode/length": 225.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9778761061946902, "episode/intrinsic_return": 0.0}
{"step": 386432, "time": 11946.17512345314, "episode/length": 179.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 386792, "time": 11955.823551177979, "episode/length": 240.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.995850622406639, "episode/intrinsic_return": 0.0}
{"step": 387088, "time": 11964.329203605652, "episode/length": 194.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 387088, "time": 11964.341760873795, "episode/length": 211.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 387152, "time": 11966.933688402176, "episode/length": 206.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 387704, "time": 11981.257197380066, "episode/length": 203.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 387832, "time": 11985.42043352127, "episode/length": 432.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9953810623556582, "episode/intrinsic_return": 0.0}
{"step": 387976, "time": 11989.842542409897, "episode/length": 192.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 388288, "time": 11998.663759231567, "episode/length": 238.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.0}
{"step": 388328, "time": 12000.35254740715, "episode/length": 154.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 388896, "time": 12015.741386890411, "episode/length": 217.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9724770642201835, "episode/intrinsic_return": 0.0}
{"step": 389200, "time": 12024.347023487091, "episode/length": 300.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9966777408637874, "episode/intrinsic_return": 0.0}
{"step": 389256, "time": 12026.442246437073, "episode/length": 193.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 389424, "time": 12031.59803724289, "episode/length": 198.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 389488, "time": 12033.97774028778, "episode/length": 188.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9682539682539683, "episode/intrinsic_return": 0.0}
{"step": 389864, "time": 12044.205517292023, "episode/length": 191.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 389904, "time": 12046.242631673813, "episode/length": 201.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 389960, "time": 12048.18211722374, "episode/length": 358.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9944289693593314, "episode/intrinsic_return": 0.0}
{"step": 390000, "time": 12052.011277198792, "eval_episode/length": 59.0, "eval_episode/score": 4.100000023841858, "eval_episode/reward_rate": 0.9833333333333333}
{"step": 390000, "time": 12054.659984588623, "eval_episode/length": 164.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9636363636363636}
{"step": 390000, "time": 12055.7198741436, "eval_episode/length": 176.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9774011299435028}
{"step": 390000, "time": 12056.552737951279, "eval_episode/length": 177.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9943820224719101}
{"step": 390000, "time": 12057.450801372528, "eval_episode/length": 180.0, "eval_episode/score": 6.0999999940395355, "eval_episode/reward_rate": 0.994475138121547}
{"step": 390000, "time": 12058.420686244965, "eval_episode/length": 189.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9947368421052631}
{"step": 390000, "time": 12059.350600242615, "eval_episode/length": 195.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9744897959183674}
{"step": 390000, "time": 12060.326902627945, "eval_episode/length": 203.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9705882352941176}
{"step": 390360, "time": 12069.379691362381, "episode/length": 61.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.0}
{"step": 390776, "time": 12080.618814945221, "episode/length": 234.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 390864, "time": 12083.832552909851, "episode/length": 200.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9850746268656716, "episode/intrinsic_return": 0.0}
{"step": 390888, "time": 12085.046892166138, "episode/length": 182.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 390896, "time": 12086.330926179886, "episode/length": 211.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 390904, "time": 12087.165043830872, "episode/length": 176.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 391208, "time": 12095.670171499252, "episode/length": 162.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9815950920245399, "episode/intrinsic_return": 0.0}
{"step": 391624, "time": 12106.688885450363, "episode/length": 157.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9620253164556962, "episode/intrinsic_return": 0.0}
{"step": 391624, "time": 12106.7181494236, "episode/length": 207.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 392208, "time": 12122.573296070099, "episode/length": 178.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9608938547486033, "episode/intrinsic_return": 0.0}
{"step": 392352, "time": 12127.150182723999, "episode/length": 181.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 392368, "time": 12128.38123011589, "episode/length": 182.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9672131147540983, "episode/intrinsic_return": 0.0}
{"step": 392424, "time": 12130.412847995758, "episode/length": 194.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 392592, "time": 12135.523152589798, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 392720, "time": 12139.63196516037, "episode/length": 228.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 392856, "time": 12143.614315509796, "episode/length": 62.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9841269841269841, "episode/intrinsic_return": 0.0}
{"step": 392873, "time": 12145.666669130325, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.5010498046875, "train/action_min": 0.0, "train/action_std": 3.343089721261001, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04336105528764608, "train/actor_opt_grad_steps": 23430.0, "train/actor_opt_loss": -6.19824110062384, "train/adv_mag": 0.6584001779556274, "train/adv_max": 0.638911372423172, "train/adv_mean": 0.0030735725035611256, "train/adv_min": -0.4573693162057458, "train/adv_std": 0.0676173845078887, "train/cont_avg": 0.9945693597560976, "train/cont_loss_mean": 0.0002808420890334019, "train/cont_loss_std": 0.008568183432249143, "train/cont_neg_acc": 0.9911531300521365, "train/cont_neg_loss": 0.03208718376302332, "train/cont_pos_acc": 0.9999664486908331, "train/cont_pos_loss": 9.180445174884775e-05, "train/cont_pred": 0.9945771406336529, "train/cont_rate": 0.9945693597560976, "train/dyn_loss_mean": 14.215999259018316, "train/dyn_loss_std": 9.206834386034709, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8457291742650473, "train/extr_critic_critic_opt_grad_steps": 23430.0, "train/extr_critic_critic_opt_loss": 15514.708374618902, "train/extr_critic_mag": 5.21383028262999, "train/extr_critic_max": 5.21383028262999, "train/extr_critic_mean": 1.0327993805815534, "train/extr_critic_min": -0.2822210015320196, "train/extr_critic_std": 1.2132507344571555, "train/extr_return_normed_mag": 1.7619123173923028, "train/extr_return_normed_max": 1.7619123173923028, "train/extr_return_normed_mean": 0.30239459814094916, "train/extr_return_normed_min": -0.13033280599771477, "train/extr_return_normed_std": 0.3342382195519238, "train/extr_return_rate": 0.48822792259658254, "train/extr_return_raw_mag": 6.484712330887957, "train/extr_return_raw_max": 6.484712330887957, "train/extr_return_raw_mean": 1.0442573827941244, "train/extr_return_raw_min": -0.5687143562770471, "train/extr_return_raw_std": 1.2460655744482831, "train/extr_reward_mag": 1.0107083716043612, "train/extr_reward_max": 1.0107083716043612, "train/extr_reward_mean": 0.026967353764467124, "train/extr_reward_min": -0.34184217976360787, "train/extr_reward_std": 0.15268820382472945, "train/image_loss_mean": 7.924469780340427, "train/image_loss_std": 11.582840426375226, "train/model_loss_mean": 16.50583212782697, "train/model_loss_std": 15.389464252751049, "train/model_opt_grad_norm": 57.96119429425495, "train/model_opt_grad_steps": 23407.434146341464, "train/model_opt_loss": 14471.459203506098, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 884.1463414634146, "train/policy_entropy_mag": 2.4992564829384407, "train/policy_entropy_max": 2.4992564829384407, "train/policy_entropy_mean": 0.647817693105558, "train/policy_entropy_min": 0.07937522479673711, "train/policy_entropy_std": 0.6046142310630984, "train/policy_logprob_mag": 7.438382709317091, "train/policy_logprob_max": -0.009455757379168418, "train/policy_logprob_mean": -0.6475867274330883, "train/policy_logprob_min": -7.438382709317091, "train/policy_logprob_std": 1.1500332361314354, "train/policy_randomness_mag": 0.882127861278813, "train/policy_randomness_max": 0.882127861278813, "train/policy_randomness_mean": 0.22865121887951362, "train/policy_randomness_min": 0.028015970765817456, "train/policy_randomness_std": 0.21340229184162327, "train/post_ent_mag": 57.85815902337795, "train/post_ent_max": 57.85815902337795, "train/post_ent_mean": 40.52283965320122, "train/post_ent_min": 21.089765781309545, "train/post_ent_std": 7.153228236407768, "train/prior_ent_mag": 67.07845600407298, "train/prior_ent_max": 67.07845600407298, "train/prior_ent_mean": 54.795727576279056, "train/prior_ent_min": 39.362830055050736, "train/prior_ent_std": 4.7847867779615445, "train/rep_loss_mean": 14.215999259018316, "train/rep_loss_std": 9.206834386034709, "train/reward_avg": 0.021451028793050747, "train/reward_loss_mean": 0.051481963648665245, "train/reward_loss_std": 0.24756853231569617, "train/reward_max_data": 1.00926829489266, "train/reward_max_pred": 1.0061279122422382, "train/reward_neg_acc": 0.9940513488723011, "train/reward_neg_loss": 0.029092236435631427, "train/reward_pos_acc": 0.9590061176113966, "train/reward_pos_loss": 0.8862435730492196, "train/reward_pred": 0.020801734224688714, "train/reward_rate": 0.02630049542682927, "train_stats/sum_log_reward": 5.5293784653399625, "train_stats/max_log_achievement_collect_coal": 0.06779661016949153, "train_stats/max_log_achievement_collect_drink": 4.169491525423729, "train_stats/max_log_achievement_collect_sapling": 2.1638418079096047, "train_stats/max_log_achievement_collect_stone": 0.3954802259887006, "train_stats/max_log_achievement_collect_wood": 8.090395480225988, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.2768361581920904, "train_stats/max_log_achievement_eat_cow": 0.05649717514124294, "train_stats/max_log_achievement_make_wood_pickaxe": 1.0564971751412429, "train_stats/max_log_achievement_make_wood_sword": 0.022598870056497175, "train_stats/max_log_achievement_place_plant": 2.0, "train_stats/max_log_achievement_place_stone": 0.05084745762711865, "train_stats/max_log_achievement_place_table": 2.5819209039548023, "train_stats/max_log_achievement_wake_up": 1.4406779661016949, "train_stats/mean_log_entropy": 0.5786293197823109, "eval_stats/sum_log_reward": 6.058333297570546, "eval_stats/max_log_achievement_collect_coal": 0.125, "eval_stats/max_log_achievement_collect_drink": 3.375, "eval_stats/max_log_achievement_collect_sapling": 2.0, "eval_stats/max_log_achievement_collect_stone": 0.5416666666666666, "eval_stats/max_log_achievement_collect_wood": 8.958333333333334, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.375, "eval_stats/max_log_achievement_eat_cow": 0.041666666666666664, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.4583333333333333, "eval_stats/max_log_achievement_make_wood_sword": 0.041666666666666664, "eval_stats/max_log_achievement_place_plant": 1.8333333333333333, "eval_stats/max_log_achievement_place_stone": 0.2916666666666667, "eval_stats/max_log_achievement_place_table": 2.6666666666666665, "eval_stats/max_log_achievement_wake_up": 1.5, "eval_stats/mean_log_entropy": 0.0, "train_stats/max_log_achievement_place_furnace": 0.012048192771084338, "eval_stats/max_log_achievement_place_furnace": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 5.471062468132004e-05, "report/cont_loss_std": 0.001019862713292241, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0012364963768050075, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 4.8911868361756206e-05, "report/cont_pred": 0.9950750470161438, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 13.375137329101562, "report/dyn_loss_std": 8.992401123046875, "report/image_loss_mean": 6.89128303527832, "report/image_loss_std": 11.594758033752441, "report/model_loss_mean": 14.974020004272461, "report/model_loss_std": 15.446700096130371, "report/post_ent_mag": 56.55522537231445, "report/post_ent_max": 56.55522537231445, "report/post_ent_mean": 41.1063232421875, "report/post_ent_min": 22.20398712158203, "report/post_ent_std": 7.128396987915039, "report/prior_ent_mag": 67.73055267333984, "report/prior_ent_max": 67.73055267333984, "report/prior_ent_mean": 55.351993560791016, "report/prior_ent_min": 40.48344802856445, "report/prior_ent_std": 4.356823921203613, "report/rep_loss_mean": 13.375137329101562, "report/rep_loss_std": 8.992401123046875, "report/reward_avg": 0.01669921912252903, "report/reward_loss_mean": 0.05760005861520767, "report/reward_loss_std": 0.23971691727638245, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.001387119293213, "report/reward_neg_acc": 0.9860139489173889, "report/reward_neg_loss": 0.041254229843616486, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7689986824989319, "report/reward_pred": 0.017709355801343918, "report/reward_rate": 0.0224609375, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 2.2573552996618673e-05, "eval/cont_loss_std": 0.0006656418554484844, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.01071733608841896, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.6444734001197503e-06, "eval/cont_pred": 0.9980658888816833, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 16.20283317565918, "eval/dyn_loss_std": 10.652373313903809, "eval/image_loss_mean": 11.781064987182617, "eval/image_loss_std": 18.46405601501465, "eval/model_loss_mean": 21.56484031677246, "eval/model_loss_std": 22.9310359954834, "eval/post_ent_mag": 57.52680969238281, "eval/post_ent_max": 57.52680969238281, "eval/post_ent_mean": 41.05038070678711, "eval/post_ent_min": 22.276519775390625, "eval/post_ent_std": 6.769387722015381, "eval/prior_ent_mag": 67.73055267333984, "eval/prior_ent_max": 67.73055267333984, "eval/prior_ent_mean": 55.27763366699219, "eval/prior_ent_min": 39.30107116699219, "eval/prior_ent_std": 5.185267448425293, "eval/rep_loss_mean": 16.20283317565918, "eval/rep_loss_std": 10.652373313903809, "eval/reward_avg": 0.02294921875, "eval/reward_loss_mean": 0.06205201894044876, "eval/reward_loss_std": 0.4910190999507904, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0018117427825928, "eval/reward_neg_acc": 0.9959959983825684, "eval/reward_neg_loss": 0.019182687625288963, "eval/reward_pos_acc": 0.7999999523162842, "eval/reward_pos_loss": 1.7751104831695557, "eval/reward_pred": 0.019039733335375786, "eval/reward_rate": 0.0244140625, "replay/size": 392369.0, "replay/inserts": 32824.0, "replay/samples": 32832.0, "replay/insert_wait_avg": 1.2145445110331272e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 5.705794047193918e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 76112.0, "eval_replay/inserts": 5896.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.209925764127858e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.301568984985352e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0614216327667, "timer/env.step_count": 4103.0, "timer/env.step_total": 156.9809696674347, "timer/env.step_frac": 0.15697132823215712, "timer/env.step_avg": 0.03826004622652564, "timer/env.step_min": 0.0022830963134765625, "timer/env.step_max": 0.9238700866699219, "timer/replay._sample_count": 32832.0, "timer/replay._sample_total": 2903.4749376773834, "timer/replay._sample_frac": 2.90329661245904, "timer/replay._sample_avg": 0.08843430000235696, "timer/replay._sample_min": 0.00038933753967285156, "timer/replay._sample_max": 0.12478232383728027, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4840.0, "timer/agent.policy_total": 48.63304424285889, "timer/agent.policy_frac": 0.048630057305337655, "timer/agent.policy_avg": 0.010048149636954315, "timer/agent.policy_min": 0.007637500762939453, "timer/agent.policy_max": 0.05080389976501465, "timer/dataset_train_count": 2052.0, "timer/dataset_train_total": 0.16674184799194336, "timer/dataset_train_frac": 0.00016673160706440364, "timer/dataset_train_avg": 8.125821052238955e-05, "timer/dataset_train_min": 6.0558319091796875e-05, "timer/dataset_train_max": 0.00025916099548339844, "timer/agent.train_count": 2052.0, "timer/agent.train_total": 762.723240852356, "timer/agent.train_frac": 0.7626763960228395, "timer/agent.train_avg": 0.3716974857954951, "timer/agent.train_min": 0.3519449234008789, "timer/agent.train_max": 1.2853593826293945, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4046766757965088, "timer/agent.report_frac": 0.0004046518214209351, "timer/agent.report_avg": 0.2023383378982544, "timer/agent.report_min": 0.2021799087524414, "timer/agent.report_max": 0.20249676704406738, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.2901763916015625e-05, "timer/dataset_eval_frac": 3.2899743160073124e-08, "timer/dataset_eval_avg": 3.2901763916015625e-05, "timer/dataset_eval_min": 3.2901763916015625e-05, "timer/dataset_eval_max": 3.2901763916015625e-05, "fps": 32.82160849231811}
{"step": 393208, "time": 12153.865872383118, "episode/length": 197.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 393288, "time": 12156.733695268631, "episode/length": 207.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9711538461538461, "episode/intrinsic_return": 0.0}
{"step": 393960, "time": 12174.561980247498, "episode/length": 218.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 394088, "time": 12178.589027881622, "episode/length": 207.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 394416, "time": 12187.78358244896, "episode/length": 211.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 394416, "time": 12187.811811685562, "episode/length": 194.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 394576, "time": 12192.57902598381, "episode/length": 247.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9959677419354839, "episode/intrinsic_return": 0.0}
{"step": 394712, "time": 12196.544101953506, "episode/length": 177.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 394728, "time": 12197.80089879036, "episode/length": 189.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 394824, "time": 12201.109041929245, "episode/length": 306.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.996742671009772, "episode/intrinsic_return": 0.0}
{"step": 395416, "time": 12216.952347278595, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 395736, "time": 12226.002045869827, "episode/length": 221.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 396032, "time": 12234.377695322037, "episode/length": 150.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 396080, "time": 12236.413573980331, "episode/length": 207.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 396112, "time": 12238.099073171616, "episode/length": 191.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 396328, "time": 12244.21772313118, "episode/length": 201.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 396376, "time": 12246.273024082184, "episode/length": 205.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 396576, "time": 12252.275014400482, "episode/length": 57.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 397328, "time": 12271.967192173004, "episode/length": 161.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 397392, "time": 12274.434071540833, "episode/length": 246.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.979757085020243, "episode/intrinsic_return": 0.0}
{"step": 397600, "time": 12280.641704559326, "episode/length": 232.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 397888, "time": 12288.828977108002, "episode/length": 433.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9792626728110599, "episode/intrinsic_return": 0.0}
{"step": 397904, "time": 12290.089650154114, "episode/length": 165.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 398024, "time": 12293.6711602211, "episode/length": 211.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 398200, "time": 12298.844183683395, "episode/length": 38.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9487179487179487, "episode/intrinsic_return": 0.0}
{"step": 398552, "time": 12308.531179904938, "episode/length": 144.0, "episode/score": 4.100000023841858, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 398576, "time": 12310.153836965561, "episode/length": 155.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 399144, "time": 12324.916686296463, "episode/length": 382.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9973890339425587, "episode/intrinsic_return": 0.0}
{"step": 399208, "time": 12327.402009248734, "episode/length": 162.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 399272, "time": 12329.842041492462, "episode/length": 361.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9917127071823204, "episode/intrinsic_return": 0.0}
{"step": 399296, "time": 12331.524970054626, "episode/length": 211.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 399800, "time": 12344.941601514816, "episode/length": 199.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.97, "episode/intrinsic_return": 0.0}
{"step": 399872, "time": 12347.866864681244, "episode/length": 230.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 399904, "time": 12349.476744413376, "episode/length": 165.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 400088, "time": 12356.24433684349, "eval_episode/length": 42.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9767441860465116}
{"step": 400088, "time": 12358.810652971268, "eval_episode/length": 144.0, "eval_episode/score": 6.100000023841858, "eval_episode/reward_rate": 0.993103448275862}
{"step": 400088, "time": 12360.156133890152, "eval_episode/length": 173.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9655172413793104}
{"step": 400088, "time": 12361.196142196655, "eval_episode/length": 185.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.978494623655914}
{"step": 400088, "time": 12362.46227312088, "eval_episode/length": 208.0, "eval_episode/score": 6.099999964237213, "eval_episode/reward_rate": 0.9808612440191388}
{"step": 400088, "time": 12363.34245300293, "eval_episode/length": 210.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.976303317535545}
{"step": 400088, "time": 12364.518296480179, "eval_episode/length": 225.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.995575221238938}
{"step": 400088, "time": 12366.126729249954, "eval_episode/length": 227.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9868421052631579}
{"step": 400752, "time": 12383.143988132477, "episode/length": 192.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 400952, "time": 12388.748833656311, "episode/length": 209.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 401064, "time": 12392.36420083046, "episode/length": 239.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 401080, "time": 12393.621570587158, "episode/length": 222.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 401352, "time": 12401.19408774376, "episode/length": 184.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 401376, "time": 12402.7661318779, "episode/length": 196.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9593908629441624, "episode/intrinsic_return": 0.0}
{"step": 401744, "time": 12412.93513083458, "episode/length": 48.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 402128, "time": 12423.296560764313, "episode/length": 146.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 402168, "time": 12424.91340970993, "episode/length": 451.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 402200, "time": 12426.618394613266, "episode/length": 180.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 402544, "time": 12436.398479938507, "episode/length": 182.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 402736, "time": 12442.1069252491, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 403024, "time": 12450.188626766205, "episode/length": 244.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.0}
{"step": 403208, "time": 12455.55826473236, "episode/length": 412.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9782082324455206, "episode/intrinsic_return": 0.0}
{"step": 403752, "time": 12469.90580868721, "episode/length": 197.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 403816, "time": 12472.395959854126, "episode/length": 210.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 403952, "time": 12476.978920936584, "episode/length": 275.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9818840579710145, "episode/intrinsic_return": 0.0}
{"step": 404344, "time": 12487.288504123688, "episode/length": 224.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 404496, "time": 12492.126949548721, "episode/length": 160.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9627329192546584, "episode/intrinsic_return": 0.0}
{"step": 404744, "time": 12499.043377637863, "episode/length": 214.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9720930232558139, "episode/intrinsic_return": 0.0}
{"step": 405144, "time": 12510.069108009338, "episode/length": 173.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9597701149425287, "episode/intrinsic_return": 0.0}
{"step": 405400, "time": 12517.274602413177, "episode/length": 180.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 405456, "time": 12519.824648141861, "episode/length": 204.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9658536585365853, "episode/intrinsic_return": 0.0}
{"step": 405616, "time": 12524.59475326538, "episode/length": 426.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9976580796252927, "episode/intrinsic_return": 0.0}
{"step": 405792, "time": 12529.775819778442, "episode/length": 161.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 405872, "time": 12532.65187573433, "episode/length": 391.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 406072, "time": 12538.333300113678, "episode/length": 215.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9675925925925926, "episode/intrinsic_return": 0.0}
{"step": 406440, "time": 12548.376670837402, "episode/length": 161.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 406792, "time": 12558.00769495964, "episode/length": 166.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9640718562874252, "episode/intrinsic_return": 0.0}
{"step": 406896, "time": 12561.742872714996, "episode/length": 186.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 407224, "time": 12570.561644077301, "episode/length": 200.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 407240, "time": 12571.798717737198, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 407432, "time": 12577.410677671432, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 407504, "time": 12580.280910253525, "episode/length": 213.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 407592, "time": 12583.103972434998, "episode/length": 43.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 407952, "time": 12593.161615848541, "episode/length": 400.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9775561097256857, "episode/intrinsic_return": 0.0}
{"step": 408256, "time": 12601.707848787308, "episode/length": 226.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.973568281938326, "episode/intrinsic_return": 0.0}
{"step": 408264, "time": 12602.535551071167, "episode/length": 170.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 408304, "time": 12604.522160768509, "episode/length": 188.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 408504, "time": 12610.120220184326, "episode/length": 159.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 408696, "time": 12615.849241733551, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 409000, "time": 12624.38490152359, "episode/length": 130.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9541984732824428, "episode/intrinsic_return": 0.0}
{"step": 409096, "time": 12627.583824396133, "episode/length": 198.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 409208, "time": 12631.331509590149, "episode/length": 201.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9702970297029703, "episode/intrinsic_return": 0.0}
{"step": 409744, "time": 12645.495923519135, "episode/length": 185.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 409824, "time": 12648.433730363846, "episode/length": 102.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.941747572815534, "episode/intrinsic_return": 0.0}
{"step": 409856, "time": 12650.157051801682, "episode/length": 198.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9698492462311558, "episode/intrinsic_return": 0.0}
{"step": 409944, "time": 12653.088620185852, "episode/length": 204.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 409968, "time": 12654.62064242363, "episode/length": 182.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 410072, "time": 12660.532482385635, "eval_episode/length": 122.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.959349593495935}
{"step": 410072, "time": 12661.866513967514, "eval_episode/length": 147.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9797297297297297}
{"step": 410072, "time": 12662.85331916809, "eval_episode/length": 154.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9935483870967742}
{"step": 410072, "time": 12664.440596103668, "eval_episode/length": 193.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.979381443298969}
{"step": 410072, "time": 12665.341177463531, "eval_episode/length": 197.0, "eval_episode/score": 5.099999979138374, "eval_episode/reward_rate": 0.9949494949494949}
{"step": 410072, "time": 12666.615409135818, "eval_episode/length": 216.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9769585253456221}
{"step": 410072, "time": 12668.798821926117, "eval_episode/length": 286.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9930313588850174}
{"step": 410072, "time": 12670.054051160812, "eval_episode/length": 161.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9629629629629629}
{"step": 410472, "time": 12680.212798833847, "episode/length": 221.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 410584, "time": 12683.898004770279, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 410776, "time": 12689.57444357872, "episode/length": 37.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 411056, "time": 12697.499863147736, "episode/length": 230.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 411160, "time": 12700.733347177505, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 411472, "time": 12709.464795589447, "episode/length": 201.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 411608, "time": 12713.532985210419, "episode/length": 204.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 411888, "time": 12721.758222103119, "episode/length": 242.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9794238683127572, "episode/intrinsic_return": 0.0}
{"step": 411976, "time": 12724.545878648758, "episode/length": 173.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 412464, "time": 12737.82049036026, "episode/length": 175.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9659090909090909, "episode/intrinsic_return": 0.0}
{"step": 412472, "time": 12738.660215377808, "episode/length": 211.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 412584, "time": 12742.314640283585, "episode/length": 354.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9943661971830986, "episode/intrinsic_return": 0.0}
{"step": 413192, "time": 12758.19005036354, "episode/length": 151.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 413280, "time": 12761.42921924591, "episode/length": 225.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 413416, "time": 12765.427146196365, "episode/length": 225.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9734513274336283, "episode/intrinsic_return": 0.0}
{"step": 413736, "time": 12774.226028442383, "episode/length": 230.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 414088, "time": 12783.840021371841, "episode/length": 187.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 414448, "time": 12793.782518863678, "episode/length": 246.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 414544, "time": 12797.000081777573, "episode/length": 422.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 414552, "time": 12797.824526071548, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 414720, "time": 12802.982203960419, "episode/length": 162.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9815950920245399, "episode/intrinsic_return": 0.0}
{"step": 415008, "time": 12810.98262643814, "episode/length": 317.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 415432, "time": 12822.066056966782, "episode/length": 211.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 415648, "time": 12828.410949230194, "episode/length": 295.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9966216216216216, "episode/intrinsic_return": 0.0}
{"step": 415912, "time": 12835.722759962082, "episode/length": 169.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 415952, "time": 12837.794748544693, "episode/length": 175.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 416080, "time": 12841.816551208496, "episode/length": 203.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 416224, "time": 12846.239777088165, "episode/length": 151.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 416872, "time": 12862.860412359238, "episode/length": 179.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 417016, "time": 12867.307551145554, "episode/length": 170.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 417072, "time": 12869.774009227753, "episode/length": 372.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9973190348525469, "episode/intrinsic_return": 0.0}
{"step": 417240, "time": 12874.624963998795, "episode/length": 160.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 417800, "time": 12889.479923009872, "episode/length": 214.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9813953488372092, "episode/intrinsic_return": 0.0}
{"step": 418064, "time": 12897.008697509766, "episode/length": 229.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9826086956521739, "episode/intrinsic_return": 0.0}
{"step": 418152, "time": 12899.87633395195, "episode/length": 279.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 418480, "time": 12909.105662584305, "episode/length": 175.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 418488, "time": 12910.00352859497, "episode/length": 183.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967391304347826, "episode/intrinsic_return": 0.0}
{"step": 418496, "time": 12911.199130535126, "episode/length": 202.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 418816, "time": 12919.995064020157, "episode/length": 511.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.990234375, "episode/intrinsic_return": 0.0}
{"step": 419368, "time": 12934.519351005554, "episode/length": 195.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 419520, "time": 12939.270927667618, "episode/length": 170.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 419720, "time": 12944.887614965439, "episode/length": 154.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 419736, "time": 12946.236499071121, "episode/length": 311.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9903846153846154, "episode/intrinsic_return": 0.0}
{"step": 420056, "time": 12958.343657255173, "eval_episode/length": 139.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9928571428571429}
{"step": 420056, "time": 12959.24601984024, "eval_episode/length": 144.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9655172413793104}
{"step": 420056, "time": 12960.211292028427, "eval_episode/length": 150.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9668874172185431}
{"step": 420056, "time": 12961.296525716782, "eval_episode/length": 163.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9695121951219512}
{"step": 420056, "time": 12962.386887550354, "eval_episode/length": 175.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9772727272727273}
{"step": 420056, "time": 12963.72684788704, "eval_episode/length": 199.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.98}
{"step": 420056, "time": 12964.695667982101, "eval_episode/length": 207.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9759615384615384}
{"step": 420056, "time": 12967.025829315186, "eval_episode/length": 151.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9539473684210527}
{"step": 420320, "time": 12973.936917066574, "episode/length": 227.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9780701754385965, "episode/intrinsic_return": 0.0}
{"step": 420512, "time": 12979.731546878815, "episode/length": 142.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 420696, "time": 12984.979702472687, "episode/length": 46.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 420952, "time": 12992.13911819458, "episode/length": 360.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9861495844875346, "episode/intrinsic_return": 0.0}
{"step": 421240, "time": 13000.076671123505, "episode/length": 189.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.968421052631579, "episode/intrinsic_return": 0.0}
{"step": 421392, "time": 13004.769013404846, "episode/length": 362.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9972451790633609, "episode/intrinsic_return": 0.0}
{"step": 422016, "time": 13021.096845626831, "episode/length": 187.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 422088, "time": 13023.545050382614, "episode/length": 173.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 422208, "time": 13027.597413778305, "episode/length": 423.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9787735849056604, "episode/intrinsic_return": 0.0}
{"step": 422320, "time": 13031.19235944748, "episode/length": 322.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9969040247678018, "episode/intrinsic_return": 0.0}
{"step": 422368, "time": 13033.218386650085, "episode/length": 355.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9859550561797753, "episode/intrinsic_return": 0.0}
{"step": 422552, "time": 13038.442261219025, "episode/length": 199.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 422768, "time": 13044.713927268982, "episode/length": 190.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9685863874345549, "episode/intrinsic_return": 0.0}
{"step": 423440, "time": 13062.192217350006, "episode/length": 177.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 423664, "time": 13068.72864818573, "episode/length": 161.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 423824, "time": 13073.583114862442, "episode/length": 303.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9967105263157895, "episode/intrinsic_return": 0.0}
{"step": 423872, "time": 13075.636594772339, "episode/length": 193.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 423904, "time": 13077.309839963913, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 424232, "time": 13086.315258741379, "episode/length": 252.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9881422924901185, "episode/intrinsic_return": 0.0}
{"step": 424520, "time": 13094.50691819191, "episode/length": 218.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 424960, "time": 13106.476313829422, "episode/length": 161.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 425160, "time": 13112.251616716385, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 425296, "time": 13116.628906726837, "episode/length": 41.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 425456, "time": 13121.462691783905, "episode/length": 193.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9639175257731959, "episode/intrinsic_return": 0.0}
{"step": 425512, "time": 13123.492637634277, "episode/length": 427.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9789719626168224, "episode/intrinsic_return": 0.0}
{"step": 425512, "time": 13123.52260184288, "episode/length": 159.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 425872, "time": 13133.497050762177, "episode/length": 249.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.972, "episode/intrinsic_return": 0.0}
{"step": 426040, "time": 13138.397951126099, "episode/length": 189.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 426104, "time": 13140.80489397049, "episode/length": 332.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.990990990990991, "episode/intrinsic_return": 0.0}
{"step": 426233, "time": 13145.731241941452, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.365369002784838, "train/action_min": 0.0, "train/action_std": 3.27628743705567, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04379183159134034, "train/actor_opt_grad_steps": 25500.0, "train/actor_opt_loss": -7.007741176554461, "train/adv_mag": 0.6540473069300492, "train/adv_max": 0.6342968554302836, "train/adv_mean": 0.002926276712847565, "train/adv_min": -0.4729326579844552, "train/adv_std": 0.06832314915420336, "train/cont_avg": 0.9943882700358851, "train/cont_loss_mean": 0.0002449869283470106, "train/cont_loss_std": 0.007110169910605595, "train/cont_neg_acc": 0.9940590116966284, "train/cont_neg_loss": 0.016697013521917017, "train/cont_pos_acc": 0.9999528992119018, "train/cont_pos_loss": 0.00013387977874609097, "train/cont_pred": 0.9943644997605867, "train/cont_rate": 0.9943882700358851, "train/dyn_loss_mean": 14.146211427935002, "train/dyn_loss_std": 9.166818157907878, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.82469412784257, "train/extr_critic_critic_opt_grad_steps": 25500.0, "train/extr_critic_critic_opt_loss": 15752.329269774222, "train/extr_critic_mag": 5.27454470447376, "train/extr_critic_max": 5.27454470447376, "train/extr_critic_mean": 0.9855383377896542, "train/extr_critic_min": -0.2991974604757209, "train/extr_critic_std": 1.2093514994000705, "train/extr_return_normed_mag": 1.779247575399408, "train/extr_return_normed_max": 1.779247575399408, "train/extr_return_normed_mean": 0.29733152751717273, "train/extr_return_normed_min": -0.13689300881333327, "train/extr_return_normed_std": 0.33873564689353325, "train/extr_return_rate": 0.4679192457187689, "train/extr_return_raw_mag": 6.430069857236871, "train/extr_return_raw_max": 6.430069857236871, "train/extr_return_raw_mean": 0.9962548211430818, "train/extr_return_raw_min": -0.5961657072368421, "train/extr_return_raw_std": 1.242464172212701, "train/extr_reward_mag": 1.0125796754964802, "train/extr_reward_max": 1.0125796754964802, "train/extr_reward_mean": 0.027569669027006225, "train/extr_reward_min": -0.3572238136136361, "train/extr_reward_std": 0.15596139894432998, "train/image_loss_mean": 7.606619930723637, "train/image_loss_std": 11.684831482371646, "train/model_loss_mean": 16.147164321972422, "train/model_loss_std": 15.454430735282351, "train/model_opt_grad_norm": 61.265506160316285, "train/model_opt_grad_steps": 25475.956937799045, "train/model_opt_loss": 15692.502602609151, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 968.8995215311005, "train/policy_entropy_mag": 2.5177991686825547, "train/policy_entropy_max": 2.5177991686825547, "train/policy_entropy_mean": 0.6437764914982627, "train/policy_entropy_min": 0.07937514721349095, "train/policy_entropy_std": 0.6284895217019405, "train/policy_logprob_mag": 7.438383138921273, "train/policy_logprob_max": -0.009455696046887117, "train/policy_logprob_mean": -0.6427064423926139, "train/policy_logprob_min": -7.438383138921273, "train/policy_logprob_std": 1.1493029206563412, "train/policy_randomness_mag": 0.8886726167783783, "train/policy_randomness_max": 0.8886726167783783, "train/policy_randomness_mean": 0.22722485055478567, "train/policy_randomness_min": 0.028015943636235437, "train/policy_randomness_std": 0.22182922129425706, "train/post_ent_mag": 58.34899223364141, "train/post_ent_max": 58.34899223364141, "train/post_ent_mean": 40.76979802327863, "train/post_ent_min": 21.22590484801662, "train/post_ent_std": 7.201370677309173, "train/prior_ent_mag": 67.29045700000233, "train/prior_ent_max": 67.29045700000233, "train/prior_ent_mean": 54.95919728621342, "train/prior_ent_min": 39.78532553859875, "train/prior_ent_std": 4.736922931442991, "train/rep_loss_mean": 14.146211427935002, "train/rep_loss_std": 9.166818157907878, "train/reward_avg": 0.022223571899155397, "train/reward_loss_mean": 0.05257268776698261, "train/reward_loss_std": 0.24906728534322037, "train/reward_max_data": 1.0129186633671299, "train/reward_max_pred": 1.0062055890069623, "train/reward_neg_acc": 0.9937529384234305, "train/reward_neg_loss": 0.029349837073405678, "train/reward_pos_acc": 0.96064478900444, "train/reward_pos_loss": 0.8822517705876292, "train/reward_pred": 0.021454126288909376, "train/reward_rate": 0.027259644138755982, "train_stats/sum_log_reward": 5.822580594401206, "train_stats/max_log_achievement_collect_coal": 0.05806451612903226, "train_stats/max_log_achievement_collect_drink": 5.051612903225807, "train_stats/max_log_achievement_collect_sapling": 2.393548387096774, "train_stats/max_log_achievement_collect_stone": 0.9354838709677419, "train_stats/max_log_achievement_collect_wood": 8.580645161290322, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.2064516129032258, "train_stats/max_log_achievement_eat_cow": 0.06451612903225806, "train_stats/max_log_achievement_make_wood_pickaxe": 0.9741935483870968, "train_stats/max_log_achievement_make_wood_sword": 0.01935483870967742, "train_stats/max_log_achievement_place_furnace": 0.0, "train_stats/max_log_achievement_place_plant": 2.2451612903225806, "train_stats/max_log_achievement_place_stone": 0.1032258064516129, "train_stats/max_log_achievement_place_table": 2.7870967741935484, "train_stats/max_log_achievement_wake_up": 1.7741935483870968, "train_stats/mean_log_entropy": 0.6319580474207478, "eval_stats/sum_log_reward": 5.849999984105428, "eval_stats/max_log_achievement_collect_coal": 0.041666666666666664, "eval_stats/max_log_achievement_collect_drink": 3.5416666666666665, "eval_stats/max_log_achievement_collect_sapling": 2.3333333333333335, "eval_stats/max_log_achievement_collect_stone": 0.4583333333333333, "eval_stats/max_log_achievement_collect_wood": 8.625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.25, "eval_stats/max_log_achievement_eat_cow": 0.041666666666666664, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.25, "eval_stats/max_log_achievement_make_wood_sword": 0.08333333333333333, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 2.2083333333333335, "eval_stats/max_log_achievement_place_stone": 0.125, "eval_stats/max_log_achievement_place_table": 2.5833333333333335, "eval_stats/max_log_achievement_wake_up": 1.5833333333333333, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.004473790992051363, "report/cont_loss_std": 0.14283251762390137, "report/cont_neg_acc": 0.800000011920929, "report/cont_neg_loss": 0.916012704372406, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.077842284757935e-06, "report/cont_pred": 0.9960896968841553, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 13.77824592590332, "report/dyn_loss_std": 9.4306058883667, "report/image_loss_mean": 7.708711624145508, "report/image_loss_std": 15.757110595703125, "report/model_loss_mean": 16.032569885253906, "report/model_loss_std": 19.43070411682129, "report/post_ent_mag": 58.192283630371094, "report/post_ent_max": 58.192283630371094, "report/post_ent_mean": 41.507301330566406, "report/post_ent_min": 23.318992614746094, "report/post_ent_std": 7.295040130615234, "report/prior_ent_mag": 66.68466186523438, "report/prior_ent_max": 66.68466186523438, "report/prior_ent_mean": 54.38907241821289, "report/prior_ent_min": 36.45481872558594, "report/prior_ent_std": 5.429579257965088, "report/rep_loss_mean": 13.77824592590332, "report/rep_loss_std": 9.4306058883667, "report/reward_avg": 0.02919921651482582, "report/reward_loss_mean": 0.05243720859289169, "report/reward_loss_std": 0.22239863872528076, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.003546953201294, "report/reward_neg_acc": 0.9909090399742126, "report/reward_neg_loss": 0.02357572875916958, "report/reward_pos_acc": 0.9411764740943909, "report/reward_pos_loss": 0.8928155303001404, "report/reward_pred": 0.02755003422498703, "report/reward_rate": 0.033203125, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 9.733033220982179e-05, "eval/cont_loss_std": 0.0020983144640922546, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.016144009307026863, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.7526580197445583e-06, "eval/cont_pred": 0.994230329990387, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 17.297271728515625, "eval/dyn_loss_std": 10.900275230407715, "eval/image_loss_mean": 12.029193878173828, "eval/image_loss_std": 15.580409049987793, "eval/model_loss_mean": 22.5064640045166, "eval/model_loss_std": 19.97606086730957, "eval/post_ent_mag": 56.0294189453125, "eval/post_ent_max": 56.0294189453125, "eval/post_ent_mean": 41.069122314453125, "eval/post_ent_min": 20.78620147705078, "eval/post_ent_std": 7.149769306182861, "eval/prior_ent_mag": 66.68466186523438, "eval/prior_ent_max": 66.68466186523438, "eval/prior_ent_mean": 54.78146743774414, "eval/prior_ent_min": 41.778018951416016, "eval/prior_ent_std": 4.798201084136963, "eval/rep_loss_mean": 17.297271728515625, "eval/rep_loss_std": 10.900275230407715, "eval/reward_avg": 0.02978515625, "eval/reward_loss_mean": 0.0988103598356247, "eval/reward_loss_std": 0.6187465190887451, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.002354621887207, "eval/reward_neg_acc": 0.9919109344482422, "eval/reward_neg_loss": 0.03118407167494297, "eval/reward_pos_acc": 0.800000011920929, "eval/reward_pos_loss": 2.0097358226776123, "eval/reward_pred": 0.02305709570646286, "eval/reward_rate": 0.0341796875, "replay/size": 425729.0, "replay/inserts": 33360.0, "replay/samples": 33360.0, "replay/insert_wait_avg": 1.2176499949942389e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 5.642215696741923e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 83096.0, "eval_replay/inserts": 6984.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.19557495379366e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.599592208862305e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0554046630859, "timer/env.step_count": 4170.0, "timer/env.step_total": 142.45527625083923, "timer/env.step_frac": 0.14244738400152115, "timer/env.step_avg": 0.03416193675080077, "timer/env.step_min": 0.002322673797607422, "timer/env.step_max": 0.9093787670135498, "timer/replay._sample_count": 33360.0, "timer/replay._sample_total": 2953.447139263153, "timer/replay._sample_frac": 2.9532835135850855, "timer/replay._sample_avg": 0.08853258810740866, "timer/replay._sample_min": 0.06709122657775879, "timer/replay._sample_max": 0.1244668960571289, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5043.0, "timer/agent.policy_total": 51.06929302215576, "timer/agent.policy_frac": 0.05106646370193937, "timer/agent.policy_avg": 0.01012676839622363, "timer/agent.policy_min": 0.0076446533203125, "timer/agent.policy_max": 0.017755746841430664, "timer/dataset_train_count": 2085.0, "timer/dataset_train_total": 0.16843366622924805, "timer/dataset_train_frac": 0.00016842433473572655, "timer/dataset_train_avg": 8.078353296366813e-05, "timer/dataset_train_min": 6.890296936035156e-05, "timer/dataset_train_max": 0.0002372264862060547, "timer/agent.train_count": 2085.0, "timer/agent.train_total": 773.5416240692139, "timer/agent.train_frac": 0.7734987686305405, "timer/agent.train_avg": 0.37100317701161334, "timer/agent.train_min": 0.3510167598724365, "timer/agent.train_max": 0.5753574371337891, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.39051222801208496, "timer/agent.report_frac": 0.0003904905930123409, "timer/agent.report_avg": 0.19525611400604248, "timer/agent.report_min": 0.18819856643676758, "timer/agent.report_max": 0.20231366157531738, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.457069396972656e-05, "timer/dataset_eval_frac": 3.45687786981895e-08, "timer/dataset_eval_avg": 3.457069396972656e-05, "timer/dataset_eval_min": 3.457069396972656e-05, "timer/dataset_eval_max": 3.457069396972656e-05, "fps": 33.357817742440616}
{"step": 426584, "time": 13154.220528841019, "episode/length": 177.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 426888, "time": 13162.796674251556, "episode/length": 171.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 426984, "time": 13166.01078915596, "episode/length": 190.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 427008, "time": 13167.53859591484, "episode/length": 213.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 427360, "time": 13177.089866399765, "episode/length": 230.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 427536, "time": 13182.340928077698, "episode/length": 186.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 427592, "time": 13184.353997468948, "episode/length": 185.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 428064, "time": 13197.239886045456, "episode/length": 184.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 428472, "time": 13208.132371425629, "episode/length": 197.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 428848, "time": 13218.487973928452, "episode/length": 163.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 428960, "time": 13222.20845413208, "episode/length": 199.0, "episode/score": 6.100000016391277, "episode/reward_rate": 0.985, "episode/intrinsic_return": 0.0}
{"step": 428992, "time": 13223.81476688385, "episode/length": 389.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9974358974358974, "episode/intrinsic_return": 0.0}
{"step": 429808, "time": 13245.062856197357, "episode/length": 217.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9724770642201835, "episode/intrinsic_return": 0.0}
{"step": 429976, "time": 13249.977408409119, "episode/length": 297.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9966442953020134, "episode/intrinsic_return": 0.0}
{"step": 430040, "time": 13255.732918977737, "eval_episode/length": 173.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9770114942528736}
{"step": 430040, "time": 13256.790890216827, "eval_episode/length": 183.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9782608695652174}
{"step": 430040, "time": 13257.857542276382, "eval_episode/length": 196.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9796954314720813}
{"step": 430040, "time": 13258.885583162308, "eval_episode/length": 203.0, "eval_episode/score": 6.1000000312924385, "eval_episode/reward_rate": 0.9950980392156863}
{"step": 430040, "time": 13259.77883720398, "eval_episode/length": 207.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9759615384615384}
{"step": 430040, "time": 13263.082185268402, "eval_episode/length": 340.0, "eval_episode/score": 7.099999979138374, "eval_episode/reward_rate": 0.9970674486803519}
{"step": 430040, "time": 13264.520341157913, "eval_episode/length": 200.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9751243781094527}
{"step": 430040, "time": 13265.526721477509, "eval_episode/length": 177.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9719101123595506}
{"step": 430216, "time": 13270.133240699768, "episode/length": 217.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 430288, "time": 13272.922447681427, "episode/length": 161.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 430616, "time": 13281.707848072052, "episode/length": 450.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9800443458980045, "episode/intrinsic_return": 0.0}
{"step": 430712, "time": 13285.027289628983, "episode/length": 218.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 430920, "time": 13290.992344379425, "episode/length": 491.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9857723577235772, "episode/intrinsic_return": 0.0}
{"step": 431000, "time": 13293.745232582092, "episode/length": 148.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 431536, "time": 13308.00199341774, "episode/length": 194.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 431552, "time": 13309.210612773895, "episode/length": 157.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 431648, "time": 13312.45625114441, "episode/length": 128.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9612403100775194, "episode/intrinsic_return": 0.0}
{"step": 431752, "time": 13315.669077634811, "episode/length": 191.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 431936, "time": 13321.388327360153, "episode/length": 152.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 432296, "time": 13331.069101572037, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 432320, "time": 13332.705498695374, "episode/length": 433.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9792626728110599, "episode/intrinsic_return": 0.0}
{"step": 433136, "time": 13353.838138103485, "episode/length": 276.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9855595667870036, "episode/intrinsic_return": 0.0}
{"step": 433168, "time": 13355.545869350433, "episode/length": 203.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 433216, "time": 13357.559490680695, "episode/length": 207.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 433304, "time": 13360.414594650269, "episode/length": 206.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 433520, "time": 13366.799485683441, "episode/length": 220.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 433528, "time": 13367.621682405472, "episode/length": 153.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9545454545454546, "episode/intrinsic_return": 0.0}
{"step": 433936, "time": 13378.867365121841, "episode/length": 249.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.996, "episode/intrinsic_return": 0.0}
{"step": 433960, "time": 13380.136570453644, "episode/length": 204.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 434416, "time": 13392.67063164711, "episode/length": 155.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 434440, "time": 13393.98348236084, "episode/length": 141.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9647887323943662, "episode/intrinsic_return": 0.0}
{"step": 434744, "time": 13402.344312906265, "episode/length": 190.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9685863874345549, "episode/intrinsic_return": 0.0}
{"step": 434808, "time": 13404.865032434464, "episode/length": 105.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9433962264150944, "episode/intrinsic_return": 0.0}
{"step": 435272, "time": 13417.408321380615, "episode/length": 166.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 435864, "time": 13433.471239805222, "episode/length": 177.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9606741573033708, "episode/intrinsic_return": 0.0}
{"step": 436168, "time": 13441.945534944534, "episode/length": 218.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 436528, "time": 13451.93726849556, "episode/length": 214.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 436544, "time": 13453.148213624954, "episode/length": 158.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 436592, "time": 13455.211538553238, "episode/length": 431.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 436904, "time": 13463.598933458328, "episode/length": 269.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9962962962962963, "episode/intrinsic_return": 0.0}
{"step": 437056, "time": 13468.369793653488, "episode/length": 441.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9796380090497737, "episode/intrinsic_return": 0.0}
{"step": 437088, "time": 13470.00227355957, "episode/length": 444.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9797752808988764, "episode/intrinsic_return": 0.0}
{"step": 437464, "time": 13480.09429526329, "episode/length": 50.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 437496, "time": 13481.75149512291, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 437592, "time": 13484.90389084816, "episode/length": 85.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9883720930232558, "episode/intrinsic_return": 0.0}
{"step": 437712, "time": 13488.904375553131, "episode/length": 230.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9826839826839827, "episode/intrinsic_return": 0.0}
{"step": 437864, "time": 13493.282058000565, "episode/length": 158.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 438016, "time": 13498.238137245178, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9623655913978495, "episode/intrinsic_return": 0.0}
{"step": 438016, "time": 13498.270079374313, "episode/length": 183.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 438544, "time": 13512.213784694672, "episode/length": 181.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 438976, "time": 13523.663927078247, "episode/length": 184.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 439024, "time": 13525.732682704926, "episode/length": 194.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 439048, "time": 13526.980639457703, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 439408, "time": 13537.13972234726, "episode/length": 211.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 439424, "time": 13538.334430456161, "episode/length": 194.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 439536, "time": 13541.889989376068, "episode/length": 189.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 439952, "time": 13553.022000551224, "episode/length": 241.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9958677685950413, "episode/intrinsic_return": 0.0}
{"step": 440024, "time": 13559.007097244263, "eval_episode/length": 169.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9705882352941176}
{"step": 440024, "time": 13560.345772266388, "eval_episode/length": 195.0, "eval_episode/score": 5.0999999940395355, "eval_episode/reward_rate": 0.9948979591836735}
{"step": 440024, "time": 13561.273816347122, "eval_episode/length": 199.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.97}
{"step": 440024, "time": 13562.448601484299, "eval_episode/length": 216.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9953917050691244}
{"step": 440024, "time": 13562.481807470322, "eval_episode/length": 216.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9953917050691244}
{"step": 440024, "time": 13563.400209665298, "eval_episode/length": 219.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9954545454545455}
{"step": 440024, "time": 13564.837864875793, "eval_episode/length": 54.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.9818181818181818}
{"step": 440024, "time": 13565.783846855164, "eval_episode/length": 256.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9961089494163424}
{"step": 440248, "time": 13571.50504231453, "episode/length": 212.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 440728, "time": 13584.395154237747, "episode/length": 209.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9857142857142858, "episode/intrinsic_return": 0.0}
{"step": 440768, "time": 13586.3894135952, "episode/length": 217.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 440832, "time": 13588.793670892715, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 440944, "time": 13592.414679050446, "episode/length": 175.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 441024, "time": 13595.308641195297, "episode/length": 199.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 441136, "time": 13598.851908445358, "episode/length": 37.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 441160, "time": 13600.091240644455, "episode/length": 150.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9602649006622517, "episode/intrinsic_return": 0.0}
{"step": 442112, "time": 13625.32345867157, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 442296, "time": 13630.55936717987, "episode/length": 190.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9633507853403142, "episode/intrinsic_return": 0.0}
{"step": 442304, "time": 13631.827689409256, "episode/length": 159.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 442312, "time": 13632.662902832031, "episode/length": 416.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9784172661870504, "episode/intrinsic_return": 0.0}
{"step": 442400, "time": 13635.856372117996, "episode/length": 154.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 442464, "time": 13638.305305242538, "episode/length": 189.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9631578947368421, "episode/intrinsic_return": 0.0}
{"step": 442552, "time": 13641.304602146149, "episode/length": 287.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9861111111111112, "episode/intrinsic_return": 0.0}
{"step": 443520, "time": 13666.371487855911, "episode/length": 175.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9659090909090909, "episode/intrinsic_return": 0.0}
{"step": 443648, "time": 13670.431237220764, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 443704, "time": 13672.496963739395, "episode/length": 175.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 443712, "time": 13673.708699941635, "episode/length": 155.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 443952, "time": 13680.52736878395, "episode/length": 205.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.970873786407767, "episode/intrinsic_return": 0.0}
{"step": 444008, "time": 13682.58936715126, "episode/length": 181.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 444544, "time": 13697.33711862564, "episode/length": 425.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9788732394366197, "episode/intrinsic_return": 0.0}
{"step": 444584, "time": 13698.978572130203, "episode/length": 116.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9487179487179487, "episode/intrinsic_return": 0.0}
{"step": 445224, "time": 13715.94373178482, "episode/length": 188.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9682539682539683, "episode/intrinsic_return": 0.0}
{"step": 445352, "time": 13720.040082931519, "episode/length": 205.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9805825242718447, "episode/intrinsic_return": 0.0}
{"step": 445672, "time": 13728.951781988144, "episode/length": 214.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 445688, "time": 13730.162004709244, "episode/length": 410.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9927007299270073, "episode/intrinsic_return": 0.0}
{"step": 445872, "time": 13735.778292417526, "episode/length": 232.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9742489270386266, "episode/intrinsic_return": 0.0}
{"step": 446504, "time": 13752.119092702866, "episode/length": 143.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9652777777777778, "episode/intrinsic_return": 0.0}
{"step": 446544, "time": 13754.182718515396, "episode/length": 83.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9880952380952381, "episode/intrinsic_return": 0.0}
{"step": 446680, "time": 13758.141919612885, "episode/length": 394.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9949367088607595, "episode/intrinsic_return": 0.0}
{"step": 446992, "time": 13766.978971719742, "episode/length": 220.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 447080, "time": 13769.80424618721, "episode/length": 175.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 447248, "time": 13775.069613933563, "episode/length": 332.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.978978978978979, "episode/intrinsic_return": 0.0}
{"step": 447304, "time": 13777.235720872879, "episode/length": 201.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 447496, "time": 13782.843992233276, "episode/length": 51.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9230769230769231, "episode/intrinsic_return": 0.0}
{"step": 447976, "time": 13795.568455696106, "episode/length": 428.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9790209790209791, "episode/intrinsic_return": 0.0}
{"step": 448168, "time": 13801.256564617157, "episode/length": 146.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9659863945578231, "episode/intrinsic_return": 0.0}
{"step": 448200, "time": 13802.882488489151, "episode/length": 206.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 448208, "time": 13804.134426355362, "episode/length": 190.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 448728, "time": 13817.610185861588, "episode/length": 277.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9820143884892086, "episode/intrinsic_return": 0.0}
{"step": 448880, "time": 13822.336653709412, "episode/length": 196.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 449056, "time": 13827.461361408234, "episode/length": 225.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 449176, "time": 13831.099950551987, "episode/length": 125.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9920634920634921, "episode/intrinsic_return": 0.0}
{"step": 449312, "time": 13835.53972697258, "episode/length": 226.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 449488, "time": 13840.64324259758, "episode/length": 160.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9565217391304348, "episode/intrinsic_return": 0.0}
{"step": 449728, "time": 13847.504202127457, "episode/length": 218.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 450008, "time": 13858.222085475922, "eval_episode/length": 135.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9632352941176471}
{"step": 450008, "time": 13859.440518140793, "eval_episode/length": 158.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9748427672955975}
{"step": 450008, "time": 13860.333144664764, "eval_episode/length": 164.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9696969696969697}
{"step": 450008, "time": 13862.060474157333, "eval_episode/length": 209.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9809523809523809}
{"step": 450008, "time": 13863.332104921341, "eval_episode/length": 235.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9957627118644068}
{"step": 450008, "time": 13865.7411942482, "eval_episode/length": 318.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.987460815047022}
{"step": 450008, "time": 13867.049015522003, "eval_episode/length": 182.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9781420765027322}
{"step": 450008, "time": 13868.220801830292, "eval_episode/length": 129.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9923076923076923}
{"step": 450176, "time": 13873.013860225677, "episode/length": 180.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 450248, "time": 13875.437312364578, "episode/length": 254.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.996078431372549, "episode/intrinsic_return": 0.0}
{"step": 450448, "time": 13881.63703417778, "episode/length": 158.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 450608, "time": 13886.536551713943, "episode/length": 215.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 450784, "time": 13891.8628718853, "episode/length": 215.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 450912, "time": 13895.937695980072, "episode/length": 199.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 451536, "time": 13912.358412265778, "episode/length": 160.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 451936, "time": 13923.130326986313, "episode/length": 185.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 451984, "time": 13925.13109588623, "episode/length": 171.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 452024, "time": 13926.861505270004, "episode/length": 138.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.0}
{"step": 452360, "time": 13936.142201423645, "episode/length": 196.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 452592, "time": 13942.897244215012, "episode/length": 357.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9888268156424581, "episode/intrinsic_return": 0.0}
{"step": 452904, "time": 13951.207008361816, "episode/length": 426.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9789227166276346, "episode/intrinsic_return": 0.0}
{"step": 452904, "time": 13951.24088549614, "episode/length": 170.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9590643274853801, "episode/intrinsic_return": 0.0}
{"step": 453208, "time": 13959.94051027298, "episode/length": 147.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 453256, "time": 13962.015522956848, "episode/length": 158.0, "episode/score": 4.100000023841858, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 453528, "time": 13969.626666545868, "episode/length": 198.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 453560, "time": 13971.261305093765, "episode/length": 149.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9733333333333334, "episode/intrinsic_return": 0.0}
{"step": 453648, "time": 13974.596825122833, "episode/length": 433.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9792626728110599, "episode/intrinsic_return": 0.0}
{"step": 454104, "time": 13986.611728668213, "episode/length": 149.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9733333333333334, "episode/intrinsic_return": 0.0}
{"step": 454224, "time": 13990.696426391602, "episode/length": 203.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 454784, "time": 14005.28775215149, "episode/length": 190.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9842931937172775, "episode/intrinsic_return": 0.0}
{"step": 454792, "time": 14006.166291713715, "episode/length": 197.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 454872, "time": 14008.929848909378, "episode/length": 245.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.983739837398374, "episode/intrinsic_return": 0.0}
{"step": 455208, "time": 14018.244825839996, "episode/length": 209.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9857142857142858, "episode/intrinsic_return": 0.0}
{"step": 455864, "time": 14036.72303533554, "episode/length": 204.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9804878048780488, "episode/intrinsic_return": 0.0}
{"step": 456176, "time": 14045.602045536041, "episode/length": 162.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 456288, "time": 14049.386132478714, "episode/length": 329.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.990909090909091, "episode/intrinsic_return": 0.0}
{"step": 456592, "time": 14057.892791748047, "episode/length": 225.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 456632, "time": 14059.575723171234, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 456744, "time": 14063.292749881744, "episode/length": 243.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9795081967213115, "episode/intrinsic_return": 0.0}
{"step": 456984, "time": 14070.00431227684, "episode/length": 427.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9789719626168224, "episode/intrinsic_return": 0.0}
{"step": 457064, "time": 14072.75852227211, "episode/length": 149.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 457424, "time": 14082.696345090866, "episode/length": 414.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9783132530120482, "episode/intrinsic_return": 0.0}
{"step": 457856, "time": 14094.257852315903, "episode/length": 195.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 457880, "time": 14095.533597707748, "episode/length": 212.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9812206572769953, "episode/intrinsic_return": 0.0}
{"step": 458136, "time": 14102.728981494904, "episode/length": 173.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 458344, "time": 14108.804365634918, "episode/length": 159.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 458488, "time": 14113.18618941307, "episode/length": 187.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 458608, "time": 14117.283656597137, "episode/length": 246.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.979757085020243, "episode/intrinsic_return": 0.0}
{"step": 458992, "time": 14127.899596691132, "episode/length": 195.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 459048, "time": 14129.9522960186, "episode/length": 148.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 459609, "time": 14145.83760046959, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.363644526554988, "train/action_min": 0.0, "train/action_std": 3.3392693927654853, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04341019738393907, "train/actor_opt_grad_steps": 27585.0, "train/actor_opt_loss": -4.069867901217479, "train/adv_mag": 0.6718839461413714, "train/adv_max": 0.6531868740343131, "train/adv_mean": 0.0033062343373138413, "train/adv_min": -0.45569885794359904, "train/adv_std": 0.06828581762070265, "train/cont_avg": 0.9948307917668269, "train/cont_loss_mean": 0.0001343506646568434, "train/cont_loss_std": 0.0038690438290536542, "train/cont_neg_acc": 0.9932692308838551, "train/cont_neg_loss": 0.015867023794861816, "train/cont_pos_acc": 0.9999716465289776, "train/cont_pos_loss": 5.8950168424566946e-05, "train/cont_pred": 0.9948372190388349, "train/cont_rate": 0.9948307917668269, "train/dyn_loss_mean": 14.12940945992103, "train/dyn_loss_std": 9.184533765682808, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8280559792541541, "train/extr_critic_critic_opt_grad_steps": 27585.0, "train/extr_critic_critic_opt_loss": 15597.074852576623, "train/extr_critic_mag": 5.254358002772698, "train/extr_critic_max": 5.254358002772698, "train/extr_critic_mean": 0.9075163221703126, "train/extr_critic_min": -0.31409404484125286, "train/extr_critic_std": 1.144539348494548, "train/extr_return_normed_mag": 1.8029398161631365, "train/extr_return_normed_max": 1.8029398161631365, "train/extr_return_normed_mean": 0.2836384346995216, "train/extr_return_normed_min": -0.13997344746111104, "train/extr_return_normed_std": 0.3308652642971048, "train/extr_return_rate": 0.4373463394406896, "train/extr_return_raw_mag": 6.320383908656927, "train/extr_return_raw_max": 6.320383908656927, "train/extr_return_raw_mean": 0.9192549869991266, "train/extr_return_raw_min": -0.5869547012620248, "train/extr_return_raw_std": 1.1763681588837733, "train/extr_reward_mag": 1.0124114912289839, "train/extr_reward_max": 1.0124114912289839, "train/extr_reward_mean": 0.025746794529438306, "train/extr_reward_min": -0.35540486299074614, "train/extr_reward_std": 0.15035895688029435, "train/image_loss_mean": 7.655353096815256, "train/image_loss_std": 11.807610447590168, "train/model_loss_mean": 16.184522642539097, "train/model_loss_std": 15.570193391579847, "train/model_opt_grad_norm": 61.3484941812662, "train/model_opt_grad_steps": 27558.802884615383, "train/model_opt_loss": 11441.972926213191, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 709.1346153846154, "train/policy_entropy_mag": 2.520675770365275, "train/policy_entropy_max": 2.520675770365275, "train/policy_entropy_mean": 0.6841318167459506, "train/policy_entropy_min": 0.07937515724020508, "train/policy_entropy_std": 0.6591969178273127, "train/policy_logprob_mag": 7.43838325372109, "train/policy_logprob_max": -0.009455702486985292, "train/policy_logprob_mean": -0.6839173759978551, "train/policy_logprob_min": -7.43838325372109, "train/policy_logprob_std": 1.1742772259391272, "train/policy_randomness_mag": 0.8896879298755755, "train/policy_randomness_max": 0.8896879298755755, "train/policy_randomness_mean": 0.24146850858456814, "train/policy_randomness_min": 0.028015947193265535, "train/policy_randomness_std": 0.23266758476025784, "train/post_ent_mag": 58.38931861290565, "train/post_ent_max": 58.38931861290565, "train/post_ent_mean": 41.03765579370352, "train/post_ent_min": 20.83260301443247, "train/post_ent_std": 7.287041994241568, "train/prior_ent_mag": 67.56288392727191, "train/prior_ent_max": 67.56288392727191, "train/prior_ent_mean": 55.21901381932772, "train/prior_ent_min": 40.17374513699458, "train/prior_ent_std": 4.674086656707984, "train/rep_loss_mean": 14.12940945992103, "train/rep_loss_std": 9.184533765682808, "train/reward_avg": 0.02221304070777618, "train/reward_loss_mean": 0.05138952990707297, "train/reward_loss_std": 0.24501511046233085, "train/reward_max_data": 1.0110576949440515, "train/reward_max_pred": 1.0070365822085967, "train/reward_neg_acc": 0.9932193933771207, "train/reward_neg_loss": 0.028384631445917945, "train/reward_pos_acc": 0.9613806616801482, "train/reward_pos_loss": 0.8855964237680802, "train/reward_pred": 0.02155091079811637, "train/reward_rate": 0.026944673978365384, "train_stats/sum_log_reward": 6.18552632473017, "train_stats/max_log_achievement_collect_coal": 0.17763157894736842, "train_stats/max_log_achievement_collect_drink": 6.203947368421052, "train_stats/max_log_achievement_collect_sapling": 2.0789473684210527, "train_stats/max_log_achievement_collect_stone": 2.0460526315789473, "train_stats/max_log_achievement_collect_wood": 7.559210526315789, "train_stats/max_log_achievement_defeat_skeleton": 0.019736842105263157, "train_stats/max_log_achievement_defeat_zombie": 0.32894736842105265, "train_stats/max_log_achievement_eat_cow": 0.046052631578947366, "train_stats/max_log_achievement_make_wood_pickaxe": 1.006578947368421, "train_stats/max_log_achievement_make_wood_sword": 0.019736842105263157, "train_stats/max_log_achievement_place_furnace": 0.019736842105263157, "train_stats/max_log_achievement_place_plant": 1.9342105263157894, "train_stats/max_log_achievement_place_stone": 0.09868421052631579, "train_stats/max_log_achievement_place_table": 2.6447368421052633, "train_stats/max_log_achievement_wake_up": 1.875, "train_stats/mean_log_entropy": 0.6213954414584135, "eval_stats/sum_log_reward": 6.016666690508525, "eval_stats/max_log_achievement_collect_coal": 0.16666666666666666, "eval_stats/max_log_achievement_collect_drink": 3.4583333333333335, "eval_stats/max_log_achievement_collect_sapling": 1.7083333333333333, "eval_stats/max_log_achievement_collect_stone": 2.1666666666666665, "eval_stats/max_log_achievement_collect_wood": 6.833333333333333, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.375, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.7083333333333334, "eval_stats/max_log_achievement_make_wood_sword": 0.041666666666666664, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.5416666666666667, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.375, "eval_stats/max_log_achievement_wake_up": 1.4583333333333333, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.00011887089931406081, "report/cont_loss_std": 0.003751958254724741, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00021466557518579066, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0001184952343464829, "report/cont_pred": 0.9959834814071655, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 13.596769332885742, "report/dyn_loss_std": 8.886419296264648, "report/image_loss_mean": 7.551249027252197, "report/image_loss_std": 10.674551963806152, "report/model_loss_mean": 15.754308700561523, "report/model_loss_std": 14.433782577514648, "report/post_ent_mag": 58.634918212890625, "report/post_ent_max": 58.634918212890625, "report/post_ent_mean": 41.65840148925781, "report/post_ent_min": 19.790987014770508, "report/post_ent_std": 7.313670635223389, "report/prior_ent_mag": 67.80970764160156, "report/prior_ent_max": 67.80970764160156, "report/prior_ent_mean": 55.527305603027344, "report/prior_ent_min": 42.3585090637207, "report/prior_ent_std": 4.354760646820068, "report/rep_loss_mean": 13.596769332885742, "report/rep_loss_std": 8.886419296264648, "report/reward_avg": 0.02236328087747097, "report/reward_loss_mean": 0.04488033428788185, "report/reward_loss_std": 0.21709604561328888, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.058929204940796, "report/reward_neg_acc": 0.9929789304733276, "report/reward_neg_loss": 0.02437843382358551, "report/reward_pos_acc": 0.9629629850387573, "report/reward_pos_loss": 0.8019320368766785, "report/reward_pred": 0.023139100521802902, "report/reward_rate": 0.0263671875, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 2.9964758141431957e-05, "eval/cont_loss_std": 0.0009257246274501085, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.006076154764741659, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.9749097052444995e-07, "eval/cont_pred": 0.9951462745666504, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 17.029155731201172, "eval/dyn_loss_std": 10.609046936035156, "eval/image_loss_mean": 16.395036697387695, "eval/image_loss_std": 26.71531105041504, "eval/model_loss_mean": 26.725303649902344, "eval/model_loss_std": 30.90308952331543, "eval/post_ent_mag": 57.125335693359375, "eval/post_ent_max": 57.125335693359375, "eval/post_ent_mean": 40.73898696899414, "eval/post_ent_min": 20.863265991210938, "eval/post_ent_std": 6.637604713439941, "eval/prior_ent_mag": 67.80970764160156, "eval/prior_ent_max": 67.80970764160156, "eval/prior_ent_mean": 55.56853485107422, "eval/prior_ent_min": 41.93531036376953, "eval/prior_ent_std": 4.443066120147705, "eval/rep_loss_mean": 17.029155731201172, "eval/rep_loss_std": 10.609046936035156, "eval/reward_avg": 0.02597656100988388, "eval/reward_loss_mean": 0.11274296790361404, "eval/reward_loss_std": 0.7095004320144653, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9996758699417114, "eval/reward_neg_acc": 0.9939515590667725, "eval/reward_neg_loss": 0.03397815302014351, "eval/reward_pos_acc": 0.71875, "eval/reward_pos_loss": 2.5544519424438477, "eval/reward_pred": 0.01830385997891426, "eval/reward_rate": 0.03125, "replay/size": 459105.0, "replay/inserts": 33376.0, "replay/samples": 33376.0, "replay/insert_wait_avg": 1.2049438969400904e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 5.777021611068301e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 91136.0, "eval_replay/inserts": 8040.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2094998241063967e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 6.258487701416016e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0923316478729, "timer/env.step_count": 4172.0, "timer/env.step_total": 140.3820514678955, "timer/env.step_frac": 0.1403690909584169, "timer/env.step_avg": 0.03364862211598646, "timer/env.step_min": 0.002315044403076172, "timer/env.step_max": 1.229444980621338, "timer/replay._sample_count": 33376.0, "timer/replay._sample_total": 2958.399509906769, "timer/replay._sample_frac": 2.9581263812233742, "timer/replay._sample_avg": 0.08863852798138688, "timer/replay._sample_min": 0.0003533363342285156, "timer/replay._sample_max": 0.1185312271118164, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5177.0, "timer/agent.policy_total": 52.29260778427124, "timer/agent.policy_frac": 0.052287779967383236, "timer/agent.policy_avg": 0.010100947997734448, "timer/agent.policy_min": 0.0075380802154541016, "timer/agent.policy_max": 0.023530006408691406, "timer/dataset_train_count": 2086.0, "timer/dataset_train_total": 0.16843962669372559, "timer/dataset_train_frac": 0.00016842407582126355, "timer/dataset_train_avg": 8.074766380332003e-05, "timer/dataset_train_min": 6.151199340820312e-05, "timer/dataset_train_max": 0.0001952648162841797, "timer/agent.train_count": 2086.0, "timer/agent.train_total": 774.575198173523, "timer/agent.train_frac": 0.7745036869718211, "timer/agent.train_avg": 0.37132080449353927, "timer/agent.train_min": 0.3537611961364746, "timer/agent.train_max": 1.4088428020477295, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4076814651489258, "timer/agent.report_frac": 0.00040764382672265926, "timer/agent.report_avg": 0.2038407325744629, "timer/agent.report_min": 0.20364999771118164, "timer/agent.report_max": 0.20403146743774414, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.504753112792969e-05, "timer/dataset_eval_frac": 3.5044295430384055e-08, "timer/dataset_eval_avg": 3.504753112792969e-05, "timer/dataset_eval_min": 3.504753112792969e-05, "timer/dataset_eval_max": 3.504753112792969e-05, "fps": 33.37247252911899}
{"step": 459904, "time": 14153.16524720192, "episode/length": 176.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 459976, "time": 14155.684591770172, "episode/length": 422.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9952718676122931, "episode/intrinsic_return": 0.0}
{"step": 460024, "time": 14157.742665290833, "episode/length": 209.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 460096, "time": 14162.695389032364, "eval_episode/length": 75.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9473684210526315}
{"step": 460096, "time": 14164.874392032623, "eval_episode/length": 153.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9675324675324676}
{"step": 460096, "time": 14165.761284351349, "eval_episode/length": 158.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9748427672955975}
{"step": 460096, "time": 14166.76329255104, "eval_episode/length": 167.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9702380952380952}
{"step": 460096, "time": 14168.114045143127, "eval_episode/length": 194.0, "eval_episode/score": 8.099999979138374, "eval_episode/reward_rate": 0.9846153846153847}
{"step": 460096, "time": 14169.967541456223, "eval_episode/length": 245.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.983739837398374}
{"step": 460096, "time": 14170.924056529999, "eval_episode/length": 253.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9960629921259843}
{"step": 460096, "time": 14172.045217037201, "eval_episode/length": 266.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9812734082397003}
{"step": 460096, "time": 14172.077512025833, "eval_episode/length": 190.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9738219895287958}
{"step": 460264, "time": 14176.495378494263, "episode/length": 206.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 460392, "time": 14180.484479904175, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 460616, "time": 14186.933543205261, "episode/length": 202.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 460656, "time": 14188.840035200119, "episode/length": 346.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9913544668587896, "episode/intrinsic_return": 0.0}
{"step": 461368, "time": 14207.217288255692, "episode/length": 173.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 461408, "time": 14209.196735620499, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 461600, "time": 14214.830738306046, "episode/length": 211.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 461608, "time": 14215.663517713547, "episode/length": 433.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9792626728110599, "episode/intrinsic_return": 0.0}
{"step": 461768, "time": 14220.371748447418, "episode/length": 187.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9627659574468085, "episode/intrinsic_return": 0.0}
{"step": 462128, "time": 14230.359072685242, "episode/length": 216.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 462136, "time": 14231.226807832718, "episode/length": 189.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 462312, "time": 14236.749007463455, "episode/length": 206.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 462432, "time": 14240.869225978851, "episode/length": 127.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.953125, "episode/intrinsic_return": 0.0}
{"step": 462944, "time": 14254.612941265106, "episode/length": 167.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 463088, "time": 14259.186600923538, "episode/length": 214.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9720930232558139, "episode/intrinsic_return": 0.0}
{"step": 463424, "time": 14268.415213823318, "episode/length": 206.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 463600, "time": 14273.674956798553, "episode/length": 183.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 463648, "time": 14275.738056659698, "episode/length": 188.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 463728, "time": 14278.60664510727, "episode/length": 176.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9661016949152542, "episode/intrinsic_return": 0.0}
{"step": 464432, "time": 14297.376725912094, "episode/length": 167.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 464456, "time": 14298.569921255112, "episode/length": 355.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9971910112359551, "episode/intrinsic_return": 0.0}
{"step": 464528, "time": 14301.459200620651, "episode/length": 197.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 464760, "time": 14307.897761583328, "episode/length": 290.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9965635738831615, "episode/intrinsic_return": 0.0}
{"step": 464840, "time": 14310.749279022217, "episode/length": 154.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 464952, "time": 14314.301981687546, "episode/length": 152.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 465216, "time": 14321.985884904861, "episode/length": 46.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 465352, "time": 14325.987394571304, "episode/length": 240.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.979253112033195, "episode/intrinsic_return": 0.0}
{"step": 465440, "time": 14329.26089835167, "episode/length": 223.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 465896, "time": 14341.302258968353, "episode/length": 179.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 466024, "time": 14345.28287768364, "episode/length": 186.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 466376, "time": 14354.892498254776, "episode/length": 177.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 466464, "time": 14358.15592122078, "episode/length": 212.0, "episode/score": 8.100000031292439, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 466728, "time": 14365.5880382061, "episode/length": 171.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 466920, "time": 14371.2922539711, "episode/length": 184.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 466952, "time": 14372.975237846375, "episode/length": 216.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 467544, "time": 14388.703206300735, "episode/length": 205.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9805825242718447, "episode/intrinsic_return": 0.0}
{"step": 467720, "time": 14393.904263734818, "episode/length": 410.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9951338199513382, "episode/intrinsic_return": 0.0}
{"step": 467856, "time": 14398.359708070755, "episode/length": 173.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 468064, "time": 14404.479166030884, "episode/length": 254.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.996078431372549, "episode/intrinsic_return": 0.0}
{"step": 468248, "time": 14409.805701971054, "episode/length": 161.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 468296, "time": 14411.7930290699, "episode/length": 239.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 468312, "time": 14413.050431489944, "episode/length": 56.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 468336, "time": 14414.589233160019, "episode/length": 200.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 468600, "time": 14421.815387010574, "episode/length": 209.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 469056, "time": 14434.395359754562, "episode/length": 92.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.989247311827957, "episode/intrinsic_return": 0.0}
{"step": 469384, "time": 14443.558249950409, "episode/length": 164.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 469536, "time": 14448.331012964249, "episode/length": 226.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.973568281938326, "episode/intrinsic_return": 0.0}
{"step": 469608, "time": 14450.728735685349, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 470056, "time": 14462.61730313301, "episode/length": 219.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 470080, "time": 14466.394448041916, "eval_episode/length": 77.0, "eval_episode/score": 5.099999979138374, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 470080, "time": 14467.61387515068, "eval_episode/length": 99.0, "eval_episode/score": 6.100000023841858, "eval_episode/reward_rate": 0.99}
{"step": 470080, "time": 14468.841372013092, "eval_episode/length": 121.0, "eval_episode/score": 7.100000023841858, "eval_episode/reward_rate": 0.9918032786885246}
{"step": 470080, "time": 14470.731196165085, "eval_episode/length": 177.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9719101123595506}
{"step": 470080, "time": 14471.85265135765, "eval_episode/length": 194.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9641025641025641}
{"step": 470080, "time": 14472.722239494324, "eval_episode/length": 195.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9642857142857143}
{"step": 470080, "time": 14474.265556573868, "eval_episode/length": 229.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9782608695652174}
{"step": 470080, "time": 14475.395382165909, "eval_episode/length": 166.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9760479041916168}
{"step": 470184, "time": 14478.088007211685, "episode/length": 230.0, "episode/score": 7.0999999567866325, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 470368, "time": 14483.78490972519, "episode/length": 220.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 470832, "time": 14496.081436395645, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 470848, "time": 14497.300338983536, "episode/length": 154.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9612903225806452, "episode/intrinsic_return": 0.0}
{"step": 471256, "time": 14508.149168252945, "episode/length": 233.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 471328, "time": 14510.985446453094, "episode/length": 472.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9936575052854123, "episode/intrinsic_return": 0.0}
{"step": 471624, "time": 14519.185305833817, "episode/length": 45.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 471840, "time": 14525.647733926773, "episode/length": 183.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 472104, "time": 14532.831223964691, "episode/length": 239.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 472168, "time": 14535.30128288269, "episode/length": 166.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 472336, "time": 14540.529573202133, "episode/length": 284.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9964912280701754, "episode/intrinsic_return": 0.0}
{"step": 472400, "time": 14542.88441824913, "episode/length": 193.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9690721649484536, "episode/intrinsic_return": 0.0}
{"step": 472624, "time": 14549.635199785233, "episode/length": 56.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9122807017543859, "episode/intrinsic_return": 0.0}
{"step": 472928, "time": 14558.078134775162, "episode/length": 199.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.97, "episode/intrinsic_return": 0.0}
{"step": 472976, "time": 14560.055071115494, "episode/length": 489.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9897959183673469, "episode/intrinsic_return": 0.0}
{"step": 473328, "time": 14569.57872247696, "episode/length": 212.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.971830985915493, "episode/intrinsic_return": 0.0}
{"step": 473392, "time": 14571.999699115753, "episode/length": 160.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 473504, "time": 14575.686339378357, "episode/length": 145.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9726027397260274, "episode/intrinsic_return": 0.0}
{"step": 473768, "time": 14582.999765634537, "episode/length": 240.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.995850622406639, "episode/intrinsic_return": 0.0}
{"step": 474000, "time": 14589.87794137001, "episode/length": 199.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.97, "episode/intrinsic_return": 0.0}
{"step": 474984, "time": 14614.995594501495, "episode/length": 250.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9800796812749004, "episode/intrinsic_return": 0.0}
{"step": 475064, "time": 14617.811368227005, "episode/length": 266.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9962546816479401, "episode/intrinsic_return": 0.0}
{"step": 475152, "time": 14621.04952096939, "episode/length": 219.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 475256, "time": 14624.24059510231, "episode/length": 185.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 475288, "time": 14625.860760688782, "episode/length": 222.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9820627802690582, "episode/intrinsic_return": 0.0}
{"step": 475352, "time": 14628.30775475502, "episode/length": 340.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9970674486803519, "episode/intrinsic_return": 0.0}
{"step": 476032, "time": 14646.178675413132, "episode/length": 253.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9881889763779528, "episode/intrinsic_return": 0.0}
{"step": 476176, "time": 14650.627982616425, "episode/length": 138.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.0}
{"step": 476568, "time": 14661.200454950333, "episode/length": 151.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 476608, "time": 14663.172042608261, "episode/length": 409.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9780487804878049, "episode/intrinsic_return": 0.0}
{"step": 476664, "time": 14665.145043849945, "episode/length": 60.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 476664, "time": 14665.178285598755, "episode/length": 209.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9809523809523809, "episode/intrinsic_return": 0.0}
{"step": 476696, "time": 14666.809074640274, "episode/length": 192.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 476856, "time": 14671.729998350143, "episode/length": 199.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.97, "episode/intrinsic_return": 0.0}
{"step": 477000, "time": 14676.223828315735, "episode/length": 213.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 477480, "time": 14689.236464977264, "episode/length": 180.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 478232, "time": 14708.750143766403, "episode/length": 191.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 478264, "time": 14710.480404615402, "episode/length": 199.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 478304, "time": 14712.583914995193, "episode/length": 211.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 478328, "time": 14713.827246665955, "episode/length": 207.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 478440, "time": 14717.497156858444, "episode/length": 119.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9916666666666667, "episode/intrinsic_return": 0.0}
{"step": 478592, "time": 14722.365977048874, "episode/length": 198.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 479848, "time": 14754.23583817482, "episode/length": 192.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 479896, "time": 14756.335231304169, "episode/length": 415.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9783653846153846, "episode/intrinsic_return": 0.0}
{"step": 480000, "time": 14759.963067531586, "episode/length": 175.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 480064, "time": 14765.78215265274, "eval_episode/length": 164.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9757575757575757}
{"step": 480064, "time": 14766.672852993011, "eval_episode/length": 165.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9698795180722891}
{"step": 480064, "time": 14767.662826299667, "eval_episode/length": 168.0, "eval_episode/score": 7.099999964237213, "eval_episode/reward_rate": 0.9763313609467456}
{"step": 480064, "time": 14769.083658218384, "eval_episode/length": 200.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9800995024875622}
{"step": 480064, "time": 14770.239468812943, "eval_episode/length": 217.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9770642201834863}
{"step": 480064, "time": 14771.44163775444, "eval_episode/length": 236.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9957805907172996}
{"step": 480064, "time": 14773.348826885223, "eval_episode/length": 296.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9797979797979798}
{"step": 480064, "time": 14775.283033370972, "eval_episode/length": 186.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9732620320855615}
{"step": 480064, "time": 14775.316845655441, "eval_episode/length": 189.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 480088, "time": 14775.962433099747, "episode/length": 219.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 480160, "time": 14778.697478055954, "episode/length": 412.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9782082324455206, "episode/intrinsic_return": 0.0}
{"step": 480408, "time": 14785.53519153595, "episode/length": 63.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.984375, "episode/intrinsic_return": 0.0}
{"step": 480416, "time": 14786.761442184448, "episode/length": 268.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9962825278810409, "episode/intrinsic_return": 0.0}
{"step": 480648, "time": 14793.2119410038, "episode/length": 60.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 481312, "time": 14811.013073444366, "episode/length": 384.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9922077922077922, "episode/intrinsic_return": 0.0}
{"step": 481520, "time": 14817.190878868103, "episode/length": 189.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 481568, "time": 14819.306834697723, "episode/length": 184.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 481840, "time": 14826.901886940002, "episode/length": 248.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 481944, "time": 14830.079327344894, "episode/length": 437.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9794520547945206, "episode/intrinsic_return": 0.0}
{"step": 481952, "time": 14831.363910198212, "episode/length": 191.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 482440, "time": 14844.122507095337, "episode/length": 114.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.991304347826087, "episode/intrinsic_return": 0.0}
{"step": 482504, "time": 14846.57636475563, "episode/length": 231.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 482568, "time": 14849.035979747772, "episode/length": 76.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.935064935064935, "episode/intrinsic_return": 0.0}
{"step": 482832, "time": 14856.549771785736, "episode/length": 110.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.990990990990991, "episode/intrinsic_return": 0.0}
{"step": 482976, "time": 14860.876762151718, "episode/length": 175.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 483544, "time": 14875.683148860931, "episode/length": 391.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9974489795918368, "episode/intrinsic_return": 0.0}
{"step": 484112, "time": 14890.814733028412, "episode/length": 208.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 484216, "time": 14893.989713907242, "episode/length": 213.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 484224, "time": 14895.198931455612, "episode/length": 206.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 484632, "time": 14905.971153736115, "episode/length": 206.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9806763285024155, "episode/intrinsic_return": 0.0}
{"step": 484712, "time": 14908.702003955841, "episode/length": 424.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9788235294117648, "episode/intrinsic_return": 0.0}
{"step": 485168, "time": 14921.03127193451, "episode/length": 291.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9965753424657534, "episode/intrinsic_return": 0.0}
{"step": 485256, "time": 14923.90197300911, "episode/length": 426.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9976580796252927, "episode/intrinsic_return": 0.0}
{"step": 485488, "time": 14930.702765703201, "episode/length": 106.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9532710280373832, "episode/intrinsic_return": 0.0}
{"step": 485624, "time": 14934.880798578262, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 485648, "time": 14936.437357187271, "episode/length": 262.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9657794676806084, "episode/intrinsic_return": 0.0}
{"step": 485712, "time": 14938.811958551407, "episode/length": 199.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 485872, "time": 14943.571409702301, "episode/length": 206.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 486352, "time": 14956.512630939484, "episode/length": 147.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 486424, "time": 14958.960291862488, "episode/length": 213.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 486824, "time": 14969.806604862213, "episode/length": 195.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 486960, "time": 14974.21590256691, "episode/length": 183.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 486992, "time": 14975.895107984543, "episode/length": 167.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 486992, "time": 14975.928921937943, "episode/length": 159.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 487336, "time": 14985.036267280579, "episode/length": 182.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 487520, "time": 14990.632483959198, "episode/length": 86.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9885057471264368, "episode/intrinsic_return": 0.0}
{"step": 487840, "time": 14999.526986837387, "episode/length": 276.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9711191335740073, "episode/intrinsic_return": 0.0}
{"step": 488128, "time": 15007.461410522461, "episode/length": 212.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9812206572769953, "episode/intrinsic_return": 0.0}
{"step": 488288, "time": 15012.287673473358, "episode/length": 161.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 488352, "time": 15014.738944292068, "episode/length": 169.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 488440, "time": 15017.599379301071, "episode/length": 184.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 489160, "time": 15036.592377901077, "episode/length": 350.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9914529914529915, "episode/intrinsic_return": 0.0}
{"step": 489392, "time": 15043.41670703888, "episode/length": 193.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 489424, "time": 15044.99836397171, "episode/length": 133.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9925373134328358, "episode/intrinsic_return": 0.0}
{"step": 489440, "time": 15046.277065515518, "episode/length": 239.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 489528, "time": 15049.13860321045, "episode/length": 154.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 489936, "time": 15060.281997442245, "episode/length": 186.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 490048, "time": 15067.524280786514, "eval_episode/length": 167.0, "eval_episode/score": 8.100000023841858, "eval_episode/reward_rate": 0.9940476190476191}
{"step": 490048, "time": 15068.421462535858, "eval_episode/length": 173.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9655172413793104}
{"step": 490048, "time": 15069.48190331459, "eval_episode/length": 186.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9786096256684492}
{"step": 490048, "time": 15070.496993780136, "eval_episode/length": 196.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9746192893401016}
{"step": 490048, "time": 15071.544181108475, "eval_episode/length": 208.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9808612440191388}
{"step": 490048, "time": 15072.448568344116, "eval_episode/length": 212.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9953051643192489}
{"step": 490048, "time": 15075.138100624084, "eval_episode/length": 308.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9838187702265372}
{"step": 490048, "time": 15076.526369571686, "eval_episode/length": 171.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9709302325581395}
{"step": 490352, "time": 15084.38451886177, "episode/length": 115.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9568965517241379, "episode/intrinsic_return": 0.0}
{"step": 490696, "time": 15093.82161450386, "episode/length": 156.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9617834394904459, "episode/intrinsic_return": 0.0}
{"step": 490736, "time": 15095.829229831696, "episode/length": 424.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9788235294117648, "episode/intrinsic_return": 0.0}
{"step": 490800, "time": 15098.237926483154, "episode/length": 158.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 491216, "time": 15109.449026823044, "episode/length": 227.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 491336, "time": 15113.178873538971, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 491456, "time": 15117.284710407257, "episode/length": 415.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9927884615384616, "episode/intrinsic_return": 0.0}
{"step": 491856, "time": 15128.10660624504, "episode/length": 187.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 492056, "time": 15133.786927700043, "episode/length": 156.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 492224, "time": 15139.115927696228, "episode/length": 382.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9973890339425587, "episode/intrinsic_return": 0.0}
{"step": 492416, "time": 15144.824226379395, "episode/length": 214.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 492417, "time": 15146.176550388336, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.261283762862043, "train/action_min": 0.0, "train/action_std": 3.201740033452104, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.044026932610971174, "train/actor_opt_grad_steps": 29650.0, "train/actor_opt_loss": -6.506540064986159, "train/adv_mag": 0.6549043760067079, "train/adv_max": 0.6442325298379107, "train/adv_mean": 0.0031918207044704682, "train/adv_min": -0.44000144019359494, "train/adv_std": 0.0680808239412017, "train/cont_avg": 0.9947837271341463, "train/cont_loss_mean": 0.00027878599733831256, "train/cont_loss_std": 0.008277563389127525, "train/cont_neg_acc": 0.9868060417291594, "train/cont_neg_loss": 0.02571929868508738, "train/cont_pos_acc": 0.9999520767025831, "train/cont_pos_loss": 0.0001373520501177122, "train/cont_pred": 0.9947988812516375, "train/cont_rate": 0.9947837271341463, "train/dyn_loss_mean": 13.79174094316436, "train/dyn_loss_std": 9.153284375260515, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8143938544319897, "train/extr_critic_critic_opt_grad_steps": 29650.0, "train/extr_critic_critic_opt_loss": 15543.449504573171, "train/extr_critic_mag": 5.243820920804652, "train/extr_critic_max": 5.243820920804652, "train/extr_critic_mean": 0.940819941788185, "train/extr_critic_min": -0.3104244615973496, "train/extr_critic_std": 1.1669546386090721, "train/extr_return_normed_mag": 1.7940966507283653, "train/extr_return_normed_max": 1.7940966507283653, "train/extr_return_normed_mean": 0.28819316516562204, "train/extr_return_normed_min": -0.13748987355246778, "train/extr_return_normed_std": 0.3320401493369079, "train/extr_return_rate": 0.4571233721767984, "train/extr_return_raw_mag": 6.392830513744819, "train/extr_return_raw_max": 6.392830513744819, "train/extr_return_raw_mean": 0.9523337627329478, "train/extr_return_raw_min": -0.5859840140110109, "train/extr_return_raw_std": 1.1998072548610408, "train/extr_reward_mag": 1.0120010352716213, "train/extr_reward_max": 1.0120010352716213, "train/extr_reward_mean": 0.026966500595757146, "train/extr_reward_min": -0.34619747371208376, "train/extr_reward_std": 0.15406651747662847, "train/image_loss_mean": 7.3555025449613245, "train/image_loss_std": 11.555734390165748, "train/model_loss_mean": 15.682244710224431, "train/model_loss_std": 15.314939075563013, "train/model_opt_grad_norm": 60.33807895939525, "train/model_opt_grad_steps": 29622.629268292683, "train/model_opt_loss": 18523.058946265242, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1189.0243902439024, "train/policy_entropy_mag": 2.543191917931161, "train/policy_entropy_max": 2.543191917931161, "train/policy_entropy_mean": 0.6507011297272473, "train/policy_entropy_min": 0.07937511961634566, "train/policy_entropy_std": 0.6479186284832839, "train/policy_logprob_mag": 7.43838330478203, "train/policy_logprob_max": -0.009455689874182388, "train/policy_logprob_mean": -0.6509700856557706, "train/policy_logprob_min": -7.43838330478203, "train/policy_logprob_std": 1.1604305691835357, "train/policy_randomness_mag": 0.8976351432683991, "train/policy_randomness_max": 0.8976351432683991, "train/policy_randomness_mean": 0.22966894427450693, "train/policy_randomness_min": 0.02801593395813209, "train/policy_randomness_std": 0.2286868444303187, "train/post_ent_mag": 58.74120835094917, "train/post_ent_max": 58.74120835094917, "train/post_ent_mean": 41.3848640069729, "train/post_ent_min": 21.00884492455459, "train/post_ent_std": 7.295786366811613, "train/prior_ent_mag": 67.70643474299733, "train/prior_ent_max": 67.70643474299733, "train/prior_ent_mean": 55.2428840637207, "train/prior_ent_min": 40.9294841673316, "train/prior_ent_std": 4.567527637249086, "train/rep_loss_mean": 13.79174094316436, "train/rep_loss_std": 9.153284375260515, "train/reward_avg": 0.023109755892215707, "train/reward_loss_mean": 0.05141891872555744, "train/reward_loss_std": 0.2419884360418087, "train/reward_max_data": 1.011219514870062, "train/reward_max_pred": 1.0064537216977376, "train/reward_neg_acc": 0.9935654361073564, "train/reward_neg_loss": 0.028135609935696533, "train/reward_pos_acc": 0.9637941212188906, "train/reward_pos_loss": 0.8749999592943889, "train/reward_pred": 0.022385460878835944, "train/reward_rate": 0.02779153963414634, "train_stats/sum_log_reward": 6.4012820567840185, "train_stats/max_log_achievement_collect_coal": 0.24358974358974358, "train_stats/max_log_achievement_collect_drink": 6.871794871794871, "train_stats/max_log_achievement_collect_sapling": 2.0705128205128207, "train_stats/max_log_achievement_collect_stone": 3.198717948717949, "train_stats/max_log_achievement_collect_wood": 8.724358974358974, "train_stats/max_log_achievement_defeat_skeleton": 0.01282051282051282, "train_stats/max_log_achievement_defeat_zombie": 0.23076923076923078, "train_stats/max_log_achievement_eat_cow": 0.07692307692307693, "train_stats/max_log_achievement_make_wood_pickaxe": 1.4743589743589745, "train_stats/max_log_achievement_make_wood_sword": 0.01282051282051282, "train_stats/max_log_achievement_place_furnace": 0.019230769230769232, "train_stats/max_log_achievement_place_plant": 1.9807692307692308, "train_stats/max_log_achievement_place_stone": 0.14102564102564102, "train_stats/max_log_achievement_place_table": 3.019230769230769, "train_stats/max_log_achievement_wake_up": 1.6794871794871795, "train_stats/mean_log_entropy": 0.5890523592631022, "eval_stats/sum_log_reward": 6.629411837633918, "eval_stats/max_log_achievement_collect_coal": 0.29411764705882354, "eval_stats/max_log_achievement_collect_drink": 5.852941176470588, "eval_stats/max_log_achievement_collect_sapling": 1.5294117647058822, "eval_stats/max_log_achievement_collect_stone": 4.0, "eval_stats/max_log_achievement_collect_wood": 7.705882352941177, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.3235294117647059, "eval_stats/max_log_achievement_eat_cow": 0.058823529411764705, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.1176470588235294, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.029411764705882353, "eval_stats/max_log_achievement_place_plant": 1.5, "eval_stats/max_log_achievement_place_stone": 0.23529411764705882, "eval_stats/max_log_achievement_place_table": 2.8529411764705883, "eval_stats/max_log_achievement_wake_up": 1.5, "eval_stats/mean_log_entropy": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.006802721088435374, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 5.296444214764051e-06, "report/cont_loss_std": 8.47197079565376e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0007564188563264906, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 2.350865088374121e-06, "report/cont_pred": 0.9960943460464478, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 14.307312965393066, "report/dyn_loss_std": 9.3596830368042, "report/image_loss_mean": 8.308635711669922, "report/image_loss_std": 11.164933204650879, "report/model_loss_mean": 16.94243621826172, "report/model_loss_std": 15.13245677947998, "report/post_ent_mag": 56.515037536621094, "report/post_ent_max": 56.515037536621094, "report/post_ent_mean": 41.20014572143555, "report/post_ent_min": 24.28379249572754, "report/post_ent_std": 6.824601173400879, "report/prior_ent_mag": 66.95907592773438, "report/prior_ent_max": 66.95907592773438, "report/prior_ent_mean": 55.67024230957031, "report/prior_ent_min": 41.916748046875, "report/prior_ent_std": 4.776963233947754, "report/rep_loss_mean": 14.307312965393066, "report/rep_loss_std": 9.3596830368042, "report/reward_avg": 0.02128906361758709, "report/reward_loss_mean": 0.04940791055560112, "report/reward_loss_std": 0.22276277840137482, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0036005973815918, "report/reward_neg_acc": 0.9979960322380066, "report/reward_neg_loss": 0.02561778761446476, "report/reward_pos_acc": 0.9615384936332703, "report/reward_pos_loss": 0.9625827074050903, "report/reward_pred": 0.018234744668006897, "report/reward_rate": 0.025390625, "eval/cont_avg": 0.9931640625, "eval/cont_loss_mean": 2.876999587897444e-06, "eval/cont_loss_std": 2.485583900124766e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 3.302155528217554e-05, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 2.669514515218907e-06, "eval/cont_pred": 0.9931615591049194, "eval/cont_rate": 0.9931640625, "eval/dyn_loss_mean": 19.022916793823242, "eval/dyn_loss_std": 10.463841438293457, "eval/image_loss_mean": 15.822075843811035, "eval/image_loss_std": 22.21482276916504, "eval/model_loss_mean": 27.348434448242188, "eval/model_loss_std": 26.10710334777832, "eval/post_ent_mag": 55.17594528198242, "eval/post_ent_max": 55.17594528198242, "eval/post_ent_mean": 39.6705322265625, "eval/post_ent_min": 21.563434600830078, "eval/post_ent_std": 6.580264091491699, "eval/prior_ent_mag": 66.95907592773438, "eval/prior_ent_max": 66.95907592773438, "eval/prior_ent_mean": 56.07646942138672, "eval/prior_ent_min": 43.59852600097656, "eval/prior_ent_std": 4.155252933502197, "eval/rep_loss_mean": 19.022916793823242, "eval/rep_loss_std": 10.463841438293457, "eval/reward_avg": 0.03476562350988388, "eval/reward_loss_mean": 0.11260601878166199, "eval/reward_loss_std": 0.6039139628410339, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0035970211029053, "eval/reward_neg_acc": 0.9898270964622498, "eval/reward_neg_loss": 0.05288701876997948, "eval/reward_pos_acc": 0.8292682766914368, "eval/reward_pos_loss": 1.544405221939087, "eval/reward_pred": 0.03301198408007622, "eval/reward_rate": 0.0400390625, "replay/size": 491913.0, "replay/inserts": 32808.0, "replay/samples": 32800.0, "replay/insert_wait_avg": 1.2227018645146334e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 5.794298358079863e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 9664.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.227939563081754e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 6.109476089477539e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3263952732086, "timer/env.step_count": 4101.0, "timer/env.step_total": 141.83354783058167, "timer/env.step_frac": 0.1417872691361345, "timer/env.step_avg": 0.03458511285798139, "timer/env.step_min": 0.002328157424926758, "timer/env.step_max": 0.9137318134307861, "timer/replay._sample_count": 32800.0, "timer/replay._sample_total": 2901.9572575092316, "timer/replay._sample_frac": 2.9010103814332027, "timer/replay._sample_avg": 0.08847430663137901, "timer/replay._sample_min": 0.0004038810729980469, "timer/replay._sample_max": 0.11594939231872559, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5309.0, "timer/agent.policy_total": 54.75568747520447, "timer/agent.policy_frac": 0.054737821309063454, "timer/agent.policy_avg": 0.010313747876286394, "timer/agent.policy_min": 0.0075130462646484375, "timer/agent.policy_max": 0.018558502197265625, "timer/dataset_train_count": 2050.0, "timer/dataset_train_total": 0.16661524772644043, "timer/dataset_train_frac": 0.00016656088304151424, "timer/dataset_train_avg": 8.127573059826362e-05, "timer/dataset_train_min": 6.628036499023438e-05, "timer/dataset_train_max": 0.00025773048400878906, "timer/agent.train_count": 2050.0, "timer/agent.train_total": 762.278995513916, "timer/agent.train_frac": 0.7620302724349514, "timer/agent.train_avg": 0.3718434124458127, "timer/agent.train_min": 0.3495159149169922, "timer/agent.train_max": 0.6454153060913086, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4186084270477295, "timer/agent.report_frac": 0.00041847183981724224, "timer/agent.report_avg": 0.20930421352386475, "timer/agent.report_min": 0.20909714698791504, "timer/agent.report_max": 0.20951128005981445, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.528594970703125e-05, "timer/dataset_eval_frac": 3.5274436297758566e-08, "timer/dataset_eval_avg": 3.528594970703125e-05, "timer/dataset_eval_min": 3.528594970703125e-05, "timer/dataset_eval_max": 3.528594970703125e-05, "fps": 32.79684406361272}
{"step": 492560, "time": 15149.868051290512, "episode/length": 227.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 492800, "time": 15156.8490254879, "episode/length": 182.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 492912, "time": 15160.572789907455, "episode/length": 181.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 493168, "time": 15167.797883033752, "episode/length": 163.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 493288, "time": 15171.547540187836, "episode/length": 90.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.945054945054945, "episode/intrinsic_return": 0.0}
{"step": 493824, "time": 15186.043791532516, "episode/length": 325.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.99079754601227, "episode/intrinsic_return": 0.0}
{"step": 493936, "time": 15189.856647014618, "episode/length": 234.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 494312, "time": 15200.014209032059, "episode/length": 174.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9657142857142857, "episode/intrinsic_return": 0.0}
{"step": 494600, "time": 15208.17125916481, "episode/length": 296.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9730639730639731, "episode/intrinsic_return": 0.0}
{"step": 494648, "time": 15210.144936323166, "episode/length": 184.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 495024, "time": 15220.469740867615, "episode/length": 52.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 495112, "time": 15223.295645952225, "episode/length": 336.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9821958456973294, "episode/intrinsic_return": 0.0}
{"step": 495264, "time": 15228.177205562592, "episode/length": 179.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 495416, "time": 15232.65312409401, "episode/length": 265.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9962406015037594, "episode/intrinsic_return": 0.0}
{"step": 495480, "time": 15235.078786849976, "episode/length": 192.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 495696, "time": 15241.479831933975, "episode/length": 172.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 496024, "time": 15250.236232757568, "episode/length": 402.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9925558312655087, "episode/intrinsic_return": 0.0}
{"step": 496080, "time": 15252.678039073944, "episode/length": 178.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 496544, "time": 15264.77246260643, "episode/length": 159.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 496832, "time": 15272.935739994049, "episode/length": 214.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 496992, "time": 15277.677819490433, "episode/length": 188.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 497048, "time": 15279.784948825836, "episode/length": 252.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9960474308300395, "episode/intrinsic_return": 0.0}
{"step": 497440, "time": 15290.616717338562, "episode/length": 176.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 497928, "time": 15303.662098407745, "episode/length": 230.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 498168, "time": 15310.510843276978, "episode/length": 202.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9802955665024631, "episode/intrinsic_return": 0.0}
{"step": 498288, "time": 15314.561882972717, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 498752, "time": 15326.911043643951, "episode/length": 219.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9727272727272728, "episode/intrinsic_return": 0.0}
{"step": 498816, "time": 15329.35995054245, "episode/length": 424.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9905882352941177, "episode/intrinsic_return": 0.0}
{"step": 498904, "time": 15332.186296701431, "episode/length": 231.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.978448275862069, "episode/intrinsic_return": 0.0}
{"step": 498968, "time": 15334.564794778824, "episode/length": 190.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 499216, "time": 15341.983812332153, "episode/length": 439.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9977272727272727, "episode/intrinsic_return": 0.0}
{"step": 499600, "time": 15352.4846804142, "episode/length": 208.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 499840, "time": 15359.270010232925, "episode/length": 108.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9908256880733946, "episode/intrinsic_return": 0.0}
{"step": 500032, "time": 15366.488543748856, "eval_episode/length": 37.0, "eval_episode/score": 3.100000001490116, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 500032, "time": 15369.40916275978, "eval_episode/length": 160.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9937888198757764}
{"step": 500032, "time": 15370.371071338654, "eval_episode/length": 168.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9704142011834319}
{"step": 500032, "time": 15371.348735809326, "eval_episode/length": 175.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9943181818181818}
{"step": 500032, "time": 15372.693897724152, "eval_episode/length": 201.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9702970297029703}
{"step": 500032, "time": 15373.754729032516, "eval_episode/length": 170.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9649122807017544}
{"step": 500032, "time": 15374.845284938812, "eval_episode/length": 219.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9772727272727273}
{"step": 500032, "time": 15376.988143205643, "eval_episode/length": 286.0, "eval_episode/score": 10.100000023841858, "eval_episode/reward_rate": 0.9965156794425087}
{"step": 500208, "time": 15381.588652610779, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 500720, "time": 15395.3753387928, "episode/length": 109.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.990909090909091, "episode/intrinsic_return": 0.0}
{"step": 500856, "time": 15399.409355401993, "episode/length": 254.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.996078431372549, "episode/intrinsic_return": 0.0}
{"step": 500904, "time": 15401.492350101471, "episode/length": 326.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9969418960244648, "episode/intrinsic_return": 0.0}
{"step": 501048, "time": 15405.873723983765, "episode/length": 359.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 501064, "time": 15407.099658250809, "episode/length": 182.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9672131147540983, "episode/intrinsic_return": 0.0}
{"step": 501176, "time": 15410.683141469955, "episode/length": 120.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9917355371900827, "episode/intrinsic_return": 0.0}
{"step": 501312, "time": 15414.98288846016, "episode/length": 32.0, "episode/score": -0.9000000283122063, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 501368, "time": 15416.96897482872, "episode/length": 268.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9962825278810409, "episode/intrinsic_return": 0.0}
{"step": 501552, "time": 15422.658917188644, "episode/length": 60.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9344262295081968, "episode/intrinsic_return": 0.0}
{"step": 502040, "time": 15435.34763789177, "episode/length": 410.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9781021897810219, "episode/intrinsic_return": 0.0}
{"step": 502448, "time": 15446.579350233078, "episode/length": 198.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 502464, "time": 15447.852496147156, "episode/length": 160.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 502544, "time": 15450.698558568954, "episode/length": 227.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 502880, "time": 15460.275251150131, "episode/length": 246.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 503080, "time": 15465.849646568298, "episode/length": 190.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9842931937172775, "episode/intrinsic_return": 0.0}
{"step": 503128, "time": 15467.895250558853, "episode/length": 219.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 503352, "time": 15474.265982866287, "episode/length": 163.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 503368, "time": 15475.506026506424, "episode/length": 256.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9844357976653697, "episode/intrinsic_return": 0.0}
{"step": 503808, "time": 15487.536928415298, "episode/length": 167.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 504056, "time": 15494.342139482498, "episode/length": 200.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 504536, "time": 15507.190376758575, "episode/length": 248.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9959839357429718, "episode/intrinsic_return": 0.0}
{"step": 504688, "time": 15512.05184173584, "episode/length": 166.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 505000, "time": 15520.512598991394, "episode/length": 203.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 505288, "time": 15528.589127779007, "episode/length": 300.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9800664451827242, "episode/intrinsic_return": 0.0}
{"step": 505568, "time": 15536.755533218384, "episode/length": 219.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9727272727272728, "episode/intrinsic_return": 0.0}
{"step": 506136, "time": 15551.86406302452, "episode/length": 199.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 506304, "time": 15556.995547771454, "episode/length": 201.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 506328, "time": 15558.23709321022, "episode/length": 405.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 506632, "time": 15566.611474514008, "episode/length": 437.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9794520547945206, "episode/intrinsic_return": 0.0}
{"step": 506760, "time": 15570.568818330765, "episode/length": 219.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 506840, "time": 15573.409840345383, "episode/length": 193.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 506976, "time": 15577.843570709229, "episode/length": 364.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9945205479452055, "episode/intrinsic_return": 0.0}
{"step": 507192, "time": 15583.902544021606, "episode/length": 202.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9704433497536946, "episode/intrinsic_return": 0.0}
{"step": 507424, "time": 15590.93141746521, "episode/length": 160.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 507624, "time": 15596.603595256805, "episode/length": 161.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 507856, "time": 15603.446803808212, "episode/length": 109.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.990909090909091, "episode/intrinsic_return": 0.0}
{"step": 508096, "time": 15610.395708560944, "episode/length": 223.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 508208, "time": 15614.049550056458, "episode/length": 170.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 508264, "time": 15616.084110975266, "episode/length": 187.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9627659574468085, "episode/intrinsic_return": 0.0}
{"step": 508848, "time": 15631.939858198166, "episode/length": 177.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9606741573033708, "episode/intrinsic_return": 0.0}
{"step": 509160, "time": 15640.371473550797, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 509680, "time": 15654.579607009888, "episode/length": 256.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9844357976653697, "episode/intrinsic_return": 0.0}
{"step": 509736, "time": 15656.58311009407, "episode/length": 387.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 509976, "time": 15663.348132133484, "episode/length": 234.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 510016, "time": 15668.735168933868, "eval_episode/length": 160.0, "eval_episode/score": 7.100000023841858, "eval_episode/reward_rate": 0.9937888198757764}
{"step": 510016, "time": 15669.5737555027, "eval_episode/length": 161.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9753086419753086}
{"step": 510016, "time": 15671.487435340881, "eval_episode/length": 219.0, "eval_episode/score": 9.099999994039536, "eval_episode/reward_rate": 0.9954545454545455}
{"step": 510016, "time": 15673.09697151184, "eval_episode/length": 263.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9848484848484849}
{"step": 510016, "time": 15674.184575796127, "eval_episode/length": 275.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9963768115942029}
{"step": 510016, "time": 15675.130419969559, "eval_episode/length": 120.0, "eval_episode/score": 7.100000023841858, "eval_episode/reward_rate": 0.9917355371900827}
{"step": 510016, "time": 15676.404774904251, "eval_episode/length": 304.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9967213114754099}
{"step": 510016, "time": 15678.226472139359, "eval_episode/length": 197.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9696969696969697}
{"step": 510112, "time": 15680.712071418762, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 510528, "time": 15692.003150939941, "episode/length": 289.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.996551724137931, "episode/intrinsic_return": 0.0}
{"step": 510592, "time": 15694.458461999893, "episode/length": 178.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 511120, "time": 15708.65606713295, "episode/length": 356.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.988795518207283, "episode/intrinsic_return": 0.0}
{"step": 511304, "time": 15713.96597290039, "episode/length": 195.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 511304, "time": 15714.001899242401, "episode/length": 148.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 511384, "time": 15716.881021261215, "episode/length": 212.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 511696, "time": 15725.767636537552, "episode/length": 562.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9840142095914742, "episode/intrinsic_return": 0.0}
{"step": 511808, "time": 15729.455252170563, "episode/length": 228.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9694323144104804, "episode/intrinsic_return": 0.0}
{"step": 512008, "time": 15735.285389184952, "episode/length": 184.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 512160, "time": 15740.071403265, "episode/length": 195.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 512528, "time": 15750.252924442291, "episode/length": 152.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 512784, "time": 15757.455270767212, "episode/length": 207.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9663461538461539, "episode/intrinsic_return": 0.0}
{"step": 513000, "time": 15763.31847524643, "episode/length": 201.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 513224, "time": 15769.90926861763, "episode/length": 190.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 513696, "time": 15782.834389209747, "episode/length": 235.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9745762711864406, "episode/intrinsic_return": 0.0}
{"step": 513824, "time": 15786.859854698181, "episode/length": 207.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 514112, "time": 15794.962332725525, "episode/length": 197.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9646464646464646, "episode/intrinsic_return": 0.0}
{"step": 514136, "time": 15796.228805541992, "episode/length": 141.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.971830985915493, "episode/intrinsic_return": 0.0}
{"step": 514208, "time": 15799.011820793152, "episode/length": 274.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9963636363636363, "episode/intrinsic_return": 0.0}
{"step": 514264, "time": 15800.996073007584, "episode/length": 184.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 514608, "time": 15810.519316673279, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 515376, "time": 15830.654500722885, "episode/length": 508.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9823182711198428, "episode/intrinsic_return": 0.0}
{"step": 515528, "time": 15835.178669452667, "episode/length": 212.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 515624, "time": 15838.362372159958, "episode/length": 240.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.995850622406639, "episode/intrinsic_return": 0.0}
{"step": 515688, "time": 15840.832273483276, "episode/length": 134.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 515824, "time": 15845.228738307953, "episode/length": 201.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 516144, "time": 15854.095584869385, "episode/length": 250.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9760956175298805, "episode/intrinsic_return": 0.0}
{"step": 516592, "time": 15866.168986320496, "episode/length": 309.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9967741935483871, "episode/intrinsic_return": 0.0}
{"step": 516696, "time": 15869.407648324966, "episode/length": 303.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9769736842105263, "episode/intrinsic_return": 0.0}
{"step": 517120, "time": 15881.295717000961, "episode/length": 178.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 517144, "time": 15882.562067508698, "episode/length": 201.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9702970297029703, "episode/intrinsic_return": 0.0}
{"step": 517328, "time": 15888.217267513275, "episode/length": 243.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9631147540983607, "episode/intrinsic_return": 0.0}
{"step": 517360, "time": 15889.814145088196, "episode/length": 216.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 517768, "time": 15900.84720826149, "episode/length": 242.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9958847736625515, "episode/intrinsic_return": 0.0}
{"step": 518096, "time": 15910.14328789711, "episode/length": 243.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 518232, "time": 15914.128148317337, "episode/length": 191.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 518248, "time": 15915.40310382843, "episode/length": 137.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9565217391304348, "episode/intrinsic_return": 0.0}
{"step": 518760, "time": 15929.00813627243, "episode/length": 204.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 518792, "time": 15930.610912561417, "episode/length": 274.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9854545454545455, "episode/intrinsic_return": 0.0}
{"step": 518856, "time": 15933.057472229004, "episode/length": 190.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 519024, "time": 15938.295253515244, "episode/length": 115.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9482758620689655, "episode/intrinsic_return": 0.0}
{"step": 519296, "time": 15945.855013370514, "episode/length": 190.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 519832, "time": 15959.670867681503, "episode/length": 199.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 520000, "time": 15966.746178865433, "eval_episode/length": 49.0, "eval_episode/score": 5.0999999940395355, "eval_episode/reward_rate": 0.98}
{"step": 520000, "time": 15968.742241621017, "eval_episode/length": 115.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9568965517241379}
{"step": 520000, "time": 15970.409744739532, "eval_episode/length": 160.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.968944099378882}
{"step": 520000, "time": 15971.608332395554, "eval_episode/length": 181.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9615384615384616}
{"step": 520000, "time": 15973.293087005615, "eval_episode/length": 225.0, "eval_episode/score": 7.099999964237213, "eval_episode/reward_rate": 0.9734513274336283}
{"step": 520000, "time": 15974.481406211853, "eval_episode/length": 243.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9754098360655737}
{"step": 520000, "time": 15976.59540438652, "eval_episode/length": 310.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9903536977491961}
{"step": 520000, "time": 15978.631257772446, "eval_episode/length": 188.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9947089947089947}
{"step": 520096, "time": 15981.239649772644, "episode/length": 133.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9925373134328358, "episode/intrinsic_return": 0.0}
{"step": 520416, "time": 15990.308370113373, "episode/length": 194.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9692307692307692, "episode/intrinsic_return": 0.0}
{"step": 520552, "time": 15994.31935596466, "episode/length": 219.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 520648, "time": 15997.578387498856, "episode/length": 168.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 520704, "time": 16000.103481769562, "episode/length": 242.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9958847736625515, "episode/intrinsic_return": 0.0}
{"step": 520880, "time": 16005.435992717743, "episode/length": 439.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9795454545454545, "episode/intrinsic_return": 0.0}
{"step": 521032, "time": 16009.915536165237, "episode/length": 47.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8958333333333334, "episode/intrinsic_return": 0.0}
{"step": 521288, "time": 16017.14705657959, "episode/length": 379.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 521488, "time": 16023.149879932404, "episode/length": 206.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9710144927536232, "episode/intrinsic_return": 0.0}
{"step": 521888, "time": 16034.07521033287, "episode/length": 166.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 521992, "time": 16037.288598775864, "episode/length": 160.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 522056, "time": 16039.712213516235, "episode/length": 204.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 522216, "time": 16044.66582608223, "episode/length": 166.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 522648, "time": 16056.533065319061, "episode/length": 81.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9390243902439024, "episode/intrinsic_return": 0.0}
{"step": 522808, "time": 16061.416084766388, "episode/length": 189.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 522848, "time": 16063.49083685875, "episode/length": 343.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 523328, "time": 16076.467375516891, "episode/length": 179.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 523424, "time": 16079.735555887222, "episode/length": 170.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 523840, "time": 16090.90417432785, "episode/length": 202.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 524184, "time": 16100.115787267685, "episode/length": 393.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9974619289340102, "episode/intrinsic_return": 0.0}
{"step": 524408, "time": 16106.584118127823, "episode/length": 219.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 524440, "time": 16108.23199748993, "episode/length": 203.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 524680, "time": 16114.970880031586, "episode/length": 398.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9774436090225563, "episode/intrinsic_return": 0.0}
{"step": 524992, "time": 16123.80215215683, "episode/length": 195.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 525152, "time": 16128.67227602005, "episode/length": 120.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9917355371900827, "episode/intrinsic_return": 0.0}
{"step": 525801, "time": 16146.33600640297, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.371221076928828, "train/action_min": 0.0, "train/action_std": 3.2099228190463127, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04425699875186505, "train/actor_opt_grad_steps": 31720.0, "train/actor_opt_loss": -4.482609179352174, "train/adv_mag": 0.6313413052182448, "train/adv_max": 0.6199339802185314, "train/adv_mean": 0.0036358358269893234, "train/adv_min": -0.43981134649098774, "train/adv_std": 0.0678853707913862, "train/cont_avg": 0.9947667464114832, "train/cont_loss_mean": 0.00016390860802837932, "train/cont_loss_std": 0.004899980069437429, "train/cont_neg_acc": 0.9980728338209636, "train/cont_neg_loss": 0.008866783914692694, "train/cont_pos_acc": 0.9999623478314523, "train/cont_pos_loss": 0.00011464708076535575, "train/cont_pred": 0.9947343696817827, "train/cont_rate": 0.9947667464114832, "train/dyn_loss_mean": 13.69685935061514, "train/dyn_loss_std": 9.15051871851871, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8178392731401909, "train/extr_critic_critic_opt_grad_steps": 31720.0, "train/extr_critic_critic_opt_loss": 15647.48682808762, "train/extr_critic_mag": 5.36753666800175, "train/extr_critic_max": 5.36753666800175, "train/extr_critic_mean": 0.9974724807237324, "train/extr_critic_min": -0.32063452193611547, "train/extr_critic_std": 1.1999378495239186, "train/extr_return_normed_mag": 1.7824612884430224, "train/extr_return_normed_max": 1.7824612884430224, "train/extr_return_normed_mean": 0.3036400469011097, "train/extr_return_normed_min": -0.13278396445455734, "train/extr_return_normed_std": 0.3325741805100555, "train/extr_return_rate": 0.4989652103214173, "train/extr_return_raw_mag": 6.488353811382677, "train/extr_return_raw_max": 6.488353811382677, "train/extr_return_raw_mean": 1.0109847607224751, "train/extr_return_raw_min": -0.6063998211799055, "train/extr_return_raw_std": 1.2323792260229303, "train/extr_reward_mag": 1.0134307448373456, "train/extr_reward_max": 1.0134307448373456, "train/extr_reward_mean": 0.0281192287089722, "train/extr_reward_min": -0.3568991747769443, "train/extr_reward_std": 0.15748227819016106, "train/image_loss_mean": 7.179581724285509, "train/image_loss_std": 11.62837836388766, "train/model_loss_mean": 15.449743225243674, "train/model_loss_std": 15.407310421957353, "train/model_opt_grad_norm": 60.97760664104845, "train/model_opt_grad_steps": 31690.507177033494, "train/model_opt_loss": 14671.919723291716, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 950.9569377990431, "train/policy_entropy_mag": 2.544854978625284, "train/policy_entropy_max": 2.544854978625284, "train/policy_entropy_mean": 0.6560260495215512, "train/policy_entropy_min": 0.0793750805504014, "train/policy_entropy_std": 0.6712701831137735, "train/policy_logprob_mag": 7.43838340585882, "train/policy_logprob_max": -0.00945567114626249, "train/policy_logprob_mean": -0.6570217185898831, "train/policy_logprob_min": -7.43838340585882, "train/policy_logprob_std": 1.1645290070173273, "train/policy_randomness_mag": 0.8982221275995793, "train/policy_randomness_max": 0.8982221275995793, "train/policy_randomness_mean": 0.23154840757401937, "train/policy_randomness_min": 0.028015920143734895, "train/policy_randomness_std": 0.23692891586340215, "train/post_ent_mag": 58.789497247723304, "train/post_ent_max": 58.789497247723304, "train/post_ent_mean": 41.577809018951854, "train/post_ent_min": 20.890397961630207, "train/post_ent_std": 7.300653617347827, "train/prior_ent_mag": 67.88628891210237, "train/prior_ent_max": 67.88628891210237, "train/prior_ent_mean": 55.35876636413866, "train/prior_ent_min": 41.24977498761775, "train/prior_ent_std": 4.532160518272072, "train/rep_loss_mean": 13.69685935061514, "train/rep_loss_std": 9.15051871851871, "train/reward_avg": 0.024282296453312965, "train/reward_loss_mean": 0.051882044835524124, "train/reward_loss_std": 0.24063322076386812, "train/reward_max_data": 1.0086124422447533, "train/reward_max_pred": 1.004769617290588, "train/reward_neg_acc": 0.993938729238282, "train/reward_neg_loss": 0.028040005700689468, "train/reward_pos_acc": 0.9663307877818933, "train/reward_pos_loss": 0.8534663020138535, "train/reward_pred": 0.023625149973111145, "train/reward_rate": 0.029016522129186602, "train_stats/sum_log_reward": 6.902721151608188, "train_stats/max_log_achievement_collect_coal": 0.3197278911564626, "train_stats/max_log_achievement_collect_drink": 6.782312925170068, "train_stats/max_log_achievement_collect_sapling": 1.782312925170068, "train_stats/max_log_achievement_collect_stone": 4.136054421768708, "train_stats/max_log_achievement_collect_wood": 10.034013605442176, "train_stats/max_log_achievement_defeat_skeleton": 0.006802721088435374, "train_stats/max_log_achievement_defeat_zombie": 0.2653061224489796, "train_stats/max_log_achievement_eat_cow": 0.04081632653061224, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 2.4149659863945576, "train_stats/max_log_achievement_make_wood_sword": 0.013605442176870748, "train_stats/max_log_achievement_place_furnace": 0.08163265306122448, "train_stats/max_log_achievement_place_plant": 1.6598639455782314, "train_stats/max_log_achievement_place_stone": 1.1224489795918366, "train_stats/max_log_achievement_place_table": 3.421768707482993, "train_stats/max_log_achievement_wake_up": 1.4421768707482994, "train_stats/mean_log_entropy": 0.6433427350050738, "eval_stats/sum_log_reward": 6.891666769981384, "eval_stats/max_log_achievement_collect_coal": 0.3333333333333333, "eval_stats/max_log_achievement_collect_drink": 4.875, "eval_stats/max_log_achievement_collect_sapling": 1.9583333333333333, "eval_stats/max_log_achievement_collect_stone": 4.541666666666667, "eval_stats/max_log_achievement_collect_wood": 9.166666666666666, "eval_stats/max_log_achievement_defeat_skeleton": 0.041666666666666664, "eval_stats/max_log_achievement_defeat_zombie": 0.25, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 2.7083333333333335, "eval_stats/max_log_achievement_make_wood_sword": 0.041666666666666664, "eval_stats/max_log_achievement_place_furnace": 0.08333333333333333, "eval_stats/max_log_achievement_place_plant": 1.9166666666666667, "eval_stats/max_log_achievement_place_stone": 0.7916666666666666, "eval_stats/max_log_achievement_place_table": 2.8333333333333335, "eval_stats/max_log_achievement_wake_up": 1.0, "eval_stats/mean_log_entropy": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.029411764705882353, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 3.6954742199668544e-07, "report/cont_loss_std": 1.922731144077261e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 1.1807983355538454e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 3.134216228772857e-07, "report/cont_pred": 0.9951170682907104, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 14.753580093383789, "report/dyn_loss_std": 9.277460098266602, "report/image_loss_mean": 6.9277567863464355, "report/image_loss_std": 10.15563678741455, "report/model_loss_mean": 15.839908599853516, "report/model_loss_std": 14.32395076751709, "report/post_ent_mag": 56.33287811279297, "report/post_ent_max": 56.33287811279297, "report/post_ent_mean": 39.64158630371094, "report/post_ent_min": 18.98660659790039, "report/post_ent_std": 6.7964935302734375, "report/prior_ent_mag": 66.9853744506836, "report/prior_ent_max": 66.9853744506836, "report/prior_ent_mean": 54.991600036621094, "report/prior_ent_min": 38.16461944580078, "report/prior_ent_std": 4.268303871154785, "report/rep_loss_mean": 14.753580093383789, "report/rep_loss_std": 9.277460098266602, "report/reward_avg": 0.02490234375, "report/reward_loss_mean": 0.06000398471951485, "report/reward_loss_std": 0.27485474944114685, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0004370212554932, "report/reward_neg_acc": 0.9919435977935791, "report/reward_neg_loss": 0.03460763394832611, "report/reward_pos_acc": 0.9354838132858276, "report/reward_pos_loss": 0.873506486415863, "report/reward_pred": 0.024910051375627518, "report/reward_rate": 0.0302734375, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 1.1734146028175019e-06, "eval/cont_loss_std": 2.7216234229854308e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 6.073770236980636e-06, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.1638247769951704e-06, "eval/cont_pred": 0.998045802116394, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 17.994766235351562, "eval/dyn_loss_std": 10.670734405517578, "eval/image_loss_mean": 14.032711029052734, "eval/image_loss_std": 20.887842178344727, "eval/model_loss_mean": 24.912445068359375, "eval/model_loss_std": 25.270124435424805, "eval/post_ent_mag": 58.17371368408203, "eval/post_ent_max": 58.17371368408203, "eval/post_ent_mean": 40.90726852416992, "eval/post_ent_min": 22.193817138671875, "eval/post_ent_std": 7.154141426086426, "eval/prior_ent_mag": 66.9853744506836, "eval/prior_ent_max": 66.9853744506836, "eval/prior_ent_mean": 56.46839141845703, "eval/prior_ent_min": 39.778011322021484, "eval/prior_ent_std": 4.2213873863220215, "eval/rep_loss_mean": 17.994766235351562, "eval/rep_loss_std": 10.670734405517578, "eval/reward_avg": 0.007617187686264515, "eval/reward_loss_mean": 0.08287234604358673, "eval/reward_loss_std": 0.49390068650245667, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9999550580978394, "eval/reward_neg_acc": 0.9891412258148193, "eval/reward_neg_loss": 0.06475215405225754, "eval/reward_pos_acc": 0.7272727489471436, "eval/reward_pos_loss": 1.7515783309936523, "eval/reward_pred": 0.009805887937545776, "eval/reward_rate": 0.0107421875, "replay/size": 525297.0, "replay/inserts": 33384.0, "replay/samples": 33392.0, "replay/insert_wait_avg": 1.2151320261147392e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 5.803313275873232e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 8136.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2271992693725707e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.046627044677734e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1455607414246, "timer/env.step_count": 4173.0, "timer/env.step_total": 135.89861249923706, "timer/env.step_frac": 0.13587883387543426, "timer/env.step_avg": 0.032566166426848085, "timer/env.step_min": 0.002360105514526367, "timer/env.step_max": 0.9265058040618896, "timer/replay._sample_count": 33392.0, "timer/replay._sample_total": 2956.589916944504, "timer/replay._sample_frac": 2.9561596161590065, "timer/replay._sample_avg": 0.08854186382799784, "timer/replay._sample_min": 0.00035381317138671875, "timer/replay._sample_max": 0.11914682388305664, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5190.0, "timer/agent.policy_total": 53.488290548324585, "timer/agent.policy_frac": 0.05348050588623603, "timer/agent.policy_avg": 0.010306029007384313, "timer/agent.policy_min": 0.007771492004394531, "timer/agent.policy_max": 0.01887989044189453, "timer/dataset_train_count": 2087.0, "timer/dataset_train_total": 0.16980981826782227, "timer/dataset_train_frac": 0.00016978510422216883, "timer/dataset_train_avg": 8.136550947188417e-05, "timer/dataset_train_min": 5.9604644775390625e-05, "timer/dataset_train_max": 0.00018286705017089844, "timer/agent.train_count": 2087.0, "timer/agent.train_total": 776.8405153751373, "timer/agent.train_frac": 0.7767274543509972, "timer/agent.train_avg": 0.37222832552713814, "timer/agent.train_min": 0.34870219230651855, "timer/agent.train_max": 0.5861029624938965, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4152345657348633, "timer/agent.report_frac": 0.00041517413268029, "timer/agent.report_avg": 0.20761728286743164, "timer/agent.report_min": 0.20643329620361328, "timer/agent.report_max": 0.20880126953125, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.314018249511719e-05, "timer/dataset_eval_frac": 3.313535928765191e-08, "timer/dataset_eval_avg": 3.314018249511719e-05, "timer/dataset_eval_min": 3.314018249511719e-05, "timer/dataset_eval_max": 3.314018249511719e-05, "fps": 33.378691119584886}
{"step": 525808, "time": 16146.375597715378, "episode/length": 309.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9870967741935484, "episode/intrinsic_return": 0.0}
{"step": 526144, "time": 16157.609434604645, "episode/length": 143.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 526240, "time": 16160.896083831787, "episode/length": 224.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 526264, "time": 16162.164196252823, "episode/length": 197.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 526272, "time": 16163.440698623657, "episode/length": 427.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9789719626168224, "episode/intrinsic_return": 0.0}
{"step": 526568, "time": 16171.52694940567, "episode/length": 176.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 527088, "time": 16185.61363363266, "episode/length": 334.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.991044776119403, "episode/intrinsic_return": 0.0}
{"step": 527408, "time": 16194.384655237198, "episode/length": 39.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 527424, "time": 16195.62269282341, "episode/length": 447.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9799107142857143, "episode/intrinsic_return": 0.0}
{"step": 527656, "time": 16202.267215013504, "episode/length": 176.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9661016949152542, "episode/intrinsic_return": 0.0}
{"step": 527760, "time": 16205.944204568863, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 527800, "time": 16207.60731101036, "episode/length": 206.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 527928, "time": 16211.765569925308, "episode/length": 264.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9962264150943396, "episode/intrinsic_return": 0.0}
{"step": 528048, "time": 16215.790360927582, "episode/length": 184.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 528496, "time": 16227.847195386887, "episode/length": 278.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.974910394265233, "episode/intrinsic_return": 0.0}
{"step": 528840, "time": 16236.988104104996, "episode/length": 178.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 528976, "time": 16241.348120450974, "episode/length": 193.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9845360824742269, "episode/intrinsic_return": 0.0}
{"step": 529104, "time": 16245.347045898438, "episode/length": 167.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 529192, "time": 16248.234917402267, "episode/length": 157.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 529216, "time": 16249.863036870956, "episode/length": 46.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 529264, "time": 16251.965665340424, "episode/length": 200.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9800995024875622, "episode/intrinsic_return": 0.0}
{"step": 529328, "time": 16254.349037885666, "episode/length": 190.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 529488, "time": 16259.098349571228, "episode/length": 179.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 530088, "time": 16277.623717069626, "eval_episode/length": 124.0, "eval_episode/score": 9.099999994039536, "eval_episode/reward_rate": 0.992}
{"step": 530088, "time": 16278.886398553848, "eval_episode/length": 147.0, "eval_episode/score": 7.100000023841858, "eval_episode/reward_rate": 0.9932432432432432}
{"step": 530088, "time": 16280.351346254349, "eval_episode/length": 181.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9725274725274725}
{"step": 530088, "time": 16281.268693208694, "eval_episode/length": 187.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.973404255319149}
{"step": 530088, "time": 16282.800156354904, "eval_episode/length": 222.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9775784753363229}
{"step": 530088, "time": 16283.674265146255, "eval_episode/length": 225.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.995575221238938}
{"step": 530088, "time": 16285.480944395065, "eval_episode/length": 49.0, "eval_episode/score": 4.099999971687794, "eval_episode/reward_rate": 0.98}
{"step": 530088, "time": 16286.497158765793, "eval_episode/length": 102.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9514563106796117}
{"step": 530464, "time": 16296.214350938797, "episode/length": 169.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 530712, "time": 16303.135452508926, "episode/length": 189.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.968421052631579, "episode/intrinsic_return": 0.0}
{"step": 530712, "time": 16303.17255973816, "episode/length": 216.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9723502304147466, "episode/intrinsic_return": 0.0}
{"step": 530792, "time": 16306.025887489319, "episode/length": 182.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9672131147540983, "episode/intrinsic_return": 0.0}
{"step": 530832, "time": 16308.085819244385, "episode/length": 201.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 531424, "time": 16323.687062978745, "episode/length": 269.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 531776, "time": 16333.201541662216, "episode/length": 409.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9780487804878049, "episode/intrinsic_return": 0.0}
{"step": 531816, "time": 16334.856017112732, "episode/length": 168.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9644970414201184, "episode/intrinsic_return": 0.0}
{"step": 531936, "time": 16338.944015741348, "episode/length": 142.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 531968, "time": 16340.666619300842, "episode/length": 309.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9806451612903225, "episode/intrinsic_return": 0.0}
{"step": 532488, "time": 16354.47484755516, "episode/length": 221.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9819819819819819, "episode/intrinsic_return": 0.0}
{"step": 532624, "time": 16358.955782175064, "episode/length": 238.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9748953974895398, "episode/intrinsic_return": 0.0}
{"step": 532696, "time": 16361.39198422432, "episode/length": 232.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9785407725321889, "episode/intrinsic_return": 0.0}
{"step": 532704, "time": 16362.655170202255, "episode/length": 159.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.95625, "episode/intrinsic_return": 0.0}
{"step": 533104, "time": 16373.58182835579, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 533328, "time": 16379.999654054642, "episode/length": 188.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 533584, "time": 16387.22052502632, "episode/length": 205.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 533880, "time": 16395.24979543686, "episode/length": 173.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 533992, "time": 16398.86333656311, "episode/length": 252.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9723320158102767, "episode/intrinsic_return": 0.0}
{"step": 534248, "time": 16406.13252210617, "episode/length": 202.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9704433497536946, "episode/intrinsic_return": 0.0}
{"step": 534320, "time": 16409.04167699814, "episode/length": 201.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9702970297029703, "episode/intrinsic_return": 0.0}
{"step": 534320, "time": 16409.053203344345, "episode/length": 202.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 534640, "time": 16417.937858581543, "episode/length": 39.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 534824, "time": 16423.23655438423, "episode/length": 186.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 535120, "time": 16431.757735729218, "episode/length": 251.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 535280, "time": 16436.538670539856, "episode/length": 160.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 535304, "time": 16437.83238053322, "episode/length": 59.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 535480, "time": 16443.015545368195, "episode/length": 199.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.97, "episode/intrinsic_return": 0.0}
{"step": 535584, "time": 16446.609206438065, "episode/length": 166.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 535784, "time": 16452.199041366577, "episode/length": 37.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 535928, "time": 16456.590151309967, "episode/length": 160.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 536144, "time": 16462.954675912857, "episode/length": 319.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9875, "episode/intrinsic_return": 0.0}
{"step": 536528, "time": 16473.440928936005, "episode/length": 175.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 537024, "time": 16486.58837413788, "episode/length": 217.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 537080, "time": 16488.687685489655, "episode/length": 221.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9819819819819819, "episode/intrinsic_return": 0.0}
{"step": 537280, "time": 16494.839756011963, "episode/length": 211.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 537288, "time": 16495.677626609802, "episode/length": 187.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 537664, "time": 16505.97562122345, "episode/length": 417.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9784688995215312, "episode/intrinsic_return": 0.0}
{"step": 537712, "time": 16508.007410287857, "episode/length": 222.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 537752, "time": 16509.641431093216, "episode/length": 57.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 537776, "time": 16511.348572015762, "episode/length": 203.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 537776, "time": 16511.39147090912, "episode/length": 155.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 538584, "time": 16532.209843873978, "episode/length": 114.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.991304347826087, "episode/intrinsic_return": 0.0}
{"step": 538712, "time": 16536.23320865631, "episode/length": 178.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 538880, "time": 16541.532709360123, "episode/length": 137.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9927536231884058, "episode/intrinsic_return": 0.0}
{"step": 538904, "time": 16542.740047693253, "episode/length": 234.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 539072, "time": 16548.048969984055, "episode/length": 248.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9959839357429718, "episode/intrinsic_return": 0.0}
{"step": 539112, "time": 16549.65485405922, "episode/length": 174.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 539424, "time": 16558.310549020767, "episode/length": 208.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 539880, "time": 16570.305987358093, "episode/length": 262.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9961977186311787, "episode/intrinsic_return": 0.0}
{"step": 540064, "time": 16575.95815396309, "episode/length": 168.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 540072, "time": 16580.423102617264, "eval_episode/length": 139.0, "eval_episode/score": 8.100000023841858, "eval_episode/reward_rate": 0.9928571428571429}
{"step": 540072, "time": 16581.56767821312, "eval_episode/length": 153.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9675324675324676}
{"step": 540072, "time": 16582.930322408676, "eval_episode/length": 177.0, "eval_episode/score": 7.099999964237213, "eval_episode/reward_rate": 0.9719101123595506}
{"step": 540072, "time": 16583.929312705994, "eval_episode/length": 185.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.967741935483871}
{"step": 540072, "time": 16584.790350437164, "eval_episode/length": 186.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9732620320855615}
{"step": 540072, "time": 16586.163818120956, "eval_episode/length": 204.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9804878048780488}
{"step": 540072, "time": 16587.27167081833, "eval_episode/length": 226.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9779735682819384}
{"step": 540072, "time": 16588.278083324432, "eval_episode/length": 49.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9}
{"step": 540352, "time": 16595.61612200737, "episode/length": 159.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 540384, "time": 16597.22136068344, "episode/length": 184.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 540528, "time": 16601.607305288315, "episode/length": 176.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 540640, "time": 16605.143620491028, "episode/length": 219.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9863636363636363, "episode/intrinsic_return": 0.0}
{"step": 540888, "time": 16612.092305660248, "episode/length": 287.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9861111111111112, "episode/intrinsic_return": 0.0}
{"step": 541112, "time": 16618.56365418434, "episode/length": 153.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 541208, "time": 16621.892727851868, "episode/length": 222.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.968609865470852, "episode/intrinsic_return": 0.0}
{"step": 541496, "time": 16629.877374887466, "episode/length": 178.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 541704, "time": 16635.949177503586, "episode/length": 164.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9575757575757575, "episode/intrinsic_return": 0.0}
{"step": 541960, "time": 16643.166047811508, "episode/length": 200.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 542272, "time": 16652.04053926468, "episode/length": 38.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 542344, "time": 16654.42026734352, "episode/length": 181.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 542584, "time": 16661.186325073242, "episode/length": 183.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 542680, "time": 16664.43830704689, "episode/length": 147.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9594594594594594, "episode/intrinsic_return": 0.0}
{"step": 542864, "time": 16670.04101729393, "episode/length": 206.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 543272, "time": 16680.89385342598, "episode/length": 195.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 543632, "time": 16691.017510652542, "episode/length": 160.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 543656, "time": 16692.25037097931, "episode/length": 390.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9974424552429667, "episode/intrinsic_return": 0.0}
{"step": 543752, "time": 16695.4072971344, "episode/length": 184.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 544040, "time": 16703.632329702377, "episode/length": 50.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 544072, "time": 16705.36637878418, "episode/length": 185.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 544296, "time": 16711.901772499084, "episode/length": 178.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 544392, "time": 16715.155143737793, "episode/length": 213.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 544688, "time": 16723.602578163147, "episode/length": 80.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9876543209876543, "episode/intrinsic_return": 0.0}
{"step": 544808, "time": 16727.185275554657, "episode/length": 191.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.984375, "episode/intrinsic_return": 0.0}
{"step": 544944, "time": 16731.59394145012, "episode/length": 537.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.983271375464684, "episode/intrinsic_return": 0.0}
{"step": 545272, "time": 16740.540229320526, "episode/length": 201.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 545504, "time": 16747.281672477722, "episode/length": 218.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9726027397260274, "episode/intrinsic_return": 0.0}
{"step": 545552, "time": 16749.397711515427, "episode/length": 34.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 545584, "time": 16751.083313941956, "episode/length": 160.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 545952, "time": 16761.354027986526, "episode/length": 157.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 546040, "time": 16764.1940741539, "episode/length": 245.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9959349593495935, "episode/intrinsic_return": 0.0}
{"step": 546184, "time": 16768.50055217743, "episode/length": 171.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9825581395348837, "episode/intrinsic_return": 0.0}
{"step": 546272, "time": 16771.64599585533, "episode/length": 165.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 547408, "time": 16800.978099107742, "episode/length": 227.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 547424, "time": 16802.243928670883, "episode/length": 233.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9829059829059829, "episode/intrinsic_return": 0.0}
{"step": 547504, "time": 16805.115332365036, "episode/length": 182.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 547568, "time": 16807.59949874878, "episode/length": 201.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 547640, "time": 16810.09937953949, "episode/length": 405.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9901477832512315, "episode/intrinsic_return": 0.0}
{"step": 547648, "time": 16811.37226819992, "episode/length": 182.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 547904, "time": 16818.55179166794, "episode/length": 203.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 548176, "time": 16826.26115322113, "episode/length": 33.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 548192, "time": 16827.560613155365, "episode/length": 335.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9851190476190477, "episode/intrinsic_return": 0.0}
{"step": 548512, "time": 16836.51619076729, "episode/length": 125.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9920634920634921, "episode/intrinsic_return": 0.0}
{"step": 548800, "time": 16844.595556259155, "episode/length": 173.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 548904, "time": 16848.02220082283, "episode/length": 166.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 549312, "time": 16859.043422698975, "episode/length": 235.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 549360, "time": 16861.058071374893, "episode/length": 213.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 549592, "time": 16867.423057556152, "episode/length": 174.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 549704, "time": 16871.177401304245, "episode/length": 190.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 549848, "time": 16875.69718527794, "episode/length": 166.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 550056, "time": 16885.17512321472, "eval_episode/length": 158.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9937106918238994}
{"step": 550056, "time": 16886.573590755463, "eval_episode/length": 187.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9787234042553191}
{"step": 550056, "time": 16887.796526670456, "eval_episode/length": 206.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.961352657004831}
{"step": 550056, "time": 16888.844011306763, "eval_episode/length": 217.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9954128440366973}
{"step": 550056, "time": 16889.784447431564, "eval_episode/length": 223.0, "eval_episode/score": 6.099999971687794, "eval_episode/reward_rate": 0.9955357142857143}
{"step": 550056, "time": 16891.43490076065, "eval_episode/length": 104.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9904761904761905}
{"step": 550056, "time": 16892.78876233101, "eval_episode/length": 287.0, "eval_episode/score": 7.0999999940395355, "eval_episode/reward_rate": 0.9965277777777778}
{"step": 550056, "time": 16894.571343898773, "eval_episode/length": 147.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9527027027027027}
{"step": 550192, "time": 16898.501936912537, "episode/length": 318.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9811912225705329, "episode/intrinsic_return": 0.0}
{"step": 550672, "time": 16911.294343471527, "episode/length": 169.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9647058823529412, "episode/intrinsic_return": 0.0}
{"step": 550776, "time": 16914.561264276505, "episode/length": 233.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9829059829059829, "episode/intrinsic_return": 0.0}
{"step": 551008, "time": 16921.426728725433, "episode/length": 205.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 551528, "time": 16934.9552154541, "episode/length": 227.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9780701754385965, "episode/intrinsic_return": 0.0}
{"step": 551584, "time": 16937.36521434784, "episode/length": 347.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9913793103448276, "episode/intrinsic_return": 0.0}
{"step": 551608, "time": 16938.61419391632, "episode/length": 219.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9727272727272728, "episode/intrinsic_return": 0.0}
{"step": 551616, "time": 16939.81702518463, "episode/length": 177.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9662921348314607, "episode/intrinsic_return": 0.0}
{"step": 552152, "time": 16953.80033183098, "episode/length": 142.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 552160, "time": 16954.987662792206, "episode/length": 172.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 552376, "time": 16961.26469182968, "episode/length": 347.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.985632183908046, "episode/intrinsic_return": 0.0}
{"step": 552488, "time": 16964.976315259933, "episode/length": 226.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 552976, "time": 16978.15130352974, "episode/length": 102.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9902912621359223, "episode/intrinsic_return": 0.0}
{"step": 553344, "time": 16988.102492809296, "episode/length": 216.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 553360, "time": 16989.298161506653, "episode/length": 228.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9781659388646288, "episode/intrinsic_return": 0.0}
{"step": 553384, "time": 16990.56595492363, "episode/length": 224.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 553632, "time": 16997.92651104927, "episode/length": 156.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 554000, "time": 17007.912877082825, "episode/length": 127.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9921875, "episode/intrinsic_return": 0.0}
{"step": 554288, "time": 17015.91481399536, "episode/length": 224.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 554720, "time": 17027.55846595764, "episode/length": 387.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9871134020618557, "episode/intrinsic_return": 0.0}
{"step": 554720, "time": 17027.595488786697, "episode/length": 319.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.996875, "episode/intrinsic_return": 0.0}
{"step": 554880, "time": 17032.412045001984, "episode/length": 191.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 555256, "time": 17042.36847114563, "episode/length": 202.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9704433497536946, "episode/intrinsic_return": 0.0}
{"step": 555416, "time": 17047.11642074585, "episode/length": 176.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 555720, "time": 17055.54127550125, "episode/length": 178.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 555784, "time": 17057.983601808548, "episode/length": 302.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.976897689768977, "episode/intrinsic_return": 0.0}
{"step": 555952, "time": 17063.342903137207, "episode/length": 153.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 556152, "time": 17069.03937959671, "episode/length": 345.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9913294797687862, "episode/intrinsic_return": 0.0}
{"step": 556192, "time": 17071.03360271454, "episode/length": 163.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 556280, "time": 17073.88454937935, "episode/length": 194.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 556416, "time": 17078.227660894394, "episode/length": 144.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 557040, "time": 17094.69321513176, "episode/length": 164.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9636363636363636, "episode/intrinsic_return": 0.0}
{"step": 557488, "time": 17107.00399184227, "episode/length": 150.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 557528, "time": 17108.667539834976, "episode/length": 138.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9712230215827338, "episode/intrinsic_return": 0.0}
{"step": 557608, "time": 17111.5099234581, "episode/length": 227.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 557808, "time": 17117.61371064186, "episode/length": 298.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9765886287625418, "episode/intrinsic_return": 0.0}
{"step": 557936, "time": 17121.596604824066, "episode/length": 217.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 558456, "time": 17135.096585273743, "episode/length": 312.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9968051118210862, "episode/intrinsic_return": 0.0}
{"step": 558520, "time": 17137.561287164688, "episode/length": 295.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9763513513513513, "episode/intrinsic_return": 0.0}
{"step": 558744, "time": 17143.98390007019, "episode/length": 212.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 558777, "time": 17146.497453927994, "train_stats/sum_log_reward": 7.409091039137407, "train_stats/max_log_achievement_collect_coal": 0.3696969696969697, "train_stats/max_log_achievement_collect_drink": 5.454545454545454, "train_stats/max_log_achievement_collect_sapling": 1.4242424242424243, "train_stats/max_log_achievement_collect_stone": 5.236363636363636, "train_stats/max_log_achievement_collect_wood": 11.606060606060606, "train_stats/max_log_achievement_defeat_skeleton": 0.012121212121212121, "train_stats/max_log_achievement_defeat_zombie": 0.38181818181818183, "train_stats/max_log_achievement_eat_cow": 0.048484848484848485, "train_stats/max_log_achievement_make_stone_pickaxe": 0.012121212121212121, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 3.393939393939394, "train_stats/max_log_achievement_make_wood_sword": 0.012121212121212121, "train_stats/max_log_achievement_place_furnace": 0.05454545454545454, "train_stats/max_log_achievement_place_plant": 1.3636363636363635, "train_stats/max_log_achievement_place_stone": 2.2545454545454544, "train_stats/max_log_achievement_place_table": 3.496969696969697, "train_stats/max_log_achievement_wake_up": 1.3212121212121213, "train_stats/mean_log_entropy": 0.5466968626687021, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.252681991429005, "train/action_min": 0.0, "train/action_std": 3.054862118461757, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04231140592578545, "train/actor_opt_grad_steps": 33795.0, "train/actor_opt_loss": 2.607141228410804, "train/adv_mag": 0.5956779243876633, "train/adv_max": 0.5757002797230933, "train/adv_mean": 0.005138255899474794, "train/adv_min": -0.4217583985583296, "train/adv_std": 0.06565976640191472, "train/cont_avg": 0.9949844508495146, "train/cont_loss_mean": 0.00018046273814737915, "train/cont_loss_std": 0.005433647285238435, "train/cont_neg_acc": 0.9929496081708704, "train/cont_neg_loss": 0.014929198188032459, "train/cont_pos_acc": 0.9999570907319634, "train/cont_pos_loss": 0.00010497340225555746, "train/cont_pred": 0.9949736259516003, "train/cont_rate": 0.9949844508495146, "train/dyn_loss_mean": 13.721985303082512, "train/dyn_loss_std": 9.218035022031914, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8895554180862835, "train/extr_critic_critic_opt_grad_steps": 33795.0, "train/extr_critic_critic_opt_loss": 16321.255603382888, "train/extr_critic_mag": 5.658850649028149, "train/extr_critic_max": 5.658850649028149, "train/extr_critic_mean": 1.2418187865354482, "train/extr_critic_min": -0.31799998619024034, "train/extr_critic_std": 1.304704554740665, "train/extr_return_normed_mag": 1.7141899206105946, "train/extr_return_normed_max": 1.7141899206105946, "train/extr_return_normed_mean": 0.32996866222724175, "train/extr_return_normed_min": -0.1272925784974133, "train/extr_return_normed_std": 0.3261470582734034, "train/extr_return_rate": 0.6022277941692222, "train/extr_return_raw_mag": 6.948865351167697, "train/extr_return_raw_max": 6.948865351167697, "train/extr_return_raw_mean": 1.2628537561129598, "train/extr_return_raw_min": -0.6182738214152531, "train/extr_return_raw_std": 1.3414921887869973, "train/extr_reward_mag": 1.0140553516091653, "train/extr_reward_max": 1.0140553516091653, "train/extr_reward_mean": 0.029344960303470783, "train/extr_reward_min": -0.3519808331739555, "train/extr_reward_std": 0.16013505736601005, "train/image_loss_mean": 7.214307192459847, "train/image_loss_std": 11.704058103191043, "train/model_loss_mean": 15.50009278417791, "train/model_loss_std": 15.552128537187299, "train/model_opt_grad_norm": 59.62765193453022, "train/model_opt_grad_steps": 33764.203883495145, "train/model_opt_loss": 19657.966180597694, "train/model_opt_model_opt_grad_overflow": 0.009708737864077669, "train/model_opt_model_opt_grad_scale": 1256.0679611650485, "train/policy_entropy_mag": 2.53428426992546, "train/policy_entropy_max": 2.53428426992546, "train/policy_entropy_mean": 0.5859138748599487, "train/policy_entropy_min": 0.07937505779769814, "train/policy_entropy_std": 0.6329539471748963, "train/policy_logprob_mag": 7.43838353295928, "train/policy_logprob_max": -0.009455663305752485, "train/policy_logprob_mean": -0.5852974968627819, "train/policy_logprob_min": -7.43838353295928, "train/policy_logprob_std": 1.1225620291186769, "train/policy_randomness_mag": 0.8944911340486656, "train/policy_randomness_max": 0.8944911340486656, "train/policy_randomness_mean": 0.2068018866250816, "train/policy_randomness_min": 0.028015912139734016, "train/policy_randomness_std": 0.2234049678861516, "train/post_ent_mag": 58.82087664928251, "train/post_ent_max": 58.82087664928251, "train/post_ent_mean": 41.67933525159521, "train/post_ent_min": 20.90961845175734, "train/post_ent_std": 7.3142424277888916, "train/prior_ent_mag": 68.0663685104222, "train/prior_ent_max": 68.0663685104222, "train/prior_ent_mean": 55.4524509652147, "train/prior_ent_min": 41.55058283018835, "train/prior_ent_std": 4.57718760295979, "train/rep_loss_mean": 13.721985303082512, "train/rep_loss_std": 9.218035022031914, "train/reward_avg": 0.02439604800429593, "train/reward_loss_mean": 0.052413973830712654, "train/reward_loss_std": 0.24707969849549452, "train/reward_max_data": 1.0097087401788212, "train/reward_max_pred": 1.0071141551999212, "train/reward_neg_acc": 0.9933168720273138, "train/reward_neg_loss": 0.027980858356086085, "train/reward_pos_acc": 0.9641718508549106, "train/reward_pos_loss": 0.8683639168739319, "train/reward_pred": 0.02359002244486971, "train/reward_rate": 0.029059845266990292, "eval_stats/sum_log_reward": 7.1416666607062025, "eval_stats/max_log_achievement_collect_coal": 0.4166666666666667, "eval_stats/max_log_achievement_collect_drink": 4.125, "eval_stats/max_log_achievement_collect_sapling": 1.4166666666666667, "eval_stats/max_log_achievement_collect_stone": 4.791666666666667, "eval_stats/max_log_achievement_collect_wood": 11.375, "eval_stats/max_log_achievement_defeat_skeleton": 0.041666666666666664, "eval_stats/max_log_achievement_defeat_zombie": 0.3333333333333333, "eval_stats/max_log_achievement_eat_cow": 0.041666666666666664, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 3.0833333333333335, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.041666666666666664, "eval_stats/max_log_achievement_place_plant": 1.3333333333333333, "eval_stats/max_log_achievement_place_stone": 1.8333333333333333, "eval_stats/max_log_achievement_place_table": 3.5416666666666665, "eval_stats/max_log_achievement_wake_up": 1.0416666666666667, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.990234375, "report/cont_loss_mean": 7.328171250264859e-06, "report/cont_loss_std": 0.00016675259394105524, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0005617457791231573, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.860541601672594e-06, "report/cont_pred": 0.9902380704879761, "report/cont_rate": 0.990234375, "report/dyn_loss_mean": 13.486845016479492, "report/dyn_loss_std": 9.35740852355957, "report/image_loss_mean": 7.059691429138184, "report/image_loss_std": 9.925764083862305, "report/model_loss_mean": 15.230536460876465, "report/model_loss_std": 13.99876594543457, "report/post_ent_mag": 61.824405670166016, "report/post_ent_max": 61.824405670166016, "report/post_ent_mean": 43.44816589355469, "report/post_ent_min": 20.11528778076172, "report/post_ent_std": 7.865710735321045, "report/prior_ent_mag": 67.96651458740234, "report/prior_ent_max": 67.96651458740234, "report/prior_ent_mean": 56.75328063964844, "report/prior_ent_min": 41.20246887207031, "report/prior_ent_std": 4.802240371704102, "report/rep_loss_mean": 13.486845016479492, "report/rep_loss_std": 9.35740852355957, "report/reward_avg": 0.03769531100988388, "report/reward_loss_mean": 0.07873024046421051, "report/reward_loss_std": 0.29823797941207886, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0035400390625, "report/reward_neg_acc": 0.9908069968223572, "report/reward_neg_loss": 0.04109976068139076, "report/reward_pos_acc": 0.9555555582046509, "report/reward_pos_loss": 0.8974024653434753, "report/reward_pred": 0.03828292340040207, "report/reward_rate": 0.0439453125, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 9.310568202636205e-06, "eval/cont_loss_std": 0.00028969792765565217, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 6.671069968433585e-06, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 9.318323463958222e-06, "eval/cont_pred": 0.9970611333847046, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 17.172210693359375, "eval/dyn_loss_std": 10.734932899475098, "eval/image_loss_mean": 13.186201095581055, "eval/image_loss_std": 17.949798583984375, "eval/model_loss_mean": 23.57189178466797, "eval/model_loss_std": 22.046279907226562, "eval/post_ent_mag": 58.765228271484375, "eval/post_ent_max": 58.765228271484375, "eval/post_ent_mean": 41.32984924316406, "eval/post_ent_min": 21.51160430908203, "eval/post_ent_std": 7.200926303863525, "eval/prior_ent_mag": 67.96651458740234, "eval/prior_ent_max": 67.96651458740234, "eval/prior_ent_mean": 55.659912109375, "eval/prior_ent_min": 43.17955017089844, "eval/prior_ent_std": 3.8429441452026367, "eval/rep_loss_mean": 17.172210693359375, "eval/rep_loss_std": 10.734932899475098, "eval/reward_avg": 0.0244140625, "eval/reward_loss_mean": 0.08235415816307068, "eval/reward_loss_std": 0.5463276505470276, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0020427703857422, "eval/reward_neg_acc": 0.9839518666267395, "eval/reward_neg_loss": 0.029655519872903824, "eval/reward_pos_acc": 0.7407407760620117, "eval/reward_pos_loss": 2.0283000469207764, "eval/reward_pred": 0.02040328085422516, "eval/reward_rate": 0.0263671875, "replay/size": 558273.0, "replay/inserts": 32976.0, "replay/samples": 32976.0, "replay/insert_wait_avg": 1.2131902212543664e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 5.813838786606878e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 6856.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2083329008229277e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.748603820800781e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1481647491455, "timer/env.step_count": 4122.0, "timer/env.step_total": 148.67100143432617, "timer/env.step_frac": 0.14864897689595363, "timer/env.step_avg": 0.03606768593748815, "timer/env.step_min": 0.002254486083984375, "timer/env.step_max": 0.9331152439117432, "timer/replay._sample_count": 32976.0, "timer/replay._sample_total": 2923.9488310813904, "timer/replay._sample_frac": 2.9235156691156527, "timer/replay._sample_avg": 0.08866899657573357, "timer/replay._sample_min": 0.0005178451538085938, "timer/replay._sample_max": 0.1282649040222168, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4979.0, "timer/agent.policy_total": 51.16790199279785, "timer/agent.policy_frac": 0.051160321836546736, "timer/agent.policy_avg": 0.010276742717975065, "timer/agent.policy_min": 0.0075533390045166016, "timer/agent.policy_max": 0.05065417289733887, "timer/dataset_train_count": 2061.0, "timer/dataset_train_total": 0.1676182746887207, "timer/dataset_train_frac": 0.0001675934432482434, "timer/dataset_train_avg": 8.132861459908817e-05, "timer/dataset_train_min": 6.29425048828125e-05, "timer/dataset_train_max": 0.00024318695068359375, "timer/agent.train_count": 2061.0, "timer/agent.train_total": 765.3899571895599, "timer/agent.train_frac": 0.7652765701785125, "timer/agent.train_avg": 0.37136824705946625, "timer/agent.train_min": 0.3533823490142822, "timer/agent.train_max": 0.6495134830474854, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4177396297454834, "timer/agent.report_frac": 0.00041767774462722704, "timer/agent.report_avg": 0.2088698148727417, "timer/agent.report_min": 0.20761513710021973, "timer/agent.report_max": 0.21012449264526367, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.5762786865234375e-05, "timer/dataset_eval_frac": 3.575748886586649e-08, "timer/dataset_eval_avg": 3.5762786865234375e-05, "timer/dataset_eval_min": 3.5762786865234375e-05, "timer/dataset_eval_max": 3.5762786865234375e-05, "fps": 32.97066747146814}
{"step": 559056, "time": 17153.468193769455, "episode/length": 195.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 559504, "time": 17165.28075361252, "episode/length": 236.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 559552, "time": 17167.306170225143, "episode/length": 217.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.981651376146789, "episode/intrinsic_return": 0.0}
{"step": 559832, "time": 17174.953666210175, "episode/length": 236.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 560040, "time": 17183.5889210701, "eval_episode/length": 106.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9906542056074766}
{"step": 560040, "time": 17185.205302238464, "eval_episode/length": 148.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9664429530201343}
{"step": 560040, "time": 17186.11673927307, "eval_episode/length": 154.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.967741935483871}
{"step": 560040, "time": 17187.02997303009, "eval_episode/length": 156.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9936305732484076}
{"step": 560040, "time": 17188.29549598694, "eval_episode/length": 179.0, "eval_episode/score": 7.100000016391277, "eval_episode/reward_rate": 0.9833333333333333}
{"step": 560040, "time": 17190.438918828964, "eval_episode/length": 248.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9839357429718876}
{"step": 560040, "time": 17192.40281867981, "eval_episode/length": 125.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9603174603174603}
{"step": 560040, "time": 17193.31049323082, "eval_episode/length": 153.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.961038961038961}
{"step": 560120, "time": 17196.780943632126, "episode/length": 199.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.97, "episode/intrinsic_return": 0.0}
{"step": 560200, "time": 17199.754930496216, "episode/length": 80.0, "episode/score": 6.1000000461936, "episode/reward_rate": 0.9876543209876543, "episode/intrinsic_return": 0.0}
{"step": 560400, "time": 17205.738981485367, "episode/length": 206.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 560592, "time": 17211.345462083817, "episode/length": 191.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 560808, "time": 17217.375201940536, "episode/length": 409.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9926829268292683, "episode/intrinsic_return": 0.0}
{"step": 560832, "time": 17218.969148874283, "episode/length": 165.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 560904, "time": 17221.371341228485, "episode/length": 305.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9967320261437909, "episode/intrinsic_return": 0.0}
{"step": 561328, "time": 17232.928879261017, "episode/length": 150.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 561656, "time": 17241.722573280334, "episode/length": 227.0, "episode/score": 6.10000005364418, "episode/reward_rate": 0.9912280701754386, "episode/intrinsic_return": 0.0}
{"step": 561888, "time": 17248.527314186096, "episode/length": 210.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 562112, "time": 17254.933106184006, "episode/length": 213.0, "episode/score": 8.099999964237213, "episode/reward_rate": 0.9813084112149533, "episode/intrinsic_return": 0.0}
{"step": 562272, "time": 17259.719976902008, "episode/length": 209.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 562416, "time": 17264.162256240845, "episode/length": 200.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 562920, "time": 17277.557326078415, "episode/length": 260.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9961685823754789, "episode/intrinsic_return": 0.0}
{"step": 563304, "time": 17287.91772055626, "episode/length": 205.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 563512, "time": 17294.0735976696, "episode/length": 136.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9927007299270073, "episode/intrinsic_return": 0.0}
{"step": 563584, "time": 17296.983505010605, "episode/length": 281.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.0}
{"step": 563672, "time": 17299.920246839523, "episode/length": 194.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9692307692307692, "episode/intrinsic_return": 0.0}
{"step": 563680, "time": 17301.169845581055, "episode/length": 175.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 564096, "time": 17312.540261030197, "episode/length": 398.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9974937343358395, "episode/intrinsic_return": 0.0}
{"step": 564168, "time": 17315.000558137894, "episode/length": 155.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 564872, "time": 17333.30291724205, "episode/length": 160.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 565368, "time": 17346.59863972664, "episode/length": 434.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9793103448275862, "episode/intrinsic_return": 0.0}
{"step": 565432, "time": 17349.06742811203, "episode/length": 219.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9681818181818181, "episode/intrinsic_return": 0.0}
{"step": 565632, "time": 17355.09440588951, "episode/length": 290.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9862542955326461, "episode/intrinsic_return": 0.0}
{"step": 565808, "time": 17360.31994009018, "episode/length": 204.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9804878048780488, "episode/intrinsic_return": 0.0}
{"step": 566088, "time": 17367.962361335754, "episode/length": 300.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9800664451827242, "episode/intrinsic_return": 0.0}
{"step": 566752, "time": 17385.40930199623, "episode/length": 331.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9849397590361446, "episode/intrinsic_return": 0.0}
{"step": 566768, "time": 17386.69273018837, "episode/length": 236.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 567048, "time": 17394.416887044907, "episode/length": 441.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9932126696832579, "episode/intrinsic_return": 0.0}
{"step": 567080, "time": 17396.066712141037, "episode/length": 205.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 567232, "time": 17400.890594005585, "episode/length": 232.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9742489270386266, "episode/intrinsic_return": 0.0}
{"step": 567648, "time": 17412.197767972946, "episode/length": 51.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 567664, "time": 17413.479159832, "episode/length": 231.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 567944, "time": 17421.16258907318, "episode/length": 148.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 568008, "time": 17423.579934597015, "episode/length": 239.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 568080, "time": 17426.320096731186, "episode/length": 53.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9074074074074074, "episode/intrinsic_return": 0.0}
{"step": 568704, "time": 17442.79022169113, "episode/length": 206.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9710144927536232, "episode/intrinsic_return": 0.0}
{"step": 569072, "time": 17452.905440807343, "episode/length": 429.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 569384, "time": 17461.343060731888, "episode/length": 214.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 569496, "time": 17464.986667871475, "episode/length": 176.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 569592, "time": 17468.220091104507, "episode/length": 205.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9805825242718447, "episode/intrinsic_return": 0.0}
{"step": 569904, "time": 17476.932908535004, "episode/length": 391.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9974489795918368, "episode/intrinsic_return": 0.0}
{"step": 569936, "time": 17478.62345957756, "episode/length": 68.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9855072463768116, "episode/intrinsic_return": 0.0}
{"step": 570024, "time": 17484.798974514008, "eval_episode/length": 157.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9746835443037974}
{"step": 570024, "time": 17486.133410930634, "eval_episode/length": 185.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.967741935483871}
{"step": 570024, "time": 17487.016357898712, "eval_episode/length": 187.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9574468085106383}
{"step": 570024, "time": 17488.247000694275, "eval_episode/length": 210.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.976303317535545}
{"step": 570024, "time": 17489.164263010025, "eval_episode/length": 213.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9626168224299065}
{"step": 570024, "time": 17490.2787835598, "eval_episode/length": 227.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9956140350877193}
{"step": 570024, "time": 17491.3177819252, "eval_episode/length": 237.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9957983193277311}
{"step": 570024, "time": 17492.62110519409, "eval_episode/length": 102.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9902912621359223}
{"step": 570200, "time": 17497.264660835266, "episode/length": 273.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9781021897810219, "episode/intrinsic_return": 0.0}
{"step": 570400, "time": 17503.36101293564, "episode/length": 165.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 570656, "time": 17510.681218147278, "episode/length": 446.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9977628635346756, "episode/intrinsic_return": 0.0}
{"step": 571192, "time": 17524.845106601715, "episode/length": 211.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 571208, "time": 17526.029742717743, "episode/length": 158.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 571272, "time": 17528.44395494461, "episode/length": 209.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9809523809523809, "episode/intrinsic_return": 0.0}
{"step": 571320, "time": 17530.537263393402, "episode/length": 176.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 571584, "time": 17538.04470872879, "episode/length": 115.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9913793103448276, "episode/intrinsic_return": 0.0}
{"step": 571872, "time": 17546.15513563156, "episode/length": 208.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 572400, "time": 17560.46148777008, "episode/length": 461.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9978354978354979, "episode/intrinsic_return": 0.0}
{"step": 572472, "time": 17562.88792538643, "episode/length": 157.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 572488, "time": 17564.08095908165, "episode/length": 161.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 572560, "time": 17566.87146782875, "episode/length": 160.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 572952, "time": 17577.298468351364, "episode/length": 318.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9843260188087775, "episode/intrinsic_return": 0.0}
{"step": 573568, "time": 17593.91226029396, "episode/length": 125.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9920634920634921, "episode/intrinsic_return": 0.0}
{"step": 573704, "time": 17598.055676221848, "episode/length": 228.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9781659388646288, "episode/intrinsic_return": 0.0}
{"step": 573848, "time": 17602.466937065125, "episode/length": 180.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 574160, "time": 17611.30303478241, "episode/length": 150.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9602649006622517, "episode/intrinsic_return": 0.0}
{"step": 574456, "time": 17619.570304870605, "episode/length": 247.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9717741935483871, "episode/intrinsic_return": 0.0}
{"step": 574584, "time": 17623.684607744217, "episode/length": 374.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9973333333333333, "episode/intrinsic_return": 0.0}
{"step": 574712, "time": 17627.793037176132, "episode/length": 423.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9787735849056604, "episode/intrinsic_return": 0.0}
{"step": 574896, "time": 17633.51502108574, "episode/length": 300.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9900332225913622, "episode/intrinsic_return": 0.0}
{"step": 575208, "time": 17641.81910610199, "episode/length": 204.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 575992, "time": 17662.051721572876, "episode/length": 159.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 576088, "time": 17665.207089424133, "episode/length": 187.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 576240, "time": 17669.99582886696, "episode/length": 259.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9961538461538462, "episode/intrinsic_return": 0.0}
{"step": 576272, "time": 17671.655757427216, "episode/length": 302.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9966996699669967, "episode/intrinsic_return": 0.0}
{"step": 576856, "time": 17686.900911569595, "episode/length": 393.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9771573604060914, "episode/intrinsic_return": 0.0}
{"step": 577576, "time": 17705.632249593735, "episode/length": 185.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 577656, "time": 17708.534212350845, "episode/length": 176.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9661016949152542, "episode/intrinsic_return": 0.0}
{"step": 577784, "time": 17712.615535736084, "episode/length": 415.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9783653846153846, "episode/intrinsic_return": 0.0}
{"step": 577824, "time": 17714.647002458572, "episode/length": 228.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 578240, "time": 17725.918725967407, "episode/length": 378.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9894459102902374, "episode/intrinsic_return": 0.0}
{"step": 578288, "time": 17727.949405670166, "episode/length": 423.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9787735849056604, "episode/intrinsic_return": 0.0}
{"step": 578768, "time": 17740.68111014366, "episode/length": 148.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.959731543624161, "episode/intrinsic_return": 0.0}
{"step": 578776, "time": 17741.528389930725, "episode/length": 312.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.987220447284345, "episode/intrinsic_return": 0.0}
{"step": 579016, "time": 17748.27610063553, "episode/length": 169.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 579080, "time": 17750.72257089615, "episode/length": 277.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9892086330935251, "episode/intrinsic_return": 0.0}
{"step": 579240, "time": 17755.510096549988, "episode/length": 181.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 580008, "time": 17778.92356777191, "eval_episode/length": 165.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9698795180722891}
{"step": 580008, "time": 17779.857863664627, "eval_episode/length": 170.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9649122807017544}
{"step": 580008, "time": 17781.064905166626, "eval_episode/length": 190.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9738219895287958}
{"step": 580008, "time": 17782.140394210815, "eval_episode/length": 204.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.975609756097561}
{"step": 580008, "time": 17783.06709432602, "eval_episode/length": 206.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.961352657004831}
{"step": 580008, "time": 17784.495475053787, "eval_episode/length": 234.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9957446808510638}
{"step": 580008, "time": 17787.02660727501, "eval_episode/length": 320.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9813084112149533}
{"step": 580008, "time": 17789.15569138527, "eval_episode/length": 183.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.9782608695652174}
{"step": 580032, "time": 17790.153621673584, "episode/length": 156.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9617834394904459, "episode/intrinsic_return": 0.0}
{"step": 580088, "time": 17792.31828904152, "episode/length": 230.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 580136, "time": 17794.347135543823, "episode/length": 230.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9783549783549783, "episode/intrinsic_return": 0.0}
{"step": 580200, "time": 17796.855871915817, "episode/length": 178.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 580392, "time": 17802.656217336655, "episode/length": 320.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9906542056074766, "episode/intrinsic_return": 0.0}
{"step": 580408, "time": 17803.904853343964, "episode/length": 165.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 580800, "time": 17814.6370947361, "episode/length": 194.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9897435897435898, "episode/intrinsic_return": 0.0}
{"step": 581096, "time": 17822.73801589012, "episode/length": 259.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9961538461538462, "episode/intrinsic_return": 0.0}
{"step": 581504, "time": 17834.085297107697, "episode/length": 183.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 581832, "time": 17842.87870168686, "episode/length": 177.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 581848, "time": 17844.126247882843, "episode/length": 219.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 581864, "time": 17845.408719301224, "episode/length": 207.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 582160, "time": 17853.799053668976, "episode/length": 220.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 582352, "time": 17859.336630821228, "episode/length": 193.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 582408, "time": 17861.37064409256, "episode/length": 163.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 582912, "time": 17874.74494791031, "episode/length": 346.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9798270893371758, "episode/intrinsic_return": 0.0}
{"step": 583024, "time": 17878.358406305313, "episode/length": 189.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 583664, "time": 17895.119522571564, "episode/length": 187.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9680851063829787, "episode/intrinsic_return": 0.0}
{"step": 584104, "time": 17906.942038297653, "episode/length": 281.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9858156028368794, "episode/intrinsic_return": 0.0}
{"step": 584216, "time": 17910.4935901165, "episode/length": 225.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 584624, "time": 17921.767842531204, "episode/length": 213.0, "episode/score": 6.1000000312924385, "episode/reward_rate": 0.9906542056074766, "episode/intrinsic_return": 0.0}
{"step": 584728, "time": 17925.041001081467, "episode/length": 296.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.98989898989899, "episode/intrinsic_return": 0.0}
{"step": 585040, "time": 17933.86124753952, "episode/length": 400.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9950124688279302, "episode/intrinsic_return": 0.0}
{"step": 585088, "time": 17935.98151421547, "episode/length": 44.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 585200, "time": 17939.75168323517, "episode/length": 191.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 585208, "time": 17940.57738685608, "episode/length": 417.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9904306220095693, "episode/intrinsic_return": 0.0}
{"step": 585512, "time": 17948.878637075424, "episode/length": 175.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9659090909090909, "episode/intrinsic_return": 0.0}
{"step": 585784, "time": 17956.549714803696, "episode/length": 344.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9855072463768116, "episode/intrinsic_return": 0.0}
{"step": 585896, "time": 17960.134970903397, "episode/length": 158.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 586152, "time": 17967.397471427917, "episode/length": 241.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9958677685950413, "episode/intrinsic_return": 0.0}
{"step": 586472, "time": 17976.381242990494, "episode/length": 172.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 587240, "time": 17996.403473615646, "episode/length": 181.0, "episode/score": 9.099999964237213, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 587280, "time": 17998.41943717003, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 587496, "time": 18004.482679843903, "episode/length": 285.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.986013986013986, "episode/intrinsic_return": 0.0}
{"step": 587512, "time": 18005.772459745407, "episode/length": 249.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.976, "episode/intrinsic_return": 0.0}
{"step": 587680, "time": 18010.982354402542, "episode/length": 309.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.0}
{"step": 588240, "time": 18025.82591867447, "episode/length": 220.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 588312, "time": 18028.25488448143, "episode/length": 269.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9851851851851852, "episode/intrinsic_return": 0.0}
{"step": 588320, "time": 18029.525906324387, "episode/length": 409.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9780487804878049, "episode/intrinsic_return": 0.0}
{"step": 589000, "time": 18047.243675231934, "episode/length": 164.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 589088, "time": 18050.468750715256, "episode/length": 198.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 589312, "time": 18057.10970067978, "episode/length": 258.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9961389961389961, "episode/intrinsic_return": 0.0}
{"step": 589320, "time": 18057.933296203613, "episode/length": 254.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.996078431372549, "episode/intrinsic_return": 0.0}
{"step": 589336, "time": 18059.1546728611, "episode/length": 227.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 589480, "time": 18063.59011054039, "episode/length": 154.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9612903225806452, "episode/intrinsic_return": 0.0}
{"step": 589760, "time": 18071.616602897644, "episode/length": 52.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9245283018867925, "episode/intrinsic_return": 0.0}
{"step": 589880, "time": 18075.231849193573, "episode/length": 194.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9641025641025641, "episode/intrinsic_return": 0.0}
{"step": 590032, "time": 18080.010887384415, "episode/length": 214.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9813953488372092, "episode/intrinsic_return": 0.0}
{"step": 590096, "time": 18083.98573589325, "eval_episode/length": 39.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.975}
{"step": 590096, "time": 18086.919181585312, "eval_episode/length": 162.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9693251533742331}
{"step": 590096, "time": 18088.414028406143, "eval_episode/length": 197.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9646464646464646}
{"step": 590096, "time": 18089.70067548752, "eval_episode/length": 218.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9954337899543378}
{"step": 590096, "time": 18090.579847812653, "eval_episode/length": 220.0, "eval_episode/score": 8.099999971687794, "eval_episode/reward_rate": 0.995475113122172}
{"step": 590096, "time": 18091.63860964775, "eval_episode/length": 229.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9956521739130435}
{"step": 590096, "time": 18093.234268903732, "eval_episode/length": 226.0, "eval_episode/score": 9.100000016391277, "eval_episode/reward_rate": 0.986784140969163}
{"step": 590096, "time": 18094.08138036728, "eval_episode/length": 46.0, "eval_episode/score": 3.0999999940395355, "eval_episode/reward_rate": 0.9787234042553191}
{"step": 590360, "time": 18100.933403730392, "episode/length": 158.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9622641509433962, "episode/intrinsic_return": 0.0}
{"step": 590432, "time": 18103.70003437996, "episode/length": 178.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 590640, "time": 18109.58590579033, "episode/length": 164.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 590960, "time": 18118.673666477203, "episode/length": 74.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.92, "episode/intrinsic_return": 0.0}
{"step": 591072, "time": 18122.379882097244, "episode/length": 198.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 591240, "time": 18127.24124932289, "episode/length": 240.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.995850622406639, "episode/intrinsic_return": 0.0}
{"step": 591416, "time": 18132.7068502903, "episode/length": 172.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 591432, "time": 18133.96043586731, "episode/length": 208.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 591768, "time": 18143.36408162117, "episode/length": 166.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 591833, "time": 18146.69847869873, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.116577443293327, "train/action_min": 0.0, "train/action_std": 2.884803389581505, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03945634674262885, "train/actor_opt_grad_steps": 35860.0, "train/actor_opt_loss": 1.6107348768571437, "train/adv_mag": 0.5378042769028945, "train/adv_max": 0.5096398008906323, "train/adv_mean": 0.004780188080660548, "train/adv_min": -0.4036996943363245, "train/adv_std": 0.06074614443136874, "train/cont_avg": 0.9947586428140096, "train/cont_loss_mean": 0.00016841638443649927, "train/cont_loss_std": 0.00509134206741477, "train/cont_neg_acc": 0.9928687020991612, "train/cont_neg_loss": 0.021418554397274702, "train/cont_pos_acc": 0.9999857403805866, "train/cont_pos_loss": 5.922874884515846e-05, "train/cont_pred": 0.9947754418216466, "train/cont_rate": 0.9947586428140096, "train/dyn_loss_mean": 13.654562802706364, "train/dyn_loss_std": 9.222417946598956, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9079466859499613, "train/extr_critic_critic_opt_grad_steps": 35860.0, "train/extr_critic_critic_opt_loss": 16319.94958201238, "train/extr_critic_mag": 6.244549461033033, "train/extr_critic_max": 6.244549461033033, "train/extr_critic_mean": 1.530373460140781, "train/extr_critic_min": -0.30607079998882497, "train/extr_critic_std": 1.4590076850232294, "train/extr_return_normed_mag": 1.6374111503794573, "train/extr_return_normed_max": 1.6374111503794573, "train/extr_return_normed_mean": 0.3473561620654691, "train/extr_return_normed_min": -0.12113923851202651, "train/extr_return_normed_std": 0.32392269049001776, "train/extr_return_rate": 0.6764225772613488, "train/extr_return_raw_mag": 7.497106600498808, "train/extr_return_raw_max": 7.497106600498808, "train/extr_return_raw_mean": 1.5524619472199592, "train/extr_return_raw_min": -0.6102527544118356, "train/extr_return_raw_std": 1.4938743989824672, "train/extr_reward_mag": 1.0184615844689706, "train/extr_reward_max": 1.0184615844689706, "train/extr_reward_mean": 0.03059567829621011, "train/extr_reward_min": -0.389451147277574, "train/extr_reward_std": 0.16359152241749464, "train/image_loss_mean": 7.191286994639226, "train/image_loss_std": 11.793225445033272, "train/model_loss_mean": 15.437397500743037, "train/model_loss_std": 15.59812919874698, "train/model_opt_grad_norm": 59.27740748492992, "train/model_opt_grad_steps": 35827.17391304348, "train/model_opt_loss": 19462.06475977506, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1262.0772946859904, "train/policy_entropy_mag": 2.5030529902177157, "train/policy_entropy_max": 2.5030529902177157, "train/policy_entropy_mean": 0.5480625874178421, "train/policy_entropy_min": 0.07937503861632324, "train/policy_entropy_std": 0.6123597151127415, "train/policy_logprob_mag": 7.438383597682639, "train/policy_logprob_max": -0.009455660421059327, "train/policy_logprob_mean": -0.5487157336755651, "train/policy_logprob_min": -7.438383597682639, "train/policy_logprob_std": 1.0993674337000088, "train/policy_randomness_mag": 0.88346786228355, "train/policy_randomness_max": 0.88346786228355, "train/policy_randomness_mean": 0.1934420413873046, "train/policy_randomness_min": 0.028015905253337203, "train/policy_randomness_std": 0.2161361071222646, "train/post_ent_mag": 59.06278180845694, "train/post_ent_max": 59.06278180845694, "train/post_ent_mean": 41.84131944813014, "train/post_ent_min": 20.79639734277403, "train/post_ent_std": 7.366943919140359, "train/prior_ent_mag": 68.23260509103969, "train/prior_ent_max": 68.23260509103969, "train/prior_ent_mean": 55.55795588470311, "train/prior_ent_min": 41.865554698999375, "train/prior_ent_std": 4.4874741985026185, "train/rep_loss_mean": 13.654562802706364, "train/rep_loss_std": 9.222417946598956, "train/reward_avg": 0.025003773907136515, "train/reward_loss_mean": 0.053204532550728836, "train/reward_loss_std": 0.24433557581210483, "train/reward_max_data": 1.0125603894680595, "train/reward_max_pred": 1.0094520561936973, "train/reward_neg_acc": 0.9935730854094317, "train/reward_neg_loss": 0.029005331495677793, "train/reward_pos_acc": 0.9680662607225243, "train/reward_pos_loss": 0.8488992803914536, "train/reward_pred": 0.024478528416909024, "train/reward_rate": 0.029702596618357488, "train_stats/sum_log_reward": 7.586111260784997, "train_stats/max_log_achievement_collect_coal": 0.3958333333333333, "train_stats/max_log_achievement_collect_drink": 4.979166666666667, "train_stats/max_log_achievement_collect_sapling": 1.4583333333333333, "train_stats/max_log_achievement_collect_stone": 8.125, "train_stats/max_log_achievement_collect_wood": 11.166666666666666, "train_stats/max_log_achievement_defeat_skeleton": 0.020833333333333332, "train_stats/max_log_achievement_defeat_zombie": 0.2569444444444444, "train_stats/max_log_achievement_eat_cow": 0.04861111111111111, "train_stats/max_log_achievement_make_stone_pickaxe": 0.034722222222222224, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 3.0833333333333335, "train_stats/max_log_achievement_make_wood_sword": 0.020833333333333332, "train_stats/max_log_achievement_place_furnace": 0.020833333333333332, "train_stats/max_log_achievement_place_plant": 1.4305555555555556, "train_stats/max_log_achievement_place_stone": 6.041666666666667, "train_stats/max_log_achievement_place_table": 3.375, "train_stats/max_log_achievement_wake_up": 1.2847222222222223, "train_stats/mean_log_entropy": 0.5861424612295296, "eval_stats/sum_log_reward": 7.193750128149986, "eval_stats/max_log_achievement_collect_coal": 0.28125, "eval_stats/max_log_achievement_collect_drink": 4.09375, "eval_stats/max_log_achievement_collect_sapling": 1.21875, "eval_stats/max_log_achievement_collect_stone": 6.625, "eval_stats/max_log_achievement_collect_wood": 11.5625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.25, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 3.25, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.03125, "eval_stats/max_log_achievement_place_plant": 1.1875, "eval_stats/max_log_achievement_place_stone": 4.21875, "eval_stats/max_log_achievement_place_table": 3.0625, "eval_stats/max_log_achievement_wake_up": 1.03125, "eval_stats/mean_log_entropy": 0.0, "train_stats/max_log_achievement_eat_plant": 0.009009009009009009, "eval_stats/max_log_achievement_eat_plant": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 2.7829641112475656e-05, "report/cont_loss_std": 0.0006197206093929708, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00015051942318677902, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 2.6985166186932474e-05, "report/cont_pred": 0.9931385517120361, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 12.603607177734375, "report/dyn_loss_std": 9.959847450256348, "report/image_loss_mean": 8.713748931884766, "report/image_loss_std": 15.260873794555664, "report/model_loss_mean": 16.336816787719727, "report/model_loss_std": 19.35905647277832, "report/post_ent_mag": 62.322837829589844, "report/post_ent_max": 62.322837829589844, "report/post_ent_mean": 44.14907455444336, "report/post_ent_min": 20.003433227539062, "report/post_ent_std": 8.614474296569824, "report/prior_ent_mag": 68.01094055175781, "report/prior_ent_max": 68.01094055175781, "report/prior_ent_mean": 56.680580139160156, "report/prior_ent_min": 43.06587219238281, "report/prior_ent_std": 4.735565662384033, "report/rep_loss_mean": 12.603607177734375, "report/rep_loss_std": 9.959847450256348, "report/reward_avg": 0.02548828162252903, "report/reward_loss_mean": 0.060876160860061646, "report/reward_loss_std": 0.2544577419757843, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0047755241394043, "report/reward_neg_acc": 0.9889112710952759, "report/reward_neg_loss": 0.03083851933479309, "report/reward_pos_acc": 0.9375, "report/reward_pos_loss": 0.992043137550354, "report/reward_pred": 0.021213587373495102, "report/reward_rate": 0.03125, "eval/cont_avg": 0.9921875, "eval/cont_loss_mean": 4.142440593568608e-05, "eval/cont_loss_std": 0.0010936874896287918, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0006972276605665684, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 3.626060060923919e-05, "eval/cont_pred": 0.9921575784683228, "eval/cont_rate": 0.9921875, "eval/dyn_loss_mean": 15.688214302062988, "eval/dyn_loss_std": 10.7841796875, "eval/image_loss_mean": 9.941146850585938, "eval/image_loss_std": 14.550688743591309, "eval/model_loss_mean": 19.45258140563965, "eval/model_loss_std": 19.089393615722656, "eval/post_ent_mag": 60.32269287109375, "eval/post_ent_max": 60.32269287109375, "eval/post_ent_mean": 41.10382843017578, "eval/post_ent_min": 21.009904861450195, "eval/post_ent_std": 7.1952409744262695, "eval/prior_ent_mag": 68.01094055175781, "eval/prior_ent_max": 68.01094055175781, "eval/prior_ent_mean": 54.91750717163086, "eval/prior_ent_min": 43.575286865234375, "eval/prior_ent_std": 4.313068866729736, "eval/rep_loss_mean": 15.688214302062988, "eval/rep_loss_std": 10.7841796875, "eval/reward_avg": 0.025390625, "eval/reward_loss_mean": 0.09846517443656921, "eval/reward_loss_std": 0.6095272898674011, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0041594505310059, "eval/reward_neg_acc": 0.9909273982048035, "eval/reward_neg_loss": 0.03872169554233551, "eval/reward_pos_acc": 0.84375, "eval/reward_pos_loss": 1.9505131244659424, "eval/reward_pred": 0.022563617676496506, "eval/reward_rate": 0.03125, "replay/size": 591329.0, "replay/inserts": 33056.0, "replay/samples": 33056.0, "replay/insert_wait_avg": 1.2242537269518428e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 5.745457887418734e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 9832.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.230503699952165e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.748603820800781e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1839020252228, "timer/env.step_count": 4132.0, "timer/env.step_total": 133.26038813591003, "timer/env.step_frac": 0.13323588578668152, "timer/env.step_avg": 0.03225081997480882, "timer/env.step_min": 0.0023775100708007812, "timer/env.step_max": 0.9094417095184326, "timer/replay._sample_count": 33056.0, "timer/replay._sample_total": 2921.151424407959, "timer/replay._sample_frac": 2.9206143175200725, "timer/replay._sample_avg": 0.08836977929598133, "timer/replay._sample_min": 0.0004405975341796875, "timer/replay._sample_max": 0.11852312088012695, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5361.0, "timer/agent.policy_total": 55.55610680580139, "timer/agent.policy_frac": 0.05554589180380587, "timer/agent.policy_avg": 0.01036301190184693, "timer/agent.policy_min": 0.0076751708984375, "timer/agent.policy_max": 0.021910667419433594, "timer/dataset_train_count": 2066.0, "timer/dataset_train_total": 0.16930365562438965, "timer/dataset_train_frac": 0.0001692725260640319, "timer/dataset_train_avg": 8.194755838547418e-05, "timer/dataset_train_min": 6.222724914550781e-05, "timer/dataset_train_max": 0.00017023086547851562, "timer/agent.train_count": 2066.0, "timer/agent.train_total": 769.7598342895508, "timer/agent.train_frac": 0.769618299925546, "timer/agent.train_avg": 0.37258462453511654, "timer/agent.train_min": 0.3535902500152588, "timer/agent.train_max": 1.6060311794281006, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.41582202911376953, "timer/agent.report_frac": 0.00041574557266097975, "timer/agent.report_avg": 0.20791101455688477, "timer/agent.report_min": 0.20775175094604492, "timer/agent.report_max": 0.2080702781677246, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.4809112548828125e-05, "timer/dataset_eval_frac": 3.480271225956035e-08, "timer/dataset_eval_avg": 3.4809112548828125e-05, "timer/dataset_eval_min": 3.4809112548828125e-05, "timer/dataset_eval_max": 3.4809112548828125e-05, "fps": 33.04937719258568}
{"step": 591904, "time": 18148.311811685562, "episode/length": 103.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9903846153846154, "episode/intrinsic_return": 0.0}
{"step": 592416, "time": 18162.61037516594, "episode/length": 181.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 592696, "time": 18170.167911052704, "episode/length": 181.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 592776, "time": 18172.928797245026, "episode/length": 167.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 593304, "time": 18187.090364933014, "episode/length": 427.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9976635514018691, "episode/intrinsic_return": 0.0}
{"step": 593336, "time": 18188.72324180603, "episode/length": 178.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 593680, "time": 18198.47565317154, "episode/length": 42.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 593720, "time": 18200.164197444916, "episode/length": 162.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 593920, "time": 18206.106631040573, "episode/length": 268.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9776951672862454, "episode/intrinsic_return": 0.0}
{"step": 593928, "time": 18207.022264003754, "episode/length": 410.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9781021897810219, "episode/intrinsic_return": 0.0}
{"step": 593984, "time": 18209.38384270668, "episode/length": 37.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 594472, "time": 18222.403401851654, "episode/length": 145.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 594496, "time": 18224.082372188568, "episode/length": 384.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9896103896103896, "episode/intrinsic_return": 0.0}
{"step": 594936, "time": 18235.67228078842, "episode/length": 279.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 595392, "time": 18248.1392056942, "episode/length": 326.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9847094801223242, "episode/intrinsic_return": 0.0}
{"step": 595416, "time": 18249.424762010574, "episode/length": 186.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 595472, "time": 18252.003044128418, "episode/length": 218.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 595544, "time": 18254.540050029755, "episode/length": 201.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 595592, "time": 18256.526168107986, "episode/length": 200.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 595904, "time": 18265.39722776413, "episode/length": 178.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 596304, "time": 18276.206040620804, "episode/length": 113.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.956140350877193, "episode/intrinsic_return": 0.0}
{"step": 596640, "time": 18285.61491584778, "episode/length": 267.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9850746268656716, "episode/intrinsic_return": 0.0}
{"step": 596720, "time": 18288.469870090485, "episode/length": 155.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 596776, "time": 18290.5095808506, "episode/length": 108.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9908256880733946, "episode/intrinsic_return": 0.0}
{"step": 596816, "time": 18292.53357076645, "episode/length": 234.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9702127659574468, "episode/intrinsic_return": 0.0}
{"step": 596864, "time": 18294.574899435043, "episode/length": 69.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9857142857142858, "episode/intrinsic_return": 0.0}
{"step": 596880, "time": 18295.805159330368, "episode/length": 166.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 597048, "time": 18300.66103744507, "episode/length": 181.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 597160, "time": 18304.3087682724, "episode/length": 217.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 597216, "time": 18306.76225423813, "episode/length": 43.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 597952, "time": 18326.651644468307, "episode/length": 163.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 598304, "time": 18336.388607263565, "episode/length": 190.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 598376, "time": 18338.81363081932, "episode/length": 165.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 598640, "time": 18346.374824285507, "episode/length": 239.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 598944, "time": 18354.883614063263, "episode/length": 257.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 599240, "time": 18362.95751261711, "episode/length": 302.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9867986798679867, "episode/intrinsic_return": 0.0}
{"step": 599296, "time": 18365.460809230804, "episode/length": 43.0, "episode/score": 3.099999949336052, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 599520, "time": 18371.93727827072, "episode/length": 195.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 599744, "time": 18378.230623960495, "episode/length": 315.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.990506329113924, "episode/intrinsic_return": 0.0}
{"step": 599992, "time": 18385.32795214653, "episode/length": 353.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9915254237288136, "episode/intrinsic_return": 0.0}
{"step": 600080, "time": 18391.825258255005, "eval_episode/length": 159.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.99375}
{"step": 600080, "time": 18392.827433109283, "eval_episode/length": 169.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9705882352941176}
{"step": 600080, "time": 18393.921310186386, "eval_episode/length": 184.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.972972972972973}
{"step": 600080, "time": 18395.188621282578, "eval_episode/length": 206.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9758454106280193}
{"step": 600080, "time": 18396.071351766586, "eval_episode/length": 210.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.995260663507109}
{"step": 600080, "time": 18398.326453208923, "eval_episode/length": 283.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9823943661971831}
{"step": 600080, "time": 18400.213718175888, "eval_episode/length": 150.0, "eval_episode/score": 8.099999971687794, "eval_episode/reward_rate": 0.9933774834437086}
{"step": 600080, "time": 18401.88736987114, "eval_episode/length": 379.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9973684210526316}
{"step": 600336, "time": 18408.41597700119, "episode/length": 244.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.0}
{"step": 600464, "time": 18412.401303052902, "episode/length": 269.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9962962962962963, "episode/intrinsic_return": 0.0}
{"step": 600792, "time": 18421.22721171379, "episode/length": 158.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9622641509433962, "episode/intrinsic_return": 0.0}
{"step": 600800, "time": 18422.413039684296, "episode/length": 194.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 601000, "time": 18428.028984069824, "episode/length": 156.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9554140127388535, "episode/intrinsic_return": 0.0}
{"step": 601648, "time": 18445.200394630432, "episode/length": 147.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 601904, "time": 18452.52258181572, "episode/length": 407.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 601904, "time": 18452.5630671978, "episode/length": 138.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.0}
{"step": 602064, "time": 18457.35427069664, "episode/length": 157.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 602136, "time": 18459.83419895172, "episode/length": 224.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9822222222222222, "episode/intrinsic_return": 0.0}
{"step": 602624, "time": 18472.954282045364, "episode/length": 415.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9783653846153846, "episode/intrinsic_return": 0.0}
{"step": 602840, "time": 18479.032257556915, "episode/length": 229.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9739130434782609, "episode/intrinsic_return": 0.0}
{"step": 603136, "time": 18487.439822912216, "episode/length": 153.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.961038961038961, "episode/intrinsic_return": 0.0}
{"step": 603152, "time": 18488.712278604507, "episode/length": 394.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9873417721518988, "episode/intrinsic_return": 0.0}
{"step": 603360, "time": 18494.771351099014, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 603376, "time": 18495.995188713074, "episode/length": 215.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 603456, "time": 18498.797603845596, "episode/length": 173.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 603568, "time": 18502.48486185074, "episode/length": 178.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9608938547486033, "episode/intrinsic_return": 0.0}
{"step": 604424, "time": 18524.38134932518, "episode/length": 197.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 604640, "time": 18530.767399311066, "episode/length": 159.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 604904, "time": 18537.88000178337, "episode/length": 220.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9819004524886877, "episode/intrinsic_return": 0.0}
{"step": 604920, "time": 18539.102885961533, "episode/length": 220.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 605400, "time": 18552.11931180954, "episode/length": 228.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 605776, "time": 18562.52089190483, "episode/length": 289.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9862068965517241, "episode/intrinsic_return": 0.0}
{"step": 605792, "time": 18563.84822487831, "episode/length": 170.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 606016, "time": 18570.248242855072, "episode/length": 423.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9787735849056604, "episode/intrinsic_return": 0.0}
{"step": 606192, "time": 18575.45810198784, "episode/length": 160.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 606512, "time": 18584.369544029236, "episode/length": 91.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9891304347826086, "episode/intrinsic_return": 0.0}
{"step": 606656, "time": 18588.73633813858, "episode/length": 107.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9444444444444444, "episode/intrinsic_return": 0.0}
{"step": 607032, "time": 18598.734853744507, "episode/length": 46.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 607136, "time": 18602.356088638306, "episode/length": 117.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9915254237288136, "episode/intrinsic_return": 0.0}
{"step": 607344, "time": 18608.48198580742, "episode/length": 302.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9834983498349835, "episode/intrinsic_return": 0.0}
{"step": 608008, "time": 18625.738271951675, "episode/length": 186.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 608176, "time": 18630.91329908371, "episode/length": 346.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9855907780979827, "episode/intrinsic_return": 0.0}
{"step": 608184, "time": 18631.748955965042, "episode/length": 600.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9950083194675541, "episode/intrinsic_return": 0.0}
{"step": 608536, "time": 18641.39918255806, "episode/length": 314.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9809523809523809, "episode/intrinsic_return": 0.0}
{"step": 608544, "time": 18642.59869503975, "episode/length": 45.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 608560, "time": 18643.783311843872, "episode/length": 190.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 608696, "time": 18647.838317155838, "episode/length": 194.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 608704, "time": 18649.06096148491, "episode/length": 169.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9647058823529412, "episode/intrinsic_return": 0.0}
{"step": 609232, "time": 18663.04027557373, "episode/length": 130.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9618320610687023, "episode/intrinsic_return": 0.0}
{"step": 609816, "time": 18678.271847963333, "episode/length": 138.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.0}
{"step": 609880, "time": 18680.65070748329, "episode/length": 166.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 610064, "time": 18688.032997131348, "eval_episode/length": 47.0, "eval_episode/score": 5.0999999940395355, "eval_episode/reward_rate": 0.9791666666666666}
{"step": 610064, "time": 18690.465213298798, "eval_episode/length": 143.0, "eval_episode/score": 6.100000023841858, "eval_episode/reward_rate": 0.9930555555555556}
{"step": 610064, "time": 18692.067373991013, "eval_episode/length": 184.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9621621621621622}
{"step": 610064, "time": 18693.0159201622, "eval_episode/length": 191.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.96875}
{"step": 610064, "time": 18693.97582411766, "eval_episode/length": 199.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.975}
{"step": 610064, "time": 18695.13937306404, "eval_episode/length": 166.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9640718562874252}
{"step": 610064, "time": 18697.11114883423, "eval_episode/length": 270.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.974169741697417}
{"step": 610064, "time": 18699.444356918335, "eval_episode/length": 135.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9558823529411765}
{"step": 610240, "time": 18704.03127670288, "episode/length": 192.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9844559585492227, "episode/intrinsic_return": 0.0}
{"step": 610328, "time": 18706.907022953033, "episode/length": 223.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 610560, "time": 18713.714573144913, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 610632, "time": 18716.181933879852, "episode/length": 748.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9973297730307076, "episode/intrinsic_return": 0.0}
{"step": 611224, "time": 18732.006237268448, "episode/length": 175.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 611232, "time": 18733.209844827652, "episode/length": 112.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9911504424778761, "episode/intrinsic_return": 0.0}
{"step": 611264, "time": 18734.893226385117, "episode/length": 406.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9975429975429976, "episode/intrinsic_return": 0.0}
{"step": 611488, "time": 18741.398287773132, "episode/length": 200.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 611728, "time": 18748.127273082733, "episode/length": 57.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 611912, "time": 18753.266705274582, "episode/length": 208.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9712918660287081, "episode/intrinsic_return": 0.0}
{"step": 611928, "time": 18754.494374990463, "episode/length": 420.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.997624703087886, "episode/intrinsic_return": 0.0}
{"step": 612360, "time": 18766.127160549164, "episode/length": 224.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 612648, "time": 18774.130942106247, "episode/length": 251.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9801587301587301, "episode/intrinsic_return": 0.0}
{"step": 612832, "time": 18779.818603754044, "episode/length": 167.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 612936, "time": 18783.069642543793, "episode/length": 212.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 613048, "time": 18786.80817270279, "episode/length": 164.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 613280, "time": 18793.568145036697, "episode/length": 168.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9644970414201184, "episode/intrinsic_return": 0.0}
{"step": 613672, "time": 18804.029036045074, "episode/length": 219.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 613904, "time": 18811.034383296967, "episode/length": 334.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9880597014925373, "episode/intrinsic_return": 0.0}
{"step": 613936, "time": 18812.744493722916, "episode/length": 124.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.96, "episode/intrinsic_return": 0.0}
{"step": 614112, "time": 18818.072991132736, "episode/length": 182.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 614336, "time": 18824.612949848175, "episode/length": 246.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 614592, "time": 18831.865569591522, "episode/length": 163.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 614648, "time": 18833.83956718445, "episode/length": 121.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9918032786885246, "episode/intrinsic_return": 0.0}
{"step": 615144, "time": 18847.178985595703, "episode/length": 150.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 615800, "time": 18864.539595127106, "episode/length": 81.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9878048780487805, "episode/intrinsic_return": 0.0}
{"step": 615832, "time": 18866.204927682877, "episode/length": 374.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9946666666666667, "episode/intrinsic_return": 0.0}
{"step": 616048, "time": 18872.675199747086, "episode/length": 181.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 616264, "time": 18878.63213777542, "episode/length": 201.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 616448, "time": 18884.230925559998, "episode/length": 424.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9788235294117648, "episode/intrinsic_return": 0.0}
{"step": 616592, "time": 18888.64476251602, "episode/length": 335.0, "episode/score": 9.099999964237213, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 616832, "time": 18895.354876041412, "episode/length": 311.0, "episode/score": 10.099999964237213, "episode/reward_rate": 0.9871794871794872, "episode/intrinsic_return": 0.0}
{"step": 616976, "time": 18899.819848775864, "episode/length": 357.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9972067039106145, "episode/intrinsic_return": 0.0}
{"step": 617280, "time": 18908.280019521713, "episode/length": 126.0, "episode/score": 6.1000000461936, "episode/reward_rate": 0.9921259842519685, "episode/intrinsic_return": 0.0}
{"step": 617680, "time": 18919.130106449127, "episode/length": 153.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 617800, "time": 18922.901278734207, "episode/length": 150.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9735099337748344, "episode/intrinsic_return": 0.0}
{"step": 618200, "time": 18933.681742429733, "episode/length": 268.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9851301115241635, "episode/intrinsic_return": 0.0}
{"step": 618552, "time": 18943.572442531586, "episode/length": 214.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 618800, "time": 18950.77085852623, "episode/length": 374.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9973333333333333, "episode/intrinsic_return": 0.0}
{"step": 619024, "time": 18957.188881874084, "episode/length": 217.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 619112, "time": 18960.039319753647, "episode/length": 409.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9975609756097561, "episode/intrinsic_return": 0.0}
{"step": 619120, "time": 18961.268345594406, "episode/length": 267.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9776119402985075, "episode/intrinsic_return": 0.0}
{"step": 619192, "time": 18963.7192633152, "episode/length": 173.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 619488, "time": 18972.318655014038, "episode/length": 45.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 619632, "time": 18976.67887187004, "episode/length": 243.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 619696, "time": 18979.1730594635, "episode/length": 186.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 620048, "time": 18991.48078250885, "eval_episode/length": 112.0, "eval_episode/score": 5.100000023841858, "eval_episode/reward_rate": 0.9911504424778761}
{"step": 620048, "time": 18993.837550640106, "eval_episode/length": 199.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.975}
{"step": 620048, "time": 18994.725214242935, "eval_episode/length": 201.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9702970297029703}
{"step": 620048, "time": 18995.77586555481, "eval_episode/length": 212.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9812206572769953}
{"step": 620048, "time": 18996.771676540375, "eval_episode/length": 220.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9773755656108597}
{"step": 620048, "time": 18999.17951464653, "eval_episode/length": 298.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.979933110367893}
{"step": 620048, "time": 19000.46339917183, "eval_episode/length": 211.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9952830188679245}
{"step": 620048, "time": 19002.35588669777, "eval_episode/length": 378.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9894459102902374}
{"step": 620616, "time": 19016.488270282745, "episode/length": 177.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 620640, "time": 19018.10555791855, "episode/length": 260.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9961685823754789, "episode/intrinsic_return": 0.0}
{"step": 620696, "time": 19020.110078811646, "episode/length": 197.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 621104, "time": 19031.343819379807, "episode/length": 201.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 621952, "time": 19053.469425201416, "episode/length": 365.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9863387978142076, "episode/intrinsic_return": 0.0}
{"step": 622072, "time": 19057.153697490692, "episode/length": 181.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 622248, "time": 19062.37076497078, "episode/length": 430.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9791183294663574, "episode/intrinsic_return": 0.0}
{"step": 622528, "time": 19070.381313085556, "episode/length": 228.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 622728, "time": 19076.08367919922, "episode/length": 202.0, "episode/score": 8.099999964237213, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 623120, "time": 19086.917194843292, "episode/length": 427.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 623160, "time": 19088.60373568535, "episode/length": 440.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9863945578231292, "episode/intrinsic_return": 0.0}
{"step": 623264, "time": 19092.284612178802, "episode/length": 66.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9850746268656716, "episode/intrinsic_return": 0.0}
{"step": 623376, "time": 19095.902418375015, "episode/length": 341.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9970760233918129, "episode/intrinsic_return": 0.0}
{"step": 623624, "time": 19102.832220315933, "episode/length": 193.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 624208, "time": 19118.508182287216, "episode/length": 209.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 624504, "time": 19126.612499713898, "episode/length": 154.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9612903225806452, "episode/intrinsic_return": 0.0}
{"step": 624888, "time": 19136.97583770752, "episode/length": 329.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.990909090909091, "episode/intrinsic_return": 0.0}
{"step": 625008, "time": 19140.9952044487, "episode/length": 203.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 625056, "time": 19142.936594247818, "episode/length": 241.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9834710743801653, "episode/intrinsic_return": 0.0}
{"step": 625161, "time": 19147.066760778427, "train_stats/sum_log_reward": 7.883783978384894, "train_stats/max_log_achievement_collect_coal": 0.6554054054054054, "train_stats/max_log_achievement_collect_drink": 5.695945945945946, "train_stats/max_log_achievement_collect_sapling": 1.2297297297297298, "train_stats/max_log_achievement_collect_stone": 9.608108108108109, "train_stats/max_log_achievement_collect_wood": 10.621621621621621, "train_stats/max_log_achievement_defeat_skeleton": 0.033783783783783786, "train_stats/max_log_achievement_defeat_zombie": 0.22297297297297297, "train_stats/max_log_achievement_eat_cow": 0.08108108108108109, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 2.6013513513513513, "train_stats/max_log_achievement_make_wood_sword": 0.006756756756756757, "train_stats/max_log_achievement_place_furnace": 0.0472972972972973, "train_stats/max_log_achievement_place_plant": 1.2162162162162162, "train_stats/max_log_achievement_place_stone": 7.283783783783784, "train_stats/max_log_achievement_place_table": 2.777027027027027, "train_stats/max_log_achievement_wake_up": 1.4189189189189189, "train_stats/mean_log_entropy": 0.5760833773057203, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.155184525709886, "train/action_min": 0.0, "train/action_std": 2.9782481285241933, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.037006912797761075, "train/actor_opt_grad_steps": 37935.0, "train/actor_opt_loss": -2.363539488780169, "train/adv_mag": 0.4865825050152265, "train/adv_max": 0.461044474863089, "train/adv_mean": 0.0037098994105552773, "train/adv_min": -0.37279333933614767, "train/adv_std": 0.05639615515246987, "train/cont_avg": 0.9948448768028846, "train/cont_loss_mean": 0.0001639741367224992, "train/cont_loss_std": 0.004710851151294002, "train/cont_neg_acc": 0.9918612645795712, "train/cont_neg_loss": 0.017840034409206194, "train/cont_pos_acc": 0.9999858456162306, "train/cont_pos_loss": 7.23116821525098e-05, "train/cont_pred": 0.9948584491816851, "train/cont_rate": 0.9948448768028846, "train/dyn_loss_mean": 13.759386709103218, "train/dyn_loss_std": 9.284495537097637, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9656294142970672, "train/extr_critic_critic_opt_grad_steps": 37935.0, "train/extr_critic_critic_opt_loss": 16277.950857309195, "train/extr_critic_mag": 6.821575132700113, "train/extr_critic_max": 6.821575132700113, "train/extr_critic_mean": 1.8361647908504193, "train/extr_critic_min": -0.2935347729004346, "train/extr_critic_std": 1.6452144155135522, "train/extr_return_normed_mag": 1.5361596162502582, "train/extr_return_normed_max": 1.5361596162502582, "train/extr_return_normed_mean": 0.3578818075788709, "train/extr_return_normed_min": -0.10537976696370886, "train/extr_return_normed_std": 0.3203199298049395, "train/extr_return_rate": 0.7287732612055081, "train/extr_return_raw_mag": 8.02684860275342, "train/extr_return_raw_max": 8.02684860275342, "train/extr_return_raw_mean": 1.8554905205965042, "train/extr_return_raw_min": -0.5722202062606812, "train/extr_return_raw_std": 1.679173163496531, "train/extr_reward_mag": 1.0219619182439952, "train/extr_reward_max": 1.0219619182439952, "train/extr_reward_mean": 0.03274991540596462, "train/extr_reward_min": -0.3624001993582799, "train/extr_reward_std": 0.16926214679215962, "train/image_loss_mean": 7.284073286331617, "train/image_loss_std": 12.177635367100056, "train/model_loss_mean": 15.594061044546274, "train/model_loss_std": 16.02161929699091, "train/model_opt_grad_norm": 58.26855588876284, "train/model_opt_grad_steps": 37900.144230769234, "train/model_opt_loss": 14461.553502009465, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 928.4855769230769, "train/policy_entropy_mag": 2.4997491251963835, "train/policy_entropy_max": 2.4997491251963835, "train/policy_entropy_mean": 0.5488941351381632, "train/policy_entropy_min": 0.07937502721324563, "train/policy_entropy_std": 0.6304706090058272, "train/policy_logprob_mag": 7.438383634273823, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5486972352059988, "train/policy_logprob_min": -7.438383634273823, "train/policy_logprob_std": 1.095376687267652, "train/policy_randomness_mag": 0.8823017437870686, "train/policy_randomness_max": 0.8823017437870686, "train/policy_randomness_mean": 0.19373554177582264, "train/policy_randomness_min": 0.028015901325628735, "train/policy_randomness_std": 0.22252845642371819, "train/post_ent_mag": 58.796394733282234, "train/post_ent_max": 58.796394733282234, "train/post_ent_mean": 41.8962850020482, "train/post_ent_min": 20.59777175463163, "train/post_ent_std": 7.378724348086577, "train/prior_ent_mag": 68.31009057851938, "train/prior_ent_max": 68.31009057851938, "train/prior_ent_mean": 55.71659739200886, "train/prior_ent_min": 41.85933481729948, "train/prior_ent_std": 4.486586830936945, "train/rep_loss_mean": 13.759386709103218, "train/rep_loss_std": 9.284495537097637, "train/reward_avg": 0.025429593439464673, "train/reward_loss_mean": 0.05419180708794066, "train/reward_loss_std": 0.2516304228741389, "train/reward_max_data": 1.0100961562532644, "train/reward_max_pred": 1.0053590633548224, "train/reward_neg_acc": 0.9933164790272713, "train/reward_neg_loss": 0.02891213599538717, "train/reward_pos_acc": 0.9623452768876002, "train/reward_pos_loss": 0.8746880553662777, "train/reward_pred": 0.02466903188570331, "train/reward_rate": 0.030137282151442308, "eval_stats/sum_log_reward": 7.516666829586029, "eval_stats/max_log_achievement_collect_coal": 0.5, "eval_stats/max_log_achievement_collect_drink": 3.8333333333333335, "eval_stats/max_log_achievement_collect_sapling": 1.125, "eval_stats/max_log_achievement_collect_stone": 8.375, "eval_stats/max_log_achievement_collect_wood": 12.208333333333334, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.2916666666666667, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 3.125, "eval_stats/max_log_achievement_make_wood_sword": 0.041666666666666664, "eval_stats/max_log_achievement_place_furnace": 0.041666666666666664, "eval_stats/max_log_achievement_place_plant": 1.125, "eval_stats/max_log_achievement_place_stone": 6.416666666666667, "eval_stats/max_log_achievement_place_table": 3.1666666666666665, "eval_stats/max_log_achievement_wake_up": 1.2083333333333333, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.0002148352359654382, "report/cont_loss_std": 0.0057032303884625435, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00028843196923844516, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.00021454659872688353, "report/cont_pred": 0.995896577835083, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 14.236984252929688, "report/dyn_loss_std": 9.40270709991455, "report/image_loss_mean": 8.35513687133789, "report/image_loss_std": 13.916494369506836, "report/model_loss_mean": 16.9462890625, "report/model_loss_std": 17.921472549438477, "report/post_ent_mag": 58.61826705932617, "report/post_ent_max": 58.61826705932617, "report/post_ent_mean": 42.706504821777344, "report/post_ent_min": 21.176738739013672, "report/post_ent_std": 7.418610572814941, "report/prior_ent_mag": 68.48944091796875, "report/prior_ent_max": 68.48944091796875, "report/prior_ent_mean": 56.82231140136719, "report/prior_ent_min": 43.97205352783203, "report/prior_ent_std": 4.599818229675293, "report/rep_loss_mean": 14.236984252929688, "report/rep_loss_std": 9.40270709991455, "report/reward_avg": 0.02744140662252903, "report/reward_loss_mean": 0.048746298998594284, "report/reward_loss_std": 0.21154864132404327, "report/reward_max_data": 1.0, "report/reward_max_pred": 0.9996501207351685, "report/reward_neg_acc": 0.992943525314331, "report/reward_neg_loss": 0.02438095025718212, "report/reward_pos_acc": 0.96875, "report/reward_pos_loss": 0.8040721416473389, "report/reward_pred": 0.0267377607524395, "report/reward_rate": 0.03125, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 1.7186543118441477e-05, "eval/cont_loss_std": 0.00042450850014574826, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0006805171724408865, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.3276932804728858e-05, "eval/cont_pred": 0.9941315650939941, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 16.936737060546875, "eval/dyn_loss_std": 10.591980934143066, "eval/image_loss_mean": 12.609481811523438, "eval/image_loss_std": 15.44802474975586, "eval/model_loss_mean": 22.879371643066406, "eval/model_loss_std": 19.688188552856445, "eval/post_ent_mag": 59.325687408447266, "eval/post_ent_max": 59.325687408447266, "eval/post_ent_mean": 41.940486907958984, "eval/post_ent_min": 20.613344192504883, "eval/post_ent_std": 7.192223072052002, "eval/prior_ent_mag": 68.48944091796875, "eval/prior_ent_max": 68.48944091796875, "eval/prior_ent_mean": 56.178916931152344, "eval/prior_ent_min": 46.183101654052734, "eval/prior_ent_std": 4.03887414932251, "eval/rep_loss_mean": 16.936737060546875, "eval/rep_loss_std": 10.591980934143066, "eval/reward_avg": 0.02421874925494194, "eval/reward_loss_mean": 0.10783256590366364, "eval/reward_loss_std": 0.7014469504356384, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9999839067459106, "eval/reward_neg_acc": 0.9909456372261047, "eval/reward_neg_loss": 0.05370747298002243, "eval/reward_pos_acc": 0.8333333730697632, "eval/reward_pos_loss": 1.9011770486831665, "eval/reward_pred": 0.024939749389886856, "eval/reward_rate": 0.029296875, "replay/size": 624657.0, "replay/inserts": 33328.0, "replay/samples": 33328.0, "replay/insert_wait_avg": 1.2221885196760876e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 5.714591740989594e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 8880.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2296814102310318e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.195638656616211e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3532223701477, "timer/env.step_count": 4166.0, "timer/env.step_total": 136.8265609741211, "timer/env.step_frac": 0.13677824783723538, "timer/env.step_avg": 0.032843629614527386, "timer/env.step_min": 0.0022459030151367188, "timer/env.step_max": 0.9252617359161377, "timer/replay._sample_count": 33328.0, "timer/replay._sample_total": 2951.6847236156464, "timer/replay._sample_frac": 2.9506424906816293, "timer/replay._sample_avg": 0.08856471206239938, "timer/replay._sample_min": 0.0005731582641601562, "timer/replay._sample_max": 0.12087178230285645, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5276.0, "timer/agent.policy_total": 54.300251722335815, "timer/agent.policy_frac": 0.05428107843115819, "timer/agent.policy_avg": 0.01029193550461255, "timer/agent.policy_min": 0.007567405700683594, "timer/agent.policy_max": 0.01938915252685547, "timer/dataset_train_count": 2083.0, "timer/dataset_train_total": 0.16877388954162598, "timer/dataset_train_frac": 0.00016871429587815809, "timer/dataset_train_avg": 8.10244308889227e-05, "timer/dataset_train_min": 6.031990051269531e-05, "timer/dataset_train_max": 0.00017881393432617188, "timer/agent.train_count": 2083.0, "timer/agent.train_total": 774.4220042228699, "timer/agent.train_frac": 0.7741485576344957, "timer/agent.train_avg": 0.3717820471545223, "timer/agent.train_min": 0.3505253791809082, "timer/agent.train_max": 0.508429765701294, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4144117832183838, "timer/agent.report_frac": 0.00041426545539235976, "timer/agent.report_avg": 0.2072058916091919, "timer/agent.report_min": 0.2066972255706787, "timer/agent.report_max": 0.20771455764770508, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.528594970703125e-05, "timer/dataset_eval_frac": 3.527349032117662e-08, "timer/dataset_eval_avg": 3.528594970703125e-05, "timer/dataset_eval_min": 3.528594970703125e-05, "timer/dataset_eval_max": 3.528594970703125e-05, "fps": 33.315711253909846}
{"step": 625280, "time": 19149.927443265915, "episode/length": 415.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9975961538461539, "episode/intrinsic_return": 0.0}
{"step": 625904, "time": 19166.47121143341, "episode/length": 174.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9542857142857143, "episode/intrinsic_return": 0.0}
{"step": 626248, "time": 19175.699464321136, "episode/length": 254.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9725490196078431, "episode/intrinsic_return": 0.0}
{"step": 626504, "time": 19182.784582853317, "episode/length": 186.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 626552, "time": 19184.852479696274, "episode/length": 158.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9622641509433962, "episode/intrinsic_return": 0.0}
{"step": 626584, "time": 19186.48469734192, "episode/length": 427.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9789719626168224, "episode/intrinsic_return": 0.0}
{"step": 626760, "time": 19191.864991903305, "episode/length": 233.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9871794871794872, "episode/intrinsic_return": 0.0}
{"step": 626992, "time": 19198.490913629532, "episode/length": 420.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9928741092636579, "episode/intrinsic_return": 0.0}
{"step": 627336, "time": 19207.704023361206, "episode/length": 93.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9893617021276596, "episode/intrinsic_return": 0.0}
{"step": 627472, "time": 19212.098387241364, "episode/length": 301.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9900662251655629, "episode/intrinsic_return": 0.0}
{"step": 627488, "time": 19213.286422252655, "episode/length": 197.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 628136, "time": 19230.142174720764, "episode/length": 197.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 628624, "time": 19243.559155225754, "episode/length": 296.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9865319865319865, "episode/intrinsic_return": 0.0}
{"step": 628888, "time": 19250.801908254623, "episode/length": 236.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 629520, "time": 19267.376645088196, "episode/length": 255.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.98046875, "episode/intrinsic_return": 0.0}
{"step": 629648, "time": 19271.331256628036, "episode/length": 360.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9944598337950139, "episode/intrinsic_return": 0.0}
{"step": 630008, "time": 19280.91574859619, "episode/length": 437.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9794520547945206, "episode/intrinsic_return": 0.0}
{"step": 630032, "time": 19284.379821300507, "eval_episode/length": 57.0, "eval_episode/score": 7.099999971687794, "eval_episode/reward_rate": 0.9827586206896551}
{"step": 630032, "time": 19285.277960777283, "eval_episode/length": 61.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9193548387096774}
{"step": 630032, "time": 19288.089384317398, "eval_episode/length": 169.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9647058823529412}
{"step": 630032, "time": 19289.51930999756, "eval_episode/length": 140.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9645390070921985}
{"step": 630032, "time": 19290.434109926224, "eval_episode/length": 205.0, "eval_episode/score": 7.0999999940395355, "eval_episode/reward_rate": 0.9951456310679612}
{"step": 630032, "time": 19292.013025522232, "eval_episode/length": 239.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9791666666666666}
{"step": 630032, "time": 19292.8776307106, "eval_episode/length": 184.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9783783783783784}
{"step": 630032, "time": 19294.294416189194, "eval_episode/length": 99.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.96}
{"step": 630504, "time": 19305.88951587677, "episode/length": 201.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 630592, "time": 19309.1196706295, "episode/length": 406.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.995085995085995, "episode/intrinsic_return": 0.0}
{"step": 630600, "time": 19309.97534918785, "episode/length": 307.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9902597402597403, "episode/intrinsic_return": 0.0}
{"step": 630760, "time": 19314.907660484314, "episode/length": 266.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9737827715355806, "episode/intrinsic_return": 0.0}
{"step": 630824, "time": 19317.3426053524, "episode/length": 416.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9976019184652278, "episode/intrinsic_return": 0.0}
{"step": 630840, "time": 19318.515978336334, "episode/length": 148.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9731543624161074, "episode/intrinsic_return": 0.0}
{"step": 631000, "time": 19323.39915060997, "episode/length": 184.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 631104, "time": 19326.98185491562, "episode/length": 42.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 631720, "time": 19343.37411379814, "episode/length": 213.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 632256, "time": 19357.712966442108, "episode/length": 206.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 632464, "time": 19363.667637348175, "episode/length": 202.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9802955665024631, "episode/intrinsic_return": 0.0}
{"step": 632504, "time": 19365.283393621445, "episode/length": 187.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 632616, "time": 19368.89582681656, "episode/length": 44.0, "episode/score": 1.0999999940395355, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 632816, "time": 19374.850240707397, "episode/length": 213.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 632816, "time": 19374.863931894302, "episode/length": 288.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9826989619377162, "episode/intrinsic_return": 0.0}
{"step": 633008, "time": 19380.60600876808, "episode/length": 301.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9966887417218543, "episode/intrinsic_return": 0.0}
{"step": 633344, "time": 19389.922403097153, "episode/length": 314.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9904761904761905, "episode/intrinsic_return": 0.0}
{"step": 634024, "time": 19407.897797584534, "episode/length": 194.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 634456, "time": 19419.47929096222, "episode/length": 180.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 634512, "time": 19421.881573677063, "episode/length": 250.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9681274900398407, "episode/intrinsic_return": 0.0}
{"step": 634696, "time": 19427.216860055923, "episode/length": 234.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 634832, "time": 19431.499220848083, "episode/length": 251.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9841269841269841, "episode/intrinsic_return": 0.0}
{"step": 635320, "time": 19444.186633825302, "episode/length": 449.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 635344, "time": 19445.893256425858, "episode/length": 164.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9636363636363636, "episode/intrinsic_return": 0.0}
{"step": 635872, "time": 19459.744285583496, "episode/length": 315.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9778481012658228, "episode/intrinsic_return": 0.0}
{"step": 635912, "time": 19461.344034194946, "episode/length": 174.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 636152, "time": 19468.17381644249, "episode/length": 441.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 636216, "time": 19470.685686588287, "episode/length": 189.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 636392, "time": 19475.95337486267, "episode/length": 194.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 636576, "time": 19481.631875038147, "episode/length": 153.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 636888, "time": 19489.986542224884, "episode/length": 303.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9835526315789473, "episode/intrinsic_return": 0.0}
{"step": 637088, "time": 19496.003254413605, "episode/length": 146.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9591836734693877, "episode/intrinsic_return": 0.0}
{"step": 637240, "time": 19500.50480031967, "episode/length": 82.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9518072289156626, "episode/intrinsic_return": 0.0}
{"step": 637496, "time": 19507.853893518448, "episode/length": 271.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9742647058823529, "episode/intrinsic_return": 0.0}
{"step": 637576, "time": 19510.776394367218, "episode/length": 177.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 638224, "time": 19527.979670524597, "episode/length": 250.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9960159362549801, "episode/intrinsic_return": 0.0}
{"step": 638840, "time": 19543.795142173767, "episode/length": 167.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 639320, "time": 19556.527685403824, "episode/length": 430.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9791183294663574, "episode/intrinsic_return": 0.0}
{"step": 639528, "time": 19562.829721689224, "episode/length": 285.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9755244755244755, "episode/intrinsic_return": 0.0}
{"step": 639552, "time": 19564.5363175869, "episode/length": 394.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9974683544303797, "episode/intrinsic_return": 0.0}
{"step": 639632, "time": 19567.41715502739, "episode/length": 342.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9854227405247813, "episode/intrinsic_return": 0.0}
{"step": 639936, "time": 19575.8541367054, "episode/length": 50.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9019607843137255, "episode/intrinsic_return": 0.0}
{"step": 640016, "time": 19580.57560801506, "eval_episode/length": 52.0, "eval_episode/score": 3.100000023841858, "eval_episode/reward_rate": 0.9811320754716981}
{"step": 640016, "time": 19583.435446977615, "eval_episode/length": 164.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9939393939393939}
{"step": 640016, "time": 19584.3888463974, "eval_episode/length": 167.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9583333333333334}
{"step": 640016, "time": 19585.41389632225, "eval_episode/length": 179.0, "eval_episode/score": 8.100000023841858, "eval_episode/reward_rate": 0.9944444444444445}
{"step": 640016, "time": 19586.49479866028, "eval_episode/length": 192.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9689119170984456}
{"step": 640016, "time": 19587.490460395813, "eval_episode/length": 200.0, "eval_episode/score": 9.099999971687794, "eval_episode/reward_rate": 0.9950248756218906}
{"step": 640016, "time": 19588.289397478104, "eval_episode/length": 201.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.995049504950495}
{"step": 640016, "time": 19589.62564110756, "eval_episode/length": 220.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.995475113122172}
{"step": 640072, "time": 19590.83327484131, "episode/length": 311.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9903846153846154, "episode/intrinsic_return": 0.0}
{"step": 640144, "time": 19593.614153385162, "episode/length": 162.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 640456, "time": 19601.865201711655, "episode/length": 420.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9786223277909739, "episode/intrinsic_return": 0.0}
{"step": 641048, "time": 19617.59952378273, "episode/length": 176.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 641256, "time": 19623.68492603302, "episode/length": 378.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9894459102902374, "episode/intrinsic_return": 0.0}
{"step": 641680, "time": 19635.39207839966, "episode/length": 294.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 641712, "time": 19637.02103805542, "episode/length": 221.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 641784, "time": 19639.41792321205, "episode/length": 213.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 641904, "time": 19643.446551322937, "episode/length": 180.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9668508287292817, "episode/intrinsic_return": 0.0}
{"step": 641912, "time": 19644.315673828125, "episode/length": 220.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 642056, "time": 19648.72973537445, "episode/length": 125.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9920634920634921, "episode/intrinsic_return": 0.0}
{"step": 642176, "time": 19652.734679937363, "episode/length": 48.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 642520, "time": 19661.847767353058, "episode/length": 157.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 642560, "time": 19663.886527061462, "episode/length": 375.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 643096, "time": 19677.77043581009, "episode/length": 172.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 643152, "time": 19680.219559192657, "episode/length": 183.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 643200, "time": 19682.273489952087, "episode/length": 161.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 643872, "time": 19699.764519691467, "episode/length": 226.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 644040, "time": 19704.730792045593, "episode/length": 232.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 644216, "time": 19709.89931988716, "episode/length": 126.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9921259842519685, "episode/intrinsic_return": 0.0}
{"step": 644576, "time": 19720.00454545021, "episode/length": 256.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.980544747081712, "episode/intrinsic_return": 0.0}
{"step": 644576, "time": 19720.046782255173, "episode/length": 251.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.996031746031746, "episode/intrinsic_return": 0.0}
{"step": 644872, "time": 19728.154535770416, "episode/length": 36.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.8648648648648649, "episode/intrinsic_return": 0.0}
{"step": 644912, "time": 19730.254173755646, "episode/length": 226.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9691629955947136, "episode/intrinsic_return": 0.0}
{"step": 645208, "time": 19738.468762874603, "episode/length": 411.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9975728155339806, "episode/intrinsic_return": 0.0}
{"step": 645424, "time": 19745.06643486023, "episode/length": 172.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9653179190751445, "episode/intrinsic_return": 0.0}
{"step": 645512, "time": 19747.902857780457, "episode/length": 294.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9966101694915255, "episode/intrinsic_return": 0.0}
{"step": 645768, "time": 19754.927823781967, "episode/length": 193.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 646000, "time": 19761.71453142166, "episode/length": 177.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 646120, "time": 19765.405940294266, "episode/length": 155.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 646120, "time": 19765.449919462204, "episode/length": 150.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9867549668874173, "episode/intrinsic_return": 0.0}
{"step": 646480, "time": 19775.459688186646, "episode/length": 158.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 646720, "time": 19782.365325450897, "episode/length": 355.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9971910112359551, "episode/intrinsic_return": 0.0}
{"step": 647152, "time": 19793.785711050034, "episode/length": 172.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9595375722543352, "episode/intrinsic_return": 0.0}
{"step": 647208, "time": 19795.78488612175, "episode/length": 211.0, "episode/score": 9.1000000461936, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 647384, "time": 19800.96802186966, "episode/length": 172.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9653179190751445, "episode/intrinsic_return": 0.0}
{"step": 647616, "time": 19807.825278043747, "episode/length": 273.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9817518248175182, "episode/intrinsic_return": 0.0}
{"step": 647736, "time": 19811.4527323246, "episode/length": 156.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 647864, "time": 19815.584614515305, "episode/length": 217.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 647872, "time": 19816.820773124695, "episode/length": 218.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 648664, "time": 19837.242109298706, "episode/length": 188.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 648760, "time": 19840.47275686264, "episode/length": 142.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.965034965034965, "episode/intrinsic_return": 0.0}
{"step": 648808, "time": 19842.398345947266, "episode/length": 117.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9915254237288136, "episode/intrinsic_return": 0.0}
{"step": 648968, "time": 19847.24491262436, "episode/length": 197.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 649128, "time": 19852.150286912918, "episode/length": 57.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 649200, "time": 19854.94397997856, "episode/length": 309.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9967741935483871, "episode/intrinsic_return": 0.0}
{"step": 649376, "time": 19860.205064296722, "episode/length": 187.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 649976, "time": 19875.851360559464, "episode/length": 345.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 650000, "time": 19880.093177080154, "eval_episode/length": 102.0, "eval_episode/score": 8.100000023841858, "eval_episode/reward_rate": 0.9902912621359223}
{"step": 650000, "time": 19883.66163444519, "eval_episode/length": 255.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9765625}
{"step": 650000, "time": 19884.74945616722, "eval_episode/length": 170.0, "eval_episode/score": 9.100000023841858, "eval_episode/reward_rate": 0.9941520467836257}
{"step": 650000, "time": 19885.93508028984, "eval_episode/length": 292.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9897610921501706}
{"step": 650000, "time": 19886.930879354477, "eval_episode/length": 301.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9966887417218543}
{"step": 650000, "time": 19888.05194234848, "eval_episode/length": 315.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.9841772151898734}
{"step": 650000, "time": 19889.57543540001, "eval_episode/length": 346.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9884726224783862}
{"step": 650000, "time": 19891.75593161583, "eval_episode/length": 420.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.995249406175772}
{"step": 650408, "time": 19901.964411258698, "episode/length": 199.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 650608, "time": 19908.022459983826, "episode/length": 153.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 650696, "time": 19910.94765472412, "episode/length": 241.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9958677685950413, "episode/intrinsic_return": 0.0}
{"step": 650768, "time": 19913.845717906952, "episode/length": 378.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9920844327176781, "episode/intrinsic_return": 0.0}
{"step": 650936, "time": 19918.794553995132, "episode/length": 216.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9723502304147466, "episode/intrinsic_return": 0.0}
{"step": 651320, "time": 19929.30471920967, "episode/length": 167.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 651344, "time": 19930.879637002945, "episode/length": 296.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9966329966329966, "episode/intrinsic_return": 0.0}
{"step": 651784, "time": 19942.57118320465, "episode/length": 135.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9926470588235294, "episode/intrinsic_return": 0.0}
{"step": 651912, "time": 19946.71816945076, "episode/length": 162.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 652248, "time": 19956.087819814682, "episode/length": 389.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9897435897435898, "episode/intrinsic_return": 0.0}
{"step": 652296, "time": 19958.15631866455, "episode/length": 235.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 652512, "time": 19964.53506541252, "episode/length": 196.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 652768, "time": 19971.850135803223, "episode/length": 180.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 653016, "time": 19978.93056344986, "episode/length": 208.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 653248, "time": 19985.95699763298, "episode/length": 182.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9672131147540983, "episode/intrinsic_return": 0.0}
{"step": 653488, "time": 19992.778675317764, "episode/length": 121.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9918032786885246, "episode/intrinsic_return": 0.0}
{"step": 653496, "time": 19993.6171066761, "episode/length": 197.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 653976, "time": 20006.57573723793, "episode/length": 400.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9775561097256857, "episode/intrinsic_return": 0.0}
{"step": 654048, "time": 20009.399626016617, "episode/length": 159.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 654192, "time": 20013.749511003494, "episode/length": 146.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9727891156462585, "episode/intrinsic_return": 0.0}
{"step": 654272, "time": 20016.54578781128, "episode/length": 246.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.97165991902834, "episode/intrinsic_return": 0.0}
{"step": 654912, "time": 20033.58753848076, "episode/length": 176.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 655032, "time": 20037.23946928978, "episode/length": 122.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.991869918699187, "episode/intrinsic_return": 0.0}
{"step": 655144, "time": 20040.90772175789, "episode/length": 145.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9726027397260274, "episode/intrinsic_return": 0.0}
{"step": 655456, "time": 20049.747441530228, "episode/length": 157.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9620253164556962, "episode/intrinsic_return": 0.0}
{"step": 655480, "time": 20051.005448818207, "episode/length": 278.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.996415770609319, "episode/intrinsic_return": 0.0}
{"step": 655680, "time": 20056.915798664093, "episode/length": 428.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9906759906759907, "episode/intrinsic_return": 0.0}
{"step": 656904, "time": 20088.206678152084, "episode/length": 426.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9976580796252927, "episode/intrinsic_return": 0.0}
{"step": 656912, "time": 20089.427733659744, "episode/length": 249.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.976, "episode/intrinsic_return": 0.0}
{"step": 657000, "time": 20092.20934987068, "episode/length": 340.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9941348973607038, "episode/intrinsic_return": 0.0}
{"step": 657432, "time": 20104.14172768593, "episode/length": 299.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.99, "episode/intrinsic_return": 0.0}
{"step": 657448, "time": 20105.37047982216, "episode/length": 67.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9852941176470589, "episode/intrinsic_return": 0.0}
{"step": 657672, "time": 20111.693189382553, "episode/length": 276.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9747292418772563, "episode/intrinsic_return": 0.0}
{"step": 658112, "time": 20123.72064805031, "episode/length": 138.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9640287769784173, "episode/intrinsic_return": 0.0}
{"step": 658168, "time": 20125.810601711273, "episode/length": 335.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9880952380952381, "episode/intrinsic_return": 0.0}
{"step": 658304, "time": 20130.106487751007, "episode/length": 106.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9906542056074766, "episode/intrinsic_return": 0.0}
{"step": 658464, "time": 20134.971559524536, "episode/length": 414.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9783132530120482, "episode/intrinsic_return": 0.0}
{"step": 658616, "time": 20139.354390859604, "episode/length": 212.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 658857, "time": 20147.142194509506, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.109142430020735, "train/action_min": 0.0, "train/action_std": 3.0040569791296647, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0348007224094105, "train/actor_opt_grad_steps": 40030.0, "train/actor_opt_loss": -5.735944054455836, "train/adv_mag": 0.48442604403360195, "train/adv_max": 0.4511373914531057, "train/adv_mean": 0.003238573638697197, "train/adv_min": -0.37866019962523223, "train/adv_std": 0.05410002339719596, "train/cont_avg": 0.9949274289099526, "train/cont_loss_mean": 0.00015551725316983786, "train/cont_loss_std": 0.004622561943905145, "train/cont_neg_acc": 0.9905820111433665, "train/cont_neg_loss": 0.0168688671141137, "train/cont_pos_acc": 0.9999767231150261, "train/cont_pos_loss": 7.705270283249683e-05, "train/cont_pred": 0.9949347628236382, "train/cont_rate": 0.9949274289099526, "train/dyn_loss_mean": 13.687128722385207, "train/dyn_loss_std": 9.275795733194215, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9418425076945698, "train/extr_critic_critic_opt_grad_steps": 40030.0, "train/extr_critic_critic_opt_loss": 16358.055127184538, "train/extr_critic_mag": 7.392879411507557, "train/extr_critic_max": 7.392879411507557, "train/extr_critic_mean": 1.9735068839873182, "train/extr_critic_min": -0.29608606557710476, "train/extr_critic_std": 1.798836314847684, "train/extr_return_normed_mag": 1.5197384447848061, "train/extr_return_normed_max": 1.5197384447848061, "train/extr_return_normed_mean": 0.36125910268010686, "train/extr_return_normed_min": -0.0970370609895878, "train/extr_return_normed_std": 0.32470735575633025, "train/extr_return_rate": 0.7161005126639, "train/extr_return_raw_mag": 8.52623104032182, "train/extr_return_raw_max": 8.52623104032182, "train/extr_return_raw_mean": 1.9916905548900226, "train/extr_return_raw_min": -0.5941562220383595, "train/extr_return_raw_std": 1.8328713794455145, "train/extr_reward_mag": 1.0185408761716002, "train/extr_reward_max": 1.0185408761716002, "train/extr_reward_mean": 0.03454283138481079, "train/extr_reward_min": -0.36824334119733476, "train/extr_reward_std": 0.17395772816728078, "train/image_loss_mean": 7.240693589522375, "train/image_loss_std": 12.094791349076546, "train/model_loss_mean": 15.507057275817292, "train/model_loss_std": 15.929398798829572, "train/model_opt_grad_norm": 56.876103794405246, "train/model_opt_grad_steps": 39993.91469194313, "train/model_opt_loss": 15145.114523937353, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 974.526066350711, "train/policy_entropy_mag": 2.5104373190640272, "train/policy_entropy_max": 2.5104373190640272, "train/policy_entropy_mean": 0.5490392217703906, "train/policy_entropy_min": 0.07937502444355408, "train/policy_entropy_std": 0.6449216554797657, "train/policy_logprob_mag": 7.438383638011336, "train/policy_logprob_max": -0.009455658124662689, "train/policy_logprob_mean": -0.5490738024926298, "train/policy_logprob_min": -7.438383638011336, "train/policy_logprob_std": 1.1002891377250166, "train/policy_randomness_mag": 0.8860742059929111, "train/policy_randomness_max": 0.8860742059929111, "train/policy_randomness_mean": 0.1937867508256605, "train/policy_randomness_min": 0.028015900350294973, "train/policy_randomness_std": 0.22762904446836896, "train/post_ent_mag": 59.12080679798578, "train/post_ent_max": 59.12080679798578, "train/post_ent_mean": 42.087588721542, "train/post_ent_min": 20.803405273582133, "train/post_ent_std": 7.425864565428964, "train/prior_ent_mag": 68.40575665659249, "train/prior_ent_max": 68.40575665659249, "train/prior_ent_mean": 55.85057848889681, "train/prior_ent_min": 42.222869836888606, "train/prior_ent_std": 4.427977864776177, "train/rep_loss_mean": 13.687128722385207, "train/rep_loss_std": 9.275795733194215, "train/reward_avg": 0.02611309595591437, "train/reward_loss_mean": 0.053930993010929976, "train/reward_loss_std": 0.25000186151520337, "train/reward_max_data": 1.010900476532525, "train/reward_max_pred": 1.0071477986060047, "train/reward_neg_acc": 0.9935719529034402, "train/reward_neg_loss": 0.02838362165907689, "train/reward_pos_acc": 0.9626576688617327, "train/reward_pos_loss": 0.8653344048707972, "train/reward_pred": 0.02531912740567143, "train/reward_rate": 0.030657582938388626, "train_stats/sum_log_reward": 7.975862234214256, "train_stats/max_log_achievement_collect_coal": 0.5310344827586206, "train_stats/max_log_achievement_collect_drink": 4.931034482758621, "train_stats/max_log_achievement_collect_sapling": 1.2482758620689656, "train_stats/max_log_achievement_collect_stone": 12.4, "train_stats/max_log_achievement_collect_wood": 9.917241379310346, "train_stats/max_log_achievement_defeat_skeleton": 0.027586206896551724, "train_stats/max_log_achievement_defeat_zombie": 0.2, "train_stats/max_log_achievement_eat_cow": 0.034482758620689655, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.013793103448275862, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 2.5586206896551724, "train_stats/max_log_achievement_make_wood_sword": 0.006896551724137931, "train_stats/max_log_achievement_place_furnace": 0.06206896551724138, "train_stats/max_log_achievement_place_plant": 1.186206896551724, "train_stats/max_log_achievement_place_stone": 9.151724137931035, "train_stats/max_log_achievement_place_table": 2.7586206896551726, "train_stats/max_log_achievement_wake_up": 1.6689655172413793, "train_stats/mean_log_entropy": 0.6067595165351342, "eval_stats/sum_log_reward": 8.141666859388351, "eval_stats/max_log_achievement_collect_coal": 1.0833333333333333, "eval_stats/max_log_achievement_collect_drink": 2.1666666666666665, "eval_stats/max_log_achievement_collect_sapling": 1.2916666666666667, "eval_stats/max_log_achievement_collect_stone": 11.916666666666666, "eval_stats/max_log_achievement_collect_wood": 8.833333333333334, "eval_stats/max_log_achievement_defeat_skeleton": 0.041666666666666664, "eval_stats/max_log_achievement_defeat_zombie": 0.25, "eval_stats/max_log_achievement_eat_cow": 0.041666666666666664, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.9166666666666667, "eval_stats/max_log_achievement_make_wood_sword": 0.041666666666666664, "eval_stats/max_log_achievement_place_furnace": 0.16666666666666666, "eval_stats/max_log_achievement_place_plant": 1.2916666666666667, "eval_stats/max_log_achievement_place_stone": 8.25, "eval_stats/max_log_achievement_place_table": 2.4166666666666665, "eval_stats/max_log_achievement_wake_up": 1.3333333333333333, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 5.885518703507842e-07, "report/cont_loss_std": 6.031901648384519e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 2.5453429771005176e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 4.665456287966663e-07, "report/cont_pred": 0.9951169490814209, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 12.642444610595703, "report/dyn_loss_std": 8.675204277038574, "report/image_loss_mean": 6.558627128601074, "report/image_loss_std": 10.936287879943848, "report/model_loss_mean": 14.21750259399414, "report/model_loss_std": 14.641510963439941, "report/post_ent_mag": 60.500431060791016, "report/post_ent_max": 60.500431060791016, "report/post_ent_mean": 43.561668395996094, "report/post_ent_min": 21.66549301147461, "report/post_ent_std": 7.395974159240723, "report/prior_ent_mag": 68.10997009277344, "report/prior_ent_max": 68.10997009277344, "report/prior_ent_mean": 56.29814147949219, "report/prior_ent_min": 40.225460052490234, "report/prior_ent_std": 4.587533950805664, "report/rep_loss_mean": 12.642444610595703, "report/rep_loss_std": 8.675204277038574, "report/reward_avg": 0.02919922024011612, "report/reward_loss_mean": 0.07340862601995468, "report/reward_loss_std": 0.3057560622692108, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0058963298797607, "report/reward_neg_acc": 0.9979757070541382, "report/reward_neg_loss": 0.040202561765909195, "report/reward_pos_acc": 0.944444477558136, "report/reward_pos_loss": 0.98473060131073, "report/reward_pred": 0.02469400130212307, "report/reward_rate": 0.03515625, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 3.404898052394856e-07, "eval/cont_loss_std": 8.101898856693879e-06, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 9.135658910963684e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 7.305759908149412e-08, "eval/cont_pred": 0.9970705509185791, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 16.417098999023438, "eval/dyn_loss_std": 10.769002914428711, "eval/image_loss_mean": 11.01472282409668, "eval/image_loss_std": 14.879619598388672, "eval/model_loss_mean": 20.98196792602539, "eval/model_loss_std": 19.335731506347656, "eval/post_ent_mag": 55.72887420654297, "eval/post_ent_max": 55.72887420654297, "eval/post_ent_mean": 40.947715759277344, "eval/post_ent_min": 19.842384338378906, "eval/post_ent_std": 7.31683349609375, "eval/prior_ent_mag": 67.92372131347656, "eval/prior_ent_max": 67.92372131347656, "eval/prior_ent_mean": 55.4024658203125, "eval/prior_ent_min": 42.82707214355469, "eval/prior_ent_std": 3.903320550918579, "eval/rep_loss_mean": 16.417098999023438, "eval/rep_loss_std": 10.769002914428711, "eval/reward_avg": 0.04287109524011612, "eval/reward_loss_mean": 0.11698327958583832, "eval/reward_loss_std": 0.7754173874855042, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.004810094833374, "eval/reward_neg_acc": 0.9938650131225586, "eval/reward_neg_loss": 0.022569969296455383, "eval/reward_pos_acc": 0.760869562625885, "eval/reward_pos_loss": 2.1242926120758057, "eval/reward_pred": 0.0350995734333992, "eval/reward_rate": 0.044921875, "replay/size": 658353.0, "replay/inserts": 33696.0, "replay/samples": 33696.0, "replay/insert_wait_avg": 1.2154988979908362e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 5.721451550127774e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 7296.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2318946813282213e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.003545761108398e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0565762519836, "timer/env.step_count": 4212.0, "timer/env.step_total": 132.57897925376892, "timer/env.step_frac": 0.1325714788563753, "timer/env.step_avg": 0.03147649080098977, "timer/env.step_min": 0.0022597312927246094, "timer/env.step_max": 0.9144115447998047, "timer/replay._sample_count": 33696.0, "timer/replay._sample_total": 2983.184863090515, "timer/replay._sample_frac": 2.9830160952202407, "timer/replay._sample_avg": 0.08853231431299012, "timer/replay._sample_min": 0.0003693103790283203, "timer/replay._sample_max": 0.11511731147766113, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5124.0, "timer/agent.policy_total": 52.59840226173401, "timer/agent.policy_frac": 0.052595426609624955, "timer/agent.policy_avg": 0.010265105827816942, "timer/agent.policy_min": 0.007407188415527344, "timer/agent.policy_max": 0.04922199249267578, "timer/dataset_train_count": 2106.0, "timer/dataset_train_total": 0.17187905311584473, "timer/dataset_train_frac": 0.0001718693293933567, "timer/dataset_train_avg": 8.161398533515894e-05, "timer/dataset_train_min": 7.081031799316406e-05, "timer/dataset_train_max": 0.00018596649169921875, "timer/agent.train_count": 2106.0, "timer/agent.train_total": 781.3041825294495, "timer/agent.train_frac": 0.7812599817678563, "timer/agent.train_avg": 0.3709896403273739, "timer/agent.train_min": 0.3527531623840332, "timer/agent.train_max": 0.5913655757904053, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4209263324737549, "timer/agent.report_frac": 0.0004209025193867575, "timer/agent.report_avg": 0.21046316623687744, "timer/agent.report_min": 0.2104196548461914, "timer/agent.report_max": 0.21050667762756348, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.409385681152344e-05, "timer/dataset_eval_frac": 3.409192801801328e-08, "timer/dataset_eval_avg": 3.409385681152344e-05, "timer/dataset_eval_min": 3.409385681152344e-05, "timer/dataset_eval_max": 3.409385681152344e-05, "fps": 33.69349600118362}
{"step": 659064, "time": 20152.02561187744, "episode/length": 422.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 659320, "time": 20159.38096189499, "episode/length": 205.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 659536, "time": 20165.767853736877, "episode/length": 262.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9961977186311787, "episode/intrinsic_return": 0.0}
{"step": 660080, "time": 20180.331594467163, "episode/length": 238.0, "episode/score": 9.10000005364418, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.0}
{"step": 660088, "time": 20183.317484378815, "eval_episode/length": 57.0, "eval_episode/score": 3.0999999716877937, "eval_episode/reward_rate": 0.9827586206896551}
{"step": 660088, "time": 20184.727907657623, "eval_episode/length": 87.0, "eval_episode/score": 7.100000016391277, "eval_episode/reward_rate": 0.9545454545454546}
{"step": 660088, "time": 20186.058397054672, "eval_episode/length": 117.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9576271186440678}
{"step": 660088, "time": 20187.74544262886, "eval_episode/length": 160.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.968944099378882}
{"step": 660088, "time": 20188.99542760849, "eval_episode/length": 185.0, "eval_episode/score": 7.100000016391277, "eval_episode/reward_rate": 0.978494623655914}
{"step": 660088, "time": 20189.96609544754, "eval_episode/length": 190.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9738219895287958}
{"step": 660088, "time": 20192.439550876617, "eval_episode/length": 214.0, "eval_episode/score": 9.099999979138374, "eval_episode/reward_rate": 0.9953488372093023}
{"step": 660088, "time": 20193.41832971573, "eval_episode/length": 277.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9856115107913669}
{"step": 660136, "time": 20194.884385347366, "episode/length": 208.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 660928, "time": 20215.84217619896, "episode/length": 173.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 661144, "time": 20222.101905107498, "episode/length": 315.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9778481012658228, "episode/intrinsic_return": 0.0}
{"step": 661520, "time": 20232.47975039482, "episode/length": 425.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 661536, "time": 20233.713212013245, "episode/length": 174.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 661600, "time": 20236.236013412476, "episode/length": 316.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9873817034700315, "episode/intrinsic_return": 0.0}
{"step": 661624, "time": 20237.51284646988, "episode/length": 192.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 661992, "time": 20247.482152700424, "episode/length": 105.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9433962264150944, "episode/intrinsic_return": 0.0}
{"step": 662304, "time": 20256.277704954147, "episode/length": 171.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 662760, "time": 20268.065363168716, "episode/length": 429.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9790697674418605, "episode/intrinsic_return": 0.0}
{"step": 663200, "time": 20279.877599477768, "episode/length": 207.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 663248, "time": 20282.035343170166, "episode/length": 617.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9854368932038835, "episode/intrinsic_return": 0.0}
{"step": 663440, "time": 20287.59623003006, "episode/length": 229.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9695652173913043, "episode/intrinsic_return": 0.0}
{"step": 663856, "time": 20298.71327805519, "episode/length": 278.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.996415770609319, "episode/intrinsic_return": 0.0}
{"step": 663936, "time": 20301.54084134102, "episode/length": 242.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9958847736625515, "episode/intrinsic_return": 0.0}
{"step": 664736, "time": 20322.677720069885, "episode/length": 303.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9967105263157895, "episode/intrinsic_return": 0.0}
{"step": 664904, "time": 20327.47327208519, "episode/length": 422.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 664952, "time": 20329.503848791122, "episode/length": 212.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.971830985915493, "episode/intrinsic_return": 0.0}
{"step": 665328, "time": 20340.074536323547, "episode/length": 320.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9906542056074766, "episode/intrinsic_return": 0.0}
{"step": 666096, "time": 20360.084481954575, "episode/length": 361.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 666416, "time": 20368.97727036476, "episode/length": 319.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.984375, "episode/intrinsic_return": 0.0}
{"step": 666472, "time": 20371.07710170746, "episode/length": 189.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 666504, "time": 20372.729383945465, "episode/length": 320.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9937694704049844, "episode/intrinsic_return": 0.0}
{"step": 666520, "time": 20374.013887643814, "episode/length": 222.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 666520, "time": 20374.05811190605, "episode/length": 201.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 666816, "time": 20382.395604610443, "episode/length": 421.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9928909952606635, "episode/intrinsic_return": 0.0}
{"step": 667248, "time": 20393.993913412094, "episode/length": 53.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 667600, "time": 20403.606407642365, "episode/length": 283.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9964788732394366, "episode/intrinsic_return": 0.0}
{"step": 667960, "time": 20413.537526845932, "episode/length": 181.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 668152, "time": 20419.117942094803, "episode/length": 203.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 668248, "time": 20422.36394047737, "episode/length": 215.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 668304, "time": 20424.80016231537, "episode/length": 275.0, "episode/score": 9.100000031292439, "episode/reward_rate": 0.9963768115942029, "episode/intrinsic_return": 0.0}
{"step": 669104, "time": 20445.63023018837, "episode/length": 187.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 669176, "time": 20448.02228450775, "episode/length": 337.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9881656804733728, "episode/intrinsic_return": 0.0}
{"step": 669536, "time": 20458.06297850609, "episode/length": 389.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 669600, "time": 20460.544835567474, "episode/length": 161.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 670072, "time": 20474.836288928986, "eval_episode/length": 48.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9795918367346939}
{"step": 670072, "time": 20476.65890645981, "eval_episode/length": 106.0, "eval_episode/score": 9.100000023841858, "eval_episode/reward_rate": 0.9906542056074766}
{"step": 670072, "time": 20478.113556861877, "eval_episode/length": 143.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9930555555555556}
{"step": 670072, "time": 20479.659517765045, "eval_episode/length": 178.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9664804469273743}
{"step": 670072, "time": 20480.71988272667, "eval_episode/length": 142.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.972027972027972}
{"step": 670072, "time": 20482.677875995636, "eval_episode/length": 248.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9959839357429718}
{"step": 670072, "time": 20484.008230686188, "eval_episode/length": 167.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9642857142857143}
{"step": 670072, "time": 20485.155484437943, "eval_episode/length": 100.0, "eval_episode/score": 6.100000023841858, "eval_episode/reward_rate": 0.9900990099009901}
{"step": 670304, "time": 20491.17818713188, "episode/length": 87.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9886363636363636, "episode/intrinsic_return": 0.0}
{"step": 670528, "time": 20497.729625940323, "episode/length": 320.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9906542056074766, "episode/intrinsic_return": 0.0}
{"step": 670568, "time": 20499.356772899628, "episode/length": 182.0, "episode/score": 9.1000000461936, "episode/reward_rate": 0.9617486338797814, "episode/intrinsic_return": 0.0}
{"step": 670616, "time": 20501.37001466751, "episode/length": 179.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 670624, "time": 20502.55223441124, "episode/length": 135.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9558823529411765, "episode/intrinsic_return": 0.0}
{"step": 670680, "time": 20504.596980571747, "episode/length": 428.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9790209790209791, "episode/intrinsic_return": 0.0}
{"step": 670856, "time": 20509.885384321213, "episode/length": 325.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9877300613496932, "episode/intrinsic_return": 0.0}
{"step": 671528, "time": 20527.451253652573, "episode/length": 421.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9786729857819905, "episode/intrinsic_return": 0.0}
{"step": 671904, "time": 20537.789999723434, "episode/length": 166.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 672144, "time": 20544.700285196304, "episode/length": 201.0, "episode/score": 10.100000031292439, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 672336, "time": 20550.282366275787, "episode/length": 213.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 672400, "time": 20552.74220442772, "episode/length": 192.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 672424, "time": 20553.98404598236, "episode/length": 217.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 673376, "time": 20578.47247338295, "episode/length": 183.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 673472, "time": 20581.736461400986, "episode/length": 141.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.971830985915493, "episode/intrinsic_return": 0.0}
{"step": 673520, "time": 20583.70655322075, "episode/length": 171.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 673640, "time": 20587.48414492607, "episode/length": 416.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9952038369304557, "episode/intrinsic_return": 0.0}
{"step": 673744, "time": 20591.243596553802, "episode/length": 167.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9583333333333334, "episode/intrinsic_return": 0.0}
{"step": 674000, "time": 20598.386838436127, "episode/length": 196.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 674200, "time": 20604.02510881424, "episode/length": 447.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9888392857142857, "episode/intrinsic_return": 0.0}
{"step": 674376, "time": 20609.343907356262, "episode/length": 46.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 674520, "time": 20613.866701364517, "episode/length": 373.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9866310160427807, "episode/intrinsic_return": 0.0}
{"step": 674736, "time": 20620.331027030945, "episode/length": 123.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9596774193548387, "episode/intrinsic_return": 0.0}
{"step": 674832, "time": 20623.572338819504, "episode/length": 148.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 675104, "time": 20631.23597049713, "episode/length": 197.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 675528, "time": 20642.315942525864, "episode/length": 125.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9682539682539683, "episode/intrinsic_return": 0.0}
{"step": 675648, "time": 20646.24550652504, "episode/length": 271.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9852941176470589, "episode/intrinsic_return": 0.0}
{"step": 675952, "time": 20654.746780633926, "episode/length": 196.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 676464, "time": 20668.538902282715, "episode/length": 215.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 676512, "time": 20670.58741235733, "episode/length": 209.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 676808, "time": 20678.566654920578, "episode/length": 325.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9815950920245399, "episode/intrinsic_return": 0.0}
{"step": 676888, "time": 20681.500375509262, "episode/length": 438.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9977220956719818, "episode/intrinsic_return": 0.0}
{"step": 677152, "time": 20689.081397294998, "episode/length": 187.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 677704, "time": 20705.043472766876, "episode/length": 324.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9969230769230769, "episode/intrinsic_return": 0.0}
{"step": 677816, "time": 20708.691764593124, "episode/length": 285.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9895104895104895, "episode/intrinsic_return": 0.0}
{"step": 677936, "time": 20712.787692308426, "episode/length": 183.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 678032, "time": 20716.07953453064, "episode/length": 40.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 678312, "time": 20723.707067489624, "episode/length": 187.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9627659574468085, "episode/intrinsic_return": 0.0}
{"step": 678328, "time": 20724.935045480728, "episode/length": 226.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.973568281938326, "episode/intrinsic_return": 0.0}
{"step": 678336, "time": 20726.15576171875, "episode/length": 297.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9966442953020134, "episode/intrinsic_return": 0.0}
{"step": 678776, "time": 20737.91408085823, "episode/length": 55.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 678776, "time": 20737.95865559578, "episode/length": 235.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9745762711864406, "episode/intrinsic_return": 0.0}
{"step": 679272, "time": 20751.572525262833, "episode/length": 61.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.0}
{"step": 679336, "time": 20754.127359628677, "episode/length": 174.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 679400, "time": 20756.545206308365, "episode/length": 170.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 679424, "time": 20758.15865778923, "episode/length": 283.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9964788732394366, "episode/intrinsic_return": 0.0}
{"step": 679496, "time": 20760.601469039917, "episode/length": 209.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 680056, "time": 20775.362397670746, "episode/length": 217.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 680056, "time": 20777.122931718826, "eval_episode/length": 54.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9818181818181818}
{"step": 680056, "time": 20779.9438996315, "eval_episode/length": 164.0, "eval_episode/score": 8.099999971687794, "eval_episode/reward_rate": 0.9939393939393939}
{"step": 680056, "time": 20781.252819538116, "eval_episode/length": 191.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9739583333333334}
{"step": 680056, "time": 20782.148183107376, "eval_episode/length": 192.0, "eval_episode/score": 8.099999971687794, "eval_episode/reward_rate": 0.9948186528497409}
{"step": 680056, "time": 20783.349514961243, "eval_episode/length": 205.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9757281553398058}
{"step": 680056, "time": 20784.23019170761, "eval_episode/length": 206.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9758454106280193}
{"step": 680056, "time": 20785.347212076187, "eval_episode/length": 214.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9767441860465116}
{"step": 680056, "time": 20786.458736658096, "eval_episode/length": 231.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9741379310344828}
{"step": 680424, "time": 20796.639201164246, "episode/length": 205.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9805825242718447, "episode/intrinsic_return": 0.0}
{"step": 680688, "time": 20804.355812311172, "episode/length": 176.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9661016949152542, "episode/intrinsic_return": 0.0}
{"step": 680936, "time": 20811.197906017303, "episode/length": 179.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 681304, "time": 20821.332280874252, "episode/length": 155.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 681736, "time": 20833.01344227791, "episode/length": 163.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 681824, "time": 20836.254553318024, "episode/length": 302.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9867986798679867, "episode/intrinsic_return": 0.0}
{"step": 681880, "time": 20838.322521209717, "episode/length": 306.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9837133550488599, "episode/intrinsic_return": 0.0}
{"step": 681952, "time": 20841.144250392914, "episode/length": 451.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9800884955752213, "episode/intrinsic_return": 0.0}
{"step": 682328, "time": 20851.238117933273, "episode/length": 373.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9893048128342246, "episode/intrinsic_return": 0.0}
{"step": 682752, "time": 20862.87787246704, "episode/length": 180.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 682960, "time": 20869.016949653625, "episode/length": 283.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9753521126760564, "episode/intrinsic_return": 0.0}
{"step": 683328, "time": 20879.24019885063, "episode/length": 180.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 683416, "time": 20882.063356637955, "episode/length": 198.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 683512, "time": 20885.266281843185, "episode/length": 194.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 683600, "time": 20888.46148777008, "episode/length": 332.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.996996996996997, "episode/intrinsic_return": 0.0}
{"step": 683776, "time": 20893.87861084938, "episode/length": 44.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 683976, "time": 20899.593457221985, "episode/length": 205.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9805825242718447, "episode/intrinsic_return": 0.0}
{"step": 684304, "time": 20908.81753897667, "episode/length": 87.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9886363636363636, "episode/intrinsic_return": 0.0}
{"step": 684328, "time": 20910.127964496613, "episode/length": 170.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 684384, "time": 20912.522358179092, "episode/length": 203.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 684704, "time": 20921.22859764099, "episode/length": 49.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 685088, "time": 20931.823170900345, "episode/length": 418.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9904534606205251, "episode/intrinsic_return": 0.0}
{"step": 685392, "time": 20940.170607566833, "episode/length": 201.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9653465346534653, "episode/intrinsic_return": 0.0}
{"step": 685696, "time": 20948.575233221054, "episode/length": 170.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 685768, "time": 20951.03186893463, "episode/length": 281.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9964539007092199, "episode/intrinsic_return": 0.0}
{"step": 685808, "time": 20953.145651578903, "episode/length": 309.0, "episode/score": 9.099999964237213, "episode/reward_rate": 0.9903225806451613, "episode/intrinsic_return": 0.0}
{"step": 685872, "time": 20955.659180879593, "episode/length": 236.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9789029535864979, "episode/intrinsic_return": 0.0}
{"step": 685960, "time": 20958.603574991226, "episode/length": 196.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 686400, "time": 20970.606516361237, "episode/length": 211.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 686824, "time": 20981.789564609528, "episode/length": 178.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 687040, "time": 20988.24221110344, "episode/length": 158.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 687080, "time": 20989.936720609665, "episode/length": 139.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.0}
{"step": 687280, "time": 20996.057858467102, "episode/length": 273.0, "episode/score": 9.100000016391277, "episode/reward_rate": 0.9817518248175182, "episode/intrinsic_return": 0.0}
{"step": 687416, "time": 21000.038607358932, "episode/length": 214.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 687632, "time": 21006.687371492386, "episode/length": 219.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 687728, "time": 21009.880659341812, "episode/length": 239.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 688224, "time": 21023.174293756485, "episode/length": 174.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9885714285714285, "episode/intrinsic_return": 0.0}
{"step": 688408, "time": 21028.437134981155, "episode/length": 165.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 688712, "time": 21036.8488342762, "episode/length": 60.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9180327868852459, "episode/intrinsic_return": 0.0}
{"step": 688888, "time": 21042.093900203705, "episode/length": 144.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 688968, "time": 21045.0525932312, "episode/length": 166.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 689032, "time": 21047.492979049683, "episode/length": 218.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 689040, "time": 21048.738952875137, "episode/length": 202.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9802955665024631, "episode/intrinsic_return": 0.0}
{"step": 689376, "time": 21058.00848507881, "episode/length": 371.0, "episode/score": 10.099999964237213, "episode/reward_rate": 0.9973118279569892, "episode/intrinsic_return": 0.0}
{"step": 689992, "time": 21073.88462638855, "episode/length": 159.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 690040, "time": 21079.185172080994, "eval_episode/length": 158.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9685534591194969}
{"step": 690040, "time": 21080.437392950058, "eval_episode/length": 183.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9728260869565217}
{"step": 690040, "time": 21082.542812108994, "eval_episode/length": 254.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9803921568627451}
{"step": 690040, "time": 21083.55670261383, "eval_episode/length": 106.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9626168224299065}
{"step": 690040, "time": 21084.55790090561, "eval_episode/length": 274.0, "eval_episode/score": 9.100000023841858, "eval_episode/reward_rate": 0.9963636363636363}
{"step": 690040, "time": 21084.602814912796, "eval_episode/length": 274.0, "eval_episode/score": 7.0999999940395355, "eval_episode/reward_rate": 0.9963636363636363}
{"step": 690040, "time": 21086.142528772354, "eval_episode/length": 311.0, "eval_episode/score": 7.099999979138374, "eval_episode/reward_rate": 0.9935897435897436}
{"step": 690040, "time": 21087.783044576645, "eval_episode/length": 354.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9943661971830986}
{"step": 690272, "time": 21093.936674833298, "episode/length": 154.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 690440, "time": 21098.84332036972, "episode/length": 193.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 690648, "time": 21104.81564593315, "episode/length": 209.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9809523809523809, "episode/intrinsic_return": 0.0}
{"step": 690680, "time": 21106.51713347435, "episode/length": 454.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9802197802197802, "episode/intrinsic_return": 0.0}
{"step": 690704, "time": 21108.112369775772, "episode/length": 286.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9721254355400697, "episode/intrinsic_return": 0.0}
{"step": 691640, "time": 21132.25010228157, "episode/length": 324.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9969230769230769, "episode/intrinsic_return": 0.0}
{"step": 692185, "time": 21147.516669273376, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.267505939190205, "train/action_min": 0.0, "train/action_std": 3.1112536306564627, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03509545321755398, "train/actor_opt_grad_steps": 42125.0, "train/actor_opt_loss": -5.919307694555475, "train/adv_mag": 0.4776903357929908, "train/adv_max": 0.44212335254997015, "train/adv_mean": 0.002781682659553133, "train/adv_min": -0.38012717191416484, "train/adv_std": 0.053584103777001686, "train/cont_avg": 0.9951594426081731, "train/cont_loss_mean": 0.00016443387495084056, "train/cont_loss_std": 0.004957142804503434, "train/cont_neg_acc": 0.9950483092939221, "train/cont_neg_loss": 0.02273454289757241, "train/cont_pos_acc": 0.9999811385686581, "train/cont_pos_loss": 5.786408562968859e-05, "train/cont_pred": 0.995165762419884, "train/cont_rate": 0.9951594426081731, "train/dyn_loss_mean": 13.596140219615055, "train/dyn_loss_std": 9.348561254831461, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9488582046559224, "train/extr_critic_critic_opt_grad_steps": 42125.0, "train/extr_critic_critic_opt_loss": 16262.640211838941, "train/extr_critic_mag": 7.650708423211024, "train/extr_critic_max": 7.650708423211024, "train/extr_critic_mean": 2.037793869582506, "train/extr_critic_min": -0.28955526993824887, "train/extr_critic_std": 1.8570364352602224, "train/extr_return_normed_mag": 1.5087573430859125, "train/extr_return_normed_max": 1.5087573430859125, "train/extr_return_normed_mean": 0.3594738349605065, "train/extr_return_normed_min": -0.09245470782312062, "train/extr_return_normed_std": 0.325144476758746, "train/extr_return_rate": 0.7191297065180081, "train/extr_return_raw_mag": 8.716164806714424, "train/extr_return_raw_max": 8.716164806714424, "train/extr_return_raw_mean": 2.0538933351635933, "train/extr_return_raw_min": -0.5662057790905237, "train/extr_return_raw_std": 1.8850475228749788, "train/extr_reward_mag": 1.0207636872163186, "train/extr_reward_max": 1.0207636872163186, "train/extr_reward_mean": 0.036917663242023155, "train/extr_reward_min": -0.36722111243468064, "train/extr_reward_std": 0.17919802812572855, "train/image_loss_mean": 7.16201063990593, "train/image_loss_std": 12.511233017994808, "train/model_loss_mean": 15.373133099996126, "train/model_loss_std": 16.364981559606697, "train/model_opt_grad_norm": 57.93346496250319, "train/model_opt_grad_steps": 42087.307692307695, "train/model_opt_loss": 19667.014667217547, "train/model_opt_model_opt_grad_overflow": 0.004807692307692308, "train/model_opt_model_opt_grad_scale": 1274.0384615384614, "train/policy_entropy_mag": 2.511760942064799, "train/policy_entropy_max": 2.511760942064799, "train/policy_entropy_mean": 0.562816431459326, "train/policy_entropy_min": 0.07937502201933128, "train/policy_entropy_std": 0.659727924145185, "train/policy_logprob_mag": 7.438383670953604, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5628118244214699, "train/policy_logprob_min": -7.438383670953604, "train/policy_logprob_std": 1.1072859156590242, "train/policy_randomness_mag": 0.8865413852035999, "train/policy_randomness_max": 0.8865413852035999, "train/policy_randomness_mean": 0.19864950200112966, "train/policy_randomness_min": 0.028015899445073537, "train/policy_randomness_std": 0.2328550058345382, "train/post_ent_mag": 59.05804307644184, "train/post_ent_max": 59.05804307644184, "train/post_ent_mean": 42.236217938936676, "train/post_ent_min": 20.82038106368138, "train/post_ent_std": 7.414066743392211, "train/prior_ent_mag": 68.70405809695905, "train/prior_ent_max": 68.70405809695905, "train/prior_ent_mean": 55.8951494877155, "train/prior_ent_min": 42.21956669367277, "train/prior_ent_std": 4.469287831049699, "train/rep_loss_mean": 13.596140219615055, "train/rep_loss_std": 9.348561254831461, "train/reward_avg": 0.02664654052708871, "train/reward_loss_mean": 0.053273995174095035, "train/reward_loss_std": 0.23956438669791588, "train/reward_max_data": 1.0125000029802322, "train/reward_max_pred": 1.006512426986144, "train/reward_neg_acc": 0.9933962713067348, "train/reward_neg_loss": 0.027970214826592173, "train/reward_pos_acc": 0.9670719879751022, "train/reward_pos_loss": 0.845342697432408, "train/reward_pred": 0.025858293811324984, "train/reward_rate": 0.030987079326923076, "train_stats/sum_log_reward": 8.330216001263626, "train_stats/max_log_achievement_collect_coal": 0.7266187050359713, "train_stats/max_log_achievement_collect_drink": 4.388489208633094, "train_stats/max_log_achievement_collect_sapling": 1.3525179856115108, "train_stats/max_log_achievement_collect_stone": 14.79136690647482, "train_stats/max_log_achievement_collect_wood": 9.273381294964029, "train_stats/max_log_achievement_defeat_skeleton": 0.07913669064748201, "train_stats/max_log_achievement_defeat_zombie": 0.35251798561151076, "train_stats/max_log_achievement_eat_cow": 0.050359712230215826, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 2.41726618705036, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_furnace": 0.1366906474820144, "train_stats/max_log_achievement_place_plant": 1.2446043165467626, "train_stats/max_log_achievement_place_stone": 11.151079136690647, "train_stats/max_log_achievement_place_table": 2.8992805755395685, "train_stats/max_log_achievement_wake_up": 1.7553956834532374, "train_stats/mean_log_entropy": 0.6001959855822351, "eval_stats/sum_log_reward": 7.81875017285347, "eval_stats/max_log_achievement_collect_coal": 0.8125, "eval_stats/max_log_achievement_collect_drink": 4.1875, "eval_stats/max_log_achievement_collect_sapling": 1.34375, "eval_stats/max_log_achievement_collect_stone": 11.46875, "eval_stats/max_log_achievement_collect_wood": 7.0625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.21875, "eval_stats/max_log_achievement_eat_cow": 0.03125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.65625, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.09375, "eval_stats/max_log_achievement_place_plant": 1.34375, "eval_stats/max_log_achievement_place_stone": 8.71875, "eval_stats/max_log_achievement_place_table": 2.125, "eval_stats/max_log_achievement_wake_up": 1.28125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 1.351110859104665e-05, "report/cont_loss_std": 0.00017636294069234282, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0003008786588907242, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.181738934974419e-05, "report/cont_pred": 0.9941307306289673, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 13.34496021270752, "report/dyn_loss_std": 9.431761741638184, "report/image_loss_mean": 6.417539596557617, "report/image_loss_std": 12.20362663269043, "report/model_loss_mean": 14.471083641052246, "report/model_loss_std": 16.288667678833008, "report/post_ent_mag": 59.2855224609375, "report/post_ent_max": 59.2855224609375, "report/post_ent_mean": 42.415496826171875, "report/post_ent_min": 21.833194732666016, "report/post_ent_std": 7.888341903686523, "report/prior_ent_mag": 68.75978088378906, "report/prior_ent_max": 68.75978088378906, "report/prior_ent_mean": 56.105865478515625, "report/prior_ent_min": 42.42083740234375, "report/prior_ent_std": 4.309698581695557, "report/rep_loss_mean": 13.34496021270752, "report/rep_loss_std": 9.431761741638184, "report/reward_avg": 0.02626953087747097, "report/reward_loss_mean": 0.046554215252399445, "report/reward_loss_std": 0.17844393849372864, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.014634132385254, "report/reward_neg_acc": 0.9939515590667725, "report/reward_neg_loss": 0.02353006787598133, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7603027820587158, "report/reward_pred": 0.02623007819056511, "report/reward_rate": 0.03125, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 9.244562534149736e-06, "eval/cont_loss_std": 0.0001448231632821262, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0018696216866374016, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 1.9489648366288748e-06, "eval/cont_pred": 0.9960991144180298, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 15.50771427154541, "eval/dyn_loss_std": 10.169577598571777, "eval/image_loss_mean": 10.213773727416992, "eval/image_loss_std": 12.914636611938477, "eval/model_loss_mean": 19.645414352416992, "eval/model_loss_std": 16.737354278564453, "eval/post_ent_mag": 58.80744934082031, "eval/post_ent_max": 58.80744934082031, "eval/post_ent_mean": 43.070892333984375, "eval/post_ent_min": 22.593307495117188, "eval/post_ent_std": 7.567148685455322, "eval/prior_ent_mag": 68.75978088378906, "eval/prior_ent_max": 68.75978088378906, "eval/prior_ent_mean": 56.893524169921875, "eval/prior_ent_min": 43.55479431152344, "eval/prior_ent_std": 4.448451995849609, "eval/rep_loss_mean": 15.50771427154541, "eval/rep_loss_std": 10.169577598571777, "eval/reward_avg": 0.0283203125, "eval/reward_loss_mean": 0.12700214982032776, "eval/reward_loss_std": 0.7374960780143738, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 1.0030012130737305, "eval/reward_neg_acc": 0.9868686199188232, "eval/reward_neg_loss": 0.06775408983230591, "eval/reward_pos_acc": 0.8235294222831726, "eval/reward_pos_loss": 1.8521660566329956, "eval/reward_pred": 0.02847832813858986, "eval/reward_rate": 0.033203125, "replay/size": 691681.0, "replay/inserts": 33328.0, "replay/samples": 33328.0, "replay/insert_wait_avg": 1.2355802497552441e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 5.781550391385375e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 9264.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.241866376939421e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.301568984985352e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3628649711609, "timer/env.step_count": 4166.0, "timer/env.step_total": 128.71189093589783, "timer/env.step_frac": 0.1286652028407796, "timer/env.step_avg": 0.030895797152159826, "timer/env.step_min": 0.002301454544067383, "timer/env.step_max": 0.9172744750976562, "timer/replay._sample_count": 33328.0, "timer/replay._sample_total": 2953.2446870803833, "timer/replay._sample_frac": 2.9521734467477674, "timer/replay._sample_avg": 0.08861151845536436, "timer/replay._sample_min": 0.0010187625885009766, "timer/replay._sample_max": 0.11536598205566406, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5324.0, "timer/agent.policy_total": 55.37787342071533, "timer/agent.policy_frac": 0.05535778601928791, "timer/agent.policy_avg": 0.01040155398585938, "timer/agent.policy_min": 0.00754237174987793, "timer/agent.policy_max": 0.04890918731689453, "timer/dataset_train_count": 2083.0, "timer/dataset_train_total": 0.17115545272827148, "timer/dataset_train_frac": 0.00017109336893788603, "timer/dataset_train_avg": 8.216776415183461e-05, "timer/dataset_train_min": 6.318092346191406e-05, "timer/dataset_train_max": 0.000240325927734375, "timer/agent.train_count": 2083.0, "timer/agent.train_total": 775.3648555278778, "timer/agent.train_frac": 0.775083604837961, "timer/agent.train_avg": 0.3722346882034939, "timer/agent.train_min": 0.3531661033630371, "timer/agent.train_max": 1.8161234855651855, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4204585552215576, "timer/agent.report_frac": 0.00042030604088215417, "timer/agent.report_avg": 0.2102292776107788, "timer/agent.report_min": 0.20939350128173828, "timer/agent.report_max": 0.21106505393981934, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.218650817871094e-05, "timer/dataset_eval_frac": 3.2174833058840935e-08, "timer/dataset_eval_avg": 3.218650817871094e-05, "timer/dataset_eval_min": 3.218650817871094e-05, "timer/dataset_eval_max": 3.218650817871094e-05, "fps": 33.31549722838644}
{"step": 692376, "time": 21152.127114534378, "episode/length": 211.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 692416, "time": 21154.156331062317, "episode/length": 379.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 692432, "time": 21155.390920877457, "episode/length": 222.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9730941704035875, "episode/intrinsic_return": 0.0}
{"step": 692672, "time": 21162.252254009247, "episode/length": 245.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9715447154471545, "episode/intrinsic_return": 0.0}
{"step": 692744, "time": 21164.672931671143, "episode/length": 343.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9912790697674418, "episode/intrinsic_return": 0.0}
{"step": 692760, "time": 21165.93674683571, "episode/length": 40.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 693320, "time": 21180.741951227188, "episode/length": 380.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9921259842519685, "episode/intrinsic_return": 0.0}
{"step": 693376, "time": 21183.331237077713, "episode/length": 216.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 693880, "time": 21196.766748428345, "episode/length": 187.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 693904, "time": 21198.44165277481, "episode/length": 185.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 694024, "time": 21202.119636535645, "episode/length": 447.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9799107142857143, "episode/intrinsic_return": 0.0}
{"step": 694184, "time": 21207.00634264946, "episode/length": 177.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 694664, "time": 21219.94964337349, "episode/length": 59.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 695176, "time": 21233.734728336334, "episode/length": 161.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 695216, "time": 21235.737363815308, "episode/length": 229.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 695416, "time": 21241.48752951622, "episode/length": 173.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9597701149425287, "episode/intrinsic_return": 0.0}
{"step": 696056, "time": 21258.38723540306, "episode/length": 413.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9927536231884058, "episode/intrinsic_return": 0.0}
{"step": 696216, "time": 21263.21071958542, "episode/length": 288.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9965397923875432, "episode/intrinsic_return": 0.0}
{"step": 696288, "time": 21266.049697875977, "episode/length": 451.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 696744, "time": 21278.01476955414, "episode/length": 427.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9789719626168224, "episode/intrinsic_return": 0.0}
{"step": 696808, "time": 21280.431859493256, "episode/length": 173.0, "episode/score": 6.100000016391277, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 697056, "time": 21287.592192411423, "episode/length": 229.0, "episode/score": 9.100000016391277, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 697496, "time": 21299.28198003769, "episode/length": 179.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 697576, "time": 21302.140281915665, "episode/length": 64.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9846153846153847, "episode/intrinsic_return": 0.0}
{"step": 697840, "time": 21309.67567873001, "episode/length": 396.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9949622166246851, "episode/intrinsic_return": 0.0}
{"step": 698088, "time": 21316.725203037262, "episode/length": 233.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 698352, "time": 21324.385912895203, "episode/length": 96.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9587628865979382, "episode/intrinsic_return": 0.0}
{"step": 698520, "time": 21329.333304405212, "episode/length": 213.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9719626168224299, "episode/intrinsic_return": 0.0}
{"step": 698616, "time": 21332.5632481575, "episode/length": 429.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9790697674418605, "episode/intrinsic_return": 0.0}
{"step": 698816, "time": 21338.527300834656, "episode/length": 258.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9961389961389961, "episode/intrinsic_return": 0.0}
{"step": 698952, "time": 21342.659241437912, "episode/length": 181.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 699088, "time": 21346.9678003788, "episode/length": 349.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 699848, "time": 21366.4721596241, "episode/length": 186.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 699904, "time": 21368.923449754715, "episode/length": 160.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 700024, "time": 21374.459574222565, "eval_episode/length": 53.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9814814814814815}
{"step": 700024, "time": 21375.419261932373, "eval_episode/length": 58.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9830508474576272}
{"step": 700024, "time": 21375.465269327164, "eval_episode/length": 58.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9830508474576272}
{"step": 700024, "time": 21377.926595449448, "eval_episode/length": 150.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9668874172185431}
{"step": 700024, "time": 21379.506459474564, "eval_episode/length": 189.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.968421052631579}
{"step": 700024, "time": 21380.618649721146, "eval_episode/length": 203.0, "eval_episode/score": 10.099999971687794, "eval_episode/reward_rate": 0.9950980392156863}
{"step": 700024, "time": 21382.362393140793, "eval_episode/length": 192.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9792746113989638}
{"step": 700024, "time": 21383.526418447495, "eval_episode/length": 262.0, "eval_episode/score": 11.100000038743019, "eval_episode/reward_rate": 0.9961977186311787}
{"step": 700048, "time": 21384.472452163696, "episode/length": 190.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 700712, "time": 21401.690623044968, "episode/length": 219.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 700984, "time": 21409.403886795044, "episode/length": 134.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 701184, "time": 21415.60440015793, "episode/length": 58.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 701224, "time": 21417.306480169296, "episode/length": 422.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9952718676122931, "episode/intrinsic_return": 0.0}
{"step": 701256, "time": 21419.001193523407, "episode/length": 395.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9974747474747475, "episode/intrinsic_return": 0.0}
{"step": 701520, "time": 21426.665667057037, "episode/length": 303.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9967105263157895, "episode/intrinsic_return": 0.0}
{"step": 701592, "time": 21429.141548395157, "episode/length": 217.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9724770642201835, "episode/intrinsic_return": 0.0}
{"step": 701776, "time": 21434.726001262665, "episode/length": 64.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9846153846153847, "episode/intrinsic_return": 0.0}
{"step": 701848, "time": 21437.326019525528, "episode/length": 224.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9822222222222222, "episode/intrinsic_return": 0.0}
{"step": 702216, "time": 21447.32110118866, "episode/length": 424.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9976470588235294, "episode/intrinsic_return": 0.0}
{"step": 702688, "time": 21460.206176042557, "episode/length": 212.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 703344, "time": 21477.637841701508, "episode/length": 186.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 703696, "time": 21487.33194422722, "episode/length": 262.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9847908745247148, "episode/intrinsic_return": 0.0}
{"step": 703752, "time": 21489.38990163803, "episode/length": 191.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 703928, "time": 21494.668981552124, "episode/length": 300.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9833887043189369, "episode/intrinsic_return": 0.0}
{"step": 704344, "time": 21505.89056634903, "episode/length": 389.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9846153846153847, "episode/intrinsic_return": 0.0}
{"step": 704488, "time": 21510.23071718216, "episode/length": 98.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9595959595959596, "episode/intrinsic_return": 0.0}
{"step": 704576, "time": 21513.485430002213, "episode/length": 349.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9857142857142858, "episode/intrinsic_return": 0.0}
{"step": 704640, "time": 21515.898136615753, "episode/length": 431.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9976851851851852, "episode/intrinsic_return": 0.0}
{"step": 704728, "time": 21518.72777557373, "episode/length": 254.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.996078431372549, "episode/intrinsic_return": 0.0}
{"step": 704896, "time": 21523.94205379486, "episode/length": 50.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 705512, "time": 21539.949707508087, "episode/length": 108.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9908256880733946, "episode/intrinsic_return": 0.0}
{"step": 705552, "time": 21542.106185674667, "episode/length": 224.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 706000, "time": 21554.057918548584, "episode/length": 158.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 706304, "time": 21562.5819504261, "episode/length": 215.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9675925925925926, "episode/intrinsic_return": 0.0}
{"step": 706464, "time": 21567.341559171677, "episode/length": 195.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 706768, "time": 21575.795415878296, "episode/length": 427.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9789719626168224, "episode/intrinsic_return": 0.0}
{"step": 707216, "time": 21587.995930194855, "episode/length": 212.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 707456, "time": 21594.81451511383, "episode/length": 388.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.987146529562982, "episode/intrinsic_return": 0.0}
{"step": 707504, "time": 21596.879381656647, "episode/length": 446.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9977628635346756, "episode/intrinsic_return": 0.0}
{"step": 707856, "time": 21606.488370656967, "episode/length": 173.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 708784, "time": 21630.613330841064, "episode/length": 251.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.996031746031746, "episode/intrinsic_return": 0.0}
{"step": 708848, "time": 21633.006862163544, "episode/length": 317.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 708968, "time": 21636.653427362442, "episode/length": 426.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9789227166276346, "episode/intrinsic_return": 0.0}
{"step": 709336, "time": 21646.682672023773, "episode/length": 234.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 709392, "time": 21649.089147090912, "episode/length": 423.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 709456, "time": 21651.429441452026, "episode/length": 243.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9795081967213115, "episode/intrinsic_return": 0.0}
{"step": 709560, "time": 21654.67524290085, "episode/length": 292.0, "episode/score": 10.1000000461936, "episode/reward_rate": 0.9829351535836177, "episode/intrinsic_return": 0.0}
{"step": 709888, "time": 21663.871742248535, "episode/length": 253.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9960629921259843, "episode/intrinsic_return": 0.0}
{"step": 710008, "time": 21669.236548662186, "eval_episode/length": 52.0, "eval_episode/score": 3.0999999940395355, "eval_episode/reward_rate": 0.9811320754716981}
{"step": 710008, "time": 21672.17720270157, "eval_episode/length": 174.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 710008, "time": 21673.84486079216, "eval_episode/length": 224.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9955555555555555}
{"step": 710008, "time": 21674.73022222519, "eval_episode/length": 225.0, "eval_episode/score": 7.0999999940395355, "eval_episode/reward_rate": 0.995575221238938}
{"step": 710008, "time": 21675.753715991974, "eval_episode/length": 234.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9702127659574468}
{"step": 710008, "time": 21677.157977342606, "eval_episode/length": 208.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9760765550239234}
{"step": 710008, "time": 21678.04495549202, "eval_episode/length": 264.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.969811320754717}
{"step": 710008, "time": 21679.954860448837, "eval_episode/length": 56.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9824561403508771}
{"step": 710352, "time": 21689.03537607193, "episode/length": 57.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 710600, "time": 21695.798125505447, "episode/length": 203.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9656862745098039, "episode/intrinsic_return": 0.0}
{"step": 710944, "time": 21705.51921772957, "episode/length": 172.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 711160, "time": 21711.596246004105, "episode/length": 296.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9966329966329966, "episode/intrinsic_return": 0.0}
{"step": 711272, "time": 21715.14261507988, "episode/length": 302.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9966996699669967, "episode/intrinsic_return": 0.0}
{"step": 711736, "time": 21727.676309347153, "episode/length": 292.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9795221843003413, "episode/intrinsic_return": 0.0}
{"step": 712272, "time": 21742.2310693264, "episode/length": 351.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9886363636363636, "episode/intrinsic_return": 0.0}
{"step": 712424, "time": 21746.605464696884, "episode/length": 157.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9620253164556962, "episode/intrinsic_return": 0.0}
{"step": 712600, "time": 21752.01518893242, "episode/length": 165.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 712792, "time": 21757.627620458603, "episode/length": 431.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 713168, "time": 21768.007422685623, "episode/length": 351.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9914772727272727, "episode/intrinsic_return": 0.0}
{"step": 713224, "time": 21770.13378572464, "episode/length": 327.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9908536585365854, "episode/intrinsic_return": 0.0}
{"step": 713480, "time": 21777.538292646408, "episode/length": 217.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9908256880733946, "episode/intrinsic_return": 0.0}
{"step": 713552, "time": 21780.391607522964, "episode/length": 118.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9915966386554622, "episode/intrinsic_return": 0.0}
{"step": 713776, "time": 21786.86732149124, "episode/length": 187.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 714248, "time": 21799.452397346497, "episode/length": 412.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9975786924939467, "episode/intrinsic_return": 0.0}
{"step": 714608, "time": 21809.578445911407, "episode/length": 179.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 714608, "time": 21809.62406849861, "episode/length": 172.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 714656, "time": 21811.640453338623, "episode/length": 109.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9545454545454546, "episode/intrinsic_return": 0.0}
{"step": 714760, "time": 21814.79256463051, "episode/length": 150.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 714768, "time": 21816.03806233406, "episode/length": 246.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.979757085020243, "episode/intrinsic_return": 0.0}
{"step": 714880, "time": 21819.61750817299, "episode/length": 306.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9837133550488599, "episode/intrinsic_return": 0.0}
{"step": 715248, "time": 21829.60603952408, "episode/length": 220.0, "episode/score": 9.099999964237213, "episode/reward_rate": 0.9819004524886877, "episode/intrinsic_return": 0.0}
{"step": 715312, "time": 21832.095080137253, "episode/length": 67.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9852941176470589, "episode/intrinsic_return": 0.0}
{"step": 715808, "time": 21845.640534877777, "episode/length": 149.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 715896, "time": 21848.554978609085, "episode/length": 205.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9805825242718447, "episode/intrinsic_return": 0.0}
{"step": 716144, "time": 21856.04063296318, "episode/length": 185.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 716168, "time": 21857.296272277832, "episode/length": 114.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9739130434782609, "episode/intrinsic_return": 0.0}
{"step": 716336, "time": 21862.775851249695, "episode/length": 196.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 716632, "time": 21871.17375445366, "episode/length": 218.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 716824, "time": 21876.99888277054, "episode/length": 276.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9819494584837545, "episode/intrinsic_return": 0.0}
{"step": 716936, "time": 21880.86474466324, "episode/length": 202.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9704433497536946, "episode/intrinsic_return": 0.0}
{"step": 717344, "time": 21892.021640777588, "episode/length": 180.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 718200, "time": 21913.89714026451, "episode/length": 253.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9724409448818898, "episode/intrinsic_return": 0.0}
{"step": 718312, "time": 21917.47092151642, "episode/length": 246.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 718472, "time": 21922.38093137741, "episode/length": 191.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 718760, "time": 21930.292033433914, "episode/length": 241.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9793388429752066, "episode/intrinsic_return": 0.0}
{"step": 718784, "time": 21931.93887257576, "episode/length": 371.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.989247311827957, "episode/intrinsic_return": 0.0}
{"step": 719736, "time": 21955.985939264297, "episode/length": 177.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 719856, "time": 21960.136640787125, "episode/length": 172.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 720072, "time": 21966.02574491501, "episode/length": 429.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9790697674418605, "episode/intrinsic_return": 0.0}
{"step": 720096, "time": 21969.32838153839, "eval_episode/length": 47.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9791666666666666}
{"step": 720096, "time": 21971.97974896431, "eval_episode/length": 149.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9666666666666667}
{"step": 720096, "time": 21973.779329061508, "eval_episode/length": 200.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9751243781094527}
{"step": 720096, "time": 21974.722870111465, "eval_episode/length": 204.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.975609756097561}
{"step": 720096, "time": 21975.85272192955, "eval_episode/length": 220.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9819004524886877}
{"step": 720096, "time": 21976.746185064316, "eval_episode/length": 176.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9943502824858758}
{"step": 720096, "time": 21978.053799390793, "eval_episode/length": 246.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9959514170040485}
{"step": 720096, "time": 21980.057653665543, "eval_episode/length": 306.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9869706840390879}
{"step": 720120, "time": 21980.716902017593, "episode/length": 169.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9588235294117647, "episode/intrinsic_return": 0.0}
{"step": 720176, "time": 21983.137549638748, "episode/length": 503.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9920634920634921, "episode/intrinsic_return": 0.0}
{"step": 720272, "time": 21986.386511087418, "episode/length": 185.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 721264, "time": 22011.587175369263, "episode/length": 148.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9731543624161074, "episode/intrinsic_return": 0.0}
{"step": 721760, "time": 22024.638638973236, "episode/length": 252.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9960474308300395, "episode/intrinsic_return": 0.0}
{"step": 721856, "time": 22027.85188150406, "episode/length": 249.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 721864, "time": 22028.77740430832, "episode/length": 217.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 721912, "time": 22030.975429058075, "episode/length": 463.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9978448275862069, "episode/intrinsic_return": 0.0}
{"step": 722128, "time": 22037.461382865906, "episode/length": 597.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9866220735785953, "episode/intrinsic_return": 0.0}
{"step": 722600, "time": 22049.898992300034, "episode/length": 302.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9966996699669967, "episode/intrinsic_return": 0.0}
{"step": 722720, "time": 22053.93208360672, "episode/length": 181.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 722976, "time": 22061.204598903656, "episode/length": 151.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 723136, "time": 22065.969336032867, "episode/length": 357.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9916201117318436, "episode/intrinsic_return": 0.0}
{"step": 723152, "time": 22067.312559127808, "episode/length": 127.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9609375, "episode/intrinsic_return": 0.0}
{"step": 723224, "time": 22069.681747436523, "episode/length": 62.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9841269841269841, "episode/intrinsic_return": 0.0}
{"step": 723328, "time": 22073.48069357872, "episode/length": 183.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 723952, "time": 22090.071593761444, "episode/length": 99.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.99, "episode/intrinsic_return": 0.0}
{"step": 724080, "time": 22094.111946344376, "episode/length": 184.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 724240, "time": 22099.06773662567, "episode/length": 137.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9927536231884058, "episode/intrinsic_return": 0.0}
{"step": 724376, "time": 22103.171045064926, "episode/length": 174.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9657142857142857, "episode/intrinsic_return": 0.0}
{"step": 725160, "time": 22123.87026810646, "episode/length": 228.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9694323144104804, "episode/intrinsic_return": 0.0}
{"step": 725176, "time": 22125.139062404633, "episode/length": 136.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9635036496350365, "episode/intrinsic_return": 0.0}
{"step": 725256, "time": 22127.952674388885, "episode/length": 423.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9787735849056604, "episode/intrinsic_return": 0.0}
{"step": 725376, "time": 22132.119786024094, "episode/length": 432.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9907621247113164, "episode/intrinsic_return": 0.0}
{"step": 725488, "time": 22135.820204496384, "episode/length": 282.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9681978798586572, "episode/intrinsic_return": 0.0}
{"step": 725608, "time": 22139.459342956543, "episode/length": 206.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9710144927536232, "episode/intrinsic_return": 0.0}
{"step": 725728, "time": 22143.46939444542, "episode/length": 185.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 725728, "time": 22143.516349315643, "episode/length": 168.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 725841, "time": 22147.53774023056, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.187113734654018, "train/action_min": 0.0, "train/action_std": 3.0804558833440145, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03435496599191711, "train/actor_opt_grad_steps": 44215.0, "train/actor_opt_loss": -7.59662735555321, "train/adv_mag": 0.4750615527232488, "train/adv_max": 0.44037745126656125, "train/adv_mean": 0.002538940359296421, "train/adv_min": -0.365919181846437, "train/adv_std": 0.05286159336212135, "train/cont_avg": 0.9949962797619047, "train/cont_loss_mean": 0.00024260549868287062, "train/cont_loss_std": 0.007363478345231604, "train/cont_neg_acc": 0.9894331083411262, "train/cont_neg_loss": 0.02803945019279906, "train/cont_pos_acc": 0.9999673099744888, "train/cont_pos_loss": 8.151191630922821e-05, "train/cont_pred": 0.9950127698126293, "train/cont_rate": 0.9949962797619047, "train/dyn_loss_mean": 13.664580862862723, "train/dyn_loss_std": 9.38774752389817, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9016212815330142, "train/extr_critic_critic_opt_grad_steps": 44215.0, "train/extr_critic_critic_opt_loss": 16075.994312686013, "train/extr_critic_mag": 7.6351276352292015, "train/extr_critic_max": 7.6351276352292015, "train/extr_critic_mean": 1.9611626142547245, "train/extr_critic_min": -0.2865429265158517, "train/extr_critic_std": 1.8388687996637254, "train/extr_return_normed_mag": 1.5114731896491278, "train/extr_return_normed_max": 1.5114731896491278, "train/extr_return_normed_mean": 0.34995195681140534, "train/extr_return_normed_min": -0.08988316995756966, "train/extr_return_normed_std": 0.32308926702964874, "train/extr_return_rate": 0.7078559410004389, "train/extr_return_raw_mag": 8.694223426637196, "train/extr_return_raw_max": 8.694223426637196, "train/extr_return_raw_mean": 1.9758331372624351, "train/extr_return_raw_min": -0.5689686772369204, "train/extr_return_raw_std": 1.869545388789404, "train/extr_reward_mag": 1.0221212069193522, "train/extr_reward_max": 1.0221212069193522, "train/extr_reward_mean": 0.03648640597682624, "train/extr_reward_min": -0.37233007181258426, "train/extr_reward_std": 0.17868549128373465, "train/image_loss_mean": 7.201368291037423, "train/image_loss_std": 12.4748489516122, "train/model_loss_mean": 15.45514776593163, "train/model_loss_std": 16.36653696241833, "train/model_opt_grad_norm": 58.265160742260164, "train/model_opt_grad_steps": 44175.35238095238, "train/model_opt_loss": 20619.909054129464, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1333.3333333333333, "train/policy_entropy_mag": 2.5113699163709367, "train/policy_entropy_max": 2.5113699163709367, "train/policy_entropy_mean": 0.5448682638860884, "train/policy_entropy_min": 0.07937502027267501, "train/policy_entropy_std": 0.6457738914660045, "train/policy_logprob_mag": 7.438383631479173, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5452081199203219, "train/policy_logprob_min": -7.438383631479173, "train/policy_logprob_std": 1.0989884064311073, "train/policy_randomness_mag": 0.8864033721742176, "train/policy_randomness_max": 0.8864033721742176, "train/policy_randomness_mean": 0.19231458597239995, "train/policy_randomness_min": 0.028015898824447678, "train/policy_randomness_std": 0.22792984424602417, "train/post_ent_mag": 59.24298317318871, "train/post_ent_max": 59.24298317318871, "train/post_ent_mean": 42.33469557989211, "train/post_ent_min": 20.56967926933652, "train/post_ent_std": 7.479198255993071, "train/prior_ent_mag": 68.78940716698057, "train/prior_ent_max": 68.78940716698057, "train/prior_ent_mean": 56.076008696783155, "train/prior_ent_min": 42.12383126758394, "train/prior_ent_std": 4.458167710758391, "train/rep_loss_mean": 13.664580862862723, "train/rep_loss_std": 9.38774752389817, "train/reward_avg": 0.027060081670060753, "train/reward_loss_mean": 0.05478844063445216, "train/reward_loss_std": 0.24853748523053668, "train/reward_max_data": 1.0152380988711402, "train/reward_max_pred": 1.010697214944022, "train/reward_neg_acc": 0.9932705654984428, "train/reward_neg_loss": 0.029027281661650965, "train/reward_pos_acc": 0.9664260693958827, "train/reward_pos_loss": 0.8490441506817228, "train/reward_pred": 0.02632893799981546, "train/reward_rate": 0.03154296875, "train_stats/sum_log_reward": 8.351748419808342, "train_stats/max_log_achievement_collect_coal": 0.8531468531468531, "train_stats/max_log_achievement_collect_drink": 6.713286713286713, "train_stats/max_log_achievement_collect_sapling": 1.1118881118881119, "train_stats/max_log_achievement_collect_stone": 14.776223776223777, "train_stats/max_log_achievement_collect_wood": 8.678321678321678, "train_stats/max_log_achievement_defeat_skeleton": 0.04895104895104895, "train_stats/max_log_achievement_defeat_zombie": 0.3776223776223776, "train_stats/max_log_achievement_eat_cow": 0.055944055944055944, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 2.104895104895105, "train_stats/max_log_achievement_make_wood_sword": 0.006993006993006993, "train_stats/max_log_achievement_place_furnace": 0.13286713286713286, "train_stats/max_log_achievement_place_plant": 1.062937062937063, "train_stats/max_log_achievement_place_stone": 11.223776223776223, "train_stats/max_log_achievement_place_table": 2.734265734265734, "train_stats/max_log_achievement_wake_up": 1.8531468531468531, "train_stats/mean_log_entropy": 0.5779942385591827, "eval_stats/sum_log_reward": 7.1833334763844805, "eval_stats/max_log_achievement_collect_coal": 0.7916666666666666, "eval_stats/max_log_achievement_collect_drink": 3.0416666666666665, "eval_stats/max_log_achievement_collect_sapling": 1.3333333333333333, "eval_stats/max_log_achievement_collect_stone": 7.833333333333333, "eval_stats/max_log_achievement_collect_wood": 7.916666666666667, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.375, "eval_stats/max_log_achievement_eat_cow": 0.041666666666666664, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.7083333333333333, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.08333333333333333, "eval_stats/max_log_achievement_place_plant": 1.2083333333333333, "eval_stats/max_log_achievement_place_stone": 5.75, "eval_stats/max_log_achievement_place_table": 2.625, "eval_stats/max_log_achievement_wake_up": 1.0, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 2.2673432340525324e-06, "report/cont_loss_std": 6.26157780061476e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 5.487732050823979e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.1643882064381614e-06, "report/cont_pred": 0.9980448484420776, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 12.755511283874512, "report/dyn_loss_std": 8.9952392578125, "report/image_loss_mean": 6.154996395111084, "report/image_loss_std": 13.5377779006958, "report/model_loss_mean": 13.854212760925293, "report/model_loss_std": 17.224321365356445, "report/post_ent_mag": 60.61220169067383, "report/post_ent_max": 60.61220169067383, "report/post_ent_mean": 42.554527282714844, "report/post_ent_min": 22.358657836914062, "report/post_ent_std": 7.140735626220703, "report/prior_ent_mag": 68.69029998779297, "report/prior_ent_max": 68.69029998779297, "report/prior_ent_mean": 55.53566360473633, "report/prior_ent_min": 36.314552307128906, "report/prior_ent_std": 4.14070987701416, "report/rep_loss_mean": 12.755511283874512, "report/rep_loss_std": 8.9952392578125, "report/reward_avg": 0.02177734300494194, "report/reward_loss_mean": 0.04590720310807228, "report/reward_loss_std": 0.2564413845539093, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0024163722991943, "report/reward_neg_acc": 0.9959959983825684, "report/reward_neg_loss": 0.026015091687440872, "report/reward_pos_acc": 0.9599999785423279, "report/reward_pos_loss": 0.8407958745956421, "report/reward_pred": 0.02250765822827816, "report/reward_rate": 0.0244140625, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 2.2713435100740753e-05, "eval/cont_loss_std": 0.0007042215438559651, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.011284141801297665, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 6.754125365660002e-07, "eval/cont_pred": 0.99806809425354, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 16.785015106201172, "eval/dyn_loss_std": 10.872159957885742, "eval/image_loss_mean": 12.577335357666016, "eval/image_loss_std": 19.152257919311523, "eval/model_loss_mean": 22.752071380615234, "eval/model_loss_std": 23.555086135864258, "eval/post_ent_mag": 57.55723190307617, "eval/post_ent_max": 57.55723190307617, "eval/post_ent_mean": 41.504615783691406, "eval/post_ent_min": 20.507205963134766, "eval/post_ent_std": 7.152535438537598, "eval/prior_ent_mag": 68.69029998779297, "eval/prior_ent_max": 68.69029998779297, "eval/prior_ent_mean": 55.99344253540039, "eval/prior_ent_min": 43.4232177734375, "eval/prior_ent_std": 4.304129600524902, "eval/rep_loss_mean": 16.785015106201172, "eval/rep_loss_std": 10.872159957885742, "eval/reward_avg": 0.04023437574505806, "eval/reward_loss_mean": 0.10370300710201263, "eval/reward_loss_std": 0.7205256819725037, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 1.0005362033843994, "eval/reward_neg_acc": 0.9887869358062744, "eval/reward_neg_loss": 0.024819104000926018, "eval/reward_pos_acc": 0.8139534592628479, "eval/reward_pos_loss": 1.903356909751892, "eval/reward_pred": 0.034566331654787064, "eval/reward_rate": 0.0419921875, "replay/size": 725337.0, "replay/inserts": 33656.0, "replay/samples": 33648.0, "replay/insert_wait_avg": 1.2332083409887213e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 5.77892964644711e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 7112.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2545135077529066e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.748603820800781e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0015177726746, "timer/env.step_count": 4207.0, "timer/env.step_total": 132.7428412437439, "timer/env.step_frac": 0.1327426397705925, "timer/env.step_avg": 0.031552850307521724, "timer/env.step_min": 0.00222015380859375, "timer/env.step_max": 0.9269847869873047, "timer/replay._sample_count": 33648.0, "timer/replay._sample_total": 2980.762379169464, "timer/replay._sample_frac": 2.980757855056642, "timer/replay._sample_avg": 0.08858661374136544, "timer/replay._sample_min": 0.00044274330139160156, "timer/replay._sample_max": 0.11861777305603027, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5096.0, "timer/agent.policy_total": 52.51939845085144, "timer/agent.policy_frac": 0.05251931873846457, "timer/agent.policy_avg": 0.010306004405583092, "timer/agent.policy_min": 0.007510185241699219, "timer/agent.policy_max": 0.021557092666625977, "timer/dataset_train_count": 2103.0, "timer/dataset_train_total": 0.17285799980163574, "timer/dataset_train_frac": 0.00017285773744288527, "timer/dataset_train_avg": 8.219591050957477e-05, "timer/dataset_train_min": 7.104873657226562e-05, "timer/dataset_train_max": 0.00017189979553222656, "timer/agent.train_count": 2103.0, "timer/agent.train_total": 781.8040661811829, "timer/agent.train_frac": 0.7818028795821353, "timer/agent.train_avg": 0.37175656974854154, "timer/agent.train_min": 0.3477916717529297, "timer/agent.train_max": 0.592864990234375, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4151463508605957, "timer/agent.report_frac": 0.00041514572076376476, "timer/agent.report_avg": 0.20757317543029785, "timer/agent.report_min": 0.20744657516479492, "timer/agent.report_max": 0.20769977569580078, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.457069396972656e-05, "timer/dataset_eval_frac": 3.457064149935155e-08, "timer/dataset_eval_avg": 3.457069396972656e-05, "timer/dataset_eval_min": 3.457069396972656e-05, "timer/dataset_eval_max": 3.457069396972656e-05, "fps": 33.65534222777388}
{"step": 726464, "time": 22163.440014839172, "episode/length": 160.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 726616, "time": 22167.968186855316, "episode/length": 154.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 727016, "time": 22178.69454240799, "episode/length": 231.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.978448275862069, "episode/intrinsic_return": 0.0}
{"step": 727488, "time": 22191.328771352768, "episode/length": 234.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 727688, "time": 22197.04266643524, "episode/length": 274.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9709090909090909, "episode/intrinsic_return": 0.0}
{"step": 727712, "time": 22198.616911888123, "episode/length": 247.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9959677419354839, "episode/intrinsic_return": 0.0}
{"step": 727736, "time": 22199.894042491913, "episode/length": 250.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9960159362549801, "episode/intrinsic_return": 0.0}
{"step": 727920, "time": 22205.452959775925, "episode/length": 112.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9557522123893806, "episode/intrinsic_return": 0.0}
{"step": 728056, "time": 22209.57004714012, "episode/length": 198.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 728376, "time": 22218.428430318832, "episode/length": 389.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9871794871794872, "episode/intrinsic_return": 0.0}
{"step": 728424, "time": 22220.436645507812, "episode/length": 225.0, "episode/score": 9.100000016391277, "episode/reward_rate": 0.9823008849557522, "episode/intrinsic_return": 0.0}
{"step": 728536, "time": 22224.070355653763, "episode/length": 130.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9923664122137404, "episode/intrinsic_return": 0.0}
{"step": 729104, "time": 22239.337160348892, "episode/length": 170.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 729232, "time": 22243.313852787018, "episode/length": 100.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9504950495049505, "episode/intrinsic_return": 0.0}
{"step": 729416, "time": 22248.622932195663, "episode/length": 186.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9625668449197861, "episode/intrinsic_return": 0.0}
{"step": 729480, "time": 22250.981170892715, "episode/length": 223.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 729712, "time": 22257.75979399681, "episode/length": 166.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 730080, "time": 22269.880004644394, "eval_episode/length": 87.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9886363636363636}
{"step": 730080, "time": 22272.297143936157, "eval_episode/length": 175.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9659090909090909}
{"step": 730080, "time": 22273.678203105927, "eval_episode/length": 204.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9951219512195122}
{"step": 730080, "time": 22274.845192193985, "eval_episode/length": 223.0, "eval_episode/score": 11.100000008940697, "eval_episode/reward_rate": 0.96875}
{"step": 730080, "time": 22274.89229941368, "eval_episode/length": 223.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9955357142857143}
{"step": 730080, "time": 22277.382348299026, "eval_episode/length": 308.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9805825242718447}
{"step": 730080, "time": 22278.241357564926, "eval_episode/length": 85.0, "eval_episode/score": 8.099999964237213, "eval_episode/reward_rate": 0.9534883720930233}
{"step": 730080, "time": 22280.001445531845, "eval_episode/length": 176.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.96045197740113}
{"step": 730136, "time": 22281.411022663116, "episode/length": 89.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9333333333333333, "episode/intrinsic_return": 0.0}
{"step": 730400, "time": 22289.02577471733, "episode/length": 114.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.991304347826087, "episode/intrinsic_return": 0.0}
{"step": 730560, "time": 22293.841554641724, "episode/length": 355.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9887640449438202, "episode/intrinsic_return": 0.0}
{"step": 730712, "time": 22298.26073026657, "episode/length": 331.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9879518072289156, "episode/intrinsic_return": 0.0}
{"step": 730904, "time": 22303.859578847885, "episode/length": 208.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 730912, "time": 22305.012701511383, "episode/length": 43.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 731144, "time": 22311.371972560883, "episode/length": 254.0, "episode/score": 9.100000031292439, "episode/reward_rate": 0.996078431372549, "episode/intrinsic_return": 0.0}
{"step": 731736, "time": 22327.14082121849, "episode/length": 252.0, "episode/score": 9.100000016391277, "episode/reward_rate": 0.9802371541501976, "episode/intrinsic_return": 0.0}
{"step": 731848, "time": 22330.828477859497, "episode/length": 180.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 731856, "time": 22332.04195356369, "episode/length": 414.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9951807228915662, "episode/intrinsic_return": 0.0}
{"step": 731952, "time": 22335.283780813217, "episode/length": 226.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9779735682819384, "episode/intrinsic_return": 0.0}
{"step": 732488, "time": 22349.20290184021, "episode/length": 221.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9819819819819819, "episode/intrinsic_return": 0.0}
{"step": 732520, "time": 22350.840253591537, "episode/length": 200.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9701492537313433, "episode/intrinsic_return": 0.0}
{"step": 733224, "time": 22369.375117778778, "episode/length": 185.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 733712, "time": 22382.65247488022, "episode/length": 152.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 734088, "time": 22392.825498580933, "episode/length": 278.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.996415770609319, "episode/intrinsic_return": 0.0}
{"step": 734152, "time": 22395.21076440811, "episode/length": 375.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9893617021276596, "episode/intrinsic_return": 0.0}
{"step": 734192, "time": 22397.271094560623, "episode/length": 59.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9333333333333333, "episode/intrinsic_return": 0.0}
{"step": 734312, "time": 22401.03883576393, "episode/length": 425.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9976525821596244, "episode/intrinsic_return": 0.0}
{"step": 734776, "time": 22413.634520053864, "episode/length": 193.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 735424, "time": 22431.310094356537, "episode/length": 446.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9977628635346756, "episode/intrinsic_return": 0.0}
{"step": 735432, "time": 22432.159203529358, "episode/length": 159.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 735448, "time": 22433.600756168365, "episode/length": 365.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9699453551912568, "episode/intrinsic_return": 0.0}
{"step": 735520, "time": 22436.363743543625, "episode/length": 445.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9798206278026906, "episode/intrinsic_return": 0.0}
{"step": 735560, "time": 22438.003174304962, "episode/length": 155.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 735744, "time": 22443.613092899323, "episode/length": 39.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 736184, "time": 22455.14357328415, "episode/length": 93.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9468085106382979, "episode/intrinsic_return": 0.0}
{"step": 736344, "time": 22460.12351346016, "episode/length": 102.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.941747572815534, "episode/intrinsic_return": 0.0}
{"step": 736968, "time": 22476.552554130554, "episode/length": 359.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 737104, "time": 22480.91472864151, "episode/length": 363.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.989010989010989, "episode/intrinsic_return": 0.0}
{"step": 737216, "time": 22484.496701717377, "episode/length": 128.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9922480620155039, "episode/intrinsic_return": 0.0}
{"step": 737472, "time": 22491.69709634781, "episode/length": 215.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 737640, "time": 22496.441029787064, "episode/length": 357.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 737744, "time": 22500.150648355484, "episode/length": 65.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9848484848484849, "episode/intrinsic_return": 0.0}
{"step": 737760, "time": 22501.464893579483, "episode/length": 274.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9781818181818182, "episode/intrinsic_return": 0.0}
{"step": 738360, "time": 22517.1996114254, "episode/length": 173.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 738568, "time": 22523.30145049095, "episode/length": 182.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9617486338797814, "episode/intrinsic_return": 0.0}
{"step": 738880, "time": 22532.037494421005, "episode/length": 428.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 739032, "time": 22536.33423781395, "episode/length": 173.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 739232, "time": 22542.260648965836, "episode/length": 183.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 739344, "time": 22545.87281870842, "episode/length": 199.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.97, "episode/intrinsic_return": 0.0}
{"step": 739352, "time": 22546.682164907455, "episode/length": 375.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9813829787234043, "episode/intrinsic_return": 0.0}
{"step": 740064, "time": 22567.39119362831, "eval_episode/length": 63.0, "eval_episode/score": 7.100000023841858, "eval_episode/reward_rate": 0.984375}
{"step": 740064, "time": 22569.818873643875, "eval_episode/length": 153.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9675324675324676}
{"step": 740064, "time": 22570.690256357193, "eval_episode/length": 154.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.967741935483871}
{"step": 740064, "time": 22571.838584423065, "eval_episode/length": 171.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9593023255813954}
{"step": 740064, "time": 22572.86120223999, "eval_episode/length": 181.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9945054945054945}
{"step": 740064, "time": 22574.36114025116, "eval_episode/length": 214.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9720930232558139}
{"step": 740064, "time": 22576.719973802567, "eval_episode/length": 120.0, "eval_episode/score": 8.100000023841858, "eval_episode/reward_rate": 0.9917355371900827}
{"step": 740064, "time": 22578.3952088356, "eval_episode/length": 181.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9615384615384616}
{"step": 740328, "time": 22585.04319000244, "episode/length": 180.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 740584, "time": 22592.395582675934, "episode/length": 154.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 740600, "time": 22593.675223350525, "episode/length": 155.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 740872, "time": 22601.299602508545, "episode/length": 229.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 740880, "time": 22602.58071231842, "episode/length": 288.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.972318339100346, "episode/intrinsic_return": 0.0}
{"step": 741080, "time": 22608.260525226593, "episode/length": 450.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9977827050997783, "episode/intrinsic_return": 0.0}
{"step": 741928, "time": 22630.569022893906, "episode/length": 445.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 742112, "time": 22636.148871421814, "episode/length": 190.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 742216, "time": 22639.427708387375, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 742552, "time": 22648.715470552444, "episode/length": 277.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9784172661870504, "episode/intrinsic_return": 0.0}
{"step": 742648, "time": 22651.860676288605, "episode/length": 426.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9789227166276346, "episode/intrinsic_return": 0.0}
{"step": 742704, "time": 22654.39230966568, "episode/length": 227.0, "episode/score": 8.099999956786633, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 743064, "time": 22663.907161712646, "episode/length": 307.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 743144, "time": 22666.735422611237, "episode/length": 257.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9961240310077519, "episode/intrinsic_return": 0.0}
{"step": 743392, "time": 22673.948217868805, "episode/length": 159.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 743520, "time": 22678.004003047943, "episode/length": 46.0, "episode/score": 4.100000023841858, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 743648, "time": 22682.1405210495, "episode/length": 178.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 743688, "time": 22683.740356445312, "episode/length": 219.0, "episode/score": 9.100000016391277, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 743992, "time": 22692.08583712578, "episode/length": 167.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 744400, "time": 22703.20680165291, "episode/length": 109.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.990909090909091, "episode/intrinsic_return": 0.0}
{"step": 744768, "time": 22713.15869665146, "episode/length": 276.0, "episode/score": 11.099999971687794, "episode/reward_rate": 0.9963898916967509, "episode/intrinsic_return": 0.0}
{"step": 745000, "time": 22719.606055259705, "episode/length": 168.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 745040, "time": 22721.664804458618, "episode/length": 130.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9923664122137404, "episode/intrinsic_return": 0.0}
{"step": 745456, "time": 22732.74133348465, "episode/length": 220.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 745544, "time": 22735.625279426575, "episode/length": 354.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9943661971830986, "episode/intrinsic_return": 0.0}
{"step": 746552, "time": 22761.396045207977, "episode/length": 222.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9775784753363229, "episode/intrinsic_return": 0.0}
{"step": 746696, "time": 22765.82595539093, "episode/length": 286.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9930313588850174, "episode/intrinsic_return": 0.0}
{"step": 746712, "time": 22767.041506290436, "episode/length": 156.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9617834394904459, "episode/intrinsic_return": 0.0}
{"step": 746872, "time": 22771.868471622467, "episode/length": 434.0, "episode/score": 10.099999964237213, "episode/reward_rate": 0.9954022988505747, "episode/intrinsic_return": 0.0}
{"step": 746952, "time": 22774.823088169098, "episode/length": 485.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9897119341563786, "episode/intrinsic_return": 0.0}
{"step": 746960, "time": 22775.972836732864, "episode/length": 239.0, "episode/score": 10.100000031292439, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 747280, "time": 22784.67187523842, "episode/length": 216.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 747424, "time": 22789.133859872818, "episode/length": 58.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 747648, "time": 22795.48438358307, "episode/length": 330.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9969788519637462, "episode/intrinsic_return": 0.0}
{"step": 748008, "time": 22805.24621963501, "episode/length": 161.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 748056, "time": 22807.310958385468, "episode/length": 169.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 748872, "time": 22828.54890203476, "episode/length": 289.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9862068965517241, "episode/intrinsic_return": 0.0}
{"step": 749496, "time": 22844.91740989685, "episode/length": 179.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 749752, "time": 22852.15016436577, "episode/length": 359.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9916666666666667, "episode/intrinsic_return": 0.0}
{"step": 749752, "time": 22852.197835206985, "episode/length": 262.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9847908745247148, "episode/intrinsic_return": 0.0}
{"step": 749760, "time": 22853.722196102142, "episode/length": 309.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9967741935483871, "episode/intrinsic_return": 0.0}
{"step": 750048, "time": 22863.344385385513, "eval_episode/length": 40.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.975609756097561}
{"step": 750048, "time": 22866.146647691727, "eval_episode/length": 157.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9683544303797469}
{"step": 750048, "time": 22867.238074064255, "eval_episode/length": 171.0, "eval_episode/score": 9.099999979138374, "eval_episode/reward_rate": 0.9767441860465116}
{"step": 750048, "time": 22868.356954574585, "eval_episode/length": 146.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9931972789115646}
{"step": 750048, "time": 22869.703221321106, "eval_episode/length": 213.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9766355140186916}
{"step": 750048, "time": 22871.648664712906, "eval_episode/length": 269.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9814814814814815}
{"step": 750048, "time": 22872.977120876312, "eval_episode/length": 105.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9528301886792453}
{"step": 750048, "time": 22873.862736701965, "eval_episode/length": 295.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9831081081081081}
{"step": 750272, "time": 22879.672456502914, "episode/length": 355.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 750464, "time": 22885.34354519844, "episode/length": 437.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.997716894977169, "episode/intrinsic_return": 0.0}
{"step": 750568, "time": 22888.529849767685, "episode/length": 211.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 751008, "time": 22900.62866616249, "episode/length": 156.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 751296, "time": 22908.73397707939, "episode/length": 224.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 751304, "time": 22909.55940413475, "episode/length": 36.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.8648648648648649, "episode/intrinsic_return": 0.0}
{"step": 751312, "time": 22910.779211759567, "episode/length": 193.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 751352, "time": 22912.467037916183, "episode/length": 417.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 751648, "time": 22920.842942237854, "episode/length": 147.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 751712, "time": 22923.35973763466, "episode/length": 142.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 752096, "time": 22934.00977897644, "episode/length": 227.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 752112, "time": 22935.221961021423, "episode/length": 49.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 752456, "time": 22944.41612958908, "episode/length": 44.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 752480, "time": 22946.03396630287, "episode/length": 103.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9903846153846154, "episode/intrinsic_return": 0.0}
{"step": 752736, "time": 22953.319473981857, "episode/length": 172.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 752840, "time": 22956.461166858673, "episode/length": 385.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9896373056994818, "episode/intrinsic_return": 0.0}
{"step": 752848, "time": 22957.70217871666, "episode/length": 191.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9895833333333334, "episode/intrinsic_return": 0.0}
{"step": 752888, "time": 22959.420630931854, "episode/length": 198.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 753176, "time": 22967.4169754982, "episode/length": 233.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 753648, "time": 22980.103140115738, "episode/length": 148.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 754088, "time": 22991.82285428047, "episode/length": 154.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 754128, "time": 22993.881920576096, "episode/length": 154.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 754184, "time": 22995.964017868042, "episode/length": 212.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 754376, "time": 23001.579510211945, "episode/length": 191.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 754456, "time": 23004.35487985611, "episode/length": 214.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 754968, "time": 23018.073088407516, "episode/length": 356.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9943977591036415, "episode/intrinsic_return": 0.0}
{"step": 755088, "time": 23022.223414182663, "episode/length": 238.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.0}
{"step": 755304, "time": 23028.188969373703, "episode/length": 206.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 755696, "time": 23038.862372398376, "episode/length": 195.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 756184, "time": 23051.510539531708, "episode/length": 225.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9867256637168141, "episode/intrinsic_return": 0.0}
{"step": 756288, "time": 23055.042138576508, "episode/length": 228.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 756432, "time": 23059.35719561577, "episode/length": 182.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 756984, "time": 23073.728982925415, "episode/length": 349.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 757152, "time": 23078.89763379097, "episode/length": 181.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 757320, "time": 23083.800466299057, "episode/length": 251.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.996031746031746, "episode/intrinsic_return": 0.0}
{"step": 757328, "time": 23085.094488859177, "episode/length": 129.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9538461538461539, "episode/intrinsic_return": 0.0}
{"step": 757512, "time": 23090.41133904457, "episode/length": 427.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9789719626168224, "episode/intrinsic_return": 0.0}
{"step": 757968, "time": 23102.705419063568, "episode/length": 56.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 758320, "time": 23112.405512094498, "episode/length": 166.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9640718562874252, "episode/intrinsic_return": 0.0}
{"step": 758488, "time": 23117.426879882812, "episode/length": 144.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 758640, "time": 23122.26994228363, "episode/length": 164.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 758728, "time": 23125.125560998917, "episode/length": 286.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9860627177700348, "episode/intrinsic_return": 0.0}
{"step": 758976, "time": 23132.388605356216, "episode/length": 227.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 759016, "time": 23134.130261421204, "episode/length": 490.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9979633401221996, "episode/intrinsic_return": 0.0}
{"step": 759497, "time": 23147.786911964417, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.302812476858708, "train/action_min": 0.0, "train/action_std": 3.043787914429796, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03511107368703702, "train/actor_opt_grad_steps": 46320.0, "train/actor_opt_loss": -5.787860451504518, "train/adv_mag": 0.4611396134182175, "train/adv_max": 0.43117955411779935, "train/adv_mean": 0.002904575612808835, "train/adv_min": -0.3619920206013449, "train/adv_std": 0.05324792808972264, "train/cont_avg": 0.9949413136848341, "train/cont_loss_mean": 0.0002926966055907791, "train/cont_loss_std": 0.009118179794208958, "train/cont_neg_acc": 0.9876325896000975, "train/cont_neg_loss": 0.04002536164736774, "train/cont_pos_acc": 0.99996741688082, "train/cont_pos_loss": 0.00011982764887291426, "train/cont_pred": 0.9949529473250511, "train/cont_rate": 0.9949413136848341, "train/dyn_loss_mean": 13.573536258173215, "train/dyn_loss_std": 9.358496394767581, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.93775387765107, "train/extr_critic_critic_opt_grad_steps": 46320.0, "train/extr_critic_critic_opt_loss": 16144.731260182169, "train/extr_critic_mag": 7.7676621929729155, "train/extr_critic_max": 7.7676621929729155, "train/extr_critic_mean": 2.061012614394816, "train/extr_critic_min": -0.2890806113374177, "train/extr_critic_std": 1.9132602695040228, "train/extr_return_normed_mag": 1.507393063527148, "train/extr_return_normed_max": 1.507393063527148, "train/extr_return_normed_mean": 0.3593929845716151, "train/extr_return_normed_min": -0.09079600602247138, "train/extr_return_normed_std": 0.3284913329716542, "train/extr_return_rate": 0.7097335717689369, "train/extr_return_raw_mag": 8.867466503974951, "train/extr_return_raw_max": 8.867466503974951, "train/extr_return_raw_mean": 2.078192464548265, "train/extr_return_raw_min": -0.5847954580569155, "train/extr_return_raw_std": 1.9429587781146804, "train/extr_reward_mag": 1.0252144280203146, "train/extr_reward_max": 1.0252144280203146, "train/extr_reward_mean": 0.03925871000717884, "train/extr_reward_min": -0.39573462427509903, "train/extr_reward_std": 0.1857026027983399, "train/image_loss_mean": 6.9012363058695865, "train/image_loss_std": 12.110569300809743, "train/model_loss_mean": 15.100798317606415, "train/model_loss_std": 16.005738321638784, "train/model_opt_grad_norm": 55.42190558989466, "train/model_opt_grad_steps": 46278.123222748814, "train/model_opt_loss": 14421.7069201718, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 953.7914691943128, "train/policy_entropy_mag": 2.551061067535979, "train/policy_entropy_max": 2.551061067535979, "train/policy_entropy_mean": 0.5549374863999714, "train/policy_entropy_min": 0.07937501974721656, "train/policy_entropy_std": 0.6597857417371036, "train/policy_logprob_mag": 7.438383660610254, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5544142444834325, "train/policy_logprob_min": -7.438383660610254, "train/policy_logprob_std": 1.106971387614571, "train/policy_randomness_mag": 0.9004126055545717, "train/policy_randomness_max": 0.9004126055545717, "train/policy_randomness_mean": 0.19586858033286453, "train/policy_randomness_min": 0.028015898681859268, "train/policy_randomness_std": 0.23287541295679826, "train/post_ent_mag": 58.96707113546218, "train/post_ent_max": 58.96707113546218, "train/post_ent_mean": 42.42859389318674, "train/post_ent_min": 20.540933292623944, "train/post_ent_std": 7.453111666638704, "train/prior_ent_mag": 68.74544228648688, "train/prior_ent_max": 68.74544228648688, "train/prior_ent_mean": 56.080628092255076, "train/prior_ent_min": 42.1414698560091, "train/prior_ent_std": 4.446565910538226, "train/rep_loss_mean": 13.573536258173215, "train/rep_loss_std": 9.358496394767581, "train/reward_avg": 0.027515920956058523, "train/reward_loss_mean": 0.055147704663929216, "train/reward_loss_std": 0.24716934208621347, "train/reward_max_data": 1.0156398141553618, "train/reward_max_pred": 1.0098215917840387, "train/reward_neg_acc": 0.9931840455927555, "train/reward_neg_loss": 0.0289595952760693, "train/reward_pos_acc": 0.9683694257555415, "train/reward_pos_loss": 0.8490975674294747, "train/reward_pred": 0.02669070612515601, "train/reward_rate": 0.032041432168246446, "train_stats/sum_log_reward": 8.481944650411606, "train_stats/max_log_achievement_collect_coal": 0.8888888888888888, "train_stats/max_log_achievement_collect_drink": 5.048611111111111, "train_stats/max_log_achievement_collect_sapling": 1.2916666666666667, "train_stats/max_log_achievement_collect_stone": 16.09027777777778, "train_stats/max_log_achievement_collect_wood": 8.020833333333334, "train_stats/max_log_achievement_defeat_skeleton": 0.0763888888888889, "train_stats/max_log_achievement_defeat_zombie": 0.3819444444444444, "train_stats/max_log_achievement_eat_cow": 0.08333333333333333, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.013888888888888888, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.9861111111111112, "train_stats/max_log_achievement_make_wood_sword": 0.027777777777777776, "train_stats/max_log_achievement_place_furnace": 0.19444444444444445, "train_stats/max_log_achievement_place_plant": 1.2361111111111112, "train_stats/max_log_achievement_place_stone": 11.354166666666666, "train_stats/max_log_achievement_place_table": 2.4791666666666665, "train_stats/max_log_achievement_wake_up": 1.9722222222222223, "train_stats/mean_log_entropy": 0.5890769467482136, "eval_stats/sum_log_reward": 8.266666809717814, "eval_stats/max_log_achievement_collect_coal": 0.4166666666666667, "eval_stats/max_log_achievement_collect_drink": 4.0, "eval_stats/max_log_achievement_collect_sapling": 1.3333333333333333, "eval_stats/max_log_achievement_collect_stone": 11.666666666666666, "eval_stats/max_log_achievement_collect_wood": 7.875, "eval_stats/max_log_achievement_defeat_skeleton": 0.08333333333333333, "eval_stats/max_log_achievement_defeat_zombie": 0.25, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.75, "eval_stats/max_log_achievement_make_wood_sword": 0.041666666666666664, "eval_stats/max_log_achievement_place_furnace": 0.08333333333333333, "eval_stats/max_log_achievement_place_plant": 1.2916666666666667, "eval_stats/max_log_achievement_place_stone": 8.625, "eval_stats/max_log_achievement_place_table": 2.5, "eval_stats/max_log_achievement_wake_up": 1.25, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.00010317838314222172, "report/cont_loss_std": 0.002123397309333086, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.007654120214283466, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 5.120533023728058e-05, "report/cont_pred": 0.9931658506393433, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 14.383495330810547, "report/dyn_loss_std": 9.315394401550293, "report/image_loss_mean": 7.148167610168457, "report/image_loss_std": 12.737480163574219, "report/model_loss_mean": 15.847221374511719, "report/model_loss_std": 16.633970260620117, "report/post_ent_mag": 60.457706451416016, "report/post_ent_max": 60.457706451416016, "report/post_ent_mean": 42.427127838134766, "report/post_ent_min": 20.842653274536133, "report/post_ent_std": 7.822573184967041, "report/prior_ent_mag": 68.58808135986328, "report/prior_ent_max": 68.58808135986328, "report/prior_ent_mean": 56.98865509033203, "report/prior_ent_min": 42.855125427246094, "report/prior_ent_std": 4.520196914672852, "report/rep_loss_mean": 14.383495330810547, "report/rep_loss_std": 9.315394401550293, "report/reward_avg": 0.03583984449505806, "report/reward_loss_mean": 0.06885312497615814, "report/reward_loss_std": 0.30284303426742554, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.0713379383087158, "report/reward_neg_acc": 0.9877800941467285, "report/reward_neg_loss": 0.03602712228894234, "report/reward_pos_acc": 0.9523809552192688, "report/reward_pos_loss": 0.8363563418388367, "report/reward_pred": 0.03483927249908447, "report/reward_rate": 0.041015625, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 1.1469817309261998e-06, "eval/cont_loss_std": 3.213076706742868e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0010287398472428322, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.4249229707274935e-07, "eval/cont_pred": 0.9990243315696716, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 18.25589370727539, "eval/dyn_loss_std": 10.695019721984863, "eval/image_loss_mean": 13.184961318969727, "eval/image_loss_std": 16.70305824279785, "eval/model_loss_mean": 24.218624114990234, "eval/model_loss_std": 20.438398361206055, "eval/post_ent_mag": 57.84869384765625, "eval/post_ent_max": 57.84869384765625, "eval/post_ent_mean": 40.98303985595703, "eval/post_ent_min": 21.731584548950195, "eval/post_ent_std": 7.906052589416504, "eval/prior_ent_mag": 68.58808135986328, "eval/prior_ent_max": 68.58808135986328, "eval/prior_ent_mean": 56.399330139160156, "eval/prior_ent_min": 41.868343353271484, "eval/prior_ent_std": 3.6622767448425293, "eval/rep_loss_mean": 18.25589370727539, "eval/rep_loss_std": 10.695019721984863, "eval/reward_avg": 0.02324218675494194, "eval/reward_loss_mean": 0.08012443780899048, "eval/reward_loss_std": 0.6039251685142517, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0018320083618164, "eval/reward_neg_acc": 0.9919919967651367, "eval/reward_neg_loss": 0.03574303165078163, "eval/reward_pos_acc": 0.8399999737739563, "eval/reward_pos_loss": 1.8536056280136108, "eval/reward_pred": 0.019512049853801727, "eval/reward_rate": 0.0244140625, "replay/size": 758993.0, "replay/inserts": 33656.0, "replay/samples": 33664.0, "replay/insert_wait_avg": 1.222051065552396e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 5.810673812496345e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 7880.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2435586319357006e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.599592208862305e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.230188369751, "timer/env.step_count": 4207.0, "timer/env.step_total": 134.29416632652283, "timer/env.step_frac": 0.1342632604854742, "timer/env.step_avg": 0.031921598841578996, "timer/env.step_min": 0.002321958541870117, "timer/env.step_max": 1.14786958694458, "timer/replay._sample_count": 33664.0, "timer/replay._sample_total": 2987.9278852939606, "timer/replay._sample_frac": 2.9872402573290717, "timer/replay._sample_avg": 0.08875736351277212, "timer/replay._sample_min": 0.0003814697265625, "timer/replay._sample_max": 0.11468958854675293, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5192.0, "timer/agent.policy_total": 53.29218649864197, "timer/agent.policy_frac": 0.05327992208023786, "timer/agent.policy_avg": 0.010264288616841673, "timer/agent.policy_min": 0.007757902145385742, "timer/agent.policy_max": 0.0188748836517334, "timer/dataset_train_count": 2104.0, "timer/dataset_train_total": 0.1708509922027588, "timer/dataset_train_frac": 0.00017081167334213773, "timer/dataset_train_avg": 8.120294306214771e-05, "timer/dataset_train_min": 6.079673767089844e-05, "timer/dataset_train_max": 0.0002346038818359375, "timer/agent.train_count": 2104.0, "timer/agent.train_total": 779.5408675670624, "timer/agent.train_frac": 0.7793614676213839, "timer/agent.train_avg": 0.3705042146231285, "timer/agent.train_min": 0.3475942611694336, "timer/agent.train_max": 0.56386399269104, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.41727733612060547, "timer/agent.report_frac": 0.00041718130583592454, "timer/agent.report_avg": 0.20863866806030273, "timer/agent.report_min": 0.2081899642944336, "timer/agent.report_max": 0.20908737182617188, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.552436828613281e-05, "timer/dataset_eval_frac": 3.551619287159594e-08, "timer/dataset_eval_avg": 3.552436828613281e-05, "timer/dataset_eval_min": 3.552436828613281e-05, "timer/dataset_eval_max": 3.552436828613281e-05, "fps": 33.64766593924475}
{"step": 759592, "time": 23149.954571008682, "episode/length": 425.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9788732394366197, "episode/intrinsic_return": 0.0}
{"step": 759752, "time": 23154.950605392456, "episode/length": 222.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 759768, "time": 23156.19064974785, "episode/length": 180.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 759824, "time": 23158.553514003754, "episode/length": 147.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 760032, "time": 23166.114297389984, "eval_episode/length": 40.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9024390243902439}
{"step": 760032, "time": 23167.589069604874, "eval_episode/length": 79.0, "eval_episode/score": 6.0999999940395355, "eval_episode/reward_rate": 0.9875}
{"step": 760032, "time": 23169.250786304474, "eval_episode/length": 122.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9512195121951219}
{"step": 760032, "time": 23171.300303459167, "eval_episode/length": 185.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9623655913978495}
{"step": 760032, "time": 23172.184770584106, "eval_episode/length": 186.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9732620320855615}
{"step": 760032, "time": 23173.177055358887, "eval_episode/length": 193.0, "eval_episode/score": 8.100000023841858, "eval_episode/reward_rate": 0.9948453608247423}
{"step": 760032, "time": 23174.38435959816, "eval_episode/length": 211.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9764150943396226}
{"step": 760032, "time": 23175.327518701553, "eval_episode/length": 174.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 760096, "time": 23177.27452325821, "episode/length": 170.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 760640, "time": 23191.871399641037, "episode/length": 202.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 761088, "time": 23204.205214500427, "episode/length": 166.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9640718562874252, "episode/intrinsic_return": 0.0}
{"step": 761120, "time": 23205.773061275482, "episode/length": 190.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9842931937172775, "episode/intrinsic_return": 0.0}
{"step": 761224, "time": 23208.99380850792, "episode/length": 341.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9912280701754386, "episode/intrinsic_return": 0.0}
{"step": 761328, "time": 23212.563348531723, "episode/length": 187.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 761392, "time": 23215.05563211441, "episode/length": 161.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 761424, "time": 23216.75060081482, "episode/length": 206.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.966183574879227, "episode/intrinsic_return": 0.0}
{"step": 762152, "time": 23235.763111114502, "episode/length": 396.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9899244332493703, "episode/intrinsic_return": 0.0}
{"step": 762576, "time": 23247.457909822464, "episode/length": 147.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 762712, "time": 23251.54395031929, "episode/length": 258.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9961389961389961, "episode/intrinsic_return": 0.0}
{"step": 762784, "time": 23254.357357263565, "episode/length": 181.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 763256, "time": 23266.7299118042, "episode/length": 266.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9962546816479401, "episode/intrinsic_return": 0.0}
{"step": 763416, "time": 23271.486285209656, "episode/length": 157.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9556962025316456, "episode/intrinsic_return": 0.0}
{"step": 763568, "time": 23276.252592086792, "episode/length": 267.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9776119402985075, "episode/intrinsic_return": 0.0}
{"step": 764096, "time": 23290.343373060226, "episode/length": 358.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9916434540389972, "episode/intrinsic_return": 0.0}
{"step": 764312, "time": 23296.53502869606, "episode/length": 199.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.97, "episode/intrinsic_return": 0.0}
{"step": 764576, "time": 23304.15911269188, "episode/length": 164.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 764624, "time": 23306.210558891296, "episode/length": 441.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9796380090497737, "episode/intrinsic_return": 0.0}
{"step": 764872, "time": 23313.00048184395, "episode/length": 286.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9790940766550522, "episode/intrinsic_return": 0.0}
{"step": 765080, "time": 23319.03456759453, "episode/length": 207.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 765128, "time": 23321.033985853195, "episode/length": 194.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 765184, "time": 23323.4351978302, "episode/length": 299.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 765488, "time": 23331.85907316208, "episode/length": 76.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.987012987012987, "episode/intrinsic_return": 0.0}
{"step": 765728, "time": 23338.767362356186, "episode/length": 176.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 766136, "time": 23349.55770587921, "episode/length": 188.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 766184, "time": 23351.49828696251, "episode/length": 56.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 766240, "time": 23353.883189678192, "episode/length": 131.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9924242424242424, "episode/intrinsic_return": 0.0}
{"step": 766312, "time": 23356.413161993027, "episode/length": 147.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 766392, "time": 23359.126965284348, "episode/length": 226.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9823788546255506, "episode/intrinsic_return": 0.0}
{"step": 767584, "time": 23389.95980978012, "episode/length": 174.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 767648, "time": 23392.405091285706, "episode/length": 443.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9977477477477478, "episode/intrinsic_return": 0.0}
{"step": 767760, "time": 23396.17622947693, "episode/length": 202.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 767848, "time": 23399.00677728653, "episode/length": 181.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 767952, "time": 23402.65246486664, "episode/length": 213.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9813084112149533, "episode/intrinsic_return": 0.0}
{"step": 767992, "time": 23404.28453230858, "episode/length": 312.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9968051118210862, "episode/intrinsic_return": 0.0}
{"step": 768496, "time": 23417.97015953064, "episode/length": 80.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9876543209876543, "episode/intrinsic_return": 0.0}
{"step": 768768, "time": 23425.675560474396, "episode/length": 101.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9901960784313726, "episode/intrinsic_return": 0.0}
{"step": 769096, "time": 23434.661529541016, "episode/length": 180.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 769400, "time": 23443.07661962509, "episode/length": 226.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9779735682819384, "episode/intrinsic_return": 0.0}
{"step": 769592, "time": 23448.71430492401, "episode/length": 199.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.985, "episode/intrinsic_return": 0.0}
{"step": 769760, "time": 23453.83826160431, "episode/length": 430.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9791183294663574, "episode/intrinsic_return": 0.0}
{"step": 769968, "time": 23459.85895037651, "episode/length": 183.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 770016, "time": 23463.506752729416, "eval_episode/length": 46.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9787234042553191}
{"step": 770016, "time": 23465.43182516098, "eval_episode/length": 108.0, "eval_episode/score": 7.100000023841858, "eval_episode/reward_rate": 0.9908256880733946}
{"step": 770016, "time": 23466.959094047546, "eval_episode/length": 147.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9594594594594594}
{"step": 770016, "time": 23468.057997226715, "eval_episode/length": 161.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9691358024691358}
{"step": 770016, "time": 23468.8876786232, "eval_episode/length": 162.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9754601226993865}
{"step": 770016, "time": 23470.34228682518, "eval_episode/length": 146.0, "eval_episode/score": 8.099999971687794, "eval_episode/reward_rate": 0.9931972789115646}
{"step": 770016, "time": 23472.787015914917, "eval_episode/length": 170.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9766081871345029}
{"step": 770016, "time": 23473.79187631607, "eval_episode/length": 284.0, "eval_episode/score": 5.100000023841858, "eval_episode/reward_rate": 0.9789473684210527}
{"step": 770496, "time": 23485.90386581421, "episode/length": 136.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9927007299270073, "episode/intrinsic_return": 0.0}
{"step": 770584, "time": 23488.809435129166, "episode/length": 185.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 770768, "time": 23494.327246427536, "episode/length": 249.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.976, "episode/intrinsic_return": 0.0}
{"step": 771024, "time": 23501.473135471344, "episode/length": 742.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9784656796769852, "episode/intrinsic_return": 0.0}
{"step": 771200, "time": 23506.847764015198, "episode/length": 200.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9800995024875622, "episode/intrinsic_return": 0.0}
{"step": 771528, "time": 23515.819429397583, "episode/length": 220.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9864253393665159, "episode/intrinsic_return": 0.0}
{"step": 771536, "time": 23517.056977510452, "episode/length": 195.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 771544, "time": 23517.96905350685, "episode/length": 472.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9830866807610994, "episode/intrinsic_return": 0.0}
{"step": 771696, "time": 23522.89118027687, "episode/length": 83.0, "episode/score": 4.099999964237213, "episode/reward_rate": 0.9523809523809523, "episode/intrinsic_return": 0.0}
{"step": 772824, "time": 23551.609337568283, "episode/length": 161.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 772904, "time": 23554.512796401978, "episode/length": 289.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.996551724137931, "episode/intrinsic_return": 0.0}
{"step": 773080, "time": 23559.792952775955, "episode/length": 322.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9845201238390093, "episode/intrinsic_return": 0.0}
{"step": 773144, "time": 23562.26272535324, "episode/length": 242.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9958847736625515, "episode/intrinsic_return": 0.0}
{"step": 773304, "time": 23567.155884742737, "episode/length": 220.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 773528, "time": 23573.66626572609, "episode/length": 247.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9798387096774194, "episode/intrinsic_return": 0.0}
{"step": 773624, "time": 23577.00558066368, "episode/length": 356.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9943977591036415, "episode/intrinsic_return": 0.0}
{"step": 774568, "time": 23601.551693439484, "episode/length": 358.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9916434540389972, "episode/intrinsic_return": 0.0}
{"step": 774976, "time": 23612.70685195923, "episode/length": 180.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9668508287292817, "episode/intrinsic_return": 0.0}
{"step": 774976, "time": 23612.759736061096, "episode/length": 236.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 775040, "time": 23615.24089050293, "episode/length": 266.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9962546816479401, "episode/intrinsic_return": 0.0}
{"step": 775064, "time": 23616.48667860031, "episode/length": 219.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 775352, "time": 23624.497925281525, "episode/length": 275.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9963768115942029, "episode/intrinsic_return": 0.0}
{"step": 775440, "time": 23627.69006872177, "episode/length": 226.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9779735682819384, "episode/intrinsic_return": 0.0}
{"step": 776232, "time": 23647.971793174744, "episode/length": 425.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9788732394366197, "episode/intrinsic_return": 0.0}
{"step": 776568, "time": 23657.413456201553, "episode/length": 249.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.996, "episode/intrinsic_return": 0.0}
{"step": 776608, "time": 23659.42607998848, "episode/length": 203.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9656862745098039, "episode/intrinsic_return": 0.0}
{"step": 776736, "time": 23663.474079608917, "episode/length": 172.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9653179190751445, "episode/intrinsic_return": 0.0}
{"step": 776832, "time": 23666.754529476166, "episode/length": 223.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9776785714285714, "episode/intrinsic_return": 0.0}
{"step": 776840, "time": 23667.62621307373, "episode/length": 174.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 777640, "time": 23688.609127521515, "episode/length": 112.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9911504424778761, "episode/intrinsic_return": 0.0}
{"step": 777664, "time": 23690.219950199127, "episode/length": 178.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9608938547486033, "episode/intrinsic_return": 0.0}
{"step": 777704, "time": 23691.841975450516, "episode/length": 329.0, "episode/score": 10.099999964237213, "episode/reward_rate": 0.990909090909091, "episode/intrinsic_return": 0.0}
{"step": 777992, "time": 23700.183101177216, "episode/length": 143.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9652777777777778, "episode/intrinsic_return": 0.0}
{"step": 778344, "time": 23709.95517873764, "episode/length": 43.0, "episode/score": 3.100000023841858, "episode/reward_rate": 0.9090909090909091, "episode/intrinsic_return": 0.0}
{"step": 778776, "time": 23721.69783258438, "episode/length": 242.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9794238683127572, "episode/intrinsic_return": 0.0}
{"step": 778944, "time": 23726.97120976448, "episode/length": 291.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9965753424657534, "episode/intrinsic_return": 0.0}
{"step": 779080, "time": 23731.029021024704, "episode/length": 313.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9840764331210191, "episode/intrinsic_return": 0.0}
{"step": 779240, "time": 23736.10065293312, "episode/length": 191.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 779520, "time": 23744.047128677368, "episode/length": 234.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9659574468085106, "episode/intrinsic_return": 0.0}
{"step": 779528, "time": 23744.91074037552, "episode/length": 568.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9982425307557118, "episode/intrinsic_return": 0.0}
{"step": 779920, "time": 23755.74905347824, "episode/length": 281.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9893617021276596, "episode/intrinsic_return": 0.0}
{"step": 780000, "time": 23761.13274049759, "eval_episode/length": 113.0, "eval_episode/score": 9.100000023841858, "eval_episode/reward_rate": 0.9912280701754386}
{"step": 780000, "time": 23763.00267100334, "eval_episode/length": 173.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9712643678160919}
{"step": 780000, "time": 23764.51238489151, "eval_episode/length": 206.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9806763285024155}
{"step": 780000, "time": 23765.836777687073, "eval_episode/length": 230.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9783549783549783}
{"step": 780000, "time": 23767.72177052498, "eval_episode/length": 286.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9965156794425087}
{"step": 780000, "time": 23768.606985092163, "eval_episode/length": 288.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9896193771626297}
{"step": 780000, "time": 23769.717670679092, "eval_episode/length": 302.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9867986798679867}
{"step": 780000, "time": 23770.816032409668, "eval_episode/length": 197.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9747474747474747}
{"step": 780264, "time": 23777.438282728195, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 780424, "time": 23782.214032888412, "episode/length": 184.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 780696, "time": 23789.803546905518, "episode/length": 201.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 780712, "time": 23791.087246894836, "episode/length": 183.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 781248, "time": 23805.25618815422, "episode/length": 362.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9944903581267218, "episode/intrinsic_return": 0.0}
{"step": 781472, "time": 23811.728734493256, "episode/length": 242.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9711934156378601, "episode/intrinsic_return": 0.0}
{"step": 781896, "time": 23822.744266033173, "episode/length": 296.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9831649831649831, "episode/intrinsic_return": 0.0}
{"step": 781896, "time": 23822.757565259933, "episode/length": 246.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 781960, "time": 23825.216060638428, "episode/length": 191.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 782072, "time": 23828.846784591675, "episode/length": 225.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 782432, "time": 23838.895281791687, "episode/length": 216.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9723502304147466, "episode/intrinsic_return": 0.0}
{"step": 782768, "time": 23848.148307323456, "episode/length": 256.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9844357976653697, "episode/intrinsic_return": 0.0}
{"step": 782912, "time": 23852.609471321106, "episode/length": 179.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 782920, "time": 23853.48645925522, "episode/length": 208.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 783288, "time": 23863.307657003403, "episode/length": 165.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 783680, "time": 23873.94876432419, "episode/length": 222.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 783752, "time": 23876.361243724823, "episode/length": 209.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 783848, "time": 23879.714401245117, "episode/length": 176.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 784096, "time": 23886.815428495407, "episode/length": 274.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9745454545454545, "episode/intrinsic_return": 0.0}
{"step": 784104, "time": 23887.601499795914, "episode/length": 52.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 784640, "time": 23902.023220539093, "episode/length": 214.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9720930232558139, "episode/intrinsic_return": 0.0}
{"step": 784656, "time": 23903.300158262253, "episode/length": 217.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9678899082568807, "episode/intrinsic_return": 0.0}
{"step": 784696, "time": 23905.017136335373, "episode/length": 175.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 785128, "time": 23916.696719646454, "episode/length": 171.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 785344, "time": 23923.119461536407, "episode/length": 321.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 785448, "time": 23926.348568677902, "episode/length": 199.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.97, "episode/intrinsic_return": 0.0}
{"step": 785728, "time": 23934.434446811676, "episode/length": 202.0, "episode/score": 10.100000016391277, "episode/reward_rate": 0.9852216748768473, "episode/intrinsic_return": 0.0}
{"step": 785864, "time": 23938.415317058563, "episode/length": 220.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9819004524886877, "episode/intrinsic_return": 0.0}
{"step": 786272, "time": 23949.643077373505, "episode/length": 196.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 786424, "time": 23954.23785328865, "episode/length": 222.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 787136, "time": 23973.139829158783, "episode/length": 158.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9622641509433962, "episode/intrinsic_return": 0.0}
{"step": 787200, "time": 23975.631812810898, "episode/length": 258.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9961389961389961, "episode/intrinsic_return": 0.0}
{"step": 787584, "time": 23986.198622226715, "episode/length": 163.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 787800, "time": 23992.18887591362, "episode/length": 392.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9974554707379135, "episode/intrinsic_return": 0.0}
{"step": 787920, "time": 23996.315255641937, "episode/length": 186.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 787992, "time": 23998.7974152565, "episode/length": 282.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9964664310954063, "episode/intrinsic_return": 0.0}
{"step": 788064, "time": 24001.64669585228, "episode/length": 326.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9969418960244648, "episode/intrinsic_return": 0.0}
{"step": 788224, "time": 24006.613713741302, "episode/length": 359.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9972222222222222, "episode/intrinsic_return": 0.0}
{"step": 788760, "time": 24021.17204284668, "episode/length": 194.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 788952, "time": 24026.871733903885, "episode/length": 143.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 789448, "time": 24040.53951358795, "episode/length": 172.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 789464, "time": 24041.849312782288, "episode/length": 290.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9965635738831615, "episode/intrinsic_return": 0.0}
{"step": 789560, "time": 24045.17019844055, "episode/length": 204.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9804878048780488, "episode/intrinsic_return": 0.0}
{"step": 789712, "time": 24050.05494570732, "episode/length": 214.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 789984, "time": 24057.776783704758, "episode/length": 64.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9846153846153847, "episode/intrinsic_return": 0.0}
{"step": 790088, "time": 24063.47576904297, "eval_episode/length": 90.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.989010989010989}
{"step": 790088, "time": 24065.393233060837, "eval_episode/length": 152.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9738562091503268}
{"step": 790088, "time": 24066.41105389595, "eval_episode/length": 161.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9691358024691358}
{"step": 790088, "time": 24067.512110710144, "eval_episode/length": 173.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9942528735632183}
{"step": 790088, "time": 24068.531812429428, "eval_episode/length": 181.0, "eval_episode/score": 9.100000023841858, "eval_episode/reward_rate": 0.9945054945054945}
{"step": 790088, "time": 24069.553030967712, "eval_episode/length": 188.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9682539682539683}
{"step": 790088, "time": 24071.463146209717, "eval_episode/length": 53.0, "eval_episode/score": 5.0999999940395355, "eval_episode/reward_rate": 0.9814814814814815}
{"step": 790088, "time": 24073.050629377365, "eval_episode/length": 192.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9792746113989638}
{"step": 790344, "time": 24079.722784519196, "episode/length": 344.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.991304347826087, "episode/intrinsic_return": 0.0}
{"step": 790536, "time": 24085.34703040123, "episode/length": 288.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9965397923875432, "episode/intrinsic_return": 0.0}
{"step": 790584, "time": 24087.418080091476, "episode/length": 203.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 790792, "time": 24093.40425467491, "episode/length": 253.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9803149606299213, "episode/intrinsic_return": 0.0}
{"step": 791448, "time": 24110.643328666687, "episode/length": 182.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 791480, "time": 24112.316468954086, "episode/length": 253.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9960629921259843, "episode/intrinsic_return": 0.0}
{"step": 791760, "time": 24120.398362874985, "episode/length": 274.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9963636363636363, "episode/intrinsic_return": 0.0}
{"step": 791768, "time": 24121.251526117325, "episode/length": 147.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 792080, "time": 24130.27617788315, "episode/length": 192.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 792128, "time": 24132.24440407753, "episode/length": 301.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9966887417218543, "episode/intrinsic_return": 0.0}
{"step": 792512, "time": 24142.604462385178, "episode/length": 214.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 792665, "time": 24147.856912374496, "train_stats/sum_log_reward": 8.530555754899979, "train_stats/max_log_achievement_collect_coal": 0.8611111111111112, "train_stats/max_log_achievement_collect_drink": 6.131944444444445, "train_stats/max_log_achievement_collect_sapling": 1.4027777777777777, "train_stats/max_log_achievement_collect_stone": 14.01388888888889, "train_stats/max_log_achievement_collect_wood": 8.305555555555555, "train_stats/max_log_achievement_defeat_skeleton": 0.09027777777777778, "train_stats/max_log_achievement_defeat_zombie": 0.4513888888888889, "train_stats/max_log_achievement_eat_cow": 0.034722222222222224, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.9583333333333333, "train_stats/max_log_achievement_make_wood_sword": 0.006944444444444444, "train_stats/max_log_achievement_place_furnace": 0.3055555555555556, "train_stats/max_log_achievement_place_plant": 1.3472222222222223, "train_stats/max_log_achievement_place_stone": 8.958333333333334, "train_stats/max_log_achievement_place_table": 2.6458333333333335, "train_stats/max_log_achievement_wake_up": 1.9305555555555556, "train_stats/mean_log_entropy": 0.5616871148554815, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.228883310216636, "train/action_min": 0.0, "train/action_std": 3.04744777702479, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03431555313836549, "train/actor_opt_grad_steps": 48410.0, "train/actor_opt_loss": -6.125470268409609, "train/adv_mag": 0.4596420836045546, "train/adv_max": 0.4276480455905343, "train/adv_mean": 0.0026812839114690955, "train/adv_min": -0.3462548020525255, "train/adv_std": 0.051750288619367396, "train/cont_avg": 0.9951973882850241, "train/cont_loss_mean": 9.935996438299926e-05, "train/cont_loss_std": 0.002913107365535272, "train/cont_neg_acc": 0.9960240417892493, "train/cont_neg_loss": 0.010688902462630033, "train/cont_pos_acc": 0.999990487444228, "train/cont_pos_loss": 4.027312194813056e-05, "train/cont_pred": 0.9952045900810168, "train/cont_rate": 0.9951973882850241, "train/dyn_loss_mean": 13.511543075819523, "train/dyn_loss_std": 9.385376985522283, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9539396497938368, "train/extr_critic_critic_opt_grad_steps": 48410.0, "train/extr_critic_critic_opt_loss": 16004.566703464674, "train/extr_critic_mag": 7.968157694535555, "train/extr_critic_max": 7.968157694535555, "train/extr_critic_mean": 2.1058449111698905, "train/extr_critic_min": -0.2665451983898734, "train/extr_critic_std": 1.9159065150984242, "train/extr_return_normed_mag": 1.4989036742039925, "train/extr_return_normed_max": 1.4989036742039925, "train/extr_return_normed_mean": 0.3483902316738442, "train/extr_return_normed_min": -0.09177140689090542, "train/extr_return_normed_std": 0.3201457330426156, "train/extr_return_rate": 0.7368518272459795, "train/extr_return_raw_mag": 9.112807352185825, "train/extr_return_raw_max": 9.112807352185825, "train/extr_return_raw_mean": 2.12212031762957, "train/extr_return_raw_min": -0.5525247053679637, "train/extr_return_raw_std": 1.9454248291282839, "train/extr_reward_mag": 1.0242540352586387, "train/extr_reward_max": 1.0242540352586387, "train/extr_reward_mean": 0.040151576768013016, "train/extr_reward_min": -0.3819787657779196, "train/extr_reward_std": 0.18743810316790704, "train/image_loss_mean": 6.98799014667382, "train/image_loss_std": 12.227456558153825, "train/model_loss_mean": 15.149440562667477, "train/model_loss_std": 16.09437368457444, "train/model_opt_grad_norm": 59.65284473769331, "train/model_opt_grad_steps": 48366.6231884058, "train/model_opt_loss": 14678.95540600468, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 972.2222222222222, "train/policy_entropy_mag": 2.534901908054444, "train/policy_entropy_max": 2.534901908054444, "train/policy_entropy_mean": 0.5579111216148892, "train/policy_entropy_min": 0.07937502112365576, "train/policy_entropy_std": 0.657216285161926, "train/policy_logprob_mag": 7.438383650664546, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5571849025102054, "train/policy_logprob_min": -7.438383650664546, "train/policy_logprob_std": 1.1057279556269808, "train/policy_randomness_mag": 0.894709132719731, "train/policy_randomness_max": 0.894709132719731, "train/policy_randomness_mean": 0.19691814431821666, "train/policy_randomness_min": 0.028015899152499465, "train/policy_randomness_std": 0.23196850839444405, "train/post_ent_mag": 59.214291779891305, "train/post_ent_max": 59.214291779891305, "train/post_ent_mean": 42.57087661448308, "train/post_ent_min": 20.506506648040624, "train/post_ent_std": 7.524716900166682, "train/prior_ent_mag": 68.84940927846421, "train/prior_ent_max": 68.84940927846421, "train/prior_ent_mean": 56.14136521712594, "train/prior_ent_min": 41.9868312596123, "train/prior_ent_std": 4.474562054095061, "train/rep_loss_mean": 13.511543075819523, "train/rep_loss_std": 9.385376985522283, "train/reward_avg": 0.027811273248587252, "train/reward_loss_mean": 0.054425370497044157, "train/reward_loss_std": 0.24434472253357153, "train/reward_max_data": 1.015942032786383, "train/reward_max_pred": 1.0101471454049078, "train/reward_neg_acc": 0.992764633634816, "train/reward_neg_loss": 0.028501538042392995, "train/reward_pos_acc": 0.9695386463317318, "train/reward_pos_loss": 0.8357848268776125, "train/reward_pred": 0.02720642241914779, "train/reward_rate": 0.032202974033816424, "eval_stats/sum_log_reward": 7.850000187754631, "eval_stats/max_log_achievement_collect_coal": 0.59375, "eval_stats/max_log_achievement_collect_drink": 3.5, "eval_stats/max_log_achievement_collect_sapling": 1.1875, "eval_stats/max_log_achievement_collect_stone": 9.53125, "eval_stats/max_log_achievement_collect_wood": 8.4375, "eval_stats/max_log_achievement_defeat_skeleton": 0.03125, "eval_stats/max_log_achievement_defeat_zombie": 0.3125, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.96875, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.125, "eval_stats/max_log_achievement_place_plant": 1.15625, "eval_stats/max_log_achievement_place_stone": 6.15625, "eval_stats/max_log_achievement_place_table": 2.59375, "eval_stats/max_log_achievement_wake_up": 1.28125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.0027007046155631542, "report/cont_loss_std": 0.08611372113227844, "report/cont_neg_acc": 0.75, "report/cont_neg_loss": 0.689738929271698, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 6.437177944462746e-06, "report/cont_pred": 0.9970037937164307, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 12.85740852355957, "report/dyn_loss_std": 9.190576553344727, "report/image_loss_mean": 6.035250186920166, "report/image_loss_std": 13.257328033447266, "report/model_loss_mean": 13.800171852111816, "report/model_loss_std": 17.238773345947266, "report/post_ent_mag": 57.66557693481445, "report/post_ent_max": 57.66557693481445, "report/post_ent_mean": 42.3648681640625, "report/post_ent_min": 20.099933624267578, "report/post_ent_std": 7.249067306518555, "report/prior_ent_mag": 69.50843811035156, "report/prior_ent_max": 69.50843811035156, "report/prior_ent_mean": 55.46175003051758, "report/prior_ent_min": 42.23886489868164, "report/prior_ent_std": 4.613073825836182, "report/rep_loss_mean": 12.85740852355957, "report/rep_loss_std": 9.190576553344727, "report/reward_avg": 0.03027343563735485, "report/reward_loss_mean": 0.047775834798812866, "report/reward_loss_std": 0.19915874302387238, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0012240409851074, "report/reward_neg_acc": 0.9959595203399658, "report/reward_neg_loss": 0.02323608286678791, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7623156309127808, "report/reward_pred": 0.029176216572523117, "report/reward_rate": 0.033203125, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 7.975161133799702e-05, "eval/cont_loss_std": 0.0019167200662195683, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.011999189853668213, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.12656468647765e-05, "eval/cont_pred": 0.9951530694961548, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 17.873889923095703, "eval/dyn_loss_std": 11.555920600891113, "eval/image_loss_mean": 14.566557884216309, "eval/image_loss_std": 22.59506607055664, "eval/model_loss_mean": 25.396862030029297, "eval/model_loss_std": 26.891483306884766, "eval/post_ent_mag": 60.62908172607422, "eval/post_ent_max": 60.62908172607422, "eval/post_ent_mean": 40.4918212890625, "eval/post_ent_min": 20.118515014648438, "eval/post_ent_std": 7.396431922912598, "eval/prior_ent_mag": 69.50843811035156, "eval/prior_ent_max": 69.50843811035156, "eval/prior_ent_mean": 55.861839294433594, "eval/prior_ent_min": 39.802005767822266, "eval/prior_ent_std": 4.9990315437316895, "eval/rep_loss_mean": 17.873889923095703, "eval/rep_loss_std": 11.555920600891113, "eval/reward_avg": 0.04052734375, "eval/reward_loss_mean": 0.10589054226875305, "eval/reward_loss_std": 0.5227982401847839, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 1.0745022296905518, "eval/reward_neg_acc": 0.9867211580276489, "eval/reward_neg_loss": 0.051208093762397766, "eval/reward_pos_acc": 0.8888888955116272, "eval/reward_pos_loss": 1.2955377101898193, "eval/reward_pred": 0.03615284711122513, "eval/reward_rate": 0.0439453125, "replay/size": 792161.0, "replay/inserts": 33168.0, "replay/samples": 33168.0, "replay/insert_wait_avg": 1.2259709334753012e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 5.81238733301747e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 8776.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2540339119562585e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.748603820800781e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0607845783234, "timer/env.step_count": 4146.0, "timer/env.step_total": 132.8423614501953, "timer/env.step_frac": 0.13283428717406257, "timer/env.step_avg": 0.03204109055721064, "timer/env.step_min": 0.0022704601287841797, "timer/env.step_max": 0.9245445728302002, "timer/replay._sample_count": 33168.0, "timer/replay._sample_total": 2941.065542459488, "timer/replay._sample_frac": 2.9408867818965536, "timer/replay._sample_avg": 0.0886717782941235, "timer/replay._sample_min": 0.0003857612609863281, "timer/replay._sample_max": 0.11913847923278809, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5243.0, "timer/agent.policy_total": 54.37975001335144, "timer/agent.policy_frac": 0.054376444764085735, "timer/agent.policy_avg": 0.010371876790644944, "timer/agent.policy_min": 0.007840394973754883, "timer/agent.policy_max": 0.03173828125, "timer/dataset_train_count": 2073.0, "timer/dataset_train_total": 0.17213797569274902, "timer/dataset_train_frac": 0.0001721275129944538, "timer/dataset_train_avg": 8.303809729510325e-05, "timer/dataset_train_min": 6.67572021484375e-05, "timer/dataset_train_max": 0.00023555755615234375, "timer/agent.train_count": 2073.0, "timer/agent.train_total": 771.0941753387451, "timer/agent.train_frac": 0.7710473075532881, "timer/agent.train_avg": 0.37197017623673184, "timer/agent.train_min": 0.35216832160949707, "timer/agent.train_max": 0.6463792324066162, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4139890670776367, "timer/agent.report_frac": 0.00041396390445626324, "timer/agent.report_avg": 0.20699453353881836, "timer/agent.report_min": 0.2063915729522705, "timer/agent.report_max": 0.2075974941253662, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.552436828613281e-05, "timer/dataset_eval_frac": 3.552220908363255e-08, "timer/dataset_eval_avg": 3.552436828613281e-05, "timer/dataset_eval_min": 3.552436828613281e-05, "timer/dataset_eval_max": 3.552436828613281e-05, "fps": 33.1655771194337}
{"step": 792688, "time": 24148.26111483574, "episode/length": 75.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9342105263157895, "episode/intrinsic_return": 0.0}
{"step": 793416, "time": 24168.74411725998, "episode/length": 205.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 793880, "time": 24181.087943792343, "episode/length": 299.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9866666666666667, "episode/intrinsic_return": 0.0}
{"step": 793888, "time": 24182.321514368057, "episode/length": 219.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 793928, "time": 24184.003288269043, "episode/length": 447.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9799107142857143, "episode/intrinsic_return": 0.0}
{"step": 793992, "time": 24186.410521030426, "episode/length": 317.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9968553459119497, "episode/intrinsic_return": 0.0}
{"step": 794024, "time": 24188.129353761673, "episode/length": 282.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9964664310954063, "episode/intrinsic_return": 0.0}
{"step": 794264, "time": 24194.89698624611, "episode/length": 218.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 795456, "time": 24225.981714487076, "episode/length": 190.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 795480, "time": 24227.243098974228, "episode/length": 257.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9883720930232558, "episode/intrinsic_return": 0.0}
{"step": 795824, "time": 24236.86379647255, "episode/length": 242.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9958847736625515, "episode/intrinsic_return": 0.0}
{"step": 796064, "time": 24243.64867043495, "episode/length": 271.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9852941176470589, "episode/intrinsic_return": 0.0}
{"step": 796072, "time": 24244.519419431686, "episode/length": 259.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9961538461538462, "episode/intrinsic_return": 0.0}
{"step": 796088, "time": 24245.851899385452, "episode/length": 424.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9788235294117648, "episode/intrinsic_return": 0.0}
{"step": 796448, "time": 24256.015485048294, "episode/length": 123.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9596774193548387, "episode/intrinsic_return": 0.0}
{"step": 797216, "time": 24276.206188201904, "episode/length": 216.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9723502304147466, "episode/intrinsic_return": 0.0}
{"step": 797480, "time": 24283.569501161575, "episode/length": 431.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9976851851851852, "episode/intrinsic_return": 0.0}
{"step": 797608, "time": 24287.73101592064, "episode/length": 189.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 797688, "time": 24290.587700128555, "episode/length": 427.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9976635514018691, "episode/intrinsic_return": 0.0}
{"step": 797712, "time": 24292.15367269516, "episode/length": 204.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 797736, "time": 24293.33673763275, "episode/length": 208.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9808612440191388, "episode/intrinsic_return": 0.0}
{"step": 798488, "time": 24313.1466588974, "episode/length": 254.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 798872, "time": 24323.579127311707, "episode/length": 157.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 798952, "time": 24326.417561769485, "episode/length": 216.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9723502304147466, "episode/intrinsic_return": 0.0}
{"step": 798960, "time": 24327.636382102966, "episode/length": 184.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 799112, "time": 24332.184127807617, "episode/length": 177.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 799264, "time": 24336.96835041046, "episode/length": 190.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 799464, "time": 24342.60430622101, "episode/length": 218.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 799600, "time": 24347.05325651169, "episode/length": 138.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9568345323741008, "episode/intrinsic_return": 0.0}
{"step": 800064, "time": 24359.510545492172, "episode/length": 529.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9905660377358491, "episode/intrinsic_return": 0.0}
{"step": 800072, "time": 24362.506927490234, "eval_episode/length": 62.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9841269841269841}
{"step": 800072, "time": 24364.825674533844, "eval_episode/length": 145.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9657534246575342}
{"step": 800072, "time": 24366.461947202682, "eval_episode/length": 189.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9631578947368421}
{"step": 800072, "time": 24367.48937702179, "eval_episode/length": 198.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9748743718592965}
{"step": 800072, "time": 24368.522587537766, "eval_episode/length": 208.0, "eval_episode/score": 11.100000016391277, "eval_episode/reward_rate": 0.9808612440191388}
{"step": 800072, "time": 24369.902286291122, "eval_episode/length": 237.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9747899159663865}
{"step": 800072, "time": 24371.19667172432, "eval_episode/length": 261.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9809160305343512}
{"step": 800072, "time": 24372.564554214478, "eval_episode/length": 225.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9823008849557522}
{"step": 800168, "time": 24375.166353225708, "episode/length": 161.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 800344, "time": 24380.454150676727, "episode/length": 173.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 800424, "time": 24383.22651529312, "episode/length": 182.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 800928, "time": 24396.694509983063, "episode/length": 62.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9841269841269841, "episode/intrinsic_return": 0.0}
{"step": 801368, "time": 24408.468070030212, "episode/length": 220.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 801440, "time": 24411.25574874878, "episode/length": 158.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 801640, "time": 24416.838277339935, "episode/length": 315.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9968354430379747, "episode/intrinsic_return": 0.0}
{"step": 801952, "time": 24425.62876391411, "episode/length": 235.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9788135593220338, "episode/intrinsic_return": 0.0}
{"step": 801984, "time": 24427.291297912598, "episode/length": 314.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9841269841269841, "episode/intrinsic_return": 0.0}
{"step": 802024, "time": 24428.946238279343, "episode/length": 209.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9809523809523809, "episode/intrinsic_return": 0.0}
{"step": 802384, "time": 24438.705278635025, "episode/length": 44.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8888888888888888, "episode/intrinsic_return": 0.0}
{"step": 802472, "time": 24441.646013498306, "episode/length": 192.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 802528, "time": 24444.024740934372, "episode/length": 144.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9724137931034482, "episode/intrinsic_return": 0.0}
{"step": 802592, "time": 24446.444061994553, "episode/length": 415.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9903846153846154, "episode/intrinsic_return": 0.0}
{"step": 802856, "time": 24453.54475426674, "episode/length": 40.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.8780487804878049, "episode/intrinsic_return": 0.0}
{"step": 802904, "time": 24455.47986650467, "episode/length": 182.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 803568, "time": 24473.121926546097, "episode/length": 240.0, "episode/score": 10.100000016391277, "episode/reward_rate": 0.995850622406639, "episode/intrinsic_return": 0.0}
{"step": 803672, "time": 24476.3887963295, "episode/length": 149.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 803672, "time": 24476.44060754776, "episode/length": 210.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 804336, "time": 24494.337579011917, "episode/length": 184.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 804432, "time": 24497.561470270157, "episode/length": 190.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9633507853403142, "episode/intrinsic_return": 0.0}
{"step": 804544, "time": 24501.221898317337, "episode/length": 243.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 804568, "time": 24502.459557056427, "episode/length": 272.0, "episode/score": 10.100000061094761, "episode/reward_rate": 0.9963369963369964, "episode/intrinsic_return": 0.0}
{"step": 804648, "time": 24505.215498924255, "episode/length": 336.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9881305637982196, "episode/intrinsic_return": 0.0}
{"step": 804888, "time": 24511.991674661636, "episode/length": 56.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 804920, "time": 24513.67168569565, "episode/length": 168.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 805672, "time": 24533.207820415497, "episode/length": 166.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 805744, "time": 24536.13149356842, "episode/length": 258.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9961389961389961, "episode/intrinsic_return": 0.0}
{"step": 806304, "time": 24550.883249998093, "episode/length": 216.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 806488, "time": 24556.05806875229, "episode/length": 351.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 806776, "time": 24564.101536035538, "episode/length": 265.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.981203007518797, "episode/intrinsic_return": 0.0}
{"step": 806792, "time": 24565.313589334488, "episode/length": 233.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 806880, "time": 24568.532110214233, "episode/length": 141.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9647887323943662, "episode/intrinsic_return": 0.0}
{"step": 807568, "time": 24588.280433893204, "episode/length": 236.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 807664, "time": 24591.47731113434, "episode/length": 169.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9647058823529412, "episode/intrinsic_return": 0.0}
{"step": 807968, "time": 24600.00075817108, "episode/length": 427.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9789719626168224, "episode/intrinsic_return": 0.0}
{"step": 808112, "time": 24604.395525455475, "episode/length": 166.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 808320, "time": 24610.613079071045, "episode/length": 428.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9790209790209791, "episode/intrinsic_return": 0.0}
{"step": 808560, "time": 24617.502576589584, "episode/length": 220.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9819004524886877, "episode/intrinsic_return": 0.0}
{"step": 808784, "time": 24624.056046247482, "episode/length": 151.0, "episode/score": 8.100000038743019, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 808984, "time": 24629.713446617126, "episode/length": 262.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9961977186311787, "episode/intrinsic_return": 0.0}
{"step": 809480, "time": 24642.98510670662, "episode/length": 188.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 809736, "time": 24650.329215049744, "episode/length": 405.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9778325123152709, "episode/intrinsic_return": 0.0}
{"step": 809744, "time": 24651.529909849167, "episode/length": 259.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9846153846153847, "episode/intrinsic_return": 0.0}
{"step": 809912, "time": 24656.439965486526, "episode/length": 224.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 809992, "time": 24659.304424524307, "episode/length": 208.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9808612440191388, "episode/intrinsic_return": 0.0}
{"step": 810056, "time": 24665.243728399277, "eval_episode/length": 154.0, "eval_episode/score": 8.100000023841858, "eval_episode/reward_rate": 0.9935483870967742}
{"step": 810056, "time": 24666.299449920654, "eval_episode/length": 167.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9761904761904762}
{"step": 810056, "time": 24667.654265403748, "eval_episode/length": 198.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9748743718592965}
{"step": 810056, "time": 24668.843458414078, "eval_episode/length": 216.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9723502304147466}
{"step": 810056, "time": 24669.765679359436, "eval_episode/length": 218.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9771689497716894}
{"step": 810056, "time": 24670.808138370514, "eval_episode/length": 229.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9739130434782609}
{"step": 810056, "time": 24672.76301550865, "eval_episode/length": 284.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9789473684210527}
{"step": 810056, "time": 24674.14207625389, "eval_episode/length": 156.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9936305732484076}
{"step": 810672, "time": 24689.94570183754, "episode/length": 263.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 810776, "time": 24693.26696872711, "episode/length": 248.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9959839357429718, "episode/intrinsic_return": 0.0}
{"step": 810992, "time": 24699.647490024567, "episode/length": 188.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 811320, "time": 24708.406351327896, "episode/length": 165.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 811416, "time": 24711.67350792885, "episode/length": 209.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9857142857142858, "episode/intrinsic_return": 0.0}
{"step": 811424, "time": 24712.84685087204, "episode/length": 209.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 811920, "time": 24725.832102775574, "episode/length": 250.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9840637450199203, "episode/intrinsic_return": 0.0}
{"step": 812000, "time": 24728.61207509041, "episode/length": 165.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 812360, "time": 24738.24407529831, "episode/length": 197.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 812416, "time": 24740.702560663223, "episode/length": 428.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9790209790209791, "episode/intrinsic_return": 0.0}
{"step": 812648, "time": 24747.138142108917, "episode/length": 165.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.963855421686747, "episode/intrinsic_return": 0.0}
{"step": 812672, "time": 24748.78519463539, "episode/length": 209.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 812944, "time": 24756.49461555481, "episode/length": 190.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 813128, "time": 24761.854539632797, "episode/length": 56.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 813544, "time": 24772.928260087967, "episode/length": 192.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 813568, "time": 24774.51357793808, "episode/length": 267.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9776119402985075, "episode/intrinsic_return": 0.0}
{"step": 814040, "time": 24786.95104765892, "episode/length": 209.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 814072, "time": 24788.57045149803, "episode/length": 206.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9710144927536232, "episode/intrinsic_return": 0.0}
{"step": 814440, "time": 24798.636040210724, "episode/length": 186.0, "episode/score": 8.100000031292439, "episode/reward_rate": 0.9572192513368984, "episode/intrinsic_return": 0.0}
{"step": 814512, "time": 24801.512013435364, "episode/length": 323.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9907407407407407, "episode/intrinsic_return": 0.0}
{"step": 814568, "time": 24803.57691669464, "episode/length": 179.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 814808, "time": 24810.312104940414, "episode/length": 157.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 815496, "time": 24828.462829113007, "episode/length": 355.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9747191011235955, "episode/intrinsic_return": 0.0}
{"step": 815576, "time": 24831.273301124573, "episode/length": 141.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 816120, "time": 24845.945143938065, "episode/length": 200.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 816472, "time": 24855.603493452072, "episode/length": 362.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9944903581267218, "episode/intrinsic_return": 0.0}
{"step": 816560, "time": 24858.832983016968, "episode/length": 310.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9903536977491961, "episode/intrinsic_return": 0.0}
{"step": 817152, "time": 24874.633489131927, "episode/length": 128.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9612403100775194, "episode/intrinsic_return": 0.0}
{"step": 817224, "time": 24877.030281066895, "episode/length": 301.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9867549668874173, "episode/intrinsic_return": 0.0}
{"step": 817424, "time": 24883.118695259094, "episode/length": 422.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 817592, "time": 24888.11738371849, "episode/length": 251.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.996031746031746, "episode/intrinsic_return": 0.0}
{"step": 817664, "time": 24890.886957883835, "episode/length": 148.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 817672, "time": 24891.73500943184, "episode/length": 271.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 817808, "time": 24896.31728386879, "episode/length": 404.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9876543209876543, "episode/intrinsic_return": 0.0}
{"step": 817840, "time": 24897.962187051773, "episode/length": 76.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.987012987012987, "episode/intrinsic_return": 0.0}
{"step": 817904, "time": 24900.42823266983, "episode/length": 167.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 818480, "time": 24915.709806203842, "episode/length": 131.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9924242424242424, "episode/intrinsic_return": 0.0}
{"step": 819080, "time": 24931.465915203094, "episode/length": 175.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 819600, "time": 24945.74872326851, "episode/length": 223.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9866071428571429, "episode/intrinsic_return": 0.0}
{"step": 819696, "time": 24948.956345796585, "episode/length": 253.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9960629921259843, "episode/intrinsic_return": 0.0}
{"step": 819712, "time": 24950.155511379242, "episode/length": 153.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 819880, "time": 24955.0108294487, "episode/length": 254.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 820040, "time": 24963.32034111023, "eval_episode/length": 161.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9691358024691358}
{"step": 820040, "time": 24964.41294193268, "eval_episode/length": 175.0, "eval_episode/score": 9.100000023841858, "eval_episode/reward_rate": 0.9943181818181818}
{"step": 820040, "time": 24965.287204504013, "eval_episode/length": 177.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9775280898876404}
{"step": 820040, "time": 24966.457183599472, "eval_episode/length": 197.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9747474747474747}
{"step": 820040, "time": 24967.90323328972, "eval_episode/length": 227.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9956140350877193}
{"step": 820040, "time": 24969.748767614365, "eval_episode/length": 118.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.957983193277311}
{"step": 820040, "time": 24971.059955358505, "eval_episode/length": 304.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9901639344262295}
{"step": 820040, "time": 24972.6191675663, "eval_episode/length": 341.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9941520467836257}
{"step": 820136, "time": 24975.141579389572, "episode/length": 317.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9968553459119497, "episode/intrinsic_return": 0.0}
{"step": 820576, "time": 24986.9896402359, "episode/length": 427.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9789719626168224, "episode/intrinsic_return": 0.0}
{"step": 820888, "time": 24995.431614875793, "episode/length": 225.0, "episode/score": 12.100000023841858, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 821696, "time": 25016.583692073822, "episode/length": 226.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 821800, "time": 25019.85934996605, "episode/length": 486.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.997946611909651, "episode/intrinsic_return": 0.0}
{"step": 821816, "time": 25021.143962860107, "episode/length": 154.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.0}
{"step": 822104, "time": 25029.232761859894, "episode/length": 50.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9019607843137255, "episode/intrinsic_return": 0.0}
{"step": 822248, "time": 25033.636936903, "episode/length": 318.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9968652037617555, "episode/intrinsic_return": 0.0}
{"step": 822584, "time": 25042.921676158905, "episode/length": 211.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 822992, "time": 25054.367363214493, "episode/length": 356.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9915966386554622, "episode/intrinsic_return": 0.0}
{"step": 823032, "time": 25056.005415201187, "episode/length": 428.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9790209790209791, "episode/intrinsic_return": 0.0}
{"step": 823144, "time": 25059.690620422363, "episode/length": 428.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9790209790209791, "episode/intrinsic_return": 0.0}
{"step": 823264, "time": 25063.70725440979, "episode/length": 180.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 823488, "time": 25070.183714151382, "episode/length": 154.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.0}
{"step": 823632, "time": 25074.622661590576, "episode/length": 228.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 824512, "time": 25097.579697608948, "episode/length": 240.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.979253112033195, "episode/intrinsic_return": 0.0}
{"step": 824712, "time": 25103.26340031624, "episode/length": 180.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 824888, "time": 25108.458620786667, "episode/length": 236.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 825288, "time": 25119.44688987732, "episode/length": 224.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 825296, "time": 25120.708270072937, "episode/length": 268.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9739776951672863, "episode/intrinsic_return": 0.0}
{"step": 825320, "time": 25121.992480516434, "episode/length": 285.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9790209790209791, "episode/intrinsic_return": 0.0}
{"step": 825384, "time": 25124.509019374847, "episode/length": 409.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9780487804878049, "episode/intrinsic_return": 0.0}
{"step": 825760, "time": 25134.975918531418, "episode/length": 58.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9322033898305084, "episode/intrinsic_return": 0.0}
{"step": 826217, "time": 25148.001176595688, "train_stats/sum_log_reward": 8.780851340462975, "train_stats/max_log_achievement_collect_coal": 1.177304964539007, "train_stats/max_log_achievement_collect_drink": 5.560283687943262, "train_stats/max_log_achievement_collect_sapling": 1.3475177304964538, "train_stats/max_log_achievement_collect_stone": 14.340425531914894, "train_stats/max_log_achievement_collect_wood": 8.631205673758865, "train_stats/max_log_achievement_defeat_skeleton": 0.05673758865248227, "train_stats/max_log_achievement_defeat_zombie": 0.3191489361702128, "train_stats/max_log_achievement_eat_cow": 0.0851063829787234, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.553191489361702, "train_stats/max_log_achievement_make_wood_sword": 0.014184397163120567, "train_stats/max_log_achievement_place_furnace": 1.2127659574468086, "train_stats/max_log_achievement_place_plant": 1.2765957446808511, "train_stats/max_log_achievement_place_stone": 6.2695035460992905, "train_stats/max_log_achievement_place_table": 2.1134751773049647, "train_stats/max_log_achievement_wake_up": 1.5815602836879432, "train_stats/mean_log_entropy": 0.5668848800532361, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.33040771484375, "train/action_min": 0.0, "train/action_std": 3.069054167611258, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03495991773725975, "train/actor_opt_grad_steps": 50495.0, "train/actor_opt_loss": -3.501879171956153, "train/adv_mag": 0.45025842104639324, "train/adv_max": 0.4198882139864422, "train/adv_mean": 0.0035508639040233987, "train/adv_min": -0.35300114105145136, "train/adv_std": 0.05299682269493739, "train/cont_avg": 0.9950613839285715, "train/cont_loss_mean": 0.00019184823587709487, "train/cont_loss_std": 0.00576652871915474, "train/cont_neg_acc": 0.9946825399285271, "train/cont_neg_loss": 0.020219034731780994, "train/cont_pos_acc": 0.9999812719367799, "train/cont_pos_loss": 9.468084859765976e-05, "train/cont_pred": 0.9950572584356581, "train/cont_rate": 0.9950613839285715, "train/dyn_loss_mean": 13.491135733468193, "train/dyn_loss_std": 9.381100164140975, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9842160761356353, "train/extr_critic_critic_opt_grad_steps": 50495.0, "train/extr_critic_critic_opt_loss": 16193.442689732143, "train/extr_critic_mag": 8.066687502179827, "train/extr_critic_max": 8.066687502179827, "train/extr_critic_mean": 2.2810001747948783, "train/extr_critic_min": -0.2620299259821574, "train/extr_critic_std": 1.9601309038343884, "train/extr_return_normed_mag": 1.4866493310247149, "train/extr_return_normed_max": 1.4866493310247149, "train/extr_return_normed_mean": 0.3669963092321441, "train/extr_return_normed_min": -0.09134349727204867, "train/extr_return_normed_std": 0.32013123283783596, "train/extr_return_rate": 0.7723574309121994, "train/extr_return_raw_mag": 9.264092640649706, "train/extr_return_raw_max": 9.264092640649706, "train/extr_return_raw_mean": 2.3030596517381214, "train/extr_return_raw_min": -0.5466075929147857, "train/extr_return_raw_std": 1.990489377294268, "train/extr_reward_mag": 1.0241270848682948, "train/extr_reward_max": 1.0241270848682948, "train/extr_reward_mean": 0.0419425384540643, "train/extr_reward_min": -0.3992766550609044, "train/extr_reward_std": 0.19119033210334324, "train/image_loss_mean": 6.859549708593459, "train/image_loss_std": 12.426479221525646, "train/model_loss_mean": 15.007593713487898, "train/model_loss_std": 16.27307591665359, "train/model_opt_grad_norm": 54.07962528410412, "train/model_opt_grad_steps": 50450.52857142857, "train/model_opt_loss": 18819.60873558408, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1255.952380952381, "train/policy_entropy_mag": 2.4935475281306676, "train/policy_entropy_max": 2.4935475281306676, "train/policy_entropy_mean": 0.5396038044066657, "train/policy_entropy_min": 0.07937501789558501, "train/policy_entropy_std": 0.6384308416218984, "train/policy_logprob_mag": 7.43838369505746, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.539458053452628, "train/policy_logprob_min": -7.43838369505746, "train/policy_logprob_std": 1.0917206406593323, "train/policy_randomness_mag": 0.8801128520852044, "train/policy_randomness_max": 0.8801128520852044, "train/policy_randomness_mean": 0.19045646297080177, "train/policy_randomness_min": 0.02801589806165014, "train/policy_randomness_std": 0.2253380707332066, "train/post_ent_mag": 59.13705974760509, "train/post_ent_max": 59.13705974760509, "train/post_ent_mean": 42.58657424563453, "train/post_ent_min": 20.387605985005695, "train/post_ent_std": 7.513935661315918, "train/prior_ent_mag": 68.9583893912179, "train/prior_ent_max": 68.9583893912179, "train/prior_ent_mean": 56.15776472545805, "train/prior_ent_min": 41.95508353823707, "train/prior_ent_std": 4.473818922042847, "train/rep_loss_mean": 13.491135733468193, "train/rep_loss_std": 9.381100164140975, "train/reward_avg": 0.027922711889481262, "train/reward_loss_mean": 0.05317083571460985, "train/reward_loss_std": 0.23683083263181504, "train/reward_max_data": 1.0161904800505865, "train/reward_max_pred": 1.0103433444386436, "train/reward_neg_acc": 0.9934188593001593, "train/reward_neg_loss": 0.027319384978285857, "train/reward_pos_acc": 0.9726725575469789, "train/reward_pos_loss": 0.8297375781195504, "train/reward_pred": 0.027120061733183407, "train/reward_rate": 0.03226841517857143, "eval_stats/sum_log_reward": 8.725000202655792, "eval_stats/max_log_achievement_collect_coal": 1.0833333333333333, "eval_stats/max_log_achievement_collect_drink": 3.4583333333333335, "eval_stats/max_log_achievement_collect_sapling": 1.375, "eval_stats/max_log_achievement_collect_stone": 12.416666666666666, "eval_stats/max_log_achievement_collect_wood": 7.708333333333333, "eval_stats/max_log_achievement_defeat_skeleton": 0.08333333333333333, "eval_stats/max_log_achievement_defeat_zombie": 0.2916666666666667, "eval_stats/max_log_achievement_eat_cow": 0.041666666666666664, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.3333333333333333, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.9583333333333334, "eval_stats/max_log_achievement_place_plant": 1.375, "eval_stats/max_log_achievement_place_stone": 4.916666666666667, "eval_stats/max_log_achievement_place_table": 2.2083333333333335, "eval_stats/max_log_achievement_wake_up": 1.6666666666666667, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 1.4622487469750922e-06, "report/cont_loss_std": 2.037657395703718e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00011808610724983737, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 1.0049003549283952e-06, "report/cont_pred": 0.9960932731628418, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 13.014748573303223, "report/dyn_loss_std": 9.560027122497559, "report/image_loss_mean": 6.514033317565918, "report/image_loss_std": 11.578169822692871, "report/model_loss_mean": 14.377541542053223, "report/model_loss_std": 15.642380714416504, "report/post_ent_mag": 57.8327751159668, "report/post_ent_max": 57.8327751159668, "report/post_ent_mean": 43.23776626586914, "report/post_ent_min": 21.584239959716797, "report/post_ent_std": 7.628481864929199, "report/prior_ent_mag": 68.55326843261719, "report/prior_ent_max": 68.55326843261719, "report/prior_ent_mean": 56.20817947387695, "report/prior_ent_min": 37.893287658691406, "report/prior_ent_std": 4.287646770477295, "report/rep_loss_mean": 13.014748573303223, "report/rep_loss_std": 9.560027122497559, "report/reward_avg": 0.02646484225988388, "report/reward_loss_mean": 0.05465715378522873, "report/reward_loss_std": 0.26794642210006714, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0023977756500244, "report/reward_neg_acc": 0.9979838132858276, "report/reward_neg_loss": 0.02541157975792885, "report/reward_pos_acc": 0.9375, "report/reward_pos_loss": 0.9612698554992676, "report/reward_pred": 0.02405008301138878, "report/reward_rate": 0.03125, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 0.00011248322698520496, "eval/cont_loss_std": 0.0035242713056504726, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0008462955593131483, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.00011176591215189546, "eval/cont_pred": 0.9989186525344849, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 19.752197265625, "eval/dyn_loss_std": 11.08202075958252, "eval/image_loss_mean": 12.59910774230957, "eval/image_loss_std": 19.165945053100586, "eval/model_loss_mean": 24.539424896240234, "eval/model_loss_std": 23.647432327270508, "eval/post_ent_mag": 60.791717529296875, "eval/post_ent_max": 60.791717529296875, "eval/post_ent_mean": 40.349082946777344, "eval/post_ent_min": 20.53407096862793, "eval/post_ent_std": 7.629950046539307, "eval/prior_ent_mag": 68.55326843261719, "eval/prior_ent_max": 68.55326843261719, "eval/prior_ent_mean": 57.019615173339844, "eval/prior_ent_min": 40.91947937011719, "eval/prior_ent_std": 4.026823043823242, "eval/rep_loss_mean": 19.752197265625, "eval/rep_loss_std": 11.08202075958252, "eval/reward_avg": 0.03681640326976776, "eval/reward_loss_mean": 0.08888708800077438, "eval/reward_loss_std": 0.5686590671539307, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.006422758102417, "eval/reward_neg_acc": 0.9969543218612671, "eval/reward_neg_loss": 0.04099670797586441, "eval/reward_pos_acc": 0.8974359035491943, "eval/reward_pos_loss": 1.2984262704849243, "eval/reward_pred": 0.031756505370140076, "eval/reward_rate": 0.0380859375, "replay/size": 825713.0, "replay/inserts": 33552.0, "replay/samples": 33552.0, "replay/insert_wait_avg": 1.2477040006594823e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 5.800225476622866e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 7544.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2350739755155174e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.387731552124023e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1279809474945, "timer/env.step_count": 4194.0, "timer/env.step_total": 131.44764304161072, "timer/env.step_frac": 0.13143082240042994, "timer/env.step_avg": 0.03134183191263966, "timer/env.step_min": 0.0023758411407470703, "timer/env.step_max": 0.9491238594055176, "timer/replay._sample_count": 33552.0, "timer/replay._sample_total": 2976.8182384967804, "timer/replay._sample_frac": 2.9764373112295313, "timer/replay._sample_avg": 0.0887225273753213, "timer/replay._sample_min": 0.00047135353088378906, "timer/replay._sample_max": 0.12033700942993164, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5137.0, "timer/agent.policy_total": 53.3852014541626, "timer/agent.policy_frac": 0.053378370039789194, "timer/agent.policy_avg": 0.010392291503632975, "timer/agent.policy_min": 0.007775306701660156, "timer/agent.policy_max": 0.018421649932861328, "timer/dataset_train_count": 2097.0, "timer/dataset_train_total": 0.1755208969116211, "timer/dataset_train_frac": 0.00017549843645543972, "timer/dataset_train_avg": 8.370095227068245e-05, "timer/dataset_train_min": 6.246566772460938e-05, "timer/dataset_train_max": 0.0002579689025878906, "timer/agent.train_count": 2097.0, "timer/agent.train_total": 780.2005591392517, "timer/agent.train_frac": 0.780100721109823, "timer/agent.train_avg": 0.37205558375739234, "timer/agent.train_min": 0.3535888195037842, "timer/agent.train_max": 1.9854745864868164, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4186851978302002, "timer/agent.report_frac": 0.0004186316209586987, "timer/agent.report_avg": 0.2093425989151001, "timer/agent.report_min": 0.2087554931640625, "timer/agent.report_max": 0.2099297046661377, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.695487976074219e-05, "timer/dataset_eval_frac": 3.6950150845426925e-08, "timer/dataset_eval_avg": 3.695487976074219e-05, "timer/dataset_eval_min": 3.695487976074219e-05, "timer/dataset_eval_max": 3.695487976074219e-05, "fps": 33.5471988671753}
{"step": 826368, "time": 25151.766913175583, "episode/length": 184.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 826472, "time": 25155.051894903183, "episode/length": 354.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9943661971830986, "episode/intrinsic_return": 0.0}
{"step": 826712, "time": 25161.999932050705, "episode/length": 42.0, "episode/score": 6.100000038743019, "episode/reward_rate": 0.9302325581395349, "episode/intrinsic_return": 0.0}
{"step": 826912, "time": 25168.06530046463, "episode/length": 201.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9653465346534653, "episode/intrinsic_return": 0.0}
{"step": 826912, "time": 25168.117131233215, "episode/length": 190.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 827624, "time": 25186.764639377594, "episode/length": 388.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9922879177377892, "episode/intrinsic_return": 0.0}
{"step": 827632, "time": 25188.020860671997, "episode/length": 288.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.972318339100346, "episode/intrinsic_return": 0.0}
{"step": 828128, "time": 25201.518025636673, "episode/length": 426.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9789227166276346, "episode/intrinsic_return": 0.0}
{"step": 828144, "time": 25202.75539135933, "episode/length": 153.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 828496, "time": 25212.612245082855, "episode/length": 197.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9646464646464646, "episode/intrinsic_return": 0.0}
{"step": 829184, "time": 25230.752755880356, "episode/length": 427.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 829240, "time": 25232.888612508774, "episode/length": 345.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9913294797687862, "episode/intrinsic_return": 0.0}
{"step": 829248, "time": 25234.136229991913, "episode/length": 202.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 829448, "time": 25239.78255701065, "episode/length": 226.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9779735682819384, "episode/intrinsic_return": 0.0}
{"step": 829552, "time": 25243.388797283173, "episode/length": 131.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9924242424242424, "episode/intrinsic_return": 0.0}
{"step": 829560, "time": 25244.30659675598, "episode/length": 178.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 829576, "time": 25245.646047592163, "episode/length": 357.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9860335195530726, "episode/intrinsic_return": 0.0}
{"step": 829616, "time": 25247.648956537247, "episode/length": 183.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 830024, "time": 25260.550270318985, "eval_episode/length": 67.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9411764705882353}
{"step": 830024, "time": 25262.80631351471, "eval_episode/length": 148.0, "eval_episode/score": 7.099999971687794, "eval_episode/reward_rate": 0.9932885906040269}
{"step": 830024, "time": 25263.846933841705, "eval_episode/length": 157.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9620253164556962}
{"step": 830024, "time": 25265.116086483, "eval_episode/length": 180.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9779005524861878}
{"step": 830024, "time": 25266.63018965721, "eval_episode/length": 212.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9671361502347418}
{"step": 830024, "time": 25267.522272348404, "eval_episode/length": 214.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9767441860465116}
{"step": 830024, "time": 25268.450736761093, "eval_episode/length": 215.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9953703703703703}
{"step": 830024, "time": 25269.65828061104, "eval_episode/length": 232.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.9785407725321889}
{"step": 830072, "time": 25271.058121442795, "episode/length": 64.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9846153846153847, "episode/intrinsic_return": 0.0}
{"step": 830656, "time": 25286.792028665543, "episode/length": 183.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 830968, "time": 25295.18859910965, "episode/length": 215.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 831504, "time": 25309.646621465683, "episode/length": 281.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9964539007092199, "episode/intrinsic_return": 0.0}
{"step": 831576, "time": 25312.065937280655, "episode/length": 265.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 831960, "time": 25322.71587586403, "episode/length": 47.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.8958333333333334, "episode/intrinsic_return": 0.0}
{"step": 831960, "time": 25322.771064519882, "episode/length": 123.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9919354838709677, "episode/intrinsic_return": 0.0}
{"step": 832072, "time": 25326.516188383102, "episode/length": 311.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9967948717948718, "episode/intrinsic_return": 0.0}
{"step": 833000, "time": 25350.72148990631, "episode/length": 429.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9790697674418605, "episode/intrinsic_return": 0.0}
{"step": 833040, "time": 25352.671197652817, "episode/length": 427.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9976635514018691, "episode/intrinsic_return": 0.0}
{"step": 833232, "time": 25358.43701028824, "episode/length": 215.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9675925925925926, "episode/intrinsic_return": 0.0}
{"step": 833248, "time": 25359.66991496086, "episode/length": 323.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 833280, "time": 25361.324366807938, "episode/length": 164.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 833576, "time": 25369.276659488678, "episode/length": 437.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9794520547945206, "episode/intrinsic_return": 0.0}
{"step": 833664, "time": 25372.45813012123, "episode/length": 212.0, "episode/score": 8.100000031292439, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 834048, "time": 25383.12069606781, "episode/length": 246.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9757085020242915, "episode/intrinsic_return": 0.0}
{"step": 834336, "time": 25391.147797822952, "episode/length": 135.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9926470588235294, "episode/intrinsic_return": 0.0}
{"step": 834472, "time": 25395.40629720688, "episode/length": 178.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 834648, "time": 25400.557565689087, "episode/length": 205.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9805825242718447, "episode/intrinsic_return": 0.0}
{"step": 835232, "time": 25416.259970664978, "episode/length": 243.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 835320, "time": 25419.264964580536, "episode/length": 158.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 835992, "time": 25436.919591903687, "episode/length": 344.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9797101449275363, "episode/intrinsic_return": 0.0}
{"step": 835992, "time": 25436.973932027817, "episode/length": 167.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9583333333333334, "episode/intrinsic_return": 0.0}
{"step": 836168, "time": 25442.227309703827, "episode/length": 228.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 836640, "time": 25455.182548046112, "episode/length": 175.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 836696, "time": 25457.214797735214, "episode/length": 378.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9973614775725593, "episode/intrinsic_return": 0.0}
{"step": 836704, "time": 25458.34758400917, "episode/length": 390.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9769820971867008, "episode/intrinsic_return": 0.0}
{"step": 836920, "time": 25464.257524490356, "episode/length": 115.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9913793103448276, "episode/intrinsic_return": 0.0}
{"step": 837624, "time": 25482.604191064835, "episode/length": 393.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9898477157360406, "episode/intrinsic_return": 0.0}
{"step": 837632, "time": 25483.81052994728, "episode/length": 288.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.986159169550173, "episode/intrinsic_return": 0.0}
{"step": 837736, "time": 25487.112378835678, "episode/length": 136.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9927007299270073, "episode/intrinsic_return": 0.0}
{"step": 838144, "time": 25498.26220679283, "episode/length": 268.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9962825278810409, "episode/intrinsic_return": 0.0}
{"step": 838536, "time": 25508.58412027359, "episode/length": 229.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 838600, "time": 25511.00497698784, "episode/length": 303.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9967105263157895, "episode/intrinsic_return": 0.0}
{"step": 838624, "time": 25512.612253427505, "episode/length": 110.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.990990990990991, "episode/intrinsic_return": 0.0}
{"step": 838872, "time": 25519.620747566223, "episode/length": 154.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9612903225806452, "episode/intrinsic_return": 0.0}
{"step": 838992, "time": 25523.64677977562, "episode/length": 48.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.8979591836734694, "episode/intrinsic_return": 0.0}
{"step": 839368, "time": 25533.87648844719, "episode/length": 217.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 839640, "time": 25541.496831178665, "episode/length": 186.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 839720, "time": 25544.35852956772, "episode/length": 349.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9885714285714285, "episode/intrinsic_return": 0.0}
{"step": 840008, "time": 25556.05161881447, "eval_episode/length": 176.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9661016949152542}
{"step": 840008, "time": 25557.521362543106, "eval_episode/length": 212.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9765258215962441}
{"step": 840008, "time": 25558.621042966843, "eval_episode/length": 227.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9780701754385965}
{"step": 840008, "time": 25559.550829172134, "eval_episode/length": 229.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9956521739130435}
{"step": 840008, "time": 25561.62556862831, "eval_episode/length": 287.0, "eval_episode/score": 10.100000023841858, "eval_episode/reward_rate": 0.9965277777777778}
{"step": 840008, "time": 25562.796433210373, "eval_episode/length": 90.0, "eval_episode/score": 6.100000023841858, "eval_episode/reward_rate": 0.989010989010989}
{"step": 840008, "time": 25563.864470005035, "eval_episode/length": 314.0, "eval_episode/score": 9.099999979138374, "eval_episode/reward_rate": 0.9968253968253968}
{"step": 840008, "time": 25564.841872930527, "eval_episode/length": 322.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9814241486068112}
{"step": 840056, "time": 25566.2468419075, "episode/length": 418.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9928400954653938, "episode/intrinsic_return": 0.0}
{"step": 840304, "time": 25573.620754241943, "episode/length": 178.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 840472, "time": 25578.451900959015, "episode/length": 93.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9468085106382979, "episode/intrinsic_return": 0.0}
{"step": 840680, "time": 25584.53630924225, "episode/length": 129.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9923076923076923, "episode/intrinsic_return": 0.0}
{"step": 840784, "time": 25588.15912795067, "episode/length": 176.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 840912, "time": 25592.437328100204, "episode/length": 285.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 840944, "time": 25594.21408724785, "episode/length": 58.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 841632, "time": 25612.515820741653, "episode/length": 386.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 841736, "time": 25615.829305648804, "episode/length": 178.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 841880, "time": 25620.392937898636, "episode/length": 116.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9914529914529915, "episode/intrinsic_return": 0.0}
{"step": 842064, "time": 25626.05438065529, "episode/length": 53.0, "episode/score": 5.100000016391277, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 842104, "time": 25627.66892027855, "episode/length": 255.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.96484375, "episode/intrinsic_return": 0.0}
{"step": 842368, "time": 25635.31511950493, "episode/length": 60.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9344262295081968, "episode/intrinsic_return": 0.0}
{"step": 842408, "time": 25636.990478754044, "episode/length": 426.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9789227166276346, "episode/intrinsic_return": 0.0}
{"step": 842544, "time": 25641.507617473602, "episode/length": 203.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 842728, "time": 25646.793471097946, "episode/length": 255.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.984375, "episode/intrinsic_return": 0.0}
{"step": 843536, "time": 25668.15466952324, "episode/length": 343.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 843664, "time": 25672.320497751236, "episode/length": 240.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.995850622406639, "episode/intrinsic_return": 0.0}
{"step": 843944, "time": 25680.313101768494, "episode/length": 229.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9739130434782609, "episode/intrinsic_return": 0.0}
{"step": 844008, "time": 25682.80060529709, "episode/length": 182.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 844176, "time": 25688.174322128296, "episode/length": 180.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 844856, "time": 25706.04483795166, "episode/length": 164.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 845080, "time": 25712.626272201538, "episode/length": 376.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9973474801061007, "episode/intrinsic_return": 0.0}
{"step": 845136, "time": 25714.972514390945, "episode/length": 345.0, "episode/score": 10.100000031292439, "episode/reward_rate": 0.9913294797687862, "episode/intrinsic_return": 0.0}
{"step": 845512, "time": 25725.182882785797, "episode/length": 187.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 845576, "time": 25727.622725248337, "episode/length": 395.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 845872, "time": 25736.643408298492, "episode/length": 211.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 845896, "time": 25737.86535000801, "episode/length": 243.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 847000, "time": 25767.05494403839, "episode/length": 137.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9927536231884058, "episode/intrinsic_return": 0.0}
{"step": 847064, "time": 25769.535839557648, "episode/length": 424.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9788235294117648, "episode/intrinsic_return": 0.0}
{"step": 847376, "time": 25779.28088259697, "episode/length": 314.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9746031746031746, "episode/intrinsic_return": 0.0}
{"step": 847400, "time": 25780.5557949543, "episode/length": 289.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.996551724137931, "episode/intrinsic_return": 0.0}
{"step": 847872, "time": 25794.0816218853, "episode/length": 286.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9790940766550522, "episode/intrinsic_return": 0.0}
{"step": 848176, "time": 25802.792670965195, "episode/length": 287.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9895833333333334, "episode/intrinsic_return": 0.0}
{"step": 848272, "time": 25806.034107923508, "episode/length": 49.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.94, "episode/intrinsic_return": 0.0}
{"step": 848600, "time": 25815.116287231445, "episode/length": 432.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9792147806004619, "episode/intrinsic_return": 0.0}
{"step": 848664, "time": 25817.61137318611, "episode/length": 393.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9923857868020305, "episode/intrinsic_return": 0.0}
{"step": 848824, "time": 25822.66647219658, "episode/length": 219.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 849088, "time": 25830.34221482277, "episode/length": 60.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 849456, "time": 25841.147387504578, "episode/length": 159.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 849584, "time": 25845.424911499023, "episode/length": 322.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9814241486068112, "episode/intrinsic_return": 0.0}
{"step": 849616, "time": 25847.08410835266, "episode/length": 118.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9915966386554622, "episode/intrinsic_return": 0.0}
{"step": 850096, "time": 25862.868927001953, "eval_episode/length": 57.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9310344827586207}
{"step": 850096, "time": 25864.281349658966, "eval_episode/length": 81.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9878048780487805}
{"step": 850096, "time": 25867.513558864594, "eval_episode/length": 135.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9705882352941176}
{"step": 850096, "time": 25868.802272558212, "eval_episode/length": 217.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9954128440366973}
{"step": 850096, "time": 25869.746906518936, "eval_episode/length": 222.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9955156950672646}
{"step": 850096, "time": 25871.484491825104, "eval_episode/length": 269.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9740740740740741}
{"step": 850096, "time": 25872.467832565308, "eval_episode/length": 195.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9744897959183674}
{"step": 850096, "time": 25873.536242723465, "eval_episode/length": 288.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9896193771626297}
{"step": 850152, "time": 25875.02265071869, "episode/length": 346.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9913544668587896, "episode/intrinsic_return": 0.0}
{"step": 850680, "time": 25889.920656442642, "episode/length": 152.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 850744, "time": 25892.48237133026, "episode/length": 206.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 850808, "time": 25894.960399627686, "episode/length": 425.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9976525821596244, "episode/intrinsic_return": 0.0}
{"step": 850864, "time": 25897.37143778801, "episode/length": 159.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 850880, "time": 25898.68187880516, "episode/length": 325.0, "episode/score": 10.099999964237213, "episode/reward_rate": 0.99079754601227, "episode/intrinsic_return": 0.0}
{"step": 850968, "time": 25901.561381340027, "episode/length": 168.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 851048, "time": 25904.442645311356, "episode/length": 45.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 851272, "time": 25910.897278547287, "episode/length": 305.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9967320261437909, "episode/intrinsic_return": 0.0}
{"step": 851888, "time": 25927.486953020096, "episode/length": 127.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9609375, "episode/intrinsic_return": 0.0}
{"step": 852272, "time": 25938.041439056396, "episode/length": 182.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 852440, "time": 25942.836236715317, "episode/length": 145.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.958904109589041, "episode/intrinsic_return": 0.0}
{"step": 852648, "time": 25949.02702999115, "episode/length": 311.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 853008, "time": 25959.24605178833, "episode/length": 244.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 853080, "time": 25961.654475688934, "episode/length": 148.0, "episode/score": 11.099999949336052, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 853160, "time": 25964.50760936737, "episode/length": 284.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.968421052631579, "episode/intrinsic_return": 0.0}
{"step": 853352, "time": 25970.044459342957, "episode/length": 325.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.99079754601227, "episode/intrinsic_return": 0.0}
{"step": 853512, "time": 25974.836418628693, "episode/length": 317.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9905660377358491, "episode/intrinsic_return": 0.0}
{"step": 853568, "time": 25977.214465618134, "episode/length": 50.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 853616, "time": 25979.277705669403, "episode/length": 167.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 854048, "time": 25990.985739946365, "episode/length": 59.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9166666666666666, "episode/intrinsic_return": 0.0}
{"step": 854168, "time": 25994.71370100975, "episode/length": 215.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 854736, "time": 26010.18448472023, "episode/length": 172.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 855104, "time": 26020.42082953453, "episode/length": 306.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.996742671009772, "episode/intrinsic_return": 0.0}
{"step": 855280, "time": 26025.729570388794, "episode/length": 283.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9753521126760564, "episode/intrinsic_return": 0.0}
{"step": 855352, "time": 26028.141956329346, "episode/length": 162.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 855632, "time": 26036.269970417023, "episode/length": 111.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9910714285714286, "episode/intrinsic_return": 0.0}
{"step": 855744, "time": 26039.939296007156, "episode/length": 265.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9962406015037594, "episode/intrinsic_return": 0.0}
{"step": 855904, "time": 26044.8813893795, "episode/length": 298.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9832775919732442, "episode/intrinsic_return": 0.0}
{"step": 855992, "time": 26047.78894352913, "episode/length": 227.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 856096, "time": 26051.352184295654, "episode/length": 376.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9920424403183024, "episode/intrinsic_return": 0.0}
{"step": 856600, "time": 26064.646941184998, "episode/length": 186.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9679144385026738, "episode/intrinsic_return": 0.0}
{"step": 856784, "time": 26070.330243349075, "episode/length": 178.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 857056, "time": 26078.084813833237, "episode/length": 163.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 857648, "time": 26094.0944981575, "episode/length": 206.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9710144927536232, "episode/intrinsic_return": 0.0}
{"step": 857688, "time": 26095.79585003853, "episode/length": 222.0, "episode/score": 9.100000016391277, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 857832, "time": 26100.185034751892, "episode/length": 153.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 857912, "time": 26103.021425008774, "episode/length": 226.0, "episode/score": 10.10000005364418, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 858296, "time": 26113.69815969467, "episode/length": 376.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9973474801061007, "episode/intrinsic_return": 0.0}
{"step": 858320, "time": 26115.275578975677, "episode/length": 335.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 858520, "time": 26120.956643104553, "episode/length": 108.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.944954128440367, "episode/intrinsic_return": 0.0}
{"step": 858592, "time": 26123.849509954453, "episode/length": 112.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9911504424778761, "episode/intrinsic_return": 0.0}
{"step": 858864, "time": 26131.59730744362, "episode/length": 225.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 858912, "time": 26133.638597488403, "episode/length": 265.0, "episode/score": 9.1000000461936, "episode/reward_rate": 0.9962406015037594, "episode/intrinsic_return": 0.0}
{"step": 859000, "time": 26136.59247803688, "episode/length": 145.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.958904109589041, "episode/intrinsic_return": 0.0}
{"step": 859401, "time": 26148.33003616333, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.29648372631718, "train/action_min": 0.0, "train/action_std": 3.1028750610812277, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.034969830939519234, "train/actor_opt_grad_steps": 52580.0, "train/actor_opt_loss": 1.0906181501017675, "train/adv_mag": 0.4594644447743605, "train/adv_max": 0.4202001525296105, "train/adv_mean": 0.004602768580992492, "train/adv_min": -0.3736307175407087, "train/adv_std": 0.053045812940252, "train/cont_avg": 0.9949992451690821, "train/cont_loss_mean": 0.00022443824909722988, "train/cont_loss_std": 0.006563218852338398, "train/cont_neg_acc": 0.9931576521072573, "train/cont_neg_loss": 0.02029868823740675, "train/cont_pos_acc": 0.9999524988414009, "train/cont_pos_loss": 0.0001394139399687697, "train/cont_pred": 0.9949716168325304, "train/cont_rate": 0.9949992451690821, "train/dyn_loss_mean": 13.324410535287166, "train/dyn_loss_std": 9.381501488063646, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0245729984292662, "train/extr_critic_critic_opt_grad_steps": 52580.0, "train/extr_critic_critic_opt_loss": 16214.927984412741, "train/extr_critic_mag": 8.572395389206743, "train/extr_critic_max": 8.572395389206743, "train/extr_critic_mean": 2.687698135053478, "train/extr_critic_min": -0.2649633026353403, "train/extr_critic_std": 2.1022126018137173, "train/extr_return_normed_mag": 1.4530249327277216, "train/extr_return_normed_max": 1.4530249327277216, "train/extr_return_normed_mean": 0.39146579204550114, "train/extr_return_normed_min": -0.0968280393216345, "train/extr_return_normed_std": 0.32091393195776546, "train/extr_return_rate": 0.8383096001574383, "train/extr_return_raw_mag": 9.78714354602611, "train/extr_return_raw_max": 9.78714354602611, "train/extr_return_raw_mean": 2.718305940789301, "train/extr_return_raw_min": -0.5396784109193922, "train/extr_return_raw_std": 2.1397090493768887, "train/extr_reward_mag": 1.0252921466090252, "train/extr_reward_max": 1.0252921466090252, "train/extr_reward_mean": 0.04282566567585952, "train/extr_reward_min": -0.3992267829784449, "train/extr_reward_std": 0.1931445643953655, "train/image_loss_mean": 6.873753080045543, "train/image_loss_std": 12.435916732474801, "train/model_loss_mean": 14.923282323828065, "train/model_loss_std": 16.310883310106064, "train/model_opt_grad_norm": 55.120896500665786, "train/model_opt_grad_steps": 52533.59420289855, "train/model_opt_loss": 19850.042478109903, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1340.5797101449275, "train/policy_entropy_mag": 2.4558267109635947, "train/policy_entropy_max": 2.4558267109635947, "train/policy_entropy_mean": 0.5274719420262581, "train/policy_entropy_min": 0.07937501622858831, "train/policy_entropy_std": 0.6356770450942182, "train/policy_logprob_mag": 7.438383682914402, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5276774814451374, "train/policy_logprob_min": -7.438383682914402, "train/policy_logprob_std": 1.0802758027965895, "train/policy_randomness_mag": 0.8667990588335599, "train/policy_randomness_max": 0.8667990588335599, "train/policy_randomness_mean": 0.18617444899347094, "train/policy_randomness_min": 0.028015897478818316, "train/policy_randomness_std": 0.2243661019537184, "train/post_ent_mag": 59.13452511478737, "train/post_ent_max": 59.13452511478737, "train/post_ent_mean": 42.74804357630043, "train/post_ent_min": 20.555931671806004, "train/post_ent_std": 7.476269825645115, "train/prior_ent_mag": 69.01882455429593, "train/prior_ent_max": 69.01882455429593, "train/prior_ent_mean": 56.15600998735658, "train/prior_ent_min": 41.31942312268243, "train/prior_ent_std": 4.527737238556867, "train/rep_loss_mean": 13.324410535287166, "train/rep_loss_std": 9.381501488063646, "train/reward_avg": 0.0280245128830058, "train/reward_loss_mean": 0.054658586186343346, "train/reward_loss_std": 0.2444471688086284, "train/reward_max_data": 1.017391308494236, "train/reward_max_pred": 1.012140124892267, "train/reward_neg_acc": 0.993016202956582, "train/reward_neg_loss": 0.028481069277378097, "train/reward_pos_acc": 0.9709330837507755, "train/reward_pos_loss": 0.8384496489008844, "train/reward_pred": 0.027189490763281567, "train/reward_rate": 0.03245301177536232, "train_stats/sum_log_reward": 9.017241593064933, "train_stats/max_log_achievement_collect_coal": 1.282758620689655, "train_stats/max_log_achievement_collect_drink": 5.048275862068966, "train_stats/max_log_achievement_collect_sapling": 1.296551724137931, "train_stats/max_log_achievement_collect_stone": 15.179310344827586, "train_stats/max_log_achievement_collect_wood": 7.255172413793104, "train_stats/max_log_achievement_defeat_skeleton": 0.1103448275862069, "train_stats/max_log_achievement_defeat_zombie": 0.3448275862068966, "train_stats/max_log_achievement_eat_cow": 0.08275862068965517, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.710344827586207, "train_stats/max_log_achievement_make_wood_sword": 0.027586206896551724, "train_stats/max_log_achievement_place_furnace": 2.524137931034483, "train_stats/max_log_achievement_place_plant": 1.2758620689655173, "train_stats/max_log_achievement_place_stone": 2.5172413793103448, "train_stats/max_log_achievement_place_table": 2.179310344827586, "train_stats/max_log_achievement_wake_up": 1.6206896551724137, "train_stats/mean_log_entropy": 0.5688051250474206, "eval_stats/sum_log_reward": 8.725000123182932, "eval_stats/max_log_achievement_collect_coal": 0.75, "eval_stats/max_log_achievement_collect_drink": 3.8333333333333335, "eval_stats/max_log_achievement_collect_sapling": 1.2083333333333333, "eval_stats/max_log_achievement_collect_stone": 14.0, "eval_stats/max_log_achievement_collect_wood": 8.375, "eval_stats/max_log_achievement_defeat_skeleton": 0.041666666666666664, "eval_stats/max_log_achievement_defeat_zombie": 0.25, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.75, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 2.2083333333333335, "eval_stats/max_log_achievement_place_plant": 1.1666666666666667, "eval_stats/max_log_achievement_place_stone": 2.5833333333333335, "eval_stats/max_log_achievement_place_table": 2.4166666666666665, "eval_stats/max_log_achievement_wake_up": 1.0416666666666667, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 1.1578530575206969e-05, "report/cont_loss_std": 0.0003643633972387761, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.002337581478059292, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.653653356470386e-07, "report/cont_pred": 0.9951284527778625, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 11.738358497619629, "report/dyn_loss_std": 8.995637893676758, "report/image_loss_mean": 5.133008003234863, "report/image_loss_std": 10.23743724822998, "report/model_loss_mean": 12.220806121826172, "report/model_loss_std": 13.789316177368164, "report/post_ent_mag": 60.01055908203125, "report/post_ent_max": 60.01055908203125, "report/post_ent_mean": 43.396209716796875, "report/post_ent_min": 17.968307495117188, "report/post_ent_std": 7.94202995300293, "report/prior_ent_mag": 69.3093032836914, "report/prior_ent_max": 69.3093032836914, "report/prior_ent_mean": 55.346351623535156, "report/prior_ent_min": 40.22492599487305, "report/prior_ent_std": 4.535618305206299, "report/rep_loss_mean": 11.738358497619629, "report/rep_loss_std": 8.995637893676758, "report/reward_avg": 0.02705078199505806, "report/reward_loss_mean": 0.04477187246084213, "report/reward_loss_std": 0.19188499450683594, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.000990390777588, "report/reward_neg_acc": 0.9949545860290527, "report/reward_neg_loss": 0.01982639729976654, "report/reward_pos_acc": 0.9696969389915466, "report/reward_pos_loss": 0.7938920855522156, "report/reward_pred": 0.02611708641052246, "report/reward_rate": 0.0322265625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 3.1144688250606123e-07, "eval/cont_loss_std": 5.886844064662e-06, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 1.2351567420409992e-05, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 2.642306924371951e-07, "eval/cont_pred": 0.9960935711860657, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 18.772838592529297, "eval/dyn_loss_std": 11.24887752532959, "eval/image_loss_mean": 14.523996353149414, "eval/image_loss_std": 17.492225646972656, "eval/model_loss_mean": 25.873321533203125, "eval/model_loss_std": 21.662500381469727, "eval/post_ent_mag": 55.793540954589844, "eval/post_ent_max": 55.793540954589844, "eval/post_ent_mean": 39.68829345703125, "eval/post_ent_min": 20.395282745361328, "eval/post_ent_std": 7.296956539154053, "eval/prior_ent_mag": 69.3093032836914, "eval/prior_ent_max": 69.3093032836914, "eval/prior_ent_mean": 55.852081298828125, "eval/prior_ent_min": 42.34901428222656, "eval/prior_ent_std": 4.595227241516113, "eval/rep_loss_mean": 18.772838592529297, "eval/rep_loss_std": 11.24887752532959, "eval/reward_avg": 0.05390624701976776, "eval/reward_loss_mean": 0.08562339842319489, "eval/reward_loss_std": 0.4427633583545685, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0044784545898438, "eval/reward_neg_acc": 0.9844560027122498, "eval/reward_neg_loss": 0.03158546984195709, "eval/reward_pos_acc": 0.9661017060279846, "eval/reward_pos_loss": 0.9694642424583435, "eval/reward_pred": 0.05537701025605202, "eval/reward_rate": 0.0576171875, "replay/size": 858897.0, "replay/inserts": 33184.0, "replay/samples": 33184.0, "replay/insert_wait_avg": 1.283145169282948e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 6.282628444719452e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 6760.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2897528134859525e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.493661880493164e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3163998126984, "timer/env.step_count": 4148.0, "timer/env.step_total": 134.18179631233215, "timer/env.step_frac": 0.1341393546456468, "timer/env.step_avg": 0.03234855263074546, "timer/env.step_min": 0.002320528030395508, "timer/env.step_max": 1.1385109424591064, "timer/replay._sample_count": 33184.0, "timer/replay._sample_total": 2983.1169481277466, "timer/replay._sample_frac": 2.9821733890260247, "timer/replay._sample_avg": 0.08989624361522862, "timer/replay._sample_min": 0.0003833770751953125, "timer/replay._sample_max": 0.12205386161804199, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4993.0, "timer/agent.policy_total": 51.88622307777405, "timer/agent.policy_frac": 0.05186981147913735, "timer/agent.policy_avg": 0.010391793125931113, "timer/agent.policy_min": 0.007717609405517578, "timer/agent.policy_max": 0.05025672912597656, "timer/dataset_train_count": 2074.0, "timer/dataset_train_total": 0.1809215545654297, "timer/dataset_train_frac": 0.00018086432912557053, "timer/dataset_train_avg": 8.723315070657169e-05, "timer/dataset_train_min": 7.081031799316406e-05, "timer/dataset_train_max": 0.00027489662170410156, "timer/agent.train_count": 2074.0, "timer/agent.train_total": 779.9260423183441, "timer/agent.train_frac": 0.7796793519174327, "timer/agent.train_avg": 0.3760492007320849, "timer/agent.train_min": 0.351959228515625, "timer/agent.train_max": 0.5660033226013184, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4066038131713867, "timer/agent.report_frac": 0.0004064752044928187, "timer/agent.report_avg": 0.20330190658569336, "timer/agent.report_min": 0.20238876342773438, "timer/agent.report_max": 0.20421504974365234, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.266334533691406e-05, "timer/dataset_eval_frac": 3.265301392942276e-08, "timer/dataset_eval_avg": 3.266334533691406e-05, "timer/dataset_eval_min": 3.266334533691406e-05, "timer/dataset_eval_max": 3.266334533691406e-05, "fps": 33.173069965137934}
{"step": 859904, "time": 26161.104306697845, "episode/length": 112.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9557522123893806, "episode/intrinsic_return": 0.0}
{"step": 860080, "time": 26168.288406848907, "eval_episode/length": 62.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9841269841269841}
{"step": 860080, "time": 26171.276689767838, "eval_episode/length": 181.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9560439560439561}
{"step": 860080, "time": 26172.14375090599, "eval_episode/length": 182.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9672131147540983}
{"step": 860080, "time": 26173.220558404922, "eval_episode/length": 189.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9947368421052631}
{"step": 860080, "time": 26174.184829950333, "eval_episode/length": 193.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.9742268041237113}
{"step": 860080, "time": 26175.67082643509, "eval_episode/length": 222.0, "eval_episode/score": 8.099999971687794, "eval_episode/reward_rate": 0.9955156950672646}
{"step": 860080, "time": 26177.06223464012, "eval_episode/length": 62.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9206349206349206}
{"step": 860080, "time": 26178.132405519485, "eval_episode/length": 82.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9397590361445783}
{"step": 860168, "time": 26180.444077014923, "episode/length": 196.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 860232, "time": 26182.93258547783, "episode/length": 238.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9832635983263598, "episode/intrinsic_return": 0.0}
{"step": 860240, "time": 26184.143661022186, "episode/length": 214.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 860264, "time": 26185.435814380646, "episode/length": 44.0, "episode/score": 7.10000005364418, "episode/reward_rate": 0.9555555555555556, "episode/intrinsic_return": 0.0}
{"step": 860480, "time": 26191.843951940536, "episode/length": 320.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9968847352024922, "episode/intrinsic_return": 0.0}
{"step": 860600, "time": 26195.472066879272, "episode/length": 216.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 860800, "time": 26201.526547193527, "episode/length": 312.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9840255591054313, "episode/intrinsic_return": 0.0}
{"step": 861768, "time": 26226.725239038467, "episode/length": 356.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9971988795518207, "episode/intrinsic_return": 0.0}
{"step": 861864, "time": 26230.015342712402, "episode/length": 203.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 862096, "time": 26236.831231355667, "episode/length": 228.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9781659388646288, "episode/intrinsic_return": 0.0}
{"step": 862152, "time": 26238.94274377823, "episode/length": 168.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 862984, "time": 26260.64702272415, "episode/length": 312.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9936102236421726, "episode/intrinsic_return": 0.0}
{"step": 863408, "time": 26272.293284893036, "episode/length": 192.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 863456, "time": 26274.400406599045, "episode/length": 410.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9781021897810219, "episode/intrinsic_return": 0.0}
{"step": 863488, "time": 26275.999795675278, "episode/length": 405.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 863592, "time": 26279.190539598465, "episode/length": 227.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 863768, "time": 26284.37556552887, "episode/length": 395.0, "episode/score": 11.1000000461936, "episode/reward_rate": 0.9873737373737373, "episode/intrinsic_return": 0.0}
{"step": 865000, "time": 26315.994998931885, "episode/length": 192.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 865176, "time": 26321.191660642624, "episode/length": 197.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 865248, "time": 26324.032807826996, "episode/length": 219.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 865320, "time": 26326.474870443344, "episode/length": 402.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9950372208436724, "episode/intrinsic_return": 0.0}
{"step": 865632, "time": 26335.4338927269, "episode/length": 232.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9699570815450643, "episode/intrinsic_return": 0.0}
{"step": 865664, "time": 26337.10942006111, "episode/length": 438.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9886104783599089, "episode/intrinsic_return": 0.0}
{"step": 865800, "time": 26341.106904745102, "episode/length": 298.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9866220735785953, "episode/intrinsic_return": 0.0}
{"step": 866392, "time": 26356.756876945496, "episode/length": 425.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 866544, "time": 26361.575830936432, "episode/length": 170.0, "episode/score": 6.1000000312924385, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 866616, "time": 26364.022891521454, "episode/length": 170.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 867320, "time": 26382.613151073456, "episode/length": 206.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 867464, "time": 26386.985409498215, "episode/length": 228.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 867480, "time": 26388.251289367676, "episode/length": 209.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 867608, "time": 26392.239630699158, "episode/length": 285.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.986013986013986, "episode/intrinsic_return": 0.0}
{"step": 867720, "time": 26395.911809682846, "episode/length": 165.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 867928, "time": 26401.9738008976, "episode/length": 172.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 868376, "time": 26414.211440324783, "episode/length": 219.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 868904, "time": 26428.11782860756, "episode/length": 177.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 869040, "time": 26432.517221212387, "episode/length": 504.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.998019801980198, "episode/intrinsic_return": 0.0}
{"step": 869288, "time": 26439.558127880096, "episode/length": 209.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 869632, "time": 26449.121654510498, "episode/length": 212.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 869976, "time": 26458.463482379913, "episode/length": 199.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 870064, "time": 26463.542811393738, "eval_episode/length": 59.0, "eval_episode/score": 5.099999971687794, "eval_episode/reward_rate": 0.9833333333333333}
{"step": 870064, "time": 26465.787296295166, "eval_episode/length": 138.0, "eval_episode/score": 9.100000023841858, "eval_episode/reward_rate": 0.9928057553956835}
{"step": 870064, "time": 26467.33167910576, "eval_episode/length": 178.0, "eval_episode/score": 10.099999979138374, "eval_episode/reward_rate": 0.994413407821229}
{"step": 870064, "time": 26468.406771183014, "eval_episode/length": 189.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9578947368421052}
{"step": 870064, "time": 26469.27108025551, "eval_episode/length": 191.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9791666666666666}
{"step": 870064, "time": 26470.500494480133, "eval_episode/length": 208.0, "eval_episode/score": 10.100000023841858, "eval_episode/reward_rate": 0.9952153110047847}
{"step": 870064, "time": 26471.416378974915, "eval_episode/length": 213.0, "eval_episode/score": 8.099999994039536, "eval_episode/reward_rate": 0.9953271028037384}
{"step": 870064, "time": 26473.734919309616, "eval_episode/length": 74.0, "eval_episode/score": 8.100000023841858, "eval_episode/reward_rate": 0.9866666666666667}
{"step": 870176, "time": 26476.648082256317, "episode/length": 306.0, "episode/score": 10.099999964237213, "episode/reward_rate": 0.990228013029316, "episode/intrinsic_return": 0.0}
{"step": 870632, "time": 26488.771928548813, "episode/length": 124.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.96, "episode/intrinsic_return": 0.0}
{"step": 870792, "time": 26493.62039589882, "episode/length": 433.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 870816, "time": 26495.22538280487, "episode/length": 418.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9904534606205251, "episode/intrinsic_return": 0.0}
{"step": 871096, "time": 26503.007335424423, "episode/length": 57.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 871408, "time": 26511.915511608124, "episode/length": 153.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 871472, "time": 26514.410056829453, "episode/length": 303.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9802631578947368, "episode/intrinsic_return": 0.0}
{"step": 871496, "time": 26515.702896118164, "episode/length": 189.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.968421052631579, "episode/intrinsic_return": 0.0}
{"step": 872032, "time": 26530.22266125679, "episode/length": 390.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9974424552429667, "episode/intrinsic_return": 0.0}
{"step": 872112, "time": 26532.984577178955, "episode/length": 352.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9971671388101983, "episode/intrinsic_return": 0.0}
{"step": 872280, "time": 26537.849915742874, "episode/length": 182.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 872360, "time": 26540.624619483948, "episode/length": 195.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 872872, "time": 26554.156615257263, "episode/length": 171.0, "episode/score": 6.100000016391277, "episode/reward_rate": 0.9825581395348837, "episode/intrinsic_return": 0.0}
{"step": 873208, "time": 26563.283044099808, "episode/length": 224.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 873384, "time": 26568.500562667847, "episode/length": 168.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9644970414201184, "episode/intrinsic_return": 0.0}
{"step": 873440, "time": 26570.904633283615, "episode/length": 165.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 873568, "time": 26575.03949213028, "episode/length": 308.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9967637540453075, "episode/intrinsic_return": 0.0}
{"step": 873584, "time": 26576.273640871048, "episode/length": 162.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9815950920245399, "episode/intrinsic_return": 0.0}
{"step": 873784, "time": 26582.022584438324, "episode/length": 288.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9792387543252595, "episode/intrinsic_return": 0.0}
{"step": 874160, "time": 26592.47958946228, "episode/length": 224.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 874576, "time": 26603.66056060791, "episode/length": 170.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 874776, "time": 26609.436060667038, "episode/length": 173.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9540229885057471, "episode/intrinsic_return": 0.0}
{"step": 875080, "time": 26617.721143245697, "episode/length": 186.0, "episode/score": 11.099999964237213, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 875192, "time": 26621.393716812134, "episode/length": 289.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.996551724137931, "episode/intrinsic_return": 0.0}
{"step": 875264, "time": 26624.209644794464, "episode/length": 227.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 875472, "time": 26630.225417375565, "episode/length": 210.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 875840, "time": 26640.26646757126, "episode/length": 283.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9894366197183099, "episode/intrinsic_return": 0.0}
{"step": 876952, "time": 26668.740914344788, "episode/length": 233.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 877000, "time": 26670.812315940857, "episode/length": 144.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 877120, "time": 26674.91169333458, "episode/length": 205.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 877288, "time": 26679.800452947617, "episode/length": 390.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9948849104859335, "episode/intrinsic_return": 0.0}
{"step": 877328, "time": 26681.931567907333, "episode/length": 343.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9854651162790697, "episode/intrinsic_return": 0.0}
{"step": 877352, "time": 26683.184236764908, "episode/length": 321.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.984472049689441, "episode/intrinsic_return": 0.0}
{"step": 877472, "time": 26687.145466566086, "episode/length": 275.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 877984, "time": 26700.74130177498, "episode/length": 348.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.997134670487106, "episode/intrinsic_return": 0.0}
{"step": 878208, "time": 26707.077405929565, "episode/length": 135.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9632352941176471, "episode/intrinsic_return": 0.0}
{"step": 878528, "time": 26715.827187538147, "episode/length": 146.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 878632, "time": 26719.0678794384, "episode/length": 203.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 878792, "time": 26723.913869857788, "episode/length": 164.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 878816, "time": 26725.493213176727, "episode/length": 190.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 878992, "time": 26730.73068022728, "episode/length": 254.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.996078431372549, "episode/intrinsic_return": 0.0}
{"step": 879664, "time": 26748.14915370941, "episode/length": 291.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9965753424657534, "episode/intrinsic_return": 0.0}
{"step": 879736, "time": 26750.59966135025, "episode/length": 218.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 879752, "time": 26751.74750304222, "episode/length": 192.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 880008, "time": 26758.995414495468, "episode/length": 184.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 880048, "time": 26762.865516662598, "eval_episode/length": 62.0, "eval_episode/score": 3.0999999716877937, "eval_episode/reward_rate": 0.9841269841269841}
{"step": 880048, "time": 26765.268552303314, "eval_episode/length": 150.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9933774834437086}
{"step": 880048, "time": 26766.25279855728, "eval_episode/length": 159.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.98125}
{"step": 880048, "time": 26767.14601778984, "eval_episode/length": 161.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9938271604938271}
{"step": 880048, "time": 26768.11426472664, "eval_episode/length": 169.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9764705882352941}
{"step": 880048, "time": 26769.067747831345, "eval_episode/length": 174.0, "eval_episode/score": 10.100000023841858, "eval_episode/reward_rate": 0.9942857142857143}
{"step": 880048, "time": 26770.078501701355, "eval_episode/length": 184.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9783783783783784}
{"step": 880048, "time": 26771.46298956871, "eval_episode/length": 210.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.976303317535545}
{"step": 880280, "time": 26777.27792572975, "episode/length": 185.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 880488, "time": 26783.32623553276, "episode/length": 208.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 880808, "time": 26792.36533021927, "episode/length": 142.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 881064, "time": 26799.64831328392, "episode/length": 303.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9802631578947368, "episode/intrinsic_return": 0.0}
{"step": 881184, "time": 26803.71954512596, "episode/length": 180.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 881392, "time": 26809.659326553345, "episode/length": 299.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 881640, "time": 26816.65977549553, "episode/length": 235.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 881840, "time": 26822.60630965233, "episode/length": 55.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 882416, "time": 26837.965671300888, "episode/length": 240.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.970954356846473, "episode/intrinsic_return": 0.0}
{"step": 882552, "time": 26841.973479270935, "episode/length": 185.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 882728, "time": 26847.267045736313, "episode/length": 239.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 883104, "time": 26857.66054701805, "episode/length": 157.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 883296, "time": 26863.466311454773, "episode/length": 206.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 883408, "time": 26867.105725049973, "episode/length": 424.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9929411764705882, "episode/intrinsic_return": 0.0}
{"step": 883568, "time": 26871.960032463074, "episode/length": 297.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9832214765100671, "episode/intrinsic_return": 0.0}
{"step": 883688, "time": 26875.707362651825, "episode/length": 425.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9788732394366197, "episode/intrinsic_return": 0.0}
{"step": 883736, "time": 26877.688081026077, "episode/length": 147.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 884456, "time": 26896.335360765457, "episode/length": 215.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 884872, "time": 26907.54169178009, "episode/length": 182.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9617486338797814, "episode/intrinsic_return": 0.0}
{"step": 885048, "time": 26912.739773988724, "episode/length": 242.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9876543209876543, "episode/intrinsic_return": 0.0}
{"step": 885264, "time": 26919.075204133987, "episode/length": 211.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 885456, "time": 26924.677765130997, "episode/length": 269.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9962962962962963, "episode/intrinsic_return": 0.0}
{"step": 885672, "time": 26930.69002175331, "episode/length": 241.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9793388429752066, "episode/intrinsic_return": 0.0}
{"step": 885768, "time": 26933.95747256279, "episode/length": 163.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 886000, "time": 26940.861331939697, "episode/length": 447.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9799107142857143, "episode/intrinsic_return": 0.0}
{"step": 886224, "time": 26947.218981981277, "episode/length": 168.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9881656804733728, "episode/intrinsic_return": 0.0}
{"step": 886240, "time": 26948.553693532944, "episode/length": 318.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9717868338557993, "episode/intrinsic_return": 0.0}
{"step": 886952, "time": 26966.98975133896, "episode/length": 147.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 887032, "time": 26969.873586177826, "episode/length": 128.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9922480620155039, "episode/intrinsic_return": 0.0}
{"step": 887440, "time": 26981.176464796066, "episode/length": 220.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 887640, "time": 26986.97189307213, "episode/length": 176.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 887848, "time": 26992.963798999786, "episode/length": 111.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9910714285714286, "episode/intrinsic_return": 0.0}
{"step": 888032, "time": 26998.668422698975, "episode/length": 321.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9968944099378882, "episode/intrinsic_return": 0.0}
{"step": 888464, "time": 27010.589835882187, "episode/length": 426.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9789227166276346, "episode/intrinsic_return": 0.0}
{"step": 888568, "time": 27013.850569725037, "episode/length": 412.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9903147699757869, "episode/intrinsic_return": 0.0}
{"step": 888808, "time": 27020.629429340363, "episode/length": 221.0, "episode/score": 11.099999964237213, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 888984, "time": 27025.927442789078, "episode/length": 342.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9912536443148688, "episode/intrinsic_return": 0.0}
{"step": 889104, "time": 27029.860639572144, "episode/length": 182.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 889872, "time": 27049.96014070511, "episode/length": 229.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 889968, "time": 27053.234946012497, "episode/length": 315.0, "episode/score": 10.099999964237213, "episode/reward_rate": 0.9873417721518988, "episode/intrinsic_return": 0.0}
{"step": 890032, "time": 27058.55701994896, "eval_episode/length": 116.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.9572649572649573}
{"step": 890032, "time": 27060.696553468704, "eval_episode/length": 188.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9788359788359788}
{"step": 890032, "time": 27062.119956731796, "eval_episode/length": 220.0, "eval_episode/score": 10.100000023841858, "eval_episode/reward_rate": 0.9683257918552036}
{"step": 890032, "time": 27063.592727184296, "eval_episode/length": 253.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9960629921259843}
{"step": 890032, "time": 27064.87705016136, "eval_episode/length": 55.0, "eval_episode/score": 7.099999979138374, "eval_episode/reward_rate": 0.9821428571428571}
{"step": 890032, "time": 27065.897944927216, "eval_episode/length": 283.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.971830985915493}
{"step": 890032, "time": 27067.25773024559, "eval_episode/length": 56.0, "eval_episode/score": 4.099999971687794, "eval_episode/reward_rate": 0.9824561403508771}
{"step": 890032, "time": 27068.40247154236, "eval_episode/length": 208.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9760765550239234}
{"step": 890384, "time": 27077.54414153099, "episode/length": 316.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9905362776025236, "episode/intrinsic_return": 0.0}
{"step": 890456, "time": 27079.94776558876, "episode/length": 183.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 891128, "time": 27097.707379579544, "episode/length": 144.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9724137931034482, "episode/intrinsic_return": 0.0}
{"step": 891456, "time": 27106.995856285095, "episode/length": 293.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 891544, "time": 27109.94048666954, "episode/length": 208.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 891776, "time": 27116.785142183304, "episode/length": 370.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9919137466307277, "episode/intrinsic_return": 0.0}
{"step": 892008, "time": 27123.462054014206, "episode/length": 429.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9790697674418605, "episode/intrinsic_return": 0.0}
{"step": 892072, "time": 27125.863714694977, "episode/length": 450.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9800443458980045, "episode/intrinsic_return": 0.0}
{"step": 892480, "time": 27136.942593812943, "episode/length": 252.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9802371541501976, "episode/intrinsic_return": 0.0}
{"step": 892889, "time": 27148.606616973877, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.1576175963479365, "train/action_min": 0.0, "train/action_std": 2.992636203765869, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03259843318727598, "train/actor_opt_grad_steps": 54660.0, "train/actor_opt_loss": -11.299286295494964, "train/adv_mag": 0.44863344208475503, "train/adv_max": 0.4139413263951762, "train/adv_mean": 0.0017454970394243845, "train/adv_min": -0.3617890765222066, "train/adv_std": 0.04970870487855382, "train/cont_avg": 0.995159240430622, "train/cont_loss_mean": 0.00020812763218572375, "train/cont_loss_std": 0.0064613698270604486, "train/cont_neg_acc": 0.9933379132014054, "train/cont_neg_loss": 0.026165335420212335, "train/cont_pos_acc": 0.9999765288886842, "train/cont_pos_loss": 8.07245909537167e-05, "train/cont_pred": 0.995160708016756, "train/cont_rate": 0.995159240430622, "train/dyn_loss_mean": 13.349340037295693, "train/dyn_loss_std": 9.355905313811233, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9753865591076573, "train/extr_critic_critic_opt_grad_steps": 54660.0, "train/extr_critic_critic_opt_loss": 15869.90683406848, "train/extr_critic_mag": 9.291612456289775, "train/extr_critic_max": 9.291612456289775, "train/extr_critic_mean": 2.836390520967365, "train/extr_critic_min": -0.23339286033046303, "train/extr_critic_std": 2.2317293260656474, "train/extr_return_normed_mag": 1.4340295677550101, "train/extr_return_normed_max": 1.4340295677550101, "train/extr_return_normed_mean": 0.383421224484033, "train/extr_return_normed_min": -0.0882098534140005, "train/extr_return_normed_std": 0.31573775453430614, "train/extr_return_rate": 0.8529973283909155, "train/extr_return_raw_mag": 10.371756850247177, "train/extr_return_raw_max": 10.371756850247177, "train/extr_return_raw_mean": 2.848888550648849, "train/extr_return_raw_min": -0.52887004236, "train/extr_return_raw_std": 2.261063234087383, "train/extr_reward_mag": 1.0300832376525733, "train/extr_reward_max": 1.0300832376525733, "train/extr_reward_mean": 0.043968957282923625, "train/extr_reward_min": -0.40484988347194983, "train/extr_reward_std": 0.1964276621929196, "train/image_loss_mean": 6.802279324052437, "train/image_loss_std": 12.498771708547784, "train/model_loss_mean": 14.865934554469643, "train/model_loss_std": 16.319469315013247, "train/model_opt_grad_norm": 53.03465326015766, "train/model_opt_grad_steps": 54611.64114832536, "train/model_opt_loss": 19966.84717497757, "train/model_opt_model_opt_grad_overflow": 0.004784688995215311, "train/model_opt_model_opt_grad_scale": 1339.7129186602872, "train/policy_entropy_mag": 2.476045584564574, "train/policy_entropy_max": 2.476045584564574, "train/policy_entropy_mean": 0.5000676797907888, "train/policy_entropy_min": 0.0793750153132603, "train/policy_entropy_std": 0.6244044765901338, "train/policy_logprob_mag": 7.4383837663385854, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.4998340107607499, "train/policy_logprob_min": -7.4383837663385854, "train/policy_logprob_std": 1.0645140078649566, "train/policy_randomness_mag": 0.8739354333809118, "train/policy_randomness_max": 0.8739354333809118, "train/policy_randomness_mean": 0.17650194608708888, "train/policy_randomness_min": 0.028015897168140663, "train/policy_randomness_std": 0.22038737852037238, "train/post_ent_mag": 59.40320957676646, "train/post_ent_max": 59.40320957676646, "train/post_ent_mean": 42.821570547003496, "train/post_ent_min": 20.507279081207713, "train/post_ent_std": 7.558617256474837, "train/prior_ent_mag": 69.07245252691388, "train/prior_ent_max": 69.07245252691388, "train/prior_ent_mean": 56.266910717247775, "train/prior_ent_min": 41.68737119464783, "train/prior_ent_std": 4.483260169553985, "train/rep_loss_mean": 13.349340037295693, "train/rep_loss_std": 9.355905313811233, "train/reward_avg": 0.028380120774668654, "train/reward_loss_mean": 0.053843128160711684, "train/reward_loss_std": 0.24331359693593385, "train/reward_max_data": 1.0167464154759092, "train/reward_max_pred": 1.013149088079279, "train/reward_neg_acc": 0.9929567957608894, "train/reward_neg_loss": 0.02772875973714168, "train/reward_pos_acc": 0.9734034002112429, "train/reward_pos_loss": 0.8287537445862327, "train/reward_pred": 0.02773608953544968, "train/reward_rate": 0.032656436901913874, "train_stats/sum_log_reward": 9.368656927080297, "train_stats/max_log_achievement_collect_coal": 1.2014925373134329, "train_stats/max_log_achievement_collect_drink": 6.253731343283582, "train_stats/max_log_achievement_collect_sapling": 1.2164179104477613, "train_stats/max_log_achievement_collect_stone": 16.723880597014926, "train_stats/max_log_achievement_collect_wood": 8.992537313432836, "train_stats/max_log_achievement_defeat_skeleton": 0.11194029850746269, "train_stats/max_log_achievement_defeat_zombie": 0.373134328358209, "train_stats/max_log_achievement_eat_cow": 0.05970149253731343, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.014925373134328358, "train_stats/max_log_achievement_make_wood_pickaxe": 2.2388059701492535, "train_stats/max_log_achievement_make_wood_sword": 0.022388059701492536, "train_stats/max_log_achievement_place_furnace": 2.5223880597014925, "train_stats/max_log_achievement_place_plant": 1.1791044776119404, "train_stats/max_log_achievement_place_stone": 3.91044776119403, "train_stats/max_log_achievement_place_table": 2.3358208955223883, "train_stats/max_log_achievement_wake_up": 1.7313432835820894, "train_stats/mean_log_entropy": 0.5384448783388779, "eval_stats/sum_log_reward": 8.475000187754631, "eval_stats/max_log_achievement_collect_coal": 0.625, "eval_stats/max_log_achievement_collect_drink": 3.375, "eval_stats/max_log_achievement_collect_sapling": 1.0625, "eval_stats/max_log_achievement_collect_stone": 12.21875, "eval_stats/max_log_achievement_collect_wood": 6.46875, "eval_stats/max_log_achievement_defeat_skeleton": 0.09375, "eval_stats/max_log_achievement_defeat_zombie": 0.21875, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.65625, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 1.4375, "eval_stats/max_log_achievement_place_plant": 1.0625, "eval_stats/max_log_achievement_place_stone": 3.21875, "eval_stats/max_log_achievement_place_table": 1.78125, "eval_stats/max_log_achievement_wake_up": 0.9375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 3.0152121325954795e-05, "report/cont_loss_std": 0.0004888433031737804, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.002787936246022582, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 1.1170322977704927e-05, "report/cont_pred": 0.9931720495223999, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 15.250509262084961, "report/dyn_loss_std": 9.266544342041016, "report/image_loss_mean": 6.143172740936279, "report/image_loss_std": 9.657929420471191, "report/model_loss_mean": 15.345587730407715, "report/model_loss_std": 13.713255882263184, "report/post_ent_mag": 57.81470489501953, "report/post_ent_max": 57.81470489501953, "report/post_ent_mean": 40.77875900268555, "report/post_ent_min": 20.994951248168945, "report/post_ent_std": 7.251938819885254, "report/prior_ent_mag": 68.86235046386719, "report/prior_ent_max": 68.86235046386719, "report/prior_ent_mean": 56.06416320800781, "report/prior_ent_min": 38.08622741699219, "report/prior_ent_std": 4.734447956085205, "report/rep_loss_mean": 15.250509262084961, "report/rep_loss_std": 9.266544342041016, "report/reward_avg": 0.03750000149011612, "report/reward_loss_mean": 0.05207984894514084, "report/reward_loss_std": 0.19836023449897766, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0011143684387207, "report/reward_neg_acc": 0.9949030876159668, "report/reward_neg_loss": 0.023266436532139778, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7094275951385498, "report/reward_pred": 0.038173288106918335, "report/reward_rate": 0.0419921875, "eval/cont_avg": 0.9931640625, "eval/cont_loss_mean": 3.276002826169133e-05, "eval/cont_loss_std": 0.00073493632953614, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.004669065587222576, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 8.483880264975596e-07, "eval/cont_pred": 0.9931948781013489, "eval/cont_rate": 0.9931640625, "eval/dyn_loss_mean": 18.933155059814453, "eval/dyn_loss_std": 10.372456550598145, "eval/image_loss_mean": 15.549201011657715, "eval/image_loss_std": 19.461305618286133, "eval/model_loss_mean": 27.055156707763672, "eval/model_loss_std": 23.271791458129883, "eval/post_ent_mag": 59.2890739440918, "eval/post_ent_max": 59.2890739440918, "eval/post_ent_mean": 40.520408630371094, "eval/post_ent_min": 21.163818359375, "eval/post_ent_std": 7.389742374420166, "eval/prior_ent_mag": 68.86235046386719, "eval/prior_ent_max": 68.86235046386719, "eval/prior_ent_mean": 56.88959503173828, "eval/prior_ent_min": 42.65843963623047, "eval/prior_ent_std": 4.339582920074463, "eval/rep_loss_mean": 18.933155059814453, "eval/rep_loss_std": 10.372456550598145, "eval/reward_avg": 0.05449219048023224, "eval/reward_loss_mean": 0.1460297852754593, "eval/reward_loss_std": 0.7326138019561768, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0034608840942383, "eval/reward_neg_acc": 0.9937695264816284, "eval/reward_neg_loss": 0.04178503155708313, "eval/reward_pos_acc": 0.7868852615356445, "eval/reward_pos_loss": 1.7917300462722778, "eval/reward_pred": 0.043289512395858765, "eval/reward_rate": 0.0595703125, "replay/size": 892385.0, "replay/inserts": 33488.0, "replay/samples": 33488.0, "replay/insert_wait_avg": 1.2384481083760122e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 5.833523386241259e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 8728.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.257707174495204e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.003545761108398e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.256498336792, "timer/env.step_count": 4186.0, "timer/env.step_total": 125.26377940177917, "timer/env.step_frac": 0.12523165768986802, "timer/env.step_avg": 0.02992445757328695, "timer/env.step_min": 0.002361774444580078, "timer/env.step_max": 0.9009230136871338, "timer/replay._sample_count": 33488.0, "timer/replay._sample_total": 2981.943651199341, "timer/replay._sample_frac": 2.9811789837483302, "timer/replay._sample_avg": 0.08904514008598127, "timer/replay._sample_min": 0.0004024505615234375, "timer/replay._sample_max": 0.11927175521850586, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5277.0, "timer/agent.policy_total": 54.7457230091095, "timer/agent.policy_frac": 0.05473168442308515, "timer/agent.policy_avg": 0.010374402692649137, "timer/agent.policy_min": 0.007622241973876953, "timer/agent.policy_max": 0.018728971481323242, "timer/dataset_train_count": 2093.0, "timer/dataset_train_total": 0.17601823806762695, "timer/dataset_train_frac": 0.00017597310125983367, "timer/dataset_train_avg": 8.409853706050022e-05, "timer/dataset_train_min": 6.222724914550781e-05, "timer/dataset_train_max": 0.0001838207244873047, "timer/agent.train_count": 2093.0, "timer/agent.train_total": 778.6308853626251, "timer/agent.train_frac": 0.778431219049632, "timer/agent.train_avg": 0.372016667636228, "timer/agent.train_min": 0.35335826873779297, "timer/agent.train_max": 0.5822398662567139, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.41072511672973633, "timer/agent.report_frac": 0.0004106197934356662, "timer/agent.report_avg": 0.20536255836486816, "timer/agent.report_min": 0.20449471473693848, "timer/agent.report_max": 0.20623040199279785, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.528594970703125e-05, "timer/dataset_eval_frac": 3.527690124053588e-08, "timer/dataset_eval_avg": 3.528594970703125e-05, "timer/dataset_eval_min": 3.528594970703125e-05, "timer/dataset_eval_max": 3.528594970703125e-05, "fps": 33.47879962468305}
{"step": 892968, "time": 27150.32239127159, "episode/length": 177.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 893112, "time": 27155.398379802704, "episode/length": 206.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9806763285024155, "episode/intrinsic_return": 0.0}
{"step": 893264, "time": 27160.203385829926, "episode/length": 359.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 893448, "time": 27165.423088550568, "episode/length": 289.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9793103448275862, "episode/intrinsic_return": 0.0}
{"step": 893984, "time": 27179.845620393753, "episode/length": 187.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 893992, "time": 27180.71244740486, "episode/length": 239.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 894552, "time": 27195.570306301117, "episode/length": 160.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 895024, "time": 27208.538885116577, "episode/length": 58.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 895048, "time": 27209.781809091568, "episode/length": 199.0, "episode/score": 10.099999964237213, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 895072, "time": 27211.30791401863, "episode/length": 262.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9961977186311787, "episode/intrinsic_return": 0.0}
{"step": 895136, "time": 27213.753295898438, "episode/length": 390.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9872122762148338, "episode/intrinsic_return": 0.0}
{"step": 895192, "time": 27215.783764600754, "episode/length": 426.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9953161592505855, "episode/intrinsic_return": 0.0}
{"step": 896048, "time": 27238.17807674408, "episode/length": 121.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9918032786885246, "episode/intrinsic_return": 0.0}
{"step": 896192, "time": 27242.645669698715, "episode/length": 384.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9922077922077922, "episode/intrinsic_return": 0.0}
{"step": 896456, "time": 27249.896631240845, "episode/length": 157.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 896496, "time": 27251.897568941116, "episode/length": 183.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 896720, "time": 27258.431427955627, "episode/length": 341.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 896752, "time": 27260.100124120712, "episode/length": 212.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 897104, "time": 27269.660193681717, "episode/length": 388.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9897172236503856, "episode/intrinsic_return": 0.0}
{"step": 897144, "time": 27271.275982618332, "episode/length": 52.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9245283018867925, "episode/intrinsic_return": 0.0}
{"step": 897824, "time": 27288.933961629868, "episode/length": 203.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 897984, "time": 27293.788662433624, "episode/length": 241.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9710743801652892, "episode/intrinsic_return": 0.0}
{"step": 898248, "time": 27300.92356824875, "episode/length": 388.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9922879177377892, "episode/intrinsic_return": 0.0}
{"step": 898376, "time": 27304.983389377594, "episode/length": 202.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9704433497536946, "episode/intrinsic_return": 0.0}
{"step": 898640, "time": 27312.532140016556, "episode/length": 186.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9679144385026738, "episode/intrinsic_return": 0.0}
{"step": 898752, "time": 27316.155371904373, "episode/length": 286.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9965156794425087, "episode/intrinsic_return": 0.0}
{"step": 898976, "time": 27322.561696767807, "episode/length": 309.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9903225806451613, "episode/intrinsic_return": 0.0}
{"step": 899248, "time": 27330.03672146797, "episode/length": 177.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 899440, "time": 27335.725143909454, "episode/length": 57.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9137931034482759, "episode/intrinsic_return": 0.0}
{"step": 899544, "time": 27339.010910511017, "episode/length": 194.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9641025641025641, "episode/intrinsic_return": 0.0}
{"step": 899800, "time": 27346.184382915497, "episode/length": 193.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9690721649484536, "episode/intrinsic_return": 0.0}
{"step": 899888, "time": 27349.49090051651, "episode/length": 155.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 899960, "time": 27352.17195057869, "episode/length": 356.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9859943977591037, "episode/intrinsic_return": 0.0}
{"step": 900000, "time": 27354.2675280571, "episode/length": 56.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 900016, "time": 27357.54334950447, "eval_episode/length": 77.0, "eval_episode/score": 6.100000023841858, "eval_episode/reward_rate": 0.9871794871794872}
{"step": 900016, "time": 27360.427790403366, "eval_episode/length": 191.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9739583333333334}
{"step": 900016, "time": 27361.337328195572, "eval_episode/length": 193.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9742268041237113}
{"step": 900016, "time": 27362.319234848022, "eval_episode/length": 198.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9748743718592965}
{"step": 900016, "time": 27363.31505060196, "eval_episode/length": 206.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9758454106280193}
{"step": 900016, "time": 27363.370864391327, "eval_episode/length": 206.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9758454106280193}
{"step": 900016, "time": 27364.368396043777, "eval_episode/length": 211.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9716981132075472}
{"step": 900016, "time": 27365.80407357216, "eval_episode/length": 162.0, "eval_episode/score": 7.1000000461936, "eval_episode/reward_rate": 0.9938650306748467}
{"step": 900264, "time": 27372.01036143303, "episode/length": 188.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 900632, "time": 27382.136177539825, "episode/length": 281.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9964539007092199, "episode/intrinsic_return": 0.0}
{"step": 900864, "time": 27389.03112268448, "episode/length": 201.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9702970297029703, "episode/intrinsic_return": 0.0}
{"step": 901040, "time": 27394.223539829254, "episode/length": 199.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 901056, "time": 27395.51956987381, "episode/length": 98.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9494949494949495, "episode/intrinsic_return": 0.0}
{"step": 901096, "time": 27397.225237846375, "episode/length": 161.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 901152, "time": 27399.807692289352, "episode/length": 64.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9846153846153847, "episode/intrinsic_return": 0.0}
{"step": 901432, "time": 27407.55021238327, "episode/length": 192.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 901576, "time": 27412.07063150406, "episode/length": 201.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 902128, "time": 27427.029062986374, "episode/length": 128.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9922480620155039, "episode/intrinsic_return": 0.0}
{"step": 902392, "time": 27434.3887860775, "episode/length": 190.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9633507853403142, "episode/intrinsic_return": 0.0}
{"step": 902560, "time": 27439.87707567215, "episode/length": 319.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.990625, "episode/intrinsic_return": 0.0}
{"step": 903120, "time": 27454.615792274475, "episode/length": 257.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9961240310077519, "episode/intrinsic_return": 0.0}
{"step": 903144, "time": 27455.783695220947, "episode/length": 195.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 903208, "time": 27458.262358427048, "episode/length": 256.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9961089494163424, "episode/intrinsic_return": 0.0}
{"step": 903224, "time": 27459.531705141068, "episode/length": 223.0, "episode/score": 9.100000031292439, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 903544, "time": 27468.215353488922, "episode/length": 122.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.991869918699187, "episode/intrinsic_return": 0.0}
{"step": 904296, "time": 27487.763283491135, "episode/length": 237.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9789915966386554, "episode/intrinsic_return": 0.0}
{"step": 904328, "time": 27489.50826907158, "episode/length": 410.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9902676399026764, "episode/intrinsic_return": 0.0}
{"step": 904560, "time": 27496.445143699646, "episode/length": 126.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9606299212598425, "episode/intrinsic_return": 0.0}
{"step": 904680, "time": 27500.02808189392, "episode/length": 194.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9641025641025641, "episode/intrinsic_return": 0.0}
{"step": 904792, "time": 27503.682089567184, "episode/length": 197.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 904904, "time": 27507.28715610504, "episode/length": 209.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9809523809523809, "episode/intrinsic_return": 0.0}
{"step": 905040, "time": 27511.759024858475, "episode/length": 363.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9972527472527473, "episode/intrinsic_return": 0.0}
{"step": 905048, "time": 27512.572347402573, "episode/length": 237.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 906296, "time": 27544.727056980133, "episode/length": 216.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 906296, "time": 27544.78340125084, "episode/length": 173.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 906416, "time": 27548.875841856003, "episode/length": 202.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9802955665024631, "episode/intrinsic_return": 0.0}
{"step": 906584, "time": 27553.77922129631, "episode/length": 285.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.972027972027972, "episode/intrinsic_return": 0.0}
{"step": 906960, "time": 27564.189123392105, "episode/length": 238.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.0}
{"step": 906960, "time": 27564.24704670906, "episode/length": 239.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 907080, "time": 27567.94140958786, "episode/length": 343.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 908056, "time": 27592.969779729843, "episode/length": 219.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 908152, "time": 27596.271791934967, "episode/length": 433.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9792626728110599, "episode/intrinsic_return": 0.0}
{"step": 908216, "time": 27598.682220458984, "episode/length": 224.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 908360, "time": 27603.086137771606, "episode/length": 221.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9819819819819819, "episode/intrinsic_return": 0.0}
{"step": 908616, "time": 27610.38980102539, "episode/length": 289.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.996551724137931, "episode/intrinsic_return": 0.0}
{"step": 909080, "time": 27622.8127245903, "episode/length": 57.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9137931034482759, "episode/intrinsic_return": 0.0}
{"step": 909544, "time": 27635.198315620422, "episode/length": 322.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9969040247678018, "episode/intrinsic_return": 0.0}
{"step": 909608, "time": 27637.65890622139, "episode/length": 181.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 909944, "time": 27646.750778913498, "episode/length": 197.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 910000, "time": 27652.488609552383, "eval_episode/length": 150.0, "eval_episode/score": 6.100000023841858, "eval_episode/reward_rate": 0.9933774834437086}
{"step": 910000, "time": 27653.380063295364, "eval_episode/length": 153.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.974025974025974}
{"step": 910000, "time": 27654.280166387558, "eval_episode/length": 157.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9620253164556962}
{"step": 910000, "time": 27655.750732421875, "eval_episode/length": 193.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9742268041237113}
{"step": 910000, "time": 27656.842094421387, "eval_episode/length": 206.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.966183574879227}
{"step": 910000, "time": 27658.934442043304, "eval_episode/length": 263.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9772727272727273}
{"step": 910000, "time": 27660.97341609001, "eval_episode/length": 323.0, "eval_episode/score": 11.099999979138374, "eval_episode/reward_rate": 0.9969135802469136}
{"step": 910000, "time": 27661.966309547424, "eval_episode/length": 178.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9776536312849162}
{"step": 910080, "time": 27664.24566054344, "episode/length": 252.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9960474308300395, "episode/intrinsic_return": 0.0}
{"step": 910552, "time": 27676.780920743942, "episode/length": 448.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9933184855233853, "episode/intrinsic_return": 0.0}
{"step": 910560, "time": 27678.03006362915, "episode/length": 184.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 910728, "time": 27682.82112956047, "episode/length": 455.0, "episode/score": 11.100000031292439, "episode/reward_rate": 0.9890350877192983, "episode/intrinsic_return": 0.0}
{"step": 911016, "time": 27690.745359420776, "episode/length": 175.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 911176, "time": 27695.54408097267, "episode/length": 153.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 911512, "time": 27704.787318229675, "episode/length": 178.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 911592, "time": 27707.60361266136, "episode/length": 51.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9230769230769231, "episode/intrinsic_return": 0.0}
{"step": 911640, "time": 27709.6482257843, "episode/length": 427.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9789719626168224, "episode/intrinsic_return": 0.0}
{"step": 912024, "time": 27719.979829072952, "episode/length": 63.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.984375, "episode/intrinsic_return": 0.0}
{"step": 912056, "time": 27721.62505555153, "episode/length": 57.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 912296, "time": 27728.42563700676, "episode/length": 216.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 912432, "time": 27732.7773001194, "episode/length": 234.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9702127659574468, "episode/intrinsic_return": 0.0}
{"step": 913064, "time": 27749.289697885513, "episode/length": 439.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9795454545454545, "episode/intrinsic_return": 0.0}
{"step": 913112, "time": 27751.288218975067, "episode/length": 297.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 913536, "time": 27762.97636628151, "episode/length": 184.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 913544, "time": 27763.82757782936, "episode/length": 59.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 913616, "time": 27766.772587299347, "episode/length": 164.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 913888, "time": 27774.62385249138, "episode/length": 280.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.99644128113879, "episode/intrinsic_return": 0.0}
{"step": 914112, "time": 27780.919483184814, "episode/length": 209.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 914424, "time": 27789.360981702805, "episode/length": 425.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9788732394366197, "episode/intrinsic_return": 0.0}
{"step": 914888, "time": 27801.755603075027, "episode/length": 158.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 914920, "time": 27803.343023777008, "episode/length": 361.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9917127071823204, "episode/intrinsic_return": 0.0}
{"step": 915392, "time": 27816.12830901146, "episode/length": 231.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 915648, "time": 27823.57477402687, "episode/length": 219.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 915776, "time": 27827.586283922195, "episode/length": 278.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.974910394265233, "episode/intrinsic_return": 0.0}
{"step": 915944, "time": 27832.434267044067, "episode/length": 353.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9915254237288136, "episode/intrinsic_return": 0.0}
{"step": 915952, "time": 27833.649822950363, "episode/length": 190.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9685863874345549, "episode/intrinsic_return": 0.0}
{"step": 916536, "time": 27849.278698921204, "episode/length": 142.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.958041958041958, "episode/intrinsic_return": 0.0}
{"step": 916600, "time": 27851.82770895958, "episode/length": 209.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 916736, "time": 27856.366050958633, "episode/length": 327.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9817073170731707, "episode/intrinsic_return": 0.0}
{"step": 917312, "time": 27871.590970993042, "episode/length": 302.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9834983498349835, "episode/intrinsic_return": 0.0}
{"step": 917320, "time": 27872.454246282578, "episode/length": 208.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9808612440191388, "episode/intrinsic_return": 0.0}
{"step": 917968, "time": 27889.57590150833, "episode/length": 153.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 918072, "time": 27892.829431772232, "episode/length": 94.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9894736842105263, "episode/intrinsic_return": 0.0}
{"step": 918160, "time": 27896.020071029663, "episode/length": 297.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9966442953020134, "episode/intrinsic_return": 0.0}
{"step": 918232, "time": 27898.401153087616, "episode/length": 203.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 918304, "time": 27901.17426109314, "episode/length": 122.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.991869918699187, "episode/intrinsic_return": 0.0}
{"step": 918344, "time": 27902.78226542473, "episode/length": 225.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9690265486725663, "episode/intrinsic_return": 0.0}
{"step": 918400, "time": 27905.188509225845, "episode/length": 305.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9771241830065359, "episode/intrinsic_return": 0.0}
{"step": 918464, "time": 27907.636335849762, "episode/length": 314.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9746031746031746, "episode/intrinsic_return": 0.0}
{"step": 918648, "time": 27912.82921242714, "episode/length": 60.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 919336, "time": 27930.673917531967, "episode/length": 128.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9534883720930233, "episode/intrinsic_return": 0.0}
{"step": 919768, "time": 27942.30527496338, "episode/length": 224.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9733333333333334, "episode/intrinsic_return": 0.0}
{"step": 919944, "time": 27947.643465280533, "episode/length": 184.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 920072, "time": 27951.62798142433, "episode/length": 229.0, "episode/score": 10.100000016391277, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 920088, "time": 27954.641175746918, "eval_episode/length": 50.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9019607843137255}
{"step": 920088, "time": 27957.901963472366, "eval_episode/length": 188.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9682539682539683}
{"step": 920088, "time": 27959.28479385376, "eval_episode/length": 219.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9954545454545455}
{"step": 920088, "time": 27960.232407331467, "eval_episode/length": 221.0, "eval_episode/score": 8.099999979138374, "eval_episode/reward_rate": 0.9954954954954955}
{"step": 920088, "time": 27961.461953163147, "eval_episode/length": 237.0, "eval_episode/score": 7.099999971687794, "eval_episode/reward_rate": 0.9957983193277311}
{"step": 920088, "time": 27963.1788918972, "eval_episode/length": 280.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9786476868327402}
{"step": 920088, "time": 27964.12385892868, "eval_episode/length": 283.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9823943661971831}
{"step": 920088, "time": 27965.035777568817, "eval_episode/length": 288.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9792387543252595}
{"step": 920120, "time": 27965.971611738205, "episode/length": 214.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 920208, "time": 27969.20628285408, "episode/length": 194.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 920832, "time": 27985.466673135757, "episode/length": 186.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 921048, "time": 27991.468428850174, "episode/length": 337.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.985207100591716, "episode/intrinsic_return": 0.0}
{"step": 921112, "time": 27993.82447719574, "episode/length": 167.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 921384, "time": 28001.419509410858, "episode/length": 413.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9927536231884058, "episode/intrinsic_return": 0.0}
{"step": 921968, "time": 28017.113093852997, "episode/length": 252.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9762845849802372, "episode/intrinsic_return": 0.0}
{"step": 922376, "time": 28027.873847723007, "episode/length": 157.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 922616, "time": 28034.79695534706, "episode/length": 195.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 922736, "time": 28038.879064798355, "episode/length": 237.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9789915966386554, "episode/intrinsic_return": 0.0}
{"step": 922784, "time": 28040.985115766525, "episode/length": 332.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.984984984984985, "episode/intrinsic_return": 0.0}
{"step": 922864, "time": 28043.82989883423, "episode/length": 60.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 922976, "time": 28047.431380033493, "episode/length": 198.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 923512, "time": 28061.732475996017, "episode/length": 429.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9906976744186047, "episode/intrinsic_return": 0.0}
{"step": 923544, "time": 28063.362334489822, "episode/length": 416.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9952038369304557, "episode/intrinsic_return": 0.0}
{"step": 923992, "time": 28075.424898147583, "episode/length": 252.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9841897233201581, "episode/intrinsic_return": 0.0}
{"step": 924352, "time": 28085.334359884262, "episode/length": 216.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 924384, "time": 28086.95765066147, "episode/length": 205.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.970873786407767, "episode/intrinsic_return": 0.0}
{"step": 924392, "time": 28087.827012062073, "episode/length": 200.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9701492537313433, "episode/intrinsic_return": 0.0}
{"step": 924656, "time": 28095.326500177383, "episode/length": 223.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 924664, "time": 28096.187425374985, "episode/length": 143.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9583333333333334, "episode/intrinsic_return": 0.0}
{"step": 925432, "time": 28116.0306327343, "episode/length": 306.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9804560260586319, "episode/intrinsic_return": 0.0}
{"step": 925872, "time": 28128.053272008896, "episode/length": 184.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 925904, "time": 28129.665141820908, "episode/length": 294.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9966101694915255, "episode/intrinsic_return": 0.0}
{"step": 926352, "time": 28141.567801713943, "episode/length": 59.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 926488, "time": 28145.622094154358, "episode/length": 227.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 926512, "time": 28147.24989962578, "episode/length": 231.0, "episode/score": 11.099999971687794, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 926513, "time": 28148.611865758896, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.173368770364337, "train/action_min": 0.0, "train/action_std": 3.0274684270976278, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.032578661190390025, "train/actor_opt_grad_steps": 56760.0, "train/actor_opt_loss": -9.288831952253084, "train/adv_mag": 0.4469699163289997, "train/adv_max": 0.40479533614423036, "train/adv_mean": 0.0019817411644192607, "train/adv_min": -0.3556875799080772, "train/adv_std": 0.049304327322832214, "train/cont_avg": 0.9952467787322274, "train/cont_loss_mean": 0.00013058440239874643, "train/cont_loss_std": 0.003919558991868766, "train/cont_neg_acc": 0.9992063493955703, "train/cont_neg_loss": 0.007531366352060061, "train/cont_pos_acc": 0.9999720120881971, "train/cont_pos_loss": 9.745817786686524e-05, "train/cont_pred": 0.9952324964988853, "train/cont_rate": 0.9952467787322274, "train/dyn_loss_mean": 13.373688901205199, "train/dyn_loss_std": 9.432205484941672, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9655014669160707, "train/extr_critic_critic_opt_grad_steps": 56760.0, "train/extr_critic_critic_opt_loss": 15957.232060870852, "train/extr_critic_mag": 9.287600553431217, "train/extr_critic_max": 9.287600553431217, "train/extr_critic_mean": 2.71913801889284, "train/extr_critic_min": -0.21861367994010167, "train/extr_critic_std": 2.2500333661716696, "train/extr_return_normed_mag": 1.431540119139504, "train/extr_return_normed_max": 1.431540119139504, "train/extr_return_normed_mean": 0.3716608393955005, "train/extr_return_normed_min": -0.08137030341613914, "train/extr_return_normed_std": 0.31716012573355185, "train/extr_return_rate": 0.8162390586889186, "train/extr_return_raw_mag": 10.344756826970249, "train/extr_return_raw_max": 10.344756826970249, "train/extr_return_raw_mean": 2.733360108041085, "train/extr_return_raw_min": -0.5204601669904745, "train/extr_return_raw_std": 2.2779755823985095, "train/extr_reward_mag": 1.031926855656773, "train/extr_reward_max": 1.031926855656773, "train/extr_reward_mean": 0.043586466178933594, "train/extr_reward_min": -0.39912488166754845, "train/extr_reward_std": 0.19534113904311193, "train/image_loss_mean": 6.839147393737359, "train/image_loss_std": 12.624435343448585, "train/model_loss_mean": 14.918579169359253, "train/model_loss_std": 16.4778875332873, "train/model_opt_grad_norm": 54.3048884405344, "train/model_opt_grad_steps": 56709.71563981043, "train/model_opt_loss": 19795.18636607672, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1327.0142180094788, "train/policy_entropy_mag": 2.51696582428087, "train/policy_entropy_max": 2.51696582428087, "train/policy_entropy_mean": 0.5197953025311656, "train/policy_entropy_min": 0.07937501469777093, "train/policy_entropy_std": 0.6537299996586208, "train/policy_logprob_mag": 7.438383737446572, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5191887615698774, "train/policy_logprob_min": -7.438383737446572, "train/policy_logprob_std": 1.0791672487959478, "train/policy_randomness_mag": 0.8883784808818763, "train/policy_randomness_max": 0.8883784808818763, "train/policy_randomness_mean": 0.18346493352222218, "train/policy_randomness_min": 0.02801589697811276, "train/policy_randomness_std": 0.23073800254207086, "train/post_ent_mag": 59.36764396197423, "train/post_ent_max": 59.36764396197423, "train/post_ent_mean": 42.836776679161034, "train/post_ent_min": 20.579855905324926, "train/post_ent_std": 7.616146232279556, "train/prior_ent_mag": 69.0500327015375, "train/prior_ent_max": 69.0500327015375, "train/prior_ent_mean": 56.30963358946886, "train/prior_ent_min": 41.44853219488786, "train/prior_ent_std": 4.494826669376608, "train/rep_loss_mean": 13.373688901205199, "train/rep_loss_std": 9.432205484941672, "train/reward_avg": 0.028586899874934936, "train/reward_loss_mean": 0.0550878971673866, "train/reward_loss_std": 0.24223371803478042, "train/reward_max_data": 1.01800948296678, "train/reward_max_pred": 1.0149817494984488, "train/reward_neg_acc": 0.9927610452706215, "train/reward_neg_loss": 0.028717437639867806, "train/reward_pos_acc": 0.9701873301329771, "train/reward_pos_loss": 0.8332273499660582, "train/reward_pred": 0.02796463588455701, "train/reward_rate": 0.03293468601895735, "train_stats/sum_log_reward": 8.985135342623737, "train_stats/max_log_achievement_collect_coal": 1.1418918918918919, "train_stats/max_log_achievement_collect_drink": 6.412162162162162, "train_stats/max_log_achievement_collect_sapling": 1.2432432432432432, "train_stats/max_log_achievement_collect_stone": 15.29054054054054, "train_stats/max_log_achievement_collect_wood": 7.777027027027027, "train_stats/max_log_achievement_defeat_skeleton": 0.08783783783783784, "train_stats/max_log_achievement_defeat_zombie": 0.4391891891891892, "train_stats/max_log_achievement_eat_cow": 0.07432432432432433, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 2.141891891891892, "train_stats/max_log_achievement_make_wood_sword": 0.013513513513513514, "train_stats/max_log_achievement_place_furnace": 2.141891891891892, "train_stats/max_log_achievement_place_plant": 1.2364864864864864, "train_stats/max_log_achievement_place_stone": 4.006756756756757, "train_stats/max_log_achievement_place_table": 2.168918918918919, "train_stats/max_log_achievement_wake_up": 1.587837837837838, "train_stats/mean_log_entropy": 0.5132512697899664, "eval_stats/sum_log_reward": 8.600000143051147, "eval_stats/max_log_achievement_collect_coal": 0.7916666666666666, "eval_stats/max_log_achievement_collect_drink": 4.708333333333333, "eval_stats/max_log_achievement_collect_sapling": 1.25, "eval_stats/max_log_achievement_collect_stone": 11.291666666666666, "eval_stats/max_log_achievement_collect_wood": 7.416666666666667, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.4583333333333333, "eval_stats/max_log_achievement_eat_cow": 0.041666666666666664, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 2.1666666666666665, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 1.3333333333333333, "eval_stats/max_log_achievement_place_plant": 1.1666666666666667, "eval_stats/max_log_achievement_place_stone": 2.5833333333333335, "eval_stats/max_log_achievement_place_table": 2.125, "eval_stats/max_log_achievement_wake_up": 1.375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.00016005539509933442, "report/cont_loss_std": 0.004725235514342785, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.001785889733582735, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.00014886478311382234, "report/cont_pred": 0.9930390119552612, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 12.923223495483398, "report/dyn_loss_std": 9.238298416137695, "report/image_loss_mean": 6.793258190155029, "report/image_loss_std": 13.007552146911621, "report/model_loss_mean": 14.598409652709961, "report/model_loss_std": 16.93853187561035, "report/post_ent_mag": 58.722190856933594, "report/post_ent_max": 58.722190856933594, "report/post_ent_mean": 42.65247344970703, "report/post_ent_min": 21.45893669128418, "report/post_ent_std": 7.059142589569092, "report/prior_ent_mag": 68.9766845703125, "report/prior_ent_max": 68.9766845703125, "report/prior_ent_mean": 55.721702575683594, "report/prior_ent_min": 39.76963806152344, "report/prior_ent_std": 5.286495208740234, "report/rep_loss_mean": 12.923223495483398, "report/rep_loss_std": 9.238298416137695, "report/reward_avg": 0.0302734375, "report/reward_loss_mean": 0.051056500524282455, "report/reward_loss_std": 0.18003739416599274, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0005104541778564, "report/reward_neg_acc": 0.9939209222793579, "report/reward_neg_loss": 0.027611851692199707, "report/reward_pos_acc": 0.9999999403953552, "report/reward_pos_loss": 0.6764582991600037, "report/reward_pred": 0.030833272263407707, "report/reward_rate": 0.0361328125, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 2.968220996990567e-06, "eval/cont_loss_std": 5.089584374218248e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00011485922004794702, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.4191976990550756e-06, "eval/cont_pred": 0.9951153993606567, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 18.04079818725586, "eval/dyn_loss_std": 10.72408390045166, "eval/image_loss_mean": 10.753185272216797, "eval/image_loss_std": 13.856087684631348, "eval/model_loss_mean": 21.688674926757812, "eval/model_loss_std": 18.328853607177734, "eval/post_ent_mag": 57.315670013427734, "eval/post_ent_max": 57.315670013427734, "eval/post_ent_mean": 39.87738037109375, "eval/post_ent_min": 22.69354248046875, "eval/post_ent_std": 7.5318989753723145, "eval/prior_ent_mag": 68.9766845703125, "eval/prior_ent_max": 68.9766845703125, "eval/prior_ent_mean": 56.11589813232422, "eval/prior_ent_min": 43.63051223754883, "eval/prior_ent_std": 4.133141994476318, "eval/rep_loss_mean": 18.04079818725586, "eval/rep_loss_std": 10.72408390045166, "eval/reward_avg": 0.04091797024011612, "eval/reward_loss_mean": 0.1110089123249054, "eval/reward_loss_std": 0.5865607261657715, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0006422996520996, "eval/reward_neg_acc": 0.9877300262451172, "eval/reward_neg_loss": 0.06503260135650635, "eval/reward_pos_acc": 0.9130434989929199, "eval/reward_pos_loss": 1.0885051488876343, "eval/reward_pred": 0.04257555305957794, "eval/reward_rate": 0.044921875, "replay/size": 926009.0, "replay/inserts": 33624.0, "replay/samples": 33616.0, "replay/insert_wait_avg": 1.2355519566341948e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 5.853369030596131e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 6904.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2290090978629066e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 6.556510925292969e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 999.9907894134521, "timer/env.step_count": 4203.0, "timer/env.step_total": 136.32441067695618, "timer/env.step_frac": 0.13632566631630447, "timer/env.step_avg": 0.0324350251432206, "timer/env.step_min": 0.00226593017578125, "timer/env.step_max": 0.9153900146484375, "timer/replay._sample_count": 33616.0, "timer/replay._sample_total": 2986.0044548511505, "timer/replay._sample_frac": 2.986031957956934, "timer/replay._sample_avg": 0.08882688168881338, "timer/replay._sample_min": 0.0004146099090576172, "timer/replay._sample_max": 0.11841773986816406, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5066.0, "timer/agent.policy_total": 51.4006609916687, "timer/agent.policy_frac": 0.05140113442626599, "timer/agent.policy_avg": 0.010146202327609297, "timer/agent.policy_min": 0.006716728210449219, "timer/agent.policy_max": 0.021902084350585938, "timer/dataset_train_count": 2101.0, "timer/dataset_train_total": 0.1748826503753662, "timer/dataset_train_frac": 0.0001748842611619895, "timer/dataset_train_avg": 8.323781550469596e-05, "timer/dataset_train_min": 6.389617919921875e-05, "timer/dataset_train_max": 0.0001804828643798828, "timer/agent.train_count": 2101.0, "timer/agent.train_total": 778.4950585365295, "timer/agent.train_frac": 0.7785022289986874, "timer/agent.train_avg": 0.3705354871663634, "timer/agent.train_min": 0.3534691333770752, "timer/agent.train_max": 0.6111884117126465, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4109370708465576, "timer/agent.report_frac": 0.0004109408558528765, "timer/agent.report_avg": 0.2054685354232788, "timer/agent.report_min": 0.20487546920776367, "timer/agent.report_max": 0.20606160163879395, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.4809112548828125e-05, "timer/dataset_eval_frac": 3.480943316412496e-08, "timer/dataset_eval_avg": 3.4809112548828125e-05, "timer/dataset_eval_min": 3.4809112548828125e-05, "timer/dataset_eval_max": 3.4809112548828125e-05, "fps": 33.62378964609139}
{"step": 926672, "time": 28152.717359781265, "episode/length": 289.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9793103448275862, "episode/intrinsic_return": 0.0}
{"step": 926776, "time": 28155.90137553215, "episode/length": 298.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9765886287625418, "episode/intrinsic_return": 0.0}
{"step": 926912, "time": 28160.4012863636, "episode/length": 364.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9945205479452055, "episode/intrinsic_return": 0.0}
{"step": 927480, "time": 28175.379435539246, "episode/length": 255.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.99609375, "episode/intrinsic_return": 0.0}
{"step": 927864, "time": 28185.807210206985, "episode/length": 244.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.0}
{"step": 928432, "time": 28201.172948360443, "episode/length": 239.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 928872, "time": 28212.77904367447, "episode/length": 261.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9961832061068703, "episode/intrinsic_return": 0.0}
{"step": 928888, "time": 28214.052728176117, "episode/length": 276.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9963898916967509, "episode/intrinsic_return": 0.0}
{"step": 928936, "time": 28216.043471097946, "episode/length": 62.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9841269841269841, "episode/intrinsic_return": 0.0}
{"step": 929040, "time": 28219.72081875801, "episode/length": 194.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 929120, "time": 28222.605285167694, "episode/length": 156.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 929792, "time": 28240.343993663788, "episode/length": 114.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.991304347826087, "episode/intrinsic_return": 0.0}
{"step": 929984, "time": 28245.960472106934, "episode/length": 453.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9801762114537445, "episode/intrinsic_return": 0.0}
{"step": 930072, "time": 28250.272808790207, "eval_episode/length": 37.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.8947368421052632}
{"step": 930072, "time": 28253.98499274254, "eval_episode/length": 201.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9752475247524752}
{"step": 930072, "time": 28254.97420144081, "eval_episode/length": 208.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9712918660287081}
{"step": 930072, "time": 28255.981607437134, "eval_episode/length": 216.0, "eval_episode/score": 9.099999994039536, "eval_episode/reward_rate": 0.9769585253456221}
{"step": 930072, "time": 28258.371537446976, "eval_episode/length": 297.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9865771812080537}
{"step": 930072, "time": 28259.44354748726, "eval_episode/length": 309.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9903225806451613}
{"step": 930072, "time": 28261.10261774063, "eval_episode/length": 351.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9886363636363636}
{"step": 930072, "time": 28262.380195379257, "eval_episode/length": 333.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.9850299401197605}
{"step": 930216, "time": 28266.166528224945, "episode/length": 165.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 930288, "time": 28268.988980293274, "episode/length": 474.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9978947368421053, "episode/intrinsic_return": 0.0}
{"step": 930328, "time": 28270.645743370056, "episode/length": 426.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9789227166276346, "episode/intrinsic_return": 0.0}
{"step": 930392, "time": 28273.069774627686, "episode/length": 168.0, "episode/score": 10.100000031292439, "episode/reward_rate": 0.9644970414201184, "episode/intrinsic_return": 0.0}
{"step": 930400, "time": 28274.351055145264, "episode/length": 159.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 930664, "time": 28281.70093512535, "episode/length": 215.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 931496, "time": 28303.33357691765, "episode/length": 159.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 931656, "time": 28308.065928459167, "episode/length": 208.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9712918660287081, "episode/intrinsic_return": 0.0}
{"step": 931696, "time": 28310.01242041588, "episode/length": 237.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9663865546218487, "episode/intrinsic_return": 0.0}
{"step": 931848, "time": 28314.523673295975, "episode/length": 194.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 932048, "time": 28320.72827887535, "episode/length": 214.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 932344, "time": 28328.865383386612, "episode/length": 243.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 933200, "time": 28351.406948566437, "episode/length": 212.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 933480, "time": 28359.028267145157, "episode/length": 178.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 933496, "time": 28360.28982901573, "episode/length": 353.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9858757062146892, "episode/intrinsic_return": 0.0}
{"step": 933544, "time": 28362.429130792618, "episode/length": 211.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 933576, "time": 28364.09020447731, "episode/length": 396.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9924433249370277, "episode/intrinsic_return": 0.0}
{"step": 933752, "time": 28369.2858440876, "episode/length": 256.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9961089494163424, "episode/intrinsic_return": 0.0}
{"step": 934848, "time": 28398.103554725647, "episode/length": 398.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9799498746867168, "episode/intrinsic_return": 0.0}
{"step": 934864, "time": 28399.402465343475, "episode/length": 170.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 935016, "time": 28403.757502555847, "episode/length": 179.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 935064, "time": 28405.73626089096, "episode/length": 232.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 935160, "time": 28408.94873046875, "episode/length": 175.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9659090909090909, "episode/intrinsic_return": 0.0}
{"step": 935296, "time": 28413.427713871002, "episode/length": 226.0, "episode/score": 11.099999971687794, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 935456, "time": 28418.271157979965, "episode/length": 238.0, "episode/score": 8.100000031292439, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.0}
{"step": 936448, "time": 28444.421655654907, "episode/length": 160.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 936536, "time": 28447.39469408989, "episode/length": 154.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 936760, "time": 28453.748578071594, "episode/length": 162.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 937016, "time": 28461.042083978653, "episode/length": 270.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.996309963099631, "episode/intrinsic_return": 0.0}
{"step": 937040, "time": 28462.686163663864, "episode/length": 586.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.989778534923339, "episode/intrinsic_return": 0.0}
{"step": 937416, "time": 28472.90465259552, "episode/length": 293.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9727891156462585, "episode/intrinsic_return": 0.0}
{"step": 937696, "time": 28480.94177532196, "episode/length": 334.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.991044776119403, "episode/intrinsic_return": 0.0}
{"step": 937896, "time": 28486.43337869644, "episode/length": 59.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 937984, "time": 28489.65432548523, "episode/length": 191.0, "episode/score": 10.100000031292439, "episode/reward_rate": 0.9895833333333334, "episode/intrinsic_return": 0.0}
{"step": 938280, "time": 28497.854570388794, "episode/length": 426.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9789227166276346, "episode/intrinsic_return": 0.0}
{"step": 938280, "time": 28497.913653612137, "episode/length": 217.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9724770642201835, "episode/intrinsic_return": 0.0}
{"step": 938400, "time": 28502.07431602478, "episode/length": 204.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 938560, "time": 28506.85230922699, "episode/length": 189.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 938920, "time": 28516.57125878334, "episode/length": 79.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9375, "episode/intrinsic_return": 0.0}
{"step": 939376, "time": 28528.9449198246, "episode/length": 209.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 939616, "time": 28535.81814455986, "episode/length": 151.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 939680, "time": 28538.295714616776, "episode/length": 222.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 939872, "time": 28543.98033475876, "episode/length": 356.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9859943977591037, "episode/intrinsic_return": 0.0}
{"step": 939880, "time": 28544.76644039154, "episode/length": 199.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 940056, "time": 28553.45233440399, "eval_episode/length": 157.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9936708860759493}
{"step": 940056, "time": 28554.32330417633, "eval_episode/length": 158.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9685534591194969}
{"step": 940056, "time": 28556.14492535591, "eval_episode/length": 211.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9952830188679245}
{"step": 940056, "time": 28557.50147008896, "eval_episode/length": 239.0, "eval_episode/score": 10.100000016391277, "eval_episode/reward_rate": 0.9958333333333333}
{"step": 940056, "time": 28558.313391923904, "eval_episode/length": 240.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.995850622406639}
{"step": 940056, "time": 28560.10440135002, "eval_episode/length": 291.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9863013698630136}
{"step": 940056, "time": 28561.500668764114, "eval_episode/length": 321.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.984472049689441}
{"step": 940056, "time": 28562.492391109467, "eval_episode/length": 173.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9770114942528736}
{"step": 940216, "time": 28566.738178014755, "episode/length": 161.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 940240, "time": 28568.3770301342, "episode/length": 209.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 940536, "time": 28576.423967838287, "episode/length": 318.0, "episode/score": 10.099999956786633, "episode/reward_rate": 0.9968652037617555, "episode/intrinsic_return": 0.0}
{"step": 941104, "time": 28591.770848035812, "episode/length": 177.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9662921348314607, "episode/intrinsic_return": 0.0}
{"step": 941160, "time": 28593.844881296158, "episode/length": 117.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9915254237288136, "episode/intrinsic_return": 0.0}
{"step": 941736, "time": 28609.082805633545, "episode/length": 186.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 941808, "time": 28611.849462032318, "episode/length": 303.0, "episode/score": 10.100000016391277, "episode/reward_rate": 0.9802631578947368, "episode/intrinsic_return": 0.0}
{"step": 941872, "time": 28614.261244535446, "episode/length": 95.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9895833333333334, "episode/intrinsic_return": 0.0}
{"step": 942224, "time": 28623.914991378784, "episode/length": 293.0, "episode/score": 9.100000031292439, "episode/reward_rate": 0.9693877551020408, "episode/intrinsic_return": 0.0}
{"step": 942272, "time": 28625.876255750656, "episode/length": 298.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9899665551839465, "episode/intrinsic_return": 0.0}
{"step": 942296, "time": 28627.10095191002, "episode/length": 219.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 942312, "time": 28628.32227754593, "episode/length": 62.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9365079365079365, "episode/intrinsic_return": 0.0}
{"step": 942712, "time": 28639.272550344467, "episode/length": 386.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9896640826873385, "episode/intrinsic_return": 0.0}
{"step": 942912, "time": 28645.282583236694, "episode/length": 218.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 943184, "time": 28652.94187951088, "episode/length": 163.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9573170731707317, "episode/intrinsic_return": 0.0}
{"step": 943488, "time": 28661.342234373093, "episode/length": 218.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 943624, "time": 28665.384919643402, "episode/length": 165.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 943968, "time": 28674.91426897049, "episode/length": 211.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 944000, "time": 28676.533932447433, "episode/length": 221.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 944072, "time": 28678.962137699127, "episode/length": 144.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9586206896551724, "episode/intrinsic_return": 0.0}
{"step": 944176, "time": 28682.55498433113, "episode/length": 232.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 944560, "time": 28693.255311727524, "episode/length": 69.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9857142857142858, "episode/intrinsic_return": 0.0}
{"step": 944688, "time": 28697.35630607605, "episode/length": 149.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 944904, "time": 28703.399594545364, "episode/length": 273.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9817518248175182, "episode/intrinsic_return": 0.0}
{"step": 945400, "time": 28716.606434106827, "episode/length": 152.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 945416, "time": 28717.811407327652, "episode/length": 180.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 945432, "time": 28719.09409070015, "episode/length": 280.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.99644128113879, "episode/intrinsic_return": 0.0}
{"step": 945432, "time": 28719.153099775314, "episode/length": 225.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 945888, "time": 28731.76041007042, "episode/length": 226.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 946544, "time": 28749.083968877792, "episode/length": 204.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9707317073170731, "episode/intrinsic_return": 0.0}
{"step": 946664, "time": 28752.69631099701, "episode/length": 262.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9847908745247148, "episode/intrinsic_return": 0.0}
{"step": 946968, "time": 28761.193774461746, "episode/length": 195.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 947280, "time": 28769.983153104782, "episode/length": 230.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 947632, "time": 28779.466675043106, "episode/length": 217.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 947992, "time": 28788.936967134476, "episode/length": 180.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.988950276243094, "episode/intrinsic_return": 0.0}
{"step": 948240, "time": 28796.042334079742, "episode/length": 352.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9915014164305949, "episode/intrinsic_return": 0.0}
{"step": 948280, "time": 28797.65270590782, "episode/length": 448.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9955456570155902, "episode/intrinsic_return": 0.0}
{"step": 948624, "time": 28807.190388441086, "episode/length": 167.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 948712, "time": 28810.073875665665, "episode/length": 217.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.981651376146789, "episode/intrinsic_return": 0.0}
{"step": 948736, "time": 28811.675773382187, "episode/length": 412.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9927360774818402, "episode/intrinsic_return": 0.0}
{"step": 949144, "time": 28822.356293916702, "episode/length": 309.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9774193548387097, "episode/intrinsic_return": 0.0}
{"step": 949160, "time": 28823.603563785553, "episode/length": 145.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 949264, "time": 28827.29693365097, "episode/length": 68.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.927536231884058, "episode/intrinsic_return": 0.0}
{"step": 949856, "time": 28843.07709145546, "episode/length": 88.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9887640449438202, "episode/intrinsic_return": 0.0}
{"step": 949864, "time": 28843.96019911766, "episode/length": 278.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.985663082437276, "episode/intrinsic_return": 0.0}
{"step": 950024, "time": 28848.709032535553, "episode/length": 107.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9907407407407407, "episode/intrinsic_return": 0.0}
{"step": 950040, "time": 28854.25917482376, "eval_episode/length": 204.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.975609756097561}
{"step": 950040, "time": 28855.247725248337, "eval_episode/length": 210.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.981042654028436}
{"step": 950040, "time": 28856.56361079216, "eval_episode/length": 236.0, "eval_episode/score": 12.099999979138374, "eval_episode/reward_rate": 0.9957805907172996}
{"step": 950040, "time": 28858.228057146072, "eval_episode/length": 274.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9963636363636363}
{"step": 950040, "time": 28859.451261281967, "eval_episode/length": 294.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9966101694915255}
{"step": 950040, "time": 28861.134588479996, "eval_episode/length": 335.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9880952380952381}
{"step": 950040, "time": 28863.50504922867, "eval_episode/length": 204.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9951219512195122}
{"step": 950040, "time": 28864.533951044083, "eval_episode/length": 425.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9953051643192489}
{"step": 950056, "time": 28865.11129808426, "episode/length": 221.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 950192, "time": 28869.498269081116, "episode/length": 195.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 950208, "time": 28870.705852746964, "episode/length": 183.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.967391304347826, "episode/intrinsic_return": 0.0}
{"step": 950224, "time": 28871.938353061676, "episode/length": 247.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9758064516129032, "episode/intrinsic_return": 0.0}
{"step": 951080, "time": 28896.104406118393, "episode/length": 226.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9691629955947136, "episode/intrinsic_return": 0.0}
{"step": 951328, "time": 28903.285337924957, "episode/length": 182.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9672131147540983, "episode/intrinsic_return": 0.0}
{"step": 951544, "time": 28909.479345798492, "episode/length": 189.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 951552, "time": 28910.65397977829, "episode/length": 211.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 951872, "time": 28919.59477543831, "episode/length": 207.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 951976, "time": 28922.80100274086, "episode/length": 218.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9863013698630136, "episode/intrinsic_return": 0.0}
{"step": 952016, "time": 28924.873070716858, "episode/length": 244.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.0}
{"step": 952480, "time": 28937.32656788826, "episode/length": 285.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9685314685314685, "episode/intrinsic_return": 0.0}
{"step": 952760, "time": 28944.984018325806, "episode/length": 209.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 953896, "time": 28974.31793475151, "episode/length": 320.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9844236760124611, "episode/intrinsic_return": 0.0}
{"step": 954088, "time": 28979.881503105164, "episode/length": 316.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9873817034700315, "episode/intrinsic_return": 0.0}
{"step": 954176, "time": 28983.103245019913, "episode/length": 269.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9962962962962963, "episode/intrinsic_return": 0.0}
{"step": 954304, "time": 28987.1584649086, "episode/length": 192.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 954872, "time": 29001.97949242592, "episode/length": 374.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.992, "episode/intrinsic_return": 0.0}
{"step": 954968, "time": 29005.214404821396, "episode/length": 373.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9973262032085561, "episode/intrinsic_return": 0.0}
{"step": 954968, "time": 29005.27347421646, "episode/length": 427.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9883177570093458, "episode/intrinsic_return": 0.0}
{"step": 955416, "time": 29017.232882738113, "episode/length": 165.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.963855421686747, "episode/intrinsic_return": 0.0}
{"step": 955472, "time": 29019.71066093445, "episode/length": 196.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9644670050761421, "episode/intrinsic_return": 0.0}
{"step": 955512, "time": 29021.32090640068, "episode/length": 67.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9852941176470589, "episode/intrinsic_return": 0.0}
{"step": 955864, "time": 29030.894201517105, "episode/length": 210.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 955912, "time": 29032.882871627808, "episode/length": 428.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9790209790209791, "episode/intrinsic_return": 0.0}
{"step": 956320, "time": 29044.090609550476, "episode/length": 251.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.996031746031746, "episode/intrinsic_return": 0.0}
{"step": 956320, "time": 29044.150197267532, "episode/length": 112.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9469026548672567, "episode/intrinsic_return": 0.0}
{"step": 956376, "time": 29046.19729232788, "episode/length": 187.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 957240, "time": 29068.24109005928, "episode/length": 220.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 957248, "time": 29069.52852511406, "episode/length": 166.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 957304, "time": 29071.614060640335, "episode/length": 291.0, "episode/score": 10.100000031292439, "episode/reward_rate": 0.9965753424657534, "episode/intrinsic_return": 0.0}
{"step": 957680, "time": 29081.944105386734, "episode/length": 162.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9631901840490797, "episode/intrinsic_return": 0.0}
{"step": 957696, "time": 29083.143825292587, "episode/length": 272.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 957816, "time": 29086.830547571182, "episode/length": 186.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 957960, "time": 29091.265404224396, "episode/length": 204.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 958584, "time": 29107.723124980927, "episode/length": 159.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 958736, "time": 29112.566563129425, "episode/length": 358.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9916434540389972, "episode/intrinsic_return": 0.0}
{"step": 959184, "time": 29124.40246796608, "episode/length": 187.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 959232, "time": 29126.415997982025, "episode/length": 247.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9758064516129032, "episode/intrinsic_return": 0.0}
{"step": 959432, "time": 29132.183351039886, "episode/length": 105.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9528301886792453, "episode/intrinsic_return": 0.0}
{"step": 959776, "time": 29141.772476911545, "episode/length": 316.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9873817034700315, "episode/intrinsic_return": 0.0}
{"step": 959993, "time": 29148.638323783875, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.206246553995963, "train/action_min": 0.0, "train/action_std": 3.0734066712228874, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.032607076734161834, "train/actor_opt_grad_steps": 58860.0, "train/actor_opt_loss": -8.920202097753018, "train/adv_mag": 0.4356288757335626, "train/adv_max": 0.3864085802621248, "train/adv_mean": 0.0020793532741541667, "train/adv_min": -0.3622176973728472, "train/adv_std": 0.04931950275050966, "train/cont_avg": 0.9951171875, "train/cont_loss_mean": 0.00015142011504109726, "train/cont_loss_std": 0.004600381033766467, "train/cont_neg_acc": 0.9959020156126756, "train/cont_neg_loss": 0.014508532156621247, "train/cont_pos_acc": 0.9999859050700539, "train/cont_pos_loss": 7.167700119090455e-05, "train/cont_pred": 0.995114105169853, "train/cont_rate": 0.9951171875, "train/dyn_loss_mean": 13.475222354870663, "train/dyn_loss_std": 9.426475041220632, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9570784859680103, "train/extr_critic_critic_opt_grad_steps": 58860.0, "train/extr_critic_critic_opt_loss": 15943.497406735945, "train/extr_critic_mag": 9.263307010157828, "train/extr_critic_max": 9.263307010157828, "train/extr_critic_mean": 2.723896415039683, "train/extr_critic_min": -0.24108836981668427, "train/extr_critic_std": 2.274212544044239, "train/extr_return_normed_mag": 1.4318312474985442, "train/extr_return_normed_max": 1.4318312474985442, "train/extr_return_normed_mean": 0.3749236204264837, "train/extr_return_normed_min": -0.08250703281192688, "train/extr_return_normed_std": 0.32173206910277097, "train/extr_return_rate": 0.8105952001074285, "train/extr_return_raw_mag": 10.307363993813548, "train/extr_return_raw_max": 10.307363993813548, "train/extr_return_raw_mean": 2.7387538458171643, "train/extr_return_raw_min": -0.536469343390191, "train/extr_return_raw_std": 2.3040255188371574, "train/extr_reward_mag": 1.034126993001363, "train/extr_reward_max": 1.034126993001363, "train/extr_reward_mean": 0.04535295241222712, "train/extr_reward_min": -0.4272426486585699, "train/extr_reward_std": 0.19914012876423923, "train/image_loss_mean": 6.843650566904168, "train/image_loss_std": 12.512378300205942, "train/model_loss_mean": 14.986295905409818, "train/model_loss_std": 16.363258653850647, "train/model_opt_grad_norm": 53.2839681725753, "train/model_opt_grad_steps": 58807.674641148325, "train/model_opt_loss": 19079.49778521232, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1273.9234449760766, "train/policy_entropy_mag": 2.51524682706623, "train/policy_entropy_max": 2.51524682706623, "train/policy_entropy_mean": 0.5103301712485592, "train/policy_entropy_min": 0.07937501452898865, "train/policy_entropy_std": 0.6503590557849008, "train/policy_logprob_mag": 7.438383727552788, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5108492787945214, "train/policy_logprob_min": -7.438383727552788, "train/policy_logprob_std": 1.0791224306850342, "train/policy_randomness_mag": 0.8877717530328121, "train/policy_randomness_max": 0.8877717530328121, "train/policy_randomness_mean": 0.18012415603444906, "train/policy_randomness_min": 0.02801589693642404, "train/policy_randomness_std": 0.22954820674001886, "train/post_ent_mag": 59.40423673419861, "train/post_ent_max": 59.40423673419861, "train/post_ent_mean": 42.84939434653834, "train/post_ent_min": 20.37304610841012, "train/post_ent_std": 7.636855371831136, "train/prior_ent_mag": 69.15527657686809, "train/prior_ent_max": 69.15527657686809, "train/prior_ent_mean": 56.39827357753042, "train/prior_ent_min": 41.47992660668478, "train/prior_ent_std": 4.504201816029526, "train/rep_loss_mean": 13.475222354870663, "train/rep_loss_std": 9.426475041220632, "train/reward_avg": 0.03127990412173802, "train/reward_loss_mean": 0.05736061032308916, "train/reward_loss_std": 0.2530606444657704, "train/reward_max_data": 1.0220095746254807, "train/reward_max_pred": 1.0159877732610019, "train/reward_neg_acc": 0.9928921295695328, "train/reward_neg_loss": 0.028785607577011915, "train/reward_pos_acc": 0.9720152978691758, "train/reward_pos_loss": 0.8370729602124702, "train/reward_pred": 0.03033293876796961, "train/reward_rate": 0.035660885167464115, "train_stats/sum_log_reward": 9.322222428189384, "train_stats/max_log_achievement_collect_coal": 1.1388888888888888, "train_stats/max_log_achievement_collect_drink": 5.777777777777778, "train_stats/max_log_achievement_collect_sapling": 1.3888888888888888, "train_stats/max_log_achievement_collect_stone": 14.722222222222221, "train_stats/max_log_achievement_collect_wood": 8.597222222222221, "train_stats/max_log_achievement_defeat_skeleton": 0.09027777777777778, "train_stats/max_log_achievement_defeat_zombie": 0.5277777777777778, "train_stats/max_log_achievement_eat_cow": 0.09027777777777778, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.006944444444444444, "train_stats/max_log_achievement_make_stone_sword": 0.006944444444444444, "train_stats/max_log_achievement_make_wood_pickaxe": 2.2777777777777777, "train_stats/max_log_achievement_make_wood_sword": 0.006944444444444444, "train_stats/max_log_achievement_place_furnace": 2.0069444444444446, "train_stats/max_log_achievement_place_plant": 1.3472222222222223, "train_stats/max_log_achievement_place_stone": 3.9027777777777777, "train_stats/max_log_achievement_place_table": 2.1944444444444446, "train_stats/max_log_achievement_wake_up": 1.6458333333333333, "train_stats/mean_log_entropy": 0.5216549794293113, "eval_stats/sum_log_reward": 8.516666854421297, "eval_stats/max_log_achievement_collect_coal": 0.9583333333333334, "eval_stats/max_log_achievement_collect_drink": 5.958333333333333, "eval_stats/max_log_achievement_collect_sapling": 1.2083333333333333, "eval_stats/max_log_achievement_collect_stone": 13.5, "eval_stats/max_log_achievement_collect_wood": 9.583333333333334, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.7083333333333334, "eval_stats/max_log_achievement_eat_cow": 0.16666666666666666, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.041666666666666664, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 2.5, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 1.6666666666666667, "eval_stats/max_log_achievement_place_plant": 1.1666666666666667, "eval_stats/max_log_achievement_place_stone": 3.9166666666666665, "eval_stats/max_log_achievement_place_table": 2.625, "eval_stats/max_log_achievement_wake_up": 1.875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 3.34680407831911e-06, "report/cont_loss_std": 7.553647446911782e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 1.2217327821417712e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 3.320739551782026e-06, "report/cont_pred": 0.9970670938491821, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 14.484956741333008, "report/dyn_loss_std": 9.13802433013916, "report/image_loss_mean": 6.767348289489746, "report/image_loss_std": 14.492715835571289, "report/model_loss_mean": 15.506952285766602, "report/model_loss_std": 18.047025680541992, "report/post_ent_mag": 61.94001770019531, "report/post_ent_max": 61.94001770019531, "report/post_ent_mean": 41.43305969238281, "report/post_ent_min": 18.517168045043945, "report/post_ent_std": 7.65654993057251, "report/prior_ent_mag": 69.59486389160156, "report/prior_ent_max": 69.59486389160156, "report/prior_ent_mean": 56.40711975097656, "report/prior_ent_min": 40.117652893066406, "report/prior_ent_std": 4.689889907836914, "report/rep_loss_mean": 14.484956741333008, "report/rep_loss_std": 9.13802433013916, "report/reward_avg": 0.02460937388241291, "report/reward_loss_mean": 0.048626936972141266, "report/reward_loss_std": 0.20846515893936157, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0093822479248047, "report/reward_neg_acc": 0.9949748516082764, "report/reward_neg_loss": 0.024721335619688034, "report/reward_pos_acc": 0.9655172228813171, "report/reward_pos_loss": 0.8688362240791321, "report/reward_pred": 0.023500509560108185, "report/reward_rate": 0.0283203125, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 3.993314408035076e-07, "eval/cont_loss_std": 7.087627409418928e-07, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 1.0533896784181707e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 3.794986298544245e-07, "eval/cont_pred": 0.9980466365814209, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 20.193161010742188, "eval/dyn_loss_std": 10.875030517578125, "eval/image_loss_mean": 10.086029052734375, "eval/image_loss_std": 13.735771179199219, "eval/model_loss_mean": 22.32806968688965, "eval/model_loss_std": 17.96734046936035, "eval/post_ent_mag": 56.323219299316406, "eval/post_ent_max": 56.323219299316406, "eval/post_ent_mean": 38.89728546142578, "eval/post_ent_min": 21.850521087646484, "eval/post_ent_std": 7.407726287841797, "eval/prior_ent_mag": 69.59486389160156, "eval/prior_ent_max": 69.59486389160156, "eval/prior_ent_mean": 55.97686004638672, "eval/prior_ent_min": 44.07145690917969, "eval/prior_ent_std": 3.6729536056518555, "eval/rep_loss_mean": 20.193161010742188, "eval/rep_loss_std": 10.875030517578125, "eval/reward_avg": 0.0458984375, "eval/reward_loss_mean": 0.12614354491233826, "eval/reward_loss_std": 0.7620542645454407, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0047821998596191, "eval/reward_neg_acc": 0.9876922965049744, "eval/reward_neg_loss": 0.03873123973608017, "eval/reward_pos_acc": 0.8163264989852905, "eval/reward_pos_loss": 1.8654698133468628, "eval/reward_pred": 0.04278569668531418, "eval/reward_rate": 0.0478515625, "replay/size": 959489.0, "replay/inserts": 33480.0, "replay/samples": 33488.0, "replay/insert_wait_avg": 1.2310602331674226e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 5.864849286505439e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 9048.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2295368390205579e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 6.854534149169922e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0100893974304, "timer/env.step_count": 4185.0, "timer/env.step_total": 131.5827922821045, "timer/env.step_frac": 0.13158146470441262, "timer/env.step_avg": 0.03144152742702616, "timer/env.step_min": 0.0023615360260009766, "timer/env.step_max": 0.9414610862731934, "timer/replay._sample_count": 33488.0, "timer/replay._sample_total": 2963.425279855728, "timer/replay._sample_frac": 2.9633953809819857, "timer/replay._sample_avg": 0.08849215479741185, "timer/replay._sample_min": 0.00038886070251464844, "timer/replay._sample_max": 0.11286520957946777, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5316.0, "timer/agent.policy_total": 55.03513979911804, "timer/agent.policy_frac": 0.055034584533322266, "timer/agent.policy_avg": 0.01035273510141423, "timer/agent.policy_min": 0.0077702999114990234, "timer/agent.policy_max": 0.024608373641967773, "timer/dataset_train_count": 2093.0, "timer/dataset_train_total": 0.17634105682373047, "timer/dataset_train_frac": 0.0001763392776666755, "timer/dataset_train_avg": 8.425277440216458e-05, "timer/dataset_train_min": 6.151199340820312e-05, "timer/dataset_train_max": 0.00013709068298339844, "timer/agent.train_count": 2093.0, "timer/agent.train_total": 778.5410833358765, "timer/agent.train_frac": 0.7785332284047223, "timer/agent.train_avg": 0.3719737617467159, "timer/agent.train_min": 0.3514835834503174, "timer/agent.train_max": 2.2290568351745605, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.40297484397888184, "timer/agent.report_frac": 0.0004029707782465473, "timer/agent.report_avg": 0.20148742198944092, "timer/agent.report_min": 0.2005467414855957, "timer/agent.report_max": 0.20242810249328613, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.552436828613281e-05, "timer/dataset_eval_frac": 3.552400987027891e-08, "timer/dataset_eval_avg": 3.552436828613281e-05, "timer/dataset_eval_min": 3.552436828613281e-05, "timer/dataset_eval_max": 3.552436828613281e-05, "fps": 33.47914307907}
{"step": 960024, "time": 29153.5957467556, "eval_episode/length": 191.0, "eval_episode/score": 9.099999964237213, "eval_episode/reward_rate": 0.9739583333333334}
{"step": 960024, "time": 29155.0579931736, "eval_episode/length": 228.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9650655021834061}
{"step": 960024, "time": 29156.116184949875, "eval_episode/length": 237.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9957983193277311}
{"step": 960024, "time": 29157.08984899521, "eval_episode/length": 242.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9958847736625515}
{"step": 960024, "time": 29158.367730379105, "eval_episode/length": 266.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9775280898876404}
{"step": 960024, "time": 29159.444697618484, "eval_episode/length": 86.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9425287356321839}
{"step": 960024, "time": 29160.59997153282, "eval_episode/length": 291.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9965753424657534}
{"step": 960024, "time": 29162.03026008606, "eval_episode/length": 319.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.984375}
{"step": 960192, "time": 29166.736461639404, "episode/length": 181.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 960608, "time": 29178.274860858917, "episode/length": 363.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9917582417582418, "episode/intrinsic_return": 0.0}
{"step": 960648, "time": 29179.943187475204, "episode/length": 353.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9887005649717514, "episode/intrinsic_return": 0.0}
{"step": 960968, "time": 29188.816120147705, "episode/length": 191.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 960976, "time": 29190.032489299774, "episode/length": 45.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.8913043478260869, "episode/intrinsic_return": 0.0}
{"step": 961384, "time": 29200.846355438232, "episode/length": 274.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9963636363636363, "episode/intrinsic_return": 0.0}
{"step": 961408, "time": 29202.43657064438, "episode/length": 430.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9791183294663574, "episode/intrinsic_return": 0.0}
{"step": 961880, "time": 29214.55917239189, "episode/length": 153.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9545454545454546, "episode/intrinsic_return": 0.0}
{"step": 961960, "time": 29217.452261209488, "episode/length": 220.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9728506787330317, "episode/intrinsic_return": 0.0}
{"step": 962248, "time": 29225.454874277115, "episode/length": 376.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9893899204244032, "episode/intrinsic_return": 0.0}
{"step": 962384, "time": 29229.781304359436, "episode/length": 176.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9661016949152542, "episode/intrinsic_return": 0.0}
{"step": 962464, "time": 29232.626158714294, "episode/length": 335.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9970238095238095, "episode/intrinsic_return": 0.0}
{"step": 963024, "time": 29247.40911912918, "episode/length": 204.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9707317073170731, "episode/intrinsic_return": 0.0}
{"step": 963224, "time": 29253.039600133896, "episode/length": 157.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 963752, "time": 29267.102380514145, "episode/length": 233.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9786324786324786, "episode/intrinsic_return": 0.0}
{"step": 963800, "time": 29269.142395734787, "episode/length": 176.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9661016949152542, "episode/intrinsic_return": 0.0}
{"step": 963992, "time": 29274.83147406578, "episode/length": 376.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9946949602122016, "episode/intrinsic_return": 0.0}
{"step": 964224, "time": 29281.67337703705, "episode/length": 149.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 964576, "time": 29291.193861484528, "episode/length": 168.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 964752, "time": 29296.33136987686, "episode/length": 124.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.952, "episode/intrinsic_return": 0.0}
{"step": 964808, "time": 29298.479367494583, "episode/length": 424.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9788235294117648, "episode/intrinsic_return": 0.0}
{"step": 964904, "time": 29301.634860754013, "episode/length": 304.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9967213114754099, "episode/intrinsic_return": 0.0}
{"step": 965096, "time": 29307.14037823677, "episode/length": 355.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9915730337078652, "episode/intrinsic_return": 0.0}
{"step": 965144, "time": 29309.14634013176, "episode/length": 167.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 965776, "time": 29325.86562204361, "episode/length": 193.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 966008, "time": 29332.34269618988, "episode/length": 113.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9473684210526315, "episode/intrinsic_return": 0.0}
{"step": 966384, "time": 29342.573281288147, "episode/length": 203.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 966448, "time": 29344.958121299744, "episode/length": 233.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9786324786324786, "episode/intrinsic_return": 0.0}
{"step": 966592, "time": 29349.440774679184, "episode/length": 222.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 966872, "time": 29356.99892926216, "episode/length": 245.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9959349593495935, "episode/intrinsic_return": 0.0}
{"step": 966960, "time": 29360.14476943016, "episode/length": 226.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9779735682819384, "episode/intrinsic_return": 0.0}
{"step": 967200, "time": 29366.88679766655, "episode/length": 400.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9925187032418953, "episode/intrinsic_return": 0.0}
{"step": 967440, "time": 29373.666786193848, "episode/length": 131.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9621212121212122, "episode/intrinsic_return": 0.0}
{"step": 967968, "time": 29387.761031150818, "episode/length": 244.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.0}
{"step": 968072, "time": 29391.007870912552, "episode/length": 149.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 968280, "time": 29397.011933088303, "episode/length": 210.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 968888, "time": 29412.959229946136, "episode/length": 210.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 969008, "time": 29416.95596575737, "episode/length": 403.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9777227722772277, "episode/intrinsic_return": 0.0}
{"step": 969008, "time": 29417.015870809555, "episode/length": 319.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.996875, "episode/intrinsic_return": 0.0}
{"step": 969048, "time": 29418.662702083588, "episode/length": 200.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9800995024875622, "episode/intrinsic_return": 0.0}
{"step": 969576, "time": 29432.89671397209, "episode/length": 65.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9848484848484849, "episode/intrinsic_return": 0.0}
{"step": 969768, "time": 29438.399918556213, "episode/length": 350.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9943019943019943, "episode/intrinsic_return": 0.0}
{"step": 970008, "time": 29447.783629179, "eval_episode/length": 112.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9911504424778761}
{"step": 970008, "time": 29448.959792137146, "eval_episode/length": 133.0, "eval_episode/score": 9.100000023841858, "eval_episode/reward_rate": 0.9925373134328358}
{"step": 970008, "time": 29450.774763822556, "eval_episode/length": 186.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9732620320855615}
{"step": 970008, "time": 29451.791794538498, "eval_episode/length": 193.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9742268041237113}
{"step": 970008, "time": 29453.19120502472, "eval_episode/length": 222.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9775784753363229}
{"step": 970008, "time": 29454.348762750626, "eval_episode/length": 239.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.975}
{"step": 970008, "time": 29455.31481218338, "eval_episode/length": 245.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9634146341463414}
{"step": 970008, "time": 29456.313262701035, "eval_episode/length": 67.0, "eval_episode/score": 6.100000023841858, "eval_episode/reward_rate": 0.9852941176470589}
{"step": 970080, "time": 29458.48611187935, "episode/length": 38.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 970152, "time": 29460.91425395012, "episode/length": 259.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9961538461538462, "episode/intrinsic_return": 0.0}
{"step": 970360, "time": 29466.939616918564, "episode/length": 298.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9832775919732442, "episode/intrinsic_return": 0.0}
{"step": 970640, "time": 29474.91140604019, "episode/length": 203.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 970704, "time": 29477.3966653347, "episode/length": 302.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 970784, "time": 29480.168612003326, "episode/length": 78.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9873417721518988, "episode/intrinsic_return": 0.0}
{"step": 970960, "time": 29485.48206424713, "episode/length": 172.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 971624, "time": 29502.673060178757, "episode/length": 341.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9883040935672515, "episode/intrinsic_return": 0.0}
{"step": 971800, "time": 29508.00211572647, "episode/length": 214.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9720930232558139, "episode/intrinsic_return": 0.0}
{"step": 971840, "time": 29510.089485168457, "episode/length": 353.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 972008, "time": 29514.824032068253, "episode/length": 205.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9805825242718447, "episode/intrinsic_return": 0.0}
{"step": 972416, "time": 29526.135979890823, "episode/length": 213.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9719626168224299, "episode/intrinsic_return": 0.0}
{"step": 972528, "time": 29529.772958040237, "episode/length": 217.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 972576, "time": 29531.755152225494, "episode/length": 241.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9958677685950413, "episode/intrinsic_return": 0.0}
